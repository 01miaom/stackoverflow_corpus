"","V1","V2","V3","V4"
"data","time","queation head","question body","answer"
"data_i","edited Oct 20 '21 at 20:07","
        Why is processing a sorted array faster than processing an unsorted array?
    ","Here is a piece of C++ code that shows some very peculiar behavior. For some strange reason, sorting the data (before the timed region) miraculously makes the loop almost six times faster.#include <algorithm>#include <ctime>#include <iostream>int main(){    // Generate data    const unsigned arraySize = 32768;    int data[arraySize];    for (unsigned c = 0; c < arraySize; ++c)        data[c] = std::rand() % 256;    // !!! With this, the next loop runs faster.    std::sort(data, data + arraySize);    // Test    clock_t start = clock();    long long sum = 0;    for (unsigned i = 0; i < 100000; ++i)    {        for (unsigned c = 0; c < arraySize; ++c)        {   // Primary loop            if (data[c] >= 128)                sum += data[c];        }    }    double elapsedTime = static_cast<double>(clock()-start) / CLOCKS_PER_SEC;    std::cout << elapsedTime << '\n';    std::cout << ""sum = "" << sum << '\n';}Without std::sort(data, data + arraySize);, the code runs in 11.54 seconds.With the sorted data, the code runs in 1.93 seconds.(Sorting itself takes more time than this one pass over the array, so it's not actually worth doing if we needed to calculate this for an unknown array.)Initially, I thought this might be just a language or compiler anomaly, so I tried Java:import java.util.Arrays;import java.util.Random;public class Main{    public static void main(String[] args)    {        // Generate data        int arraySize = 32768;        int data[] = new int[arraySize];        Random rnd = new Random(0);        for (int c = 0; c < arraySize; ++c)            data[c] = rnd.nextInt() % 256;        // !!! With this, the next loop runs faster        Arrays.sort(data);        // Test        long start = System.nanoTime();        long sum = 0;        for (int i = 0; i < 100000; ++i)        {            for (int c = 0; c < arraySize; ++c)            {   // Primary loop                if (data[c] >= 128)                    sum += data[c];            }        }        System.out.println((System.nanoTime() - start) / 1000000000.0);        System.out.println(""sum = "" + sum);    }}With a similar but less extreme result.My first thought was that sorting brings the data into the cache, but then I thought how silly that was because the array was just generated.What is going on?Why is processing a sorted array faster than processing an unsorted array?The code is summing up some independent terms, so the order should not matter.Related / followup Q&As about the same effect with different / later compilers and options:Why is processing an unsorted array the same speed as processing a sorted array with modern x86-64 clang?gcc optimization flag -O3 makes code slower than -O2","You are a victim of branch prediction fail.What is Branch Prediction?Consider a railroad junction:Image by Mecanismo, via Wikimedia Commons. Used under the CC-By-SA 3.0 license.Now for the sake of argument, suppose this is back in the 1800s - before long-distance or radio communication.You are a blind operator of a junction and you hear a train coming. You have no idea which way it is supposed to go. You stop the train to ask the driver which direction they want. And then you set the switch appropriately.Trains are heavy and have a lot of inertia, so they take forever to start up and slow down.Is there a better way? You guess which direction the train will go!If you guessed right, it continues on.If you guessed wrong, the captain will stop, back up, and yell at you to flip the switch. Then it can restart down the other path.If you guess right every time, the train will never have to stop.If you guess wrong too often, the train will spend a lot of time stopping, backing up, and restarting.Consider an if-statement: At the processor level, it is a branch instruction:You are a processor and you see a branch. You have no idea which way it will go. What do you do? You halt execution and wait until the previous instructions are complete. Then you continue down the correct path.Modern processors are complicated and have long pipelines. This means they take forever to ""warm up"" and ""slow down"".Is there a better way? You guess which direction the branch will go!If you guessed right, you continue executing.If you guessed wrong, you need to flush the pipeline and roll back to the branch. Then you can restart down the other path.If you guess right every time, the execution will never have to stop.If you guess wrong too often, you spend a lot of time stalling, rolling back, and restarting.This is branch prediction. I admit it's not the best analogy since the train could just signal the direction with a flag. But in computers, the processor doesn't know which direction a branch will go until the last moment.How would you strategically guess to minimize the number of times that the train must back up and go down the other path? You look at the past history! If the train goes left 99% of the time, then you guess left. If it alternates, then you alternate your guesses. If it goes one way every three times, you guess the same...In other words, you try to identify a pattern and follow it. This is more or less how branch predictors work.Most applications have well-behaved branches. Therefore, modern branch predictors will typically achieve >90% hit rates. But when faced with unpredictable branches with no recognizable patterns, branch predictors are virtually useless.Further reading: ""Branch predictor"" article on Wikipedia.As hinted from above, the culprit is this if-statement:if (data[c] >= 128)    sum += data[c];Notice that the data is evenly distributed between 0 and 255. When the data is sorted, roughly the first half of the iterations will not enter the if-statement. After that, they will all enter the if-statement.This is very friendly to the branch predictor since the branch consecutively goes the same direction many times. Even a simple saturating counter will correctly predict the branch except for the few iterations after it switches direction.Quick visualization:T = branch takenN = branch not takendata[] = 0, 1, 2, 3, 4, ... 126, 127, 128, 129, 130, ... 250, 251, 252, ...branch = N  N  N  N  N  ...   N    N    T    T    T  ...   T    T    T  ...       = NNNNNNNNNNNN ... NNNNNNNTTTTTTTTT ... TTTTTTTTTT  (easy to predict)However, when the data is completely random, the branch predictor is rendered useless, because it can't predict random data. Thus there will probably be around 50% misprediction (no better than random guessing).data[] = 226, 185, 125, 158, 198, 144, 217, 79, 202, 118,  14, 150, 177, 182, ...branch =   T,   T,   N,   T,   T,   T,   T,  N,   T,   N,   N,   T,   T,   T  ...       = TTNTTTTNTNNTTT ...   (completely random - impossible to predict)What can be done?If the compiler isn't able to optimize the branch into a conditional move, you can try some hacks if you are willing to sacrifice readability for performance.Replace:if (data[c] >= 128)    sum += data[c];with:int t = (data[c] - 128) >> 31;sum += ~t & data[c];This eliminates the branch and replaces it with some bitwise operations.(Note that this hack is not strictly equivalent to the original if-statement. But in this case, it's valid for all the input values of data[].)Benchmarks: Core i7 920 @ 3.5 GHzC++ - Visual Studio 2010 - x64 ReleaseScenarioTime (seconds)Branching - Random data11.777Branching - Sorted data2.352Branchless - Random data2.564Branchless - Sorted data2.587Java - NetBeans 7.1.1 JDK 7 - x64ScenarioTime (seconds)Branching - Random data10.93293813Branching - Sorted data5.643797077Branchless - Random data3.113581453Branchless - Sorted data3.186068823Observations:With the Branch: There is a huge difference between the sorted and unsorted data.With the Hack: There is no difference between sorted and unsorted data.In the C++ case, the hack is actually a tad slower than with the branch when the data is sorted.A general rule of thumb is to avoid data-dependent branching in critical loops (such as in this example).Update:GCC 4.6.1 with -O3 or -ftree-vectorize on x64 is able to generate a conditional move, so there is no difference between the sorted and unsorted data - both are fast.(Or somewhat fast: for the already-sorted case, cmov can be slower especially if GCC puts it on the critical path instead of just add, especially on Intel before Broadwell where cmov has 2 cycle latency: gcc optimization flag -O3 makes code slower than -O2)VC++ 2010 is unable to generate conditional moves for this branch even under /Ox.Intel C++ Compiler (ICC) 11 does something miraculous. It interchanges the two loops, thereby hoisting the unpredictable branch to the outer loop. Not only is it immune to the mispredictions, it's also twice as fast as whatever VC++ and GCC can generate! In other words, ICC took advantage of the test-loop to defeat the benchmark...If you give the Intel compiler the branchless code, it just outright vectorizes it... and is just as fast as with the branch (with the loop interchange).This goes to show that even mature modern compilers can vary wildly in their ability to optimize code..."
"data_i","edited Jul 04 '22 at 23:35","
        How do I undo the most recent local commits in Git?
    ","I accidentally committed the wrong files to Git, but didn't push the commit to the server yet. How do I undo those commits from the local repository?","Undo a commit & redo$ git commit -m ""Something terribly misguided"" # (0: Your Accident)$ git reset HEAD~                              # (1)[ edit files as necessary ]                    # (2)$ git add .                                    # (3)$ git commit -c ORIG_HEAD                      # (4)git reset is the command responsible for the undo. It will undo your last commit while leaving your working tree (the state of your files on disk) untouched. You'll need to add them again before you can commit them again).Make corrections to working tree files.git add anything that you want to include in your new commit.Commit the changes, reusing the old commit message. reset copied the old head to .git/ORIG_HEAD; commit with -c ORIG_HEAD will open an editor, which initially contains the log message from the old commit and allows you to edit it. If you do not need to edit the message, you could use the -C option.Alternatively, to edit the previous commit (or just its commit message), commit --amend will add changes within the current index to the previous commit.To remove (not revert) a commit that has been pushed to the server, rewriting history with git push origin main --force[-with-lease] is necessary. It's almost always a bad idea to use --force; prefer --force-with-lease instead, and as noted in the git manual:You should understand the implications of rewriting history if you [rewrite history] has already been published.Further ReadingYou can use git reflog to determine the SHA-1 for the commit to which you wish to revert. Once you have this value, use the sequence of commands as explained above.HEAD~ is the same as HEAD~1. The article What is the HEAD in git? is helpful if you want to uncommit multiple commits."
"data_i","edited Jul 24 '22 at 23:07","
        How do I delete a Git branch locally and remotely?
    ","Failed Attempts to Delete a Remote Branch:$ git branch -d remotes/origin/bugfixerror: branch 'remotes/origin/bugfix' not found.$ git branch -d origin/bugfixerror: branch 'origin/bugfix' not found.$ git branch -rd origin/bugfixDeleted remote branch origin/bugfix (was 2a14ef7).$ git pushEverything up-to-date$ git pullFrom github.com:gituser/gitproject* [new branch] bugfix -> origin/bugfixAlready up-to-date.How do I properly delete the remotes/origin/bugfix branch both locally and remotely?","Executive Summarygit push -d <remote_name> <branchname>git branch -d <branchname>Note: In most cases, <remote_name> will be origin.Delete Local BranchTo delete the local branch use one of the following:git branch -d <branch_name>git branch -D <branch_name>The -d option is an alias for --delete, which only deletes the branch if it has already been fully merged in its upstream branch.The -D option is an alias for --delete --force, which deletes the branch ""irrespective of its merged status."" [Source: man git-branch]As of Git v2.3, git branch -d (delete) learned to honor the -f (force) flag.You will receive an error if you try to delete the currently selected branch.Delete Remote BranchAs of Git v1.7.0, you can delete a remote branch using$ git push <remote_name> --delete <branch_name>which might be easier to remember than$ git push <remote_name> :<branch_name>which was added in Git v1.5.0 ""to delete a remote branch or a tag.""Starting with Git v2.8.0, you can also use git push with the -d option as an alias for --delete. Therefore, the version of Git you have installed will dictate whether you need to use the easier or harder syntax.Delete Remote Branch [Original Answer from 5-Jan-2010]From Chapter 3 of Pro Git by Scott Chacon:Deleting Remote BranchesSuppose you’re done with a remote branch — say, you and your collaborators are finished with a feature and have merged it into your remote’s main branch (or whatever branch your stable code-line is in). You can delete a remote branch using the rather obtuse syntax git push [remotename] :[branch]. If you want to delete your server-fix branch from the server, you run the following:$ git push origin :serverfixTo git@github.com:schacon/simplegit.git - [deleted]         serverfixBoom. No more branches on your server. You may want to dog-ear this page, because you’ll need that command, and you’ll likely forget the syntax. A way to remember this command is by recalling the git push [remotename] [localbranch]:[remotebranch] syntax that we went over a bit earlier. If you leave off the [localbranch] portion, then you’re basically saying, “Take nothing on my side and make it be [remotebranch].”I issued git push origin: bugfix and it worked beautifully. Scott Chacon was right—I will want to dog ear that page (or virtually dog ear by answering this on Stack Overflow).Then you should execute this on other machines# Fetch changes from all remotes and locally delete # remote deleted branches/tags etc# --prune will do the job :-;git fetch --all --pruneto propagate changes."
"data_i","edited Jul 18 '22 at 18:44","
        What is the difference between 'git pull' and 'git fetch'?
    ","What are the differences between git pull and git fetch?","In the simplest terms, git pull does a git fetch followed by a git merge.git fetch updates your remote-tracking branches under refs/remotes/<remote>/. This operation is safe to run at any time since it never changes any of your local branches under refs/heads.git pull brings a local branch up-to-date with its remote version, while also updating your other remote-tracking branches.From the Git documentation for git pull:In its default mode, git pull is shorthand for git fetch followed by git merge FETCH_HEAD."
"data_i","edited Jun 05 '22 at 22:03","
        What does the ""yield"" keyword do?
    ","What is the use of the yield keyword in Python? What does it do?For example, I'm trying to understand this code1:def _get_child_candidates(self, distance, min_dist, max_dist):    if self._leftchild and distance - max_dist < self._median:        yield self._leftchild    if self._rightchild and distance + max_dist >= self._median:        yield self._rightchild  And this is the caller:result, candidates = [], [self]while candidates:    node = candidates.pop()    distance = node._get_dist(obj)    if distance <= max_dist and distance >= min_dist:        result.extend(node._values)    candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))return resultWhat happens when the method _get_child_candidates is called?Is a list returned? A single element? Is it called again? When will subsequent calls stop?1. This piece of code was written by Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.","To understand what yield does, you must understand what generators are. And before you can understand generators, you must understand iterables.IterablesWhen you create a list, you can read its items one by one. Reading its items one by one is called iteration:>>> mylist = [1, 2, 3]>>> for i in mylist:...    print(i)123mylist is an iterable. When you use a list comprehension, you create a list, and so an iterable:>>> mylist = [x*x for x in range(3)]>>> for i in mylist:...    print(i)014Everything you can use ""for... in..."" on is an iterable; lists, strings, files...These iterables are handy because you can read them as much as you wish, but you store all the values in memory and this is not always what you want when you have a lot of values.GeneratorsGenerators are iterators, a kind of iterable you can only iterate over once. Generators do not store all the values in memory, they generate the values on the fly:>>> mygenerator = (x*x for x in range(3))>>> for i in mygenerator:...    print(i)014It is just the same except you used () instead of []. BUT, you cannot perform for i in mygenerator a second time since generators can only be used once: they calculate 0, then forget about it and calculate 1, and end calculating 4, one by one.Yieldyield is a keyword that is used like return, except the function will return a generator.>>> def create_generator():...    mylist = range(3)...    for i in mylist:...        yield i*i...>>> mygenerator = create_generator() # create a generator>>> print(mygenerator) # mygenerator is an object!<generator object create_generator at 0xb7555c34>>>> for i in mygenerator:...     print(i)014Here it's a useless example, but it's handy when you know your function will return a huge set of values that you will only need to read once.To master yield, you must understand that when you call the function, the code you have written in the function body does not run. The function only returns the generator object, this is a bit tricky.Then, your code will continue from where it left off each time for uses the generator.Now the hard part:The first time the for calls the generator object created from your function, it will run the code in your function from the beginning until it hits yield, then it'll return the first value of the loop. Then, each subsequent call will run another iteration of the loop you have written in the function and return the next value. This will continue until the generator is considered empty, which happens when the function runs without hitting yield. That can be because the loop has come to an end, or because you no longer satisfy an ""if/else"".Your code explainedGenerator:# Here you create the method of the node object that will return the generatordef _get_child_candidates(self, distance, min_dist, max_dist):    # Here is the code that will be called each time you use the generator object:    # If there is still a child of the node object on its left    # AND if the distance is ok, return the next child    if self._leftchild and distance - max_dist < self._median:        yield self._leftchild    # If there is still a child of the node object on its right    # AND if the distance is ok, return the next child    if self._rightchild and distance + max_dist >= self._median:        yield self._rightchild    # If the function arrives here, the generator will be considered empty    # there is no more than two values: the left and the right childrenCaller:# Create an empty list and a list with the current object referenceresult, candidates = list(), [self]# Loop on candidates (they contain only one element at the beginning)while candidates:    # Get the last candidate and remove it from the list    node = candidates.pop()    # Get the distance between obj and the candidate    distance = node._get_dist(obj)    # If distance is ok, then you can fill the result    if distance <= max_dist and distance >= min_dist:        result.extend(node._values)    # Add the children of the candidate in the candidate's list    # so the loop will keep running until it will have looked    # at all the children of the children of the children, etc. of the candidate    candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))return resultThis code contains several smart parts:The loop iterates on a list, but the list expands while the loop is being iterated. It's a concise way to go through all these nested data even if it's a bit dangerous since you can end up with an infinite loop. In this case, candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) exhaust all the values of the generator, but while keeps creating new generator objects which will produce different values from the previous ones since it's not applied on the same node.The extend() method is a list object method that expects an iterable and adds its values to the list.Usually we pass a list to it:>>> a = [1, 2]>>> b = [3, 4]>>> a.extend(b)>>> print(a)[1, 2, 3, 4]But in your code, it gets a generator, which is good because:You don't need to read the values twice.You may have a lot of children and you don't want them all stored in memory.And it works because Python does not care if the argument of a method is a list or not. Python expects iterables so it will work with strings, lists, tuples, and generators! This is called duck typing and is one of the reasons why Python is so cool. But this is another story, for another question...You can stop here, or read a little bit to see an advanced use of a generator:Controlling a generator exhaustion>>> class Bank(): # Let's create a bank, building ATMs...    crisis = False...    def create_atm(self):...        while not self.crisis:...            yield ""$100"">>> hsbc = Bank() # When everything's ok the ATM gives you as much as you want>>> corner_street_atm = hsbc.create_atm()>>> print(corner_street_atm.next())$100>>> print(corner_street_atm.next())$100>>> print([corner_street_atm.next() for cash in range(5)])['$100', '$100', '$100', '$100', '$100']>>> hsbc.crisis = True # Crisis is coming, no more money!>>> print(corner_street_atm.next())<type 'exceptions.StopIteration'>>>> wall_street_atm = hsbc.create_atm() # It's even true for new ATMs>>> print(wall_street_atm.next())<type 'exceptions.StopIteration'>>>> hsbc.crisis = False # The trouble is, even post-crisis the ATM remains empty>>> print(corner_street_atm.next())<type 'exceptions.StopIteration'>>>> brand_new_atm = hsbc.create_atm() # Build a new one to get back in business>>> for cash in brand_new_atm:...    print cash$100$100$100$100$100$100$100$100$100...Note: For Python 3, useprint(corner_street_atm.__next__()) or print(next(corner_street_atm))It can be useful for various things like controlling access to a resource.Itertools, your best friendThe itertools module contains special functions to manipulate iterables. Ever wish to duplicate a generator?Chain two generators? Group values in a nested list with a one-liner? Map / Zip without creating another list?Then just import itertools.An example? Let's see the possible orders of arrival for a four-horse race:>>> horses = [1, 2, 3, 4]>>> races = itertools.permutations(horses)>>> print(races)<itertools.permutations object at 0xb754f1dc>>>> print(list(itertools.permutations(horses)))[(1, 2, 3, 4), (1, 2, 4, 3), (1, 3, 2, 4), (1, 3, 4, 2), (1, 4, 2, 3), (1, 4, 3, 2), (2, 1, 3, 4), (2, 1, 4, 3), (2, 3, 1, 4), (2, 3, 4, 1), (2, 4, 1, 3), (2, 4, 3, 1), (3, 1, 2, 4), (3, 1, 4, 2), (3, 2, 1, 4), (3, 2, 4, 1), (3, 4, 1, 2), (3, 4, 2, 1), (4, 1, 2, 3), (4, 1, 3, 2), (4, 2, 1, 3), (4, 2, 3, 1), (4, 3, 1, 2), (4, 3, 2, 1)]Understanding the inner mechanisms of iterationIteration is a process implying iterables (implementing the __iter__() method) and iterators (implementing the __next__() method).Iterables are any objects you can get an iterator from. Iterators are objects that let you iterate on iterables.There is more about it in this article about how for loops work."
"data_i","edited Aug 29 '22 at 10:22","
        Which JSON content type do I use?
    ","There are many ""standards"" for the JSON content type:application/jsonapplication/x-javascripttext/javascripttext/x-javascripttext/x-jsonWhich one do I use, and where? I assume security and browser support issues are a factor.Related: What MIME type if JSON is being returned by a REST API?","For JSON text:application/jsonThe MIME media type for JSON text is application/json. The default encoding is UTF-8. (Source: RFC 4627)For JSONP (runnable JavaScript) with callback:application/javascriptHere are some blog posts that were mentioned in the relevant comments:Why you shouldn't use text/html for JSONInternet Explorer sometimes has issues with application/jsonA rather complete list of Mimetypes and what to use them forThe official mime type list at IANA from @gnrfan's answer below"
"data_i","edited Mar 28 '22 at 12:14","
        How can I remove a specific item from an array?
    ","How do I remove a specific value from an array? Something like:array.remove(value);  // removes all elements with valueI have to use core JavaScript. Frameworks are not allowed.","Find the index of the array element you want to remove using indexOf, and then remove that index with splice.The splice() method changes the contents of an array by removingexisting elements and/or adding new elements.const array = [2, 5, 9];console.log(array);const index = array.indexOf(5);if (index > -1) { // only splice array when item is found  array.splice(index, 1); // 2nd parameter means remove one item only}// array = [2, 9]console.log(array); The second parameter of splice is the number of elements to remove. Note that splice modifies the array in place and returns a new array containing the elements that have been removed.For the reason of completeness, here are functions. The first function removes only a single occurrence (i.e. removing the first match of 5 from [2,5,9,1,5,8,5]), while the second function removes all occurrences:function removeItemOnce(arr, value) {  var index = arr.indexOf(value);  if (index > -1) {    arr.splice(index, 1);  }  return arr;}function removeItemAll(arr, value) {  var i = 0;  while (i < arr.length) {    if (arr[i] === value) {      arr.splice(i, 1);    } else {      ++i;    }  }  return arr;}// Usageconsole.log(removeItemOnce([2,5,9,1,5,8,5], 5))console.log(removeItemAll([2,5,9,1,5,8,5], 5))In TypeScript, these functions can stay type-safe with a type parameter:function removeItem<T>(arr: Array<T>, value: T): Array<T> {   const index = arr.indexOf(value);  if (index > -1) {    arr.splice(index, 1);  }  return arr;}"
"data_i","edited Jul 25 '22 at 03:51","
        How do I rename a local Git branch?
    ","How do I rename a local branch which has not yet been pushed to a remote repository?Related:Rename master branch for both local and remote Git repositoriesHow do I rename both a Git local and remote branch name?","To rename the current branch:git branch -m <newname>To rename a branch while pointed to any branch:git branch -m <oldname> <newname>-m is short for --move.To push the  local branch and reset the upstream branch:git push origin -u <newname>To delete the  remote branch:git push origin --delete <oldname>To create a git rename alias:git config --global alias.rename 'branch -m'On Windows or another case-insensitive filesystem, use -M if there are only capitalization changes in the name. Otherwise, Git will throw a ""branch already exists"" error.git branch -M <newname>"
"data_i","edited Jul 25 '22 at 02:07","
        How do I undo 'git add' before commit?
    ","I mistakenly added files to Git using the command:git add myfile.txtI have not yet run git commit. How do I undo this so that these changes will not be included in the commit?","Undo git add for uncommitted changes with:git reset <file>That will remove the file from the current index (the ""about to be committed"" list) without changing anything else.To unstage all changes for all files:git resetIn old versions of Git, the above commands are equivalent to git reset HEAD <file> and git reset HEAD respectively, and will fail if HEAD is undefined (because you haven't yet made any commits in your repository) or ambiguous (because you created a branch called HEAD, which is a stupid thing that you shouldn't do). This was changed in Git 1.8.2, though, so in modern versions of Git you can use the commands above even prior to making your first commit:""git reset"" (without options or parameters) used to error out whenyou do not have any commits in your history, but it now gives youan empty index (to match non-existent commit you are not even on).Documentation: git reset"
"data_i","edited Jul 16 '22 at 21:18","
        What is the ""-->"" operator in C++?
    ","After reading Hidden Features and Dark Corners of C++/STL on comp.lang.c++.moderated, I was completely surprised that the following snippet compiled and worked in both Visual Studio 2008 and G++ 4.4.Here's the code:#include <stdio.h>int main(){    int x = 10;    while (x --> 0) // x goes to 0    {        printf(""%d "", x);    }}Output:9 8 7 6 5 4 3 2 1 0I'd assume this is C, since it works in GCC as well. Where is this defined in the standard, and where has it come from?","--> is not an operator. It is in fact two separate operators, -- and >.The conditional's code decrements x, while returning x's original (not decremented) value, and then compares the original value with 0 using the > operator.To better understand, the statement could be written as follows:while( (x--) > 0 )"
"data_i","edited Jul 05 '22 at 00:30","
        What and where are the stack and heap?
    ","What are the stack and heap?Where are they located physically in a computer's memory?To what extent are they controlled by the OS or language run-time?What is their scope?What determines their sizes?What makes one faster?","The stack is the memory set aside as scratch space for a thread of execution.  When a function is called, a block is reserved on the top of the stack for local variables and some bookkeeping data.  When that function returns, the block becomes unused and can be used the next time a function is called.  The stack is always reserved in a LIFO (last in first out) order; the most recently reserved block is always the next block to be freed.  This makes it really simple to keep track of the stack; freeing a block from the stack is nothing more than adjusting one pointer.The heap is memory set aside for dynamic allocation.  Unlike the stack, there's no enforced pattern to the allocation and deallocation of blocks from the heap; you can allocate a block at any time and free it at any time.  This makes it much more complex to keep track of which parts of the heap are allocated or free at any given time; there are many custom heap allocators available to tune heap performance for different usage patterns.Each thread gets a stack, while there's typically only one heap for the application (although it isn't uncommon to have multiple heaps for different types of allocation).To answer your questions directly:To what extent are they controlled by the OS or language runtime?The OS allocates the stack for each system-level thread when the thread is created.  Typically the OS is called by the language runtime to allocate the heap for the application.What is their scope?The stack is attached to a thread, so when the thread exits the stack is reclaimed.  The heap is typically allocated at application startup by the runtime, and is reclaimed when the application (technically process) exits.What determines the size of each of them?The size of the stack is set when a thread is created.  The size of the heap is set on application startup, but can grow as space is needed (the allocator requests more memory from the operating system).What makes one faster?The stack is faster because the access pattern makes it trivial to allocate and deallocate memory from it (a pointer/integer is simply incremented or decremented), while the heap has much more complex bookkeeping involved in an allocation or deallocation.  Also, each byte in the stack tends to be reused very frequently which means it tends to be mapped to the processor's cache, making it very fast. Another performance hit for the heap is that the heap, being mostly a global resource, typically has to be multi-threading safe, i.e. each allocation and deallocation needs to be - typically - synchronized with ""all"" other heap accesses in the program.A clear demonstration:Image source: vikashazrati.wordpress.com"
"data_i","edited Jul 05 '22 at 00:35","
        Can comments be used in JSON?
    ","Can I use comments inside a JSON file? If so, how?","No.JSON is data-only. If you include a comment, then it must be data too.You could have a designated data element called ""_comment"" (or something) that should be ignored by apps that use the JSON data.You would probably be better having the comment in the processes that generates/receives the JSON, as they are supposed to know what the JSON data will be in advance, or at least the structure of it.But if you decided to:{   ""_comment"": ""comment text goes here..."",   ""glossary"": {      ""title"": ""example glossary"",      ""GlossDiv"": {         ""title"": ""S"",         ""GlossList"": {            ""GlossEntry"": {               ""ID"": ""SGML"",               ""SortAs"": ""SGML"",               ""GlossTerm"": ""Standard Generalized Markup Language"",               ""Acronym"": ""SGML"",               ""Abbrev"": ""ISO 8879:1986"",               ""GlossDef"": {                  ""para"": ""A meta-markup language, used to create markup languages such as DocBook."",                  ""GlossSeeAlso"": [""GML"", ""XML""]               },               ""GlossSee"": ""markup""            }         }      }   }}"
"data_i","edited Jul 18 '22 at 18:42","
        How do I force ""git pull"" to overwrite local files?
    ","How do I force an overwrite of local files on a git pull? My local repository contains a file of the same filename as on the server.error: Untracked working tree file 'example.txt' would be overwritten by merge","⚠ Warning:Any uncommitted local changes to tracked files will be lost.Any local files that are not tracked by Git will not be affected.First, update all origin/<branch> refs to latest:git fetch --allBackup your current branch (e.g. master):git branch backup-masterJump to the latest commit on origin/master and checkout those files:git reset --hard origin/masterExplanation:git fetch downloads the latest from remote without trying to merge or rebase anything.git reset resets the master branch to what you just fetched. The --hard option changes all the files in your working tree to match the files in origin/master.Maintain current local commits[*]: It's worth noting that it is possible to maintain current local commits by creating a branch from master before resetting:git checkout mastergit branch new-branch-to-save-current-commitsgit fetch --allgit reset --hard origin/masterAfter this, all of the old commits will be kept in new-branch-to-save-current-commits.Uncommitted changesUncommitted changes, however (even staged), will be lost. Make sure to stash and commit anything you need. For that you can run the following:git stashAnd then to reapply these uncommitted changes:git stash pop"
"data_i","edited Jun 06 '22 at 07:37","
        Why does HTML think “chucknorris” is a color?
    ","Why do certain random strings produce colors when entered as background colors in HTML?For example, bgcolor=""chucknorris"" produces a red background:<body bgcolor=""chucknorris""> test </body>Conversely,  bgcolor=""chucknorr"" produces a yellow background:<body bgcolor=""chucknorr""> test </body>This holds true across various browsers and platforms. What’s going on here?","It’s a holdover from the Netscape days:Missing digits are treated as 0[...]. An incorrect digit is simply interpreted as 0. For example the values #F0F0F0, F0F0F0, F0F0F, #FxFxFx and FxFxFx are all the same.It is from the blog post A little rant about Microsoft Internet Explorer's color parsing which covers it in great detail, including varying lengths of color values, etc.If we apply the rules in turn from the blog post, we get the following:Replace all nonvalid hexadecimal characters with 0’s:chucknorris becomes c00c0000000Pad out to the next total number of characters divisible by 3 (11 → 12):c00c 0000 0000Split into three equal groups, with each component representing the corresponding colour component of an RGB colour:RGB (c00c, 0000, 0000)Truncate each of the arguments from the right down to two characters.Which, finally, gives the following result:RGB (c0, 00, 00) = #C00000 or RGB(192, 0, 0)Here’s an example demonstrating the bgcolor attribute in action, to produce this “amazing” colour swatch:<table>  <tr>    <td bgcolor=""chucknorris"" cellpadding=""8"" width=""100"" align=""center"">chuck norris</td>    <td bgcolor=""mrt""         cellpadding=""8"" width=""100"" align=""center"" style=""color:#ffffff"">Mr T</td>    <td bgcolor=""ninjaturtle"" cellpadding=""8"" width=""100"" align=""center"" style=""color:#ffffff"">ninjaturtle</td>  </tr>  <tr>    <td bgcolor=""sick""  cellpadding=""8"" width=""100"" align=""center"">sick</td>    <td bgcolor=""crap""  cellpadding=""8"" width=""100"" align=""center"">crap</td>    <td bgcolor=""grass"" cellpadding=""8"" width=""100"" align=""center"">grass</td>  </tr></table>This also answers the other part of the question: Why does bgcolor=""chucknorr"" produce a yellow colour? Well, if we apply the rules, the string is:c00c00000 => c00 c00 000 => c0 c0 00 [RGB(192, 192, 0)]Which gives a light yellow gold colour. As the string starts off as 9 characters, we keep the second ‘C’ this time around, hence it ends up in the final colour value.I originally encountered this when someone pointed out that you could do color=""crap"" and, well, it comes out brown."
"data_i","edited Jul 05 '22 at 07:29","
        How do I check if an element is hidden in jQuery?
    ","How do I toggle the visibility of an element using  .hide(), .show(), or .toggle()?How do I test if an element is visible or hidden?","Since the question refers to a single element, this code might be more suitable:// Checks CSS content for display:[none|block], ignores visibility:[true|false]$(element).is("":visible"");// The same works with hidden$(element).is("":hidden"");It is the same as twernt's suggestion, but applied to a single element; and it matches the algorithm recommended in the jQuery FAQ.We use jQuery's is() to check the selected element with another element, selector or any jQuery object. This method traverses along the DOM elements to find a match, which satisfies the passed parameter. It will return true if there is a match, otherwise return false."
"data_i","asked Aug 26 '09 at 16:10","
        What does ""use strict"" do in JavaScript, and what is the reasoning behind it?
    ","Recently, I ran some of my JavaScript code through Crockford's JSLint, and it gave the following error:Problem at line 1 character 1: Missing ""use strict"" statement.Doing some searching, I realized that some people add ""use strict""; into their JavaScript code. Once I added the statement, the error stopped appearing. Unfortunately, Google did not reveal much of the history behind this string statement. Certainly it must have something to do with how the JavaScript is interpreted by the browser, but I have no idea what the effect would be.So what is ""use strict""; all about, what does it imply, and is it still relevant?Do any of the current browsers respond to the ""use strict""; string or is it for future use?","Update for ES6 modulesInside native ECMAScript modules (with import and export statements) and ES6 classes, strict mode is always enabled and cannot be disabled.Original answerThis article about Javascript Strict Mode might interest you: John Resig - ECMAScript 5 Strict Mode, JSON, and MoreTo quote some interesting parts:Strict Mode is a new feature in ECMAScript 5 that allows you to place a program, or a function, in a ""strict"" operating context. This strict context prevents certain actions from being taken and throws more exceptions.And:Strict mode helps out in a couple ways:It catches some common coding bloopers, throwing exceptions.It prevents, or throws errors, when relatively ""unsafe"" actions are taken (such as gaining access to the global object).It disables features that are confusing or poorly thought out.Also note you can apply ""strict mode"" to the whole file... Or you can use it only for a specific function (still quoting from John Resig's article):// Non-strict code...(function(){  ""use strict"";  // Define your library strictly...})();// Non-strict code...Which might be helpful if you have to mix old and new code ;-)So, I suppose it's a bit like the ""use strict"" you can use in Perl (hence the name?): it helps you make fewer errors, by detecting more things that could lead to breakages.Strict mode is now supported by all major browsers."
"data_i","edited Jul 18 '22 at 18:45","
        How do I check out a remote Git branch?
    ","Somebody pushed a branch called test with git push origin test to a shared repository. I can see the branch with git branch -r. How do I check out the remote test branch? I've tried:git checkout test, which does nothinggit checkout origin/test gives * (no branch)","The answer has been split depending on whether there is one remote repository configured or multiple. The reason for this is that for the single remote case, some of the commands can be simplified as there is less ambiguity.Updated for Git 2.23: For older versions, see the section at the end.With One RemoteIn both cases, start by fetching from the remote repository to make sure you have all the latest changes downloaded.$ git fetchThis will fetch all of the remote branches for you. You can see the branches available for checkout with:$ git branch -v -a...remotes/origin/testThe branches that start with remotes/* can be thought of as read only copies of the remote branches. To work on a branch you need to create a local branch from it. This is done with the Git command switch (since Git 2.23) by giving it the name of the remote branch (minus the remote name):$ git switch testIn this case Git is guessing (can be disabled with --no-guess) that you are trying to checkout and track the remote branch with the same name.With Multiple RemotesIn the case where multiple remote repositories exist, the remote repository needs to be explicitly named.As before, start by fetching the latest remote changes:$ git fetch originThis will fetch all of the remote branches for you. You can see the branches available for checkout with:$ git branch -v -aWith the remote branches in hand, you now need to check out the branch you are interested in with -c to create a new local branch:$ git switch -c test origin/testFor more information about using git switch:$ man git-switchI also created the image below for you to share the differences, look at how to fetch works, and also how it's different to pull:Prior to Git 2.23git switch was added in Git 2.23, prior to this git checkout was used to switch branches.To checkout out with only a single remote repository:git checkout testif there there are multiple remote repositories configured it becomes a bit longergit checkout -b test <name of remote>/test"
"data_i","edited Aug 03 '22 at 04:58","
        How do I remove local (untracked) files from the current Git working tree?
    ","How do I delete untracked local files from the current working tree?","git-clean - Remove untracked files from the working treeSynopsisgit clean [-d] [-f] [-i] [-n] [-q] [-e <pattern>] [-x | -X] [--] <path>…​DescriptionCleans the working tree by recursively removing files that are not under version control, starting from the current directory.Normally, only files unknown to Git are removed, but if the -x option is specified, ignored files are also removed. This can, for example, be useful to remove all build products.If any optional <path>... arguments are given, only those paths are affected.Step 1 is to show what will be deleted by using the -n option:# Print out the list of files and directories which will be removed (dry run)git clean -n -dClean Step - beware: this will delete files:# Delete the files from the repositorygit clean -fTo remove directories, run git clean -f -d or git clean -fdTo remove ignored files, run git clean -f -X or git clean -fXTo remove ignored and non-ignored files, run git clean -f -x or git clean -fxNote the case difference on the X for the two latter commands.If clean.requireForce is set to ""true"" (the default) in your configuration, one needs to specify -f otherwise nothing will actually happen.Again see the git-clean docs for more information.Options-f, --forceIf the Git configuration variable clean.requireForce is not set tofalse, git clean will refuse to run unless given -f, -n or -i.-xDon’t use the standard ignore rules read from .gitignore (perdirectory) and $GIT_DIR/info/exclude, but do still use the ignorerules given with -e options. This allows removing all untracked files,including build products. This can be used (possibly in conjunctionwith git reset) to create a pristine working directory to test a cleanbuild.-XRemove only files ignored by Git. This may be useful to rebuildeverything from scratch, but keep manually created files.-n, --dry-runDon’t actually remove anything, just show what would be done.-dRemove untracked directories in addition to untracked files. If anuntracked directory is managed by a different Git repository, it isnot removed by default. Use -f option twice if you really want toremove such a directory."
"data_i","edited Aug 29 '22 at 03:57","
        What does if __name__ == ""__main__"": do?
    ","What does this do, and why should one include the if statement?if __name__ == ""__main__"":    print(""Hello, World!"")This question explains what the code does and how it works. If you are trying to close a question where someone should be using this idiom and isn't, consider closing as a duplicate of Why is Python running my module when I import it, and how do I stop it? instead.","Short AnswerIt's boilerplate code that protects users from accidentally invoking the script when they didn't intend to. Here are some common problems when the guard is omitted from a script:If you import the guardless script in another script (e.g. import my_script_without_a_name_eq_main_guard), then the latter script will trigger the former to run at import time and using the second script's command line arguments. This is almost always a mistake.If you have a custom class in the guardless script and save it to a pickle file, then unpickling it in another script will trigger an import of the guardless script, with the same problems outlined in the previous bullet.Long AnswerTo better understand why and how this matters, we need to take a step back to understand how Python initializes scripts and how this interacts with its module import mechanism.Whenever the Python interpreter reads a source file, it does two things:it sets a few special variables like __name__, and thenit executes all of the code found in the file.Let's see how this works and how it relates to your question about the __name__ checks we always see in Python scripts.Code SampleLet's use a slightly different code sample to explore how imports and scripts work.  Suppose the following is in a file called foo.py.# Suppose this is foo.py.print(""before import"")import mathprint(""before function_a"")def function_a():    print(""Function A"")print(""before function_b"")def function_b():    print(""Function B {}"".format(math.sqrt(100)))print(""before __name__ guard"")if __name__ == '__main__':    function_a()    function_b()print(""after __name__ guard"")Special VariablesWhen the Python interpreter reads a source file, it first defines a few special variables. In this case, we care about the __name__ variable.When Your Module Is the Main ProgramIf you are running your module (the source file) as the main program, e.g.python foo.pythe interpreter will assign the hard-coded string ""__main__"" to the __name__ variable, i.e.# It's as if the interpreter inserts this at the top# of your module when run as the main program.__name__ = ""__main__"" When Your Module Is Imported By AnotherOn the other hand, suppose some other module is the main program and it imports your module. This means there's a statement like this in the main program, or in some other module the main program imports:# Suppose this is in some other main program.import fooThe interpreter will search for your foo.py file (along with searching for a few other variants), and prior to executing that module, it will assign the name ""foo"" from the import statement to the __name__ variable, i.e.# It's as if the interpreter inserts this at the top# of your module when it's imported from another module.__name__ = ""foo""Executing the Module's CodeAfter the special variables are set up, the interpreter executes all the code in the module, one statement at a time. You may want to open another window on the side with the code sample so you can follow along with this explanation.AlwaysIt prints the string ""before import"" (without quotes).It loads the math module and assigns it to a variable called math. This is equivalent to replacing import math with the following (note that __import__ is a low-level function in Python that takes a string and triggers the actual import):# Find and load a module given its string name, ""math"",# then assign it to a local variable called math.math = __import__(""math"")It prints the string ""before function_a"".It executes the def block, creating a function object, then assigning that function object to a variable called function_a.It prints the string ""before function_b"".It executes the second def block, creating another function object, then assigning it to a variable called function_b.It prints the string ""before __name__ guard"".Only When Your Module Is the Main ProgramIf your module is the main program, then it will see that __name__ was indeed set to ""__main__"" and it calls the two functions, printing the strings ""Function A"" and ""Function B 10.0"".Only When Your Module Is Imported by Another(instead) If your module is not the main program but was imported by another one, then __name__ will be ""foo"", not ""__main__"", and it'll skip the body of the if statement.AlwaysIt will print the string ""after __name__ guard"" in both situations.SummaryIn summary, here's what'd be printed in the two cases:# What gets printed if foo is the main programbefore importbefore function_abefore function_bbefore __name__ guardFunction AFunction B 10.0after __name__ guard# What gets printed if foo is imported as a regular modulebefore importbefore function_abefore function_bbefore __name__ guardafter __name__ guardWhy Does It Work This Way?You might naturally wonder why anybody would want this.  Well, sometimes you want to write a .py file that can be both used by other programs and/or modules as a module, and can also be run as the main program itself.  Examples:Your module is a library, but you want to have a script mode where it runs some unit tests or a demo.Your module is only used as a main program, but it has some unit tests, and the testing framework works by importing .py files like your script and running special test functions. You don't want it to try running the script just because it's importing the module.Your module is mostly used as a main program, but it also provides a programmer-friendly API for advanced users.Beyond those examples, it's elegant that running a script in Python is just setting up a few magic variables and importing the script. ""Running"" the script is a side effect of importing the script's module.Food for ThoughtQuestion: Can I have multiple __name__ checking blocks?  Answer: it's strange to do so, but the language won't stop you.Suppose the following is in foo2.py.  What happens if you say python foo2.py on the command-line? Why?# Suppose this is foo2.py.import os, sys; sys.path.insert(0, os.path.dirname(__file__)) # needed for some interpretersdef function_a():    print(""a1"")    from foo2 import function_b    print(""a2"")    function_b()    print(""a3"")def function_b():    print(""b"")print(""t1"")if __name__ == ""__main__"":    print(""m1"")    function_a()    print(""m2"")print(""t2"")      Now, figure out what will happen if you remove the __name__ check in foo3.py:# Suppose this is foo3.py.import os, sys; sys.path.insert(0, os.path.dirname(__file__)) # needed for some interpretersdef function_a():    print(""a1"")    from foo3 import function_b    print(""a2"")    function_b()    print(""a3"")def function_b():    print(""b"")print(""t1"")print(""m1"")function_a()print(""m2"")print(""t2"")What will this do when used as a script?  When imported as a module?# Suppose this is in foo4.py__name__ = ""__main__""def bar():    print(""bar"")    print(""before __name__ guard"")if __name__ == ""__main__"":    bar()print(""after __name__ guard"")"
"data_i","edited Feb 06 '18 at 12:40","
        How do I redirect to another webpage?
    ","How can I redirect the user from one page to another using jQuery or pure JavaScript?","One does not simply redirect using jQueryjQuery is not necessary, and window.location.replace(...) will best simulate an HTTP redirect.  window.location.replace(...) is better than using window.location.href, because replace() does not keep the originating page in the session history, meaning the user won't get stuck in a never-ending back-button fiasco.If you want to simulate someone clicking on a link, use location.hrefIf you want to simulate an HTTP redirect, use location.replaceFor example:// similar behavior as an HTTP redirectwindow.location.replace(""http://stackoverflow.com"");// similar behavior as clicking on a linkwindow.location.href = ""http://stackoverflow.com"";"
"data_i","edited May 02 '19 at 10:16","
        How to modify existing, unpushed commit messages?
    ","I wrote the wrong thing in a commit message.How can I change the message? The commit has not been pushed yet.","Amending the most recent commit messagegit commit --amendwill open your editor, allowing you to change the commit message of the most recent commit. Additionally, you can set the commit message directly in the command line with:git commit --amend -m ""New commit message""…however, this can make multi-line commit messages or small corrections more cumbersome to enter.Make sure you don't have any working copy changes staged before doing this or they will get committed too. (Unstaged changes will not get committed.)Changing the message of a commit that you've already pushed to your remote branchIf you've already pushed your commit up to your remote branch, then - after amending your commit locally (as described above) - you'll also need to force push the commit with:git push <remote> <branch> --force# Orgit push <remote> <branch> -fWarning: force-pushing will overwrite the remote branch with the state of your local one. If there are commits on the remote branch that you don't have in your local branch, you will lose those commits.Warning: be cautious about amending commits that you have already shared with other people. Amending commits essentially rewrites them to have different SHA IDs, which poses a problem if other people have copies of the old commit that you've rewritten. Anyone who has a copy of the old commit will need to synchronize their work with your newly re-written commit, which can sometimes be difficult, so make sure you coordinate with others when attempting to rewrite shared commit history, or just avoid rewriting shared commits altogether.Perform an interactive rebaseAnother option is to use interactive rebase.This allows you to edit any message you want to update even if it's not the latest message.In order to do a Git squash, follow these steps:// n is the number of commits up to the last commit you want to be able to editgit rebase -i HEAD~nOnce you squash your commits - choose the e/r for editing the message:Important note about interactive rebaseWhen you use git rebase -i HEAD~n there can be more than n commits. Git will ""collect"" all the commits in the last n commits, and if there was a merge somewhere in between that range you will see all the commits as well, so the outcome will be n + .Good tip:If you have to do it for more than a single branch and you might face conflicts when amending the content, set up git rerere and let Git resolve those conflicts automatically for you.Documentationgit-commit(1) Manual Pagegit-rebase(1) Manual Pagegit-push(1) Manual Page"
"data_i","edited Apr 09 '17 at 13:55","
        How do JavaScript closures work?
    ","How would you explain JavaScript closures to someone with a knowledge of the concepts they consist of (for example functions, variables and the like), but does not understand closures themselves?I have seen the Scheme example given on Wikipedia, but unfortunately it did not help.","A closure is a pairing of:A function andA reference to that function's outer scope (lexical environment)A lexical environment is part of every execution context (stack frame) and is a map between identifiers (i.e. local variable names) and values.Every function in JavaScript maintains a reference to its outer lexical environment. This reference is used to configure the execution context created when a function is invoked. This reference enables code inside the function to ""see"" variables declared outside the function, regardless of when and where the function is called.If a function was called by a function, which in turn was called by another function, then a chain of references to outer lexical environments is created. This chain is called the scope chain.In the following code, inner forms a closure with the lexical environment of the execution context created when foo is invoked, closing over variable secret:function foo() {  const secret = Math.trunc(Math.random() * 100)  return function inner() {    console.log(`The secret number is ${secret}.`)  }}const f = foo() // `secret` is not directly accessible from outside `foo`f() // The only way to retrieve `secret`, is to invoke `f`In other words: in JavaScript, functions carry a reference to a private ""box of state"", to which only they (and any other functions declared within the same lexical environment) have access. This box of the state is invisible to the caller of the function, delivering an excellent mechanism for data-hiding and encapsulation.And remember: functions in JavaScript can be passed around like variables (first-class functions), meaning these pairings of functionality and state can be passed around your program: similar to how you might pass an instance of a class around in C++.If JavaScript did not have closures, then more states would have to be passed between functions explicitly, making parameter lists longer and code noisier.So, if you want a function to always have access to a private piece of state, you can use a closure....and frequently we do want to associate the state with a function. For example, in Java or C++, when you add a private instance variable and a method to a class, you are associating the state with functionality.In C and most other common languages, after a function returns, all the local variables are no longer accessible because the stack-frame is destroyed. In JavaScript, if you declare a function within another function, then the local variables of the outer function can remain accessible after returning from it. In this way, in the code above, secret remains available to the function object inner, after it has been returned from foo.Uses of ClosuresClosures are useful whenever you need a private state associated with a function. This is a very common scenario - and remember: JavaScript did not have a class syntax until 2015, and it still does not have a private field syntax. Closures meet this need.Private Instance VariablesIn the following code, the function toString closes over the details of the car.function Car(manufacturer, model, year, color) {  return {    toString() {      return `${manufacturer} ${model} (${year}, ${color})`    }  }}const car = new Car('Aston Martin', 'V8 Vantage', '2012', 'Quantum Silver')console.log(car.toString())Functional ProgrammingIn the following code, the function inner closes over both fn and args.function curry(fn) {  const args = []  return function inner(arg) {    if(args.length === fn.length) return fn(...args)    args.push(arg)    return inner  }}function add(a, b) {  return a + b}const curriedAdd = curry(add)console.log(curriedAdd(2)(3)()) // 5Event-Oriented ProgrammingIn the following code, function onClick closes over variable BACKGROUND_COLOR.const $ = document.querySelector.bind(document)const BACKGROUND_COLOR = 'rgba(200, 200, 242, 1)'function onClick() {  $('body').style.background = BACKGROUND_COLOR}$('button').addEventListener('click', onClick)<button>Set background color</button>ModularizationIn the following example, all the implementation details are hidden inside an immediately executed function expression. The functions tick and toString close over the private state and functions they need to complete their work. Closures have enabled us to modularize and encapsulate our code.let namespace = {};(function foo(n) {  let numbers = []  function format(n) {    return Math.trunc(n)  }  function tick() {    numbers.push(Math.random() * 100)  }  function toString() {    return numbers.map(format)  }  n.counter = {    tick,    toString  }}(namespace))const counter = namespace.countercounter.tick()counter.tick()console.log(counter.toString())ExamplesExample 1This example shows that the local variables are not copied in the closure: the closure maintains a reference to the original variables themselves. It is as though the stack-frame stays alive in memory even after the outer function exits.function foo() {  let x = 42  let inner = () => console.log(x)  x = x + 1  return inner}foo()() // logs 43Example 2In the following code, three methods log, increment, and update all close over the same lexical environment.And every time createObject is called, a new execution context (stack frame) is created and a completely new variable x, and a new set of functions (log etc.) are created, that close over this new variable.function createObject() {  let x = 42;  return {    log() { console.log(x) },    increment() { x++ },    update(value) { x = value }  }}const o = createObject()o.increment()o.log() // 43o.update(5)o.log() // 5const p = createObject()p.log() // 42Example 3If you are using variables declared using var, be careful you understand which variable you are closing over. Variables declared using var are hoisted. This is much less of a problem in modern JavaScript due to the introduction of let and const.In the following code, each time around the loop, a new function inner is created, which closes over i. But because var i is hoisted outside the loop, all of these inner functions close over the same variable, meaning that the final value of i (3) is printed, three times.function foo() {  var result = []  for (var i = 0; i < 3; i++) {    result.push(function inner() { console.log(i) } )  }  return result}const result = foo()// The following will print `3`, three times...for (var i = 0; i < 3; i++) {  result[i]() }Final points:Whenever a function is declared in JavaScript closure is created.Returning a function from inside another function is the classic example of closure, because the state inside the outer function is implicitly available to the returned inner function, even after the outer function has completed execution.Whenever you use eval() inside a function, a closure is used. The text you eval can reference local variables of the function, and in the non-strict mode, you can even create new local variables by using eval('var foo = …').When you use new Function(…) (the Function constructor) inside a function, it does not close over its lexical environment: it closes over the global context instead. The new function cannot reference the local variables of the outer function.A closure in JavaScript is like keeping a reference (NOT a copy) to the scope at the point of function declaration, which in turn keeps a reference to its outer scope, and so on, all the way to the global object at the top of the scope chain.A closure is created when a function is declared; this closure is used to configure the execution context when the function is invoked.A new set of local variables is created every time a function is called.LinksDouglas Crockford's simulated private attributes and private methods for an object, using closures.A great explanation of how closures can cause memory leaks in IE if you are not careful.MDN documentation on JavaScript Closures."
"data_i","edited Dec 16 '19 at 13:02","
        How do I revert a Git repository to a previous commit?
    ","How do I revert from my current state to a snapshot made on a certain commit?If I do git log, then I get the following output:$ git logcommit a867b4af366350be2e7c21b8de9cc6504678a61b`Author: Me <me@me.com>Date:   Thu Nov 4 18:59:41 2010 -0400blah blah blah...commit 25eee4caef46ae64aa08e8ab3f988bc917ee1ce4Author: Me <me@me.com>Date:   Thu Nov 4 05:13:39 2010 -0400more blah blah blah...commit 0766c053c0ea2035e90f504928f8df3c9363b8bdAuthor: Me <me@me.com>Date:   Thu Nov 4 00:55:06 2010 -0400And yet more blah blah...commit 0d1d7fc32e5a947fbd92ee598033d85bfc445a50Author: Me <me@me.com>Date:   Wed Nov 3 23:56:08 2010 -0400Yep, more blah blah.How do I revert to the commit from November 3, i.e. commit 0d1d7fc?","This depends a lot on what you mean by ""revert"".Temporarily switch to a different commitIf you want to temporarily go back to it, fool around, then come back to where you are, all you have to do is check out the desired commit:# This will detach your HEAD, that is, leave you with no branch checked out:git checkout 0d1d7fc32Or if you want to make commits while you're there, go ahead and make a new branch while you're at it:git checkout -b old-state 0d1d7fc32To go back to where you were, just check out the branch you were on again. (If you've made changes, as always when switching branches, you'll have to deal with them as appropriate. You could reset to throw them away; you could stash, checkout, stash pop to take them with you; you could commit them to a branch there if you want a branch there.)Hard delete unpublished commitsIf, on the other hand, you want to really get rid of everything you've done since then, there are two possibilities. One, if you haven't published any of these commits, simply reset:# This will destroy any local modifications.# Don't do it if you have uncommitted work you want to keep.git reset --hard 0d1d7fc32# Alternatively, if there's work to keep:git stashgit reset --hard 0d1d7fc32git stash pop# This saves the modifications, then reapplies that patch after resetting.# You could get merge conflicts, if you've modified things which were# changed since the commit you reset to.If you mess up, you've already thrown away your local changes, but you can at least get back to where you were before by resetting again.Undo published commits with new commitsOn the other hand, if you've published the work, you probably don't want to reset the branch, since that's effectively rewriting history. In that case, you could indeed revert the commits. With Git, revert has a very specific meaning: create a commit with the reverse patch to cancel it out. This way you don't rewrite any history.# This will create three separate revert commits:git revert a867b4af 25eee4ca 0766c053# It also takes ranges. This will revert the last two commits:git revert HEAD~2..HEAD#Similarly, you can revert a range of commits using commit hashes (non inclusive of first hash):git revert 0d1d7fc..a867b4a# Reverting a merge commitgit revert -m 1 <merge_commit_sha># To get just one, you could use `rebase -i` to squash them afterwards# Or, you could do it manually (be sure to do this at top level of the repo)# get your index and work tree into the desired state, without changing HEAD:git checkout 0d1d7fc32 .# Then commit. Be sure and write a good message describing what you just didgit commitThe git-revert manpage actually covers a lot of this in its description. Another useful link is this git-scm.com section discussing git-revert.If you decide you didn't want to revert after all, you can revert the revert (as described here) or reset back to before the revert (see the previous section).You may also find this answer helpful in this case:How can I move HEAD back to a previous location? (Detached head) & Undo commits"
"data_i","edited Sep 05 '21 at 13:31","
        Is Java ""pass-by-reference"" or ""pass-by-value""?
    ","I always thought Java uses pass-by-reference.However, I've seen a blog post that claims that Java uses pass-by-value.I don't think I understand the distinction they're making.What is the explanation?","The terms ""pass-by-value"" and ""pass-by-reference"" have special, precisely defined meanings in computer science. These meanings differ from the intuition many people have when first hearing the terms. Much of the confusion in this discussion seems to come from this fact.The terms ""pass-by-value"" and ""pass-by-reference"" are talking about variables. Pass-by-value means that the value of a variable is passed to a function/method. Pass-by-reference means that a reference to that variable is passed to the function. The latter gives the function a way to change the contents of the variable.By those definitions, Java is always pass-by-value.  Unfortunately, when we deal with variables holding objects we are really dealing with object-handles called references which are passed-by-value as well.  This terminology and semantics easily confuse many beginners.It goes like this:public static void main(String[] args) {    Dog aDog = new Dog(""Max"");    Dog oldDog = aDog;    // we pass the object to foo    foo(aDog);    // aDog variable is still pointing to the ""Max"" dog when foo(...) returns    aDog.getName().equals(""Max""); // true    aDog.getName().equals(""Fifi""); // false    aDog == oldDog; // true}public static void foo(Dog d) {    d.getName().equals(""Max""); // true    // change d inside of foo() to point to a new Dog instance ""Fifi""    d = new Dog(""Fifi"");    d.getName().equals(""Fifi""); // true}In the example above aDog.getName() will still return ""Max"". The value aDog within main is not changed in the function foo with the Dog ""Fifi"" as the object reference is passed by value. If it were passed by reference, then the aDog.getName() in main would return ""Fifi"" after the call to foo.Likewise:public static void main(String[] args) {    Dog aDog = new Dog(""Max"");    Dog oldDog = aDog;    foo(aDog);    // when foo(...) returns, the name of the dog has been changed to ""Fifi""    aDog.getName().equals(""Fifi""); // true    // but it is still the same dog:    aDog == oldDog; // true}public static void foo(Dog d) {    d.getName().equals(""Max""); // true    // this changes the name of d to be ""Fifi""    d.setName(""Fifi"");}In the above example, Fifi is the dog's name after call to foo(aDog) because the object's name was set inside of foo(...). Any operations that foo performs on d are such that, for all practical purposes, they are performed on aDog, but it is not possible to change the value of the variable aDog itself.For more information on pass by reference and pass by value, consult the following answer: https://stackoverflow.com/a/430958/6005228. This explains more thoroughly the semantics and history behind the two and also explains why Java and many other modern languages appear to do both in certain cases."
"data_i","edited Jun 06 '22 at 02:52","
        Does Python have a ternary conditional operator?
    ","Is there a ternary conditional operator in Python?","Yes, it was added in version 2.5. The expression syntax is:a if condition else bFirst condition is evaluated, then exactly one of either a or b is evaluated and returned based on the Boolean value of condition. If condition evaluates to True, then a is evaluated and returned but b is ignored, or else when b is evaluated and returned but a is ignored.This allows short-circuiting because when condition is true only a is evaluated and b is not evaluated at all, but when condition is false only b is evaluated and a is not evaluated at all.For example:>>> 'true' if True else 'false''true'>>> 'true' if False else 'false''false'Note that conditionals are an expression, not a statement. This means you can't use statements such as pass, or assignments with = (or ""augmented"" assignments like +=), within a conditional expression:>>> pass if False else pass  File ""<stdin>"", line 1    pass if False else pass         ^SyntaxError: invalid syntax>>> # Python parses this as `x = (1 if False else y) = 2`>>> # The `(1 if False else x)` part is actually valid, but>>> # it can't be on the left-hand side of `=`.>>> x = 1 if False else y = 2  File ""<stdin>"", line 1SyntaxError: cannot assign to conditional expression>>> # If we parenthesize it instead...>>> (x = 1) if False else (y = 2)  File ""<stdin>"", line 1    (x = 1) if False else (y = 2)       ^SyntaxError: invalid syntax(In 3.8 and above, the := ""walrus"" operator allows simple assignment of values as an expression, which is then compatible with this syntax. But please don't write code like that; it will quickly become very difficult to understand.)Similarly, because it is an expression, the else part is mandatory:# Invalid syntax: we didn't specify what the value should be if the # condition isn't met. It doesn't matter if we can verify that# ahead of time.a if TrueYou can, however, use conditional expressions to assign a variable like so:x = a if True else bOr for example to return a value:# Of course we should just use the standard library `max`;# this is just for demonstration purposes.def my_max(a, b):    return a if a > b else bThink of the conditional expression as switching between two values. We can use it when we are in a 'one value or another' situation, where we will do the same thing with the result, regardless of whether the condition is met. We use the expression to compute the value, and then do something with it. If you need to do something different depending on the condition, then use a normal if statement instead.Keep in mind that it's frowned upon by some Pythonistas for several reasons:The order of the arguments is different from those of the classic condition ? a : b ternary operator from many other languages (such as C, C++, Go, Perl, Ruby, Java, JavaScript, etc.), which may lead to bugs when people unfamiliar with Python's ""surprising"" behaviour use it (they may reverse the argument order).Some find it ""unwieldy"", since it goes contrary to the normal flow of thought (thinking of the condition first and then the effects).Stylistic reasons. (Although the 'inline if' can be really useful, and make your script more concise, it really does complicate your code)If you're having trouble remembering the order, then remember that when read aloud, you (almost) say what you mean. For example, x = 4 if b > 8 else 9 is read aloud as x will be 4 if b is greater than 8 otherwise 9.Official documentation:Conditional expressionsIs there an equivalent of C’s ”?:” ternary operator?"
"data_i","asked Dec 03 '08 at 11:31","
        var functionName = function() {} vs function functionName() {}
    ","I've recently started maintaining someone else's JavaScript code. I'm fixing bugs, adding features and also trying to tidy up the code and make it more consistent.The previous developer used two ways of declaring functions and I can't work out if there is a reason behind it or not.The two ways are:var functionOne = function() {    // Some code};function functionTwo() {    // Some code}What are the reasons for using these two different methods and what are the pros and cons of each? Is there anything that can be done with one method that can't be done with the other?","The difference is that functionOne is a function expression and so only defined when that line is reached, whereas functionTwo is a function declaration and is defined as soon as its surrounding function or script is executed (due to hoisting).  For example, a function expression:// TypeError: functionOne is not a functionfunctionOne();var functionOne = function() {  console.log(""Hello!"");};And, a function declaration:   // Outputs: ""Hello!""functionTwo();function functionTwo() {  console.log(""Hello!"");}Historically, function declarations defined within blocks were handled inconsistently between browsers. Strict mode (introduced in ES5) resolved this by scoping function declarations to their enclosing block.'use strict';    { // note this block!  function functionThree() {    console.log(""Hello!"");  }}functionThree(); // ReferenceError"
"data_i","edited Apr 03 '19 at 13:17","
        How to check whether a string contains a substring in JavaScript?
    ","Usually I would expect a String.contains() method, but there doesn't seem to be one. What is a reasonable way to check for this?","ECMAScript 6  introduced String.prototype.includes:const string = ""foo"";const substring = ""oo"";console.log(string.includes(substring)); // trueString.prototype.includes is case-sensitive and is not supported by Internet Explorer without a polyfill.In ECMAScript 5 or older environments, use String.prototype.indexOf, which returns -1 when a substring cannot be found:var string = ""foo"";var substring = ""oo"";console.log(string.indexOf(substring) !== -1); // true"
"data_i","edited Jul 25 '22 at 03:31","
        How do I make Git forget about a file that was tracked, but is now in .gitignore?
    ","I put a file that was previously being tracked by Git onto the .gitignore list. However, the file still shows up in git status after it is edited. How do I force Git to completely forget the file?",".gitignore will prevent untracked files from being added (without an add -f) to the set of files tracked by Git. However, Git will continue to track any files that are already being tracked.To stop tracking a file, we must remove it from the index:git rm --cached <file>To remove a folder and all files in the folder recursively:git rm -r --cached <folder>The removal of the file from the head revision will happen on the next commit.WARNING: While this will not remove the physical file from your local machine, it will remove the files from other developers' machines on their next git pull."
"data_i","edited May 22 '21 at 07:55","
        Why is subtracting these two times (in 1927) giving a strange result?
    ","If I run the following program, which parses two date strings referencing times 1 second apart and compares them:public static void main(String[] args) throws ParseException {    SimpleDateFormat sf = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss"");      String str3 = ""1927-12-31 23:54:07"";      String str4 = ""1927-12-31 23:54:08"";      Date sDt3 = sf.parse(str3);      Date sDt4 = sf.parse(str4);      long ld3 = sDt3.getTime() /1000;      long ld4 = sDt4.getTime() /1000;    System.out.println(ld4-ld3);}The output is:353Why is ld4-ld3, not 1 (as I would expect from the one-second difference in the times), but 353?If I change the dates to times 1 second later:String str3 = ""1927-12-31 23:54:08"";  String str4 = ""1927-12-31 23:54:09"";  Then ld4-ld3 will be 1.Java version:java version ""1.6.0_22""Java(TM) SE Runtime Environment (build 1.6.0_22-b04)Dynamic Code Evolution Client VM (build 0.2-b02-internal, 19.0-b04-internal, mixed mode)Timezone(`TimeZone.getDefault()`):sun.util.calendar.ZoneInfo[id=""Asia/Shanghai"",offset=28800000,dstSavings=0,useDaylight=false,transitions=19,lastRule=null]Locale(Locale.getDefault()): zh_CN","It's a time zone change on December 31st in Shanghai.See this page for details of 1927 in Shanghai. Basically at midnight at the end of 1927, the clocks went back 5 minutes and 52 seconds. So ""1927-12-31 23:54:08"" actually happened twice, and it looks like Java is parsing it as the later possible instant for that local date/time - hence the difference.Just another episode in the often weird and wonderful world of time zones.EDIT: Stop press! History changes...The original question would no longer demonstrate quite the same behaviour, if rebuilt with version 2013a of TZDB. In 2013a, the result would be 358 seconds, with a transition time of 23:54:03 instead of 23:54:08.I only noticed this because I'm collecting questions like this in Noda Time, in the form of unit tests... The test has now been changed, but it just goes to show - not even historical data is safe.EDIT: History has changed again...In TZDB 2014f, the time of the change has moved to 1900-12-31, and it's now a mere 343 second change (so the time between t and t+1 is 344 seconds, if you see what I mean).EDIT: To answer a question around a transition at 1900... it looks like the Java timezone implementation treats all time zones as simply being in their standard time for any instant before the start of 1900 UTC:import java.util.TimeZone;public class Test {    public static void main(String[] args) throws Exception {        long startOf1900Utc = -2208988800000L;        for (String id : TimeZone.getAvailableIDs()) {            TimeZone zone = TimeZone.getTimeZone(id);            if (zone.getRawOffset() != zone.getOffset(startOf1900Utc - 1)) {                System.out.println(id);            }        }    }}The code above produces no output on my Windows machine. So any time zone which has any offset other than its standard one at the start of 1900 will count that as a transition. TZDB itself has some data going back earlier than that, and doesn't rely on any idea of a ""fixed"" standard time (which is what getRawOffset assumes to be a valid concept) so other libraries needn't introduce this artificial transition."
"data_i","edited Sep 12 '22 at 10:35","
        What is the difference between String and string in C#?
    ","What are the differences between these two and which one should I use?string s = ""Hello world!"";String s = ""Hello world!"";","string is an alias in C# for System.String.So technically, there is no difference.  It's like int vs. System.Int32.As far as guidelines, it's generally recommended to use string any time you're referring to an object.e.g.string place = ""world"";Likewise, I think it's generally recommended to use String if you need to refer specifically to the class.e.g.string greet = String.Format(""Hello {0}!"", place);This is the style that Microsoft tends to use in their examples.It appears that the guidance in this area may have changed, as StyleCop now enforces the use of the C# specific aliases."
"data_i","edited Aug 29 '22 at 10:25","
        How do I remove a property from a JavaScript object?
    ","Given an object:let myObject = {  ""ircEvent"": ""PRIVMSG"",  ""method"": ""newURI"",  ""regex"": ""^http://.*""};How do I remove the property regex to end up with the following myObject?let myObject = {  ""ircEvent"": ""PRIVMSG"",  ""method"": ""newURI""};","To remove a property from an object (mutating the object), you can do it like this:delete myObject.regex;// or,delete myObject['regex'];// or,var prop = ""regex"";delete myObject[prop];Demovar myObject = {    ""ircEvent"": ""PRIVMSG"",    ""method"": ""newURI"",    ""regex"": ""^http://.*""};delete myObject.regex;console.log(myObject);For anyone interested in reading more about it, Stack Overflow user kangax has written an incredibly in-depth blog post about the delete statement on their blog, Understanding delete. It is highly recommended.If you'd like a new object with all the keys of the original except some, you could use destructuring.Demolet myObject = {  ""ircEvent"": ""PRIVMSG"",  ""method"": ""newURI"",  ""regex"": ""^http://.*""};// assign the key regex to the variable _ indicating it will be unusedconst {regex: _, ...newObj} = myObject;console.log(newObj);   // has no 'regex' keyconsole.log(myObject); // remains unchanged"
"data_i","edited Apr 19 '22 at 02:11","
        What are metaclasses in Python?
    ","What are metaclasses? What are they used for?","Classes as objectsBefore understanding metaclasses, you need to master classes in Python. And Python has a very peculiar idea of what classes are, borrowed from the Smalltalk language.In most languages, classes are just pieces of code that describe how to produce an object. That's kinda true in Python too:>>> class ObjectCreator(object):...       pass...>>> my_object = ObjectCreator()>>> print(my_object)<__main__.ObjectCreator object at 0x8974f2c>But classes are more than that in Python. Classes are objects too.Yes, objects.As soon as you use the keyword class, Python executes it and createsan object. The instruction>>> class ObjectCreator(object):...       pass...creates in memory an object with the name ObjectCreator.This object (the class) is itself capable of creating objects (the instances),and this is why it's a class.But still, it's an object, and therefore:you can assign it to a variableyou can copy ityou can add attributes to ityou can pass it as a function parametere.g.:>>> print(ObjectCreator) # you can print a class because it's an object<class '__main__.ObjectCreator'>>>> def echo(o):...       print(o)...>>> echo(ObjectCreator) # you can pass a class as a parameter<class '__main__.ObjectCreator'>>>> print(hasattr(ObjectCreator, 'new_attribute'))False>>> ObjectCreator.new_attribute = 'foo' # you can add attributes to a class>>> print(hasattr(ObjectCreator, 'new_attribute'))True>>> print(ObjectCreator.new_attribute)foo>>> ObjectCreatorMirror = ObjectCreator # you can assign a class to a variable>>> print(ObjectCreatorMirror.new_attribute)foo>>> print(ObjectCreatorMirror())<__main__.ObjectCreator object at 0x8997b4c>Creating classes dynamicallySince classes are objects, you can create them on the fly, like any object.First, you can create a class in a function using class:>>> def choose_class(name):...     if name == 'foo':...         class Foo(object):...             pass...         return Foo # return the class, not an instance...     else:...         class Bar(object):...             pass...         return Bar...>>> MyClass = choose_class('foo')>>> print(MyClass) # the function returns a class, not an instance<class '__main__.Foo'>>>> print(MyClass()) # you can create an object from this class<__main__.Foo object at 0x89c6d4c>But it's not so dynamic, since you still have to write the whole class yourself.Since classes are objects, they must be generated by something.When you use the class keyword, Python creates this object automatically. But aswith most things in Python, it gives you a way to do it manually.Remember the function type? The good old function that lets you know whattype an object is:>>> print(type(1))<type 'int'>>>> print(type(""1""))<type 'str'>>>> print(type(ObjectCreator))<type 'type'>>>> print(type(ObjectCreator()))<class '__main__.ObjectCreator'>Well, type has a completely different ability, it can also create classes on the fly. type can take the description of a class as parameters,and return a class.(I  know, it's silly that the same function can have two completely different uses according to the parameters you pass to it. It's an issue due to backwardcompatibility in Python)type works this way:type(name, bases, attrs)Where:name: name of the classbases: tuple of the parent class (for inheritance, can be empty)attrs: dictionary containing attributes names and valuese.g.:>>> class MyShinyClass(object):...       passcan be created manually this way:>>> MyShinyClass = type('MyShinyClass', (), {}) # returns a class object>>> print(MyShinyClass)<class '__main__.MyShinyClass'>>>> print(MyShinyClass()) # create an instance with the class<__main__.MyShinyClass object at 0x8997cec>You'll notice that we use MyShinyClass as the name of the classand as the variable to hold the class reference. They can be different,but there is no reason to complicate things.type accepts a dictionary to define the attributes of the class. So:>>> class Foo(object):...       bar = TrueCan be translated to:>>> Foo = type('Foo', (), {'bar':True})And used as a normal class:>>> print(Foo)<class '__main__.Foo'>>>> print(Foo.bar)True>>> f = Foo()>>> print(f)<__main__.Foo object at 0x8a9b84c>>>> print(f.bar)TrueAnd of course, you can inherit from it, so:>>>   class FooChild(Foo):...         passwould be:>>> FooChild = type('FooChild', (Foo,), {})>>> print(FooChild)<class '__main__.FooChild'>>>> print(FooChild.bar) # bar is inherited from FooTrueEventually, you'll want to add methods to your class. Just define a functionwith the proper signature and assign it as an attribute.>>> def echo_bar(self):...       print(self.bar)...>>> FooChild = type('FooChild', (Foo,), {'echo_bar': echo_bar})>>> hasattr(Foo, 'echo_bar')False>>> hasattr(FooChild, 'echo_bar')True>>> my_foo = FooChild()>>> my_foo.echo_bar()TrueAnd you can add even more methods after you dynamically create the class, just like adding methods to a normally created class object.>>> def echo_bar_more(self):...       print('yet another method')...>>> FooChild.echo_bar_more = echo_bar_more>>> hasattr(FooChild, 'echo_bar_more')TrueYou see where we are going: in Python, classes are objects, and you can create a class on the fly, dynamically.This is what Python does when you use the keyword class, and it does so by using a metaclass.What are metaclasses (finally)Metaclasses are the 'stuff' that creates classes.You define classes in order to create objects, right?But we learned that Python classes are objects.Well, metaclasses are what create these objects. They are the classes' classes,you can picture them this way:MyClass = MetaClass()my_object = MyClass()You've seen that type lets you do something like this:MyClass = type('MyClass', (), {})It's because the function type is in fact a metaclass. type is themetaclass Python uses to create all classes behind the scenes.Now you wonder ""why the heck is it written in lowercase, and not Type?""Well, I guess it's a matter of consistency with str, the class that createsstrings objects, and int the class that creates integer objects. type isjust the class that creates class objects.You see that by checking the __class__ attribute.Everything, and I mean everything, is an object in Python. That includes integers,strings, functions and classes. All of them are objects. And all of them havebeen created from a class:>>> age = 35>>> age.__class__<type 'int'>>>> name = 'bob'>>> name.__class__<type 'str'>>>> def foo(): pass>>> foo.__class__<type 'function'>>>> class Bar(object): pass>>> b = Bar()>>> b.__class__<class '__main__.Bar'>Now, what is the __class__ of any __class__ ?>>> age.__class__.__class__<type 'type'>>>> name.__class__.__class__<type 'type'>>>> foo.__class__.__class__<type 'type'>>>> b.__class__.__class__<type 'type'>So, a metaclass is just the stuff that creates class objects.You can call it a 'class factory' if you wish.type is the built-in metaclass Python uses, but of course, you can create yourown metaclass.The __metaclass__ attributeIn Python 2, you can add a __metaclass__ attribute when you write a class (see next section for the Python 3 syntax):class Foo(object):    __metaclass__ = something...    [...]If you do so, Python will use the metaclass to create the class Foo.Careful, it's tricky.You write class Foo(object) first, but the class object Foo is not createdin memory yet.Python will look for __metaclass__ in the class definition. If it finds it,it will use it to create the object class Foo. If it doesn't, it will usetype to create the class.Read that several times.When you do:class Foo(Bar):    passPython does the following:Is there a __metaclass__ attribute in Foo?If yes, create in-memory a class object (I said a class object, stay with me here), with the name Foo by using what is in __metaclass__.If Python can't find __metaclass__, it will look for a __metaclass__ at the MODULE level, and try to do the same (but only for classes that don't inherit anything, basically old-style classes).Then if it can't find any __metaclass__ at all, it will use the Bar's (the first parent) own metaclass (which might be the default type) to create the class object.Be careful here that the __metaclass__ attribute will not be inherited, the metaclass of the parent (Bar.__class__) will be. If Bar used a __metaclass__ attribute that created Bar with type() (and not type.__new__()), the subclasses will not inherit that behavior.Now the big question is, what can you put in __metaclass__?The answer is something that can create a class.And what can create a class? type, or anything that subclasses or uses it.Metaclasses in Python 3The syntax to set the metaclass has been changed in Python 3:class Foo(object, metaclass=something):    ...i.e. the __metaclass__ attribute is no longer used, in favor of a keyword argument in the list of base classes.The behavior of metaclasses however stays largely the same.One thing added to metaclasses in Python 3 is that you can also pass attributes as keyword-arguments into a metaclass, like so:class Foo(object, metaclass=something, kwarg1=value1, kwarg2=value2):    ...Read the section below for how Python handles this.Custom metaclassesThe main purpose of a metaclass is to change the class automatically,when it's created.You usually do this for APIs, where you want to create classes matching thecurrent context.Imagine a stupid example, where you decide that all classes in your moduleshould have their attributes written in uppercase. There are several ways todo this, but one way is to set __metaclass__ at the module level.This way, all classes of this module will be created using this metaclass,and we just have to tell the metaclass to turn all attributes to uppercase.Luckily, __metaclass__ can actually be any callable, it doesn't need to be aformal class (I know, something with 'class' in its name doesn't need to bea class, go figure... but it's helpful).So we will start with a simple example, by using a function.# the metaclass will automatically get passed the same argument# that you usually pass to `type`def upper_attr(future_class_name, future_class_parents, future_class_attrs):    """"""      Return a class object, with the list of its attribute turned      into uppercase.    """"""    # pick up any attribute that doesn't start with '__' and uppercase it    uppercase_attrs = {        attr if attr.startswith(""__"") else attr.upper(): v        for attr, v in future_class_attrs.items()    }    # let `type` do the class creation    return type(future_class_name, future_class_parents, uppercase_attrs)__metaclass__ = upper_attr # this will affect all classes in the moduleclass Foo(): # global __metaclass__ won't work with ""object"" though    # but we can define __metaclass__ here instead to affect only this class    # and this will work with ""object"" children    bar = 'bip'Let's check:>>> hasattr(Foo, 'bar')False>>> hasattr(Foo, 'BAR')True>>> Foo.BAR'bip'Now, let's do exactly the same, but using a real class for a metaclass:# remember that `type` is actually a class like `str` and `int`# so you can inherit from itclass UpperAttrMetaclass(type):    # __new__ is the method called before __init__    # it's the method that creates the object and returns it    # while __init__ just initializes the object passed as parameter    # you rarely use __new__, except when you want to control how the object    # is created.    # here the created object is the class, and we want to customize it    # so we override __new__    # you can do some stuff in __init__ too if you wish    # some advanced use involves overriding __call__ as well, but we won't    # see this    def __new__(upperattr_metaclass, future_class_name,                future_class_parents, future_class_attrs):        uppercase_attrs = {            attr if attr.startswith(""__"") else attr.upper(): v            for attr, v in future_class_attrs.items()        }        return type(future_class_name, future_class_parents, uppercase_attrs)Let's rewrite the above, but with shorter and more realistic variable names now that we know what they mean:class UpperAttrMetaclass(type):    def __new__(cls, clsname, bases, attrs):        uppercase_attrs = {            attr if attr.startswith(""__"") else attr.upper(): v            for attr, v in attrs.items()        }        return type(clsname, bases, uppercase_attrs)You may have noticed the extra argument cls. There isnothing special about it: __new__ always receives the class it's defined in, as the first parameter. Just like you have self for ordinary methods which receive the instance as the first parameter, or the defining class for class methods.But this is not proper OOP. We are calling type directly and we aren't overriding or calling the parent's __new__. Let's do that instead:class UpperAttrMetaclass(type):    def __new__(cls, clsname, bases, attrs):        uppercase_attrs = {            attr if attr.startswith(""__"") else attr.upper(): v            for attr, v in attrs.items()        }        return type.__new__(cls, clsname, bases, uppercase_attrs)We can make it even cleaner by using super, which will ease inheritance (because yes, you can have metaclasses, inheriting from metaclasses, inheriting from type):class UpperAttrMetaclass(type):    def __new__(cls, clsname, bases, attrs):        uppercase_attrs = {            attr if attr.startswith(""__"") else attr.upper(): v            for attr, v in attrs.items()        }        # Python 2 requires passing arguments to super:        return super(UpperAttrMetaclass, cls).__new__(            cls, clsname, bases, uppercase_attrs)        # Python 3 can use no-arg super() which infers them:        return super().__new__(cls, clsname, bases, uppercase_attrs)Oh, and in Python 3 if you do this call with keyword arguments, like this:class Foo(object, metaclass=MyMetaclass, kwarg1=value1):    ...It translates to this in the metaclass to use it:class MyMetaclass(type):    def __new__(cls, clsname, bases, dct, kwargs1=default):        ...That's it. There is really nothing more about metaclasses.The reason behind the complexity of the code using metaclasses is not becauseof metaclasses, it's because you usually use metaclasses to do twisted stuffrelying on introspection, manipulating inheritance, vars such as __dict__, etc.Indeed, metaclasses are especially useful to do black magic, and thereforecomplicated stuff. But by themselves, they are simple:intercept a class creationmodify the classreturn the modified classWhy would you use metaclasses classes instead of functions?Since __metaclass__ can accept any callable, why would you use a classsince it's obviously more complicated?There are several reasons to do so:The intention is clear. When you read UpperAttrMetaclass(type), you knowwhat's going to followYou can use OOP. Metaclass can inherit from metaclass, override parent methods. Metaclasses can even use metaclasses.Subclasses of a class will be instances of its metaclass if you specified a metaclass-class, but not with a metaclass-function.You can structure your code better. You never use metaclasses for something as trivial as the above example. It's usually for something complicated. Having the ability to make several methods and group them in one class is very useful to make the code easier to read.You can hook on __new__, __init__ and __call__. Which will allow you to do different stuff, Even if usually you can do it all in __new__,some people are just more comfortable using __init__.These are called metaclasses, damn it! It must mean something!Why would you use metaclasses?Now the big question. Why would you use some obscure error-prone feature?Well, usually you don't:Metaclasses are deeper magic that99% of users should never worry about it.If you wonder whether you need them,you don't (the people who actuallyneed them know with certainty thatthey need them, and don't need anexplanation about why).Python Guru Tim PetersThe main use case for a metaclass is creating an API. A typical example of this is the Django ORM. It allows you to define something like this:class Person(models.Model):    name = models.CharField(max_length=30)    age = models.IntegerField()But if you do this:person = Person(name='bob', age='35')print(person.age)It won't return an IntegerField object. It will return an int, and can even take it directly from the database.This is possible because models.Model defines __metaclass__ andit uses some magic that will turn the Person you just defined with simple statementsinto a complex hook to a database field.Django makes something complex look simple by exposing a simple APIand using metaclasses, recreating code from this API to do the real jobbehind the scenes.The last wordFirst, you know that classes are objects that can create instances.Well, in fact, classes are themselves instances. Of metaclasses.>>> class Foo(object): pass>>> id(Foo)142630324Everything is an object in Python, and they are all either instance of classesor instances of metaclasses.Except for type.type is actually its own metaclass. This is not something you couldreproduce in pure Python, and is done by cheating a little bit at the implementationlevel.Secondly, metaclasses are complicated. You may not want to use them forvery simple class alterations. You can change classes by using two different techniques:monkey patchingclass decorators99% of the time you need class alteration, you are better off using these.But 98% of the time, you don't need class alteration at all."
"data_i","edited Sep 03 '22 at 23:20","
        How to find all files containing specific text (string) on Linux
    ","How do I find all files containing a specific string of text within their file contents?The following doesn't work. It seems to display every single file in the system.find / -type f -exec grep -H 'text-to-find-here' {} \;","Do the following:grep -rnw '/path/to/somewhere/' -e 'pattern'-r or -R is recursive,-n is line number, and-w stands for match the whole word.-l (lower-case L) can be added to just give the file name of matching files.-e is the pattern used during the searchAlong with these, --exclude, --include, --exclude-dir flags could be used for efficient searching:This will only search through those files which have .c or .h extensions:grep --include=\*.{c,h} -rnw '/path/to/somewhere/' -e ""pattern""This will exclude searching all the files ending with .o extension:grep --exclude=\*.o -rnw '/path/to/somewhere/' -e ""pattern""For directories it's possible to exclude one or more directories using the --exclude-dir parameter. For example, this will exclude the dirs dir1/, dir2/ and all of them matching *.dst/:grep --exclude-dir={dir1,dir2,*.dst} -rnw '/path/to/somewhere/' -e ""pattern""This works very well for me, to achieve almost the same purpose like yours.For more options, see man grep."
"data_i","edited Mar 27 '21 at 19:42","
        How do I check whether a file exists without exceptions?
    ","How do I check whether a file exists or not, without using the try statement?","If the reason you're checking is so you can do something like if file_exists: open_it(), it's safer to use a try around the attempt to open it. Checking and then opening risks the file being deleted or moved or something between when you check and when you try to open it.If you're not planning to open the file immediately, you can use os.path.isfileReturn True if path is an existing regular file. This follows symbolic links, so both islink() and isfile() can be true for the same path.import os.pathos.path.isfile(fname) if you need to be sure it's a file.Starting with Python 3.4, the pathlib module offers an object-oriented approach (backported to pathlib2 in Python 2.7):from pathlib import Pathmy_file = Path(""/path/to/file"")if my_file.is_file():    # file existsTo check a directory, do:if my_file.is_dir():    # directory existsTo check whether a Path object exists independently of whether is it a file or directory, use exists():if my_file.exists():    # path existsYou can also use resolve(strict=True) in a try block:try:    my_abs_path = my_file.resolve(strict=True)except FileNotFoundError:    # doesn't existelse:    # exists"
"data_i","edited Jun 22 '22 at 18:01","
        How do I merge two dictionaries in a single expression?
    ","I want to merge two dictionaries into a new dictionary.x = {'a': 1, 'b': 2}y = {'b': 3, 'c': 4}z = merge(x, y)>>> z{'a': 1, 'b': 3, 'c': 4}Whenever a key k is present in both dictionaries, only the value y[k] should be kept.","How can I merge two Python dictionaries in a single expression?For dictionaries x and y, their shallowly-merged dictionary z takes values from y, replacing those from x.In Python 3.9.0 or greater (released 17 October 2020, PEP-584, discussed here):z = x | yIn Python 3.5 or greater:z = {**x, **y}In Python 2, (or 3.4 or lower) write a function:def merge_two_dicts(x, y):    z = x.copy()   # start with keys and values of x    z.update(y)    # modifies z with keys and values of y    return zand now:z = merge_two_dicts(x, y)ExplanationSay you have two dictionaries and you want to merge them into a new dictionary without altering the original dictionaries:x = {'a': 1, 'b': 2}y = {'b': 3, 'c': 4}The desired result is to get a new dictionary (z) with the values merged, and the second dictionary's values overwriting those from the first.>>> z{'a': 1, 'b': 3, 'c': 4}A new syntax for this, proposed in PEP 448 and available as of Python 3.5, isz = {**x, **y}And it is indeed a single expression.Note that we can merge in with literal notation as well:z = {**x, 'foo': 1, 'bar': 2, **y}and now:>>> z{'a': 1, 'b': 3, 'foo': 1, 'bar': 2, 'c': 4}It is now showing as implemented in the release schedule for 3.5, PEP 478, and it has now made its way into the What's New in Python 3.5 document.However, since many organizations are still on Python 2, you may wish to do this in a backward-compatible way. The classically Pythonic way, available in Python 2 and Python 3.0-3.4, is to do this as a two-step process:z = x.copy()z.update(y) # which returns None since it mutates zIn both approaches, y will come second and its values will replace x's values, thus b will point to 3 in our final result.Not yet on Python 3.5, but want a single expressionIf you are not yet on Python 3.5 or need to write backward-compatible code, and you want this in a single expression, the most performant while the correct approach is to put it in a function:def merge_two_dicts(x, y):    """"""Given two dictionaries, merge them into a new dict as a shallow copy.""""""    z = x.copy()    z.update(y)    return zand then you have a single expression:z = merge_two_dicts(x, y)You can also make a function to merge an arbitrary number of dictionaries, from zero to a very large number:def merge_dicts(*dict_args):    """"""    Given any number of dictionaries, shallow copy and merge into a new dict,    precedence goes to key-value pairs in latter dictionaries.    """"""    result = {}    for dictionary in dict_args:        result.update(dictionary)    return resultThis function will work in Python 2 and 3 for all dictionaries. e.g. given dictionaries a to g:z = merge_dicts(a, b, c, d, e, f, g) and key-value pairs in g will take precedence over dictionaries a to f, and so on.Critiques of Other AnswersDon't use what you see in the formerly accepted answer:z = dict(x.items() + y.items())In Python 2, you create two lists in memory for each dict, create a third list in memory with length equal to the length of the first two put together, and then discard all three lists to create the dict. In Python 3, this will fail because you're adding two dict_items objects together, not two lists ->>> c = dict(a.items() + b.items())Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>TypeError: unsupported operand type(s) for +: 'dict_items' and 'dict_items'and you would have to explicitly create them as lists, e.g. z = dict(list(x.items()) + list(y.items())). This is a waste of resources and computation power.Similarly, taking the union of items() in Python 3 (viewitems() in Python 2.7) will also fail when values are unhashable objects (like lists, for example). Even if your values are hashable, since sets are semantically unordered, the behavior is undefined in regards to precedence. So don't do this:>>> c = dict(a.items() | b.items())This example demonstrates what happens when values are unhashable:>>> x = {'a': []}>>> y = {'b': []}>>> dict(x.items() | y.items())Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>TypeError: unhashable type: 'list'Here's an example where y should have precedence, but instead the value from x is retained due to the arbitrary order of sets:>>> x = {'a': 2}>>> y = {'a': 1}>>> dict(x.items() | y.items()){'a': 2}Another hack you should not use:z = dict(x, **y)This uses the dict constructor and is very fast and memory-efficient (even slightly more so than our two-step process) but unless you know precisely what is happening here (that is, the second dict is being passed as keyword arguments to the dict constructor), it's difficult to read, it's not the intended usage, and so it is not Pythonic.Here's an example of the usage being remediated in django.Dictionaries are intended to take hashable keys (e.g. frozensets or tuples), but this method fails in Python 3 when keys are not strings.>>> c = dict(a, **b)Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>TypeError: keyword arguments must be stringsFrom the mailing list, Guido van Rossum, the creator of the language, wrote:I am fine withdeclaring dict({}, **{1:3}) illegal, since after all it is abuse ofthe ** mechanism.andApparently dict(x, **y) is going around as ""cool hack"" for ""callx.update(y) and return x"". Personally, I find it more despicable thancool.It is my understanding (as well as the understanding of the creator of the language) that the intended usage for dict(**y) is for creating dictionaries for readability purposes, e.g.:dict(a=1, b=10, c=11)instead of{'a': 1, 'b': 10, 'c': 11}Response to commentsDespite what Guido says, dict(x, **y) is in line with the dict specification, which btw. works for both Python 2 and 3. The fact that this only works for string keys is a direct consequence of how keyword parameters work and not a short-coming of dict. Nor is using the ** operator in this place an abuse of the mechanism, in fact, ** was designed precisely to pass dictionaries as keywords.Again, it doesn't work for 3 when keys are not strings. The implicit calling contract is that namespaces take ordinary dictionaries, while users must only pass keyword arguments that are strings. All other callables enforced it. dict broke this consistency in Python 2:>>> foo(**{('a', 'b'): None})Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>TypeError: foo() keywords must be strings>>> dict(**{('a', 'b'): None}){('a', 'b'): None}This inconsistency was bad given other implementations of Python (PyPy, Jython, IronPython). Thus it was fixed in Python 3, as this usage could be a breaking change.I submit to you that it is malicious incompetence to intentionally write code that only works in one version of a language or that only works given certain arbitrary constraints.More comments:dict(x.items() + y.items()) is still the most readable solution for Python 2. Readability counts.My response: merge_two_dicts(x, y) actually seems much clearer to me, if we're actually concerned about readability. And it is not forward compatible, as Python 2 is increasingly deprecated.{**x, **y} does not seem to handle nested dictionaries. the contents of nested keys are simply overwritten, not merged [...] I ended up being burnt by these answers that do not merge recursively and I was surprised no one mentioned it. In my interpretation of the word ""merging"" these answers describe ""updating one dict with another"", and not merging.Yes. I must refer you back to the question, which is asking for a shallow merge of two dictionaries, with the first's values being overwritten by the second's - in a single expression.Assuming two dictionaries of dictionaries, one might recursively merge them in a single function, but you should be careful not to modify the dictionaries from either source, and the surest way to avoid that is to make a copy when assigning values. As keys must be hashable and are usually therefore immutable, it is pointless to copy them:from copy import deepcopydef dict_of_dicts_merge(x, y):    z = {}    overlapping_keys = x.keys() & y.keys()    for key in overlapping_keys:        z[key] = dict_of_dicts_merge(x[key], y[key])    for key in x.keys() - overlapping_keys:        z[key] = deepcopy(x[key])    for key in y.keys() - overlapping_keys:        z[key] = deepcopy(y[key])    return zUsage:>>> x = {'a':{1:{}}, 'b': {2:{}}}>>> y = {'b':{10:{}}, 'c': {11:{}}}>>> dict_of_dicts_merge(x, y){'b': {2: {}, 10: {}}, 'a': {1: {}}, 'c': {11: {}}}Coming up with contingencies for other value types is far beyond the scope of this question, so I will point you at my answer to the canonical question on a ""Dictionaries of dictionaries merge"".Less Performant But Correct Ad-hocsThese approaches are less performant, but they will provide correct behavior.They will be much less performant than copy and update or the new unpacking because they iterate through each key-value pair at a higher level of abstraction, but they do respect the order of precedence (latter dictionaries have precedence)You can also chain the dictionaries manually inside a dict comprehension:{k: v for d in dicts for k, v in d.items()} # iteritems in Python 2.7or in Python 2.6 (and perhaps as early as 2.4 when generator expressions were introduced):dict((k, v) for d in dicts for k, v in d.items()) # iteritems in Python 2itertools.chain will chain the iterators over the key-value pairs in the correct order:from itertools import chainz = dict(chain(x.items(), y.items())) # iteritems in Python 2Performance AnalysisI'm only going to do the performance analysis of the usages known to behave correctly. (Self-contained so you can copy and paste yourself.)from timeit import repeatfrom itertools import chainx = dict.fromkeys('abcdefg')y = dict.fromkeys('efghijk')def merge_two_dicts(x, y):    z = x.copy()    z.update(y)    return zmin(repeat(lambda: {**x, **y}))min(repeat(lambda: merge_two_dicts(x, y)))min(repeat(lambda: {k: v for d in (x, y) for k, v in d.items()}))min(repeat(lambda: dict(chain(x.items(), y.items()))))min(repeat(lambda: dict(item for d in (x, y) for item in d.items())))In Python 3.8.1, NixOS:>>> min(repeat(lambda: {**x, **y}))1.0804965235292912>>> min(repeat(lambda: merge_two_dicts(x, y)))1.636518670246005>>> min(repeat(lambda: {k: v for d in (x, y) for k, v in d.items()}))3.1779992282390594>>> min(repeat(lambda: dict(chain(x.items(), y.items()))))2.740647904574871>>> min(repeat(lambda: dict(item for d in (x, y) for item in d.items())))4.266070580109954$ uname -aLinux nixos 4.19.113 #1-NixOS SMP Wed Mar 25 07:06:15 UTC 2020 x86_64 GNU/LinuxResources on DictionariesMy explanation of Python's dictionary implementation, updated for 3.6.Answer on how to add new keys to a dictionaryMapping two lists into a dictionaryThe official Python docs on dictionariesThe Dictionary Even Mightier - talk by Brandon Rhodes at Pycon 2017Modern Python Dictionaries, A Confluence of Great Ideas - talk by Raymond Hettinger at Pycon 2017"
"data_i","edited Jul 06 '22 at 21:29","
        How do I return the response from an asynchronous call?
    ","How do I return the response/result from a function foo that makes an asynchronous request?I am trying to return the value from the callback, as well as assigning the result to a local variable inside the function and returning that one, but none of those ways actually return the response — they all return undefined or whatever the initial value of the variable result is.Example of an asynchronous function that accepts a callback (using jQuery's ajax function):function foo() {    var result;    $.ajax({        url: '...',        success: function(response) {            result = response;            // return response; // <- I tried that one as well        }    });    return result; // It always returns `undefined`}Example using Node.js:function foo() {    var result;    fs.readFile(""path/to/file"", function(err, data) {        result = data;        // return data; // <- I tried that one as well    });    return result; // It always returns `undefined`}Example using the then block of a promise:function foo() {    var result;    fetch(url).then(function(response) {        result = response;        // return response; // <- I tried that one as well    });    return result; // It always returns `undefined`}","→ For a more general explanation of asynchronous behaviour with different examples, see Why is my variable unaltered after I modify it inside of a function? - Asynchronous code reference→ If you already understand the problem, skip to the possible solutions below.The problemThe A in Ajax stands for asynchronous. That means sending the request (or rather receiving the response) is taken out of the normal execution flow. In your example, $.ajax returns immediately and the next statement, return result;, is executed before the function you passed as success callback was even called.Here is an analogy which hopefully makes the difference between synchronous and asynchronous flow clearer:SynchronousImagine you make a phone call to a friend and ask him to look something up for you. Although it might take a while, you wait on the phone and stare into space, until your friend gives you the answer that you needed.The same is happening when you make a function call containing ""normal"" code:function findItem() {    var item;    while(item_not_found) {        // search    }    return item;}var item = findItem();// Do something with itemdoSomethingElse();Even though findItem might take a long time to execute, any code coming after var item = findItem(); has to wait until the function returns the result.AsynchronousYou call your friend again for the same reason. But this time you tell him that you are in a hurry and he should call you back on your mobile phone. You hang up, leave the house, and do whatever you planned to do. Once your friend calls you back, you are dealing with the information he gave to you.That's exactly what's happening when you do an Ajax request.findItem(function(item) {    // Do something with the item});doSomethingElse();Instead of waiting for the response, the execution continues immediately and the statement after the Ajax call is executed. To get the response eventually, you provide a function to be called once the response was received, a callback (notice something? call back ?). Any statement coming after that call is executed before the callback is called.Solution(s)Embrace the asynchronous nature of JavaScript! While certain asynchronous operations provide synchronous counterparts (so does ""Ajax""), it's generally discouraged to use them, especially in a browser context.Why is it bad do you ask?JavaScript runs in the UI thread of the browser and any long-running process will lock the UI, making it unresponsive. Additionally, there is an upper limit on the execution time for JavaScript and the browser will ask the user whether to continue the execution or not.All of this results in a really bad user experience. The user won't be able to tell whether everything is working fine or not. Furthermore, the effect will be worse for users with a slow connection.In the following we will look at three different solutions that are all building on top of each other:Promises with async/await (ES2017+, available in older browsers if you use a transpiler or regenerator)Callbacks (popular in node)Promises with then() (ES2015+, available in older browsers if you use one of the many promise libraries)All three are available in current browsers, and node 7+.ES2017+: Promises with async/awaitThe ECMAScript version released in 2017 introduced syntax-level support for asynchronous functions. With the help of async and await, you can write asynchronous in a ""synchronous style"". The code is still asynchronous, but it's easier to read/understand.async/await builds on top of promises: an async function always returns a promise. await ""unwraps"" a promise and either result in the value the promise was resolved with or throws an error if the promise was rejected.Important: You can only use await inside an async function or in a JavaScript module. Top-level await is not supported outside of modules, so you might have to make an async IIFE (Immediately Invoked Function Expression) to start an async context if not using a module.You can read more about async and await on MDN.Here is an example that elaborates the delay function findItem() above:// Using 'superagent' which will return a promise.var superagent = require('superagent')// This is isn't declared as `async` because it already returns a promisefunction delay() {  // `delay` returns a promise  return new Promise(function(resolve, reject) {    // Only `delay` is able to resolve or reject the promise    setTimeout(function() {      resolve(42); // After 3 seconds, resolve the promise with value 42    }, 3000);  });}async function getAllBooks() {  try {    // GET a list of book IDs of the current user    var bookIDs = await superagent.get('/user/books');    // wait for 3 seconds (just for the sake of this example)    await delay();    // GET information about each book    return superagent.get('/books/ids='+JSON.stringify(bookIDs));  } catch(error) {    // If any of the awaited promises was rejected, this catch block    // would catch the rejection reason    return null;  }}// Start an IIFE to use `await` at the top level(async function(){  let books = await getAllBooks();  console.log(books);})();Current browser and node versions support async/await. You can also support older environments by transforming your code to ES5 with the help of regenerator (or tools that use regenerator, such as Babel).Let functions accept callbacksA callback is when function 1 is passed to function 2. Function 2 can call function 1 whenever it is ready. In the context of an asynchronous process, the callback will be called whenever the asynchronous process is done. Usually, the result is passed to the callback.In the example of the question, you can make foo accept a callback and use it as success callback. So thisvar result = foo();// Code that depends on 'result'becomesfoo(function(result) {    // Code that depends on 'result'});Here we defined the function ""inline"" but you can pass any function reference:function myCallback(result) {    // Code that depends on 'result'}foo(myCallback);foo itself is defined as follows:function foo(callback) {    $.ajax({        // ...        success: callback    });}callback will refer to the function we pass to foo when we call it and we pass it on to success. I.e. once the Ajax request is successful, $.ajax will call callback and pass the response to the callback (which can be referred to with result, since this is how we defined the callback).You can also process the response before passing it to the callback:function foo(callback) {    $.ajax({        // ...        success: function(response) {            // For example, filter the response            callback(filtered_response);        }    });}It's easier to write code using callbacks than it may seem. After all, JavaScript in the browser is heavily event-driven (DOM events). Receiving the Ajax response is nothing else but an event.Difficulties could arise when you have to work with third-party code, but most problems can be solved by just thinking through the application flow.ES2015+: Promises with then()The Promise API is a new feature of ECMAScript 6 (ES2015), but it has good browser support already. There are also many libraries which implement the standard Promises API and provide additional methods to ease the use and composition of asynchronous functions (e.g., bluebird).Promises are containers for future values. When the promise receives the value (it is resolved) or when it is canceled (rejected), it notifies all of its ""listeners"" who want to access this value.The advantage over plain callbacks is that they allow you to decouple your code and they are easier to compose.Here is an example of using a promise:function delay() {  // `delay` returns a promise  return new Promise(function(resolve, reject) {    // Only `delay` is able to resolve or reject the promise    setTimeout(function() {      resolve(42); // After 3 seconds, resolve the promise with value 42    }, 3000);  });}delay()  .then(function(v) { // `delay` returns a promise    console.log(v); // Log the value once it is resolved  })  .catch(function(v) {    // Or do something else if it is rejected    // (it would not happen in this example, since `reject` is not called).  });.as-console-wrapper { max-height: 100% !important; top: 0; }Applied to our Ajax call we could use promises like this:function ajax(url) {  return new Promise(function(resolve, reject) {    var xhr = new XMLHttpRequest();    xhr.onload = function() {      resolve(this.responseText);    };    xhr.onerror = reject;    xhr.open('GET', url);    xhr.send();  });}ajax(""https://jsonplaceholder.typicode.com/todos/1"")  .then(function(result) {    console.log(result); // Code depending on result  })  .catch(function() {    // An error occurred  });.as-console-wrapper { max-height: 100% !important; top: 0; }Describing all the advantages that promise offer is beyond the scope of this answer, but if you write new code, you should seriously consider them. They provide a great abstraction and separation of your code.More information about promises: HTML5 rocks - JavaScript Promises.Side note: jQuery's deferred objectsDeferred objects are jQuery's custom implementation of promises (before the Promise API was standardized). They behave almost like promises but expose a slightly different API.Every Ajax method of jQuery already returns a ""deferred object"" (actually a promise of a deferred object) which you can just return from your function:function ajax() {    return $.ajax(...);}ajax().done(function(result) {    // Code depending on result}).fail(function() {    // An error occurred});Side note: Promise gotchasKeep in mind that promises and deferred objects are just containers for a future value, they are not the value itself. For example, suppose you had the following:function checkPassword() {    return $.ajax({        url: '/password',        data: {            username: $('#username').val(),            password: $('#password').val()        },        type: 'POST',        dataType: 'json'    });}if (checkPassword()) {    // Tell the user they're logged in}This code misunderstands the above asynchronous issues. Specifically, $.ajax() doesn't freeze the code while it checks the '/password' page on your server - it sends a request to the server and while it waits, it immediately returns a jQuery Ajax Deferred object, not the response from the server. That means the if statement is going to always get this Deferred object, treat it as true, and proceed as though the user is logged in. Not good.But the fix is easy:checkPassword().done(function(r) {    if (r) {        // Tell the user they're logged in    } else {        // Tell the user their password was bad    }}).fail(function(x) {    // Tell the user something bad happened});Not recommended: Synchronous ""Ajax"" callsAs I mentioned, some(!) asynchronous operations have synchronous counterparts. I don't advocate their use, but for completeness' sake, here is how you would perform a synchronous call:Without jQueryIf you directly use a XMLHttpRequest object, pass false as third argument to .open.jQueryIf you use jQuery, you can set the async option to false. Note that this option is deprecated since jQuery 1.8.You can then either still use a success callback or access the responseText property of the jqXHR object:function foo() {    var jqXHR = $.ajax({        //...        async: false    });    return jqXHR.responseText;}If you use any other jQuery Ajax method, such as $.get, $.getJSON, etc., you have to change it to $.ajax (since you can only pass configuration parameters to $.ajax).Heads up! It is not possible to make a synchronous JSONP request. JSONP by its very nature is always asynchronous (one more reason to not even consider this option)."
"data_i","edited Jul 11 '22 at 05:53","
        What is the difference between px, dip, dp, and sp?
    ","What is the difference between the units of measurepx, dip, dp, and sp?","From the Android Developer Documentation:pxPixels - corresponds to actual pixels on the screen.inInches - based on the physical size of the screen.1 Inch OR 2.54 centimetersmm> Millimeters - based on the physical size of the screen.pt> Points - 1/72 of an inch based on the physical size of the screen.dp or dip> Density-independent Pixels - an abstract unit that is based on the physical density of the screen. These units are relative to a 160dpi screen, so one dp is one pixel on a 160 dpi screen. The ratio of dp-to-pixel will change with the screen density, but not necessarily in direct proportion. Note: The compiler accepts both ""dip"" and ""dp"", though ""dp"" is more consistent with ""sp"".sp> Scaleable Pixels OR scale-independent pixels - this is like the dp unit, but it is also scaled by the user's font size preference. It is recommended youuse this unit when specifying font sizes, so they will be adjustedfor both the screen density and the user's preference. Note, the Android documentation is inconsistent on what sp actually stands for, one doc says ""scale-independent pixels"", the other says ""scaleable pixels"".From Understanding Density Independence In Android:Density BucketScreen DensityPhysical SizePixel Sizeldpi120 dpi0.5 x 0.5 in0.5 in * 120 dpi = 60x60 pxmdpi160 dpi0.5 x 0.5 in0.5 in * 160 dpi = 80x80 pxhdpi240 dpi0.5 x 0.5 in0.5 in * 240 dpi = 120x120 pxxhdpi320 dpi0.5 x 0.5 in0.5 in * 320 dpi = 160x160 pxxxhdpi480 dpi0.5 x 0.5 in0.5 in * 480 dpi = 240x240 pxxxxhdpi640 dpi0.5 x 0.5 in0.5 in * 640 dpi = 320x320 pxUnitDescriptionUnits Per Physical InchDensity Independent?Same Physical Size On Every Screen?pxPixelsVariesNoNoinInches1YesYesmmMillimeters25.4YesYesptPoints72YesYesdpDensity Independent Pixels~160YesNospScale Independent Pixels~160YesNoMore info can be also be found in the Google Design Documentation."
"data_i","edited Jul 08 '22 at 04:10","
        Move the most recent commit(s) to a new branch with Git
    ","How do I move my recent commits on master to a new branch, and reset master to before those commits were made? e.g. From this:master A - B - C - D - ETo this:newbranch     C - D - E             /master A - B ","Moving to an existing branchIf you want to move your commits to an existing branch, it will look like this:git checkout existingbranchgit merge mastergit checkout mastergit reset --hard HEAD~3 # Go back 3 commits. You *will* lose uncommitted work.git checkout existingbranchYou can store uncommitted edits to your stash before doing this, using git stash. Once complete, you can retrieve the stashed uncommitted edits with git stash popMoving to a new branchWARNING: This method works because you are creating a new branch with the first command: git branch newbranch. If you want to move commits to an existing branch you need to merge your changes into the existing branch before executing git reset --hard HEAD~3 (see Moving to an existing branch above). If you don't merge your changes first, they will be lost.Unless there are other circumstances involved, this can be easily done by branching and rolling back.# Note: Any changes not committed will be lost.git branch newbranch      # Create a new branch, saving the desired commitsgit checkout master       # checkout master, this is the place you want to go backgit reset --hard HEAD~3   # Move master back by 3 commits (Make sure you know how many commits you need to go back)git checkout newbranch    # Go to the new branch that still has the desired commitsBut do make sure how many commits to go back. Alternatively, you can instead of HEAD~3, simply provide the hash of the commit (or the reference like origin/master) you want to ""revert back to"" on the master (/current) branch, e.g:git reset --hard a1b2c3d4*1 You will only be ""losing"" commits from the master branch, but don't worry, you'll have those commits in newbranch!Lastly, you may need to force push your latest changes to main repo:git push origin master --forceWARNING: With Git version 2.0 and later, if you later git rebase the new branch upon the original (master) branch, you may need an explicit --no-fork-point option during the rebase to avoid losing the carried-over commits.  Having branch.autosetuprebase always set makes this more likely.  See John Mellor's answer for details."
"data_i","edited Oct 07 '21 at 07:34","
        What is the difference between POST and PUT in HTTP?
    ","According to RFC 2616, § 9.5, POST is used to create a resource:The POST method is used to request that the origin server accept the entity enclosed in the request as a new subordinate of the resource identified by the Request-URI in the Request-Line.According to RFC 2616, § 9.6, PUT is used to create or replace a resource:The PUT method requests that the enclosed entity be stored under the supplied Request-URI. If the Request-URI refers to an already existing resource, the enclosed entity SHOULD be considered as a modified version of the one residing on the origin server. If the Request-URI does not point to an existing resource, and that URI is capable of being defined as a new resource by the requesting user agent, the origin server can create the resource with that URI.So which HTTP method should be used to create a resource? Or should both be supported?","Overall:Both PUT and POST can be used for creating.You have to ask, ""what are you performing the action upon?"", to distinguish what you should be using. Let's assume you're designing an API for asking questions.  If you want to use POST, then you would do that to a list of questions. If you want to use PUT, then you would do that to a particular question.Great, both can be used, so which one should I use in my RESTful design:You do not need to support both PUT and POST.Which you use is up to you.  But just remember to use the right one depending on what object you are referencing in the request.Some considerations:Do you name the URL objects you create explicitly, or let the server decide? If you name them then use PUT.  If you let the server decide then use POST.PUT is defined to assume idempotency, so if you PUT an object twice, it should have no additional effect.  This is a nice property, so I would use PUT when possible. Just make sure that the PUT-idempotency actually is implemented correctly in the server.You can update or create a resource with PUT with the same object URLWith POST you can have 2 requests coming in at the same time making modifications to a URL, and they may update different parts of the object.An example:I wrote the following as part of another answer on SO regarding this:POST:Used to modify and update a resourcePOST /questions/<existing_question> HTTP/1.1Host: www.example.com/Note that the following is an error:POST /questions/<new_question> HTTP/1.1Host: www.example.com/If the URL is not yet created, youshould not be using POST to create itwhile specifying the name.  This shouldresult in a 'resource not found' errorbecause <new_question> does not existyet.  You should PUT the <new_question>resource on the server first.You could though do something likethis to create a resources using POST:POST /questions HTTP/1.1Host: www.example.com/Note that in this case the resourcename is not specified, the new objectsURL path would be returned to you.PUT:Used to create a resource, oroverwrite it.  While you specify theresources new URL.For a new resource:PUT /questions/<new_question> HTTP/1.1Host: www.example.com/To overwrite an existing resource:PUT /questions/<existing_question> HTTP/1.1Host: www.example.com/Additionally, and a bit more concisely, RFC 7231 Section 4.3.4 PUT states (emphasis added),4.3.4.  PUTThe PUT method requests that the state of the target resource becreated or replaced with the state defined by the representationenclosed in the request message payload."
"data_i","edited Jul 24 '22 at 23:47","
        How do I include a JavaScript file in another JavaScript file?
    ","How do I include a JavaScript file inside another JavaScript file, similar to @import in CSS?","The old versions of JavaScript had no import, include, or require, so many different approaches to this problem have been developed.But since 2015 (ES6), JavaScript has had the ES6 modules standard to import modules in Node.js, which is also supported by most modern browsers.For compatibility with older browsers, build tools like Webpack and Rollup and/or transpilation tools like Babel can be used.ES6 ModulesECMAScript (ES6) modules have been supported in Node.js since v8.5, with the --experimental-modules flag, and since at least Node.js v13.8.0 without the flag. To enable ""ESM"" (vs. Node.js's previous CommonJS-style module system [""CJS""]) you either use ""type"": ""module"" in package.json or give the files the extension .mjs. (Similarly, modules written with Node.js's previous CJS module can be named .cjs if your default is ESM.)Using package.json:{    ""type"": ""module""}Then module.js:export function hello() {  return ""Hello"";}Then main.js:import { hello } from './module.js';let val = hello();  // val is ""Hello"";Using .mjs, you'd have module.mjs:export function hello() {  return ""Hello"";}Then main.mjs:import { hello } from './module.mjs';let val = hello();  // val is ""Hello"";ECMAScript modules in browsersBrowsers have had support for loading ECMAScript modules directly (no tools like Webpack required) since Safari 10.1, Chrome 61, Firefox 60, and Edge 16. Check the current support at caniuse. There is no need to use Node.js' .mjs extension; browsers completely ignore file extensions on modules/scripts.<script type=""module"">  import { hello } from './hello.mjs'; // Or the extension could be just `.js`  hello('world');</script>// hello.mjs -- or the extension could be just `.js`export function hello(text) {  const div = document.createElement('div');  div.textContent = `Hello ${text}`;  document.body.appendChild(div);}Read more at https://jakearchibald.com/2017/es-modules-in-browsers/Dynamic imports in browsersDynamic imports let the script load other scripts as needed:<script type=""module"">  import('hello.mjs').then(module => {      module.hello('world');    });</script>Read more at https://developers.google.com/web/updates/2017/11/dynamic-importNode.js requireThe older CJS module style, still widely used in Node.js, is the module.exports/require system.// mymodule.jsmodule.exports = {   hello: function() {      return ""Hello"";   }}// server.jsconst myModule = require('./mymodule');let val = myModule.hello(); // val is ""Hello""   There are other ways for JavaScript to include external JavaScript contents in browsers that do not require preprocessing.AJAX LoadingYou could load an additional script with an AJAX call and then use eval to run it. This is the most straightforward way, but it is limited to your domain because of the JavaScript sandbox security model. Using eval also opens the door to bugs, hacks and security issues.Fetch LoadingLike Dynamic Imports you can load one or many scripts with a fetch call using promises to control order of execution for script dependencies using the Fetch Inject library:fetchInject([  'https://cdn.jsdelivr.net/momentjs/2.17.1/moment.min.js']).then(() => {  console.log(`Finish in less than ${moment().endOf('year').fromNow(true)}`)})jQuery LoadingThe jQuery library provides loading functionality in one line:$.getScript(""my_lovely_script.js"", function() {   alert(""Script loaded but not necessarily executed."");});Dynamic Script LoadingYou could add a script tag with the script URL into the HTML. To avoid the overhead of jQuery, this is an ideal solution.The script can even reside on a different server. Furthermore, the browser evaluates the code. The <script> tag can be injected into either the web page <head>, or inserted just before the closing </body> tag.Here is an example of how this could work:function dynamicallyLoadScript(url) {    var script = document.createElement(""script"");  // create a script DOM node    script.src = url;  // set its src to the provided URL       document.head.appendChild(script);  // add it to the end of the head section of the page (could change 'head' to 'body' to add it to the end of the body section instead)}This function will add a new <script> tag to the end of the head section of the page, where the src attribute is set to the URL which is given to the function as the first parameter.Both of these solutions are discussed and illustrated in JavaScript Madness: Dynamic Script Loading.Detecting when the script has been executedNow, there is a big issue you must know about. Doing that implies that you remotely load the code. Modern web browsers will load the file and keep executing your current script because they load everything asynchronously to improve performance. (This applies to both the jQuery method and the manual dynamic script loading method.)It means that if you use these tricks directly, you won't be able to use your newly loaded code the next line after you asked it to be loaded, because it will be still loading.For example: my_lovely_script.js contains MySuperObject:var js = document.createElement(""script"");js.type = ""text/javascript"";js.src = jsFilePath;document.body.appendChild(js);var s = new MySuperObject();Error : MySuperObject is undefinedThen you reload the page hitting F5. And it works! Confusing...So what to do about it ?Well, you can use the hack the author suggests in the link I gave you. In summary, for people in a hurry, he uses an event to run a callback function when the script is loaded. So you can put all the code using the remote library in the callback function. For example:function loadScript(url, callback){    // Adding the script tag to the head as suggested before    var head = document.head;    var script = document.createElement('script');    script.type = 'text/javascript';    script.src = url;    // Then bind the event to the callback function.    // There are several events for cross browser compatibility.    script.onreadystatechange = callback;    script.onload = callback;    // Fire the loading    head.appendChild(script);}Then you write the code you want to use AFTER the script is loaded in a lambda function:var myPrettyCode = function() {   // Here, do whatever you want};Then you run all that:loadScript(""my_lovely_script.js"", myPrettyCode);Note that the script may execute after the DOM has loaded, or before, depending on the browser and whether you included the line script.async = false;. There's a great article on Javascript loading in general which discusses this.Source Code Merge/PreprocessingAs mentioned at the top of this answer, many developers use build/transpilation tool(s) like Parcel, Webpack, or Babel in their projects, allowing them to use upcoming JavaScript syntax, provide backward compatibility for older browsers, combine files, minify, perform code splitting etc."
"data_i","edited Jul 24 '22 at 23:50","
        How to disable text selection highlighting
    ","For anchors that act like buttons (for example, the buttons on the sidebar of this Stack Overflow page titled Questions, Tags, and Users) or tabs, is there a CSS standard way to disable the highlighting effect if the user accidentally selects the text?I realize that this could be done with JavaScript and a little googling yielded the Mozilla-only -moz-user-select option.Is there a standard-compliant way to accomplish this with CSS, and if not, what is the ""best practice"" approach?","UPDATE January, 2017:According to Can I use, the user-select + -webkit-user-select for Safari is enough to achieve desired behavior in all major browsers.These are all of the available correct CSS variations:.noselect {  -webkit-touch-callout: none; /* iOS Safari */    -webkit-user-select: none; /* Safari */     -khtml-user-select: none; /* Konqueror HTML */       -moz-user-select: none; /* Old versions of Firefox */        -ms-user-select: none; /* Internet Explorer/Edge */            user-select: none; /* Non-prefixed version, currently                                  supported by Chrome, Edge, Opera and Firefox */}<p>  Selectable text.</p><p class=""noselect"">  Unselectable text.</p>Note that user-select is in standardization process (currently in a W3C working draft). It is not guaranteed to work everywhere and there might be differences in implementation among browsers. Also, browsers can drop support for it in the future.More information can be found in Mozilla Developer Network documentation.The values of this attribute are none, text, toggle, element, elements, all and inherit."
"data_i","edited Jul 21 '22 at 13:56","
        What is the difference between ""let"" and ""var""?
    ","ECMAScript 6 introduced the let statement.I've heard that it's described as a local variable, but I'm still not quite sure how it behaves differently than the var keyword.What are the differences? When should let be used instead of var?","Scoping rulesThe main difference is scoping rules. Variables declared by var keyword are scoped to the immediate function body (hence the function scope) while let variables are scoped to the immediate enclosing block denoted by { } (hence the block scope).function run() {  var foo = ""Foo"";  let bar = ""Bar"";  console.log(foo, bar); // Foo Bar  {    var moo = ""Mooo""    let baz = ""Bazz"";    console.log(moo, baz); // Mooo Bazz  }  console.log(moo); // Mooo  console.log(baz); // ReferenceError}run();The reason why let keyword was introduced to the language was function scope is confusing and was one of the main sources of bugs in JavaScript.Take a look at this example from another Stack Overflow question:var funcs = [];// let's create 3 functionsfor (var i = 0; i < 3; i++) {  // and store them in funcs  funcs[i] = function() {    // each should log its value.    console.log(""My value: "" + i);  };}for (var j = 0; j < 3; j++) {  // and now let's run each one to see  funcs[j]();}My value: 3 was output to console each time funcs[j](); was invoked since anonymous functions were bound to the same variable.People had to create immediately invoked functions to capture correct values from the loops but that was also hairy.HoistingWhile variables declared with var keyword are hoisted (initialized with undefined before the code is run) which means they are accessible in their enclosing scope even before they are declared:function run() {  console.log(foo); // undefined  var foo = ""Foo"";  console.log(foo); // Foo}run();let variables are not initialized until their definition is evaluated. Accessing them before the initialization results in a ReferenceError. The variable is said to be in ""temporal dead zone"" from the start of the block until the initialization is processed.function checkHoisting() {  console.log(foo); // ReferenceError  let foo = ""Foo"";  console.log(foo); // Foo}checkHoisting();Creating global object propertyAt the top level, let, unlike var, does not create a property on the global object:var foo = ""Foo"";  // globally scopedlet bar = ""Bar""; // not allowed to be globally scopedconsole.log(window.foo); // Fooconsole.log(window.bar); // undefinedRedeclarationIn strict mode, var will let you re-declare the same variable in the same scope while let raises a SyntaxError.'use strict';var foo = ""foo1"";var foo = ""foo2""; // No problem, 'foo1' is replaced with 'foo2'.let bar = ""bar1""; let bar = ""bar2""; // SyntaxError: Identifier 'bar' has already been declared"
"data_i","edited Jul 27 '22 at 08:42","
        How do I discard unstaged changes in Git?
    ","How do I discard changes in my working copy that are not in the index?","For all unstaged files in current working directory use:git restore .For a specific file use:git restore path/to/file/to/revertThat together with git switch replaces the overloaded git checkout (see here), and thus removes the argument disambiguation.If a file has both staged and unstaged changes, only the unstaged changes shown in git diff are reverted. Changes shown in git diff --staged stay intact.Before Git 2.23For all unstaged files in current working directory:git checkout -- .For a specific file:git checkout -- path/to/file/to/revert-- here to remove ambiguity (this is known as  argument disambiguation)."
"data_i","edited Jul 24 '22 at 23:51","
        How do I get the directory where a Bash script is located from within the script itself?
    ","How do I get the path of the directory in which a Bash script is located, inside that script?I want to use a Bash script as a launcher for another application. I want to change the working directory to the one where the Bash script is located, so I can operate on the files in that directory, like so:$ ./application","#!/usr/bin/env bashSCRIPT_DIR=$( cd -- ""$( dirname -- ""${BASH_SOURCE[0]}"" )"" &> /dev/null && pwd )is a useful one-liner which will give you the full directory name of the script no matter where it is being called from.It will work as long as the last component of the path used to find the script is not a symlink (directory links are OK).  If you also want to resolve any links to the script itself, you need a multi-line solution:#!/usr/bin/env bashSOURCE=${BASH_SOURCE[0]}while [ -L ""$SOURCE"" ]; do # resolve $SOURCE until the file is no longer a symlink  DIR=$( cd -P ""$( dirname ""$SOURCE"" )"" >/dev/null 2>&1 && pwd )  SOURCE=$(readlink ""$SOURCE"")  [[ $SOURCE != /* ]] && SOURCE=$DIR/$SOURCE # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was locateddoneDIR=$( cd -P ""$( dirname ""$SOURCE"" )"" >/dev/null 2>&1 && pwd )This last one will work with any combination of aliases, source, bash -c, symlinks, etc.Beware: if you cd to a different directory before running this snippet, the result may be incorrect!Also, watch out for $CDPATH gotchas, and stderr output side effects if the user has smartly overridden cd to redirect output to stderr instead (including escape sequences, such as when calling update_terminal_cwd >&2 on Mac). Adding >/dev/null 2>&1 at the end of your cd command will take care of both possibilities.To understand how it works, try running this more verbose form:#!/usr/bin/env bashSOURCE=${BASH_SOURCE[0]}while [ -L ""$SOURCE"" ]; do # resolve $SOURCE until the file is no longer a symlink  TARGET=$(readlink ""$SOURCE"")  if [[ $TARGET == /* ]]; then    echo ""SOURCE '$SOURCE' is an absolute symlink to '$TARGET'""    SOURCE=$TARGET  else    DIR=$( dirname ""$SOURCE"" )    echo ""SOURCE '$SOURCE' is a relative symlink to '$TARGET' (relative to '$DIR')""    SOURCE=$DIR/$TARGET # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located  fidoneecho ""SOURCE is '$SOURCE'""RDIR=$( dirname ""$SOURCE"" )DIR=$( cd -P ""$( dirname ""$SOURCE"" )"" >/dev/null 2>&1 && pwd )if [ ""$DIR"" != ""$RDIR"" ]; then  echo ""DIR '$RDIR' resolves to '$DIR'""fiecho ""DIR is '$DIR'""And it will print something like:SOURCE './scriptdir.sh' is a relative symlink to 'sym2/scriptdir.sh' (relative to '.')SOURCE is './sym2/scriptdir.sh'DIR './sym2' resolves to '/home/ubuntu/dotfiles/fo fo/real/real1/real2'DIR is '/home/ubuntu/dotfiles/fo fo/real/real1/real2'"
"data_i","edited Mar 29 '22 at 09:30","
        How do I execute a program or call a system command?
    ","How do I call an external command within Python as if I'd typed it in a shell or command prompt?","Use the subprocess module in the standard library:import subprocesssubprocess.run([""ls"", ""-l""])The advantage of subprocess.run over os.system is that it is more flexible (you can get the stdout, stderr, the ""real"" status code, better error handling, etc...).Even the documentation for os.system recommends using subprocess instead:The subprocess module provides more powerful facilities for spawning new processes and retrieving their results; using that module is preferable to using this function. See the Replacing Older Functions with the subprocess Module section in the subprocess documentation for some helpful recipes.On Python 3.4 and earlier, use subprocess.call instead of .run:subprocess.call([""ls"", ""-l""])"
"data_i","edited Mar 22 '17 at 16:13","
        Which equals operator (== vs ===) should be used in JavaScript comparisons?
    ","I'm using JSLint to go through JavaScript, and it's returning many suggestions to replace == (two equals signs) with === (three equals signs) when doing things like comparing idSele_UNVEHtype.value.length == 0 inside of an if statement.Is there a performance benefit to replacing == with ===? Any performance improvement would be welcomed as many comparison operators exist.If no type conversion takes place, would there be a performance gain over ==?","The strict equality operator (===) behaves identically to the abstract equality operator (==) except no type conversion is done, and the types must be the same to be considered equal.Reference: Javascript Tutorial: Comparison OperatorsThe == operator will compare for equality after doing any necessary type conversions.  The === operator will not do the conversion, so if two values are not the same type === will simply return false. Both are equally quick.To quote Douglas Crockford's excellent JavaScript: The Good Parts,JavaScript has two sets of equality operators: === and !==, and their evil twins == and !=.  The good ones work the way you would expect.  If the two operands are of the same type and have the same value, then === produces true and !== produces false.  The evil twins do the right thing when the operands are of the same type, but if they are of different types, they attempt to coerce the values.  the rules by which they do that are complicated and unmemorable.  These are some of the interesting cases:'' == '0'           // false0 == ''             // true0 == '0'            // truefalse == 'false'    // falsefalse == '0'        // truefalse == undefined  // falsefalse == null       // falsenull == undefined   // true' \t\r\n ' == 0     // trueThe lack of transitivity is alarming.  My advice is to never use the evil twins.  Instead, always use === and !==.  All of the comparisons just shown produce false with the === operator.Update:A good point was brought up by @Casebash in the comments and in @Phillipe Laybaert's answer concerning objects.  For objects, == and === act consistently with one another (except in a special case).var a = [1,2,3];var b = [1,2,3];var c = { x: 1, y: 2 };var d = { x: 1, y: 2 };var e = ""text"";var f = ""te"" + ""xt"";a == b            // falsea === b           // falsec == d            // falsec === d           // falsee == f            // truee === f           // trueThe special case is when you compare a primitive with an object that evaluates to the same primitive, due to its toString or valueOf method. For example, consider the comparison of a string primitive with a string object created using the String constructor.""abc"" == new String(""abc"")    // true""abc"" === new String(""abc"")   // falseHere the == operator is checking the values of the two objects and returning true, but the === is seeing that they're not the same type and returning false.  Which one is correct?  That really depends on what you're trying to compare.  My advice is to bypass the question entirely and just don't use the String constructor to create string objects from string literals.Referencehttp://www.ecma-international.org/ecma-262/5.1/#sec-11.9.3"
"data_i","edited Aug 24 '22 at 19:29","
        How do I change the URI (URL) for a remote Git repository?
    ","I have a repo (origin) on a USB key that I cloned on my hard drive (local). I moved ""origin"" to a NAS and successfully tested cloning it from here.I would like to know if I can change the URI of ""origin"" in the settings of ""local"" so it will now pull from the NAS, and not from the USB key.For now, I can see two solutions:push everything to the USB origin, and copy it to the NAS again (implies a lot of work due to new commits to NAS origin);add a new remote to ""local"" and delete the old one (I fear I'll break my history).","You cangit remote set-url origin new.git.url/hereSee git help remote. You also can edit .git/config and change the URLs there.You're not in any danger of losing history unless you do something very silly (and if you're worried, just make a copy of your repo, since your repo is your history.)"
"data_i","edited Nov 11 '21 at 19:35","
        The definitive guide to form-based website authentication
    ","Moderator note:This question is not a good fit for our question and answer format with the topicality rules which currently apply for Stack Overflow. We normally use a ""historical lock"" for such questions where the content still has value. However, the answers on this question are actively maintained and a historical lock doesn't permit editing of the answers. As such, a ""wiki answer"" lock has been applied to allow the answers to be edited. You should assume the topicality issues which are normally handled by a historical lock are present (i.e. this question not a good example of an on-topic question for Stack Overflow).Form-based authentication for websitesWe believe that Stack Overflow should not just be a resource for very specific technical questions, but also for general guidelines on how to solve variations on common problems. ""Form based authentication for websites"" should be a fine topic for such an experiment.It should include topics such as:How to log inHow to log outHow to remain logged inManaging cookies (including recommended settings)SSL/HTTPS encryptionHow to store passwordsUsing secret questionsForgotten username/password functionalityUse of nonces to prevent cross-site request forgeries (CSRF)OpenID""Remember me"" checkboxBrowser autocompletion of usernames and passwordsSecret URLs (public URL protected by digest)Checking password strengthE-mail validationand much more about form based authentication...It should not include things like:Roles and authorizationHTTP basic authenticationPlease help us by:Suggesting subtopicsSubmitting good articles about this subjectEditing the official answer","PART I: How To Log InWe'll assume you already know how to build a login+password HTML form which POSTs the values to a script on the server side for authentication. The sections below will deal with patterns for sound practical auth, and how to avoid the most common security pitfalls.To HTTPS or not to HTTPS?Unless the connection is already secure (that is, tunneled through HTTPS using SSL/TLS), your login form values will be sent in cleartext, which allows anyone eavesdropping on the line between browser and web server will be able to read logins as they pass through. This type of wiretapping is done routinely by governments, but in general, we won't address 'owned' wires other than to say this: Just use HTTPS.In essence, the only practical way to protect against wiretapping/packet sniffing during login is by using HTTPS or another certificate-based encryption scheme (for example, TLS) or a proven & tested challenge-response scheme (for example, the Diffie-Hellman-based SRP). Any other method can be easily circumvented by an eavesdropping attacker.Of course, if you are willing to get a little bit impractical, you could also employ some form of two-factor authentication scheme (e.g. the Google Authenticator app, a physical 'cold war style' codebook, or an RSA key generator dongle). If applied correctly, this could work even with an unsecured connection, but it's hard to imagine that a dev would be willing to implement two-factor auth but not SSL.(Do not) Roll-your-own JavaScript encryption/hashingGiven the perceived (though now avoidable) cost and technical difficulty of setting up an SSL certificate on your website, some developers are tempted to roll their own in-browser hashing or encryption schemes in order to avoid passing cleartext logins over an unsecured wire.While this is a noble thought, it is essentially useless (and can be a security flaw) unless it is combined with one of the above - that is, either securing the line with strong encryption or using a tried-and-tested challenge-response mechanism (if you don't know what that is, just know that it is one of the most difficult to prove, most difficult to design, and most difficult to implement concepts in digital security).While it is true that hashing the password can be effective against password disclosure, it is vulnerable to replay attacks, Man-In-The-Middle attacks / hijackings (if an attacker can inject a few bytes into your unsecured HTML page before it reaches your browser, they can simply comment out the hashing in the JavaScript), or brute-force attacks (since you are handing the attacker both username, salt and hashed password).CAPTCHAS against humanityCAPTCHA is meant to thwart one specific category of attack: automated dictionary/brute force trial-and-error with no human operator. There is no doubt that this is a real threat, however, there are ways of dealing with it seamlessly that don't require a CAPTCHA, specifically properly designed server-side login throttling schemes - we'll discuss those later.Know that CAPTCHA implementations are not created alike; they often aren't human-solvable, most of them are actually ineffective against bots, all of them are ineffective against cheap third-world labor (according to OWASP, the current sweatshop rate is $12 per 500 tests), and some implementations may be technically illegal in some countries (see OWASP Authentication Cheat Sheet). If you must use a CAPTCHA, use Google's reCAPTCHA, since it is OCR-hard by definition (since it uses already OCR-misclassified book scans) and tries very hard to be user-friendly.Personally, I tend to find CAPTCHAS annoying, and use them only as a last resort when a user has failed to log in a number of times and throttling delays are maxed out. This will happen rarely enough to be acceptable, and it strengthens the system as a whole.Storing Passwords / Verifying loginsThis may finally be common knowledge after all the highly-publicized hacks and user data leaks we've seen in recent years, but it has to be said: Do not store passwords in cleartext in your database. User databases are routinely hacked, leaked or gleaned through SQL injection, and if you are storing raw, plaintext passwords, that is instant game over for your login security.So if you can't store the password, how do you check that the login+password combination POSTed from the login form is correct? The answer is hashing using a key derivation function. Whenever a new user is created or a password is changed, you take the password and run it through a KDF, such as Argon2, bcrypt, scrypt or PBKDF2, turning the cleartext password (""correcthorsebatterystaple"") into a long, random-looking string, which is a lot safer to store in your database. To verify a login, you run the same hash function on the entered password, this time passing in the salt and compare the resulting hash string to the value stored in your database. Argon2, bcrypt and scrypt store the salt with the hash already. Check out this article on sec.stackexchange for more detailed information.The reason a salt is used is that hashing in itself is not sufficient -- you'll want to add a so-called 'salt' to protect the hash against rainbow tables. A salt effectively prevents two passwords that exactly match from being stored as the same hash value, preventing the whole database being scanned in one run if an attacker is executing a password guessing attack.A cryptographic hash should not be used for password storage because user-selected passwords are not strong enough (i.e. do not usually contain enough entropy) and a password guessing attack could be completed in a relatively short time by an attacker with access to the hashes. This is why KDFs are used - these effectively ""stretch the key"", which means that every password guess an attacker makes causes multiple repetitions of the hash algorithm, for example 10,000 times, which causes the attacker to guess the password 10,000 times slower.Session data - ""You are logged in as Spiderman69""Once the server has verified the login and password against your user database and found a match, the system needs a way to remember that the browser has been authenticated. This fact should only ever be stored server side in the session data.If you are unfamiliar with session data, here's how it works: A single randomly-generated string is stored in an expiring cookie and used to reference a collection of data - the session data - which is stored on the server. If you are using an MVC framework, this is undoubtedly handled already.If at all possible, make sure the session cookie has the secure and HTTP Only flags set when sent to the browser. The HttpOnly flag provides some protection against the cookie being read through XSS attack. The secure flag ensures that the cookie is only sent back via HTTPS, and therefore protects against network sniffing attacks. The value of the cookie should not be predictable. Where a cookie referencing a non-existent session is presented, its value should be replaced immediately to prevent session fixation.Session state can also be maintained on the client side. This is achieved by using techniques like JWT (JSON Web Token).PART II: How To Remain Logged In - The Infamous ""Remember Me"" CheckboxPersistent Login Cookies (""remember me"" functionality) are a danger zone; on the one hand, they are entirely as safe as conventional logins when users understand how to handle them; and on the other hand, they are an enormous security risk in the hands of careless users, who may use them on public computers and forget to log out, and who may not know what browser cookies are or how to delete them.Personally, I like persistent logins for the websites I visit on a regular basis, but I know how to handle them safely. If you are positive that your users know the same, you can use persistent logins with a clean conscience. If not - well, then you may subscribe to the philosophy that users who are careless with their login credentials brought it upon themselves if they get hacked. It's not like we go to our user's houses and tear off all those facepalm-inducing Post-It notes with passwords they have lined up on the edge of their monitors, either.Of course, some systems can't afford to have any accounts hacked; for such systems, there is no way you can justify having persistent logins.If you DO decide to implement persistent login cookies, this is how you do it:First, take some time to read Paragon Initiative's article on the subject. You'll need to get a bunch of elements right, and the article does a great job of explaining each.And just to reiterate one of the most common pitfalls, DO NOT STORE THE PERSISTENT LOGIN COOKIE (TOKEN) IN YOUR DATABASE, ONLY A HASH OF IT! The login token is Password Equivalent, so if an attacker got their hands on your database, they could use the tokens to log in to any account, just as if they were cleartext login-password combinations. Therefore, use hashing (according to https://security.stackexchange.com/a/63438/5002 a weak hash will do just fine for this purpose) when storing persistent login tokens.PART III: Using Secret QuestionsDon't implement 'secret questions'. The 'secret questions' feature is a security anti-pattern. Read the paper from link number 4 from the MUST-READ list. You can ask Sarah Palin about that one, after her Yahoo! email account got hacked during a previous presidential campaign because the answer to her security question was... ""Wasilla High School""!Even with user-specified questions, it is highly likely that most users will choose either:A 'standard' secret question like mother's maiden name or favorite petA simple piece of trivia that anyone could lift from their blog, LinkedIn profile, or similarAny question that is easier to answer than guessing their password. Which, for any decent password, is every question you can imagineIn conclusion, security questions are inherently insecure in virtually all their forms and variations, and should not be employed in an authentication scheme for any reason.The true reason why security questions even exist in the wild is that they conveniently save the cost of a few support calls from users who can't access their email to get to a reactivation code. This at the expense of security and Sarah Palin's reputation. Worth it? Probably not.PART IV: Forgotten Password FunctionalityI already mentioned why you should never use security questions for handling forgotten/lost user passwords; it also goes without saying that you should never e-mail users their actual passwords. There are at least two more all-too-common pitfalls to avoid in this field:Don't reset a forgotten password to an autogenerated strong password - such passwords are notoriously hard to remember, which means the user must either change it or write it down - say, on a bright yellow Post-It on the edge of their monitor. Instead of setting a new password, just let users pick a new one right away - which is what they want to do anyway. (An exception to this might be if the users are universally using a password manager to store/manage passwords that would normally be impossible to remember without writing it down).Always hash the lost password code/token in the database. AGAIN, this code is another example of a Password Equivalent, so it MUST be hashed in case an attacker got their hands on your database. When a lost password code is requested, send the plaintext code to the user's email address, then hash it, save the hash in your database -- and throw away the original. Just like a password or a persistent login token.A final note: always make sure your interface for entering the 'lost password code' is at least as secure as your login form itself, or an attacker will simply use this to gain access instead. Making sure you generate very long 'lost password codes' (for example, 16 case-sensitive alphanumeric characters) is a good start, but consider adding the same throttling scheme that you do for the login form itself.PART V: Checking Password StrengthFirst, you'll want to read this small article for a reality check: The 500 most common passwordsOkay, so maybe the list isn't the canonical list of most common passwords on any system anywhere ever, but it's a good indication of how poorly people will choose their passwords when there is no enforced policy in place. Plus, the list looks frighteningly close to home when you compare it to publicly available analyses of recently stolen passwords.So: With no minimum password strength requirements, 2% of users use one of the top 20 most common passwords. Meaning: if an attacker gets just 20 attempts, 1 in 50 accounts on your website will be crackable.Thwarting this requires calculating the entropy of a password and then applying a threshold.  The National Institute of Standards and Technology (NIST) Special Publication 800-63 has a set of very good suggestions.  That, when combined with a dictionary and keyboard layout analysis (for example, 'qwertyuiop' is a bad password), can reject 99% of all poorly selected passwords at a level of 18 bits of entropy.  Simply calculating password strength and showing a visual strength meter to a user is good, but insufficient.  Unless it is enforced, a lot of users will most likely ignore it.And for a refreshing take on user-friendliness of high-entropy passwords, Randall Munroe's Password Strength xkcd is highly recommended.Utilize Troy Hunt's Have I Been Pwned API to check users passwords against passwords compromised in public data breaches.PART VI: Much More - Or: Preventing Rapid-Fire Login AttemptsFirst, have a look at the numbers: Password Recovery Speeds - How long will your password stand upIf you don't have the time to look through the tables in that link, here's the list of them:It takes virtually no time to crack a weak password, even if you're cracking it with an abacusIt takes virtually no time to crack an alphanumeric 9-character password if it is case insensitiveIt takes virtually no time to crack an intricate, symbols-and-letters-and-numbers, upper-and-lowercase password if it is less than 8 characters long (a desktop PC can search the entire keyspace up to 7 characters in a matter of days or even hours)It would, however, take an inordinate amount of time to crack even a 6-character password, if you were limited to one attempt per second!So what can we learn from these numbers? Well, lots, but we can focus on the most important part: the fact that preventing large numbers of rapid-fire successive login attempts (ie. the brute force attack) really isn't that difficult. But preventing it right isn't as easy as it seems.Generally speaking, you have three choices that are all effective against brute-force attacks (and dictionary attacks, but since you are already employing a strong passwords policy, they shouldn't be an issue):Present a CAPTCHA after N failed attempts (annoying as hell and often ineffective -- but I'm repeating myself here)Locking accounts and requiring email verification after N failed attempts (this is a DoS attack waiting to happen)And finally, login throttling: that is, setting a time delay between attempts after N failed attempts (yes, DoS attacks are still possible, but at least they are far less likely and a lot more complicated to pull off).Best practice #1: A short time delay that increases with the number of failed attempts, like:1 failed attempt = no delay2 failed attempts = 2 sec delay3 failed attempts = 4 sec delay4 failed attempts = 8 sec delay5 failed attempts = 16 sec delayetc.DoS attacking this scheme would be very impractical, since the resulting lockout time is slightly larger than the sum of the previous lockout times.To clarify: The delay is not a delay before returning the response to the browser. It is more like a timeout or refractory period during which login attempts to a specific account or from a specific IP address will not be accepted or evaluated at all. That is, correct credentials will not return in a successful login, and incorrect credentials will not trigger a delay increase.Best practice #2: A medium length time delay that goes into effect after N failed attempts, like:1-4 failed attempts = no delay5 failed attempts = 15-30 min delayDoS attacking this scheme would be quite impractical, but certainly doable. Also, it might be relevant to note that such a long delay can be very annoying for a legitimate user. Forgetful users will dislike you.Best practice #3: Combining the two approaches - either a fixed, short time delay that goes into effect after N failed attempts, like:1-4 failed attempts = no delay5+ failed attempts = 20 sec delayOr, an increasing delay with a fixed upper bound, like:1 failed attempt = 5 sec delay2 failed attempts = 15 sec delay3+ failed attempts = 45 sec delayThis final scheme was taken from the OWASP best-practices suggestions (link 1 from the MUST-READ list) and should be considered best practice, even if it is admittedly on the restrictive side.As a rule of thumb, however, I would say: the stronger your password policy is, the less you have to bug users with delays. If you require strong (case-sensitive alphanumerics + required numbers and symbols) 9+ character passwords, you could give the users 2-4 non-delayed password attempts before activating the throttling.DoS attacking this final login throttling scheme would be very impractical. And as a final touch, always allow persistent (cookie) logins (and/or a CAPTCHA-verified login form) to pass through, so legitimate users won't even be delayed while the attack is in progress. That way, the very impractical DoS attack becomes an extremely impractical attack.Additionally, it makes sense to do more aggressive throttling on admin accounts, since those are the most attractive entry pointsPART VII: Distributed Brute Force AttacksJust as an aside, more advanced attackers will try to circumvent login throttling by 'spreading their activities':Distributing the attempts on a botnet to prevent IP address flaggingRather than picking one user and trying the 50.000 most common passwords (which they can't, because of our throttling), they will pick THE most common password and try it against 50.000 users instead. That way, not only do they get around maximum-attempts measures like CAPTCHAs and login throttling, their chance of success increases as well, since the number 1 most common password is far more likely than number 49.995Spacing the login requests for each user account, say, 30 seconds apart, to sneak under the radarHere, the best practice would be logging the number of failed logins, system-wide, and using a running average of your site's bad-login frequency as the basis for an upper limit that you then impose on all users.Too abstract? Let me rephrase:Say your site has had an average of 120 bad logins per day over the past 3 months. Using that (running average), your system might set the global limit to 3 times that -- ie. 360 failed attempts over a 24 hour period. Then, if the total number of failed attempts across all accounts exceeds that number within one day (or even better, monitor the rate of acceleration and trigger on a calculated threshold), it activates system-wide login throttling - meaning short delays for ALL users (still, with the exception of cookie logins and/or backup CAPTCHA logins).I also posted a question with more details and a really good discussion of how to avoid tricky pitfals in fending off distributed brute force attacksPART VIII: Two-Factor Authentication and Authentication ProvidersCredentials can be compromised, whether by exploits, passwords being written down and lost, laptops with keys being stolen, or users entering logins into phishing sites.  Logins can be further protected with two-factor authentication, which uses out-of-band factors such as single-use codes received from a phone call, SMS message, app, or dongle. Several providers offer two-factor authentication services.Authentication can be completely delegated to a single-sign-on service, where another provider handles collecting credentials. This pushes the problem to a trusted third party. Google and Twitter both provide standards-based SSO services, while Facebook provides a similar proprietary solution.MUST-READ LINKS About Web AuthenticationOWASP Guide To Authentication / OWASP Authentication Cheat SheetDos and Don’ts of Client Authentication on the Web (very readable MIT research paper)Wikipedia: HTTP cookiePersonal knowledge questions for fallback authentication: Security questions in the era of Facebook (very readable Berkeley research paper)"
"data_i","edited Jul 24 '22 at 23:52","
        What is the maximum length of a URL in different browsers?
    ","What is the maximum length of a URL for each browser?Is a maximum URL length part of the HTTP specification?","Short answer - de facto limit of 2000 charactersIf you keep URLs under 2000 characters, they'll work in virtually any combination of client and server software.If you are targeting particular browsers, see below for more details on specific limits.Longer answer - first, the standards...RFC 2616 (Hypertext Transfer Protocol HTTP/1.1) section 3.2.1 saysThe HTTP protocol does not placeany a priori limit on the length ofa URI. Servers MUST be able to handlethe URI of any resource they    serve,and SHOULD be able to handle URIs ofunbounded length if they    provideGET-based forms that could generatesuch URIs. A server    SHOULD return414 (Request-URI Too Long) status if aURI is longer    than the server canhandle (see section 10.4.15).That RFC has been obsoleted by RFC7230 which is a refresh of the HTTP/1.1 specification. It contains similar language, but also goes on to suggest this:Various ad hoc limitations on request-line length are found inpractice. It is RECOMMENDED that all HTTP senders and recipientssupport, at a minimum, request-line lengths of 8000 octets....and the realityThat's what the standards say. For the reality, there was an article on boutell.com (link goes to Internet Archive backup) that discussed what individual browser and server implementations will support. The executive summary is:Extremely long URLs are usually amistake. URLs over 2,000 characterswill not work in the most popular webbrowsers. Don't use them if you intendyour site to work for the majority ofInternet users.(Note: this is a quote from an article written in 2006, but in 2015 IE's declining usage means that longer URLs do work for the majority. However, IE still has the limitation...)Internet Explorer's limitations...IE8's maximum URL length is 2083 chars, and it seems IE9 has a similar limit.I've tested IE10 and the address bar will only accept 2083 chars. You can click a URL which is longer than this, but the address bar will still only show 2083 characters of this link.There's a nice writeup on the IE Internals blog which goes into some of the background to this.There are mixed reports IE11 supports longer URLs - see comments below. Given some people report issues, the general advice still stands.Search engines like URLs < 2048 chars...Be aware that the sitemaps protocol, which allows a site to inform search engines about available pages, has a limit of 2048 characters in a URL. If you intend to use sitemaps, a limit has been decided for you! (see Calin-Andrei Burloiu's answer below)There's also some research from 2010 into the maximum URL length that search engines will crawl and index. They found the limit was 2047 chars, which appears allied to the sitemap protocol spec. However, they also found the Google SERP tool wouldn't cope with URLs longer than 1855 chars.CDNs have limitsCDNs also impose limits on URI length, and will return a 414 Too long request when these limits are reached, for example:Fastly 8KbCloudFront 8KbCloudFlare 16Kb(credit to timrs2998 for providing that info in the comments)Additional browser roundupI tested the following against an Apache 2.4 server configured with a very large LimitRequestLine and LimitRequestFieldSize.Browser     Address bar   document.location                          or anchor tag------------------------------------------Chrome          32779           >64kAndroid          8192           >64kFirefox          >64k           >64kSafari           >64k           >64kIE11             2047           5120Edge 16          2047          10240See also this answer from Matas Vaitkevicius below.Is this information up to date?This is a popular question, and as the original research is ~14 years old I'll try to keep it up to date: As of Jan 2021, the advice still stands. Even though IE11 may possibly accept longer URLs, the ubiquity of older IE installations plus the search engine limitations mean staying under 2000 chars is the best general policy."
"data_i","edited Mar 28 '22 at 11:34","
        For-each over an array in JavaScript
    ","How can I loop through all the entries in an array using JavaScript?","TL;DRYour best bets are usuallya for-of loop (ES2015+ only; spec | MDN) - simple and async-friendlyfor (const element of theArray) {    // ...use `element`...}forEach (ES5+ only; spec | MDN) (or its relatives some and such) - not async-friendly (but see details)theArray.forEach(element => {    // ...use `element`...});a simple old-fashioned for loop - async-friendlyfor (let index = 0; index < theArray.length; ++index) {    const element = theArray[index];    // ...use `element`...}(rarely) for-in with safeguards - async-friendlyfor (const propertyName in theArray) {    if (/*...is an array element property (see below)...*/) {        const element = theArray[propertyName];        // ...use `element`...    }}Some quick ""don't""s:Don't use for-in unless you use it with safeguards or are at least aware of why it might bite you.Don't use map if you're not using its return value.(There's sadly someone out there teaching map [spec / MDN] as though it were forEach — but as I write on my blog, that's not what it's for. If you aren't using the array it creates, don't use map.)Don't use forEach if the callback does asynchronous work and you want the forEach to wait until that work is done (because it won't).But there's lots more to explore, read on...JavaScript has powerful semantics for looping through arrays and array-like objects. I've split the answer into two parts: Options for genuine arrays, and options for things that are just array-like, such as the arguments object, other iterable objects (ES2015+), DOM collections, and so on.Okay, let's look at our options:For Actual ArraysYou have five options (two supported basically forever, another added by ECMAScript 5 [""ES5""], and two more added in ECMAScript 2015 (""ES2015"", aka ""ES6""):Use for-of (use an iterator implicitly) (ES2015+)Use forEach and related (ES5+)Use a simple for loopUse for-in correctlyUse an iterator explicitly (ES2015+)(You can see those old specs here: ES5, ES2015, but both have been superceded; the current editor's draft is always here.)Details:1. Use for-of (use an iterator implicitly) (ES2015+)ES2015 added iterators and iterables to JavaScript. Arrays are iterable (so are strings, Maps, and Sets, as well as DOM collections and lists, as you'll see later). Iterable objects provide iterators for their values. The new for-of statement loops through the values returned by an iterator:const a = [""a"", ""b"", ""c""];for (const element of a) { // You can use `let` instead of `const` if you like    console.log(element);}// a// b// cIt doesn't get simpler than that! Under the covers, that gets an iterator from the array and loops through the values the iterator returns. The iterator provided by arrays provides the values of the array elements, in order beginning to end.Notice how element is scoped to each loop iteration; trying to use element after the end of the loop would fail because it doesn't exist outside the loop body.In theory, a for-of loop involves several function calls (one to get the iterator, then one to get each value from it). Even when that's true, it's nothing to worry about, function calls are very cheap in modern JavaScript engines (it bothered me for forEach [below] until I looked into it; details). But additionally, JavaScript engines optimize those calls away (in performance-critical code) when dealing with native iterators for things like arrays.for-of is entirely async-friendly. If you need the work in a loop body to be done in series (not in parallel), an await in the loop body will wait for the promise to settle before continuing. Here's a silly example:function delay(ms) {    return new Promise(resolve => {        setTimeout(resolve, ms);    });}async function showSlowly(messages) {    for (const message of messages) {        await delay(400);        console.log(message);    }}showSlowly([    ""So"", ""long"", ""and"", ""thanks"", ""for"", ""all"", ""the"", ""fish!""]);// `.catch` omitted because we know it never rejectsNote how the words appear with a delay before each one.It's a matter of coding style, but for-of is the first thing I reach for when looping through anything iterable.2. Use forEach and relatedIn any even vaguely-modern environment (so, not IE8) where you have access to the Array features added by ES5, you can use forEach (spec | MDN) if you're only dealing with synchronous code (or you don't need to wait for an asynchronous process to finish during the loop):const a = [""a"", ""b"", ""c""];a.forEach((element) => {    console.log(element);});forEach accepts a callback function and, optionally, a value to use as this when calling that callback (not used above). The callback is called for each element in the array, in order, skipping non-existent elements in sparse arrays. Although I only used one parameter above, the callback is called with three arguments: The element for that iteration, the index of that element, and a reference to the array you're iterating over (in case your function doesn't already have it handy).Like for-of, forEach has the advantage that you don't have to declare indexing and value variables in the containing scope; in this case, they're supplied as arguments to the iteration function, and so nicely scoped to just that iteration.Unlike for-of, forEach has the disadvantage that it doesn't understand async functions and await. If you use an async function as the callback, forEach does not wait for that function's promise to settle before continuing. Here's the async example from for-of using forEach instead — notice how there's an initial delay, but then all the text appears right away instead of waiting:function delay(ms) {    return new Promise(resolve => {        setTimeout(resolve, ms);    });}async function showSlowly(messages) {    // INCORRECT, doesn't wait before continuing,    // doesn't handle promise rejections    messages.forEach(async message => {        await delay(400);        console.log(message);    });}showSlowly([    ""So"", ""long"", ""and"", ""thanks"", ""for"", ""all"", ""the"", ""fish!""]);// `.catch` omitted because we know it never rejectsforEach is the ""loop through them all"" function, but ES5 defined several other useful ""work your way through the array and do things"" functions, including:every (spec | MDN) - stops looping the first time the callback returns a falsy valuesome (spec | MDN) - stops looping the first time the callback returns a truthy valuefilter (spec | MDN) - creates a new array including elements where the callback returns a truthy value, omitting the ones where it doesn'tmap (spec | MDN) - creates a new array from the values returned by the callbackreduce (spec | MDN) - builds up a value by repeatedly calling the callback, passing in previous values; see the spec for the detailsreduceRight (spec | MDN) - like reduce, but works in descending rather than ascending orderAs with forEach, if you use an async function as your callback, none of those waits for the function's promise to settle. That means:Using an async function callback is never appropriate with every, some, and filter since they will treat the returned promise as though it were a truthy value; they don't wait for the promise to settle and then use the fulfillment value.Using an async function callback is often appropriate with map, if the goal is to turn an array of something into an array of promises, perhaps for passing to one of the promise combinator functions (Promise.all, Promise.race, promise.allSettled, or Promise.any).Using an async function callback is rarely appropriate with reduce or reduceRight, because (again) the callback will always return a promise. But there is an idiom of building a chain of promises from an array that uses reduce (const promise = array.reduce((p, element) => p.then(/*...something using `element`...*/));), but usually in those cases a for-of or for loop in an async function will be clearer and easier to debug.3. Use a simple for loopSometimes the old ways are the best:const a = [""a"", ""b"", ""c""];for (let index = 0; index < a.length; ++index) {    const element = a[index];    console.log(element);}If the length of the array won't change during the loop, and it's in highly performance-sensitive code, a slightly more complicated version grabbing the length up front might be a tiny bit faster:const a = [""a"", ""b"", ""c""];for (let index = 0, len = a.length; index < len; ++index) {    const element = a[index];    console.log(element);}And/or counting backward:const a = [""a"", ""b"", ""c""];for (let index = a.length - 1; index >= 0; --index) {    const element = a[index];    console.log(element);}But with modern JavaScript engines, it's rare you need to eke out that last bit of juice.Before ES2015, the loop variable had to exist in the containing scope, because var only has function-level scope, not block-level scope. But as you saw in the examples above, you can use let within the for to scope the variables to just the loop. And when you do that, the index variable is recreated for each loop iteration, meaning closures created in the loop body keep a reference to the index for that specific iteration, which solves the old ""closures in loops"" problem:// (The `NodeList` from `querySelectorAll` is array-like)const divs = document.querySelectorAll(""div"");for (let index = 0; index < divs.length; ++index) {    divs[index].addEventListener('click', e => {        console.log(""Index is: "" + index);    });}<div>zero</div><div>one</div><div>two</div><div>three</div><div>four</div>In the above, you get ""Index is: 0"" if you click the first and ""Index is: 4"" if you click the last. This does not work if you use var instead of let (you'd always see ""Index is: 5"").Like for-of, for loops work well in async functions. Here's the earlier example using a for loop:function delay(ms) {    return new Promise(resolve => {        setTimeout(resolve, ms);    });}async function showSlowly(messages) {    for (let i = 0; i < messages.length; ++i) {        const message = messages[i];        await delay(400);        console.log(message);    }}showSlowly([    ""So"", ""long"", ""and"", ""thanks"", ""for"", ""all"", ""the"", ""fish!""]);// `.catch` omitted because we know it never rejects4. Use for-in correctlyfor-in isn't for looping through arrays, it's for looping through the names of an object's properties. It does often seem to work for looping through arrays as a by-product of the fact that arrays are objects, but it doesn't just loop through the array indexes, it loops through all enumerable properties of the object (including inherited ones). (It also used to be that the order wasn't specified; it is now [details in this other answer], but even though the order is specified now, the rules are complex, there are exceptions, and relying on the order is not best practice.)The only real use cases for for-in on an array are:It's a sparse array with massive gaps in it, orYou're using non-element properties on the array object and you want to include them in the loopLooking only at that first example: You can use for-in to visit those sparse array elements if you use appropriate safeguards:// `a` is a sparse arrayconst a = [];a[0] = ""a"";a[10] = ""b"";a[10000] = ""c"";for (const name in a) {    if (Object.hasOwn(a, name) &&       // These checks are        /^0$|^[1-9]\d*$/.test(name) &&  // explained        name <= 4294967294              // below       ) {        const element = a[name];        console.log(a[name]);    }}Note the three checks:That the object has its own property by that name (not one it inherits from its prototype; this check is also often written as a.hasOwnProperty(name) but ES2022 adds Object.hasOwn which can be more reliable), andThat the name is all decimal digits (e.g., normal string form, not scientific notation), andThat the name's value when coerced to a number is <= 2^32 - 2 (which is 4,294,967,294). Where does that number come from? It's part of the definition of an array index in the specification. Other numbers (non-integers, negative numbers, numbers greater than 2^32 - 2) are not array indexes. The reason it's 2^32 - 2 is that that makes the greatest index value one lower than 2^32 - 1, which is the maximum value an array's length can have. (E.g., an array's length fits in a 32-bit unsigned integer.)...although with that said, most code only does the hasOwnProperty check.You wouldn't do that in inline code, of course. You'd write a utility function. Perhaps:// Utility function for antiquated environments without `forEach`const hasOwn = Object.prototype.hasOwnProperty.call.bind(Object.prototype.hasOwnProperty);const rexNum = /^0$|^[1-9]\d*$/;function sparseEach(array, callback, thisArg) {    for (const name in array) {        const index = +name;        if (hasOwn(a, name) &&            rexNum.test(name) &&            index <= 4294967294           ) {            callback.call(thisArg, array[name], index, array);        }    }}const a = [];a[5] = ""five"";a[10] = ""ten"";a[100000] = ""one hundred thousand"";a.b = ""bee"";sparseEach(a, (value, index) => {    console.log(""Value at "" + index + "" is "" + value);});Like for, for-in works well in asynchronous functions if the work within it needs to be done in series.function delay(ms) {    return new Promise(resolve => {        setTimeout(resolve, ms);    });}async function showSlowly(messages) {    for (const name in messages) {        if (messages.hasOwnProperty(name)) { // Almost always this is the only check people do            const message = messages[name];            await delay(400);            console.log(message);        }    }}showSlowly([    ""So"", ""long"", ""and"", ""thanks"", ""for"", ""all"", ""the"", ""fish!""]);// `.catch` omitted because we know it never rejects5. Use an iterator explicitly (ES2015+)for-of uses an iterator implicitly, doing all the scut work for you. Sometimes, you might want to use an iterator explicitly. It looks like this:const a = [""a"", ""b"", ""c""];const it = a.values(); // Or `const it = a[Symbol.iterator]();` if you likelet entry;while (!(entry = it.next()).done) {    const element = entry.value;    console.log(element);}An iterator is an object matching the Iterator definition in the specification. Its next method returns a new result object each time you call it. The result object has a property, done, telling us whether it's done, and a property value with the value for that iteration. (done is optional if it would be false, value is optional if it would be undefined.)What you get for value varies depending on the iterator. On arrays, the default iterator provides the value of each array element (""a"", ""b"", and ""c"" in the example earlier). Arrays also have three other methods that return iterators:values(): This is an alias for the [Symbol.iterator] method that returns the default iterator.keys(): Returns an iterator that provides each key (index) in the array. In the example above, it would provide ""0"", then ""1"", then ""2"" (yes, as strings).entries(): Returns an iterator that provides [key, value] arrays.Since iterator objects don't advance until you call next, they work well in async function loops. Here's the earlier for-of example using the iterator explicitly:function delay(ms) {    return new Promise(resolve => {        setTimeout(resolve, ms);    });}async function showSlowly(messages) {    const it = messages.values()    while (!(entry = it.next()).done) {        await delay(400);        const element = entry.value;        console.log(element);    }}showSlowly([    ""So"", ""long"", ""and"", ""thanks"", ""for"", ""all"", ""the"", ""fish!""]);// `.catch` omitted because we know it never rejectsFor Array-Like ObjectsAside from true arrays, there are also array-like objects that have a length property and properties with all-digits names: NodeList instances, HTMLCollection instances, the arguments object, etc. How do we loop through their contents?Use most of the options aboveAt least some, and possibly most or even all, of the array approaches above apply equally well to array-like objects:Use for-of (use an iterator implicitly) (ES2015+)for-of uses the iterator provided by the object (if any). That includes host-provided objects (like DOM collections and lists). For instance, HTMLCollection instances from getElementsByXYZ methods and NodeLists instances from querySelectorAll both support iteration. (This is defined quite subtly by the HTML and DOM specifications. Basically, any object with length and indexed access is automatically iterable. It doesn't have to be marked iterable; that is used only for collections that, in addition to being iterable, support forEach, values, keys, and entries methods. NodeList does; HTMLCollection doesn't, but both are iterable.)Here's an example of looping through div elements:const divs = document.querySelectorAll(""div"");for (const div of divs) {    div.textContent = Math.random();}<div>zero</div><div>one</div><div>two</div><div>three</div><div>four</div>Use forEach and related (ES5+)The various functions on Array.prototype are ""intentionally generic"" and can be used on array-like objects via Function#call (spec | MDN) or Function#apply (spec | MDN). (If you have to deal with IE8 or earlier [ouch], see the ""Caveat for host-provided objects"" at the end of this answer, but it's not an issue with vaguely-modern browsers.)Suppose you wanted to use forEach on a Node's childNodes collection (which, being an HTMLCollection, doesn't have forEach natively). You'd do this:Array.prototype.forEach.call(node.childNodes, (child) => {    // Do something with `child`});(Note, though, that you could just use for-of on node.childNodes.)If you're going to do that a lot, you might want to grab a copy of the function reference into a variable for reuse, e.g.:// (This is all presumably in a module or some scoping function)const forEach = Array.prototype.forEach.call.bind(Array.prototype.forEach);// Then later...forEach(node.childNodes, (child) => {    // Do something with `child`});Use a simple for loopPerhaps obviously, a simple for loop works for array-like objects.Use an iterator explicitly (ES2015+)See #1.You may be able to get away with for-in (with safeguards), but with all of these more appropriate options, there's no reason to try.Create a true arrayOther times, you may want to convert an array-like object into a true array. Doing that is surprisingly easy:Use Array.fromArray.from (spec) | (MDN) (ES2015+, but easily polyfilled) creates an array from an array-like object, optionally passing the entries through a mapping function first. So:const divs = Array.from(document.querySelectorAll(""div""));...takes the NodeList from querySelectorAll and makes an array from it.The mapping function is handy if you were going to map the contents in some way. For instance, if you wanted to get an array of the tag names of the elements with a given class:// Typical use (with an arrow function):const divs = Array.from(document.querySelectorAll("".some-class""), element => element.tagName);// Traditional function (since `Array.from` can be polyfilled):var divs = Array.from(document.querySelectorAll("".some-class""), function(element) {    return element.tagName;});Use spread syntax (...)It's also possible to use ES2015's spread syntax. Like for-of, this uses the iterator provided by the object (see #1 in the previous section):const trueArray = [...iterableObject];So for instance, if we want to convert a NodeList into a true array, with spread syntax this becomes quite succinct:const divs = [...document.querySelectorAll(""div"")];Use the slice method of arraysWe can use the slice method of arrays, which like the other methods mentioned above is ""intentionally generic"" and so can be used with array-like objects, like this:const trueArray = Array.prototype.slice.call(arrayLikeObject);So for instance, if we want to convert a NodeList into a true array, we could do this:const divs = Array.prototype.slice.call(document.querySelectorAll(""div""));(If you still have to handle IE8 [ouch], will fail; IE8 didn't let you use host-provided objects as this like that.)Caveat for host-provided objectsIf you use Array.prototype functions with host-provided array-like objects (for example, DOM collections and such provided by the browser rather than the JavaScript engine), obsolete browsers like IE8 didn't necessarily handle that way, so if you have to support them, be sure to test in your target environments. But it's not an issue with vaguely-modern browsers. (For non-browser environments, naturally it'll depend on the environment.)"
"data_i","edited Jul 28 '22 at 07:55","
        How can I validate an email address in JavaScript?
    ","I'd like to check if the user input is an email address in JavaScript, before sending it to a server or attempting to send an email to it, to prevent the most basic mistyping. How could I achieve this?","Using regular expressions is probably the best way. You can see a bunch of tests here (taken from chromium)const validateEmail = (email) => {  return String(email)    .toLowerCase()    .match(      /^(([^<>()[\]\\.,;:\s@""]+(\.[^<>()[\]\\.,;:\s@""]+)*)|("".+""))@((\[[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\])|(([a-zA-Z\-0-9]+\.)+[a-zA-Z]{2,}))$/    );};Here's the example of a regular expression that accepts unicode:const re =  /^(([^<>()[\]\.,;:\s@\""]+(\.[^<>()[\]\.,;:\s@\""]+)*)|(\"".+\""))@(([^<>()[\]\.,;:\s@\""]+\.)+[^<>()[\]\.,;:\s@\""]{2,})$/i;But keep in mind that one should not rely only upon JavaScript validation. JavaScript can easily be disabled. This should be validated on the server side as well.Here's an example of the above in action:const validateEmail = (email) => {  return email.match(    /^(([^<>()[\]\\.,;:\s@\""]+(\.[^<>()[\]\\.,;:\s@\""]+)*)|(\"".+\""))@((\[[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\])|(([a-zA-Z\-0-9]+\.)+[a-zA-Z]{2,}))$/  );};const validate = () => {  const $result = $('#result');  const email = $('#email').val();  $result.text('');  if (validateEmail(email)) {    $result.text(email + ' is valid :)');    $result.css('color', 'green');  } else {    $result.text(email + ' is not valid :(');    $result.css('color', 'red');  }  return false;}$('#email').on('input', validate);<script src=""https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js""></script><label for=""email"">Enter an email address: </label><input id=""email"" /><h2 id=""result""></h2>"
"data_i","edited Jul 08 '22 at 04:17","
        How do I reset or revert a file to a specific revision?
    ","How do I revert a modified file to its previous revision at a specific commit hash (which I determined via git log and git diff)?","Assuming the hash of the commit you want is c5f567:git checkout c5f567 -- file1/to/restore file2/to/restoreThe git checkout man page gives more information.If you want to revert to the commit before c5f567, append ~1 (where 1 is the number of commits you want to go back, it can be anything):git checkout c5f567~1 -- file1/to/restore file2/to/restoreAs a side note, I've always been uncomfortable with this command because it's used for both ordinary things (changing between branches) and unusual, destructive things (discarding changes in the working directory).There is also a new git restore command that is specifically designed for restoring working copy files that have been modified. If your git is new enough you can use this command, but the documentation comes with a warning:THIS COMMAND IS EXPERIMENTAL. THE BEHAVIOR MAY CHANGE."
"data_i","edited Sep 24 '22 at 11:35","
        How can I safely create a nested directory?
    ","How do I check if the directory into which a file is going to be written does exist, and if it does not, create the directory using Python?","On Python ≥ 3.5, use pathlib.Path.mkdir:from pathlib import PathPath(""/my/directory"").mkdir(parents=True, exist_ok=True)For older versions of Python, I see two answers with good qualities, each with a small flaw, so I will give my take on it:Try os.path.exists, and consider os.makedirs for the creation.import osif not os.path.exists(directory):    os.makedirs(directory)As noted in comments and elsewhere, there's a race condition – if the directory is created between the os.path.exists and the os.makedirs calls, the os.makedirs will fail with an OSError. Unfortunately, blanket-catching OSError and continuing is not foolproof, as it will ignore a failure to create the directory due to other factors, such as insufficient permissions, full disk, etc.One option would be to trap the OSError and examine the embedded error code (see Is there a cross-platform way of getting information from Python’s OSError):import os, errnotry:    os.makedirs(directory)except OSError as e:    if e.errno != errno.EEXIST:        raiseAlternatively, there could be a second os.path.exists, but suppose another created the directory after the first check, then removed it before the second one – we could still be fooled. Depending on the application, the danger of concurrent operations may be more or less than the danger posed by other factors such as file permissions. The developer would have to know more about the particular application being developed and its expected environment before choosing an implementation.Modern versions of Python improve this code quite a bit, both by exposing FileExistsError (in 3.3+)...try:    os.makedirs(""path/to/directory"")except FileExistsError:    # directory already exists    pass...and by allowing a keyword argument to os.makedirs called exist_ok (in 3.2+).os.makedirs(""path/to/directory"", exist_ok=True)  # succeeds even if directory exists."
"data_i","edited Jul 25 '22 at 02:03","
        How do I push a new local branch to a remote Git repository and track it too?
    ","How do I:Create a local branch from another branch (via git branch or git checkout -b).Push the local branchto the remote repository (i.e. publish), but make ittrackable so that git pull and git push will work.","In Git 1.7.0 and later, you can checkout a new branch:git checkout -b <branch>Edit files, add and commit. Then push with the -u (short for --set-upstream) option:git push -u origin <branch>Git will set up the tracking information during the push."
"data_i","edited Jul 22 '16 at 15:40","
        What is a plain English explanation of ""Big O"" notation?
    ","I'd prefer as little formal definition as possible and simple mathematics.","Quick note, my answer is almost certainly confusing Big Oh notation (which is an upper bound) with Big Theta notation ""Θ"" (which is a two-side bound). But in my experience, this is actually typical of discussions in non-academic settings. Apologies for any confusion caused.BigOh complexity can be visualized with this graph:The simplest definition I can give for Big Oh notation is this:Big Oh notation is a relative representation of the complexity of an algorithm.There are some important and deliberately chosen words in that sentence:relative: you can only compare apples to apples.  You can't compare an algorithm that does arithmetic multiplication to an algorithm that sorts a list of integers.  But a comparison of two algorithms to do arithmetic operations (one multiplication, one addition) will tell you something meaningful;representation: BigOh (in its simplest form) reduces the comparison between algorithms to a single variable.  That variable is chosen based on observations or assumptions.  For example, sorting algorithms are typically compared based on comparison operations (comparing two nodes to determine their relative ordering).  This assumes that comparison is expensive.  But what if the comparison is cheap but swapping is expensive?  It changes the comparison; andcomplexity: if it takes me one second to sort 10,000 elements, how long will it take me to sort one million?  Complexity in this instance is a relative measure to something else.Come back and reread the above when you've read the rest.The best example of BigOh I can think of is doing arithmetic.  Take two numbers (123456 and 789012).  The basic arithmetic operations we learned in school were:addition;subtraction;multiplication; anddivision.Each of these is an operation or a problem.  A method of solving these is called an algorithm.The addition is the simplest.  You line the numbers up (to the right) and add the digits in a column writing the last number of that addition in the result.  The 'tens' part of that number is carried over to the next column.Let's assume that the addition of these numbers is the most expensive operation in this algorithm. It stands to reason that to add these two numbers together we have to add together 6 digits (and possibly carry a 7th). If we add two 100 digit numbers together we have to do 100 additions.  If we add two 10,000 digit numbers we have to do 10,000 additions.See the pattern?  The complexity (being the number of operations) is directly proportional to the number of digits n in the larger number.  We call this O(n) or linear complexity.Subtraction is similar (except you may need to borrow instead of carry).Multiplication is different. You line the numbers up, take the first digit in the bottom number and multiply it in turn against each digit in the top number and so on through each digit. So to multiply our two 6 digit numbers we must do 36 multiplications. We may need to do as many as 10 or 11 column adds to get the end result too.If we have two 100-digit numbers we need to do 10,000 multiplications and 200 adds.  For two one million digit numbers we need to do one trillion (1012) multiplications and two million adds.As the algorithm scales with n-squared, this is O(n2) or quadratic complexity. This is a good time to introduce another important concept:We only care about the most significant portion of complexity.The astute may have realized that we could express the number of operations as: n2 + 2n.  But as you saw from our example with two numbers of a million digits apiece, the second term (2n) becomes insignificant (accounting for 0.0002% of the total operations by that stage).One can notice that we've assumed the worst case scenario here. While multiplying 6 digit numbers, if one of them has 4 digits and the other one has 6 digits, then we only have 24 multiplications. Still, we calculate the worst case scenario for that 'n', i.e when both are 6 digit numbers. Hence Big Oh notation is about the Worst-case scenario of an algorithm.The Telephone BookThe next best example I can think of is the telephone book, normally called the White Pages or similar but it varies from country to country.  But I'm talking about the one that lists people by surname and then initials or first name, possibly address and then telephone numbers.Now if you were instructing a computer to look up the phone number for ""John Smith"" in a telephone book that contains 1,000,000 names, what would you do?  Ignoring the fact that you could guess how far in the S's started (let's assume you can't), what would you do?A typical implementation might be to open up to the middle, take the 500,000th and compare it to ""Smith"". If it happens to be ""Smith, John"", we just got really lucky.  Far more likely is that ""John Smith"" will be before or after that name.  If it's after we then divide the last half of the phone book in half and repeat.  If it's before then we divide the first half of the phone book in half and repeat.  And so on.This is called a binary search and is used every day in programming whether you realize it or not.So if you want to find a name in a phone book of a million names you can actually find any name by doing this at most 20 times.  In comparing search algorithms we decide that this comparison is our 'n'.For a phone book of 3 names it takes 2 comparisons (at most).For 7 it takes at most 3.For 15 it takes 4.…For 1,000,000 it takes 20.That is staggeringly good, isn't it?In BigOh terms this is O(log n) or logarithmic complexity.  Now the logarithm in question could be ln (base e), log10, log2 or some other base.  It doesn't matter it's still O(log n) just like O(2n2) and O(100n2) are still both O(n2).It's worthwhile at this point to explain that BigOh can be used to determine three cases with an algorithm:Best Case: In the telephone book search, the best case is that we find the name in one comparison.  This is O(1) or constant complexity;Expected Case: As discussed above this is O(log n); andWorst Case: This is also O(log n).Normally we don't care about the best case.  We're interested in the expected and worst case.  Sometimes one or the other of these will be more important.Back to the telephone book.What if you have a phone number and want to find a name?  The police have a reverse phone book but such look-ups are denied to the general public.  Or are they?  Technically you can reverse look-up a number in an ordinary phone book.  How?You start at the first name and compare the number.  If it's a match, great, if not, you move on to the next.  You have to do it this way because the phone book is unordered (by phone number anyway).So to find a name given the phone number (reverse lookup):Best Case: O(1);Expected Case: O(n) (for 500,000); andWorst Case: O(n) (for 1,000,000).The Traveling SalesmanThis is quite a famous problem in computer science and deserves a mention.  In this problem, you have N towns. Each of those towns is linked to 1 or more other towns by a road of a certain distance. The Traveling Salesman problem is to find the shortest tour that visits every town.Sounds simple?  Think again.If you have 3 towns A, B, and C with roads between all pairs then you could go:A → B → CA → C → BB → C → AB → A → CC → A → BC → B → AWell, actually there's less than that because some of these are equivalent (A → B → C and C → B → A are equivalent, for example, because they use the same roads, just in reverse).In actuality, there are 3 possibilities.Take this to 4 towns and you have (iirc) 12 possibilities.With 5 it's 60.6 becomes 360.This is a function of a mathematical operation called a factorial.  Basically:5! = 5 × 4 × 3 × 2 × 1 = 1206! = 6 × 5 × 4 × 3 × 2 × 1 = 7207! = 7 × 6 × 5 × 4 × 3 × 2 × 1 = 5040…25! = 25 × 24 × … × 2 × 1 = 15,511,210,043,330,985,984,000,000…50! = 50 × 49 × … × 2 × 1 = 3.04140932 × 1064So the BigOh of the Traveling Salesman problem is O(n!) or factorial or combinatorial complexity.By the time you get to 200 towns there isn't enough time left in the universe to solve the problem with traditional computers.Something to think about.Polynomial TimeAnother point I wanted to make a quick mention of is that any algorithm that has a complexity of O(na) is said to have polynomial complexity or is solvable in polynomial time.O(n), O(n2) etc. are all polynomial time. Some problems cannot be solved in polynomial time. Certain things are used in the world because of this. Public Key Cryptography is a prime example. It is computationally hard to find two prime factors of a very large number. If it wasn't, we couldn't use the public key systems we use.Anyway, that's it for my (hopefully plain English) explanation of BigOh (revised)."
"data_i","edited Jul 24 '22 at 23:55","
        How do I replace all occurrences of a string in JavaScript?
    ","Given a string:s = ""Test abc test test abc test test test abc test test abc"";This seems to only remove the first occurrence of abc in the string above:s = s.replace('abc', '');How do I replace all occurrences of it?","As of August 2020: Modern browsers have support for the String.replaceAll() method defined by the ECMAScript 2021 language specification.For older/legacy browsers:function escapeRegExp(string) {  return string.replace(/[.*+?^${}()|[\]\\]/g, '\\$&'); // $& means the whole matched string}function replaceAll(str, find, replace) {  return str.replace(new RegExp(escapeRegExp(find), 'g'), replace);}Here is how this answer evolved:str = str.replace(/abc/g, '');In response to comment ""what's if 'abc' is passed as a variable?"":var find = 'abc';var re = new RegExp(find, 'g');str = str.replace(re, '');In response to Click Upvote's comment, you could simplify it even more:function replaceAll(str, find, replace) {  return str.replace(new RegExp(find, 'g'), replace);}Note: Regular expressions contain special (meta) characters, and as such it is dangerous to blindly pass an argument in the find function above without pre-processing it to escape those characters.  This is covered in the Mozilla Developer Network's JavaScript Guide on Regular Expressions, where they present the following utility function (which has changed at least twice since this answer was originally written, so make sure to check the MDN site for potential updates):function escapeRegExp(string) {  return string.replace(/[.*+?^${}()|[\]\\]/g, '\\$&'); // $& means the whole matched string}So in order to make the replaceAll() function above safer, it could be modified to the following if you also include escapeRegExp:function replaceAll(str, find, replace) {  return str.replace(new RegExp(escapeRegExp(find), 'g'), replace);}"
"data_i","edited Jul 08 '22 at 04:24","
        How do I resolve merge conflicts in a Git repository?
    ","How do I resolve merge conflicts in my Git repository?","Try:git mergetoolIt opens a GUI that steps you through each conflict, and you get to choose how to merge.  Sometimes it requires a bit of hand editing afterwards, but usually it's enough by itself.  It is much better than doing the whole thing by hand certainly.As per Josh Glover's comment:[This command]doesn't necessarily open a GUI unless you install one. Running git mergetool for me resulted in vimdiff being used. You can installone of the following tools to use it instead: meld, opendiff,kdiff3, tkdiff, xxdiff, tortoisemerge, gvimdiff, diffuse,ecmerge, p4merge, araxis, vimdiff, emerge.Below is a sample procedure using vimdiff to resolve merge conflicts, based on this link.Run the following commands in your terminalgit config merge.tool vimdiffgit config merge.conflictstyle diff3git config mergetool.prompt falseThis will set vimdiff as the default merge tool.Run the following command in your terminalgit mergetoolYou will see a vimdiff display in the following format:  ╔═══════╦══════╦════════╗  ║       ║      ║        ║  ║ LOCAL ║ BASE ║ REMOTE ║  ║       ║      ║        ║  ╠═══════╩══════╩════════╣  ║                       ║  ║        MERGED         ║  ║                       ║  ╚═══════════════════════╝These 4 views areLOCAL: this is the file from the current branchBASE: the common ancestor, how this file looked before both changesREMOTE: the file you are merging into your branchMERGED: the merge result; this is what gets saved in the merge commit and used in the futureYou can navigate among these views using ctrl+w. You can directly reach the MERGED view using ctrl+w followed by j.More information about vimdiff navigation is here and here.You can edit the MERGED view like this:If you want to get changes from REMOTE:diffg REIf you want to get changes from BASE:diffg BAIf you want to get changes from LOCAL:diffg LOSave, Exit, Commit, and Clean up:wqa save and exit from vigit commit -m ""message""git clean Remove extra files (e.g. *.orig) created by the diff tool."
"data_i","edited Mar 22 '17 at 16:17","
        What is the most efficient way to deep clone an object in JavaScript?
    ","What is the most efficient way to clone a JavaScript object? I've seen obj = eval(uneval(o)); being used, but that's non-standard and only supported by Firefox. I've done things like obj = JSON.parse(JSON.stringify(o)); but question the efficiency.  I've also seen recursive copying functions with various flaws.I'm surprised no canonical solution exists.","Native deep cloningThere's now a JS standard called ""structured cloning"", that works experimentally in Node 11 and later, will land in browsers, and which has polyfills for existing systems.structuredClone(value)If needed, loading the polyfill first:import structuredClone from '@ungap/structured-clone';See this answer for more details.Older answersFast cloning with data loss - JSON.parse/stringifyIf you do not use Dates, functions, undefined, Infinity, RegExps, Maps, Sets, Blobs, FileLists, ImageDatas, sparse Arrays, Typed Arrays or other complex types within your object, a very simple one liner to deep clone an object is:JSON.parse(JSON.stringify(object))const a = {  string: 'string',  number: 123,  bool: false,  nul: null,  date: new Date(),  // stringified  undef: undefined,  // lost  inf: Infinity,  // forced to 'null'  re: /.*/,  // lost}console.log(a);console.log(typeof a.date);  // Date objectconst clone = JSON.parse(JSON.stringify(a));console.log(clone);console.log(typeof clone.date);  // result of .toISOString()See Corban's answer for benchmarks.Reliable cloning using a librarySince cloning objects is not trivial (complex types, circular references, function etc.), most major libraries provide function to clone objects. Don't reinvent the wheel - if you're already using a library, check if it has an object cloning function. For example,lodash - cloneDeep; can be imported separately via the lodash.clonedeep module and is probably your best choice if you're not already using a library that provides a deep cloning functionAngularJS - angular.copyjQuery - jQuery.extend(true, { }, oldObject); .clone() only clones DOM elementsjust library - just-clone; Part of a library of zero-dependency npm modules that do just do one thing.Guilt-free utilities for every occasion."
"data_i","edited Aug 02 '22 at 22:05","
        Reset local repository branch to be just like remote repository HEAD
    ","How do I reset my local branch to be just like the branch on the remote repository?I tried:git reset --hard HEADBut git status claims I have modified files:On branch masterChanges to be committed:  (use ""git reset HEAD <file>..."" to unstage)      modified:   java/com/mycompany/TestContacts.java      modified:   java/com/mycompany/TestParser.java","Setting your branch to exactly match the remote branch can be done in two steps:git fetch origingit reset --hard origin/masterIf you want to save your current branch's state before doing this (just in case), you can do:git commit -a -m ""Saving my work, just in case""git branch my-saved-workNow your work is saved on the branch ""my-saved-work"" in case you decide you want it back (or want to look at it later or diff it against your updated branch).Note that the first example assumes that the remote repo's name is ""origin"" and that the branch named ""master"" in the remote repo matches the currently checked-out branch in your local repo.BTW, this situation that you're in looks an awful lot like a common case where a push has been done into the currently checked out branch of a non-bare repository. Did you recently push into your local repo? If not, then no worries -- something else must have caused these files to unexpectedly end up modified. Otherwise, you should be aware that it's not recommended to push into a non-bare repository (and not into the currently checked-out branch, in particular)."
"data_i","edited Aug 28 '22 at 04:26","
        What is the difference between ""INNER JOIN"" and ""OUTER JOIN""?
    ","Also, how do LEFT OUTER JOIN, RIGHT OUTER JOIN, and FULL OUTER JOIN fit in?","Assuming you're joining on columns with no duplicates, which is a very common case:An inner join of A and B gives the result of A intersect B, i.e. the inner part of a Venn diagram intersection.An outer join of A and B gives the results of A union B, i.e. the outer parts of a Venn diagram union.ExamplesSuppose you have two tables, with a single column each, and data as follows:A    B-    -1    32    43    54    6Note that (1,2) are unique to A, (3,4) are common, and (5,6) are unique to B.Inner joinAn inner join using either of the equivalent queries gives the intersection of the two tables, i.e. the two rows they have in common.select * from a INNER JOIN b on a.a = b.b;select a.*, b.*  from a,b where a.a = b.b;a | b--+--3 | 34 | 4Left outer joinA left outer join will give all rows in A, plus any common rows in B.select * from a LEFT OUTER JOIN b on a.a = b.b;select a.*, b.*  from a,b where a.a = b.b(+);a |  b--+-----1 | null2 | null3 |    34 |    4Right outer joinA right outer join will give all rows in B, plus any common rows in A.select * from a RIGHT OUTER JOIN b on a.a = b.b;select a.*, b.*  from a,b where a.a(+) = b.b;a    |  b-----+----3    |  34    |  4null |  5null |  6Full outer joinA full outer join will give you the union of A and B, i.e. all the rows in A and all the rows in B. If something in A doesn't have a corresponding datum in B, then the B portion is null, and vice versa.select * from a FULL OUTER JOIN b on a.a = b.b; a   |  b-----+-----   1 | null   2 | null   3 |    3   4 |    4null |    6null |    5"
"data_i","edited Sep 20 '22 at 20:26","
        How to determine the URL that a local Git repository was originally cloned from
    ","I pulled a project with several forks on GitHub, but forgot which fork it was. How do I determine which fork I pulled?","To obtain only the remote URL:git config --get remote.origin.urlIf you require full output, and you are on a network that can reach the remote repo where the origin resides:git remote show originWhen using git clone (from GitHub, or any source repository for that matter) the default name for the source of the clone is ""origin"". Using git remote show will display the information about this remote name. The first few lines should show:C:\Users\jaredpar\VsVim> git remote show origin* remote origin  Fetch URL: git@github.com:jaredpar/VsVim.git  Push  URL: git@github.com:jaredpar/VsVim.git  HEAD branch: master  Remote branches:If you want to use the value in the script, you would use the first command listed in this answer."
"data_i","edited Feb 20 '21 at 00:03","
        How do I check whether a checkbox is checked in jQuery?
    ","I need to check the checked property of a checkbox and perform an action based on the checked property using jQuery.For example, if the age checkbox is checked, then I need to show a textbox to enter age, else hide the textbox.But the following code returns false by default:if ($('#isAgeSelected').attr('checked')) {  $(""#txtAge"").show();} else {  $(""#txtAge"").hide();}<script src=""https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js""></script><input type=""checkbox"" id=""isAgeSelected""/><div id=""txtAge"" style=""display:none"">  Age is selected</div>How do I successfully query the checked property?","How do I successfully query the checked property?The checked property of a checkbox DOM element will give you the checked state of the element.Given your existing code, you could therefore do this:if(document.getElementById('isAgeSelected').checked) {    $(""#txtAge"").show();} else {    $(""#txtAge"").hide();}However, there's a much prettier way to do this, using toggle:$('#isAgeSelected').click(function() {    $(""#txtAge"").toggle(this.checked);});<script src=""https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js""></script><input type=""checkbox"" id=""isAgeSelected""/><div id=""txtAge"" style=""display:none"">Age is something</div>"
"data_i","edited Jul 18 '22 at 18:41","
        How do I add an empty directory to a Git repository?
    ","How do I add an empty directory (that contains no files) to a Git repository?","Another way to make a directory stay (almost) empty (in the repository) is to create a .gitignore file inside that directory that contains these four lines:# Ignore everything in this directory*# Except this file!.gitignoreThen you don't have to get the order right the way that you have to do in m104's solution.This also gives the benefit that files in that directory won't show up as ""untracked"" when you do a git status.Making @GreenAsJade's comment persistent:I think it's worth noting that this solution does precisely what the question asked for, but is not perhaps what many people looking at this question will have been looking for. This solution guarantees that the directory remains empty. It says ""I truly never want files checked in here"". As opposed to ""I don't have any files to check in here, yet, but I need the directory here, files may be coming later""."
"data_i","edited Jul 24 '22 at 23:56","
        Regular expression to match a line that doesn't contain a word
    ","I know it's possible to match a word and then reverse the matches using other tools (e.g. grep -v). However, is it possible to match lines that do not contain a specific word, e.g. hede, using a regular expression?Input:hohohihihahahedeCode:grep ""<Regex for 'doesn't contain hede'>"" inputDesired output:hohohihihaha","The notion that regex doesn't support inverse matching is not entirely true. You can mimic this behavior by using negative look-arounds:^((?!hede).)*$Non-capturing variant:^(?:(?!:hede).)*$The regex above will match any string, or line without a line break, not containing the (sub)string 'hede'. As mentioned, this is not something regex is ""good"" at (or should do), but still, it is possible.And if you need to match line break chars as well, use the DOT-ALL modifier (the trailing s in the following pattern):/^((?!hede).)*$/sor use it inline:/(?s)^((?!hede).)*$/(where the /.../ are the regex delimiters, i.e., not part of the pattern)If the DOT-ALL modifier is not available, you can mimic the same behavior with the character class [\s\S]:/^((?!hede)[\s\S])*$/ExplanationA string is just a list of n characters. Before, and after each character, there's an empty string. So a list of n characters will have n+1 empty strings. Consider the string ""ABhedeCD"":    ┌──┬───┬──┬───┬──┬───┬──┬───┬──┬───┬──┬───┬──┬───┬──┬───┬──┐S = │e1│ A │e2│ B │e3│ h │e4│ e │e5│ d │e6│ e │e7│ C │e8│ D │e9│    └──┴───┴──┴───┴──┴───┴──┴───┴──┴───┴──┴───┴──┴───┴──┴───┴──┘    index    0      1      2      3      4      5      6      7where the e's are the empty strings. The regex (?!hede). looks ahead to see if there's no substring ""hede"" to be seen, and if that is the case (so something else is seen), then the . (dot) will match any character except a line break. Look-arounds are also called zero-width-assertions because they don't consume any characters. They only assert/validate something.So, in my example, every empty string is first validated to see if there's no ""hede"" up ahead, before a character is consumed by the . (dot). The regex (?!hede). will do that only once, so it is wrapped in a group, and repeated zero or more times: ((?!hede).)*. Finally, the start- and end-of-input are anchored to make sure the entire input is consumed: ^((?!hede).)*$As you can see, the input ""ABhedeCD"" will fail because on e3, the regex (?!hede) fails (there is ""hede"" up ahead!)."
"data_i","edited Jul 24 '22 at 23:56","
        How do I create a GUID / UUID?
    ","How do I create GUIDs (globally-unique identifiers) in JavaScript? The GUID / UUID should be at least 32 characters and should stay in the ASCII range to avoid trouble when passing them around.I'm not sure what routines are available on all browsers, how ""random"" and seeded the built-in random number generator is, etc.","[Edited 2021-10-16 to reflect latest best-practices for producing RFC4122-compliant UUIDs]Most readers here will want to use the uuid module.  It is well-tested and supported.The crypto.randomUUID() function is an emerging standard that is supported in Node.js and an increasing number of browsers.If neither of those work for you, there is this method (based on the original answer to this question):function uuidv4() {  return ([1e7]+-1e3+-4e3+-8e3+-1e11).replace(/[018]/g, c =>    (c ^ crypto.getRandomValues(new Uint8Array(1))[0] & 15 >> c / 4).toString(16)  );}console.log(uuidv4());Note: The use of any UUID generator that relies on Math.random() is strongly discouraged (including snippets featured in previous versions of this answer) for reasons best-explained here. TL;DR: Math.random()-based solutions do not provide good uniqueness guarantees."
"data_i","edited Jul 06 '22 at 14:21","
        Reference — What does this symbol mean in PHP?
    ","What is this?This is a collection of questions that come up every now and then about syntax in PHP. This is also a Community Wiki, so everyone is invited to participate in maintaining this list.Why is this?It used to be hard to find questions about operators and other syntax tokens.¹The main idea is to have links to existing questions on Stack Overflow, so it's easier for us to reference them, not to copy over content from the PHP Manual.Note: Since January 2013, Stack Overflow does support special characters. Just surround the search terms by quotes, e.g. [php] ""=="" vs ""===""What should I do here?If you have been pointed here by someone because you have asked such a question, please find the particular syntax below. The linked pages to the PHP manual along with the linked questions will likely answer your question then. If so, you are encouraged to upvote the answer. This list is not meant as a substitute for the help others provided.The ListIf your particular token is not listed below, you might find it in the List of Parser Tokens.& Bitwise Operators or ReferencesWhat does it mean to start a PHP function with an ampersand?Understanding PHP & (ampersand, bitwise and) operatorPHP ""&"" operatorDifference between & and && in PHPWhat does ""&"" mean here in PHP?What does ""&"" mean in this case?What does the ""&"" sign mean in PHP?What does this signature mean (&) in PHP?How does the ""&"" operator work in a PHP function?What does & in &2 mean in PHP?When should I use a bitwise operator?Is there ever a need to use ampersand in front of an object? (&$)=& ReferencesReference assignment operator in PHP, =&What do the ""=&"" and ""&="" operators in PHP mean?What do the '&=' and '=&' operators do?What does =& mean in PHP?&= Bitwise OperatorsWhat do the ""=&"" and ""&="" operators in PHP mean?What do the '&=' and '=&' operators do?&& Logical Operators'AND' vs '&&' as operatorDifference between & and && in PHPIs there any difference between ""and"" and ""&&"" operators in PHP?PHP - and / or keywords% Arithmetic OperatorsWhat does the percent sign mean in PHP?What is the PHP operator % and how do I use it in real-world examples?!! Logical OperatorsDouble not (!!) operator in PHP@ Error Control OperatorsWhat is the use of the @ symbol in PHP?'At' symbol before variable name in PHP: @$_POSTPHP functions and @functionsShould I use @ in my PHP code?What does @ mean in PHP??: Ternary OperatorWhat are the PHP operators ""?"" and "":"" called and what do they do??: operator (the 'Elvis operator') in PHPWhere can I read about conditionals done with ""?"" and "":"" (colon)?Using PHP 5.3 ?: operator?? Null Coalesce Operator (since PHP 7)C#'s null coalescing operator (??) in PHP?string?int?array?bool?float Nullable return type declaration (since PHP 7.1)Nullable return type declarationNullable parameter type declarationphp method argument type hinting with question mark (?type): Alternative syntax for control structures, Ternary Operator, Return Type DeclarationWhat is "":"" in PHP?What does "":"" mean in PHP?Colon after method declaration?:: Scope Resolution OperatorWhat do two colons mean in PHP?What's the meaning of the PHP token name T_PAAMAYIM_NEKUDOTAYIM?What's the difference between :: (double colon) and -> (arrow) in PHP?What exactly are late static bindings in PHP?static::staticFunctionName()Unexpected T_PAAMAYIM_NEKUDOTAYIM, expecting T_NS_Separator\ NamespacesBackslash in PHP -- what does it mean?What does a \ (backslash) do in PHP (5.3+)?-> Classes And ObjectsWhat is the ""->"" PHP operator called?Where do we use the object operator ""->"" in PHP?What's the difference between :: (double colon) and -> (arrow) in PHP?What does the PHP syntax $var1->$var2 mean?What does ""->"" mean/refer to in PHP?=> ArraysWhat does ""=>"" mean in PHP?Use of => in PHPWhat does $k => $v in foreach($ex as $k=>$v) mean?^ Bitwise OperatorsHow does the bitwise operator XOR ('^') work?What does ^ mean in PHP?>> Bitwise OperatorsWhat does >> mean in PHP?<< Bitwise OperatorsStrange print behaviour in PHP?<<< Heredoc or NowdocWhat does <<<END mean in PHP?PHP expression <<<EOBIn PHP, what does ""<<<"" represent?Using <<<CON in PHPWhat's this kind of syntax in PHP?= Assignment OperatorsThe 3 different equals== Comparison OperatorsHow do the PHP equality (== double equals) and identity (=== triple equals) comparison operators differ?PHP != and == operatorsThe 3 different equalsType-juggling and (strict) greater/lesser-than comparisons in PHP=== Comparison OperatorsWhat does ""==="" mean?How do the PHP equality (== double equals) and identity (=== triple equals) comparison operators differ?The 3 different equalsType-juggling and (strict) greater/lesser-than comparisons in PHP!== Comparison OperatorsWhat does !== comparison operator in PHP mean?Is there a difference between !== and != in PHP?!= Comparison OperatorsPHP != and == operatorsIs there a difference between !== and != in PHP?comparing, !== versus !=What is the difference between <> and !=<> Comparison OperatorsPHP operator <>PHP's <> operatorWhat is the difference between <> and !=Type-juggling and (strict) greater/lesser-than comparisons in PHP<=> Comparison Operators (since PHP 7.0)Spaceship (three way comparison) operator| Bitwise OperatorsWhat is the difference between the | and || operators?What Does Using A Single Pipe '|' In A Function Argument Do?|| Logical OperatorsWhat is the difference between the | and || operators?PHP - and / or keywordsWhat exactly does || mean?The behaviour of the or operator in PHP~ Bitwise OperatorsWhat does this ~ operator mean here?+ Arithmetic Operators, Array Operators+ operator for array in PHP?+= and -= Assignment OperatorsWhat is += used for?What does `$page -= 1` in my PHP document mean?++ and -- Incrementing/Decrementing OperatorsUnderstanding IncrementingAnswer below.= Assignment OperatorsWhat is the difference between .= and += in PHP?To understand a line of PHP. String OperatorsDifference between period and comma when concatenating with echo versus return?What does a . (dot) do in PHP?, Function ArgumentsDifference between period and comma when concatenating with echo versus return?, Variable DeclarationsWhat do commas mean in a variable declaration?$$ Variable VariablesWhat does $$ (dollar dollar or double dollar) mean in PHP?what is ""$$"" in PHP$function() and $$variable` Execution OperatorWhat are the backticks `` called?<?= Short Open TagsWhat does this symbol mean in PHP <?=What does '<?=' mean in PHP?What does <?= mean?[] Arrays (short syntax since PHP 5.4)PHP arrays... What is/are the meaning(s) of an empty bracket?What is the meaning of []Php array_push() vs myArray[]What does [] mean when reading from a PHP array?Shorthand for arrays: literal $var = [] empty array<? Opening and Closing tagsAre PHP short tags acceptable to use?.. Double-dot character rangeNative PHP functions that allow double-dot range syntax... Argument unpacking (since PHP 5.6)** Exponentiation (since PHP 5.6)# One-line shell-style commentCan I use hashes for comments in PHP??-> NullSafe Operator Calls (since PHP 8.0)Is there a ""nullsafe operator"" in PHP?","Incrementing / Decrementing Operators++ increment operator-- decrement operatorExample    Name              Effect---------------------------------------------------------------------++$a       Pre-increment     Increments $a by one, then returns $a.$a++       Post-increment    Returns $a, then increments $a by one.--$a       Pre-decrement     Decrements $a by one, then returns $a.$a--       Post-decrement    Returns $a, then decrements $a by one.These can go before or after the variable.If put before the variable, the increment/decrement operation is done to the variable first then the result is returned. If put after the variable, the variable is first returned, then the increment/decrement operation is done.For example:$apples = 10;for ($i = 0; $i < 10; ++$i) {    echo 'I have ' . $apples-- . "" apples. I just ate one.\n"";}Live exampleIn the case above ++$i is used, since it is faster. $i++ would have the same results.Pre-increment is a little bit faster because it really increments the variable and after that 'returns' the result. Post-increment creates a special variable, copies there the value of the first variable and only after the first variable is used, replaces its value with second's.However, you must use $apples--, since first, you want to display the current number of apples, and then you want to subtract one from it.You can also increment letters in PHP:$i = ""a"";while ($i < ""c"") {    echo $i++;}Once z is reached aa is next, and so on.Note that character variables can be incremented but not decremented and even so only plain ASCII characters (a-z and A-Z) are supported.Stack Overflow Posts:Understanding Incrementing "
"data_i","edited Aug 10 '22 at 00:26","
        How can I horizontally center an element?
    ","How can I horizontally center a <div> within another <div> using CSS?<div id=""outer"">  <div id=""inner"">Foo foo</div></div>","You can apply this CSS to the inner <div>:#inner {  width: 50%;  margin: 0 auto;}Of course, you don't have to set the width to 50%. Any width less than the containing <div> will work. The margin: 0 auto is what does the actual centering.If you are targeting Internet Explorer 8 (and later), it might be better to have this instead:#inner {  display: table;  margin: 0 auto;}It will make the inner element center horizontally and it works without setting a specific width.Working example here:#inner {  display: table;  margin: 0 auto;  border: 1px solid black;}#outer {  border: 1px solid red;  width:100%}<div id=""outer"">  <div id=""inner"">Foo foo</div></div>EDITWith flexbox it is very easy to style the div horizontally and vertically centered.#inner {    border: 0.05em solid black;}#outer {  border: 0.05em solid red;  width:100%;  display: flex;  justify-content: center;}<div id=""outer"">  <div id=""inner"">Foo foo</div></div>To align the div vertically centered, use the property align-items: center."
"data_i","edited Jun 04 '22 at 11:47","
        How do I exit Vim?
    ","I am stuck and cannot escape. It says:type :quit<Enter> to quit VIMBut when I type that it simply appears in the object body.","Hit the Esc key to enter ""Normal mode"". Then you can type : to enter ""Command-line mode"". A colon (:) will appear at the bottom of the screen and you can type in one of the following commands. To execute a command, press the Enter key.:q  to quit (short for :quit):q! to quit without saving (short for :quit!):wq to write and quit:wq! to write and quit even if file has only read permission (if file does not have write permission: force write):x  to write and quit (similar to :wq, but only write if there are changes):exit to write and exit (same as :x):qa to quit all (short for :quitall):cq to quit without saving and make Vim return non-zero error (i.e. exit with error)You can also exit Vim directly from ""Normal mode"" by typing ZZ to save and quit (same as :x) or ZQ to just quit (same as :q!). (Note that case is important here. ZZ and zz do not mean the same thing.)Vim has extensive help - that you can access with the :help command - where you can find answers to all your questions and a tutorial for beginners."
"data_i","edited Aug 08 '22 at 00:51","
        Accessing the index in 'for' loops
    ","How do I access the index while iterating over a sequence with a for loop?xs = [8, 23, 45]for x in xs:    print(""item #{} = {}"".format(index, x))Desired output:item #1 = 8item #2 = 23item #3 = 45","Use the built-in function enumerate():for idx, x in enumerate(xs):    print(idx, x)It is non-pythonic to manually index via for i in range(len(xs)): x = xs[i] or manually manage an additional state variable.Check out PEP 279 for more."
"data_i","edited Sep 10 '22 at 09:22","
        How do I make a flat list out of a list of lists?
    ","I have a list of lists like [[1, 2, 3], [4, 5, 6], [7], [8, 9]]. How can I flatten it to get [1, 2, 3, 4, 5, 6, 7, 8, 9]?If your list of lists comes from a nested list comprehension, the problem can be solved more simply/directly by fixing the comprehension; please see python list comprehensions; compressing a list of lists?.The most popular solutions here generally only flatten one ""level"" of the nested list. See Flatten an irregular (arbitrarily nested) list of lists for solutions that completely flatten a deeply nested structure (recursively, in general).","Given a list of lists l,flat_list = [item for sublist in l for item in sublist]which means:flat_list = []for sublist in l:    for item in sublist:        flat_list.append(item)is faster than the shortcuts posted so far. (l is the list to flatten.)Here is the corresponding function:def flatten(l):    return [item for sublist in l for item in sublist]As evidence, you can use the timeit module in the standard library:$ python -mtimeit -s'l=[[1,2,3],[4,5,6], [7], [8,9]]*99' '[item for sublist in l for item in sublist]'10000 loops, best of 3: 143 usec per loop$ python -mtimeit -s'l=[[1,2,3],[4,5,6], [7], [8,9]]*99' 'sum(l, [])'1000 loops, best of 3: 969 usec per loop$ python -mtimeit -s'l=[[1,2,3],[4,5,6], [7], [8,9]]*99' 'reduce(lambda x,y: x+y,l)'1000 loops, best of 3: 1.1 msec per loopExplanation: the shortcuts based on + (including the implied use in sum) are, of necessity, O(L**2) when there are L sublists -- as the intermediate result list keeps getting longer, at each step a new intermediate result list object gets allocated, and all the items in the previous intermediate result must be copied over (as well as a few new ones added at the end). So, for simplicity and without actual loss of generality, say you have L sublists of I items each: the first I items are copied back and forth L-1 times, the second I items L-2 times, and so on; total number of copies is I times the sum of x for x from 1 to L excluded, i.e., I * (L**2)/2.The list comprehension just generates one list, once, and copies each item over (from its original place of residence to the result list) also exactly once."
"data_i","edited Aug 06 '22 at 23:46","
        What is the difference between a URI, a URL, and a URN?
    ","What is the difference between a URL, a URI, and a URN?","URIs identify and URLs locate; however, locators are also identifiers, so every URL is also a URI, but there are URIs which are not URLs.ExamplesRoger PateThis is my name, which is an identifier.It is like a URI, but cannot be a URL, as it tells you nothing about my location or how to contact me.In this case it also happens to identify at least 5 other people in the USA alone.4914 West Bay Street, Nassau, BahamasThis is a locator, which is an identifier for that physical location.It is like both a URL and URI (since all URLs are URIs), and also identifies me indirectly as ""resident of.."".In this case it uniquely identifies me, but that would change if I get a roommate.I say ""like"" because these examples do not follow the required syntax.Popular confusionFrom Wikipedia:In computing, a Uniform Resource Locator (URL) is a subset of the Uniform Resource Identifier (URI) that specifies where an identified resource is available and the mechanism for retrieving it. In popular usage and in many technical documents and verbal discussions it is often incorrectly used as a synonym for URI, ... [emphasis mine]Because of this common confusion, many products and documentation incorrectly use one term instead of the other, assign their own distinction, or use them synonymously.URNsMy name, Roger Pate, could be like a URN (Uniform Resource Name), except those are much more regulated and intended to be unique across both space and time.Because I currently share this name with other people, it's not globally unique and would not be appropriate as a URN.  However, even if no other family used this name, I'm named after my paternal grandfather, so it still wouldn't be unique across time.  And even if that wasn't the case, the possibility of naming my descendants after me make this unsuitable as a URN.URNs are different from URLs in this rigid uniqueness constraint, even though they both share the syntax of URIs."
"data_i","edited Jul 08 '22 at 04:55","
        How do I squash my last N commits together?
    ","How do I squash my last N commits together into one commit?","You can do this fairly easily without git rebase or git merge --squash. In this example, we'll squash the last 3 commits.If you want to write the new commit message from scratch, this suffices:git reset --soft HEAD~3 &&git commitIf you want to start editing the new commit message with a concatenation of the existing commit messages (i.e. similar to what a pick/squash/squash/…/squash git rebase -i instruction list would start you with), then you need to extract those messages and pass them to git commit:git reset --soft HEAD~3 && git commit --edit -m""$(git log --format=%B --reverse HEAD..HEAD@{1})""Both of those methods squash the last three commits into a single new commit in the same way. The soft reset just re-points HEAD to the last commit that you do not want to squash. Neither the index nor the working tree are touched by the soft reset, leaving the index in the desired state for your new commit (i.e. it already has all the changes from the commits that you are about to “throw away”)."
"data_i","edited Apr 07 '21 at 14:41","
        How do I make the first letter of a string uppercase in JavaScript?
    ","How do I make the first letter of a string uppercase, but not change the case of any of the other letters?For example:""this is a test"" → ""This is a test""""the Eiffel Tower"" → ""The Eiffel Tower""""/index.html"" → ""/index.html""","The basic solution is:function capitalizeFirstLetter(string) {  return string.charAt(0).toUpperCase() + string.slice(1);}console.log(capitalizeFirstLetter('foo')); // FooSome other answers modify String.prototype (this answer used to as well), but I would advise against this now due to maintainability (hard to find out where the function is being added to the prototype and could cause conflicts if other code uses the same name / a browser adds a native function with that same name in future)....and then, there is so much more to this question when you consider internationalisation, as this astonishingly good answer (buried below) shows.If you want to work with Unicode code points instead of code units (for example to handle Unicode characters outside of the Basic Multilingual Plane) you can leverage the fact that String#[@iterator] works with code points, and you can use toLocaleUpperCase to get locale-correct uppercasing:const capitalizeFirstLetter = ([ first, ...rest ], locale = navigator.language) =>  first === undefined ? '' : first.toLocaleUpperCase(locale) + rest.join('')console.log(  capitalizeFirstLetter(''), // [empty string]  capitalizeFirstLetter('foo'), // Foo  capitalizeFirstLetter(""""), // """" (correct!)  capitalizeFirstLetter(""italya"", 'tr') // İtalya"" (correct in Turkish Latin!))For even more internationalization options, please see the original answer below."
"data_i","edited Nov 02 '19 at 16:07","
        How to pass ""Null"" (a real surname!) to a SOAP web service in ActionScript 3
    ","We have an employee whose surname is Null. Our employee lookup application is killed when that last name is used as the search term (which happens to be quite often now). The error received (thanks Fiddler!) is:<soapenv:Fault>   <faultcode>soapenv:Server.userException</faultcode>   <faultstring>coldfusion.xml.rpc.CFCInvocationException: [coldfusion.runtime.MissingArgumentException : The SEARCHSTRING parameter to the getFacultyNames function is required but was not passed in.]</faultstring>Cute, huh?The parameter type is string.I am using:WSDL (SOAP)Flex 3.5ActionScript 3ColdFusion 8Note that the error does not occur when calling the webservice as an object from a ColdFusion page."," Tracking it down At first I thought this was a coercion bug where null was getting coerced to ""null"" and a test of ""null"" == null was passing. It's not. I was close, but so very, very wrong. Sorry about that!I've since done lots of fiddling on wonderfl.net and tracing through the code in mx.rpc.xml.*. At line 1795 of XMLEncoder (in the 3.5 source), in setValue, all of the XMLEncoding boils down to currentChild.appendChild(xmlSpecialCharsFilter(Object(value)));which is essentially the same as:currentChild.appendChild(""null"");This code, according to my original fiddle, returns an empty XML element. But why? Cause According to commenter Justin Mclean on bug report FLEX-33664, the following is the culprit (see last two tests in my fiddle which verify this):var thisIsNotNull:XML = <root>null</root>;if(thisIsNotNull == null){    // always branches here, as (thisIsNotNull == null) strangely returns true    // despite the fact that thisIsNotNull is a valid instance of type XML}When currentChild.appendChild is passed the string ""null"", it first converts it to a root XML element with text null, and then tests that element against the null literal. This is a weak equality test, so either the XML containing null is coerced to the null type, or the null type is coerced to a root xml element containing the string ""null"", and the test passes where it arguably should fail. One fix might be to always use strict equality tests when checking XML (or anything, really) for ""nullness.""SolutionThe only reasonable workaround I can think of, short of fixing this bug in every damn version of ActionScript, is to test fields for ""null"" and escape them as CDATA values.CDATA values are the most appropriate way to mutate an entire text value that would otherwise cause encoding/decoding problems. Hex encoding, for instance, is meant for individual characters. CDATA values are preferred when you're escaping the entire text of an element. The biggest reason for this is that it maintains human readability."
"data_i","edited Jan 11 '21 at 07:13","
        What's the difference between tilde(~) and caret(^) in package.json?
    ","After I upgraded to the latest stable node and npm, I tried npm install moment --save. It saves the entry in the package.json with the caret ^ prefix. Previously, it was a tilde ~ prefix.Why are these changes made in npm?What is the difference between tilde ~ and caret ^?What are the advantages over others?","See the NPM docs and semver docs:~version “Approximately equivalent to version”, will update you to all future patch versions, without incrementing the minor version. ~1.2.3 will use releases from 1.2.3 to <1.3.0.^version “Compatible with version”, will update you to all future minor/patch versions, without incrementing the major version. ^2.3.4 will use releases from 2.3.4 to <3.0.0.See Comments below for exceptions, in particular for pre-one versions, such as ^0.2.3"
"data_i","edited Jun 16 '22 at 16:54","
        How do I check if an array includes a value in JavaScript?
    ","What is the most concise and efficient way to find out if a JavaScript array contains a value?This is the only way I know to do it:function contains(a, obj) {    for (var i = 0; i < a.length; i++) {        if (a[i] === obj) {            return true;        }    }    return false;}Is there a better and more concise way to accomplish this?This is very closely related to Stack Overflow question Best way to find an item in a JavaScript Array? which addresses finding objects in an array using indexOf.","Modern browsers have Array#includes, which does exactly that and is widely supported by everyone except IE:console.log(['joe', 'jane', 'mary'].includes('jane')); //trueYou can also use Array#indexOf, which is less direct, but doesn't require polyfills for outdated browsers.console.log(['joe', 'jane', 'mary'].indexOf('jane') >= 0); //trueMany frameworks also offer similar methods:jQuery: $.inArray(value, array, [fromIndex])Underscore.js: _.contains(array, value) (also aliased as _.include and _.includes)Dojo Toolkit: dojo.indexOf(array, value, [fromIndex, findLast])Prototype: array.indexOf(value)MooTools: array.indexOf(value)MochiKit: findValue(array, value)MS Ajax: array.indexOf(value)Ext: Ext.Array.contains(array, value)Lodash: _.includes(array, value, [from]) (is _.contains prior 4.0.0)Ramda: R.includes(value, array)Notice that some frameworks implement this as a function, while others add the function to the array prototype."
"data_i","edited Jul 08 '22 at 05:11","
        Undo a Git merge that hasn't been pushed yet
    ","I accidentally ran git merge some_other_branch on my local master branch. I haven't pushed the changes to origin master. How do I undo the merge?After merging, git status says:# On branch master# Your branch is ahead of 'origin/master' by 5 commits.How do I undo all these commits?","With git reflog check which commit is one prior the merge (git reflog will be a better option than git log). Then you can reset it using:git reset --hard commit_shaThere's also another way:git reset --hard HEAD~1It will get you back 1 commit.Be aware that any modified and uncommitted/unstashed files will be reset to their unmodified state. To keep them either stash changes away or see --merge option below.  As @Velmont suggested below in his answer, in this direct case using:git reset --hard ORIG_HEADmight yield better results, as it should preserve your changes. ORIG_HEAD will point to a commit directly before merge has occurred, so you don't have to hunt for it yourself.A further tip is to use the --merge switch instead of --hard since it doesn't reset files unnecessarily:git reset --merge ORIG_HEAD--mergeResets the index and updates the files in the working tree that are different between <commit> and HEAD, but keeps those which are different between the index and working tree (i.e. which have changes which have not been added). "
"data_i","asked Sep 15 '08 at 22:42","
        How do I clone all remote branches?
    ","My master and development branches are tracked remotely on GitHub. How do I clone both these branches?","First, clone a remote Git repository and cd into it:$ git clone git://example.com/myproject$ cd myprojectNext, look at the local branches in your repository:$ git branch* masterBut there are other branches hiding in your repository! See these using the -a flag:$ git branch -a* master  remotes/origin/HEAD  remotes/origin/master  remotes/origin/v1.0-stable  remotes/origin/experimentalTo take a quick peek at an upstream branch, check it out directly:$ git checkout origin/experimentalTo work on that branch, create a local tracking branch, which is done automatically by:$ git checkout experimentalBranch experimental set up to track remote branch experimental from origin.Switched to a new branch 'experimental'Here, ""new branch"" simply means that the branch is taken from the index and created locally for you.  As the previous line tells you, the branch is being set up to track the remote branch, which usually means the origin/branch_name branch.Your local branches should now show:$ git branch* experimental  masterYou can track more than one remote repository using git remote:$ git remote add win32 git://example.com/users/joe/myproject-win32-port$ git branch -a* master  remotes/origin/HEAD  remotes/origin/master  remotes/origin/v1.0-stable  remotes/origin/experimental  remotes/win32/master  remotes/win32/new-widgetsAt this point, things are getting pretty crazy, so run gitk to see what's going on:$ gitk --all &"
"data_i","edited Aug 07 '22 at 21:40","
        How do I get a timestamp in JavaScript?
    ","I want a single number that represents the current date and time, like a Unix timestamp.","Timestamp in millisecondsTo get the number of milliseconds since Unix epoch, call Date.now:Date.now()Alternatively, use the unary operator + to call Date.prototype.valueOf:+ new Date()Alternatively, call valueOf directly:new Date().valueOf()To support IE8 and earlier (see compatibility table), create a shim for Date.now:if (!Date.now) {    Date.now = function() { return new Date().getTime(); }}Alternatively, call getTime directly:new Date().getTime()Timestamp in secondsTo get the number of seconds since Unix epoch, i.e. Unix timestamp:Math.floor(Date.now() / 1000)Alternatively, using bitwise-or to floor is slightly faster, but also less readable and may break in the future (see explanations 1, 2):Date.now() / 1000 | 0Timestamp in milliseconds (higher resolution)Use performance.now:var isPerformanceSupported = (    window.performance &&    window.performance.now &&    window.performance.timing &&    window.performance.timing.navigationStart);var timeStampInMs = (    isPerformanceSupported ?    window.performance.now() +    window.performance.timing.navigationStart :    Date.now());console.log(timeStampInMs, Date.now());"
"data_i","edited Sep 23 '22 at 14:49","
        How do I read / convert an InputStream into a String in Java?
    ","If you have a java.io.InputStream object, how should you process that object and produce a String?Suppose I have an InputStream that contains text data, and I want to convert it to a String, so for example I can write that to a log file.What is the easiest way to take the InputStream and convert it to a String?public String convertStreamToString(InputStream is) {// ???}","Summarize other answers I found 11 main ways to do this (see below). And I wrote some performance tests (see results below):Ways to convert an InputStream to a String:Using IOUtils.toString (Apache Utils) String result = IOUtils.toString(inputStream, StandardCharsets.UTF_8);Using CharStreams (Guava) String result = CharStreams.toString(new InputStreamReader(       inputStream, Charsets.UTF_8));Using Scanner (JDK) Scanner s = new Scanner(inputStream).useDelimiter(""\\A""); String result = s.hasNext() ? s.next() : """";Using Stream API (Java 8). Warning: This solution converts different line breaks (like \r\n) to \n. String result = new BufferedReader(new InputStreamReader(inputStream))   .lines().collect(Collectors.joining(""\n""));Using parallel Stream API (Java 8). Warning: This solution converts different line breaks (like \r\n) to \n. String result = new BufferedReader(new InputStreamReader(inputStream))    .lines().parallel().collect(Collectors.joining(""\n""));Using InputStreamReader and StringBuilder (JDK) int bufferSize = 1024; char[] buffer = new char[bufferSize]; StringBuilder out = new StringBuilder(); Reader in = new InputStreamReader(stream, StandardCharsets.UTF_8); for (int numRead; (numRead = in.read(buffer, 0, buffer.length)) > 0; ) {     out.append(buffer, 0, numRead); } return out.toString();Using StringWriter and IOUtils.copy (Apache Commons) StringWriter writer = new StringWriter(); IOUtils.copy(inputStream, writer, ""UTF-8""); return writer.toString();Using ByteArrayOutputStream and inputStream.read (JDK) ByteArrayOutputStream result = new ByteArrayOutputStream(); byte[] buffer = new byte[1024]; for (int length; (length = inputStream.read(buffer)) != -1; ) {     result.write(buffer, 0, length); } // StandardCharsets.UTF_8.name() > JDK 7 return result.toString(""UTF-8"");Using BufferedReader (JDK). Warning: This solution converts different line breaks (like \n\r) to line.separator system property (for example, in Windows to ""\r\n""). String newLine = System.getProperty(""line.separator""); BufferedReader reader = new BufferedReader(         new InputStreamReader(inputStream)); StringBuilder result = new StringBuilder(); for (String line; (line = reader.readLine()) != null; ) {     if (result.length() > 0) {         result.append(newLine);     }     result.append(line); } return result.toString();Using BufferedInputStream and ByteArrayOutputStream (JDK)BufferedInputStream bis = new BufferedInputStream(inputStream);ByteArrayOutputStream buf = new ByteArrayOutputStream();for (int result = bis.read(); result != -1; result = bis.read()) {    buf.write((byte) result);}// StandardCharsets.UTF_8.name() > JDK 7return buf.toString(""UTF-8"");Using inputStream.read() and StringBuilder (JDK). Warning: This solution has problems with Unicode, for example with Russian text (works correctly only with non-Unicode text)StringBuilder sb = new StringBuilder();for (int ch; (ch = inputStream.read()) != -1; ) {    sb.append((char) ch);}return sb.toString();Warning:Solutions 4, 5 and 9 convert different line breaks to one.Solution 11 can't work correctly with Unicode textPerformance testsPerformance tests for small String (length = 175), url in github (mode = Average Time, system = Linux, score 1,343 is the best):              Benchmark                         Mode  Cnt   Score   Error  Units 8. ByteArrayOutputStream and read (JDK)        avgt   10   1,343 ± 0,028  us/op 6. InputStreamReader and StringBuilder (JDK)   avgt   10   6,980 ± 0,404  us/op10. BufferedInputStream, ByteArrayOutputStream  avgt   10   7,437 ± 0,735  us/op11. InputStream.read() and StringBuilder (JDK)  avgt   10   8,977 ± 0,328  us/op 7. StringWriter and IOUtils.copy (Apache)      avgt   10  10,613 ± 0,599  us/op 1. IOUtils.toString (Apache Utils)             avgt   10  10,605 ± 0,527  us/op 3. Scanner (JDK)                               avgt   10  12,083 ± 0,293  us/op 2. CharStreams (guava)                         avgt   10  12,999 ± 0,514  us/op 4. Stream Api (Java 8)                         avgt   10  15,811 ± 0,605  us/op 9. BufferedReader (JDK)                        avgt   10  16,038 ± 0,711  us/op 5. parallel Stream Api (Java 8)                avgt   10  21,544 ± 0,583  us/opPerformance tests for big String (length = 50100), url in github (mode = Average Time, system = Linux, score 200,715 is the best):               Benchmark                        Mode  Cnt   Score        Error  Units 8. ByteArrayOutputStream and read (JDK)        avgt   10   200,715 ±   18,103  us/op 1. IOUtils.toString (Apache Utils)             avgt   10   300,019 ±    8,751  us/op 6. InputStreamReader and StringBuilder (JDK)   avgt   10   347,616 ±  130,348  us/op 7. StringWriter and IOUtils.copy (Apache)      avgt   10   352,791 ±  105,337  us/op 2. CharStreams (guava)                         avgt   10   420,137 ±   59,877  us/op 9. BufferedReader (JDK)                        avgt   10   632,028 ±   17,002  us/op 5. parallel Stream Api (Java 8)                avgt   10   662,999 ±   46,199  us/op 4. Stream Api (Java 8)                         avgt   10   701,269 ±   82,296  us/op10. BufferedInputStream, ByteArrayOutputStream  avgt   10   740,837 ±    5,613  us/op 3. Scanner (JDK)                               avgt   10   751,417 ±   62,026  us/op11. InputStream.read() and StringBuilder (JDK)  avgt   10  2919,350 ± 1101,942  us/opGraphs (performance tests depending on Input Stream length in Windows 7 system)Performance test (Average Time) depending on Input Stream length in Windows 7 system: length  182    546     1092    3276    9828    29484   58968 test8  0.38    0.938   1.868   4.448   13.412  36.459  72.708 test4  2.362   3.609   5.573   12.769  40.74   81.415  159.864 test5  3.881   5.075   6.904   14.123  50.258  129.937 166.162 test9  2.237   3.493   5.422   11.977  45.98   89.336  177.39 test6  1.261   2.12    4.38    10.698  31.821  86.106  186.636 test7  1.601   2.391   3.646   8.367   38.196  110.221 211.016 test1  1.529   2.381   3.527   8.411   40.551  105.16  212.573 test3  3.035   3.934   8.606   20.858  61.571  118.744 235.428 test2  3.136   6.238   10.508  33.48   43.532  118.044 239.481 test10 1.593   4.736   7.527   20.557  59.856  162.907 323.147 test11 3.913   11.506  23.26   68.644  207.591 600.444 1211.545"
"data_i","edited Nov 02 '18 at 23:22","
        ""Thinking in AngularJS"" if I have a jQuery background?
    ","Suppose I'm familiar with developing client-side applications in jQuery, but now I'd like to start using AngularJS. Can you describe the paradigm shift that is necessary? Here are a few questions that might help you frame an answer:How do I architect and design client-side web applications differently? What is the biggest difference?What should I stop doing/using; What should I start doing/using instead?Are there any server-side considerations/restrictions?I'm not looking for a detailed comparison between jQuery and AngularJS.","1. Don't design your page, and then change it with DOM manipulationsIn jQuery, you design a page, and then you make it dynamic. This is because jQuery was designed for augmentation and has grown incredibly from that simple premise.But in AngularJS, you must start from the ground up with your architecture in mind. Instead of starting by thinking ""I have this piece of the DOM and I want to make it do X"", you have to start with what you want to accomplish, then go about designing your application, and then finally go about designing your view.2. Don't augment jQuery with AngularJSSimilarly, don't start with the idea that jQuery does X, Y, and Z, so I'll just add AngularJS on top of that for models and controllers. This is really tempting when you're just starting out, which is why I always recommend that new AngularJS developers don't use jQuery at all, at least until they get used to doing things the ""Angular Way"".I've seen many developers here and on the mailing list create these elaborate solutions with jQuery plugins of 150 or 200 lines of code that they then glue into AngularJS with a collection of callbacks and $applys that are confusing and convoluted; but they eventually get it working! The problem is that in most cases that jQuery plugin could be rewritten in AngularJS in a fraction of the code, where suddenly everything becomes comprehensible and straightforward.The bottom line is this: when solutioning, first ""think in AngularJS""; if you can't think of a solution, ask the community; if after all of that there is no easy solution, then feel free to reach for the jQuery. But don't let jQuery become a crutch or you'll never master AngularJS.3. Always think in terms of architectureFirst know that single-page applications are applications. They're not webpages. So we need to think like a server-side developer in addition to thinking like a client-side developer. We have to think about how to divide our application into individual, extensible, testable components.So then how do you do that? How do you ""think in AngularJS""? Here are some general principles, contrasted with jQuery.The view is the ""official record""In jQuery, we programmatically change the view. We could have a dropdown menu defined as a ul like so:<ul class=""main-menu"">    <li class=""active"">        <a href=""#/home"">Home</a>    </li>    <li>        <a href=""#/menu1"">Menu 1</a>        <ul>            <li><a href=""#/sm1"">Submenu 1</a></li>            <li><a href=""#/sm2"">Submenu 2</a></li>            <li><a href=""#/sm3"">Submenu 3</a></li>        </ul>    </li>    <li>        <a href=""#/home"">Menu 2</a>    </li></ul>In jQuery, in our application logic, we would activate it with something like:$('.main-menu').dropdownMenu();When we just look at the view, it's not immediately obvious that there is any functionality here. For small applications, that's fine. But for non-trivial applications, things quickly get confusing and hard to maintain.In AngularJS, though, the view is the official record of view-based functionality. Our ul declaration would look like this instead:<ul class=""main-menu"" dropdown-menu>    ...</ul>These two do the same thing, but in the AngularJS version anyone looking at the template knows what's supposed to happen. Whenever a new member of the development team comes on board, she can look at this and then know that there is a directive called dropdownMenu operating on it; she doesn't need to intuit the right answer or sift through any code. The view told us what was supposed to happen. Much cleaner.Developers new to AngularJS often ask a question like: how do I find all links of a specific kind and add a directive onto them. The developer is always flabbergasted when we reply: you don't. But the reason you don't do that is that this is like half-jQuery, half-AngularJS, and no good. The problem here is that the developer is trying to ""do jQuery"" in the context of AngularJS. That's never going to work well. The view is the official record. Outside of a directive (more on this below), you never, ever, never change the DOM. And directives are applied in the view, so intent is clear.Remember: don't design, and then mark up. You must architect, and then design.Data bindingThis is by far one of the most awesome features of AngularJS and cuts out a lot of the need to do the kinds of DOM manipulations I mentioned in the previous section. AngularJS will automatically update your view so you don't have to! In jQuery, we respond to events and then update content. Something like:$.ajax({  url: '/myEndpoint.json',  success: function ( data, status ) {    $('ul#log').append('<li>Data Received!</li>');  }});For a view that looks like this:<ul class=""messages"" id=""log""></ul>Apart from mixing concerns, we also have the same problems of signifying intent that I mentioned before. But more importantly, we had to manually reference and update a DOM node. And if we want to delete a log entry, we have to code against the DOM for that too. How do we test the logic apart from the DOM? And what if we want to change the presentation?This a little messy and a trifle frail. But in AngularJS, we can do this:$http( '/myEndpoint.json' ).then( function ( response ) {    $scope.log.push( { msg: 'Data Received!' } );});And our view can look like this:<ul class=""messages"">    <li ng-repeat=""entry in log"">{{ entry.msg }}</li></ul>But for that matter, our view could look like this:<div class=""messages"">    <div class=""alert"" ng-repeat=""entry in log"">        {{ entry.msg }}    </div></div>And now instead of using an unordered list, we're using Bootstrap alert boxes. And we never had to change the controller code! But more importantly, no matter where or how the log gets updated, the view will change too. Automatically. Neat!Though I didn't show it here, the data binding is two-way. So those log messages could also be editable in the view just by doing this: <input ng-model=""entry.msg"" />. And there was much rejoicing.Distinct model layerIn jQuery, the DOM is kind of like the model. But in AngularJS, we have a separate model layer that we can manage in any way we want, completely independently from the view. This helps for the above data binding, maintains separation of concerns, and introduces far greater testability. Other answers mentioned this point, so I'll just leave it at that.Separation of concernsAnd all of the above tie into this over-arching theme: keep your concerns separate. Your view acts as the official record of what is supposed to happen (for the most part); your model represents your data; you have a service layer to perform reusable tasks; you do DOM manipulation and augment your view with directives; and you glue it all together with controllers. This was also mentioned in other answers, and the only thing I would add pertains to testability, which I discuss in another section below.Dependency injectionTo help us out with separation of concerns is dependency injection (DI). If you come from a server-side language (from Java to PHP) you're probably familiar with this concept already, but if you're a client-side guy coming from jQuery, this concept can seem anything from silly to superfluous to hipster. But it's not. :-)From a broad perspective, DI means that you can declare components very freely and then from any other component, just ask for an instance of it and it will be granted. You don't have to know about loading order, or file locations, or anything like that. The power may not immediately be visible, but I'll provide just one (common) example: testing.Let's say in our application, we require a service that implements server-side storage through a REST API and, depending on application state, local storage as well. When running tests on our controllers, we don't want to have to communicate with the server - we're testing the controller, after all. We can just add a mock service of the same name as our original component, and the injector will ensure that our controller gets the fake one automatically - our controller doesn't and needn't know the difference.Speaking of testing...4. Test-driven development - alwaysThis is really part of section 3 on architecture, but it's so important that I'm putting it as its own top-level section.Out of all of the many jQuery plugins you've seen, used, or written, how many of them had an accompanying test suite? Not very many because jQuery isn't very amenable to that. But AngularJS is.In jQuery, the only way to test is often to create the component independently with a sample/demo page against which our tests can perform DOM manipulation. So then we have to develop a component separately and then integrate it into our application. How inconvenient! So much of the time, when developing with jQuery, we opt for iterative instead of test-driven development. And who could blame us?But because we have separation of concerns, we can do test-driven development iteratively in AngularJS! For example, let's say we want a super-simple directive to indicate in our menu what our current route is. We can declare what we want in the view of our application:<a href=""/hello"" when-active>Hello</a>Okay, now we can write a test for the non-existent when-active directive:it( 'should add ""active"" when the route changes', inject(function() {    var elm = $compile( '<a href=""/hello"" when-active>Hello</a>' )( $scope );    $location.path('/not-matching');    expect( elm.hasClass('active') ).toBeFalsey();    $location.path( '/hello' );    expect( elm.hasClass('active') ).toBeTruthy();}));And when we run our test, we can confirm that it fails. Only now should we create our directive:.directive( 'whenActive', function ( $location ) {    return {        scope: true,        link: function ( scope, element, attrs ) {            scope.$on( '$routeChangeSuccess', function () {                if ( $location.path() == element.attr( 'href' ) ) {                    element.addClass( 'active' );                }                else {                    element.removeClass( 'active' );                }            });        }    };});Our test now passes and our menu performs as requested. Our development is both iterative and test-driven. Wicked-cool.5. Conceptually, directives are not packaged jQueryYou'll often hear ""only do DOM manipulation in a directive"". This is a necessity. Treat it with due deference!But let's dive a little deeper...Some directives just decorate what's already in the view (think ngClass) and therefore sometimes do DOM manipulation straight away and then are basically done. But if a directive is like a ""widget"" and has a template, it should also respect separation of concerns. That is, the template too should remain largely independent from its implementation in the link and controller functions.AngularJS comes with an entire set of tools to make this very easy; with ngClass we can dynamically update the class; ngModel allows two-way data binding; ngShow and ngHide programmatically show or hide an element; and many more - including the ones we write ourselves. In other words, we can do all kinds of awesomeness without DOM manipulation. The less DOM manipulation, the easier directives are to test, the easier they are to style, the easier they are to change in the future, and the more re-usable and distributable they are.I see lots of developers new to AngularJS using directives as the place to throw a bunch of jQuery. In other words, they think ""since I can't do DOM manipulation in the controller, I'll take that code put it in a directive"". While that certainly is much better, it's often still wrong.Think of the logger we programmed in section 3. Even if we put that in a directive, we still want to do it the ""Angular Way"". It still doesn't take any DOM manipulation! There are lots of times when DOM manipulation is necessary, but it's a lot rarer than you think! Before doing DOM manipulation anywhere in your application, ask yourself if you really need to. There might be a better way.Here's a quick example that shows the pattern I see most frequently. We want a toggleable button. (Note: this example is a little contrived and a skosh verbose to represent more complicated cases that are solved in exactly the same way.).directive( 'myDirective', function () {    return {        template: '<a class=""btn"">Toggle me!</a>',        link: function ( scope, element, attrs ) {            var on = false;            $(element).click( function () {                on = !on;                $(element).toggleClass('active', on);            });        }    };});There are a few things wrong with this:First, jQuery was never necessary. There's nothing we did here that needed jQuery at all!Second, even if we already have jQuery on our page, there's no reason to use it here; we can simply use angular.element and our component will still work when dropped into a project that doesn't have jQuery.Third, even assuming jQuery was required for this directive to work, jqLite (angular.element) will always use jQuery if it was loaded! So we needn't use the $ - we can just use angular.element.Fourth, closely related to the third, is that jqLite elements needn't be wrapped in $ - the element that is passed to the link function would already be a jQuery element! And fifth, which we've mentioned in previous sections, why are we mixing template stuff into our logic?This directive can be rewritten (even for very complicated cases!) much more simply like so:.directive( 'myDirective', function () {    return {        scope: true,        template: '<a class=""btn"" ng-class=""{active: on}"" ng-click=""toggle()"">Toggle me!</a>',        link: function ( scope, element, attrs ) {            scope.on = false;            scope.toggle = function () {                scope.on = !scope.on;            };        }    };});Again, the template stuff is in the template, so you (or your users) can easily swap it out for one that meets any style necessary, and the logic never had to be touched. Reusability - boom!And there are still all those other benefits, like testing - it's easy! No matter what's in the template, the directive's internal API is never touched, so refactoring is easy. You can change the template as much as you want without touching the directive. And no matter what you change, your tests still pass.w00t!So if directives aren't just collections of jQuery-like functions, what are they? Directives are actually extensions of HTML. If HTML doesn't do something you need it to do, you write a directive to do it for you, and then use it just as if it was part of HTML.Put another way, if AngularJS doesn't do something out of the box, think how the team would accomplish it to fit right in with ngClick, ngClass, et al.SummaryDon't even use jQuery. Don't even include it. It will hold you back. And when you come to a problem that you think you know how to solve in jQuery already, before you reach for the $, try to think about how to do it within the confines the AngularJS. If you don't know, ask! 19 times out of 20, the best way to do it doesn't need jQuery and to try to solve it with jQuery results in more work for you."
"data_i","edited Mar 08 '20 at 23:08","
        Setting ""checked"" for a checkbox with jQuery
    ","I'd like to do something like this to tick a checkbox using jQuery:$("".myCheckBox"").checked(true);or$("".myCheckBox"").selected(true);Does such a thing exist?","Modern jQueryUse .prop():$('.myCheckbox').prop('checked', true);$('.myCheckbox').prop('checked', false);DOM APIIf you're working with just one element, you can always just access the underlying HTMLInputElement and modify its .checked property:$('.myCheckbox')[0].checked = true;$('.myCheckbox')[0].checked = false;The benefit to using the .prop() and .attr() methods instead of this is that they will operate on all matched elements.jQuery 1.5.x and belowThe .prop() method is not available, so you need to use .attr().$('.myCheckbox').attr('checked', true);$('.myCheckbox').attr('checked', false);Note that this is the approach used by jQuery's unit tests prior to version 1.6 and is preferable to using $('.myCheckbox').removeAttr('checked'); since the latter will, if the box was initially checked, change the behaviour of a call to .reset() on any form that contains it – a subtle but probably unwelcome behaviour change.For more context, some incomplete discussion of the changes to the handling of the checked attribute/property in the transition from 1.5.x to 1.6 can be found in the version 1.6 release notes and the Attributes vs. Properties section of the .prop() documentation."
"data_i","edited Jul 08 '22 at 05:19","
        How do I update or sync a forked repository on GitHub?
    ","I forked a project, made changes, and created a pull request which was accepted. New commits were later added to the repository. How do I get those commits into my fork?","In your local clone of your forked repository, you can add the original GitHub repository as a ""remote"".  (""Remotes"" are like nicknames for the URLs of repositories - origin is one, for example.)  Then you can fetch all the branches from that upstream repository, and rebase your work to continue working on the upstream version.  In terms of commands that might look like:# Add the remote, call it ""upstream"":git remote add upstream https://github.com/whoever/whatever.git# Fetch all the branches of that remote into remote-tracking branchesgit fetch upstream# Make sure that you're on your master branch:git checkout master# Rewrite your master branch so that any commits of yours that# aren't already in upstream/master are replayed on top of that# other branch:git rebase upstream/masterIf you don't want to rewrite the history of your master branch, (for example because other people may have cloned it) then you should replace the last command with git merge upstream/master.  However, for making further pull requests that are as clean as possible, it's probably better to rebase.If you've rebased your branch onto upstream/master you may need to force the push in order to push it to your own forked repository on GitHub.  You'd do that with:git push -f origin masterYou only need to use the -f the first time after you've rebased."
"data_i","edited Jul 10 '22 at 21:34","
        How do I delete a remote tag?
    ","How do I delete a Git tag that has already been pushed?","You can push an 'empty' reference to the remote tag name:git push origin :tagnameOr, more expressively, use the --delete option (or -d if your git version is older than 1.8.0):git push --delete origin tagnameNote that git has tag namespace and branch namespace so you may use the same name for a branch and for a tag. If you want to make sure that you cannot accidentally remove the branch instead of the tag, you can specify full ref which will never delete a branch:git push origin :refs/tags/tagnameIf you also need to delete the local tag, use:git tag --delete tagnameBackgroundPushing a branch, tag, or other ref to a remote repository involves specifying ""which repo, what source, what destination?""git push remote-repo source-ref:destination-refA real world example where you push your master branch to the origin's master branch is:git push origin refs/heads/master:refs/heads/masterWhich because of default paths, can be shortened to:git push origin master:masterTags work the same way:git push origin refs/tags/release-1.0:refs/tags/release-1.0Which can also be shortened to:git push origin release-1.0:release-1.0By omitting the source ref (the part before the colon), you push 'nothing' to the destination, deleting the ref on the remote end."
"data_i","edited Apr 09 '22 at 06:53","
        Difference between @staticmethod and @classmethod
    ","What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?","Maybe a bit of example code will help: Notice the difference in the call signatures of foo, class_foo and static_foo:class A(object):    def foo(self, x):        print(f""executing foo({self}, {x})"")    @classmethod    def class_foo(cls, x):        print(f""executing class_foo({cls}, {x})"")    @staticmethod    def static_foo(x):        print(f""executing static_foo({x})"")a = A()Below is the usual way an object instance calls a method. The object instance, a, is implicitly passed as the first argument.a.foo(1)# executing foo(<__main__.A object at 0xb7dbef0c>, 1)With classmethods, the class of the object instance is implicitly passed as the first argument instead of self.a.class_foo(1)# executing class_foo(<class '__main__.A'>, 1)You can also call class_foo using the class. In fact, if you define something to bea classmethod, it is probably because you intend to call it from the class rather than from a class instance. A.foo(1) would have raised a TypeError, but A.class_foo(1) works just fine:A.class_foo(1)# executing class_foo(<class '__main__.A'>, 1)One use people have found for class methods is to create inheritable alternative constructors.With staticmethods, neither self (the object instance) nor  cls (the class) is implicitly passed as the first argument. They behave like plain functions except that you can call them from an instance or the class:a.static_foo(1)# executing static_foo(1)A.static_foo('hi')# executing static_foo(hi)Staticmethods are used to group functions which have some logical connection with a class to the class.foo is just a function, but when you call a.foo you don't just get the function,you get a ""partially applied"" version of the function with the object instance a bound as the first argument to the function. foo expects 2 arguments, while a.foo only expects 1 argument.a is bound to foo. That is what is meant by the term ""bound"" below:print(a.foo)# <bound method A.foo of <__main__.A object at 0xb7d52f0c>>With a.class_foo, a is not bound to class_foo, rather the class A is bound to class_foo.print(a.class_foo)# <bound method type.class_foo of <class '__main__.A'>>Here, with a staticmethod, even though it is a method, a.static_foo just returnsa good 'ole function with no arguments bound. static_foo expects 1 argument, anda.static_foo expects 1 argument too.print(a.static_foo)# <function static_foo at 0xb7d479cc>And of course the same thing happens when you call static_foo with the class A instead.print(A.static_foo)# <function static_foo at 0xb7d479cc>"
"data_i","edited Jan 03 '20 at 22:03","
        Why does Google prepend while(1); to their JSON responses?
    ","Why does Google prepend while(1); to their (private) JSON responses?For example, here's a response while turning a calendar on and off in Google Calendar:while (1);[  ['u', [    ['smsSentFlag', 'false'],    ['hideInvitations', 'false'],    ['remindOnRespondedEventsOnly', 'true'],    ['hideInvitations_remindOnRespondedEventsOnly', 'false_true'],    ['Calendar ID stripped for privacy', 'false'],    ['smsVerifiedFlag', 'true']  ]]]I would assume this is to prevent people from doing an eval() on it, but all you'd really have to do is replace the while and then you'd be set. I would assume the eval prevention is to make sure people write safe JSON parsing code.I've seen this used in a couple of other places, too, but a lot more so with Google (Mail, Calendar, Contacts, etc.) Strangely enough, Google Docs starts with &&&START&&& instead, and Google Contacts seems to start with while(1); &&&START&&&.What's going on here?","It prevents JSON hijacking, a major JSON security issue that is formally fixed in all major browsers since 2011 with ECMAScript 5.Contrived example: say Google has a URL like mail.google.com/json?action=inbox which returns the first 50 messages of your inbox in JSON format. Evil websites on other domains can't make AJAX requests to get this data due to the same-origin policy, but they can include the URL via a <script> tag. The URL is visited with your cookies, and by overriding the global array constructor or accessor methods they can have a method called whenever an object (array or hash) attribute is set, allowing them to read the JSON content.The while(1); or &&&BLAH&&& prevents this: an AJAX request at mail.google.com will have full access to the text content, and can strip it away. But a <script> tag insertion blindly executes the JavaScript without any processing, resulting in either an infinite loop or a syntax error.This does not address the issue of cross-site request forgery."
"data_i","edited Feb 19 '17 at 08:58","
        Which ""href"" value should I use for JavaScript links, ""#"" or ""javascript:void(0)""?
    ","The following are two methods of building a link that has the sole purpose of running JavaScript code. Which is better, in terms of functionality, page load speed, validation purposes, etc.?function myJsFunc() {    alert(""myJsFunc"");}<a href=""#"" onclick=""myJsFunc();"">Run JavaScript Code</a>orfunction myJsFunc() {    alert(""myJsFunc"");} <a href=""javascript:void(0)"" onclick=""myJsFunc();"">Run JavaScript Code</a>","I use javascript:void(0).Three reasons. Encouraging the use of # amongst a team of developers inevitably leads to some using the return value of the function called like this:function doSomething() {    //Some code    return false;}But then they forget to use return doSomething() in the onclick and just use doSomething().A second reason for avoiding # is that the final return false; will not execute if the called function throws an error. Hence the developers have to also remember to handle any error appropriately in the called function.A third reason is that there are cases where the onclick event property is assigned dynamically.  I prefer to be able to call a function or assign it dynamically without having to code the function specifically for one method of attachment or another. Hence my onclick (or on anything) in HTML markup look like this:onclick=""someFunc.call(this)""ORonclick=""someFunc.apply(this, arguments)""Using javascript:void(0) avoids all of the above headaches, and I haven't found any examples of a downside.So if you're a lone developer then you can clearly make your own choice, but if you work as a team you have to either state:Use href=""#"", make sure onclick always contains return false; at the end, that any called function does not throw an error and if you attach a function dynamically to the onclick property make sure that as well as not throwing an error it returns false.ORUse href=""javascript:void(0)""The second is clearly much easier to communicate."
"data_i","edited Mar 29 '22 at 11:10","
        Understanding slicing
    ","I need a good explanation (references are a plus) on Python slicing.","The syntax is:a[start:stop]  # items start through stop-1a[start:]      # items start through the rest of the arraya[:stop]       # items from the beginning through stop-1a[:]           # a copy of the whole arrayThere is also the step value, which can be used with any of the above:a[start:stop:step] # start through not past stop, by stepThe key point to remember is that the :stop value represents the first value that is not in the selected slice. So, the difference between stop and start is the number of elements selected (if step is 1, the default).The other feature is that start or stop may be a negative number, which means it counts from the end of the array instead of the beginning. So:a[-1]    # last item in the arraya[-2:]   # last two items in the arraya[:-2]   # everything except the last two itemsSimilarly, step may be a negative number:a[::-1]    # all items in the array, reverseda[1::-1]   # the first two items, reverseda[:-3:-1]  # the last two items, reverseda[-3::-1]  # everything except the last two items, reversedPython is kind to the programmer if there are fewer items than you ask for. For example, if you ask for a[:-2] and a only contains one element, you get an empty list instead of an error. Sometimes you would prefer the error, so you have to be aware that this may happen.Relationship with the slice objectA slice object can represent a slicing operation, i.e.:a[start:stop:step]is equivalent to:a[slice(start, stop, step)]Slice objects also behave slightly differently depending on the number of arguments, similarly to range(), i.e. both slice(stop) and slice(start, stop[, step]) are supported.To skip specifying a given argument, one might use None, so that e.g. a[start:] is equivalent to a[slice(start, None)] or a[::-1] is equivalent to a[slice(None, None, -1)].While the :-based notation is very helpful for simple slicing, the explicit use of slice() objects simplifies the programmatic generation of slicing."
"data_i","edited Jul 10 '22 at 23:18","
        Avoiding NullPointerException in Java
    ","I use x != null to avoid NullPointerException. Is there an alternative?if (x != null) {    // ...}","This to me sounds like a reasonably common problem that junior to intermediate developers tend to face at some point: they either don't know or don't trust the contracts they are participating in and defensively overcheck for nulls.  Additionally, when writing their own code, they tend to rely on returning nulls to indicate something thus requiring the caller to check for nulls.To put this another way, there are two instances where null checking comes up:Where null is a valid response in terms of the contract; andWhere it isn't a valid response.(2) is easy.  As of Java 1.7 you can use Objects.requireNonNull(foo). (If you are stuck with a previous version then assertions may be a good alternative.)""Proper"" usage of this method would be like below. The method returns the object passed into it and throws a NullPointerException if the object is null. This means that the returned value is always non-null. The method is primarily intended for validating parameters.public Foo(Bar bar) {    this.bar = Objects.requireNonNull(bar);}It can also be used like an assertion though since it throws an exception if the object is null. In both uses, a message can be added which will be shown in the exception. Below is using it like an assertion and providing a message.Objects.requireNonNull(someobject, ""if someobject is null then something is wrong"");someobject.doCalc();Generally throwing a specific exception like NullPointerException when a value is null but shouldn't be is favorable to throwing a more general exception like AssertionError. This is the approach the Java library takes; favoring NullPointerException over IllegalArgumentException when an argument is not allowed to be null.(1) is a little harder.  If you have no control over the code you're calling then you're stuck.  If null is a valid response, you have to check for it.If it's code that you do control, however (and this is often the case), then it's a different story.  Avoid using nulls as a response.  With methods that return collections, it's easy: return empty collections (or arrays) instead of nulls pretty much all the time.With non-collections it might be harder.  Consider this as an example: if you have these interfaces:public interface Action {  void doSomething();}public interface Parser {  Action findAction(String userInput);}where Parser takes raw user input and finds something to do, perhaps if you're implementing a command line interface for something.  Now you might make the contract that it returns null if there's no appropriate action.  That leads the null checking you're talking about.An alternative solution is to never return null and instead use the Null Object pattern:public class MyParser implements Parser {  private static Action DO_NOTHING = new Action() {    public void doSomething() { /* do nothing */ }  };  public Action findAction(String userInput) {    // ...    if ( /* we can't find any actions */ ) {      return DO_NOTHING;    }  }}Compare:Parser parser = ParserFactory.getParser();if (parser == null) {  // now what?  // this would be an example of where null isn't (or shouldn't be) a valid response}Action action = parser.findAction(someInput);if (action == null) {  // do nothing} else {  action.doSomething();}toParserFactory.getParser().findAction(someInput).doSomething();which is a much better design because it leads to more concise code.That said, perhaps it is entirely appropriate for the findAction() method to throw an Exception with a meaningful error message -- especially in this case where you are relying on user input.  It would be much better for the findAction method to throw an Exception than for the calling method to blow up with a simple NullPointerException with no explanation.try {    ParserFactory.getParser().findAction(someInput).doSomething();} catch(ActionNotFoundException anfe) {    userConsole.err(anfe.getMessage());}Or if you think the try/catch mechanism is too ugly, rather than Do Nothing your default action should provide feedback to the user.public Action findAction(final String userInput) {    /* Code to return requested Action if found */    return new Action() {        public void doSomething() {            userConsole.err(""Action not found: "" + userInput);        }    }}"
"data_i","edited Feb 03 '21 at 10:58","
        Change a HTML5 input's placeholder color with CSS
    ","Chrome supports the placeholder attribute on input[type=text] elements (others probably do too).But the following CSS doesn't do anything to the placeholder's value:input[placeholder], [placeholder], *[placeholder] {    color: red !important;}<input type=""text"" placeholder=""Value"">But Value will still remain grey instead of red.Is there a way to change the color of the placeholder text?","ImplementationThere are three different implementations: pseudo-elements, pseudo-classes, and nothing.WebKit, Blink (Safari, Google Chrome, Opera 15+) and Microsoft Edge are using a pseudo-element: ::-webkit-input-placeholder. [Ref]Mozilla Firefox 4 to 18 is using a pseudo-class: :-moz-placeholder (one colon). [Ref]Mozilla Firefox 19+ is using a pseudo-element: ::-moz-placeholder, but the old selector will still work for a while. [Ref]Internet Explorer 10 and 11 are using a pseudo-class: :-ms-input-placeholder. [Ref]April 2017: Most modern browsers support the simple pseudo-element ::placeholder [Ref]Internet Explorer 9 and lower does not support the placeholder attribute at all, while Opera 12 and lower do not support any CSS selector for placeholders.The discussion about the best implementation is still going on. Note the pseudo-elements act like real elements in the Shadow DOM. A padding on an input will not get the same background color as the pseudo-element.CSS selectorsUser agents are required to ignore a rule with an unknown selector. See Selectors Level 3:a group of selectors containing an invalid selector is invalid.So we need separate rules for each browser. Otherwise the whole group would be ignored by all browsers.::-webkit-input-placeholder { /* WebKit, Blink, Edge */    color:    #909;}:-moz-placeholder { /* Mozilla Firefox 4 to 18 */   color:    #909;   opacity:  1;}::-moz-placeholder { /* Mozilla Firefox 19+ */   color:    #909;   opacity:  1;}:-ms-input-placeholder { /* Internet Explorer 10-11 */   color:    #909;}::-ms-input-placeholder { /* Microsoft Edge */   color:    #909;}::placeholder { /* Most modern browsers support this now. */   color:    #909;}<input placeholder=""Stack Snippets are awesome!"">Usage notesBe careful to avoid bad contrasts. Firefox's placeholder appears to be defaulting with a reduced opacity, so needs to use opacity: 1 here.Note that placeholder text is just cut off if it doesn’t fit – size your input elements in em and test them with big minimum font size settings. Don’t forget translations: some languages need more room for the same word.Browsers with HTML support for placeholder but without CSS support for that (like Opera) should be tested too.Placeholders are no replacement for labels, so make sure you have a label, tooSome browsers use additional default CSS for some input types (email, search). These might affect the rendering in unexpected ways. Use the properties -webkit-appearance and -moz-appearance to change that. Example:    [type=""search""] {        -moz-appearance:    textfield;        -webkit-appearance: textfield;        appearance: textfield;    }"
"data_i","edited Mar 27 '22 at 15:13","
        How is Docker different from a virtual machine?
    ","I keep rereading the Docker documentation to try to understand the difference between Docker and a full VM. How does it manage to provide a full filesystem, isolated networking environment, etc. without being as heavy?Why is deploying software to a Docker image (if that's the right term) easier than simply deploying to a consistent production environment?","Docker originally used LinuX Containers (LXC), but later switched to runC (formerly known as libcontainer), which runs in the same operating system as its host. This allows it to share a lot of the host operating system resources. Also, it uses a layered filesystem (AuFS) and manages networking.AuFS is a layered file system, so you can have a read only part and a write part which are merged together. One could have the common parts of the operating system as read only (and shared amongst all of your containers) and then give each container its own mount for writing.So, let's say you have a 1 GB container image; if you wanted to use a full VM, you would need to have 1 GB x number of VMs you want. With Docker and AuFS you can share the bulk of the 1 GB between all the containers and if you have 1000 containers you still might only have a little over 1 GB of space for the containers OS (assuming they are all running the same OS image).A full virtualized system gets its own set of resources allocated to it, and does minimal sharing. You get more isolation, but it is much heavier (requires more resources). With Docker you get less isolation, but the containers are lightweight (require fewer resources). So you could easily run thousands of containers on a host, and it won't even blink. Try doing that with Xen, and unless you have a really big host, I don't think it is possible.A full virtualized system usually takes minutes to start, whereas Docker/LXC/runC containers take seconds, and often even less than a second.There are pros and cons for each type of virtualized system. If you want full isolation with guaranteed resources, a full VM is the way to go. If you just want to isolate processes from each other and want to run a ton of them on a reasonably sized host, then Docker/LXC/runC seems to be the way to go.For more information, check out this set of blog posts which do a good job of explaining how LXC works.Why is deploying software to a docker image (if that's the right term) easier than simply deploying to a consistent production environment?Deploying a consistent production environment is easier said than done. Even if you use tools like Chef and Puppet, there are always OS updates and other things that change between hosts and environments.Docker gives you the ability to snapshot the OS into a shared image, and makes it easy to deploy on other Docker hosts. Locally, dev, qa, prod, etc.: all the same image. Sure you can do this with other tools, but not nearly as easily or fast.This is great for testing; let's say you have thousands of tests that need to connect to a database, and each test needs a pristine copy of the database and will make changes to the data. The classic approach to this is to reset the database after every test either with custom code or with tools like Flyway - this can be very time-consuming and means that tests must be run serially. However, with Docker you could create an image of your database and run up one instance per test, and then run all the tests in parallel since you know they will all be running against the same snapshot of the database. Since the tests are running in parallel and in Docker containers they could run all on the same box at the same time and should finish much faster. Try doing that with a full VM.From comments...Interesting! I suppose I'm still confused by the notion of ""snapshot[ting] the OS"". How does one do that without, well, making an image of the OS?Well, let's see if I can explain. You start with a base image, and then make your changes, and commit those changes using docker, and it creates an image. This image contains only the differences from the base. When you want to run your image, you also need the base, and it layers your image on top of the base using a layered file system: as mentioned above, Docker uses AuFS. AuFS merges the different layers together and you get what you want; you just need to run it. You can keep adding more and more images (layers) and it will continue to only save the diffs. Since Docker typically builds on top of ready-made images from a registry, you rarely have to ""snapshot"" the whole OS yourself."
"data_i","edited Jun 23 '22 at 13:06","
        How to close/hide the Android soft keyboard programmatically?
    ","I have an EditText and a Button in my layout.After writing in the edit field and clicking on the Button, I want to hide the virtual keyboard when touching it outside the keyboard. I assume that this is a simple piece of code, but where can I find an example of it?","You can force Android to hide the virtual keyboard using the InputMethodManager, calling hideSoftInputFromWindow, passing in the token of the window containing your focused view.// Check if no view has focus:View view = this.getCurrentFocus();if (view != null) {      InputMethodManager imm = (InputMethodManager)getSystemService(Context.INPUT_METHOD_SERVICE);    imm.hideSoftInputFromWindow(view.getWindowToken(), 0);}This will force the keyboard to be hidden in all situations. In some cases, you will want to pass in InputMethodManager.HIDE_IMPLICIT_ONLY as the second parameter to ensure you only hide the keyboard when the user didn't explicitly force it to appear (by holding down the menu).Note: If you want to do this in Kotlin, use:context?.getSystemService(Context.INPUT_METHOD_SERVICE) as InputMethodManagerKotlin Syntax// Only runs if there is a view that is currently focusedthis.currentFocus?.let { view ->    val imm = getSystemService(Context.INPUT_METHOD_SERVICE) as? InputMethodManager    imm?.hideSoftInputFromWindow(view.windowToken, 0)}"
"data_i","edited Dec 09 '19 at 22:29","
        How to enumerate an enum
    ","How can you enumerate an enum in C#?E.g. the following code does not compile:public enum Suit{    Spades,    Hearts,    Clubs,    Diamonds}public void EnumerateAllSuitsDemoMethod(){    foreach (Suit suit in Suit)    {        DoSomething(suit);    }}And it gives the following compile-time error:'Suit' is a 'type' but is used like a 'variable'It fails on the Suit keyword, the second one.","foreach (Suit suit in (Suit[]) Enum.GetValues(typeof(Suit))){}Note: The cast to (Suit[]) is not strictly necessary, but it does make the code 0.5 ns faster."
"data_i","edited Jan 18 '21 at 12:34","
        The Definitive C++ Book Guide and List
    ","This question attempts to collect the few pearls among the dozens of bad C++ books that are published every year.Unlike many other programming languages, which are often picked up on the go from tutorials found on the Internet, few are able to quickly pick up C++ without studying a well-written C++ book. It is way too big and complex for doing this. In fact, it is so big and complex, that there are very many very bad C++ books out there. And we are not talking about bad style, but things like sporting glaringly obvious factual errors and promoting abysmally bad programming styles.Please edit the accepted answer to provide quality books and an approximate skill level — preferably after discussing your addition in the C++ chat room. (The regulars might mercilessly undo your work if they disagree with a recommendation.) Add a short blurb/description about each book that you have personally read/benefited from. Feel free to debate quality, headings, etc. Books that meet the criteria will be added to the list.  Books that have reviews by the Association of C and C++ Users (ACCU) have links to the review.*Note: FAQs and other resources can be found in the C++ tag info and under c++-faq. ","BeginnerIntroductory, no previous programming experienceBookAuthor(s)DescriptionreviewC++ Primer* * Not to be confused with C++ Primer Plus (Stephen Prata), with a significantly less favorable review.Stanley Lippman, Josée Lajoie, and Barbara E. Moo  (updated for C++11)Coming at 1k pages, this is a very thorough introduction into C++ that covers just about everything in the language in a very accessible format and in great detail. The fifth edition (released August 16, 2012) covers C++11.[Review]Programming: Principles and Practice Using C++Bjarne Stroustrup, 2nd Edition - May 25, 2014 (updated for C++11/C++14)An introduction to programming using C++ by the creator of the language. A good read, that assumes no previous programming experience, but is not only for beginners.Introductory, with previous programming experienceBookAuthor(s)DescriptionreviewA Tour of C++Bjarne Stroustrup (2nd edition for C++17, 3rd edition for C++20)The “tour” is a quick (about 180 pages and 14 chapters) tutorial overview of all of standard C++ (language and standard library, and using C++11) at a moderately high level for people who already know C++ or at least are experienced programmers. This book is an extended version of the material that constitutes Chapters 2-5 of The C++ Programming Language, 4th edition.Accelerated C++Andrew Koenig and Barbara Moo, 1st Edition - August 24, 2000This basically covers the same ground as the C++ Primer, but does so in a quarter of its space. This is largely because it does not attempt to be an introduction to programming, but an introduction to C++ for people who've previously programmed in some other language. It has a steeper learning curve, but, for those who can cope with this, it is a very compact introduction to the language. (Historically, it broke new ground by being the first beginner's book to use a modern approach to teaching the language.) Despite this, the C++ it teaches is purely C++98.[Review]Best practicesBookAuthor(s)DescriptionreviewEffective C++Scott Meyers, 3rd Edition - May 22, 2005This was written with the aim of being the best second book C++ programmers should read, and it succeeded. Earlier editions were aimed at programmers coming from C, the third edition changes this and targets programmers coming from languages like Java. It presents ~50 easy-to-remember rules of thumb along with their rationale in a very accessible (and enjoyable) style. For C++11 and C++14 the examples and a few issues are outdated and Effective Modern C++ should be preferred.[Review]Effective Modern C++Scott MeyersThis book is aimed at C++ programmers making the transition from C++03 to C++11 and C++14. This book can be treated like a continuation and ""correction"" of some parts of the previous book - ""Effective C++"". They don't cover the same things, but keep similar item-based theme.[Review]Effective STLScott MeyersThis aims to do the same to the part of the standard library coming from the STL what Effective C++ did to the language as a whole: It presents rules of thumb along with their rationale.IntermediateBookAuthor(s)DescriptionreviewMore Effective C++Scott MeyersEven more rules of thumb than Effective C++. Not as important as the ones in the first book, but still good to know.Exceptional C++Herb SutterPresented as a set of puzzles, this has one of the best and thorough discussions of the proper resource management and exception safety in C++ through Resource Acquisition is Initialization (RAII) in addition to in-depth coverage of a variety of other topics including the pimpl idiom, name lookup, good class design, and the C++ memory model.[Review]More Exceptional C++Herb SutterCovers additional exception safety topics not covered in Exceptional C++, in addition to discussion of effective object-oriented programming in C++ and correct use of the STL.[Review]Exceptional C++ StyleHerb SutterDiscusses generic programming, optimization, and resource management; this book also has an excellent exposition of how to write modular code in C++ by using non-member functions and the single responsibility principle.[Review]C++ Coding StandardsHerb Sutter and Andrei Alexandrescu“Coding standards” here doesn't mean “how many spaces should I indent my code?”  This book contains 101 best practices, idioms, and common pitfalls that can help you to write correct, understandable, and efficient C++ code.[Review]C++ Templates: The Complete GuideDavid Vandevoorde and Nicolai M. JosuttisThis is the book about templates as they existed before C++11.  It covers everything from the very basics to some of the most advanced template metaprogramming and explains every detail of how templates work (both conceptually and at how they are implemented) and discusses many common pitfalls.  Has excellent summaries of the One Definition Rule (ODR) and overload resolution in the appendices. A second edition covering C++11, C++14 and C++17 has been already published.[Review]C++ 17 - The Complete GuideNicolai M. JosuttisThis book describes all the new features introduced in the C++17 Standard covering everything from the simple ones like 'Inline Variables', 'constexpr if' all the way up to 'Polymorphic Memory Resources' and 'New and Delete with over aligned Data'.[Review]C++ 20 - The Complete GuideNicolai M. JosuttisThis book presents all the new language and library features of C++20. It covers the motivation and context of each new feature with examples and background information. The focus is on how these features impact day-to-day programming, what it means to combine them, and how to benefit from C++20 in practice. (Note that this book is published step-by-step.)C++ in ActionBartosz MilewskiThis book explains C++ and its features by building an application from ground up.[Review]Functional Programming in C++Ivan ČukićThis book introduces functional programming techniques to modern C++ (C++11 and later). A very nice read for those who want to apply functional programming paradigms to C++.AdvancedBookAuthor(s)DescriptionreviewModern C++ DesignAndrei AlexandrescuA groundbreaking book on advanced generic programming techniques.  Introduces policy-based design, type lists, and fundamental generic programming idioms then explains how many useful design patterns (including small object allocators, functors, factories, visitors, and multi-methods) can be implemented efficiently, modularly, and cleanly using generic programming.[Review]C++ Template MetaprogrammingDavid Abrahams and Aleksey GurtovoyC++ Concurrency In ActionAnthony WilliamsA book covering C++11 concurrency support including the thread library, the atomics library, the C++ memory model, locks and mutexes, as well as issues of designing and debugging multithreaded applications. A second edition covering C++14 and C++17 has already been published.[Review]Advanced C++ MetaprogrammingDavide Di GennaroA pre-C++11 manual of TMP techniques, focused more on practice than theory.  There are a ton of snippets in this book, some of which are made obsolete by type traits, but the techniques, are nonetheless useful to know.  If you can put up with the quirky formatting/editing, it is easier to read than Alexandrescu, and arguably, more rewarding.  For more experienced developers, there is a good chance that you may pick up something about a dark corner of C++ (a quirk) that usually only comes about through extensive experience.Large Scale C++ volume I, Process and architecture (2020)John LakosPart one of a three-part series extending the older book 'Large Scale C++ Design'. Lakos explains battle-tested techniques to manage very big C++ software projects. If you work in a big C++ software project this is a great read, detailing the relationship between physical and logical structure, strategies for components, and their reuse.[Review]Reference Style - All LevelsBookAuthor(s)DescriptionreviewThe C++ Programming LanguageBjarne Stroustrup (updated for C++11)The classic introduction to C++ by its creator. Written to parallel the classic K&R, this indeed reads very much like it and covers just about everything from the core language to the standard library, to programming paradigms to the language's philosophy.[Review] Note: All releases of the C++ standard are tracked in the question ""Where do I find the current C or C++ standard documents?"".C++ Standard Library Tutorial and ReferenceNicolai Josuttis (updated for C++11)The introduction and reference for the C++ Standard Library. The second edition (released on April 9, 2012) covers C++11.[Review]The C++ IO Streams and LocalesAngelika Langer and Klaus KreftThere's very little to say about this book except that if you want to know anything about streams and locales, then this is the one place to find definitive answers.[Review]C++11/14/17/… References:Working Draft, Standard for Programming Language C++ generated from  LaTeX sources published on GitHub.C++ Standard Papers, latest standard working draft: ISO working draftThe C++11/14/17 Standard (INCITS/ISO/IEC 14882:2011/2014/2017) This, of course, is the final arbiter of all that is or isn't C++. Be aware, however, that it is intended purely as a reference for experienced users willing to devote considerable time and effort to its understanding. The C++17 standard is released in electronic form for 198 Swiss Francs.The C++17 standard is available, but seemingly not in an economical form – directly from the ISO it costs 198 Swiss Francs (about $200 US). For most people, the final draft before standardization is more than adequate (and free). Many will prefer an even newer draft, documenting new features that are likely to be included in C++20.C++20 draft is available on GitHub as some older too.Overview of the New C++ (C++11/14) (PDF only) (Scott Meyers) (updated for C++14) These are the presentation materials (slides and some lecture notes) of a three-day training course offered by Scott Meyers, who's a highly respected author on C++. Even though the list of items is short, the quality is high.The C++ Core Guidelines (C++11/14/17/…) (edited by Bjarne Stroustrup and Herb Sutter) is an evolving online document consisting of a set of guidelines for using modern C++ well. The guidelines are focused on relatively higher-level issues, such as interfaces, resource management, memory management, and concurrency affecting application architecture and library design. The project was announced at CppCon'15 by Bjarne Stroustrup and others and welcomes contributions from the community. Most guidelines are supplemented with a rationale and examples as well as discussions of possible tool support. Many rules are designed specifically to be automatically checkable by static analysis tools.The C++ Super-FAQ (Marshall Cline, Bjarne Stroustrup, and others) is an effort by the Standard C++ Foundation to unify the C++ FAQs previously maintained individually by Marshall Cline and Bjarne Stroustrup and also incorporating new contributions. The items mostly address issues at an intermediate level and are often written with a humorous tone. Not all items might be fully up to date with the latest edition of the C++ standard yet.cppreference.com (C++03/11/14/17/…) (initiated by Nate Kohl) is a wiki that summarizes the basic core-language features and has extensive documentation of the C++ standard library. The documentation is very precise but is easier to read than the official standard document and provides better navigation due to its wiki nature. The project documents all versions of the C++ standard and the site allows filtering the display for a specific version. The project was presented by Nate Kohl at CppCon'14.Classics / OlderNote: Some information contained within these books may not be up-to-date or no longer considered best practice.The Design and Evolution of C++ (Bjarne Stroustrup)  If you want to know why the language is the way it is, this book is where you find answers. This covers everything before the standardization of C++.Ruminations on C++ - (Andrew Koenig and Barbara Moo) [Review]Advanced C++ Programming Styles and Idioms (James Coplien)  A predecessor of the pattern movement, it describes many C++-specific “idioms”. It's certainly a very good book and might still be worth a read if you can spare the time, but quite old and not up-to-date with current C++.Large Scale C++ Software Design (John Lakos)  Lakos explains techniques to manage very big C++ software projects. Certainly, a good read, if it only was up to date. It was written long before C++ 98 and misses on many features (e.g. namespaces) important for large-scale projects. If you need to work on a big C++ software project, you might want to read it, although you need to take more than a grain of salt with it. Not to be confused with the extended and later book series Large Scale C++ volume I-III.Inside the C++ Object Model (Stanley Lippman)  If you want to know how virtual member functions are commonly implemented and how base objects are commonly laid out in memory in a multi-inheritance scenario, and how all this affects performance, this is where you will find thorough discussions of such topics.The Annotated C++ Reference Manual (Bjarne Stroustrup, Margaret A. Ellis) This book is quite outdated in the fact that it explores the 1989 C++ 2.0 version - Templates, exceptions, namespaces, and new casts were not yet introduced. Saying that however, this book goes through the entire C++ standard of the time explaining the rationale, the possible implementations, and features of the language. This is not a book to learn programming principles and patterns on C++, but to understand every aspect of the C++ language.Thinking in C++ (Bruce Eckel, 2nd Edition, 2000).  Two volumes; is a tutorial-style free set of intro level books. Downloads: vol 1, vol 2. Unfortunately, they're marred by a number of trivial errors (e.g. maintaining that temporaries are automatic const), with no official errata list. A partial 3rd party errata list is available at http://www.computersciencelab.com/Eckel.htm, but it is apparently not maintained.Scientific and Engineering C++: An Introduction to Advanced Techniques and Examples (John Barton and Lee Nackman)It is a comprehensive and very detailed book that tried to explain and make use of all the features available in C++, in the context of numerical methods. It introduced at the time several new techniques, such as the Curiously Recurring Template Pattern (CRTP, also called Barton-Nackman trick).It pioneered several techniques such as dimensional analysis and automatic differentiation.It came with a lot of compilable and useful code, ranging from an expression parser to a Lapack wrapper.The code is still available online.Unfortunately, the books have become somewhat outdated in the style and C++ features, however, it was an incredible tour-de-force at the time (1994, pre-STL).The chapters on dynamics inheritance are a bit complicated to understand and not very useful.An updated version of this classic book that includes move semantics and the lessons learned from the STL would be very nice."
"data_i","edited Jul 17 '22 at 00:28","
        How do I copy to the clipboard in JavaScript?
    ","How do I copy text to the clipboard (multi-browser)?Related: How does Trello access the user's clipboard?","OverviewThere are three primary browser APIs for copying to the clipboard:Async Clipboard API [navigator.clipboard.writeText]Text-focused portion available in Chrome 66 (March 2018)Access is asynchronous and uses JavaScript Promises, can be written so security user prompts (if displayed) don't interrupt the JavaScript in the page.Text can be copied to the clipboard directly from a variable.Only supported on pages served over HTTPS.In Chrome 66 pages inactive tabs can write to the clipboard without a permissions prompt.document.execCommand('copy') (deprecated) Most browsers support this as of ~April 2015 (see Browser Support below).Access is synchronous, i.e. stops JavaScript in the page until complete including displaying and user interacting with any security prompts.Text is read from the DOM and placed on the clipboard.During testing ~April 2015 only Internet Explorer was noted as displaying permissions prompts whilst writing to the clipboard.Overriding the copy eventSee Clipboard API documentation on Overriding the copy event.Allows you to modify what appears on the clipboard from any copy event, can include other formats of data other than plain text.Not covered here as it doesn't directly answer the question.General development notesDon't expect clipboard related commands to work whilst you are testing code in the console. Generally, the page is required to be active (Async Clipboard API) or requires user interaction (e.g. a user click) to allow (document.execCommand('copy')) to access the clipboard see below for more detail.IMPORTANT (noted here 2020/02/20)Note that since this post was originally written deprecation of permissions in cross-origin IFRAMEs and other IFRAME ""sandboxing"" prevents the embedded demos ""Run code snippet"" buttons and ""codepen.io example"" from working in some browsers (including Chrome and Microsoft Edge).To develop create your own web page, serve that page over an HTTPS connection to test and develop against.Here is a test/demo page which demonstrates the code working:https://deanmarktaylor.github.io/clipboard-test/Async + FallbackDue to the level of browser support for the new Async Clipboard API, you will likely want to fall back to the document.execCommand('copy') method to get good browser coverage.Here is a simple example (may not work embedded in this site, read ""important"" note above):function fallbackCopyTextToClipboard(text) {  var textArea = document.createElement(""textarea"");  textArea.value = text;    // Avoid scrolling to bottom  textArea.style.top = ""0"";  textArea.style.left = ""0"";  textArea.style.position = ""fixed"";  document.body.appendChild(textArea);  textArea.focus();  textArea.select();  try {    var successful = document.execCommand('copy');    var msg = successful ? 'successful' : 'unsuccessful';    console.log('Fallback: Copying text command was ' + msg);  } catch (err) {    console.error('Fallback: Oops, unable to copy', err);  }  document.body.removeChild(textArea);}function copyTextToClipboard(text) {  if (!navigator.clipboard) {    fallbackCopyTextToClipboard(text);    return;  }  navigator.clipboard.writeText(text).then(function() {    console.log('Async: Copying to clipboard was successful!');  }, function(err) {    console.error('Async: Could not copy text: ', err);  });}var copyBobBtn = document.querySelector('.js-copy-bob-btn'),  copyJaneBtn = document.querySelector('.js-copy-jane-btn');copyBobBtn.addEventListener('click', function(event) {  copyTextToClipboard('Bob');});copyJaneBtn.addEventListener('click', function(event) {  copyTextToClipboard('Jane');});<div style=""display:inline-block; vertical-align:top;"">  <button class=""js-copy-bob-btn"">Set clipboard to BOB</button><br /><br />  <button class=""js-copy-jane-btn"">Set clipboard to JANE</button></div><div style=""display:inline-block;"">  <textarea class=""js-test-textarea"" cols=""35"" rows=""4"">Try pasting into here to see what you have on your clipboard:  </textarea></div>(codepen.io example may not work, read ""important"" note above)Note that this snippet is not working well in Stack Overflow's embedded preview you can try it here: https://codepen.io/DeanMarkTaylor/pen/RMRaJX?editors=1011Async Clipboard APIMDN ReferenceChrome 66 announcement post (March 2018)Reference Async Clipboard API draft documentationNote that there is an ability to ""request permission"" and test for access to the clipboard via the permissions API in Chrome 66.var text = ""Example text to appear on clipboard"";navigator.clipboard.writeText(text).then(function() {  console.log('Async: Copying to clipboard was successful!');}, function(err) {  console.error('Async: Could not copy text: ', err);});document.execCommand('copy')The rest of this post goes into the nuances and detail of the document.execCommand('copy') API.Browser SupportThe JavaScript document.execCommand('copy') support has grown, see the links below for browser updates:  (deprecated) Internet Explorer 10+ (although this document indicates some support was there from Internet Explorer 5.5+).Google Chrome 43+ (~April 2015)Mozilla Firefox 41+ (shipping ~September 2015)Opera 29+ (based on Chromium 42, ~April 2015)Simple Example(may not work embedded in this site, read ""important"" note above)var copyTextareaBtn = document.querySelector('.js-textareacopybtn');copyTextareaBtn.addEventListener('click', function(event) {  var copyTextarea = document.querySelector('.js-copytextarea');  copyTextarea.focus();  copyTextarea.select();  try {    var successful = document.execCommand('copy');    var msg = successful ? 'successful' : 'unsuccessful';    console.log('Copying text command was ' + msg);  } catch (err) {    console.log('Oops, unable to copy');  }});<p>  <button class=""js-textareacopybtn"" style=""vertical-align:top;"">Copy Textarea</button>  <textarea class=""js-copytextarea"">Hello I'm some text</textarea></p>Complex Example: Copy to clipboard without displaying inputThe above simple example works great if there is a textarea or input element visible on the screen.In some cases, you might wish to copy text to the clipboard without displaying an input / textarea element. This is one example of a way to work around this (basically insert an element, copy to clipboard, remove element):Tested with Google Chrome 44, Firefox 42.0a1, and Internet Explorer 11.0.8600.17814.(may not work embedded in this site, read ""important"" note above)function copyTextToClipboard(text) {  var textArea = document.createElement(""textarea"");  //  // *** This styling is an extra step which is likely not required. ***  //  // Why is it here? To ensure:  // 1. the element is able to have focus and selection.  // 2. if the element was to flash render it has minimal visual impact.  // 3. less flakyness with selection and copying which **might** occur if  //    the textarea element is not visible.  //  // The likelihood is the element won't even render, not even a  // flash, so some of these are just precautions. However in  // Internet Explorer the element is visible whilst the popup  // box asking the user for permission for the web page to  // copy to the clipboard.  //  // Place in the top-left corner of screen regardless of scroll position.  textArea.style.position = 'fixed';  textArea.style.top = 0;  textArea.style.left = 0;  // Ensure it has a small width and height. Setting to 1px / 1em  // doesn't work as this gives a negative w/h on some browsers.  textArea.style.width = '2em';  textArea.style.height = '2em';  // We don't need padding, reducing the size if it does flash render.  textArea.style.padding = 0;  // Clean up any borders.  textArea.style.border = 'none';  textArea.style.outline = 'none';  textArea.style.boxShadow = 'none';  // Avoid flash of the white box if rendered for any reason.  textArea.style.background = 'transparent';  textArea.value = text;  document.body.appendChild(textArea);  textArea.focus();  textArea.select();  try {    var successful = document.execCommand('copy');    var msg = successful ? 'successful' : 'unsuccessful';    console.log('Copying text command was ' + msg);  } catch (err) {    console.log('Oops, unable to copy');  }  document.body.removeChild(textArea);}var copyBobBtn = document.querySelector('.js-copy-bob-btn'),  copyJaneBtn = document.querySelector('.js-copy-jane-btn');copyBobBtn.addEventListener('click', function(event) {  copyTextToClipboard('Bob');});copyJaneBtn.addEventListener('click', function(event) {  copyTextToClipboard('Jane');});<div style=""display:inline-block; vertical-align:top;"">  <button class=""js-copy-bob-btn"">Set clipboard to BOB</button><br /><br />  <button class=""js-copy-jane-btn"">Set clipboard to JANE</button></div><div style=""display:inline-block;"">  <textarea class=""js-test-textarea"" cols=""35"" rows=""4"">Try pasting into here to see what you have on your clipboard:  </textarea></div>Additional notesOnly works if the user takes an actionAll document.execCommand('copy') calls must take place as a direct result of a user action, e.g. click event handler. This is a measure to prevent messing with the user's clipboard when they don't expect it.See the Google Developers post here for more info.Clipboard APINote the full Clipboard API draft specification can be found here:https://w3c.github.io/clipboard-apis/Is it supported?document.queryCommandSupported('copy') should return true if the command ""is supported by the browser"".and document.queryCommandEnabled('copy') return true if the document.execCommand('copy') will succeed if called now. Checking to ensure the command was called from a user-initiated thread and other requirements are met.However, as an example of browser compatibility issues, Google Chrome from ~April to ~October 2015 only returned true from document.queryCommandSupported('copy') if the command was called from a user-initiated thread.Note compatibility detail below.Browser Compatibility DetailWhilst a simple call to document.execCommand('copy') wrapped in a try/catch block called as a result of a user click will get you the most compatibility use the following has some provisos:Any call to document.execCommand, document.queryCommandSupported or document.queryCommandEnabled should be wrapped in a try/catch block.Different browser implementations and browser versions throw differing types of exceptions when called instead of returning false.Different browser implementations are still in flux and the Clipboard API is still in draft, so remember to do your testing."
"data_i","edited Jul 18 '22 at 18:38","
        How do I check if a directory exists in a Bash shell script?
    ","What command checks if a directory exists or not within a Bash shell script?","To check if a directory exists:if [ -d ""$DIRECTORY"" ]; then  echo ""$DIRECTORY does exist.""fiTo check if a directory does not exist:if [ ! -d ""$DIRECTORY"" ]; then  echo ""$DIRECTORY does not exist.""fiHowever, as Jon Ericson points out, subsequent commands may not work as intended if you do not take into account that a symbolic link to a directory will also pass this check.E.g. running this:ln -s ""$ACTUAL_DIR"" ""$SYMLINK""if [ -d ""$SYMLINK"" ]; then   rmdir ""$SYMLINK"" fiWill produce the error message:rmdir: failed to remove `symlink': Not a directorySo symbolic links may have to be treated differently, if subsequent commands expect directories:if [ -d ""$LINK_OR_DIR"" ]; then   if [ -L ""$LINK_OR_DIR"" ]; then    # It is a symlink!    # Symbolic link specific commands go here.    rm ""$LINK_OR_DIR""  else    # It's a directory!    # Directory command goes here.    rmdir ""$LINK_OR_DIR""  fifiTake particular note of the double-quotes used to wrap the variables. The reason for this is explained by 8jean in another answer.If the variables contain spaces or other unusual characters it will probably cause the script to fail."
"data_i","edited Jul 10 '22 at 21:41","
        How do I remove a submodule?
    ","How do I remove a Git submodule?Why can't I dogit submodule rm module_name?","In modern git (I'm writing this in 2022, with an updated git installation), this has become quite a bit simpler:Run git rm <path-to-submodule>, and commit.This removes the filetree at <path-to-submodule>, and the submodule's entry in the .gitmodules file. I.e. all traces of the submodule in your repository proper are removed.As the docs note however, the .git dir of the submodule is kept around (in the modules/ directory of the main project's .git dir), ""to make it possible to checkout past commits without requiring fetching from another repository"".If you nonetheless want to remove this info, manually delete the submodule's directory in .git/modules/, and remove the submodule's entry in the file .git/config. These steps can be automated using the commandsrm -rf .git/modules/<path-to-submodule>, andgit config --remove-section submodule.<path-to-submodule>.Older community wiki instructions:Via the page Git Submodule Tutorial:To remove a submodule you need to:Delete the relevant section from the .gitmodules file.Stage the .gitmodules changes:git add .gitmodulesDelete the relevant section from .git/config.Remove the submodule files from the working tree and index:git rm --cached path_to_submodule (no trailing slash).Remove the submodule's .git directory:rm -rf .git/modules/path_to_submoduleCommit the changes:git commit -m ""Removed submodule <name>""Delete the now untracked submodule files:rm -rf path_to_submoduleSee also: alternative steps below."
"data_i","edited Aug 01 '20 at 11:19","
        What are the differences between a HashMap and a Hashtable in Java?
    ","What are the differences between a HashMap and a Hashtable in Java?Which is more efficient for non-threaded applications?","There are several differences between HashMap and Hashtable in Java:Hashtable is synchronized, whereas HashMap is not. This makes HashMap better for non-threaded applications, as unsynchronized Objects typically perform better than synchronized ones.Hashtable does not allow null keys or values.  HashMap allows one null key and any number of null values.One of HashMap's subclasses is LinkedHashMap, so in the event that you'd want predictable iteration order (which is insertion order by default), you could easily swap out the HashMap for a LinkedHashMap.  This wouldn't be as easy if you were using Hashtable.Since synchronization is not an issue for you, I'd recommend HashMap. If synchronization becomes an issue, you may also look at ConcurrentHashMap."
"data_i","edited Mar 28 '22 at 12:01","
        Finding the index of an item in a list
    ","Given a list [""foo"", ""bar"", ""baz""] and an item in the list ""bar"", how do I get its index 1?",">>> [""foo"", ""bar"", ""baz""].index(""bar"")1Reference: Data Structures > More on ListsCaveats followNote that while this is perhaps the cleanest way to answer the question as asked, index is a rather weak component of the list API, and I can't remember the last time I used it in anger. It's been pointed out to me in the comments that because this answer is heavily referenced, it should be made more complete. Some caveats about list.index follow. It is probably worth initially taking a look at the documentation for it:list.index(x[, start[, end]])Return zero-based index in the list of the first item whose value is equal to x. Raises a ValueError if there is no such item.The optional arguments start and end are interpreted as in the slice notation and are used to limit the search to a particular subsequence of the list. The returned index is computed relative to the beginning of the full sequence rather than the start argument.Linear time-complexity in list lengthAn index call checks every element of the list in order, until it finds a match. If your list is long, and you don't know roughly where in the list it occurs, this search could become a bottleneck. In that case, you should consider a different data structure. Note that if you know roughly where to find the match, you can give index a hint. For instance, in this snippet, l.index(999_999, 999_990, 1_000_000) is roughly five orders of magnitude faster than straight l.index(999_999), because the former only has to search 10 entries, while the latter searches a million:>>> import timeit>>> timeit.timeit('l.index(999_999)', setup='l = list(range(0, 1_000_000))', number=1000)9.356267921015387>>> timeit.timeit('l.index(999_999, 999_990, 1_000_000)', setup='l = list(range(0, 1_000_000))', number=1000)0.0004404920036904514 Only returns the index of the first match to its argumentA call to index searches through the list in order until it finds a match, and stops there. If you expect to need indices of more matches, you should use a list comprehension, or generator expression.>>> [1, 1].index(1)0>>> [i for i, e in enumerate([1, 2, 1]) if e == 1][0, 2]>>> g = (i for i, e in enumerate([1, 2, 1]) if e == 1)>>> next(g)0>>> next(g)2Most places where I once would have used index, I now use a list comprehension or generator expression because they're more generalizable. So if you're considering reaching for index, take a look at these excellent Python features.Throws if element not present in listA call to index results in a ValueError if the item's not present.>>> [1, 1].index(2)Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>ValueError: 2 is not in listIf the item might not be present in the list, you should eitherCheck for it first with item in my_list (clean, readable approach), orWrap the index call in a try/except block which catches ValueError (probably faster, at least when the list to search is long, and the item is usually present.)"
"data_i","edited Jul 10 '22 at 23:19","
        What is RESTful programming?
    ","What exactly is RESTful programming?","REST is the underlying architectural principle of the web. The amazing thing about the web is the fact that clients (browsers) and servers can interact in complex ways without the client knowing anything beforehand about the server and the resources it hosts. The key constraint is that the server and client must both agree on the media used, which in the case of the web is HTML.An API that adheres to the principles of REST does not require the client to know anything about the structure of the API. Rather, the server needs to provide whatever information the client needs to interact with the service. An HTML form is an example of this: The server specifies the location of the resource and the required fields. The browser doesn't know in advance where to submit the information, and it doesn't know in advance what information to submit. Both forms of information are entirely supplied by the server. (This principle is called HATEOAS: Hypermedia As The Engine Of Application State.)So, how does this apply to HTTP, and how can it be implemented in practice? HTTP is oriented around verbs and resources. The two verbs in mainstream usage are GET and POST, which I think everyone will recognize. However, the HTTP standard defines several others such as PUT and DELETE. These verbs are then applied to resources, according to the instructions provided by the server.For example, Let's imagine that we have a user database that is managed by a web service. Our service uses a custom hypermedia based on JSON, for which we assign the mimetype application/json+userdb (There might also be an application/xml+userdb and application/whatever+userdb - many media types may be supported). The client and the server have both been programmed to understand this format, but they don't know anything about each other. As Roy Fielding points out:A REST API should spend almost all of its descriptive effort in  defining the media type(s) used for representing resources and driving  application state, or in defining extended relation names and/or  hypertext-enabled mark-up for existing standard media types.A request for the base resource / might return something like this:RequestGET /Accept: application/json+userdbResponse200 OKContent-Type: application/json+userdb{    ""version"": ""1.0"",    ""links"": [        {            ""href"": ""/user"",            ""rel"": ""list"",            ""method"": ""GET""        },        {            ""href"": ""/user"",            ""rel"": ""create"",            ""method"": ""POST""        }    ]}We know from the description of our media that we can find information about related resources from sections called ""links"". This is called Hypermedia controls. In this case, we can tell from such a section that we can find a user list by making another request for /user:RequestGET /userAccept: application/json+userdbResponse200 OKContent-Type: application/json+userdb{    ""users"": [        {            ""id"": 1,            ""name"": ""Emil"",            ""country: ""Sweden"",            ""links"": [                {                    ""href"": ""/user/1"",                    ""rel"": ""self"",                    ""method"": ""GET""                },                {                    ""href"": ""/user/1"",                    ""rel"": ""edit"",                    ""method"": ""PUT""                },                {                    ""href"": ""/user/1"",                    ""rel"": ""delete"",                    ""method"": ""DELETE""                }            ]        },        {            ""id"": 2,            ""name"": ""Adam"",            ""country: ""Scotland"",            ""links"": [                {                    ""href"": ""/user/2"",                    ""rel"": ""self"",                    ""method"": ""GET""                },                {                    ""href"": ""/user/2"",                    ""rel"": ""edit"",                    ""method"": ""PUT""                },                {                    ""href"": ""/user/2"",                    ""rel"": ""delete"",                    ""method"": ""DELETE""                }            ]        }    ],    ""links"": [        {            ""href"": ""/user"",            ""rel"": ""create"",            ""method"": ""POST""        }    ]}We can tell a lot from this response. For instance, we now know we can create a new user by POSTing to /user:RequestPOST /userAccept: application/json+userdbContent-Type: application/json+userdb{    ""name"": ""Karl"",    ""country"": ""Austria""}Response201 CreatedContent-Type: application/json+userdb{    ""user"": {        ""id"": 3,        ""name"": ""Karl"",        ""country"": ""Austria"",        ""links"": [            {                ""href"": ""/user/3"",                ""rel"": ""self"",                ""method"": ""GET""            },            {                ""href"": ""/user/3"",                ""rel"": ""edit"",                ""method"": ""PUT""            },            {                ""href"": ""/user/3"",                ""rel"": ""delete"",                ""method"": ""DELETE""            }        ]    },    ""links"": {       ""href"": ""/user"",       ""rel"": ""list"",       ""method"": ""GET""    }}We also know that we can change existing data:RequestPUT /user/1Accept: application/json+userdbContent-Type: application/json+userdb{    ""name"": ""Emil"",    ""country"": ""Bhutan""}Response200 OKContent-Type: application/json+userdb{    ""user"": {        ""id"": 1,        ""name"": ""Emil"",        ""country"": ""Bhutan"",        ""links"": [            {                ""href"": ""/user/1"",                ""rel"": ""self"",                ""method"": ""GET""            },            {                ""href"": ""/user/1"",                ""rel"": ""edit"",                ""method"": ""PUT""            },            {                ""href"": ""/user/1"",                ""rel"": ""delete"",                ""method"": ""DELETE""            }        ]    },    ""links"": {       ""href"": ""/user"",       ""rel"": ""list"",       ""method"": ""GET""    }}Notice that we are using different HTTP verbs (GET, PUT, POST, DELETE etc.) to manipulate these resources, and that the only knowledge we presume on the client's part is our media definition.Further reading:The many much better answers on this very page.  How I explained REST to my wife. How I explained REST to my wife.  Martin Fowler'sthoughtsPayPal's API has hypermedia controls(This answer has been the subject of a fair amount of criticism for missing the point. For the most part, that has been a fair critique. What I originally described was more in line with how REST was usually implemented a few years ago when I first wrote this, rather than its true meaning. I've revised the answer to better represent the real meaning.)"
"data_i","edited Apr 23 '20 at 19:19","
        How can I pair socks from a pile efficiently?
    ","Yesterday I was pairing the socks from the clean laundry and figured out the way I was doing it is not very efficient. I was doing a naive search — picking one sock and ""iterating"" the pile in order to find its pair. This requires iterating over n/2 * n/4 = n2/8 socks on average.As a computer scientist I was thinking what I could do? Sorting (according to size/color/...) of course came to mind to achieve an O(NlogN) solution.Hashing or other not-in-place solutions are not an option, because I am not able to duplicate my socks (though it could be nice if I could).So, the question is basically:Given a pile of n pairs of socks, containing 2n elements (assume each sock has exactly one matching pair), what is the best way to pair them up efficiently with up to logarithmic extra space? (I believe I can remember that amount of info if needed.)I will appreciate an answer that addresses the following aspects:A general theoretical solution for a huge number of socks.The actual number of socks is not that large, I don't believe my spouse and I have more than 30 pairs. (And it is fairly easy to distinguish between my socks and hers; can this be used as well?)Is it equivalent to the element distinctness problem?","Sorting solutions have been proposed, but sorting is a little too much: We don't need order; we just need equality groups.So hashing would be enough (and faster).For each color of socks, form a pile. Iterate over all socks in your input basket and distribute them onto the color piles.Iterate over each pile and distribute it by some other metric (e.g. pattern) into the second set of pilesRecursively apply this scheme until you have distributed all socks onto very small piles that you can visually process immediatelyThis kind of recursive hash partitioning is actually being done by SQL Server when it needs to hash join or hash aggregate over huge data sets. It distributes its build input stream into many partitions which are independent. This scheme scales to arbitrary amounts of data and multiple CPUs linearly.You don't need recursive partitioning if you can find a distribution key (hash key) that provides enough buckets that each bucket is small enough to be processed very quickly. Unfortunately, I don't think socks have such a property.If each sock had an integer called ""PairID"" one could easily distribute them into 10 buckets according to PairID % 10 (the last digit).The best real-world partitioning I can think of is creating a rectangle of piles: one dimension is color, the other is the pattern. Why a rectangle? Because we need O(1) random-access to piles. (A 3D cuboid would also work, but that is not very practical.)Update:What about parallelism? Can multiple humans match the socks faster?The simplest parallelization strategy is to have multiple workers take from the input basket and put the socks onto the piles. This only scales up so much - imagine 100 people fighting over 10 piles. The synchronization costs (manifesting themselves as hand-collisions and human communication) destroy efficiency and speed-up (see the Universal Scalability Law!). Is this prone to deadlocks? No, because each worker only needs to access one pile at a time. With just one ""lock"" there cannot be a deadlock. Livelocks might be possible depending on how the humans coordinate access to piles. They might just use random backoff like network cards do that on a physical level to determine what card can exclusively access the network wire. If it works for NICs, it should work for humans as well.It scales nearly indefinitely if each worker has its own set of piles. Workers can then take big chunks of socks from the input basket (very little contention as they are doing it rarely) and they do not need to synchronise when distributing the socks at all (because they have thread-local piles). At the end, all workers need to union their pile-sets. I believe that can be done in O(log (worker count * piles per worker)) if the workers form an aggregation tree.What about the element distinctness problem? As the article states, the element distinctness problem can be solved in O(N). This is the same for the socks problem (also O(N), if you need only one distribution step (I proposed multiple steps only because humans are bad at calculations - one step is enough if you distribute on md5(color, length, pattern, ...), i.e. a perfect hash of all attributes)).Clearly, one cannot go faster than O(N), so we have reached the optimal lower bound.Although the outputs are not exactly the same (in one case, just a boolean. In the other case, the pairs of socks), the asymptotic complexities are the same."
"data_i","edited May 01 '22 at 16:21","
        How do I UPDATE from a SELECT in SQL Server?
    ","In SQL Server, it is possible to insert rows into a table with an INSERT.. SELECT statement:INSERT INTO Table (col1, col2, col3)SELECT col1, col2, col3 FROM other_table WHERE sql = 'cool'Is it also possible to update a table with SELECT? I have a temporary table containing the values and would like to update another table using those values. Perhaps something like this:UPDATE Table SET col1, col2SELECT col1, col2 FROM other_table WHERE sql = 'cool'WHERE Table.id = other_table.id","UPDATE    Table_ASET    Table_A.col1 = Table_B.col1,    Table_A.col2 = Table_B.col2FROM    Some_Table AS Table_A    INNER JOIN Other_Table AS Table_B        ON Table_A.id = Table_B.idWHERE    Table_A.col3 = 'cool'"
"data_i","edited Apr 01 '22 at 00:48","
        Iterating over dictionaries using 'for' loops
    ","d = {'x': 1, 'y': 2, 'z': 3}for key in d:    print(key, 'corresponds to', d[key])How does Python recognize that it needs only to read the key from the dictionary? Is key a special keyword, or is it simply a variable?","key is just a variable name.  for key in d:will simply loop over the keys in the dictionary, rather than the keys and values.  To loop over both key and value you can use the following:For Python 3.x:for key, value in d.items():For Python 2.x:for key, value in d.iteritems():To test for yourself, change the word key to poop.In Python 3.x, iteritems() was replaced with simply items(), which returns a set-like view backed by the dict, like iteritems() but even better. This is also available in 2.7 as viewitems(). The operation items() will work for both 2 and 3, but in 2 it will return a list of the dictionary's (key, value) pairs, which will not reflect changes to the dict that happen after the items() call. If you want the 2.x behavior in 3.x, you can call list(d.items())."
"data_i","edited Jul 17 '22 at 00:14","
        Create ArrayList from array
    ","Given an array of type Element[]:Element[] array = {new Element(1), new Element(2), new Element(3)};How do I convert this array into an object of type ArrayList<Element>?ArrayList<Element> arrayList = ???;","new ArrayList<>(Arrays.asList(array));"
"data_i","edited Jul 17 '22 at 00:09","
        grep: show lines surrounding each match
    ","How do I grep and show the preceding and following 5 lines surrounding each matched line?","For BSD or GNU grep you can use -B num to set how many lines before the match and -A num for the number of lines after the match.grep -B 3 -A 2 foo README.txtIf you want the same number of lines before and after you can use -C num.grep -C 3 foo README.txtThis will show 3 lines before and 3 lines after."
"data_i","edited Jul 08 '22 at 04:44","
        How do I delete a commit from a branch?
    ","How do I delete a commit from my branch history?Should I use git reset --hard HEAD?","Careful: git reset --hard WILL DELETE YOUR WORKING DIRECTORY CHANGES. Be sure to stash any local changes you want to keep before running this command.Assuming you are sitting on that commit, then this command will wack it...git reset --hard HEAD~1The HEAD~1 means the commit before head.Or, you could look at the output of git log, find the commit id of the commit you want to back up to, and then do this:git reset --hard <sha1-commit-id>If you already pushed it, you will need to do a force push to get rid of it...git push origin HEAD --forceHowever, if others may have pulled it, then you would be better off starting a new branch.  Because when they pull, it will just merge it into their work, and you will get it pushed back up again.If you already pushed, it may be better to use git revert, to create a ""mirror image"" commit that will undo the changes.  However, both commits will be in the log.FYI -- git reset --hard HEAD is great if you want to get rid of WORK IN PROGRESS.  It will reset you back to the most recent commit, and erase all the changes in your working tree and index.Lastly, if you need to find a commit that you ""deleted"", it is typically present in git reflog unless you have garbage collected your repository."
"data_i","edited Jul 24 '22 at 23:01","
        How do I generate random integers within a specific range in Java?
    ","How do I generate a random int value in a specific range?The following methods have bugs related to integer overflow:randomNum = minimum + (int)(Math.random() * maximum);// Bug: `randomNum` can be bigger than `maximum`.Random rn = new Random();int n = maximum - minimum + 1;int i = rn.nextInt() % n;randomNum =  minimum + i;// Bug: `randomNum` can be smaller than `minimum`.","In Java 1.7 or later, the standard way to do this is as follows:import java.util.concurrent.ThreadLocalRandom;// nextInt is normally exclusive of the top value,// so add 1 to make it inclusiveint randomNum = ThreadLocalRandom.current().nextInt(min, max + 1);See the relevant JavaDoc.  This approach has the advantage of not needing to explicitly initialize a java.util.Random instance, which can be a source of confusion and error if used inappropriately.However, conversely there is no way to explicitly set the seed so it can be difficult to reproduce results in situations where that is useful such as testing or saving game states or similar.  In those situations, the pre-Java 1.7 technique shown below can be used.Before Java 1.7, the standard way to do this is as follows:import java.util.Random;/** * Returns a pseudo-random number between min and max, inclusive. * The difference between min and max can be at most * <code>Integer.MAX_VALUE - 1</code>. * * @param min Minimum value * @param max Maximum value.  Must be greater than min. * @return Integer between min and max, inclusive. * @see java.util.Random#nextInt(int) */public static int randInt(int min, int max) {    // NOTE: This will (intentionally) not run as written so that folks    // copy-pasting have to think about how to initialize their    // Random instance.  Initialization of the Random instance is outside    // the main scope of the question, but some decent options are to have    // a field that is initialized once and then re-used as needed or to    // use ThreadLocalRandom (if using at least Java 1.7).    //     // In particular, do NOT do 'Random rand = new Random()' here or you    // will get not very good / not very random results.    Random rand;    // nextInt is normally exclusive of the top value,    // so add 1 to make it inclusive    int randomNum = rand.nextInt((max - min) + 1) + min;    return randomNum;}See the relevant JavaDoc.  In practice, the java.util.Random class is often preferable to java.lang.Math.random().In particular, there is no need to reinvent the random integer generation wheel when there is a straightforward API within the standard library to accomplish the task."
"data_i","edited Aug 07 '22 at 20:15","
        Undoing a git rebase
    ","How do I easily undo a git rebase? A lengthy manual method is:checkout the commit parent to both of the branchescreate and checkout a temporary branchcherry-pick all commits by handreset the faulty rebased branch to point to the temporary branchIn my current situation, this works because I can easily spot commits from both branches (one was my stuff, the other was my colleague's stuff). However, my approach strikes me as suboptimal and error-prone (let's say I had just rebased with two of my own branches).Clarification: I am talking about a rebase during which multiple commits were replayed, not only one.","The easiest way would be to find the head commit of the branch as it was immediately before the rebase started in the reflog...git reflogand to reset the current branch to it (with the usual caveats about being absolutely sure before reseting with the --hard option).Suppose the old commit was HEAD@{2} in the ref log:git reset --hard HEAD@{2}In Windows, you may need to quote the reference:git reset --hard ""HEAD@{2}""You can check the history of the candidate old head by just doing a git log HEAD@{2} (Windows: git log ""HEAD@{2}"").If you've not disabled per branch reflogs you should be able to simply do git reflog branchname@{1} as a rebase detaches the branch head before reattaching to the final head. I would double check this, though as I haven't verified this recently.Per default, all reflogs are activated for non-bare repositories:[core]    logAllRefUpdates = true"
"data_i","edited Aug 13 '13 at 21:20","
        What is the !! (not not) operator in JavaScript?
    ","I saw some code that seems to use an operator I don't recognize, in the form of two exclamation points, like so: !!. Can someone please tell me what this operator does?The context in which I saw this was,this.vertical = vertical !== undefined ? !!vertical : this.vertical;","It converts Object to boolean. If it was falsey (e.g., 0, null, undefined, etc.), it would be false, otherwise, true.!object  // Inverted Boolean!!object // Noninverted Boolean, so true Boolean representationSo !! is not an operator; it's just the ! operator twice.It may be simpler to do:Boolean(object) // BooleanReal World Example ""Test IE version"":const isIE8 = !! navigator.userAgent.match(/MSIE 8.0/);console.log(isIE8); // Returns true or falseIf you ⇒console.log(navigator.userAgent.match(/MSIE 8.0/));// Returns either an Array or nullBut if you ⇒console.log(!!navigator.userAgent.match(/MSIE 8.0/));// Returns either true or false"
"data_i","edited Sep 07 '18 at 08:21","
        Proper use cases for Android UserManager.isUserAGoat()?
    ","I was looking at the new APIs introduced in Android 4.2.While looking at the UserManager class I came across the following method:public boolean isUserAGoat()Used to determine whether the user making this call is subject to teleportations.Returns whether the user making this call is a goat.How and when should this be used?","Android R Update:From Android R, this method always returns false. Google says that this is done ""to protect goat privacy"":/** * Used to determine whether the user making this call is subject to * teleportations. * * <p>As of {@link android.os.Build.VERSION_CODES#LOLLIPOP}, this method can * now automatically identify goats using advanced goat recognition technology.</p> * * <p>As of {@link android.os.Build.VERSION_CODES#R}, this method always returns * {@code false} in order to protect goat privacy.</p> * * @return Returns whether the user making this call is a goat. */public boolean isUserAGoat() {    if (mContext.getApplicationInfo().targetSdkVersion >= Build.VERSION_CODES.R) {        return false;    }    return mContext.getPackageManager()            .isPackageAvailable(""com.coffeestainstudios.goatsimulator"");}Previous answer:From their source, the method used to return false until it was changed in API 21./** * Used to determine whether the user making this call is subject to * teleportations. * @return whether the user making this call is a goat  */public boolean isUserAGoat() {    return false;}It looks like the method has no real use for us as developers. Someone has previously stated that it might be an Easter egg.In API 21 the implementation was changed to check if there is an installed app with the package com.coffeestainstudios.goatsimulator/** * Used to determine whether the user making this call is subject to * teleportations. * * <p>As of {@link android.os.Build.VERSION_CODES#LOLLIPOP}, this method can * now automatically identify goats using advanced goat recognition technology.</p> * * @return Returns true if the user making this call is a goat. */public boolean isUserAGoat() {    return mContext.getPackageManager()            .isPackageAvailable(""com.coffeestainstudios.goatsimulator"");}Here is the source and the change."
"data_i","edited May 04 '22 at 13:51","
        How can I validate an email address using a regular expression?
    ","Over the years I have slowly developed a regular expression that validates most email addresses correctly, assuming they don't use an IP address as the server part.I use it in several PHP programs, and it works most of the time.  However, from time to time I get contacted by someone that is having trouble with a site that uses it, and I end up having to make some adjustment (most recently I realized that I wasn't allowing four-character TLDs).What is the best regular expression you have or have seen for validating emails?I've seen several solutions that use functions that use several shorter expressions, but I'd rather have one long complex expression in a simple function instead of several short expression in a more complex function.","The fully RFC 822 compliant regex is inefficient and obscure because of its length.  Fortunately, RFC 822 was superseded twice and the current specification for email addresses is RFC 5322.  RFC 5322 leads to a regex that can be understood if studied for a few minutes and is efficient enough for actual use.One RFC 5322 compliant regex can be found at the top of the page at http://emailregex.com/ but uses the IP address pattern that is floating around the internet with a bug that allows 00 for any of the unsigned byte decimal values in a dot-delimited address, which is illegal.  The rest of it appears to be consistent with the RFC 5322 grammar and passes several tests using grep -Po, including cases domain names, IP addresses, bad ones, and account names with and without quotes.Correcting the 00 bug in the IP pattern, we obtain a working and fairly fast regex.  (Scrape the rendered version, not the markdown, for actual code.)(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|""(?:[\x01-\x08\x0b\x0c\x0e-\x1f\x21\x23-\x5b\x5d-\x7f]|\\[\x01-\x09\x0b\x0c\x0e-\x7f])*"")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\[(?:(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9]))\.){3}(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9])|[a-z0-9-]*[a-z0-9]:(?:[\x01-\x08\x0b\x0c\x0e-\x1f\x21-\x5a\x53-\x7f]|\\[\x01-\x09\x0b\x0c\x0e-\x7f])+)\])or:(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|""(?:[\x01-\x08\x0b\x0c\x0e-\x1f\x21\x23-\x5b\x5d-\x7f]|\\[\x01-\x09\x0b\x0c\x0e-\x7f])*"")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\[(?:(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9]))\.){3}(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9])|[a-z0-9-]*[a-z0-9]:(?:[\x01-\x08\x0b\x0c\x0e-\x1f\x21-\x5a\x53-\x7f]|\\[\x01-\x09\x0b\x0c\x0e-\x7f])+)\])Here is diagram of finite state machine for above regexp which is more clear than regexp itselfThe more sophisticated patterns in Perl and PCRE (regex library used e.g. in PHP) can correctly parse RFC 5322 without a hitch. Python and C# can do that too, but they use a different syntax from those first two. However, if you are forced to use one of the many less powerful pattern-matching languages, then it’s best to use a real parser.It's also important to understand that validating it per the RFC tells you absolutely nothing about whether that address actually exists at the supplied domain, or whether the person entering the address is its true owner. People sign others up to mailing lists this way all the time. Fixing that requires a fancier kind of validation that involves sending that address a message that includes a confirmation token meant to be entered on the same web page as was the address.Confirmation tokens are the only way to know you got the address of the person entering it. This is why most mailing lists now use that mechanism to confirm sign-ups. After all, anybody can put down president@whitehouse.gov, and that will even parse as legal, but it isn't likely to be the person at the other end.For PHP, you should not use the pattern given in Validate an E-Mail Address with PHP, the Right Way from which I quote:There is some danger that common usage and widespread sloppy coding will establish a de facto standard for e-mail addresses that is more restrictive than the recorded formal standard.That is no better than all the other non-RFC patterns. It isn’t even smart enough to handle even RFC 822, let alone RFC 5322. This one, however, is.If you want to get fancy and pedantic, implement a complete state engine. A regular expression can only act as a rudimentary filter. The problem with regular expressions is that telling someone that their perfectly valid e-mail address is invalid (a false positive) because your regular expression can't handle it is just rude and impolite from the user's perspective. A state engine for the purpose can both validate and even correct e-mail addresses that would otherwise be considered invalid as it disassembles the e-mail address according to each RFC. This allows for a potentially more pleasing experience, likeThe specified e-mail address 'myemail@address,com' is invalid. Did you mean 'myemail@address.com'?See also Validating Email Addresses, including the comments. Or Comparing E-mail Address Validating Regular Expressions.Debuggex Demo"
"data_i","edited Mar 07 '22 at 12:49","
        How to insert an item into an array at a specific index (JavaScript)
    ","I am looking for a JavaScript array insert method, in the style of:arr.insert(index, item)Preferably in jQuery, but any JavaScript implementation will do at this point.","You want the splice function on the native array object.arr.splice(index, 0, item); will insert item into arr at the specified index (deleting 0 items first, that is, it's just an insert).In this example we will create an array and add an element to it into index 2:var arr = [];arr[0] = ""Jani"";arr[1] = ""Hege"";arr[2] = ""Stale"";arr[3] = ""Kai Jim"";arr[4] = ""Borge"";console.log(arr.join()); // Jani,Hege,Stale,Kai Jim,Borgearr.splice(2, 0, ""Lene"");console.log(arr.join()); // Jani,Hege,Lene,Stale,Kai Jim,Borge"
"data_i","edited Jan 17 '20 at 13:22","
        How do I test for an empty JavaScript object?
    ","After an AJAX request, sometimes my application may return an empty object, like:var a = {};How can I check whether that's the case?","ECMA 5+:// because Object.keys(new Date()).length === 0;// we have to do some additional checkobj //  null and undefined check&& Object.keys(obj).length === 0&& Object.getPrototypeOf(obj) === Object.prototypeNote, though, that this creates an unnecessary array (the return value of keys).Pre-ECMA 5:function isEmpty(obj) {  for(var prop in obj) {    if(Object.prototype.hasOwnProperty.call(obj, prop)) {      return false;    }  }  return JSON.stringify(obj) === JSON.stringify({});}jQuery:jQuery.isEmptyObject({}); // truelodash:_.isEmpty({}); // trueUnderscore:_.isEmpty({}); // trueHoekHoek.deepEqual({}, {}); // trueExtJSExt.Object.isEmpty({}); // trueAngularJS (version 1)angular.equals({}, {}); // trueRamdaR.isEmpty({}); // true"
"data_i","edited May 23 '14 at 19:39","
        Make an existing Git branch track a remote branch?
    ","I know how to make a new branch that tracks remote branches, but how do I make an existing branch track a remote branch?I know I can just edit the .git/config file, but it seems there should be an easier way.","Given a branch foo and a remote upstream:As of Git 1.8.0:git branch -u upstream/fooOr, if local branch foo is not the current branch:git branch -u upstream/foo fooOr, if you like to type longer commands, these are equivalent to the above two:git branch --set-upstream-to=upstream/foogit branch --set-upstream-to=upstream/foo fooAs of Git 1.7.0 (before 1.8.0):git branch --set-upstream foo upstream/fooNotes:All of the above commands will cause local branch foo to track remote branch foo from remote upstream.The old (1.7.x) syntax is deprecated in favor of the new (1.8+) syntax.  The new syntax is intended to be more intuitive and easier to remember.Defining an upstream branch will fail when run against newly-created remotes that have not already been fetched. In that case, run git fetch upstream beforehand.See also: Why do I need to do `--set-upstream` all the time?"
"data_i","edited May 22 '22 at 05:10","
        Is there a CSS parent selector?
    ","How do I select the <li> element that is a direct parent of the anchor element?As an example, my CSS would be something like this:li < a.active {    property: value;}Obviously there are ways of doing this with JavaScript, but I'm hoping that there is some sort of workaround that exists native to CSS Level 2.The menu that I am trying to style is being spewed out by a CMS, so I can't move the active element to the <li> element... (unless I theme the menu creation module which I'd rather not do).","There is currently no way to select the parent of an element in CSS in a way that works across all browsers.That said, the Selectors Level 4 Working Draft includes a :has() pseudo-class that will provide this capability. It will be similar to the jQuery implementation.li:has(> a.active) { /* styles to apply to the li tag */ }As of 2022, it is only supported by Safari, and by Chromium browsers behind a flag.In the meantime, you'll have to resort to JavaScript if you need to select a parent element with full cross-browser support."
"data_i","edited Mar 08 '20 at 06:31","
        How do I efficiently iterate over each entry in a Java Map?
    ","If I have an object implementing the Map interface in Java and I wish to iterate over every pair contained within it,  what is the most efficient way of going through the map?Will the ordering of elements depend on the specific map implementation that I have for the interface?","Map<String, String> map = ...for (Map.Entry<String, String> entry : map.entrySet()) {    System.out.println(entry.getKey() + ""/"" + entry.getValue());}On Java 10+:for (var entry : map.entrySet()) {    System.out.println(entry.getKey() + ""/"" + entry.getValue());}"
"data_i","edited May 08 '22 at 17:25","
        Loop through an array in JavaScript
    ","In Java, you can use a for loop to traverse objects in an array as follows:String[] myStringArray = {""Hello"", ""World""};for (String s : myStringArray) {    // Do something}Can I do the same in JavaScript?","Three main options:for (var i = 0; i < xs.length; i++) { console.log(xs[i]); }xs.forEach((x, i) => console.log(x));for (const x of xs) { console.log(x); }Detailed examples are below.1. Sequential for loop:var myStringArray = [""Hello"",""World""];var arrayLength = myStringArray.length;for (var i = 0; i < arrayLength; i++) {    console.log(myStringArray[i]);    //Do something}ProsWorks on every environmentYou can use break and continue flow control statementsConsToo verboseImperativeEasy to have off-by-one errors (sometimes also called a fence post error)2. Array.prototype.forEach:The ES5 specification introduced a lot of beneficial array methods. One of them, the Array.prototype.forEach, gave us a concise way to iterate over an array:const array = [""one"", ""two"", ""three""]array.forEach(function (item, index) {  console.log(item, index);});Being almost ten years as the time of writing that the ES5 specification was released (Dec. 2009), it has been implemented by nearly all modern engines in the desktop, server, and mobile environments, so it's safe to use them.And with the ES6 arrow function syntax, it's even more succinct:array.forEach(item => console.log(item));Arrow functions are also widely implemented unless you plan to support ancient platforms (e.g., Internet Explorer 11); you are also safe to go.ProsVery short and succinct.DeclarativeConsCannot use break / continueNormally, you can replace the need to break out of imperative loops by filtering the array elements before iterating them, for example:array.filter(item => item.condition < 10)     .forEach(item => console.log(item))Keep in mind if you are iterating an array to build another array from it, you should use map. I've seen this anti-pattern so many times.Anti-pattern:const numbers = [1,2,3,4,5], doubled = [];numbers.forEach((n, i) => { doubled[i] = n * 2 });Proper use case of map:const numbers = [1,2,3,4,5];const doubled = numbers.map(n => n * 2);console.log(doubled);Also, if you are trying to reduce the array to a value, for example, you want to sum an array of numbers, you should use the reduce method.Anti-pattern:const numbers = [1,2,3,4,5];const sum = 0;numbers.forEach(num => { sum += num });Proper use of reduce:const numbers = [1,2,3,4,5];const sum = numbers.reduce((total, n) => total + n, 0);console.log(sum);3. ES6 for-of statement:The ES6 standard introduces the concept of iterable objects and defines a new construct for traversing data, the for...of statement.This statement works for any kind of iterable object and also for generators (any object that has a \[Symbol.iterator\] property).Array objects are by definition built-in iterables in ES6, so you can use this statement on them:let colors = ['red', 'green', 'blue'];for (const color of colors){    console.log(color);}ProsIt can iterate over a large variety of objects.Can use normal flow control statements (break / continue).Useful to iterate serially asynchronous values.ConsIf you are targeting older browsers, the transpiled output might surprise you.Do not use for...in@zipcodeman suggests the use of the for...in statement, but for iterating arrays for-in should be avoided, that statement is meant to enumerate object properties.It shouldn't be used for array-like objects because:The order of iteration is not guaranteed; the array indexes may not be visited in numeric order.Inherited properties are also enumerated.The second point is that it can give you a lot of problems, for example, if you extend the Array.prototype object to include a method there, that property will also be enumerated.For example:Array.prototype.foo = ""foo!"";var array = ['a', 'b', 'c'];for (var i in array) {    console.log(array[i]);}The above code will console log ""a"", ""b"", ""c"", and ""foo!"".That can be particularly a problem if you use some library that relies heavily on native prototypes augmentation (such as MooTools).The for-in statement, as I said before, is there to enumerate object properties, for example:var obj = {    ""a"": 1,    ""b"": 2,    ""c"": 3};for (var prop in obj) {    if (obj.hasOwnProperty(prop)) {        // or if (Object.prototype.hasOwnProperty.call(obj,prop)) for safety...        console.log(""prop: "" + prop + "" value: "" + obj[prop])    }}In the above example, the hasOwnProperty method allows you to enumerate only own properties. That's it, only the properties that the object physically has, no inherited properties.I would recommend you to read the following article:Enumeration VS Iteration"
"data_i","edited Sep 11 '18 at 07:37","
        Why don't Java's +=, -=, *=, /= compound assignment operators require casting?
    ","Until today, I thought that for example:i += j;Was just a shortcut for:i = i + j;But if we try this:int i = 5;long j = 8;Then i = i + j; will not compile but i += j; will compile fine.Does it mean that in fact i += j; is a shortcut for something like thisi = (type of i) (i + j)?","As always with these questions, the JLS holds the answer. In this case §15.26.2 Compound Assignment Operators. An extract:A compound assignment expression of the form E1 op= E2 is equivalent to E1 = (T)((E1) op (E2)), where T is the type of E1, except that E1 is evaluated only once.An example cited from §15.26.2[...] the following code is correct:short x = 3;x += 4.6;and results in x having the value 7 because it is equivalent to:short x = 3;x = (short)(x + 4.6);In other words, your assumption is correct."
"data_i","edited Jan 30 '20 at 09:24","
        Checking if a key exists in a JavaScript object?
    ","How do I check if a particular key exists in a JavaScript object or array?If a key doesn't exist, and I try to access it, will it return false? Or throw an error?","Checking for undefined-ness is not an accurate way of testing whether a key exists. What if the key exists but the value is actually undefined?var obj = { key: undefined };console.log(obj[""key""] !== undefined); // false, but the key exists!You should instead use the in operator:var obj = { key: undefined };console.log(""key"" in obj); // true, regardless of the actual valueIf you want to check if a key doesn't exist, remember to use parenthesis:var obj = { not_key: undefined };console.log(!(""key"" in obj)); // true if ""key"" doesn't exist in objectconsole.log(!""key"" in obj);   // Do not do this! It is equivalent to ""false in obj""Or, if you want to particularly test for properties of the object instance (and not inherited properties), use hasOwnProperty:var obj = { key: undefined };console.log(obj.hasOwnProperty(""key"")); // trueFor performance comparison between the methods that are in, hasOwnProperty and key is undefined, see this benchmark:"
"data_i","edited Jul 17 '22 at 00:23","
        How do I tell if a file does not exist in Bash?
    ","This checks if a file exists:#!/bin/bashFILE=$1     if [ -f $FILE ]; then   echo ""File $FILE exists.""else   echo ""File $FILE does not exist.""fiHow do I only check if the file does not exist?","The test command (written as [ here) has a ""not"" logical operator, ! (exclamation mark):if [ ! -f /tmp/foo.txt ]; then    echo ""File not found!""fi"
"data_i","edited Jun 10 '20 at 18:08","
        Sort array of objects by string property value
    ","I have an array of JavaScript objects:var objs = [     { first_nom: 'Lazslo', last_nom: 'Jamf'     },    { first_nom: 'Pig',    last_nom: 'Bodine'   },    { first_nom: 'Pirate', last_nom: 'Prentice' }];How can I sort them by the value of last_nom in JavaScript?I know about sort(a,b), but that only seems to work on strings and numbers. Do I need to add a toString() method to my objects?","It's easy enough to write your own comparison function:function compare( a, b ) {  if ( a.last_nom < b.last_nom ){    return -1;  }  if ( a.last_nom > b.last_nom ){    return 1;  }  return 0;}objs.sort( compare );Or inline (c/o Marco Demaio):objs.sort((a,b) => (a.last_nom > b.last_nom) ? 1 : ((b.last_nom > a.last_nom) ? -1 : 0))Or simplified for numeric (c/o Andre Figueiredo):objs.sort((a,b) => a.last_nom - b.last_nom); // b - a for reverse sort"
"data_i","edited Dec 25 '21 at 22:18","
        Message 'src refspec master does not match any' when pushing commits in Git
    ","I clone my repository with:git clone ssh://xxxxx/xx.git But after I change some files and add and commit them, I want to push them to the server:git add xxx.phpgit commit -m ""TEST""git push origin masterBut the error I get back is:error: src refspec master does not match any.  error: failed to push some refs to 'ssh://xxxxx.com/project.git'","Maybe you just need to commit. I ran into this when I did:mkdir repo && cd repogit remote add origin /path/to/origin.gitgit add .Oops! Never committed!git push -u origin mastererror: src refspec master does not match any.All I had to do was:git commit -m ""initial commit""git push origin mainSuccess!"
"data_i","edited Jul 04 '22 at 20:58","
        What are the differences between a pointer variable and a reference variable?
    ","What is the difference between a pointer variable and a reference variable?","A pointer can be re-assigned:int x = 5;int y = 6;int *p;p = &x;p = &y;*p = 10;assert(x == 5);assert(y == 10);A reference cannot be re-bound, and must be bound at initialization:int x = 5;int y = 6;int &q; // errorint &r = x;A pointer variable has its own identity: a distinct, visible memory address that can be taken with the unary & operator and a certain amount of space that can be measured with the sizeof operator. Using those operators on a reference returns a value corresponding to whatever the reference is bound to; the reference’s own address and size are invisible. Since the reference assumes the identity of the original variable in this way, it is convenient to think of a reference as another name for the same variable.int x = 0;int &r = x;int *p = &x;int *p2 = &r;assert(p == p2); // &x == &rassert(&p != &p2);You can have arbitrarily nested pointers to pointers offering extra levels of indirection. References only offer one level of indirection.int x = 0;int y = 0;int *p = &x;int *q = &y;int **pp = &p;**pp = 2;pp = &q; // *pp is now q**pp = 4;assert(y == 4);assert(x == 2);A pointer can be assigned nullptr, whereas a reference must be bound to an existing object. If you try hard enough, you can bind a reference to nullptr, but this is undefined and will not behave consistently./* the code below is undefined; your compiler may optimise it * differently, emit warnings, or outright refuse to compile it */int &r = *static_cast<int *>(nullptr);// prints ""null"" under GCC 10std::cout    << (&r != nullptr        ? ""not null"" : ""null"")    << std::endl;bool f(int &r) { return &r != nullptr; }// prints ""not null"" under GCC 10std::cout    << (f(*static_cast<int *>(nullptr))        ? ""not null"" : ""null"")    << std::endl;You can, however, have a reference to a pointer whose value is nullptr.Pointers can iterate over an array; you can use ++ to go to the next item that a pointer is pointing to, and + 4 to go to the 5th element.  This is no matter what size the object is that the pointer points to.A pointer needs to be dereferenced with * to access the memory location it points to, whereas a reference can be used directly.  A pointer to a class/struct uses -> to access its members whereas a reference uses a ..References cannot be put into an array, whereas pointers can be (Mentioned by user @litb)Const references can be bound to temporaries. Pointers cannot (not without some indirection):const int &x = int(12); // legal C++int *y = &int(12); // illegal to take the address of a temporary.This makes const & more convenient to use in argument lists and so forth."
"data_i","edited May 05 '22 at 15:28","
        How to round to at most 2 decimal places, if necessary
    ","I'd like to round at most two decimal places, but only if necessary.Input:101.77777779.1Output:101.789.1How can I do this in JavaScript?","Use Math.round() :Math.round(num * 100) / 100Or to be more specific and to ensure things like 1.005 round correctly, use Number.EPSILON  :Math.round((num + Number.EPSILON) * 100) / 100"
"data_i","edited Jan 13 '17 at 11:48","
        Why is char[] preferred over String for passwords?
    ","In Swing, the password field has a getPassword() (returns char[]) method instead of the usual getText() (returns String) method. Similarly, I have come across a suggestion not to use String to handle passwords.Why does String pose a threat to security when it comes to passwords?It feels inconvenient to use char[].","Strings are immutable. That means once you've created the String, if another process can dump memory, there's no way (aside from reflection) you can get rid of the data before garbage collection kicks in.With an array, you can explicitly wipe the data after you're done with it. You can overwrite the array with anything you like, and the password won't be present anywhere in the system, even before garbage collection.So yes, this is a security concern - but even using char[] only reduces the window of opportunity for an attacker, and it's only for this specific type of attack.As noted in the comments, it's possible that arrays being moved by the garbage collector will leave stray copies of the data in memory. I believe this is implementation-specific - the garbage collector may clear all memory as it goes, to avoid this sort of thing. Even if it does, there's still the time during which the char[] contains the actual characters as an attack window."
"data_i","edited Sep 09 '22 at 14:53","
        Using global variables in a function
    ","How do I create or use a global variable inside a function?How do I use a global variable that was defined in one function inside other functions?Failing to use the global keyword where appropriate often causes UnboundLocalError. The precise rules for this are explained at UnboundLocalError on local variable when reassigned after first use. Generally, please close other questions as a duplicate of that question when an explanation is sought, and this question when someone simply needs to know the global keyword.","You can use a global variable within other functions by declaring it as global within each function that assigns a value to it:globvar = 0def set_globvar_to_one():    global globvar    # Needed to modify global copy of globvar    globvar = 1def print_globvar():    print(globvar)     # No need for global declaration to read value of globvarset_globvar_to_one()print_globvar()       # Prints 1Since it's unclear whether globvar = 1 is creating a local variable or changing a global variable, Python defaults to creating a local variable, and makes you explicitly choose the other behavior with the global keyword.See other answers if you want to share a global variable across modules."
"data_i","edited Jul 10 '22 at 23:22","
        How do I cast int to enum in C#?
    ","How do I cast an int to an enum in C#?","From an int:YourEnum foo = (YourEnum)yourInt;From a string:YourEnum foo = (YourEnum) Enum.Parse(typeof(YourEnum), yourString);// The foo.ToString().Contains("","") check is necessary for // enumerations marked with a [Flags] attribute.if (!Enum.IsDefined(typeof(YourEnum), foo) && !foo.ToString().Contains("","")){    throw new InvalidOperationException(        $""{yourString} is not an underlying value of the YourEnum enumeration.""    );}From a number:YourEnum foo = (YourEnum)Enum.ToObject(typeof(YourEnum), yourInt);"
"data_i","edited Sep 15 '21 at 15:53","
        How do I clone a specific Git branch?
    ","Git clone will clone remote branch into local.Is there any way to clone a specific branch by myself without switching branches on the remote repository?","git clone -b <branch> <remote_repo>Example:git clone -b my-branch git@github.com:user/myproject.gitWith Git 1.7.10 and later, add --single-branch to prevent fetching of all branches. Example, with OpenCV 2.4 branch:git clone -b opencv-2.4 --single-branch https://github.com/Itseez/opencv.git"
"data_i","edited Apr 29 '19 at 14:53","
        Is floating point math broken?
    ","Consider the following code:0.1 + 0.2 == 0.3  ->  false0.1 + 0.2         ->  0.30000000000000004Why do these inaccuracies happen?","Binary floating point math is like this. In most programming languages, it is based on the IEEE 754 standard. The crux of the problem is that numbers are represented in this format as a whole number times a power of two; rational numbers (such as 0.1, which is 1/10) whose denominator is not a power of two cannot be exactly represented.For 0.1 in the standard binary64 format, the representation can be written exactly as0.1000000000000000055511151231257827021181583404541015625 in decimal, or0x1.999999999999ap-4 in C99 hexfloat notation.In contrast, the rational number 0.1, which is 1/10, can be written exactly as0.1 in decimal, or0x1.99999999999999...p-4 in an analogue of C99 hexfloat notation, where the ... represents an unending sequence of 9's.The constants 0.2 and 0.3 in your program will also be approximations to their true values.  It happens that the closest double to 0.2 is larger than the rational number 0.2 but that the closest double to 0.3 is smaller than the rational number 0.3.  The sum of 0.1 and 0.2 winds up being larger than the rational number 0.3 and hence disagreeing with the constant in your code.A fairly comprehensive treatment of floating-point arithmetic issues is What Every Computer Scientist Should Know About Floating-Point Arithmetic. For an easier-to-digest explanation, see floating-point-gui.de.Side Note: All positional (base-N) number systems share this problem with precisionPlain old decimal (base 10) numbers have the same issues, which is why numbers like 1/3 end up as 0.333333333...You've just stumbled on a number (3/10) that happens to be easy to represent with the decimal system, but doesn't fit the binary system. It goes both ways (to some small degree) as well: 1/16 is an ugly number in decimal (0.0625), but in binary it looks as neat as a 10,000th does in decimal (0.0001)** - if we were in the habit of using a base-2 number system in our daily lives, you'd even look at that number and instinctively understand you could arrive there by halving something, halving it again, and again and again.** Of course, that's not exactly how floating-point numbers are stored in memory (they use a form of scientific notation). However, it does illustrate the point that binary floating-point precision errors tend to crop up because the ""real world"" numbers we are usually interested in working with are so often powers of ten - but only because we use a decimal number system day-to-day. This is also why we'll say things like 71% instead of ""5 out of every 7"" (71% is an approximation, since 5/7 can't be represented exactly with any decimal number).So no: binary floating point numbers are not broken, they just happen to be as imperfect as every other base-N number system :)Side Side Note: Working with Floats in ProgrammingIn practice, this problem of precision means you need to use rounding functions to round your floating point numbers off to however many decimal places you're interested in before you display them.You also need to replace equality tests with comparisons that allow some amount of tolerance, which means:Do not do if (x == y) { ... }Instead do if (abs(x - y) < myToleranceValue) { ... }.where abs is the absolute value. myToleranceValue needs to be chosen for your particular application - and it will have a lot to do with how much ""wiggle room"" you are prepared to allow, and what the largest number you are going to be comparing may be (due to loss of precision issues). Beware of ""epsilon"" style constants in your language of choice. These are not to be used as tolerance values."
"data_i","edited Oct 09 '17 at 05:01","
        Move existing, uncommitted work to a new branch in Git
    ","I started some work on a new feature and after coding for a bit, I decided this feature should be on its own branch. How do I move the existing uncommitted changes to a new branch and reset my current one?I want to reset my current branch while preserving existing work on the new feature.","Update 2020 / Git 2.23Git 2.23 adds the new switch subcommand in an attempt to clear some of the confusion that comes from the overloaded usage of checkout (switching branches, restoring files, detaching HEAD, etc.)Starting with this version of Git, replace the checkout command with:git switch -c <new-branch>The behavior is identical and remains unchanged.Before Update 2020 / Git 2.23Use the following:git checkout -b <new-branch>This will leave your current branch as it is, create and checkout a new branch and keep all your changes. You can then stage changes in files to commit with:git add <files>and commit to your new branch with:git commit -m ""<Brief description of this commit>""The changes in the working directory and changes staged in index do not belong to any branch yet. This changes the branch where those modifications would end in.You don't reset your original branch, it stays as it is. The last commit on <old-branch> will still be the same. Therefore you checkout -b and then commit."
"data_i","edited Oct 29 '19 at 16:00","
        Iterate through a HashMap
    ","What's the best way to iterate over the items in a HashMap?","If you're only interested in the keys, you can iterate through the keySet() of the map:Map<String, Object> map = ...;for (String key : map.keySet()) {    // ...}If you only need the values, use values():for (Object value : map.values()) {    // ...}Finally, if you want both the key and value, use entrySet():for (Map.Entry<String, Object> entry : map.entrySet()) {    String key = entry.getKey();    Object value = entry.getValue();    // ...}One caveat: if you want to remove items mid-iteration, you'll need to do so via an Iterator (see karim79's answer). However, changing item values is OK (see Map.Entry)."
"data_i","edited Jul 24 '22 at 23:18","
        How do I check for an empty/undefined/null string in JavaScript?
    ","Is there a string.Empty in JavaScript, or is it just a case of checking for """"?","Empty string, undefined, null, ...To check for a truthy value:if (strValue) {    // strValue was non-empty string, true, 42, Infinity, [], ...}To check for a falsy value:if (!strValue) {    // strValue was empty string, false, 0, null, undefined, ...}Empty string (only!)To check for exactly an empty string, compare for strict equality against """" using the === operator:if (strValue === """") {    // strValue was empty string}To check for not an empty string strictly, use the !== operator:if (strValue !== """") {    // strValue was not an empty string}"
"data_i","edited Aug 09 '21 at 23:43","
        How can I create a memory leak in Java?
    ","I just had an interview where I was asked to create a memory leak with Java.Needless to say, I felt pretty dumb having no clue on how to even start creating one.What would an example be?","Here's a good way to create a true memory leak (objects inaccessible by running code but still stored in memory) in pure Java:The application creates a long-running thread (or use a thread pool to leak even faster).The thread loads a class via an (optionally custom) ClassLoader.The class allocates a large chunk of memory (e.g. new byte[1000000]), stores a strong reference to it in a static field, and then stores a reference to itself in a ThreadLocal.  Allocating the extra memory is optional (leaking the class instance is enough), but it will make the leak work that much faster.The application clears all references to the custom class or the ClassLoader it was loaded from.Repeat.Due to the way ThreadLocal is implemented in Oracle's JDK, this creates a memory leak:Each Thread has a private field threadLocals, which actually stores the thread-local values.Each key in this map is a weak reference to a ThreadLocal object, so after that ThreadLocal object is garbage-collected, its entry is removed from the map.But each value is a strong reference, so when a value (directly or indirectly) points to the ThreadLocal object that is its key, that object will neither be garbage-collected nor removed from the map as long as the thread lives.In this example, the chain of strong references looks like this:Thread object → threadLocals map → instance of example class → example class → static ThreadLocal field → ThreadLocal object.(The ClassLoader doesn't really play a role in creating the leak, it just makes the leak worse because of this additional reference chain: example class → ClassLoader → all the classes it has loaded. It was even worse in many JVM implementations, especially prior to Java 7, because classes and ClassLoaders were allocated straight into permgen and were never garbage-collected at all.)A variation on this pattern is why application containers (like Tomcat) can leak memory like a sieve if you frequently redeploy applications which happen to use ThreadLocals that in some way point back to themselves. This can happen for a number of subtle reasons and is often hard to debug and/or fix.Update: Since lots of people keep asking for it, here's some example code that shows this behavior in action."
"data_i","edited Jun 06 '18 at 19:40","
        Set cellpadding and cellspacing in CSS?
    ","In an HTML table, the cellpadding and cellspacing can be set like this:<table cellspacing=""1"" cellpadding=""1"">How can the same be accomplished using CSS?","BasicsFor controlling ""cellpadding"" in CSS, you can simply use padding on table cells. E.g. for 10px of ""cellpadding"":td {     padding: 10px;}For ""cellspacing"", you can apply the border-spacing CSS property to your table. E.g. for 10px of ""cellspacing"":table {     border-spacing: 10px;    border-collapse: separate;}This property will even allow separate horizontal and vertical spacing, something you couldn't do with old-school ""cellspacing"".Issues in IE ≤  7This will work in almost all popular browsers except for Internet Explorer up through Internet Explorer 7, where you're almost out of luck. I say ""almost"" because these browsers still support the border-collapse property, which merges the borders of adjoining table cells. If you're trying to eliminate cellspacing (that is, cellspacing=""0"") then border-collapse:collapse should have the same effect: no space between table cells. This support is buggy, though, as it does not override an existing cellspacing HTML attribute on the table element.In short: for non-Internet Explorer 5-7 browsers, border-spacing handles you. For Internet Explorer, if your situation is just right (you want 0 cellspacing and your table doesn't have it defined already), you can use border-collapse:collapse.table {     border-spacing: 0;    border-collapse: collapse;}Note: For a great overview of CSS properties that one can apply to tables and for which browsers, see this fantastic Quirksmode page."
"data_i","edited Jul 10 '22 at 21:49","
        View the change history of a file using Git versioning
    ","How do I view the history of an individual file with complete details of what has changed?git log -- [filename] shows me the commit history of a file, but how do I see the file content that changed?","This lets Git generate the patches for each log entry:git log -p -- filenameSee git help log for more options — it can actually do a lot of nice things. :)To get just the diff for a specific commit, usegit show HEADor specify any other revision by identifier.To browse the changes visually:gitk"
"data_i","edited Jul 25 '22 at 16:58","
        Remove a file from a Git repository without deleting it from the local filesystem
    ","I want to remove a file from my repository.git rm file_to_remove.txtwill remove the file from the repository, but it will also remove the file from the local file system. How do I remove this file from the repo without deleting my local copy of the file?","The git rm documentation states:When --cached is given, the staged content has to match either the tip of the branch or the file on disk, allowing the file to be removed from just the index.So, for a single file:git rm --cached file_to_remove.txtand for a single directory:git rm --cached -r directory_to_remove"
"data_i","edited Apr 01 '22 at 11:27","
        How do I get the current time?
    ","How do I get the current time?","Use datetime:>>> import datetime>>> now = datetime.datetime.now()>>> nowdatetime.datetime(2009, 1, 6, 15, 8, 24, 78915)>>> print(now)2009-01-06 15:08:24.789150For just the clock time without the date:>>> now.time()datetime.time(15, 8, 24, 78915)>>> print(now.time())15:08:24.789150To save typing, you can import the datetime object from the datetime module:>>> from datetime import datetimeThen remove the prefix datetime. from all of the above."
"data_i","edited Jun 06 '22 at 03:15","
        How to iterate over rows in a DataFrame in Pandas
    ","I have a pandas dataframe, df:   c1   c20  10  1001  11  1102  12  120How do I iterate over the rows of this dataframe? For every row, I want to be able to access its elements (values in cells) by the name of the columns. For example:for row in df.rows:   print(row['c1'], row['c2'])I found a similar question which suggests using either of these:for date, row in df.T.iteritems():for row in df.iterrows():But I do not understand what the row object is and how I can work with it.","DataFrame.iterrows is a generator which yields both the index and row (as a Series):import pandas as pddf = pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 120]})df = df.reset_index()  # make sure indexes pair with number of rowsfor index, row in df.iterrows():    print(row['c1'], row['c2'])10 10011 11012 120"
"data_i","edited May 26 '17 at 18:02","
        Does Python have a string 'contains' substring method?
    ","I'm looking for a string.contains or string.indexof method in Python.I want to do:if not somestring.contains(""blah""):   continue","Use the in operator:if ""blah"" not in somestring:     continue"
"data_i","edited Jul 11 '22 at 05:48","
        How do I stash only one file out of multiple files that have changed?
    ","How do I stash only one of the multiple changed files on my branch?","git stash push -p -m ""my commit message""-p let's you select the hunks that should be stashed; whole files can be selected as well.You'll be prompted with a few actions for each hunk:   y - stash this hunk   n - do not stash this hunk   q - quit; do not stash this hunk or any of the remaining ones   a - stash this hunk and all later hunks in the file   d - do not stash this hunk or any of the later hunks in the file   g - select a hunk to go to   / - search for a hunk matching the given regex   j - leave this hunk undecided, see next undecided hunk   J - leave this hunk undecided, see next hunk   k - leave this hunk undecided, see previous undecided hunk   K - leave this hunk undecided, see previous hunk   s - split the current hunk into smaller hunks   e - manually edit the current hunk   ? - print help"
"data_i","asked Jun 24 '11 at 15:55","
        Catch multiple exceptions in one line (except block)
    ","I know that I can do:try:    # do something that may failexcept:    # do this if ANYTHING goes wrongI can also do this:try:    # do something that may failexcept IDontLikeYouException:    # say pleaseexcept YouAreTooShortException:    # stand on a ladderBut if I want to do the same thing inside two different exceptions, the best I can think of right now is to do this:try:    # do something that may failexcept IDontLikeYouException:    # say pleaseexcept YouAreBeingMeanException:    # say pleaseIs there any way that I can do something like this (since the action to take in both exceptions is to say please):try:    # do something that may failexcept IDontLikeYouException, YouAreBeingMeanException:    # say pleaseNow this really won't work, as it matches the syntax for:try:    # do something that may failexcept Exception, e:    # say pleaseSo, my effort to catch the two distinct exceptions doesn't exactly come through.Is there a way to do this?","From Python Documentation:An except clause may name multiple exceptions as a parenthesized tuple, for exampleexcept (IDontLikeYouException, YouAreBeingMeanException) as e:    passOr, for Python 2 only:except (IDontLikeYouException, YouAreBeingMeanException), e:    passSeparating the exception from the variable with a comma will still work in Python 2.6 and 2.7, but is now deprecated and does not work in Python 3; now you should be using as."
"data_i","asked Oct 05 '09 at 09:21","
        How do I create a remote Git branch?
    ","I created a local branch. How do I push it to the remote server?UPDATE: I have written a simpler answer for Git 2.0 here.","First, create a new local branch and check it out:git checkout -b <branch-name>The remote branch is automatically created when you push it to the remote server:git push <remote-name> <branch-name> <remote-name> is typically origin, which is the name which git gives to the remote you cloned from. Your colleagues may then simply pull that branch.Note however that formally, the format is:git push <remote-name> <local-branch-name>:<remote-branch-name>But when you omit one, it assumes both branch names are the same. Having said this, as a word of caution, do not make the critical mistake of specifying only :<remote-branch-name> (with the colon), or the remote branch will be deleted!So that a subsequent git pull will know what to do, you might instead want to use:git push --set-upstream <remote-name> <local-branch-name> As described below, the --set-upstream option sets up an upstream branch:For every branch that is up to date orsuccessfully pushed, add upstream(tracking) reference, used byargument-less git-pull(1) and othercommands."
"data_i","edited Jul 08 '22 at 06:38","
        How do I get the current branch name in Git?
    ","How do I get the name of the current branch in Git?","To display only the name of the current branch you're on:git rev-parse --abbrev-ref HEADReference: Show just the current branch in Git"
"data_i","edited Apr 30 '20 at 19:52","
        How do I correctly clone a JavaScript object?
    ","I have an object x. I'd like to copy it as object y, such that changes to y do not modify x. I realized that copying objects derived from built-in JavaScript objects will result in extra, unwanted properties. This isn't a problem, since I'm copying one of my own literal-constructed objects.How do I correctly clone a JavaScript object?","2022 updateThere's a new JS standard called structured cloning. It works on all browsers:const clone = structuredClone(object);Old answerTo do this for any object in JavaScript will not be simple or straightforward. You will run into the problem of erroneously picking up attributes from the object's prototype that should be left in the prototype and not copied to the new instance. If, for instance, you are adding a clone method to Object.prototype, as some answers depict, you will need to explicitly skip that attribute. But what if there are other additional methods added to Object.prototype, or other intermediate prototypes, that you don't know about? In that case, you will copy attributes you shouldn't, so you need to detect unforeseen, non-local attributes with the hasOwnProperty method.In addition to non-enumerable attributes, you'll encounter a tougher problem when you try to copy objects that have hidden properties. For example, prototype is a hidden property of a function. Also, an object's prototype is referenced with the attribute __proto__, which is also hidden, and will not be copied by a for/in loop iterating over the source object's attributes. I think __proto__ might be specific to Firefox's JavaScript interpreter and it may be something different in other browsers, but you get the picture. Not everything is enumerable. You can copy a hidden attribute if you know its name, but I don't know of any way to discover it automatically.Yet another snag in the quest for an elegant solution is the problem of setting up the prototype inheritance correctly. If your source object's prototype is Object, then simply creating a new general object with {} will work, but if the source's prototype is some descendant of Object, then you are going to be missing the additional members from that prototype which you skipped using the hasOwnProperty filter, or which were in the prototype, but weren't enumerable in the first place. One solution might be to call the source object's constructor property to get the initial copy object and then copy over the attributes, but then you still will not get non-enumerable attributes. For example, a Date object stores its data as a hidden member:function clone(obj) {    if (null == obj || ""object"" != typeof obj) return obj;    var copy = obj.constructor();    for (var attr in obj) {        if (obj.hasOwnProperty(attr)) copy[attr] = obj[attr];    }    return copy;}var d1 = new Date();/* Executes function after 5 seconds. */setTimeout(function(){    var d2 = clone(d1);    alert(""d1 = "" + d1.toString() + ""\nd2 = "" + d2.toString());}, 5000);The date string for d1 will be 5 seconds behind that of d2. A way to make one Date the same as another is by calling the setTime method, but that is specific to the Date class. I don't think there is a bullet-proof general solution to this problem, though I would be happy to be wrong!When I had to implement general deep copying I ended up compromising by assuming that I would only need to copy a plain Object, Array, Date, String, Number, or Boolean. The last 3 types are immutable, so I could perform a shallow copy and not worry about it changing. I further assumed that any elements contained in Object or Array would also be one of the 6 simple types in that list. This can be accomplished with code like the following:function clone(obj) {    var copy;    // Handle the 3 simple types, and null or undefined    if (null == obj || ""object"" != typeof obj) return obj;    // Handle Date    if (obj instanceof Date) {        copy = new Date();        copy.setTime(obj.getTime());        return copy;    }    // Handle Array    if (obj instanceof Array) {        copy = [];        for (var i = 0, len = obj.length; i < len; i++) {            copy[i] = clone(obj[i]);        }        return copy;    }    // Handle Object    if (obj instanceof Object) {        copy = {};        for (var attr in obj) {            if (obj.hasOwnProperty(attr)) copy[attr] = clone(obj[attr]);        }        return copy;    }    throw new Error(""Unable to copy obj! Its type isn't supported."");}The above function will work adequately for the 6 simple types I mentioned, as long as the data in the objects and arrays form a tree structure. That is, there isn't more than one reference to the same data in the object. For example:// This would be cloneable:var tree = {    ""left""  : { ""left"" : null, ""right"" : null, ""data"" : 3 },    ""right"" : null,    ""data""  : 8};// This would kind-of work, but you would get 2 copies of the // inner node instead of 2 references to the same copyvar directedAcylicGraph = {    ""left""  : { ""left"" : null, ""right"" : null, ""data"" : 3 },    ""data""  : 8};directedAcyclicGraph[""right""] = directedAcyclicGraph[""left""];// Cloning this would cause a stack overflow due to infinite recursion:var cyclicGraph = {    ""left""  : { ""left"" : null, ""right"" : null, ""data"" : 3 },    ""data""  : 8};cyclicGraph[""right""] = cyclicGraph;It will not be able to handle any JavaScript object, but it may be sufficient for many purposes as long as you don't assume that it will just work for anything you throw at it."
"data_i","edited Jan 14 '20 at 00:25","
        How do I POST JSON data with cURL?
    ","I use Ubuntu and installed cURL on it. I want to test my Spring REST application with cURL. I wrote my POST code at the Java side. However, I want to test it with cURL. I am trying to post a JSON data. Example data is like this:{""value"":""30"",""type"":""Tip 3"",""targetModule"":""Target 3"",""configurationGroup"":null,""name"":""Configuration Deneme 3"",""description"":null,""identity"":""Configuration Deneme 3"",""version"":0,""systemId"":3,""active"":true}I use this command:curl -i \    -H ""Accept: application/json"" \    -H ""X-HTTP-Method-Override: PUT"" \    -X POST -d ""value"":""30"",""type"":""Tip 3"",""targetModule"":""Target 3"",""configurationGroup"":null,""name"":""Configuration Deneme 3"",""description"":null,""identity"":""Configuration Deneme 3"",""version"":0,""systemId"":3,""active"":true \    http://localhost:8080/xx/xxx/xxxxIt returns this error:HTTP/1.1 415 Unsupported Media TypeServer: Apache-Coyote/1.1Content-Type: text/html;charset=utf-8Content-Length: 1051Date: Wed, 24 Aug 2011 08:50:17 GMTThe error description is this:The server refused this request because the request entity is in a format not supported by the requested resource for the requested method ().Tomcat log:    ""POST /ui/webapp/conf/clear HTTP/1.1"" 415 1051What is the right format of the cURL command?This is my Java side PUT code (I have tested GET and DELETE and they work):@RequestMapping(method = RequestMethod.PUT)public Configuration updateConfiguration(HttpServletResponse response, @RequestBody Configuration configuration) { //consider @Valid tag    configuration.setName(""PUT worked"");    //todo If error occurs response.sendError(HttpServletResponse.SC_NOT_FOUND);    return configuration;}","You need to set your content-type to application/json. But -d (or --data) sends the Content-Type application/x-www-form-urlencoded, which is not accepted on Spring's side.Looking at the curl man page, I think you can use -H (or --header):-H ""Content-Type: application/json""Full example:curl --header ""Content-Type: application/json"" \  --request POST \  --data '{""username"":""xyz"",""password"":""xyz""}' \  http://localhost:3000/api/login(-H is short for --header, -d for --data)Note that -request POST is optional if you use -d, as the -d flag implies a POST request.On Windows, things are slightly different. See the comment thread."
"data_i","edited Sep 11 '18 at 14:54","
        What is the difference between public, protected, package-private and private in Java?
    ","In Java, are there clear rules on when to use each of access modifiers, namely the default (package private), public, protected and private, while making class and interface and dealing with inheritance?","The official tutorial may be of some use to you.ClassPackageSubclass(same pkg)Subclass(diff pkg)Worldpublic+++++protected++++no modifier+++private++ : accessibleblank : not accessible"
"data_i","edited Sep 23 '17 at 23:41","
        Get the current URL with JavaScript?
    ","All I want is to get the website URL. Not the URL as taken from a link. On the page loading I need to be able to grab the full, current URL of the website and set it as a variable to do with as I please.","Use:window.location.hrefAs noted in the comments, the line below works, but it is bugged for Firefox.document.URLSee URL of type DOMString, readonly."
"data_i","edited Jan 05 '22 at 21:13","
        When to use LinkedList over ArrayList in Java?
    ","I've always been one to simply use:List<String> names = new ArrayList<>();I use the interface as the type name for portability, so that when I ask questions such as this, I can rework my code.When should LinkedList be used over ArrayList and vice-versa?","Summary ArrayList with ArrayDeque are preferable in many more use-cases than LinkedList. If you're not sure — just start with ArrayList.TLDR, in ArrayList accessing an element takes constant time [O(1)] and adding an element takes O(n) time [worst case]. In LinkedList inserting an element takes O(n) time and accessing also takes O(n) time but LinkedList uses more memory than ArrayList.LinkedList and ArrayList are two different implementations of the List interface. LinkedList implements it with a doubly-linked list. ArrayList implements it with a dynamically re-sizing array.As with standard linked list and array operations, the various methods will have different algorithmic runtimes.For LinkedList<E>get(int index) is O(n) (with n/4 steps on average), but O(1) when index = 0 or index = list.size() - 1 (in this case, you can also use getFirst() and getLast()). One of the main benefits of LinkedList<E>add(int index, E element) is O(n) (with n/4 steps on average), but O(1) when index = 0 or index = list.size() - 1 (in this case, you can also use addFirst() and addLast()/add()). One of the main benefits of LinkedList<E>remove(int index) is O(n) (with n/4 steps on average), but O(1) when index = 0 or index = list.size() - 1 (in this case, you can also use removeFirst() and removeLast()). One of the main benefits of LinkedList<E>Iterator.remove() is O(1). One of the main benefits of LinkedList<E>ListIterator.add(E element) is O(1). One of the main benefits of LinkedList<E>Note: Many of the operations need n/4 steps on average, constant number of steps in the best case (e.g. index = 0), and n/2 steps in worst case (middle of list)For ArrayList<E>get(int index) is O(1). Main benefit of ArrayList<E>add(E element) is O(1) amortized, but O(n) worst-case since the array must be resized and copiedadd(int index, E element) is O(n) (with n/2 steps on average)remove(int index) is O(n) (with n/2 steps on average)Iterator.remove() is O(n) (with n/2 steps on average)ListIterator.add(E element) is O(n) (with n/2 steps on average)Note: Many of the operations need n/2 steps on average, constant number of steps in the best case (end of list), n steps in the worst case (start of list)LinkedList<E> allows for constant-time insertions or removals using iterators, but only sequential access of elements. In other words, you can walk the list forwards or backwards, but finding a position in the list takes time proportional to the size of the list. Javadoc says ""operations that index into the list will traverse the list from the beginning or the end, whichever is closer"", so those methods are O(n) (n/4 steps) on average, though O(1) for index = 0.ArrayList<E>, on the other hand, allow fast random read access, so you can grab any element in constant time. But adding or removing from anywhere but the end requires shifting all the latter elements over, either to make an opening or fill the gap. Also, if you add more elements than the capacity of the underlying array, a new array (1.5 times the size) is allocated, and the old array is copied to the new one, so adding to an ArrayList is O(n) in the worst case but constant on average.So depending on the operations you intend to do, you should choose the implementations accordingly. Iterating over either kind of List is practically equally cheap. (Iterating over an ArrayList is technically faster, but unless you're doing something really performance-sensitive, you shouldn't worry about this -- they're both constants.)The main benefits of using a LinkedList arise when you re-use existing iterators to insert and remove elements. These operations can then be done in O(1) by changing the list locally only. In an array list, the remainder of the array needs to be moved (i.e. copied). On the other side, seeking in a LinkedList means following the links in O(n) (n/2 steps) for worst case, whereas in an ArrayList the desired position can be computed mathematically and accessed in O(1).Another benefit of using a LinkedList arises when you add or remove from the head of the list, since those operations are O(1), while they are O(n) for ArrayList. Note that ArrayDeque may be a good alternative to LinkedList for adding and removing from the head, but it is not a List.Also, if you have large lists, keep in mind that memory usage is also different. Each element of a LinkedList has more overhead since pointers to the next and previous elements are also stored. ArrayLists don't have this overhead. However, ArrayLists take up as much memory as is allocated for the capacity, regardless of whether elements have actually been added.The default initial capacity of an ArrayList is pretty small (10 from Java 1.4 - 1.8). But since the underlying implementation is an array, the array must be resized if you add a lot of elements. To avoid the high cost of resizing when you know you're going to add a lot of elements, construct the ArrayList with a higher initial capacity.If the data structures perspective is used to understand the two structures, a LinkedList is basically a sequential data structure which contains a head Node. The Node is a wrapper for two components : a value of type T [accepted through generics] and another reference to the Node linked to it. So, we can assert it is a recursive data structure (a Node contains another Node which has another Node and so on...). Addition of elements takes linear time in LinkedList as stated above.An ArrayList is a growable array. It is just like a regular array. Under the hood, when an element is added, and the ArrayList is already full to capacity, it creates another array with a size which is greater than previous size. The elements are then copied from previous array to new one and the elements that are to be added are also placed at the specified indices."
"data_i","edited Jul 29 '20 at 01:23","
        Why is the Android emulator so slow? How can we speed up the Android emulator?
    ","I have got a 2.67  GHz Celeron processor, and 1.21  GB of RAM on a x86 Windows XP Professional machine.My understanding is that the Android Emulator should start fairly quickly on such a machine, but for me, it doesn't. I have followed all the instructions in setting up the IDE, SDKs, JDKs and such and have had some success in starting the emulator quickly, but that is very rare. How can I, if possible, fix this problem?Even if it starts and loads the home screen, it is very sluggish. I have tried the Eclipse IDE in version 3.5 (Galileo) and 3.4 (Ganymede).","UpdateYou can now enable the Quick Boot option for Android Emulator. That will save emulator state, and it will start the emulator quickly on the next boot.Click on Emulator edit button, then click Show Advanced Setting. Then enable Quick Boot like below screenshot.Android Development Tools (ADT) 9.0.0 (or later) has a feature that allows you to save state of the AVD (emulator), and you can start your emulator instantly. You have to enable this feature while creating a new AVD or you can just create it later by editing the AVD.Also I have increased the Device RAM Size to 1024 which results in a very fast emulator.Refer to the given below screenshots for more information.Creating a new AVD with the save snapshot feature.Launching the emulator from the snapshot.And for speeding up your emulator you can refer to Speed up your Android Emulator!:Using ssd hard drive has too much impact and I recommend to use more suitable ram (8 or higher)"
"data_i","edited Mar 19 '14 at 20:42","
        What is dependency injection?
    ","There have been several questions already posted with specific questions about dependency injection, such as when to use it and what frameworks are there for it. However,What is dependency injection and when/why should or shouldn't it be used?","The best definition I've found so far is one by James Shore: ""Dependency Injection"" is a 25-dollar  term for a 5-cent concept. [...]  Dependency injection means giving an  object its instance variables. [...].There is an article by Martin Fowler that may prove useful, too.Dependency injection is basically providing the objects that an object needs (its dependencies) instead of having it construct them itself. It's a very useful technique for testing, since it allows dependencies to be mocked or stubbed out.Dependencies can be injected into objects by many means (such as constructor injection or setter injection). One can even use specialized dependency injection frameworks (e.g. Spring) to do that, but they certainly aren't required. You don't need those frameworks to have dependency injection. Instantiating and passing objects (dependencies) explicitly is just as good an injection as injection by framework."
"data_i","edited Oct 06 '21 at 08:31","
        How can I pretty-print JSON in a shell script?
    ","Is there a (Unix) shell script to format JSON in human-readable form?Basically, I want it to transform the following:{ ""foo"": ""lorem"", ""bar"": ""ipsum"" }... into something like this:{    ""foo"": ""lorem"",    ""bar"": ""ipsum""}","With Python 2.6+ you can do:echo '{""foo"": ""lorem"", ""bar"": ""ipsum""}' | python -m json.toolor, if the JSON is in a file, you can do:python -m json.tool my_json.jsonif the JSON is from an internet source such as an API, you can usecurl http://my_url/ | python -m json.toolFor convenience in all of these cases you can make an alias:alias prettyjson='python -m json.tool'For even more convenience with a bit more typing to get it ready:prettyjson_s() {    echo ""$1"" | python -m json.tool}prettyjson_f() {    python -m json.tool ""$1""}prettyjson_w() {    curl ""$1"" | python -m json.tool}for all the above cases. You can put this in .bashrc and it will be available every time in shell. Invoke it like prettyjson_s '{""foo"": ""lorem"", ""bar"": ""ipsum""}'.Note that as @pnd pointed out in the comments below, in Python 3.5+ the JSON object is no longer sorted by default. To sort, add the --sort-keys flag to the end. I.e. ... | python -m json.tool --sort-keys."
"data_i","edited Jan 24 '18 at 22:44","
        What does the explicit keyword mean?
    ","What does the explicit keyword mean in C++?","The compiler is allowed to make one implicit conversion to resolve the parameters to a function. What this means is that the compiler can use constructors callable with a single parameter to convert from one type to another in order to get the right type for a parameter.Here's an example class with a constructor that can be used for implicit conversions:class Foo{private:  int m_foo;public:  // single parameter constructor, can be used as an implicit conversion  Foo (int foo) : m_foo (foo) {}  int GetFoo () { return m_foo; }};Here's a simple function that takes a Foo object:void DoBar (Foo foo){  int i = foo.GetFoo ();}and here's where the DoBar function is called:int main (){  DoBar (42);}The argument is not a Foo object, but an int. However, there exists a constructor for Foo that takes an int so this constructor can be used to convert the parameter to the correct type.The compiler is allowed to do this once for each parameter.Prefixing the explicit keyword to the constructor prevents the compiler from using that constructor for implicit conversions. Adding it to the above class will create a compiler error at the function call DoBar (42).  It is now necessary to call for conversion explicitly with  DoBar (Foo (42))The reason you might want to do this is to avoid accidental construction that can hide bugs.Contrived example:You have a MyString class with a constructor that constructs a string of the given size.  You have a function print(const MyString&) (as well as an overload print (char *string)), and you call print(3) (when you actually intended to call print(""3"")).  You expect it to print ""3"", but it prints an empty string of length 3 instead."
"data_i","edited Oct 22 '17 at 02:35","
        How do I list all files of a directory?
    ","How can I list all files of a directory in Python and add them to a list?","os.listdir() returns everything inside a directory -- including both files and directories.os.path's isfile() can be used to only list files:from os import listdirfrom os.path import isfile, joinonlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]Alternatively, os.walk() yields two lists for each directory it visits -- one for files and one for dirs. If you only want the top directory you can break the first time it yields:from os import walkf = []for (dirpath, dirnames, filenames) in walk(mypath):    f.extend(filenames)    breakor, shorter:from os import walkfilenames = next(walk(mypath), (None, None, []))[2]  # [] if no file"
"data_i","edited Apr 01 '22 at 11:29","
        What is the difference between __str__ and __repr__?
    ","What is the difference between __str__ and __repr__ in Python?","Alex summarized well but, surprisingly, was too succinct.First, let me reiterate the main points in Alex’s post:The default implementation is useless (it’s hard to think of one which wouldn’t be, but yeah)__repr__ goal is to be unambiguous__str__ goal is to be readableContainer’s __str__ uses contained objects’ __repr__Default implementation is uselessThis is mostly a surprise because Python’s defaults tend to be fairly useful. However, in this case, having a default for __repr__ which would act like:return ""%s(%r)"" % (self.__class__, self.__dict__)would have been too dangerous (for example, too easy to get into infinite recursion if objects reference each other). So Python cops out. Note that there is one default which is true: if __repr__ is defined, and __str__ is not, the object will behave as though __str__=__repr__.This means, in simple terms: almost every object you implement should have a functional __repr__ that’s usable for understanding the object. Implementing __str__ is optional: do that if you need a “pretty print” functionality (for example, used by a report generator).The goal of __repr__ is to be unambiguousLet me come right out and say it — I do not believe in debuggers. I don’t really know how to use any debugger, and have never used one seriously. Furthermore, I believe that the big fault in debuggers is their basic nature — most failures I debug happened a long long time ago, in a galaxy far far away. This means that I do believe, with religious fervor, in logging. Logging is the lifeblood of any decent fire-and-forget server system. Python makes it easy to log: with maybe some project specific wrappers, all you need is alog(INFO, ""I am in the weird function and a is"", a, ""and b is"", b, ""but I got a null C — using default"", default_c)But you have to do the last step — make sure every object you implement has a useful repr, so code like that can just work. This is why the “eval” thing comes up: if you have enough information so eval(repr(c))==c, that means you know everything there is to know about c. If that’s easy enough, at least in a fuzzy way, do it. If not, make sure you have enough information about c anyway. I usually use an eval-like format: ""MyClass(this=%r,that=%r)"" % (self.this,self.that). It does not mean that you can actually construct MyClass, or that those are the right constructor arguments — but it is a useful form to express “this is everything you need to know about this instance”.Note: I used %r above, not %s. You always want to use repr() [or %r formatting character, equivalently] inside __repr__ implementation, or you’re defeating the goal of repr. You want to be able to differentiate MyClass(3) and MyClass(""3"").The goal of __str__ is to be readableSpecifically, it is not intended to be unambiguous — notice that str(3)==str(""3""). Likewise, if you implement an IP abstraction, having the str of it look like 192.168.1.1 is just fine. When implementing a date/time abstraction, the str can be ""2010/4/12 15:35:22"", etc. The goal is to represent it in a way that a user, not a programmer, would want to read it. Chop off useless digits, pretend to be some other class — as long is it supports readability, it is an improvement.Container’s __str__ uses contained objects’ __repr__This seems surprising, doesn’t it? It is a little, but how readable would it be if it used their __str__?[moshe is, 3, helloworld, this is a list, oh I don't know, containing just 4 elements]Not very. Specifically, the strings in a container would find it way too easy to disturb its string representation. In the face of ambiguity, remember, Python resists the temptation to guess. If you want the above behavior when you’re printing a list, justprint(""["" + "", "".join(l) + ""]"")(you can probably also figure out what to do about dictionaries.SummaryImplement __repr__ for any class you implement. This should be second nature. Implement __str__ if you think it would be useful to have a string version which errs on the side of readability."
"data_i","edited Sep 19 '22 at 17:00","
        Convert bytes to a string
    ","I captured the standard output of an external program into a bytes object:>>> from subprocess import *>>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]>>>>>> command_stdoutb'total 0\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\n'I want to convert that to a normal Python string, so that I can print it like this:>>> print(command_stdout)-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2I tried the binascii.b2a_qp() method, but got the same bytes object again:>>> binascii.b2a_qp(command_stdout)b'total 0\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\n'How do I convert the bytes object to a str with Python 3?","Decode the bytes object to produce a string:>>> b""abcde"".decode(""utf-8"") 'abcde'The above example assumes that the bytes object is in UTF-8, because it is a common encoding. However, you should use the encoding your data is actually in!"
"data_i","edited May 08 '22 at 17:29","
        How do I loop through or enumerate a JavaScript object?
    ","I have a JavaScript object like the following:var p = {    ""p1"": ""value1"",    ""p2"": ""value2"",    ""p3"": ""value3""};How do I loop through all of p's elements (p1, p2, p3...) and get their keys and values?","You can use the for-in loop as shown by others. However, you also have to make sure that the key you get is an actual property of an object, and doesn't come from the prototype.Here is the snippet:var p = {    ""p1"": ""value1"",    ""p2"": ""value2"",    ""p3"": ""value3""};for (var key in p) {    if (p.hasOwnProperty(key)) {        console.log(key + "" -> "" + p[key]);    }}For-of with Object.keys() alternative:var p = {    0: ""value1"",    ""b"": ""value2"",    key: ""value3""};for (var key of Object.keys(p)) {    console.log(key + "" -> "" + p[key])}Notice the use of for-of instead of for-in, if not used it will return undefined on named properties, and Object.keys() ensures the use of only the object's own properties without the whole prototype-chain propertiesUsing the new Object.entries() method:Note: This method is not supported natively by Internet Explorer. You may consider using a Polyfill for older browsers.const p = {    ""p1"": ""value1"",    ""p2"": ""value2"",    ""p3"": ""value3""};for (let [key, value] of Object.entries(p)) {  console.log(`${key}: ${value}`);}"
"data_i","edited Mar 20 '19 at 22:50","
        How do I sort a dictionary by value?
    ","I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.I can sort on the keys, but how can I sort based on the values?Note: I have read Stack Overflow question here How do I sort a list of dictionaries by a value of the dictionary? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution to sort either in ascending or descending order.","Python 3.7+ or CPython 3.6Dicts preserve insertion order in Python 3.7+. Same in CPython 3.6, but it's an implementation detail.>>> x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}>>> {k: v for k, v in sorted(x.items(), key=lambda item: item[1])}{0: 0, 2: 1, 1: 2, 4: 3, 3: 4}or>>> dict(sorted(x.items(), key=lambda item: item[1])){0: 0, 2: 1, 1: 2, 4: 3, 3: 4}Older PythonIt is not possible to sort a dictionary, only to get a representation of a dictionary that is sorted. Dictionaries are inherently orderless, but other types, such as lists and tuples, are not. So you need an ordered data type to represent sorted values, which will be a list—probably a list of tuples.For instance,import operatorx = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}sorted_x = sorted(x.items(), key=operator.itemgetter(1))sorted_x will be a list of tuples sorted by the second element in each tuple. dict(sorted_x) == x.And for those wishing to sort on keys instead of values:import operatorx = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}sorted_x = sorted(x.items(), key=operator.itemgetter(0))In Python3 since unpacking is not allowed we can usex = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}sorted_x = sorted(x.items(), key=lambda kv: kv[1])If you want the output as a dict, you can use collections.OrderedDict:import collectionssorted_dict = collections.OrderedDict(sorted_x)"
"data_i","edited Apr 01 '22 at 01:31","
        How to copy files?
    ","How do I copy a file in Python?","shutil has many methods you can use. One of which is:import shutilshutil.copyfile(src, dst)# 2nd optionshutil.copy(src, dst)  # dst can be a folder; use shutil.copy2() to preserve timestampCopy the contents of the file named src to a file named dst. Both src and dst need to be the entire filename of the files, including path.The destination location must be writable; otherwise, an IOError exception will be raised.If dst already exists, it will be replaced.Special files such as character or block devices and pipes cannot be copied with this function.With copy, src and dst are path names given as strs.Another shutil method to look at is shutil.copy2(). It's similar but preserves more metadata (e.g. time stamps).If you use os.path operations, use copy rather than copyfile. copyfile will only accept strings."
"data_i","edited Sep 14 '22 at 14:08","
        How do I convert a String to an int in Java?
    ","How can I convert a String to an int?""1234""  →  1234","String myString = ""1234"";int foo = Integer.parseInt(myString);If you look at the Java documentation you'll notice the ""catch"" is that this function can throw a NumberFormatException, which you can handle:int foo;try {   foo = Integer.parseInt(myString);}catch (NumberFormatException e) {   foo = 0;}(This treatment defaults a malformed number to 0, but you can do something else if you like.)Alternatively, you can use an Ints method from the Guava library, which in combination with Java 8's Optional, makes for a powerful and concise way to convert a string into an int:import com.google.common.primitives.Ints;int foo = Optional.ofNullable(myString) .map(Ints::tryParse) .orElse(0)"
"data_i","edited Nov 25 '16 at 12:46","
        AngularJS: Service vs provider vs factory
    ","What are the differences between a Service, Provider and Factory in AngularJS?","From the AngularJS mailing list I got an amazing thread that explains service vs factory vs provider and their injection usage. Compiling the answers:ServicesSyntax: module.service( 'serviceName', function ); Result: When declaring serviceName as an injectable argument you will be provided with an instance of the function. In other words new FunctionYouPassedToService().FactoriesSyntax: module.factory( 'factoryName', function ); Result: When declaring factoryName as an injectable argument you will be provided with the value that is returned by invoking the function reference passed to module.factory.ProvidersSyntax: module.provider( 'providerName', function ); Result: When declaring providerName as an injectable argument you will be provided with (new ProviderFunction()).$get(). The constructor function is instantiated before the $get method is called - ProviderFunction is  the function reference passed to module.provider.Providers have the advantage that they can be configured during the module configuration phase.See here for the provided code.Here's a great further explanation by Misko:provide.value('a', 123);function Controller(a) {  expect(a).toEqual(123);}In this case the injector simply returns the value as is. But what if you want to compute the value? Then use a factoryprovide.factory('b', function(a) {  return a*2;});function Controller(b) {  expect(b).toEqual(246);}So factory is a function which is responsible for creating the value. Notice that the factory function can ask for other dependencies.But what if you want to be more OO and have a class called Greeter?function Greeter(a) {  this.greet = function() {    return 'Hello ' + a;  }}Then to instantiate you would have to writeprovide.factory('greeter', function(a) {  return new Greeter(a);});Then we could ask for 'greeter' in controller like thisfunction Controller(greeter) {  expect(greeter instanceof Greeter).toBe(true);  expect(greeter.greet()).toEqual('Hello 123');}But that is way too wordy. A shorter way to write this would be provider.service('greeter', Greeter);But what if we wanted to configure the Greeter class before the injection? Then we could writeprovide.provider('greeter2', function() {  var salutation = 'Hello';  this.setSalutation = function(s) {    salutation = s;  }  function Greeter(a) {    this.greet = function() {      return salutation + ' ' + a;    }  }  this.$get = function(a) {    return new Greeter(a);  };});Then we can do this:angular.module('abc', []).config(function(greeter2Provider) {  greeter2Provider.setSalutation('Halo');});function Controller(greeter2) {  expect(greeter2.greet()).toEqual('Halo 123');}As a side note, service, factory, and value are all derived from provider.provider.service = function(name, Class) {  provider.provide(name, function() {    this.$get = function($injector) {      return $injector.instantiate(Class);    };  });}provider.factory = function(name, factory) {  provider.provide(name, function() {    this.$get = function($injector) {      return $injector.invoke(factory);    };  });}provider.value = function(name, value) {  provider.factory(name, function() {    return value;  });};"
"data_i","edited Nov 26 '19 at 15:37","
        403 Forbidden vs 401 Unauthorized HTTP responses
    ","For a web page that exists, but for which a user does not have sufficient privileges (they are not logged in or do not belong to the proper user group), what is the proper HTTP response to serve?401 Unauthorized?403 Forbidden?Something else?What I've read on each so far isn't very clear on the difference between the two. What use cases are appropriate for each response?","A clear explanation from Daniel Irvine [original link]:There's a problem with 401 Unauthorized, the HTTP status code for authentication errors. And that’s just it: it’s for authentication, not authorization.Receiving a 401 response is the server telling you, “you aren’tauthenticated–either not authenticated at all or authenticatedincorrectly–but please reauthenticate and try again.” To help you out,it will always include a WWW-Authenticate header that describes howto authenticate.This is a response generally returned by your web server, not your webapplication.It’s also something very temporary; the server is asking you to tryagain.So, for authorization I use the 403 Forbidden response. It’spermanent, it’s tied to my application logic, and it’s a more concreteresponse than a 401.Receiving a 403 response is the server telling you, “I’m sorry. I knowwho you are–I believe who you say you are–but you just don’t havepermission to access this resource. Maybe if you ask the systemadministrator nicely, you’ll get permission. But please don’t botherme again until your predicament changes.”In summary, a 401 Unauthorized response should be used for missingor bad authentication, and a 403 Forbidden response should be usedafterwards, when the user is authenticated but isn’t authorized toperform the requested operation on the given resource.Another nice pictorial format of how http status codes should be used."
"data_i","edited Oct 30 '21 at 12:56","
        What is the difference between call and apply?
    ","What is the difference between using Function.prototype.apply() and Function.prototype.call() to invoke a function?var func = function() {  alert('hello!');};func.apply(); vs func.call();Are there performance differences between the two aforementioned methods? When is it best to use call over apply and vice versa?","The difference is that apply lets you invoke the function with arguments as an array; call requires the parameters be listed explicitly. A useful mnemonic is ""A for array and C for comma.""See MDN's documentation on apply and call.Pseudo syntax:theFunction.apply(valueForThis, arrayOfArgs)theFunction.call(valueForThis, arg1, arg2, ...)There is also, as of ES6, the possibility to spread the array for use with the call function, you can see the compatibilities here.Sample code:function theFunction(name, profession) {    console.log(""My name is "" + name + "" and I am a "" + profession +""."");}theFunction(""John"", ""fireman"");theFunction.apply(undefined, [""Susan"", ""school teacher""]);theFunction.call(undefined, ""Claude"", ""mathematician"");theFunction.call(undefined, ...[""Matthew"", ""physicist""]); // used with the spread operator"
"data_i","edited Apr 01 '22 at 01:25","
        How can I add new keys to a dictionary?
    ","How do I add a key to an existing dictionary? It doesn't have an .add() method.","You create a new key/value pair on a dictionary by assigning a value to that keyd = {'key': 'value'}print(d)  # {'key': 'value'}d['mynewkey'] = 'mynewvalue'print(d)  # {'key': 'value', 'mynewkey': 'mynewvalue'}If the key doesn't exist, it's added and points to that value. If it exists, the current value it points to is overwritten."
"data_i","edited Aug 26 '22 at 20:42","
        How do I list all the files in a commit?
    ","How can I print a plain list of all files that were part of a given commit?Although the following lists the files, it also includes unwanted diff information for each:git show a303aa90779efdd2f6b9d90693e2cbbbe4613c1d","Preferred Way (because it's a plumbing command; meant to be programmatic):$ git diff-tree --no-commit-id --name-only -r bd61ad98index.htmljavascript/application.jsjavascript/ie6.jsAnother Way (less preferred for scripts, because it's a porcelain command; meant to be user-facing)$ git show --pretty="""" --name-only bd61ad98    index.htmljavascript/application.jsjavascript/ie6.jsThe --no-commit-id suppresses the commit ID output.The --pretty argument specifies an empty format string to avoid the cruft at the beginning.The --name-only argument shows only the file names that were affected (Thanks Hank). Use --name-status instead, if you want to see what happened to each file (Deleted, Modified, Added)The -r argument is to recurse into sub-trees"
"data_i","edited Mar 17 '18 at 18:15","
        What is the JavaScript version of sleep()?
    ","Is there a better way to engineer a sleep in JavaScript than the following pausecomp function (taken from here)?function pausecomp(millis){    var date = new Date();    var curDate = null;    do { curDate = new Date(); }    while(curDate-date < millis);}This is not a duplicate of Sleep in JavaScript - delay between actions; I want a real sleep in the middle of a function, and not a delay before a piece of code executes.","2017 — 2021 updateSince 2009 when this question was asked, JavaScript has evolved significantly. All other answers are now obsolete or overly complicated. Here is the current best practice:function sleep(ms) {    return new Promise(resolve => setTimeout(resolve, ms));}Or as a one-liner:await new Promise(r => setTimeout(r, 2000));As a function:const sleep = ms => new Promise(r => setTimeout(r, ms));or in Typescript:const sleep = (ms: number) => new Promise((r) => setTimeout(r, ms));use it as:await sleep(<duration>);Demo:function sleep(ms) {    return new Promise(resolve => setTimeout(resolve, ms));}async function demo() {    for (let i = 0; i < 5; i++) {        console.log(`Waiting ${i} seconds...`);        await sleep(i * 1000);    }    console.log('Done');}demo();Note that,await can only be executed in functions prefixed with the async keyword, or at the top level of your script in an increasing number of environments.await only pauses the current async function. This means it does not block the execution of the rest of the script, which is what you want in the vast majority of the cases. If you do want a blocking construct, see this answer using Atomics.wait, but note that most browsers will not allow it on the browser's main thread.Two new JavaScript features (as of 2017) helped write this ""sleep"" function:Promises, a native feature of ES2015 (aka ES6). We also use arrow functions in the definition of the sleep function.The async/await feature lets the code explicitly wait for a promise to settle (resolve or reject).Compatibilitypromises are supported in Node v0.12+ and widely supported in browsers, except IEasync/await landed in V8 and has been enabled by default since Chrome 55 (released in Dec 2016)it landed in Node 7 in October 2016and also landed in Firefox Nightly in November 2016If for some reason you're using Node older than 7 (which reached end of life in 2017), or are targeting old browsers, async/await can still be used via Babel (a tool that will transpile JavaScript + new features into plain old JavaScript), with the transform-async-to-generator plugin."
"data_i","edited Apr 01 '22 at 11:42","
        What is __init__.py for?
    ","What is __init__.py for in a Python source directory?","It used to be a required part of a package (old, pre-3.3 ""regular package"", not newer 3.3+ ""namespace package"").Here's the documentation.Python defines two types of packages, regular packages and namespace packages. Regular packages are traditional packages as they existed in Python 3.2 and earlier. A regular package is typically implemented as a directory containing an __init__.py file. When a regular package is imported, this __init__.py file is implicitly executed, and the objects it defines are bound to names in the package’s namespace. The __init__.py file can contain the same Python code that any other module can contain, and Python will add some additional attributes to the module when it is imported.But just click the link, it contains an example, more information, and an explanation of namespace packages, the kind of packages without __init__.py."
"data_i","edited Mar 07 '17 at 18:03","
        Commit only part of a file in Git
    ","When I make changes to a file in Git, how can I commit only some of the changes?For example, how could I commit only 15 lines out of 30 lines that have been changed in a file?","You can use:git add --patch <filename>or for short:git add -p <filename>Git will break down your file into what it thinks are sensible ""hunks"" (portions of the file). It will then prompt you with this question:Stage this hunk [y,n,q,a,d,/,j,J,g,s,e,?]?Here is a description of each option:y stage this hunk for the next commitn do not stage this hunk for the next commitq quit; do not stage this hunk or any of the remaining hunksa stage this hunk and all later hunks in the filed do not stage this hunk or any of the later hunks in the fileg select a hunk to go to/ search for a hunk matching the given regexj leave this hunk undecided, see next undecided hunkJ leave this hunk undecided, see next hunkk leave this hunk undecided, see previous undecided hunkK leave this hunk undecided, see previous hunks split the current hunk into smaller hunkse manually edit the current hunkYou can then edit the hunk manually by replacing +/- by # (thanks veksen)? print hunk helpIf the file is not in the repository yet, you can first do git add -N <filename>. Afterwards you can go on with git add -p <filename>.Afterwards, you can use:git diff --staged to check that you staged the correct changesgit reset -p to unstage mistakenly added hunksgit commit -v to view your commit while you edit the commit message.Note this is far different than the git format-patch command, whose purpose is to parse commit data into a .patch files.Reference for future: Git Tools - Interactive Staging"
"data_i","edited May 31 '22 at 03:50","
        How to concatenate string variables in Bash
    ","In PHP, strings are concatenated together as follows:$foo = ""Hello"";$foo .= "" World"";Here, $foo becomes ""Hello World"".How is this accomplished in Bash?","foo=""Hello""foo=""${foo} World""echo ""${foo}""> Hello WorldIn general to concatenate two variables you can just write them one after another:a='Hello'b='World'c=""${a} ${b}""echo ""${c}""> Hello World"
"data_i","edited Mar 17 '15 at 22:44","
        What is a serialVersionUID and why should I use it?
    ","Eclipse issues warnings when a serialVersionUID is missing.  The serializable class Foo does not declare a static final  serialVersionUID field of type longWhat is serialVersionUID and why is it important?  Please show an example where missing serialVersionUID will cause a problem.","The docs for java.io.Serializable are probably about as good an explanation as you'll get:The serialization runtime associates with each serializable class a version number, called a serialVersionUID, which is used during deserialization to verify that the sender and receiver of a serialized object have loaded classes for that object that are compatible with respect to serialization. If the receiver has loaded a class for the object that has a different serialVersionUID than that of the corresponding sender's class, then deserialization will result in anInvalidClassException. A serializable class can declare its own serialVersionUID explicitly by declaring a field named serialVersionUID that must be static, final, and of type long:ANY-ACCESS-MODIFIER static final long serialVersionUID = 42L;If a serializable class does not explicitly declare a serialVersionUID, then the serialization runtime will calculate a default serialVersionUID value for that class based on various aspects of the class, as described in the Java(TM) Object Serialization Specification. However, it is strongly recommended that all serializable classes explicitly declare serialVersionUID values, since the default serialVersionUID computation is highly sensitive to class details that may vary depending on compiler implementations, and can thus result in unexpected InvalidClassExceptions during deserialization. Therefore, to guarantee a consistent serialVersionUID value across different java compiler implementations, a serializable class must declare an explicit serialVersionUID value. It is also strongly advised that explicit serialVersionUID declarations use the private modifier where possible, since such declarations apply only to the immediately declaring class — serialVersionUID fields are not useful as inherited members."
"data_i","edited Jul 10 '22 at 22:26","
        Difference between ""git add -A"" and ""git add .""
    ","What is the difference between git add [--all | -A] and git add .?","This answer only applies to Git version 1.x. For Git version 2.x, see other answers.Summary:git add -A stages all changesgit add . stages new files and modifications, without deletions (on the current directory and its subdirectories).git add -u stages modifications and deletions, without new filesDetail:git add -A is equivalent to  git add .; git add -u.The important point about git add . is that it looks at the working tree and adds all those paths to the staged changes if they are either changed or are new and not ignored, it does not stage any 'rm' actions.git add -u looks at all the already tracked files and stages the changes to those files if they are different or if they have been removed. It does not add any new files, it only stages changes to already tracked files.git add -A is a handy shortcut for doing both of those.You can test the differences out with something like this (note that for Git version 2.x your output for git add . git status will be different):git initecho Change me > change-meecho Delete me > delete-megit add change-me delete-megit commit -m initialecho OK >> change-merm delete-meecho Add me > add-megit status# Changed but not updated:#   modified:   change-me#   deleted:    delete-me# Untracked files:#   add-megit add .git status# Changes to be committed:#   new file:   add-me#   modified:   change-me# Changed but not updated:#   deleted:    delete-megit resetgit add -ugit status# Changes to be committed:#   modified:   change-me#   deleted:    delete-me# Untracked files:#   add-megit resetgit add -Agit status# Changes to be committed:#   new file:   add-me#   modified:   change-me#   deleted:    delete-me"
"data_i","edited Jan 28 '22 at 12:44","
        Case insensitive 'Contains(string)'
    ","Is there a way to make the following return true?string title = ""ASTRINGTOTEST"";title.Contains(""string"");There doesn't seem to be an overload that allows me to set the case sensitivity. Currently I UPPERCASE them both, but that's just silly (by which I am referring to the i18n issues that come with up- and down casing).UPDATEThis question is ancient and since then I have realized I asked for a simple answer for a really vast and difficult topic if you care to investigate it fully.For most cases, in mono-lingual, English code bases this answer will suffice. I'm suspecting because most people coming here fall in this category this is the most popular answer.This answer however brings up the inherent problem that we can't compare text case insensitive until we know both texts are the same culture and we know  what that culture is. This is maybe a less popular answer, but I think it is more correct and that's why I marked it as such.","You could use the String.IndexOf Method and pass StringComparison.OrdinalIgnoreCase as the type of search to use:string title = ""STRING"";bool contains = title.IndexOf(""string"", StringComparison.OrdinalIgnoreCase) >= 0;Even better is defining a new extension method for string:public static class StringExtensions{    public static bool Contains(this string source, string toCheck, StringComparison comp)    {        return source?.IndexOf(toCheck, comp) >= 0;    }}Note, that null propagation ?. is available since C# 6.0 (VS 2015), for older versions useif (source == null) return false;return source.IndexOf(toCheck, comp) >= 0;USAGE:string title = ""STRING"";bool contains = title.Contains(""string"", StringComparison.OrdinalIgnoreCase);"
"data_i","edited Jul 04 '22 at 21:01","
        How do I iterate over the words of a string?
    ","How do I iterate over the words of a string composed of words separated by whitespace?Note that I'm not interested in C string functions or that kind of character manipulation/access. I prefer elegance over efficiency. My current solution:#include <iostream>#include <sstream>#include <string>using namespace std;int main() {    string s = ""Somewhere down the road"";    istringstream iss(s);    do {        string subs;        iss >> subs;        cout << ""Substring: "" << subs << endl;    } while (iss);}","I use this to split string by a delimiter. The first puts the results in a pre-constructed vector, the second returns a new vector.#include <string>#include <sstream>#include <vector>#include <iterator>template <typename Out>void split(const std::string &s, char delim, Out result) {    std::istringstream iss(s);    std::string item;    while (std::getline(iss, item, delim)) {        *result++ = item;    }}std::vector<std::string> split(const std::string &s, char delim) {    std::vector<std::string> elems;    split(s, delim, std::back_inserter(elems));    return elems;}Note that this solution does not skip empty tokens, so the following will find 4 items, one of which is empty:std::vector<std::string> x = split(""one:two::three"", ':');"
"data_i","edited Nov 29 '21 at 07:14","
        How can I convert a string to boolean in JavaScript?
    ","Can I convert a string representing a boolean value (e.g., 'true', 'false') into a intrinsic type in JavaScript?I have a hidden form in HTML that is updated based upon a user's selection within a list. This form contains some fields which represent boolean values and are dynamically populated with an intrinsic boolean value. However, once this value is placed into the hidden input field it becomes a string.The only way I could find to determine the field's boolean value, once it was converted into a string, was to depend upon the literal value of its string representation.var myValue = document.myForm.IS_TRUE.value;var isTrueSet = myValue == 'true';Is there a better way to accomplish this?","Do:var isTrueSet = (myValue === 'true');using the identity operator (===), which doesn't make any implicit type conversions when the compared variables have different types.This will set isTrueSet to a boolean true if the string is ""true"" and boolean false if it is string ""false"" or not set at all.Don't:You should probably be cautious about using these two methods for your specific needs:var myBool = Boolean(""false"");  // == truevar myBool = !!""false"";  // == trueAny string which isn't the empty string will evaluate to true by using them. Although they're the cleanest methods I can think of concerning to boolean conversion, I think they're not what you're looking for."
"data_i","edited Sep 10 '22 at 07:21","
        Creating multiline strings in JavaScript
    ","I have the following code in Ruby. I want to convert this code into JavaScript. What is the equivalent code in JS?text = <<""HERE""ThisIsAMultilineStringHERE","Update:ECMAScript 6 (ES6) introduces a new type of literal, namely template literals. They have many features, variable interpolation among others, but most importantly for this question, they can be multiline.A template literal is delimited by backticks:var html = `  <div>    <span>Some HTML here</span>  </div>`;(Note: I'm not advocating to use HTML in strings)Browser support is OK, but you can use transpilers to be more compatible.Original ES5 answer:Javascript doesn't have a here-document syntax. You can escape the literal newline, however, which comes close:""foo \bar"""
"data_i","edited Jan 20 '21 at 12:03","
        How to check if a string contains a substring in Bash
    ","I have a string in Bash:string=""My string""How can I test if it contains another string?if [ $string ?? 'foo' ]; then  echo ""It's there!""fiWhere ?? is my unknown operator. Do I use echo and grep?if echo ""$string"" | grep 'foo'; then  echo ""It's there!""fiThat looks a bit clumsy.","You can use Marcus's answer (* wildcards) outside a case statement, too, if you use double brackets:string='My long string'if [[ $string == *""My long""* ]]; then  echo ""It's there!""fiNote that spaces in the needle string need to be placed between double quotes, and the * wildcards should be outside. Also note that a simple comparison operator is used (i.e. ==), not the regex operator =~."
"data_i","edited Oct 27 '20 at 05:52","
        How can I change an element's class with JavaScript?
    ","How can I change the class of an HTML element in response to an onclick or any other events using JavaScript?","Modern HTML5 Techniques for changing classesModern browsers have added classList which provides methods to make it easier to manipulate classes without needing a library:document.getElementById(""MyElement"").classList.add('MyClass');document.getElementById(""MyElement"").classList.remove('MyClass');if ( document.getElementById(""MyElement"").classList.contains('MyClass') )document.getElementById(""MyElement"").classList.toggle('MyClass');Unfortunately, these do not work in Internet Explorer prior to v10, though there is a shim to add support for it to IE8 and IE9, available from this page. It is, though, getting more and more supported.Simple cross-browser solutionThe standard JavaScript way to select an element is using document.getElementById(""Id""), which is what the following examples use - you can of course obtain elements in other ways, and in the right situation may simply use this instead - however, going into detail on this is beyond the scope of the answer.To change all classes for an element:To replace all existing classes with one or more new classes, set the className attribute:document.getElementById(""MyElement"").className = ""MyClass"";(You can use a space-delimited list to apply multiple classes.)To add an additional class to an element:To add a class to an element, without removing/affecting existing values, append a space and the new classname, like so:document.getElementById(""MyElement"").className += "" MyClass"";To remove a class from an element:To remove a single class to an element, without affecting other potential classes, a simple regex replace is required:document.getElementById(""MyElement"").className =   document.getElementById(""MyElement"").className.replace      ( /(?:^|\s)MyClass(?!\S)/g , '' )/* Code wrapped for readability - above is all one statement */An explanation of this regex is as follows:(?:^|\s) # Match the start of the string or any single whitespace characterMyClass  # The literal text for the classname to remove(?!\S)   # Negative lookahead to verify the above is the whole classname         # Ensures there is no non-space character following         # (i.e. must be the end of the string or space)The g flag tells the replace to repeat as required, in case the class name has been added multiple times.To check if a class is already applied to an element:The same regex used above for removing a class can also be used as a check as to whether a particular class exists:if ( document.getElementById(""MyElement"").className.match(/(?:^|\s)MyClass(?!\S)/) )### Assigning these actions to onclick events:Whilst it is possible to write JavaScript directly inside the HTML event attributes (such as onclick=""this.className+=' MyClass'"") this is not recommended behaviour. Especially on larger applications, more maintainable code is achieved by separating HTML markup from JavaScript interaction logic.The first step to achieving this is by creating a function, and calling the function in the onclick attribute, for example:<script type=""text/javascript"">    function changeClass(){        // Code examples from above    }</script>...<button onclick=""changeClass()"">My Button</button>(It is not required to have this code in script tags, this is simply for the brevity of example, and including the JavaScript in a distinct file may be more appropriate.)The second step is to move the onclick event out of the HTML and into JavaScript, for example using addEventListener<script type=""text/javascript"">    function changeClass(){        // Code examples from above    }    window.onload = function(){        document.getElementById(""MyElement"").addEventListener( 'click', changeClass);    }</script>...<button id=""MyElement"">My Button</button>(Note that the window.onload part is required so that the contents of that function are executed after the HTML has finished loading - without this, the MyElement might not exist when the JavaScript code is called, so that line would fail.)JavaScript Frameworks and LibrariesThe above code is all in standard JavaScript, however, it is common practice to use either a framework or a library to simplify common tasks, as well as benefit from fixed bugs and edge cases that you might not think of when writing your code.Whilst some people consider it overkill to add a ~50  KB framework for simply changing a class, if you are doing any substantial amount of JavaScript work or anything that might have unusual cross-browser behavior, it is well worth considering.(Very roughly, a library is a set of tools designed for a specific task, whilst a framework generally contains multiple libraries and performs a complete set of duties.)The examples above have been reproduced below using jQuery, probably the most commonly used JavaScript library (though there are others worth investigating too).(Note that $ here is the jQuery object.)Changing Classes with jQuery:$('#MyElement').addClass('MyClass');$('#MyElement').removeClass('MyClass');if ( $('#MyElement').hasClass('MyClass') )In addition, jQuery provides a shortcut for adding a class if it doesn't apply, or removing a class that does:$('#MyElement').toggleClass('MyClass');### Assigning a function to a click event with jQuery:$('#MyElement').click(changeClass);or, without needing an id:$(':button:contains(My Button)').click(changeClass);"
"data_i","edited Aug 14 '21 at 07:41","
        How can I check if an object is an array?
    ","I'm trying to write a function that either accepts a list of strings, or a single string. If it's a string, then I want to convert it to an array with just the one item so I can loop over it without fear of an error.So how do I check if the variable is an array?","The method given in the ECMAScript standard to find the class of Object is to use the toString method from Object.prototype.if(Object.prototype.toString.call(someVar) === '[object Array]') {    alert('Array!');}Or you could use typeof to test if it is a string:if(typeof someVar === 'string') {    someVar = [someVar];}Or if you're not concerned about performance, you could just do a concat to a new empty Array.someVar = [].concat(someVar);There's also the constructor which you can query directly:if (somevar.constructor.name == ""Array"") {    // do something}Check out a thorough treatment from T.J. Crowder's blog, as posted in his comment below.Check out this benchmark to get an idea which method performs better: http://jsben.ch/#/QgYAVFrom @Bharath, convert a string to an array using ES6 for the question asked:const convertStringToArray = (object) => {   return (typeof object === 'string') ? Array(object) : object}Suppose:let m = 'bla'let n = ['bla','Meow']let y = convertStringToArray(m)let z = convertStringToArray(n)console.log('check y: '+JSON.stringify(y)) . // check y: ['bla']console.log('check y: '+JSON.stringify(z)) . // check y: ['bla','Meow']"
"data_i","edited Jun 05 '19 at 11:27","
        Git refusing to merge unrelated histories on rebase
    ","During git rebase origin/development the following error message is shown from Git:fatal: refusing to merge unrelated historiesError redoing merge 1234deadbeef1234deadbeefMy Git version is 2.9.0. It used to work fine in the previous version. How can I continue this rebase allowing unrelated histories with the forced flag introduced in the new release?","You can use --allow-unrelated-histories to force the merge to happen.The reason behind this is that default behavior has changed since Git 2.9:""git merge"" used to allow merging two branches that have no commonbase by default, which led to a brand new history of an existingproject created and then get pulled by an unsuspecting maintainer,which allowed an unnecessary parallel history merged into theexisting project. The command has been taught not to allow this bydefault, with an escape hatch --allow-unrelated-histories optionto be used in a rare event that merges histories of two projectsthat started their lives independently.See the Git release changelog for more information.More information can be found in this answer."
"data_i","edited Mar 17 '19 at 09:15","
        How do I concatenate two lists in Python?
    ","How do I concatenate two lists in Python?Example:listone = [1, 2, 3]listtwo = [4, 5, 6]Expected outcome:>>> joinedlist[1, 2, 3, 4, 5, 6]","Use the + operator to combine the lists:listone = [1, 2, 3]listtwo = [4, 5, 6]joinedlist = listone + listtwoOutput:>>> joinedlist[1, 2, 3, 4, 5, 6]"
"data_i","edited Jan 30 '21 at 15:19","
        Improve INSERT-per-second performance of SQLite
    ","Optimizing SQLite is tricky. Bulk-insert performance of a C application can vary from 85 inserts per second to over 96,000 inserts per second!Background: We are using SQLite as part of a desktop application. We have large amounts of configuration data stored in XML files that are parsed and loaded into an SQLite database for further processing when the application is initialized. SQLite is ideal for this situation because it's fast, it requires no specialized configuration, and the database is stored on disk as a single file.Rationale: Initially I was disappointed with the performance I was seeing. It turns-out that the performance of SQLite can vary significantly (both for bulk-inserts and selects) depending on how the database is configured and how you're using the API. It was not a trivial matter to figure out what all of the options and techniques were, so I thought it prudent to create this community wiki entry to share the results with Stack Overflow readers in order to save others the trouble of the same investigations.The Experiment: Rather than simply talking about performance tips in the general sense (i.e. ""Use a transaction!""), I thought it best to write some C code and actually measure the impact of various options. We're going to start with some simple data:A 28 MB TAB-delimited text file (approximately 865,000 records) of the complete transit schedule for the city of TorontoMy test machine is a 3.60 GHz P4 running Windows XP.The code is compiled with Visual C++ 2005 as ""Release"" with ""Full Optimization"" (/Ox) and Favor Fast Code (/Ot).I'm using the SQLite ""Amalgamation"", compiled directly into my test application. The SQLite version I happen to have is a bit older (3.6.7), but I suspect these results will be comparable to the latest release (please leave a comment if you think otherwise).Let's write some code!The Code: A simple C program that reads the text file line-by-line, splits the string into values and then inserts the data into an SQLite database. In this ""baseline"" version of the code, the database is created, but we won't actually insert data:/*************************************************************    Baseline code to experiment with SQLite performance.    Input data is a 28 MB TAB-delimited text file of the    complete Toronto Transit System schedule/route info    from http://www.toronto.ca/open/datasets/ttc-routes/**************************************************************/#include <stdio.h>#include <stdlib.h>#include <time.h>#include <string.h>#include ""sqlite3.h""#define INPUTDATA ""C:\\TTC_schedule_scheduleitem_10-27-2009.txt""#define DATABASE ""c:\\TTC_schedule_scheduleitem_10-27-2009.sqlite""#define TABLE ""CREATE TABLE IF NOT EXISTS TTC (id INTEGER PRIMARY KEY, Route_ID TEXT, Branch_Code TEXT, Version INTEGER, Stop INTEGER, Vehicle_Index INTEGER, Day Integer, Time TEXT)""#define BUFFER_SIZE 256int main(int argc, char **argv) {    sqlite3 * db;    sqlite3_stmt * stmt;    char * sErrMsg = 0;    char * tail = 0;    int nRetCode;    int n = 0;    clock_t cStartClock;    FILE * pFile;    char sInputBuf [BUFFER_SIZE] = ""\0"";    char * sRT = 0;  /* Route */    char * sBR = 0;  /* Branch */    char * sVR = 0;  /* Version */    char * sST = 0;  /* Stop Number */    char * sVI = 0;  /* Vehicle */    char * sDT = 0;  /* Date */    char * sTM = 0;  /* Time */    char sSQL [BUFFER_SIZE] = ""\0"";    /*********************************************/    /* Open the Database and create the Schema */    sqlite3_open(DATABASE, &db);    sqlite3_exec(db, TABLE, NULL, NULL, &sErrMsg);    /*********************************************/    /* Open input file and import into Database*/    cStartClock = clock();    pFile = fopen (INPUTDATA,""r"");    while (!feof(pFile)) {        fgets (sInputBuf, BUFFER_SIZE, pFile);        sRT = strtok (sInputBuf, ""\t"");     /* Get Route */        sBR = strtok (NULL, ""\t"");            /* Get Branch */        sVR = strtok (NULL, ""\t"");            /* Get Version */        sST = strtok (NULL, ""\t"");            /* Get Stop Number */        sVI = strtok (NULL, ""\t"");            /* Get Vehicle */        sDT = strtok (NULL, ""\t"");            /* Get Date */        sTM = strtok (NULL, ""\t"");            /* Get Time */        /* ACTUAL INSERT WILL GO HERE */        n++;    }    fclose (pFile);    printf(""Imported %d records in %4.2f seconds\n"", n, (clock() - cStartClock) / (double)CLOCKS_PER_SEC);    sqlite3_close(db);    return 0;}The ""Control""Running the code as-is doesn't actually perform any database operations, but it will give us an idea of how fast the raw C file I/O and string processing operations are.Imported 864913 records in 0.94secondsGreat! We can do 920,000 inserts per second, provided we don't actually do any inserts :-)The ""Worst-Case-Scenario""We're going to generate the SQL string using the values read from the file and invoke that SQL operation using sqlite3_exec:sprintf(sSQL, ""INSERT INTO TTC VALUES (NULL, '%s', '%s', '%s', '%s', '%s', '%s', '%s')"", sRT, sBR, sVR, sST, sVI, sDT, sTM);sqlite3_exec(db, sSQL, NULL, NULL, &sErrMsg);This is going to be slow because the SQL will be compiled into VDBE code for every insert and every insert will happen in its own transaction. How slow?Imported 864913 records in 9933.61secondsYikes! 2 hours and 45 minutes! That's only 85 inserts per second.Using a TransactionBy default, SQLite will evaluate every INSERT / UPDATE statement within a unique transaction. If performing a large number of inserts, it's advisable to wrap your operation in a transaction:sqlite3_exec(db, ""BEGIN TRANSACTION"", NULL, NULL, &sErrMsg);pFile = fopen (INPUTDATA,""r"");while (!feof(pFile)) {    ...}fclose (pFile);sqlite3_exec(db, ""END TRANSACTION"", NULL, NULL, &sErrMsg);Imported 864913 records in 38.03secondsThat's better. Simply wrapping all of our inserts in a single transaction improved our performance to 23,000 inserts per second.Using a Prepared StatementUsing a transaction was a huge improvement, but recompiling the SQL statement for every insert doesn't make sense if we using the same SQL over-and-over. Let's use sqlite3_prepare_v2 to compile our SQL statement once and then bind our parameters to that statement using sqlite3_bind_text:/* Open input file and import into the database */cStartClock = clock();sprintf(sSQL, ""INSERT INTO TTC VALUES (NULL, @RT, @BR, @VR, @ST, @VI, @DT, @TM)"");sqlite3_prepare_v2(db,  sSQL, BUFFER_SIZE, &stmt, &tail);sqlite3_exec(db, ""BEGIN TRANSACTION"", NULL, NULL, &sErrMsg);pFile = fopen (INPUTDATA,""r"");while (!feof(pFile)) {    fgets (sInputBuf, BUFFER_SIZE, pFile);    sRT = strtok (sInputBuf, ""\t"");   /* Get Route */    sBR = strtok (NULL, ""\t"");        /* Get Branch */    sVR = strtok (NULL, ""\t"");        /* Get Version */    sST = strtok (NULL, ""\t"");        /* Get Stop Number */    sVI = strtok (NULL, ""\t"");        /* Get Vehicle */    sDT = strtok (NULL, ""\t"");        /* Get Date */    sTM = strtok (NULL, ""\t"");        /* Get Time */    sqlite3_bind_text(stmt, 1, sRT, -1, SQLITE_TRANSIENT);    sqlite3_bind_text(stmt, 2, sBR, -1, SQLITE_TRANSIENT);    sqlite3_bind_text(stmt, 3, sVR, -1, SQLITE_TRANSIENT);    sqlite3_bind_text(stmt, 4, sST, -1, SQLITE_TRANSIENT);    sqlite3_bind_text(stmt, 5, sVI, -1, SQLITE_TRANSIENT);    sqlite3_bind_text(stmt, 6, sDT, -1, SQLITE_TRANSIENT);    sqlite3_bind_text(stmt, 7, sTM, -1, SQLITE_TRANSIENT);    sqlite3_step(stmt);    sqlite3_clear_bindings(stmt);    sqlite3_reset(stmt);    n++;}fclose (pFile);sqlite3_exec(db, ""END TRANSACTION"", NULL, NULL, &sErrMsg);printf(""Imported %d records in %4.2f seconds\n"", n, (clock() - cStartClock) / (double)CLOCKS_PER_SEC);sqlite3_finalize(stmt);sqlite3_close(db);return 0;Imported 864913 records in 16.27secondsNice! There's a little bit more code (don't forget to call sqlite3_clear_bindings and sqlite3_reset), but we've more than doubled our performance to 53,000 inserts per second.PRAGMA synchronous = OFFBy default, SQLite will pause after issuing a OS-level write command. This guarantees that the data is written to the disk. By setting synchronous = OFF, we are instructing SQLite to simply hand-off the data to the OS for writing and then continue. There's a chance that the database file may become corrupted if the computer suffers a catastrophic crash (or power failure) before the data is written to the platter:/* Open the database and create the schema */sqlite3_open(DATABASE, &db);sqlite3_exec(db, TABLE, NULL, NULL, &sErrMsg);sqlite3_exec(db, ""PRAGMA synchronous = OFF"", NULL, NULL, &sErrMsg);Imported 864913 records in 12.41secondsThe improvements are now smaller, but we're up to 69,600 inserts per second.PRAGMA journal_mode = MEMORYConsider storing the rollback journal in memory by evaluating PRAGMA journal_mode = MEMORY. Your transaction will be faster, but if you lose power or your program crashes during a transaction you database could be left in a corrupt state with a partially-completed transaction:/* Open the database and create the schema */sqlite3_open(DATABASE, &db);sqlite3_exec(db, TABLE, NULL, NULL, &sErrMsg);sqlite3_exec(db, ""PRAGMA journal_mode = MEMORY"", NULL, NULL, &sErrMsg);Imported 864913 records in 13.50secondsA little slower than the previous optimization at 64,000 inserts per second.PRAGMA synchronous = OFF and PRAGMA journal_mode = MEMORYLet's combine the previous two optimizations. It's a little more risky (in case of a crash), but we're just importing data (not running a bank):/* Open the database and create the schema */sqlite3_open(DATABASE, &db);sqlite3_exec(db, TABLE, NULL, NULL, &sErrMsg);sqlite3_exec(db, ""PRAGMA synchronous = OFF"", NULL, NULL, &sErrMsg);sqlite3_exec(db, ""PRAGMA journal_mode = MEMORY"", NULL, NULL, &sErrMsg);Imported 864913 records in 12.00secondsFantastic! We're able to do 72,000 inserts per second.Using an In-Memory DatabaseJust for kicks, let's build upon all of the previous optimizations and redefine the database filename so we're working entirely in RAM:#define DATABASE "":memory:""Imported 864913 records in 10.94secondsIt's not super-practical to store our database in RAM, but it's impressive that we can perform 79,000 inserts per second.Refactoring C CodeAlthough not specifically an SQLite improvement, I don't like the extra char* assignment operations in the while loop. Let's quickly refactor that code to pass the output of strtok() directly into sqlite3_bind_text(), and let the compiler try to speed things up for us:pFile = fopen (INPUTDATA,""r"");while (!feof(pFile)) {    fgets (sInputBuf, BUFFER_SIZE, pFile);    sqlite3_bind_text(stmt, 1, strtok (sInputBuf, ""\t""), -1, SQLITE_TRANSIENT); /* Get Route */    sqlite3_bind_text(stmt, 2, strtok (NULL, ""\t""), -1, SQLITE_TRANSIENT);    /* Get Branch */    sqlite3_bind_text(stmt, 3, strtok (NULL, ""\t""), -1, SQLITE_TRANSIENT);    /* Get Version */    sqlite3_bind_text(stmt, 4, strtok (NULL, ""\t""), -1, SQLITE_TRANSIENT);    /* Get Stop Number */    sqlite3_bind_text(stmt, 5, strtok (NULL, ""\t""), -1, SQLITE_TRANSIENT);    /* Get Vehicle */    sqlite3_bind_text(stmt, 6, strtok (NULL, ""\t""), -1, SQLITE_TRANSIENT);    /* Get Date */    sqlite3_bind_text(stmt, 7, strtok (NULL, ""\t""), -1, SQLITE_TRANSIENT);    /* Get Time */    sqlite3_step(stmt);        /* Execute the SQL Statement */    sqlite3_clear_bindings(stmt);    /* Clear bindings */    sqlite3_reset(stmt);        /* Reset VDBE */    n++;}fclose (pFile);Note: We are back to using a real database file. In-memory databases are fast, but not necessarily practicalImported 864913 records in 8.94secondsA slight refactoring to the string processing code used in our parameter binding has allowed us to perform 96,700 inserts per second. I think it's safe to say that this is plenty fast. As we start to tweak other variables (i.e. page size, index creation, etc.) this will be our benchmark.Summary (so far)I hope you're still with me! The reason we started down this road is that bulk-insert performance varies so wildly with SQLite, and it's not always obvious what changes need to be made to speed-up our operation. Using the same compiler (and compiler options), the same version of SQLite and the same data we've optimized our code and our usage of SQLite to go from a worst-case scenario of 85 inserts per second to over 96,000 inserts per second!CREATE INDEX then INSERT vs. INSERT then CREATE INDEXBefore we start measuring SELECT performance, we know that we'll be creating indices. It's been suggested in one of the answers below that when doing bulk inserts, it is faster to create the index after the data has been inserted (as opposed to creating the index first then inserting the data). Let's try:Create Index then Insert Datasqlite3_exec(db, ""CREATE  INDEX 'TTC_Stop_Index' ON 'TTC' ('Stop')"", NULL, NULL, &sErrMsg);sqlite3_exec(db, ""BEGIN TRANSACTION"", NULL, NULL, &sErrMsg);...Imported 864913 records in 18.13secondsInsert Data then Create Index...sqlite3_exec(db, ""END TRANSACTION"", NULL, NULL, &sErrMsg);sqlite3_exec(db, ""CREATE  INDEX 'TTC_Stop_Index' ON 'TTC' ('Stop')"", NULL, NULL, &sErrMsg);Imported 864913 records in 13.66secondsAs expected, bulk-inserts are slower if one column is indexed, but it does make a difference if the index is created after the data is inserted. Our no-index baseline is 96,000 inserts per second. Creating the index first then inserting data gives us 47,700 inserts per second, whereas inserting the data first then creating the index gives us 63,300 inserts per second.I'd gladly take suggestions for other scenarios to try... And will be compiling similar data for SELECT queries soon.","Several tips:Put inserts/updates in a transaction.For older versions of SQLite - Consider a less paranoid journal mode (pragma journal_mode). There is NORMAL, and then there is OFF, which can significantly increase insert speed if you're not too worried about the database possibly getting corrupted if the OS crashes. If your application crashes the data should be fine. Note that in newer versions, the OFF/MEMORY settings are not safe for application level crashes.Playing with page sizes makes a difference as well (PRAGMA page_size). Having larger page sizes can make reads and writes go a bit faster as larger pages are held in memory. Note that more memory will be used for your database.If you have indices, consider calling CREATE INDEX after doing all your inserts. This is significantly faster than creating the index and then doing your inserts.You have to be quite careful if you have concurrent access to SQLite, as the whole database is locked when writes are done, and although multiple readers are possible, writes will be locked out. This has been improved somewhat with the addition of a WAL in newer SQLite versions.Take advantage of saving space...smaller databases go faster. For instance, if you have key value pairs, try making the key an INTEGER PRIMARY KEY if possible, which will replace the implied unique row number column in the table.If you are using multiple threads, you can try using the shared page cache, which will allow loaded pages to be shared between threads, which can avoid expensive I/O calls.Don't use !feof(file)!I've also asked similar questions here and here."
"data_i","edited Nov 18 '18 at 11:13","
        How do I check if a list is empty?
    ","For example, if passed the following:a = []How do I check to see if a is empty?","if not a:    print(""List is empty"")Using the implicit booleanness of the empty list is quite Pythonic."
"data_i","edited May 31 '22 at 03:51","
        Echo newline in Bash prints literal \n
    ","How do I print a newline? This merely prints \n:$ echo -e ""Hello,\nWorld!""Hello,\nWorld!","Use printf instead:printf ""hello\nworld\n""printf behaves more consistently across different environments than echo."
"data_i","edited Jul 22 '22 at 11:06","
        ""Least Astonishment"" and the Mutable Default Argument
    ","Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:def foo(a=[]):    a.append(5)    return aPython novices would expect this function called with no parameter to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):>>> foo()[5]>>> foo()[5, 5]>>> foo()[5, 5, 5]>>> foo()[5, 5, 5, 5]>>> foo()A manager of mine once had his first encounter with this feature, and called it ""a dramatic design flaw"" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)Edit:Baczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:>>> def a():...     print(""a executed"")...     return []... >>>            >>> def b(x=a()):...     x.append(5)...     print(x)... a executed>>> b()[5]>>> b()[5, 5]To me, it seems that the design decision was relative to where to put the scope of parameters: inside the function, or ""together"" with it?Doing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be ""hybrid"" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.The actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.","Actually, this is not a design flaw, and it is not because of internals or performance. It comes simply from the fact that functions in Python are first-class objects, and not only a piece of code.As soon as you think of it this way, then it completely makes sense: a function is an object being evaluated on its definition; default parameters are kind of ""member data"" and therefore their state may change from one call to the other - exactly as in any other object.In any case, the effbot (Fredrik Lundh) has a very nice explanation of the reasons for this behavior in Default Parameter Values in Python.I found it very clear, and I really suggest reading it for a better knowledge of how function objects work."
"data_i","edited Jul 17 '22 at 20:41","
        How do I format a date in JavaScript?
    ","How do I format a Date object to a string?","If you need slightly less control over formatting than the currently accepted answer, Date#toLocaleDateString can be used to create standard locale-specific renderings. The locale and options arguments let applications specify the language whose formatting conventions should be used, and allow some customization of the rendering.Options key examples:day: The representation of the day. Possible values are ""numeric"", ""2-digit"".weekday: The representation of the weekday. Possible values are ""narrow"", ""short"", ""long"".year: The representation of the year. Possible values are ""numeric"", ""2-digit"".month: The representation of the month. Possible values are ""numeric"", ""2-digit"", ""narrow"", ""short"", ""long"".hour: The representation of the hour. Possible values are ""numeric"", ""2-digit"".minute:The representation of the minute. Possible values are ""numeric"", ""2-digit"".second: The representation of the second. Possible values are ""numeric"", 2-digit"".All these keys are optional.  You can change the number of options values based on your requirements, and this will also reflect the presence of each date time term.Note: If you would only like to configure the content options, but still use the current locale, passing null for the first parameter will cause an error.  Use undefined instead.For different languages:""en-US"": For American English""en-GB"": For British English""hi-IN"": For Hindi""ja-JP"": For JapaneseYou can use more language options.For examplevar options = { weekday: 'long', year: 'numeric', month: 'long', day: 'numeric' };var today  = new Date();console.log(today.toLocaleDateString(""en-US"")); // 9/17/2016console.log(today.toLocaleDateString(""en-US"", options)); // Saturday, September 17, 2016console.log(today.toLocaleDateString(""hi-IN"", options)); // शनिवार, 17 सितंबर 2016You can also use the toLocaleString() method for the same purpose. The only difference is this function provides the time when you don't pass any options.// Example9/17/2016, 1:21:34 PMReferences:toLocaleString()toLocaleDateString()"
"data_i","edited Nov 21 '19 at 09:48","
        Initialization of an ArrayList in one line
    ","I wanted to create a list of options for testing purposes. At first, I did this:ArrayList<String> places = new ArrayList<String>();places.add(""Buenos Aires"");places.add(""Córdoba"");places.add(""La Plata"");Then, I refactored the code as follows:ArrayList<String> places = new ArrayList<String>(    Arrays.asList(""Buenos Aires"", ""Córdoba"", ""La Plata""));Is there a better way to do this?","It would be simpler if you were to just declare it as a List - does it have to be an ArrayList?List<String> places = Arrays.asList(""Buenos Aires"", ""Córdoba"", ""La Plata"");Or if you have only one element:List<String> places = Collections.singletonList(""Buenos Aires"");This would mean that places is immutable (trying to change it will cause an UnsupportedOperationException exception to be thrown).To make a mutable list that is a concrete ArrayList you can create an ArrayList from the immutable list:ArrayList<String> places = new ArrayList<>(Arrays.asList(""Buenos Aires"", ""Córdoba"", ""La Plata""));And import the correct package:import java.util.Arrays;"
"data_i","edited Aug 26 '19 at 10:09","
        event.preventDefault() vs. return false
    ","When I want to prevent other event handlers from executing after a certain event is fired, I can use one of two techniques. I'll use jQuery in the examples, but this applies to plain-JS as well:1. event.preventDefault()$('a').click(function (e) {    // custom handling here    e.preventDefault();});2. return false$('a').click(function () {    // custom handling here    return false;});Is there any significant difference between those two methods of stopping event propagation?For me, return false; is simpler, shorter and probably less error prone than executing a method. With the method, you have to remember about correct casing, parenthesis, etc. Also, I have to define the first parameter in callback to be able to call the method. Perhaps, there are some reasons why I should avoid doing it like this and use preventDefault instead? What's the better way?","return false from within a jQuery event handler is effectively the same as calling both  e.preventDefault and e.stopPropagation on the passed jQuery.Event object.e.preventDefault() will prevent the default event from occuring, e.stopPropagation() will prevent the event from bubbling up and return false will do both. Note that this behaviour differs from normal (non-jQuery) event handlers, in which, notably, return false does not stop the event from bubbling up.Source: John ResigAny benefit to using event.preventDefault() over ""return false"" to cancel out an href click?"
"data_i","edited Jul 04 '22 at 21:05","
        Why is ""using namespace std;"" considered bad practice?
    ","I have heard using namespace std; is bad practice, and that I should use std::cout and std::cin directly instead.Why is this? Does it risk declaring variables that share the same name as something in the std namespace?","Consider two libraries called Foo and Bar:using namespace foo;using namespace bar;Everything works fine, and you can call Blah() from Foo and Quux() from Bar without problems. But one day you upgrade to a new version of Foo 2.0, which now offers a function called Quux(). Now you've got a conflict: Both Foo 2.0 and Bar import Quux() into your global namespace. This is going to take some effort to fix, especially if the function parameters happen to match.If you had used foo::Blah() and bar::Quux(), then the introduction of foo::Quux() would have been a non-event."
"data_i","edited Dec 15 '21 at 10:22","
        How do I copy a folder from remote to local using scp?
    ","How do I copy a folder from remote to local host using scp?I use ssh to log in to my server.Then, I would like to copy the remote folder foo to local /home/user/Desktop.How do I achieve this?","scp -r user@your.server.example.com:/path/to/foo /home/user/Desktop/By not including the trailing '/' at the end of foo, you will copy the directory itself (including contents), rather than only the contents of the directory.From man scp (See online manual)-r Recursively copy entire directories"
"data_i","edited Feb 24 '20 at 00:04","
        pretty-print JSON using JavaScript
    ","How can I display JSON in an easy-to-read (for human readers) format? I'm looking primarily for indentation and whitespace, with perhaps even colors / font-styles / etc.","Pretty-printing is implemented natively in JSON.stringify(). The third argument enables pretty printing and sets the spacing to use:var str = JSON.stringify(obj, null, 2); // spacing level = 2If you need syntax highlighting, you might use some regex magic like so:function syntaxHighlight(json) {    if (typeof json != 'string') {         json = JSON.stringify(json, undefined, 2);    }    json = json.replace(/&/g, '&amp;').replace(/</g, '&lt;').replace(/>/g, '&gt;');    return json.replace(/(""(\\u[a-zA-Z0-9]{4}|\\[^u]|[^\\""])*""(\s*:)?|\b(true|false|null)\b|-?\d+(?:\.\d*)?(?:[eE][+\-]?\d+)?)/g, function (match) {        var cls = 'number';        if (/^""/.test(match)) {            if (/:$/.test(match)) {                cls = 'key';            } else {                cls = 'string';            }        } else if (/true|false/.test(match)) {            cls = 'boolean';        } else if (/null/.test(match)) {            cls = 'null';        }        return '<span class=""' + cls + '"">' + match + '</span>';    });}See in action here: jsfiddleOr a full snippet provided below:function output(inp) {    document.body.appendChild(document.createElement('pre')).innerHTML = inp;}function syntaxHighlight(json) {    json = json.replace(/&/g, '&amp;').replace(/</g, '&lt;').replace(/>/g, '&gt;');    return json.replace(/(""(\\u[a-zA-Z0-9]{4}|\\[^u]|[^\\""])*""(\s*:)?|\b(true|false|null)\b|-?\d+(?:\.\d*)?(?:[eE][+\-]?\d+)?)/g, function (match) {        var cls = 'number';        if (/^""/.test(match)) {            if (/:$/.test(match)) {                cls = 'key';            } else {                cls = 'string';            }        } else if (/true|false/.test(match)) {            cls = 'boolean';        } else if (/null/.test(match)) {            cls = 'null';        }        return '<span class=""' + cls + '"">' + match + '</span>';    });}var obj = {a:1, 'b':'foo', c:[false,'false',null, 'null', {d:{e:1.3e5,f:'1.3e5'}}]};var str = JSON.stringify(obj, undefined, 4);output(str);output(syntaxHighlight(str));pre {outline: 1px solid #ccc; padding: 5px; margin: 5px; }.string { color: green; }.number { color: darkorange; }.boolean { color: blue; }.null { color: magenta; }.key { color: red; }"
"data_i","edited Jul 29 '20 at 09:41","
        JavaScript closure inside loops – simple practical example
    ","var funcs = [];// let's create 3 functionsfor (var i = 0; i < 3; i++) {  // and store them in funcs  funcs[i] = function() {    // each should log its value.    console.log(""My value: "" + i);  };}for (var j = 0; j < 3; j++) {  // and now let's run each one to see  funcs[j]();}It outputs this:My value: 3My value: 3My value: 3Whereas I'd like it to output:My value: 0My value: 1My value: 2The same problem occurs when the delay in running the function is caused by using event listeners:var buttons = document.getElementsByTagName(""button"");// let's create 3 functionsfor (var i = 0; i < buttons.length; i++) {  // as event listeners  buttons[i].addEventListener(""click"", function() {    // each should log its value.    console.log(""My value: "" + i);  });}<button>0</button><br /><button>1</button><br /><button>2</button>… or asynchronous code, e.g. using Promises:// Some async wait functionconst wait = (ms) => new Promise((resolve, reject) => setTimeout(resolve, ms));for (var i = 0; i < 3; i++) {  // Log `i` as soon as each promise resolves.  wait(i * 100).then(() => console.log(i));}It is also apparent in for in and for of loops:const arr = [1,2,3];const fns = [];for(var i in arr){  fns.push(() => console.log(`index: ${i}`));}for(var v of arr){  fns.push(() => console.log(`value: ${v}`));}for(var f of fns){  f();}What’s the solution to this basic problem?","Well, the problem is that the variable i, within each of your anonymous functions, is bound to the same variable outside of the function.ES6 solution: letECMAScript 6 (ES6) introduces new let and const keywords that are scoped differently than var-based variables. For example, in a loop with a let-based index, each iteration through the loop will have a new variable i with loop scope, so your code would work as you expect. There are many resources, but I'd recommend 2ality's block-scoping post as a great source of information.for (let i = 0; i < 3; i++) {  funcs[i] = function() {    console.log(""My value: "" + i);  };}Beware, though, that IE9-IE11 and Edge prior to Edge 14 support let but get the above wrong (they don't create a new i each time, so all the functions above would log 3 like they would if we used var). Edge 14 finally gets it right.ES5.1 solution: forEachWith the relatively widespread availability of the Array.prototype.forEach function (in 2015), it's worth noting that in those situations involving iteration primarily over an array of values, .forEach() provides a clean, natural way to get a distinct closure for every iteration. That is, assuming you've got some sort of array containing values (DOM references, objects, whatever), and the problem arises of setting up callbacks specific to each element, you can do this:var someArray = [ /* whatever */ ];// ...someArray.forEach(function(arrayElement) {  // ... code code code for this one element  someAsynchronousFunction(arrayElement, function() {    arrayElement.doSomething();  });});The idea is that each invocation of the callback function used with the .forEach loop will be its own closure. The parameter passed in to that handler is the array element specific to that particular step of the iteration. If it's used in an asynchronous callback, it won't collide with any of the other callbacks established at other steps of the iteration.If you happen to be working in jQuery, the $.each() function gives you a similar capability.Classic solution: ClosuresWhat you want to do is bind the variable within each function to a separate, unchanging value outside of the function:var funcs = [];function createfunc(i) {  return function() {    console.log(""My value: "" + i);  };}for (var i = 0; i < 3; i++) {  funcs[i] = createfunc(i);}for (var j = 0; j < 3; j++) {  // and now let's run each one to see  funcs[j]();}Since there is no block scope in JavaScript - only function scope - by wrapping the function creation in a new function, you ensure that the value of ""i"" remains as you intended."
"data_i","edited Aug 16 '22 at 15:34","
        Detecting an undefined object property
    ","How do I check if an object property in JavaScript is undefined?","The usual way to check if the value of a property is the special value undefined, is:if(o.myProperty === undefined) {  alert(""myProperty value is the special value `undefined`"");}To check if an object does not actually have such a property, and will therefore return undefined by default when you try to access it:if(!o.hasOwnProperty('myProperty')) {  alert(""myProperty does not exist"");}To check if the value associated with an identifier is the special value undefined, or if that identifier has not been declared:if(typeof myVariable === 'undefined') {  alert('myVariable is either the special value `undefined`, or it has not been declared');}Note: this last method is the only way to refer to an undeclared identifier without an early error, which is different from having a value of undefined.In versions of JavaScript prior to ECMAScript 5, the property named ""undefined"" on the global object was writeable, and therefore a simple check foo === undefined might behave unexpectedly if it had accidentally been redefined. In modern JavaScript, the property is read-only.However, in modern JavaScript, ""undefined"" is not a keyword, and so variables inside functions can be named ""undefined"" and shadow the global property.If you are worried about this (unlikely) edge case, you can use the void operator to get at the special undefined value itself:if(myVariable === void 0) {  alert(""myVariable is the special value `undefined`"");}"
"data_i","edited Jun 05 '22 at 22:16","
        How do I pass a variable by reference?
    ","Are parameters passed by reference or by value? How do I pass by reference so that the code below outputs 'Changed' instead of 'Original'?class PassByReference:    def __init__(self):        self.variable = 'Original'        self.change(self.variable)        print(self.variable)    def change(self, var):        var = 'Changed'","Arguments are passed by assignment. The rationale behind this is twofold:the parameter passed in is actually a reference to an object (but the reference is passed by value)some data types are mutable, but others aren'tSo:If you pass a mutable object into a method, the method gets a reference to that same object and you can mutate it to your heart's delight, but if you rebind the reference in the method, the outer scope will know nothing about it, and after you're done, the outer reference will still point at the original object. If you pass an immutable object to a method, you still can't rebind the outer reference, and you can't even mutate the object.To make it even more clear, let's have some examples. List - a mutable typeLet's try to modify the list that was passed to a method:def try_to_change_list_contents(the_list):    print('got', the_list)    the_list.append('four')    print('changed to', the_list)outer_list = ['one', 'two', 'three']print('before, outer_list =', outer_list)try_to_change_list_contents(outer_list)print('after, outer_list =', outer_list)Output:before, outer_list = ['one', 'two', 'three']got ['one', 'two', 'three']changed to ['one', 'two', 'three', 'four']after, outer_list = ['one', 'two', 'three', 'four']Since the parameter passed in is a reference to outer_list, not a copy of it, we can use the mutating list methods to change it and have the changes reflected in the outer scope.Now let's see what happens when we try to change the reference that was passed in as a parameter:def try_to_change_list_reference(the_list):    print('got', the_list)    the_list = ['and', 'we', 'can', 'not', 'lie']    print('set to', the_list)outer_list = ['we', 'like', 'proper', 'English']print('before, outer_list =', outer_list)try_to_change_list_reference(outer_list)print('after, outer_list =', outer_list)Output:before, outer_list = ['we', 'like', 'proper', 'English']got ['we', 'like', 'proper', 'English']set to ['and', 'we', 'can', 'not', 'lie']after, outer_list = ['we', 'like', 'proper', 'English']Since the the_list parameter was passed by value, assigning a new list to it had no effect that the code outside the method could see. The the_list was a copy of the outer_list reference, and we had the_list point to a new list, but there was no way to change where outer_list pointed.String - an immutable typeIt's immutable, so there's nothing we can do to change the contents of the stringNow, let's try to change the referencedef try_to_change_string_reference(the_string):    print('got', the_string)    the_string = 'In a kingdom by the sea'    print('set to', the_string)outer_string = 'It was many and many a year ago'print('before, outer_string =', outer_string)try_to_change_string_reference(outer_string)print('after, outer_string =', outer_string)Output:before, outer_string = It was many and many a year agogot It was many and many a year agoset to In a kingdom by the seaafter, outer_string = It was many and many a year agoAgain, since the the_string parameter was passed by value, assigning a new string to it had no effect that the code outside the method could see. The the_string was a copy of the outer_string reference, and we had the_string point to a new string, but there was no way to change where outer_string pointed.I hope this clears things up a little.EDIT: It's been noted that this doesn't answer the question that @David originally asked, ""Is there something I can do to pass the variable by actual reference?"". Let's work on that.How do we get around this?As @Andrea's answer shows, you could return the new value. This doesn't change the way things are passed in, but does let you get the information you want back out:def return_a_whole_new_string(the_string):    new_string = something_to_do_with_the_old_string(the_string)    return new_string# then you could call it likemy_string = return_a_whole_new_string(my_string)If you really wanted to avoid using a return value, you could create a class to hold your value and pass it into the function or use an existing class, like a list:def use_a_wrapper_to_simulate_pass_by_reference(stuff_to_change):    new_string = something_to_do_with_the_old_string(stuff_to_change[0])    stuff_to_change[0] = new_string# then you could call it likewrapper = [my_string]use_a_wrapper_to_simulate_pass_by_reference(wrapper)do_something_with(wrapper[0])Although this seems a little cumbersome."
"data_i","edited Sep 18 '22 at 10:42","
        How do I select rows from a DataFrame based on column values?
    ","How can I select rows from a DataFrame based on values in some column in Pandas?In SQL, I would use:SELECT *FROM tableWHERE column_name = some_value","To select rows whose column value equals a scalar, some_value, use ==:df.loc[df['column_name'] == some_value]To select rows whose column value is in an iterable, some_values, use isin:df.loc[df['column_name'].isin(some_values)]Combine multiple conditions with &: df.loc[(df['column_name'] >= A) & (df['column_name'] <= B)]Note the parentheses. Due to Python's operator precedence rules, & binds more tightly than <= and >=. Thus, the parentheses in the last example are necessary. Without the parentheses df['column_name'] >= A & df['column_name'] <= Bis parsed as df['column_name'] >= (A & df['column_name']) <= Bwhich results in a Truth value of a Series is ambiguous error.To select rows whose column value does not equal some_value, use !=:df.loc[df['column_name'] != some_value]isin returns a boolean Series, so to select rows whose value is not in some_values, negate the boolean Series using ~:df.loc[~df['column_name'].isin(some_values)]For example,import pandas as pdimport numpy as npdf = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),                   'B': 'one one two three two two one three'.split(),                   'C': np.arange(8), 'D': np.arange(8) * 2})print(df)#      A      B  C   D# 0  foo    one  0   0# 1  bar    one  1   2# 2  foo    two  2   4# 3  bar  three  3   6# 4  foo    two  4   8# 5  bar    two  5  10# 6  foo    one  6  12# 7  foo  three  7  14print(df.loc[df['A'] == 'foo'])yields     A      B  C   D0  foo    one  0   02  foo    two  2   44  foo    two  4   86  foo    one  6  127  foo  three  7  14If you have multiple values you want to include, put them in alist (or more generally, any iterable) and use isin:print(df.loc[df['B'].isin(['one','three'])])yields     A      B  C   D0  foo    one  0   01  bar    one  1   23  bar  three  3   66  foo    one  6  127  foo  three  7  14Note, however, that if you wish to do this many times, it is more efficient tomake an index first, and then use df.loc:df = df.set_index(['B'])print(df.loc['one'])yields       A  C   DB              one  foo  0   0one  bar  1   2one  foo  6  12or, to include multiple values from the index use df.index.isin:df.loc[df.index.isin(['one','two'])]yields       A  C   DB              one  foo  0   0one  bar  1   2two  foo  2   4two  foo  4   8two  bar  5  10one  foo  6  12"
"data_i","edited Apr 01 '22 at 01:38","
        How do I clone a list so that it doesn't change unexpectedly after assignment?
    ","While using new_list = my_list, any modifications to new_list changes my_list every time. Why is this, and how can I clone or copy the list to prevent it?","new_list = my_list doesn't actually create a second list. The assignment just copies the reference to the list, not the actual list, so both new_list and my_list refer to the same list after the assignment.To actually copy the list, you have several options:You can use the builtin list.copy() method (available since Python 3.3):new_list = old_list.copy()You can slice it:new_list = old_list[:]Alex Martelli's opinion (at least back in 2007) about this is, that it is a weird syntax and it does not make sense to use it ever. ;) (In his opinion, the next one is more readable).You can use the built in list() constructor:new_list = list(old_list)You can use generic copy.copy():import copynew_list = copy.copy(old_list)This is a little slower than list() because it has to find out the datatype of old_list first.If you need to copy the elements of the list as well, use generic copy.deepcopy():import copynew_list = copy.deepcopy(old_list)Obviously the slowest and most memory-needing method, but sometimes unavoidable. This operates recursively; it will handle any number of levels of nested lists (or other containers).Example:import copyclass Foo(object):    def __init__(self, val):         self.val = val    def __repr__(self):        return f'Foo({self.val!r})'foo = Foo(1)a = ['foo', foo]b = a.copy()c = a[:]d = list(a)e = copy.copy(a)f = copy.deepcopy(a)# edit orignal list and instance a.append('baz')foo.val = 5print(f'original: {a}\nlist.copy(): {b}\nslice: {c}\nlist(): {d}\ncopy: {e}\ndeepcopy: {f}')Result:original: ['foo', Foo(5), 'baz']list.copy(): ['foo', Foo(5)]slice: ['foo', Foo(5)]list(): ['foo', Foo(5)]copy: ['foo', Foo(5)]deepcopy: ['foo', Foo(1)]"
"data_i","edited Apr 08 '21 at 23:01","
        How do you disable browser autocomplete on web form field / input tags?
    ","How do you disable autocomplete in the major browsers for a specific input (or form field)?","Firefox 30 ignores autocomplete=""off"" for passwords, opting to prompt the user instead whether the password should be stored on the client. Note the following commentary from May 5, 2014:The password manager always prompts if it wants to save a password. Passwords are not saved without permission from the user.We are the third browser to implement this change, after IE and Chrome.According to the Mozilla Developer Network documentation, the Boolean form element attribute autocomplete prevents form data from being cached in older browsers.<input type=""text"" name=""foo"" autocomplete=""off"" />"
"data_i","edited Sep 26 '19 at 09:21","
        How do I disable the resizable property of a textarea?
    ","I want to disable the resizable property of a textarea.Currently, I can resize a textarea by clicking on the bottom right corner of the textarea and dragging the mouse. How can I disable this?","The following CSS rule disables resizing behavior for textarea elements:textarea {  resize: none;}To disable it for some (but not all) textareas, there are a couple of options.You can use class attribute in your tag(<textarea class=""textarea1"">):.textarea1 {  resize: none;}To disable a specific textarea with the name attribute set to foo (i.e., <textarea name=""foo""></textarea>):textarea[name=foo] {  resize: none;}Or, using an id attribute (i.e., <textarea id=""foo""></textarea>):#foo {  resize: none;}The W3C page lists possible values for resizing restrictions: none, both, horizontal, vertical, and inherit:textarea {  resize: vertical; /* user can resize vertically, but width is fixed */}Review a decent compatibility page to see what browsers currently support this feature. As Jon Hulka has commented, the dimensions can be further restrained in CSS using max-width, max-height, min-width, and min-height.Super important to know:This property does nothing unless the overflow property is something other than visible, which is the default for most elements. So generally to use this, you'll have to set something like overflow: scroll;Quote by Sara Cope,http://css-tricks.com/almanac/properties/r/resize/"
"data_i","edited Feb 26 '20 at 20:53","
        Add a column with a default value to an existing table in SQL Server
    ","How can I add a column with a default value to an existing table in SQL Server 2000 / SQL Server 2005?","Syntax:ALTER TABLE {TABLENAME} ADD {COLUMNNAME} {TYPE} {NULL|NOT NULL} CONSTRAINT {CONSTRAINT_NAME} DEFAULT {DEFAULT_VALUE}WITH VALUESExample:ALTER TABLE SomeTable        ADD SomeCol Bit NULL --Or NOT NULL. CONSTRAINT D_SomeTable_SomeCol --When Omitted a Default-Constraint Name is autogenerated.    DEFAULT (0)--Optional Default-Constraint.WITH VALUES --Add if Column is Nullable and you want the Default Value for Existing Records.Notes:Optional Constraint Name:If you leave out CONSTRAINT D_SomeTable_SomeCol then SQL Server will autogenerate    a Default-Contraint with a funny Name like: DF__SomeTa__SomeC__4FB7FEF6Optional With-Values Statement:The WITH VALUES is only needed when your Column is Nullable    and you want the Default Value used for Existing Records.If your Column is NOT NULL, then it will automatically use the Default Value    for all Existing Records, whether you specify WITH VALUES or not.How Inserts work with a Default-Constraint:If you insert a Record into SomeTable and do not Specify SomeCol's value, then it will Default to 0.If you insert a Record and Specify SomeCol's value as NULL (and your column allows nulls),    then the Default-Constraint will not be used and NULL will be inserted as the Value.Notes were based on everyone's great feedback below.Special Thanks to:    @Yatrix, @WalterStabosz, @YahooSerious, and @StackMan for their Comments."
"data_i","edited May 08 '22 at 18:13","
        How to iterate over a dictionary?
    ","I've seen a few different ways to iterate over a dictionary in C#.  Is there a standard way?","foreach(KeyValuePair<string, string> entry in myDictionary){    // do something with entry.Value or entry.Key}"
"data_i","edited May 21 '19 at 17:18","
        What is the difference between Python's list methods append and extend?
    ","What's the difference between the list methods append() and extend()?","append appends a specified object at the end of the list:>>> x = [1, 2, 3]>>> x.append([4, 5])>>> print(x)[1, 2, 3, [4, 5]]extend extends the list by appending elements from the specified iterable:>>> x = [1, 2, 3]>>> x.extend([4, 5])>>> print(x)[1, 2, 3, 4, 5]"
"data_i","edited Apr 01 '22 at 01:47","
        What does ** (double star/asterisk) and * (star/asterisk) do for parameters?
    ","What do *args and **kwargs mean?def foo(x, y, *args):def bar(x, y, **kwargs):","The *args and **kwargs is a common idiom to allow arbitrary number of arguments to functions as described in the section more on defining functions in the Python documentation.The *args will give you all function parameters as a tuple:def foo(*args):    for a in args:        print(a)        foo(1)# 1foo(1,2,3)# 1# 2# 3The **kwargs will give you allkeyword arguments except for those corresponding to a formal parameter as a dictionary.def bar(**kwargs):    for a in kwargs:        print(a, kwargs[a])  bar(name='one', age=27)# name one# age 27Both idioms can be mixed with normal arguments to allow a set of fixed and some variable arguments:def foo(kind, *args, **kwargs):   passIt is also possible to use this the other way around:def foo(a, b, c):    print(a, b, c)obj = {'b':10, 'c':'lee'}foo(100,**obj)# 100 10 leeAnother usage of the *l idiom is to unpack argument lists when calling a function.def foo(bar, lee):    print(bar, lee)l = [1,2]foo(*l)# 1 2In Python 3 it is possible to use *l on the left side of an assignment (Extended Iterable Unpacking), though it gives a list instead of a tuple in this context:first, *rest = [1,2,3,4]first, *l, last = [1,2,3,4]Also Python 3 adds new semantic (refer PEP 3102):def func(arg1, arg2, arg3, *, kwarg1, kwarg2):    passFor example the following works in python 3 but not python 2:>>> x = [1, 2]>>> [*x][1, 2]>>> [*x, 3, 4][1, 2, 3, 4]>>> x = {1:1, 2:2}>>> x{1: 1, 2: 2}>>> {**x, 3:3, 4:4}{1: 1, 2: 2, 3: 3, 4: 4}Such function accepts only 3 positional arguments, and everything after * can only be passed as keyword arguments.Note:A Python dict, semantically used for keyword argument passing, are arbitrarily ordered. However, in Python 3.6, keyword arguments are guaranteed to remember insertion order.""The order of elements in **kwargs now corresponds to the order in which keyword arguments were passed to the function."" - What’s New In Python 3.6In fact, all dicts in CPython 3.6 will remember insertion order as an implementation detail, this becomes standard in Python 3.7."
"data_i","edited Jul 11 '22 at 06:25","
        How do I make git use the editor of my choice for editing commit messages?
    ","How do I globally configure git to use a particular editor (e.g. vim) for commit messages?","Setting the default editor for GitPick one:Set core.editor in your Git config:git config --global core.editor ""vim""Set the GIT_EDITOR environment variable:export GIT_EDITOR=vimSetting the default editor for all programsSet the standardized VISUAL and EDITOR environment variables*:export VISUAL=vimexport EDITOR=""$VISUAL""NOTE: Setting both is not necessarily needed, but some programs may not use the more-correct VISUAL. See VISUAL vs. EDITOR.Fixing compatibility issuesSome editors require a --wait flag, or they will open a blank page. For example:Sublime Text (if correctly set up; or use the full path to the executable in place of subl):export VISUAL=""subl --wait""VS Code (after adding the shell command):export VISUAL=""code --wait"""
"data_i","edited Jun 13 '22 at 00:08","
        How do I make a time delay?
    ","How do I put a time delay in a Python script?","This delays for 2.5 seconds:import timetime.sleep(2.5)Here is another example where something is run approximately once a minute:import timewhile True:    print(""This prints once a minute."")    time.sleep(60) # Delay for 1 minute (60 seconds)."
"data_i","edited Jul 25 '22 at 11:27","
        How to stop EditText from gaining focus when an activity starts in Android?
    ","I have an Activity in Android, with two elements:EditTextListViewWhen my Activity starts, the EditText immediately has the input focus (flashing cursor). I don't want any control to have input focus at startup. I tried:EditText.setSelected(false);EditText.setFocusable(false);No luck. How can I convince the EditText to not select itself when the Activity starts?","Adding the tags android:focusableInTouchMode=""true"" and android:focusable=""true"" to the parent layout (e.g. LinearLayout or ConstraintLayout) like in the following example, will fix the problem.<!-- Dummy item to prevent AutoCompleteTextView from receiving focus --><LinearLayout    android:focusable=""true""     android:focusableInTouchMode=""true""    android:layout_width=""0px""     android:layout_height=""0px""/><!-- :nextFocusUp and :nextFocusLeft have been set to the id of this componentto prevent the dummy from receiving focus again --><AutoCompleteTextView android:id=""@+id/autotext""    android:layout_width=""fill_parent""     android:layout_height=""wrap_content""    android:nextFocusUp=""@id/autotext""     android:nextFocusLeft=""@id/autotext""/>"
"data_i","edited Jul 18 '22 at 18:45","
        How do I find and restore a deleted file in a Git repository?
    ","Say I'm in a Git repository. I delete a file and commit that change. I continue working and make some more commits. Then, I discover that I need to restore that file after deleting it.I know I can checkout a file using git checkout <commit> -- filename.txt, but I don't know when that file was deleted.How do I find the commit that deleted a given filename?How do I restore that file back into my working copy?","Find the last commit that affected the given path. As the file isn't in the HEAD commit, that previous commit must have deleted it.git rev-list -n 1 HEAD -- <file_path>Then checkout the version at the commit before, using the caret (^) symbol:git checkout <deleting_commit>^ -- <file_path>Or in one command, if $file is the file in question.git checkout $(git rev-list -n 1 HEAD -- ""$file"")^ -- ""$file""If you are using zsh and have the EXTENDED_GLOB option enabled, the caret symbol won't work. You can use ~1 instead.git checkout $(git rev-list -n 1 HEAD -- ""$file"")~1 -- ""$file"""
"data_i","edited Oct 19 '21 at 20:41","
        How do I test a class that has private methods, fields or inner classes?
    ","How do I use JUnit to test a class that has internal private methods, fields or nested classes?It seems bad to change the access modifier for a method just to be able to run a test.","If you have somewhat of a legacy Java application, and you're not allowed to change the visibility of your methods, the best way to test private methods is to use reflection.Internally we're using helpers to get/set private and private static variables as well as invoke private and private static methods. The following patterns will let you do pretty much anything related to the private methods and fields. Of course, you can't change private static final variables through reflection.Method method = TargetClass.getDeclaredMethod(methodName, argClasses);method.setAccessible(true);return method.invoke(targetObject, argObjects);And for fields:Field field = TargetClass.getDeclaredField(fieldName);field.setAccessible(true);field.set(object, value);Notes:TargetClass.getDeclaredMethod(methodName, argClasses) lets you look into private methods. The same thing applies forgetDeclaredField.The setAccessible(true) is required to play around with privates."
"data_i","edited Sep 16 '22 at 07:59","
        Why does my JavaScript code receive a ""No 'Access-Control-Allow-Origin' header is present on the requested resource"" error, while Postman does not?
    ","Mod note: This question is about why XMLHttpRequest/fetch/etc. on the browser are subject to the Same Access Policy restrictions (you get errors mentioning CORB or CORS) while Postman is not. This question is not about how to fix a ""No 'Access-Control-Allow-Origin'..."" error. It's about why they happen.Please stop posting:CORS configurations for every language/framework under the sun. Instead find your relevant language/framework's question.3rd party services that allow a request to circumvent CORSCommand line options for turning off CORS for various browsersI am trying to do authorization using JavaScript by connecting to the RESTful API built-in Flask. However, when I make the request, I get the following error:XMLHttpRequest cannot load http://myApiUrl/login. No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'null' is therefore not allowed access.I know that the API or remote resource must set the header, but why did it work when I made the request via the Chrome extension Postman?This is the request code:$.ajax({      type: 'POST',      dataType: 'text',      url: api,      username: 'user',      password: 'pass',      crossDomain: true,      xhrFields: {        withCredentials: true,      },    })      .done(function (data) {        console.log('done');      })      .fail(function (xhr, textStatus, errorThrown) {        alert(xhr.responseText);        alert(textStatus);      });","If I understood it right you are doing an XMLHttpRequest to a different domain than your page is on. So the browser is blocking it as it usually allows a request in the same origin for security reasons. You need to do something different when you want to do a cross-domain request.When you are using Postman they are not restricted by this policy. Quoted from Cross-Origin XMLHttpRequest:Regular web pages can use the XMLHttpRequest object to send and receive data from remote servers, but they're limited by the same origin policy. Extensions aren't so limited. An extension can talk to remote servers outside of its origin, as long as it first requests cross-origin permissions."
"data_i","edited Jun 03 '21 at 07:58","
        How can I upload files asynchronously with jQuery?
    ","I would like to upload a file asynchronously with jQuery. $(document).ready(function () {    $(""#uploadbutton"").click(function () {        var filename = $(""#file"").val();        $.ajax({            type: ""POST"",            url: ""addFile.do"",            enctype: 'multipart/form-data',            data: {                file: filename            },            success: function () {                alert(""Data Uploaded: "");            }        });    });});<script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.0/jquery.min.js""></script><span>File</span><input type=""file"" id=""file"" name=""file"" size=""10""/><input id=""uploadbutton"" type=""button"" value=""Upload""/>Instead of the file being uploaded, I am only getting the filename. What can I do to fix this problem?","With HTML5 you can make file uploads with Ajax and jQuery. Not only that, you can do file validations (name, size, and MIME type) or handle the progress event with the HTML5 progress tag (or a div). Recently I had to make a file uploader, but I didn't want to use Flash nor Iframes or plugins and after some research I came up with the solution.The HTML:<form enctype=""multipart/form-data"">    <input name=""file"" type=""file"" />    <input type=""button"" value=""Upload"" /></form><progress></progress>First, you can do some validation if you want. For example, in the .on('change') event of the file:$(':file').on('change', function () {  var file = this.files[0];  if (file.size > 1024) {    alert('max upload size is 1k');  }  // Also see .name, .type});Now the $.ajax() submit with the button's click:$(':button').on('click', function () {  $.ajax({    // Your server script to process the upload    url: 'upload.php',    type: 'POST',    // Form data    data: new FormData($('form')[0]),    // Tell jQuery not to process data or worry about content-type    // You *must* include these options!    cache: false,    contentType: false,    processData: false,    // Custom XMLHttpRequest    xhr: function () {      var myXhr = $.ajaxSettings.xhr();      if (myXhr.upload) {        // For handling the progress of the upload        myXhr.upload.addEventListener('progress', function (e) {          if (e.lengthComputable) {            $('progress').attr({              value: e.loaded,              max: e.total,            });          }        }, false);      }      return myXhr;    }  });});As you can see, with HTML5 (and some research) file uploading not only becomes possible but super easy. Try it with Google Chrome as some of the HTML5 components of the examples aren't available in every browser."
"data_i","edited Dec 16 '18 at 05:11","
        Is it possible to apply CSS to half of a character?
    ","What I am looking for:A way to style one HALF of a character. (In this case, half the letter being transparent)What I have currently searched for and tried (With no luck):Methods for styling half of a character/letterStyling part of a character with CSS or JavaScriptApply CSS to 50% of a characterBelow is an example of what I am trying to obtain.Does a CSS or JavaScript solution exist for this, or am I going to have to resort to images? I would prefer not to go the image route as this text will end up being generated dynamically.UPDATE:Since many have asked why I would ever want to style half of a character, this is why. My city had recently spent $250,000 to define a new ""brand"" for itself. This logo is what they came up with. Many people have complained about the simplicity and lack of creativity and continue to do so. My goal was to come up with this website as a joke. Type in 'Halifax' and you will see what I mean.","Now on GitHub as a Plugin! Feel free to fork and improve.Demo | Download Zip | Half-Style.com (Redirects to GitHub)Pure CSS for a Single CharacterJavaScript used for automation across text or multiple charactersPreserves Text Accessibility for screen readers for the blind or visuallyimpairedPart 1: Basic SolutionDemo: http://jsfiddle.net/arbel/pd9yB/1694/This works on any dynamic text, or a single character, and is all automated. All you need to do is add a class on the target text and the rest is taken care of.Also, the accessibility of the original text is preserved for screen readers for the blind or visually impaired.Explanation for a single character:Pure CSS. All you need to do is to apply .halfStyle class to each element that contains the character you want to be half-styled.For each span element containing the character, you can create a data attribute, for example here data-content=""X"", and on the pseudo element use content: attr(data-content); so the .halfStyle:before class will be dynamic and you won't need to hard code it for every instance.Explanation for any text:Simply add textToHalfStyle class to the element containing the text.// jQuery for automated modejQuery(function($) {    var text, chars, $el, i, output;    // Iterate over all class occurences    $('.textToHalfStyle').each(function(idx, el) {    $el = $(el);    text = $el.text();    chars = text.split('');    // Set the screen-reader text    $el.html('<span style=""position: absolute !important;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);"">' + text + '</span>');    // Reset output for appending    output = '';    // Iterate over all chars in the text    for (i = 0; i < chars.length; i++) {        // Create a styled element for each character and append to container        output += '<span aria-hidden=""true"" class=""halfStyle"" data-content=""' + chars[i] + '"">' + chars[i] + '</span>';    }    // Write to DOM only once    $el.append(output);  });});.halfStyle {    position: relative;    display: inline-block;    font-size: 80px; /* or any font size will work */    color: black; /* or transparent, any color */    overflow: hidden;    white-space: pre; /* to preserve the spaces from collapsing */}.halfStyle:before {    display: block;    z-index: 1;    position: absolute;    top: 0;    left: 0;    width: 50%;    content: attr(data-content); /* dynamic content for the pseudo element */    overflow: hidden;    color: #f00;}<script src=""https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js""></script><p>Single Characters:</p><span class=""halfStyle"" data-content=""X"">X</span><span class=""halfStyle"" data-content=""Y"">Y</span><span class=""halfStyle"" data-content=""Z"">Z</span><span class=""halfStyle"" data-content=""A"">A</span><hr/><p>Automated:</p><span class=""textToHalfStyle"">Half-style, please.</span>(JSFiddle demo)Part 2: Advanced solution - Independent left and right partsWith this solution you can style left and right parts, individually and independently.Everything is the same, only more advanced CSS does the magic.jQuery(function($) {    var text, chars, $el, i, output;    // Iterate over all class occurences    $('.textToHalfStyle').each(function(idx, el) {        $el = $(el);        text = $el.text();        chars = text.split('');        // Set the screen-reader text        $el.html('<span style=""position: absolute !important;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);"">' + text + '</span>');        // Reset output for appending        output = '';        // Iterate over all chars in the text        for (i = 0; i < chars.length; i++) {            // Create a styled element for each character and append to container            output += '<span aria-hidden=""true"" class=""halfStyle"" data-content=""' + chars[i] + '"">' + chars[i] + '</span>';        }        // Write to DOM only once        $el.append(output);    });});.halfStyle {    position: relative;    display: inline-block;    font-size: 80px; /* or any font size will work */    color: transparent; /* hide the base character */    overflow: hidden;    white-space: pre; /* to preserve the spaces from collapsing */}.halfStyle:before { /* creates the left part */    display: block;    z-index: 1;    position: absolute;    top: 0;    width: 50%;    content: attr(data-content); /* dynamic content for the pseudo element */    overflow: hidden;    pointer-events: none; /* so the base char is selectable by mouse */    color: #f00; /* for demo purposes */    text-shadow: 2px -2px 0px #af0; /* for demo purposes */}.halfStyle:after { /* creates the right part */    display: block;    direction: rtl; /* very important, will make the width to start from right */    position: absolute;    z-index: 2;    top: 0;    left: 50%;    width: 50%;    content: attr(data-content); /* dynamic content for the pseudo element */    overflow: hidden;    pointer-events: none; /* so the base char is selectable by mouse */    color: #000; /* for demo purposes */    text-shadow: 2px 2px 0px #0af; /* for demo purposes */}<script src=""https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js""></script><p>Single Characters:</p><span class=""halfStyle"" data-content=""X"">X</span><span class=""halfStyle"" data-content=""Y"">Y</span><span class=""halfStyle"" data-content=""Z"">Z</span><span class=""halfStyle"" data-content=""A"">A</span><hr/><p>Automated:</p><span class=""textToHalfStyle"">Half-style, please.</span>(JSFiddle demo)Part 3: Mix-Match and ImproveNow that we know what is possible, let's create some variations.-Horizontal Half PartsWithout Text Shadow:Possibility of Text Shadow for each half part independently:// jQuery for automated modejQuery(function($) {    var text, chars, $el, i, output;    // Iterate over all class occurences    $('.textToHalfStyle').each(function(idx, el) {        $el = $(el);        text = $el.text();        chars = text.split('');        // Set the screen-reader text        $el.html('<span style=""position: absolute !important;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);"">' + text + '</span>');        // Reset output for appending        output = '';        // Iterate over all chars in the text        for (i = 0; i < chars.length; i++) {            // Create a styled element for each character and append to container            output += '<span aria-hidden=""true"" class=""halfStyle"" data-content=""' + chars[i] + '"">' + chars[i] + '</span>';        }        // Write to DOM only once        $el.append(output);    });});.halfStyle {  position: relative;  display: inline-block;  font-size: 80px; /* or any font size will work */  color: transparent; /* hide the base character */  overflow: hidden;  white-space: pre; /* to preserve the spaces from collapsing */}.halfStyle:before { /* creates the top part */  display: block;  z-index: 2;  position: absolute;  top: 0;  height: 50%;  content: attr(data-content); /* dynamic content for the pseudo element */  overflow: hidden;  pointer-events: none; /* so the base char is selectable by mouse */  color: #f00; /* for demo purposes */  text-shadow: 2px -2px 0px #af0; /* for demo purposes */}.halfStyle:after { /* creates the bottom part */  display: block;  position: absolute;  z-index: 1;  top: 0;  height: 100%;  content: attr(data-content); /* dynamic content for the pseudo element */  overflow: hidden;  pointer-events: none; /* so the base char is selectable by mouse */  color: #000; /* for demo purposes */  text-shadow: 2px 2px 0px #0af; /* for demo purposes */}<script src=""https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js""></script><p>Single Characters:</p><span class=""halfStyle"" data-content=""X"">X</span><span class=""halfStyle"" data-content=""Y"">Y</span><span class=""halfStyle"" data-content=""Z"">Z</span><span class=""halfStyle"" data-content=""A"">A</span><hr/><p>Automated:</p><span class=""textToHalfStyle"">Half-style, please.</span>(JSFiddle demo)-Vertical 1/3 PartsWithout Text Shadow:Possibility of Text Shadow for each 1/3 part independently:// jQuery for automated modejQuery(function($) {    var text, chars, $el, i, output;    // Iterate over all class occurences    $('.textToHalfStyle').each(function(idx, el) {    $el = $(el);    text = $el.text();    chars = text.split('');    // Set the screen-reader text    $el.html('<span style=""position: absolute !important;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);"">' + text + '</span>');    // Reset output for appending    output = '';    // Iterate over all chars in the text    for (i = 0; i < chars.length; i++) {        // Create a styled element for each character and append to container        output += '<span aria-hidden=""true"" class=""halfStyle"" data-content=""' + chars[i] + '"">' + chars[i] + '</span>';    }    // Write to DOM only once    $el.append(output);  });});.halfStyle { /* base char and also the right 1/3 */    position: relative;    display: inline-block;    font-size: 80px; /* or any font size will work */    color: transparent; /* hide the base character */    overflow: hidden;    white-space: pre; /* to preserve the spaces from collapsing */    color: #f0f; /* for demo purposes */    text-shadow: 2px 2px 0px #0af; /* for demo purposes */}.halfStyle:before { /* creates the left 1/3 */    display: block;    z-index: 2;    position: absolute;    top: 0;    width: 33.33%;    content: attr(data-content); /* dynamic content for the pseudo element */    overflow: hidden;    pointer-events: none; /* so the base char is selectable by mouse */    color: #f00; /* for demo purposes */    text-shadow: 2px -2px 0px #af0; /* for demo purposes */}.halfStyle:after { /* creates the middle 1/3 */    display: block;    z-index: 1;    position: absolute;    top: 0;    width: 66.66%;    content: attr(data-content); /* dynamic content for the pseudo element */    overflow: hidden;    pointer-events: none; /* so the base char is selectable by mouse */    color: #000; /* for demo purposes */    text-shadow: 2px 2px 0px #af0; /* for demo purposes */}<script src=""https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js""></script><p>Single Characters:</p><span class=""halfStyle"" data-content=""X"">X</span><span class=""halfStyle"" data-content=""Y"">Y</span><span class=""halfStyle"" data-content=""Z"">Z</span><span class=""halfStyle"" data-content=""A"">A</span><hr/><p>Automated:</p><span class=""textToHalfStyle"">Half-style, please.</span>(JSFiddle demo)-Horizontal 1/3 PartsWithout Text Shadow:Possibility of Text Shadow for each 1/3 part independently:// jQuery for automated modejQuery(function($) {    var text, chars, $el, i, output;    // Iterate over all class occurences    $('.textToHalfStyle').each(function(idx, el) {    $el = $(el);    text = $el.text();    chars = text.split('');    // Set the screen-reader text    $el.html('<span style=""position: absolute !important;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);"">' + text + '</span>');    // Reset output for appending    output = '';    // Iterate over all chars in the text    for (i = 0; i < chars.length; i++) {        // Create a styled element for each character and append to container        output += '<span aria-hidden=""true"" class=""halfStyle"" data-content=""' + chars[i] + '"">' + chars[i] + '</span>';    }    // Write to DOM only once    $el.append(output);  });});.halfStyle { /* base char and also the bottom 1/3 */  position: relative;  display: inline-block;  font-size: 80px; /* or any font size will work */  color: transparent;  overflow: hidden;  white-space: pre; /* to preserve the spaces from collapsing */  color: #f0f;  text-shadow: 2px 2px 0px #0af; /* for demo purposes */}.halfStyle:before { /* creates the top 1/3 */  display: block;  z-index: 2;  position: absolute;  top: 0;  height: 33.33%;  content: attr(data-content); /* dynamic content for the pseudo element */  overflow: hidden;  pointer-events: none; /* so the base char is selectable by mouse */  color: #f00; /* for demo purposes */  text-shadow: 2px -2px 0px #fa0; /* for demo purposes */}.halfStyle:after { /* creates the middle 1/3 */  display: block;  position: absolute;  z-index: 1;  top: 0;  height: 66.66%;  content: attr(data-content); /* dynamic content for the pseudo element */  overflow: hidden;  pointer-events: none; /* so the base char is selectable by mouse */  color: #000; /* for demo purposes */  text-shadow: 2px 2px 0px #af0; /* for demo purposes */}<script src=""https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js""></script><p>Single Characters:</p><span class=""halfStyle"" data-content=""X"">X</span><span class=""halfStyle"" data-content=""Y"">Y</span><span class=""halfStyle"" data-content=""Z"">Z</span><span class=""halfStyle"" data-content=""A"">A</span><hr/><p>Automated:</p><span class=""textToHalfStyle"">Half-style, please.</span>(JSFiddle demo)-HalfStyle Improvement By @KevinGranger// jQuery for automated modejQuery(function($) {    var text, chars, $el, i, output;    // Iterate over all class occurences    $('.textToHalfStyle').each(function(idx, el) {    $el = $(el);    text = $el.text();    chars = text.split('');    // Set the screen-reader text    $el.html('<span style=""position: absolute !important;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);"">' + text + '</span>');    // Reset output for appending    output = '';    // Iterate over all chars in the text    for (i = 0; i < chars.length; i++) {        // Create a styled element for each character and append to container        output += '<span aria-hidden=""true"" class=""halfStyle"" data-content=""' + chars[i] + '"">' + chars[i] + '</span>';    }    // Write to DOM only once    $el.append(output);  });});body {    background-color: black;}.textToHalfStyle {    display: block;    margin: 200px 0 0 0;    text-align: center;}.halfStyle {    font-family: 'Libre Baskerville', serif;    position: relative;    display: inline-block;    width: 1;    font-size: 70px;    color: black;    overflow: hidden;    white-space: pre;    text-shadow: 1px 2px 0 white;}.halfStyle:before {    display: block;    z-index: 1;    position: absolute;    top: 0;    width: 50%;    content: attr(data-content); /* dynamic content for the pseudo element */    overflow: hidden;    color: white;}<script src=""https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js""></script><p>Single Characters:</p><span class=""halfStyle"" data-content=""X"">X</span><span class=""halfStyle"" data-content=""Y"">Y</span><span class=""halfStyle"" data-content=""Z"">Z</span><span class=""halfStyle"" data-content=""A"">A</span><hr/><p>Automated:</p><span class=""textToHalfStyle"">Half-style, please.</span>(JSFiddle demo)-PeelingStyle improvement of HalfStyle by @SamTremaine// jQuery for automated modejQuery(function($) {    var text, chars, $el, i, output;    // Iterate over all class occurences    $('.textToHalfStyle').each(function(idx, el) {    $el = $(el);    text = $el.text();    chars = text.split('');    // Set the screen-reader text    $el.html('<span style=""position: absolute !important;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);"">' + text + '</span>');    // Reset output for appending    output = '';    // Iterate over all chars in the text    for (i = 0; i < chars.length; i++) {        // Create a styled element for each character and append to container        output += '<span aria-hidden=""true"" class=""halfStyle"" data-content=""' + chars[i] + '"">' + chars[i] + '</span>';    }    // Write to DOM only once    $el.append(output);  });});.halfStyle {    position: relative;    display: inline-block;    font-size: 68px;    color: rgba(0, 0, 0, 0.8);    overflow: hidden;    white-space: pre;    transform: rotate(4deg);    text-shadow: 2px 1px 3px rgba(0, 0, 0, 0.3);}.halfStyle:before { /* creates the left part */    display: block;    z-index: 1;    position: absolute;    top: -0.5px;    left: -3px;    width: 100%;    content: attr(data-content);    overflow: hidden;    pointer-events: none;    color: #FFF;    transform: rotate(-4deg);    text-shadow: 0px 0px 1px #000;}<script src=""https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js""></script><p>Single Characters:</p><span class=""halfStyle"" data-content=""X"">X</span><span class=""halfStyle"" data-content=""Y"">Y</span><span class=""halfStyle"" data-content=""Z"">Z</span><span class=""halfStyle"" data-content=""A"">A</span><hr/><p>Automated:</p><span class=""textToHalfStyle"">Half-style, please.</span>(JSFiddle demo and on samtremaine.co.uk)Part 4: Ready for ProductionCustomized different Half-Style style-sets can be used on desired elements on the same page.You can define multiple style-sets and tell the plugin which one to use.The plugin uses data attribute data-halfstyle=""[-CustomClassName-]"" on the target .textToHalfStyle elements and makes all the necessary changes automatically.So, simply on the element containing the text add textToHalfStyle class and data attribute data-halfstyle=""[-CustomClassName-]"". The plugin will do the rest of the job.Also the CSS style-sets' class definitions match the [-CustomClassName-] part mentioned above and is chained to .halfStyle, so we will have .halfStyle.[-CustomClassName-]jQuery(function($) {    var halfstyle_text, halfstyle_chars, $halfstyle_el, halfstyle_i, halfstyle_output, halfstyle_style;    // Iterate over all class occurrences    $('.textToHalfStyle').each(function(idx, halfstyle_el) {        $halfstyle_el = $(halfstyle_el);        halfstyle_style = $halfstyle_el.data('halfstyle') || 'hs-base';        halfstyle_text = $halfstyle_el.text();        halfstyle_chars = halfstyle_text.split('');        // Set the screen-reader text        $halfstyle_el.html('<span style=""position: absolute !important;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);"">' + halfstyle_text + '</span>');        // Reset output for appending        halfstyle_output = '';        // Iterate over all chars in the text        for (halfstyle_i = 0; halfstyle_i < halfstyle_chars.length; halfstyle_i++) {            // Create a styled element for each character and append to container            halfstyle_output += '<span aria-hidden=""true"" class=""halfStyle ' + halfstyle_style + '"" data-content=""' + halfstyle_chars[halfstyle_i] + '"">' + halfstyle_chars[halfstyle_i] + '</span>';        }        // Write to DOM only once        $halfstyle_el.append(halfstyle_output);    });});/* start half-style hs-base */.halfStyle.hs-base {    position: relative;    display: inline-block;    font-size: 80px; /* or any font size will work */    overflow: hidden;    white-space: pre; /* to preserve the spaces from collapsing */    color: #000; /* for demo purposes */}.halfStyle.hs-base:before {    display: block;    z-index: 1;    position: absolute;    top: 0;    width: 50%;    content: attr(data-content); /* dynamic content for the pseudo element */    pointer-events: none; /* so the base char is selectable by mouse */    overflow: hidden;    color: #f00; /* for demo purposes */}/* end half-style hs-base *//* start half-style hs-horizontal-third */.halfStyle.hs-horizontal-third { /* base char and also the bottom 1/3 */    position: relative;    display: inline-block;    font-size: 80px; /* or any font size will work */    color: transparent;    overflow: hidden;    white-space: pre; /* to preserve the spaces from collapsing */    color: #f0f;    text-shadow: 2px 2px 0px #0af; /* for demo purposes */}.halfStyle.hs-horizontal-third:before { /* creates the top 1/3 */    display: block;    z-index: 2;    position: absolute;    top: 0;    height: 33.33%;    content: attr(data-content); /* dynamic content for the pseudo element */    overflow: hidden;    pointer-events: none; /* so the base char is selectable by mouse */    color: #f00; /* for demo purposes */    text-shadow: 2px -2px 0px #fa0; /* for demo purposes */}.halfStyle.hs-horizontal-third:after { /* creates the middle 1/3 */    display: block;    position: absolute;    z-index: 1;    top: 0;    height: 66.66%;    content: attr(data-content); /* dynamic content for the pseudo element */    overflow: hidden;    pointer-events: none; /* so the base char is selectable by mouse */    color: #000; /* for demo purposes */    text-shadow: 2px 2px 0px #af0; /* for demo purposes */}/* end half-style hs-horizontal-third *//* start half-style hs-PeelingStyle, by user SamTremaine on Stackoverflow.com */.halfStyle.hs-PeelingStyle {  position: relative;  display: inline-block;  font-size: 68px;  color: rgba(0, 0, 0, 0.8);  overflow: hidden;  white-space: pre;  transform: rotate(4deg);  text-shadow: 2px 1px 3px rgba(0, 0, 0, 0.3);}.halfStyle.hs-PeelingStyle:before { /* creates the left part */  display: block;  z-index: 1;  position: absolute;  top: -0.5px;  left: -3px;  width: 100%;  content: attr(data-content);  overflow: hidden;  pointer-events: none;  color: #FFF;  transform: rotate(-4deg);  text-shadow: 0px 0px 1px #000;}/* end half-style hs-PeelingStyle *//* start half-style hs-KevinGranger, by user KevinGranger on StackOverflow.com*/.textToHalfStyle.hs-KevinGranger {  display: block;  margin: 200px 0 0 0;  text-align: center;}.halfStyle.hs-KevinGranger {  font-family: 'Libre Baskerville', serif;  position: relative;  display: inline-block;  width: 1;  font-size: 70px;  color: black;  overflow: hidden;  white-space: pre;  text-shadow: 1px 2px 0 white;}.halfStyle.hs-KevinGranger:before {  display: block;  z-index: 1;  position: absolute;  top: 0;  width: 50%;  content: attr(data-content); /* dynamic content for the pseudo element */  overflow: hidden;  color: white;}/* end half-style hs-KevinGranger<script src=""https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js""></script><p>    <span class=""textToHalfStyle"" data-halfstyle=""hs-base"">Half-style, please.</span></p><p>    <span class=""textToHalfStyle"" data-halfstyle=""hs-horizontal-third"">Half-style, please.</span></p><p>    <span class=""textToHalfStyle"" data-halfstyle=""hs-PeelingStyle"">Half-style, please.</span></p><p style=""background-color:#000;"">    <span class=""textToHalfStyle"" data-halfstyle=""hs-KevinGranger"">Half-style, please.</span></p>(JSFiddle demo)"
"data_i","edited Dec 15 '21 at 17:58","
        How can I merge properties of two JavaScript objects dynamically?
    ","I need to be able to merge two (very simple) JavaScript objects at runtime.  For example I'd like to:var obj1 = { food: 'pizza', car: 'ford' }var obj2 = { animal: 'dog' }obj1.merge(obj2);//obj1 now has three properties: food, car, and animalIs there a built in way to do this?  I do not need recursion, and I do not need to merge functions, just methods on flat objects.","ECMAScript 2018 Standard MethodYou would use object spread:let merged = {...obj1, ...obj2};merged is now the union of obj1 and obj2. Properties in obj2 will overwrite those in obj1./** There's no limit to the number of objects you can merge. *  Later properties overwrite earlier properties with the same name. */const allRules = {...obj1, ...obj2, ...obj3};Here is also the MDN documentation for this syntax. If you're using babel you'll need the babel-plugin-transform-object-rest-spread plugin for it to work.ECMAScript 2015 (ES6) Standard Method/* For the case in question, you would do: */Object.assign(obj1, obj2);/** There's no limit to the number of objects you can merge. *  All objects get merged into the first object.  *  Only the object in the first argument is mutated and returned. *  Later properties overwrite earlier properties with the same name. */const allRules = Object.assign({}, obj1, obj2, obj3, etc);(see MDN JavaScript Reference)Method for ES5 and Earlierfor (var attrname in obj2) { obj1[attrname] = obj2[attrname]; }Note that this will simply add all attributes of obj2 to obj1 which might not be what you want if you still want to use the unmodified obj1.If you're using a framework that craps all over your prototypes then you have to get fancier with checks like hasOwnProperty, but that code will work for 99% of cases.Example function:/** * Overwrites obj1's values with obj2's and adds obj2's if non existent in obj1 * @param obj1 * @param obj2 * @returns obj3 a new object based on obj1 and obj2 */function merge_options(obj1,obj2){    var obj3 = {};    for (var attrname in obj1) { obj3[attrname] = obj1[attrname]; }    for (var attrname in obj2) { obj3[attrname] = obj2[attrname]; }    return obj3;}"
"data_i","edited Dec 16 '17 at 11:29","
        Is there an ""exists"" function for jQuery?
    ","How can I check the existence of an element in jQuery?The current code that I have is this:if ($(selector).length > 0) {    // Do something}Is there a more elegant way to approach this? Perhaps a plugin or a function?","In JavaScript, everything is 'truthy' or 'falsy', and for numbers 0 means false, everything else true. So you could write:if ($(selector).length)You don't need that >0 part."
"data_i","edited Apr 01 '22 at 11:47","
        Understanding Python super() with __init__() methods
    ","Why is super() used?Is there a difference between using Base.__init__ and super().__init__?class Base(object):    def __init__(self):        print ""Base created""        class ChildA(Base):    def __init__(self):        Base.__init__(self)        class ChildB(Base):    def __init__(self):        super(ChildB, self).__init__()        ChildA() ChildB()","super() lets you avoid referring to the base class explicitly, which can be nice. But the main advantage comes with multiple inheritance, where all sorts of fun stuff can happen. See the standard docs on super if you haven't already.Note that the syntax changed in Python 3.0: you can just say super().__init__() instead of super(ChildB, self).__init__() which IMO is quite a bit nicer. The standard docs also refer to a guide to using super() which is quite explanatory."
"data_i","edited Aug 15 '22 at 05:46","
        How do I make function decorators and chain them together?
    ","How do I make two decorators in Python that would do the following?@make_bold@make_italicdef say():   return ""Hello""Calling say() should return:""<b><i>Hello</i></b>""","If you are not into long explanations, see Paolo Bergantino’s answer.Decorator BasicsPython’s functions are objectsTo understand decorators, you must first understand that functions are objects in Python. This has important consequences. Let’s see why with a simple example :def shout(word=""yes""):    return word.capitalize()+""!""print(shout())# outputs : 'Yes!'# As an object, you can assign the function to a variable like any other object scream = shout# Notice we don't use parentheses: we are not calling the function,# we are putting the function ""shout"" into the variable ""scream"".# It means you can then call ""shout"" from ""scream"":print(scream())# outputs : 'Yes!'# More than that, it means you can remove the old name 'shout',# and the function will still be accessible from 'scream'del shouttry:    print(shout())except NameError as e:    print(e)    #outputs: ""name 'shout' is not defined""print(scream())# outputs: 'Yes!'Keep this in mind. We’ll circle back to it shortly.Another interesting property of Python functions is they can be defined inside another function!def talk():    # You can define a function on the fly in ""talk"" ...    def whisper(word=""yes""):        return word.lower()+""...""    # ... and use it right away!    print(whisper())# You call ""talk"", that defines ""whisper"" EVERY TIME you call it, then# ""whisper"" is called in ""talk"". talk()# outputs: # ""yes...""# But ""whisper"" DOES NOT EXIST outside ""talk"":try:    print(whisper())except NameError as e:    print(e)    #outputs : ""name 'whisper' is not defined""*    #Python's functions are objectsFunctions referencesOkay, still here? Now the fun part...You’ve seen that functions are objects. Therefore, functions:can be assigned to a variablecan be defined in another functionThat means that a function can return another function.def getTalk(kind=""shout""):    # We define functions on the fly    def shout(word=""yes""):        return word.capitalize()+""!""    def whisper(word=""yes"") :        return word.lower()+""...""    # Then we return one of them    if kind == ""shout"":        # We don't use ""()"", we are not calling the function,        # we are returning the function object        return shout      else:        return whisper# How do you use this strange beast?# Get the function and assign it to a variabletalk = getTalk()      # You can see that ""talk"" is here a function object:print(talk)#outputs : <function shout at 0xb7ea817c># The object is the one returned by the function:print(talk())#outputs : Yes!# And you can even use it directly if you feel wild:print(getTalk(""whisper"")())#outputs : yes...There’s more!If you can return a function, you can pass one as a parameter:def doSomethingBefore(func):     print(""I do something before then I call the function you gave me"")    print(func())doSomethingBefore(scream)#outputs: #I do something before then I call the function you gave me#Yes!Well, you just have everything needed to understand decorators. You see, decorators are “wrappers”, which means that they let you execute code before and after the function they decorate without modifying the function itself.Handcrafted decoratorsHow you’d do it manually:# A decorator is a function that expects ANOTHER function as parameterdef my_shiny_new_decorator(a_function_to_decorate):    # Inside, the decorator defines a function on the fly: the wrapper.    # This function is going to be wrapped around the original function    # so it can execute code before and after it.    def the_wrapper_around_the_original_function():        # Put here the code you want to be executed BEFORE the original function is called        print(""Before the function runs"")        # Call the function here (using parentheses)        a_function_to_decorate()        # Put here the code you want to be executed AFTER the original function is called        print(""After the function runs"")    # At this point, ""a_function_to_decorate"" HAS NEVER BEEN EXECUTED.    # We return the wrapper function we have just created.    # The wrapper contains the function and the code to execute before and after. It’s ready to use!    return the_wrapper_around_the_original_function# Now imagine you create a function you don't want to ever touch again.def a_stand_alone_function():    print(""I am a stand alone function, don't you dare modify me"")a_stand_alone_function() #outputs: I am a stand alone function, don't you dare modify me# Well, you can decorate it to extend its behavior.# Just pass it to the decorator, it will wrap it dynamically in # any code you want and return you a new function ready to be used:a_stand_alone_function_decorated = my_shiny_new_decorator(a_stand_alone_function)a_stand_alone_function_decorated()#outputs:#Before the function runs#I am a stand alone function, don't you dare modify me#After the function runsNow, you probably want that every time you call a_stand_alone_function, a_stand_alone_function_decorated is called instead. That’s easy, just overwrite a_stand_alone_function with the function returned by my_shiny_new_decorator:a_stand_alone_function = my_shiny_new_decorator(a_stand_alone_function)a_stand_alone_function()#outputs:#Before the function runs#I am a stand alone function, don't you dare modify me#After the function runs# That’s EXACTLY what decorators do!Decorators demystifiedThe previous example, using the decorator syntax:@my_shiny_new_decoratordef another_stand_alone_function():    print(""Leave me alone"")another_stand_alone_function()  #outputs:  #Before the function runs#Leave me alone#After the function runsYes, that’s all, it’s that simple. @decorator is just a shortcut to:another_stand_alone_function = my_shiny_new_decorator(another_stand_alone_function)Decorators are just a pythonic variant of the decorator design pattern. There are several classic design patterns embedded in Python to ease development (like iterators).Of course, you can accumulate decorators:def bread(func):    def wrapper():        print(""</''''''\>"")        func()        print(""<\______/>"")    return wrapperdef ingredients(func):    def wrapper():        print(""#tomatoes#"")        func()        print(""~salad~"")    return wrapperdef sandwich(food=""--ham--""):    print(food)sandwich()#outputs: --ham--sandwich = bread(ingredients(sandwich))sandwich()#outputs:#</''''''\># #tomatoes## --ham--# ~salad~#<\______/>Using the Python decorator syntax:@bread@ingredientsdef sandwich(food=""--ham--""):    print(food)sandwich()#outputs:#</''''''\># #tomatoes## --ham--# ~salad~#<\______/>The order you set the decorators MATTERS:@ingredients@breaddef strange_sandwich(food=""--ham--""):    print(food)strange_sandwich()#outputs:##tomatoes##</''''''\># --ham--#<\______/># ~salad~Now: to answer the question...As a conclusion, you can easily see how to answer the question:# The decorator to make it bolddef makebold(fn):    # The new function the decorator returns    def wrapper():        # Insertion of some code before and after        return ""<b>"" + fn() + ""</b>""    return wrapper# The decorator to make it italicdef makeitalic(fn):    # The new function the decorator returns    def wrapper():        # Insertion of some code before and after        return ""<i>"" + fn() + ""</i>""    return wrapper@makebold@makeitalicdef say():    return ""hello""print(say())#outputs: <b><i>hello</i></b># This is the exact equivalent to def say():    return ""hello""say = makebold(makeitalic(say))print(say())#outputs: <b><i>hello</i></b>You can now just leave happy, or burn your brain a little bit more and see advanced uses of decorators.Taking decorators to the next levelPassing arguments to the decorated function# It’s not black magic, you just have to let the wrapper # pass the argument:def a_decorator_passing_arguments(function_to_decorate):    def a_wrapper_accepting_arguments(arg1, arg2):        print(""I got args! Look: {0}, {1}"".format(arg1, arg2))        function_to_decorate(arg1, arg2)    return a_wrapper_accepting_arguments# Since when you are calling the function returned by the decorator, you are# calling the wrapper, passing arguments to the wrapper will let it pass them to # the decorated function@a_decorator_passing_argumentsdef print_full_name(first_name, last_name):    print(""My name is {0} {1}"".format(first_name, last_name))    print_full_name(""Peter"", ""Venkman"")# outputs:#I got args! Look: Peter Venkman#My name is Peter VenkmanDecorating methodsOne nifty thing about Python is that methods and functions are really the same.  The only difference is that methods expect that their first argument is a reference to the current object (self).That means you can build a decorator for methods the same way! Just remember to take self into consideration:def method_friendly_decorator(method_to_decorate):    def wrapper(self, lie):        lie = lie - 3 # very friendly, decrease age even more :-)        return method_to_decorate(self, lie)    return wrapper        class Lucy(object):        def __init__(self):        self.age = 32        @method_friendly_decorator    def sayYourAge(self, lie):        print(""I am {0}, what did you think?"".format(self.age + lie))        l = Lucy()l.sayYourAge(-3)#outputs: I am 26, what did you think?If you’re making general-purpose decorator--one you’ll apply to any function or method, no matter its arguments--then just use *args, **kwargs:def a_decorator_passing_arbitrary_arguments(function_to_decorate):    # The wrapper accepts any arguments    def a_wrapper_accepting_arbitrary_arguments(*args, **kwargs):        print(""Do I have args?:"")        print(args)        print(kwargs)        # Then you unpack the arguments, here *args, **kwargs        # If you are not familiar with unpacking, check:        # http://www.saltycrane.com/blog/2008/01/how-to-use-args-and-kwargs-in-python/        function_to_decorate(*args, **kwargs)    return a_wrapper_accepting_arbitrary_arguments@a_decorator_passing_arbitrary_argumentsdef function_with_no_argument():    print(""Python is cool, no argument here."")function_with_no_argument()#outputs#Do I have args?:#()#{}#Python is cool, no argument here.@a_decorator_passing_arbitrary_argumentsdef function_with_arguments(a, b, c):    print(a, b, c)    function_with_arguments(1,2,3)#outputs#Do I have args?:#(1, 2, 3)#{}#1 2 3  @a_decorator_passing_arbitrary_argumentsdef function_with_named_arguments(a, b, c, platypus=""Why not ?""):    print(""Do {0}, {1} and {2} like platypus? {3}"".format(a, b, c, platypus))function_with_named_arguments(""Bill"", ""Linus"", ""Steve"", platypus=""Indeed!"")#outputs#Do I have args ? :#('Bill', 'Linus', 'Steve')#{'platypus': 'Indeed!'}#Do Bill, Linus and Steve like platypus? Indeed!class Mary(object):        def __init__(self):        self.age = 31        @a_decorator_passing_arbitrary_arguments    def sayYourAge(self, lie=-3): # You can now add a default value        print(""I am {0}, what did you think?"".format(self.age + lie))m = Mary()m.sayYourAge()#outputs# Do I have args?:#(<__main__.Mary object at 0xb7d303ac>,)#{}#I am 28, what did you think?Passing arguments to the decoratorGreat, now what would you say about passing arguments to the decorator itself?This can get somewhat twisted, since a decorator must accept a function as an argument. Therefore, you cannot pass the decorated function’s arguments directly to the decorator.Before rushing to the solution, let’s write a little reminder:# Decorators are ORDINARY functionsdef my_decorator(func):    print(""I am an ordinary function"")    def wrapper():        print(""I am function returned by the decorator"")        func()    return wrapper# Therefore, you can call it without any ""@""def lazy_function():    print(""zzzzzzzz"")decorated_function = my_decorator(lazy_function)#outputs: I am an ordinary function            # It outputs ""I am an ordinary function"", because that’s just what you do:# calling a function. Nothing magic.@my_decoratordef lazy_function():    print(""zzzzzzzz"")    #outputs: I am an ordinary functionIt’s exactly the same. ""my_decorator"" is called. So when you @my_decorator, you are telling Python to call the function 'labelled by the variable ""my_decorator""'.This is important! The label you give can point directly to the decorator—or not.Let’s get evil. ☺def decorator_maker():        print(""I make decorators! I am executed only once: ""          ""when you make me create a decorator."")                def my_decorator(func):                print(""I am a decorator! I am executed only when you decorate a function."")                       def wrapped():            print(""I am the wrapper around the decorated function. ""                  ""I am called when you call the decorated function. ""                  ""As the wrapper, I return the RESULT of the decorated function."")            return func()                print(""As the decorator, I return the wrapped function."")                return wrapped        print(""As a decorator maker, I return a decorator"")    return my_decorator            # Let’s create a decorator. It’s just a new function after all.new_decorator = decorator_maker()       #outputs:#I make decorators! I am executed only once: when you make me create a decorator.#As a decorator maker, I return a decorator# Then we decorate the function            def decorated_function():    print(""I am the decorated function."")   decorated_function = new_decorator(decorated_function)#outputs:#I am a decorator! I am executed only when you decorate a function.#As the decorator, I return the wrapped function     # Let’s call the function:decorated_function()#outputs:#I am the wrapper around the decorated function. I am called when you call the decorated function.#As the wrapper, I return the RESULT of the decorated function.#I am the decorated function.No surprise here.Let’s do EXACTLY the same thing, but skip all the pesky intermediate variables:def decorated_function():    print(""I am the decorated function."")decorated_function = decorator_maker()(decorated_function)#outputs:#I make decorators! I am executed only once: when you make me create a decorator.#As a decorator maker, I return a decorator#I am a decorator! I am executed only when you decorate a function.#As the decorator, I return the wrapped function.# Finally:decorated_function()    #outputs:#I am the wrapper around the decorated function. I am called when you call the decorated function.#As the wrapper, I return the RESULT of the decorated function.#I am the decorated function.Let’s make it even shorter:@decorator_maker()def decorated_function():    print(""I am the decorated function."")#outputs:#I make decorators! I am executed only once: when you make me create a decorator.#As a decorator maker, I return a decorator#I am a decorator! I am executed only when you decorate a function.#As the decorator, I return the wrapped function.#Eventually: decorated_function()    #outputs:#I am the wrapper around the decorated function. I am called when you call the decorated function.#As the wrapper, I return the RESULT of the decorated function.#I am the decorated function.Hey, did you see that? We used a function call with the ""@"" syntax! :-)So, back to decorators with arguments. If we can use functions to generate the decorator on the fly, we can pass arguments to that function, right?def decorator_maker_with_arguments(decorator_arg1, decorator_arg2):        print(""I make decorators! And I accept arguments: {0}, {1}"".format(decorator_arg1, decorator_arg2))                def my_decorator(func):        # The ability to pass arguments here is a gift from closures.        # If you are not comfortable with closures, you can assume it’s ok,        # or read: https://stackoverflow.com/questions/13857/can-you-explain-closures-as-they-relate-to-python        print(""I am the decorator. Somehow you passed me arguments: {0}, {1}"".format(decorator_arg1, decorator_arg2))                       # Don't confuse decorator arguments and function arguments!        def wrapped(function_arg1, function_arg2) :            print(""I am the wrapper around the decorated function.\n""                  ""I can access all the variables\n""                  ""\t- from the decorator: {0} {1}\n""                  ""\t- from the function call: {2} {3}\n""                  ""Then I can pass them to the decorated function""                  .format(decorator_arg1, decorator_arg2,                          function_arg1, function_arg2))            return func(function_arg1, function_arg2)                return wrapped        return my_decorator@decorator_maker_with_arguments(""Leonard"", ""Sheldon"")def decorated_function_with_arguments(function_arg1, function_arg2):    print(""I am the decorated function and only knows about my arguments: {0}""           "" {1}"".format(function_arg1, function_arg2))          decorated_function_with_arguments(""Rajesh"", ""Howard"")#outputs:#I make decorators! And I accept arguments: Leonard Sheldon#I am the decorator. Somehow you passed me arguments: Leonard Sheldon#I am the wrapper around the decorated function. #I can access all the variables #   - from the decorator: Leonard Sheldon #   - from the function call: Rajesh Howard #Then I can pass them to the decorated function#I am the decorated function and only knows about my arguments: Rajesh HowardHere it is: a decorator with arguments. Arguments can be set as variable:c1 = ""Penny""c2 = ""Leslie""@decorator_maker_with_arguments(""Leonard"", c1)def decorated_function_with_arguments(function_arg1, function_arg2):    print(""I am the decorated function and only knows about my arguments:""           "" {0} {1}"".format(function_arg1, function_arg2))decorated_function_with_arguments(c2, ""Howard"")#outputs:#I make decorators! And I accept arguments: Leonard Penny#I am the decorator. Somehow you passed me arguments: Leonard Penny#I am the wrapper around the decorated function. #I can access all the variables #   - from the decorator: Leonard Penny #   - from the function call: Leslie Howard #Then I can pass them to the decorated function#I am the decorated function and only know about my arguments: Leslie HowardAs you can see, you can pass arguments to the decorator like any function using this trick. You can even use *args, **kwargs if you wish. But remember decorators are called only once. Just when Python imports the script. You can't dynamically set the arguments afterwards. When you do ""import x"", the function is already decorated, so you can'tchange anything.Let’s practice: decorating a decoratorOkay, as a bonus, I'll give you a snippet to make any decorator accept generically any argument. After all, in order to accept arguments, we created our decorator using another function.We wrapped the decorator.Anything else we saw recently that wrapped function?Oh yes, decorators!Let’s have some fun and write a decorator for the decorators:def decorator_with_args(decorator_to_enhance):    """"""     This function is supposed to be used as a decorator.    It must decorate an other function, that is intended to be used as a decorator.    Take a cup of coffee.    It will allow any decorator to accept an arbitrary number of arguments,    saving you the headache to remember how to do that every time.    """"""        # We use the same trick we did to pass arguments    def decorator_maker(*args, **kwargs):               # We create on the fly a decorator that accepts only a function        # but keeps the passed arguments from the maker.        def decorator_wrapper(func):                   # We return the result of the original decorator, which, after all,             # IS JUST AN ORDINARY FUNCTION (which returns a function).            # Only pitfall: the decorator must have this specific signature or it won't work:            return decorator_to_enhance(func, *args, **kwargs)                return decorator_wrapper        return decorator_maker       It can be used as follows:# You create the function you will use as a decorator. And stick a decorator on it :-)# Don't forget, the signature is ""decorator(func, *args, **kwargs)""@decorator_with_args def decorated_decorator(func, *args, **kwargs):     def wrapper(function_arg1, function_arg2):        print(""Decorated with {0} {1}"".format(args, kwargs))        return func(function_arg1, function_arg2)    return wrapper    # Then you decorate the functions you wish with your brand new decorated decorator.@decorated_decorator(42, 404, 1024)def decorated_function(function_arg1, function_arg2):    print(""Hello {0} {1}"".format(function_arg1, function_arg2))decorated_function(""Universe and"", ""everything"")#outputs:#Decorated with (42, 404, 1024) {}#Hello Universe and everything# Whoooot!I know, the last time you had this feeling, it was after listening a guy saying: ""before understanding recursion, you must first understand recursion"". But now, don't you feel good about mastering this?Best practices: decoratorsDecorators were introduced in Python 2.4, so be sure your code will be run on >= 2.4.Decorators slow down the function call. Keep that in mind.You cannot un-decorate a function. (There are hacks to create decorators that can be removed, but nobody uses them.) So once a function is decorated, it’s decorated for all the code.Decorators wrap functions, which can make them hard to debug.  (This gets better from Python >= 2.5; see below.)The functools module was introduced in Python 2.5. It includes the function functools.wraps(), which copies the name, module, and docstring of the decorated function to its wrapper.(Fun fact: functools.wraps() is a decorator! ☺)# For debugging, the stacktrace prints you the function __name__def foo():    print(""foo"")    print(foo.__name__)#outputs: foo    # With a decorator, it gets messy    def bar(func):    def wrapper():        print(""bar"")        return func()    return wrapper@bardef foo():    print(""foo"")print(foo.__name__)#outputs: wrapper# ""functools"" can help for thatimport functoolsdef bar(func):    # We say that ""wrapper"", is wrapping ""func""    # and the magic begins    @functools.wraps(func)    def wrapper():        print(""bar"")        return func()    return wrapper@bardef foo():    print(""foo"")print(foo.__name__)#outputs: fooHow can the decorators be useful?Now the big question: What can I use decorators for?Seem cool and powerful, but a practical example would be great. Well, there are 1000 possibilities. Classic uses are extending a function behavior from an external lib (you can't modify it), or for debugging (you don't want to modify it because it’s temporary).You can use them to extend several functions in a DRY’s way, like so:def benchmark(func):    """"""    A decorator that prints the time a function takes    to execute.    """"""    import time    def wrapper(*args, **kwargs):        t = time.clock()        res = func(*args, **kwargs)        print(""{0} {1}"".format(func.__name__, time.clock()-t))        return res    return wrapperdef logging(func):    """"""    A decorator that logs the activity of the script.    (it actually just prints it, but it could be logging!)    """"""    def wrapper(*args, **kwargs):        res = func(*args, **kwargs)        print(""{0} {1} {2}"".format(func.__name__, args, kwargs))        return res    return wrapperdef counter(func):    """"""    A decorator that counts and prints the number of times a function has been executed    """"""    def wrapper(*args, **kwargs):        wrapper.count = wrapper.count + 1        res = func(*args, **kwargs)        print(""{0} has been used: {1}x"".format(func.__name__, wrapper.count))        return res    wrapper.count = 0    return wrapper@counter@benchmark@loggingdef reverse_string(string):    return str(reversed(string))print(reverse_string(""Able was I ere I saw Elba""))print(reverse_string(""A man, a plan, a canoe, pasta, heros, rajahs, a coloratura, maps, snipe, percale, macaroni, a gag, a banana bag, a tan, a tag, a banana bag again (or a camel), a crepe, pins, Spam, a rut, a Rolo, cash, a jar, sore hats, a peon, a canal: Panama!""))#outputs:#reverse_string ('Able was I ere I saw Elba',) {}#wrapper 0.0#wrapper has been used: 1x #ablE was I ere I saw elbA#reverse_string ('A man, a plan, a canoe, pasta, heros, rajahs, a coloratura, maps, snipe, percale, macaroni, a gag, a banana bag, a tan, a tag, a banana bag again (or a camel), a crepe, pins, Spam, a rut, a Rolo, cash, a jar, sore hats, a peon, a canal: Panama!',) {}#wrapper 0.0#wrapper has been used: 2x#!amanaP :lanac a ,noep a ,stah eros ,raj a ,hsac ,oloR a ,tur a ,mapS ,snip ,eperc a ,)lemac a ro( niaga gab ananab a ,gat a ,nat a ,gab ananab a ,gag a ,inoracam ,elacrep ,epins ,spam ,arutaroloc a ,shajar ,soreh ,atsap ,eonac a ,nalp a ,nam AOf course the good thing with decorators is that you can use them right away on almost anything without rewriting. DRY, I said:@counter@benchmark@loggingdef get_random_futurama_quote():    from urllib import urlopen    result = urlopen(""http://subfusion.net/cgi-bin/quote.pl?quote=futurama"").read()    try:        value = result.split(""<br><b><hr><br>"")[1].split(""<br><br><hr>"")[0]        return value.strip()    except:        return ""No, I'm ... doesn't!""    print(get_random_futurama_quote())print(get_random_futurama_quote())#outputs:#get_random_futurama_quote () {}#wrapper 0.02#wrapper has been used: 1x#The laws of science be a harsh mistress.#get_random_futurama_quote () {}#wrapper 0.01#wrapper has been used: 2x#Curse you, merciful Poseidon!Python itself provides several decorators: property, staticmethod, etc.Django uses decorators to manage caching and view permissions.Twisted to fake inlining asynchronous functions calls.This really is a large playground."
"data_i","edited Jul 24 '22 at 23:15","
        How do I find out which process is listening on a TCP or UDP port on Windows?
    ","How do I find out which process is listening on a TCP or UDP port on Windows?","New answer, powershellTCPGet-Process -Id (Get-NetTCPConnection -LocalPort YourPortNumberHere).OwningProcessUDPGet-Process -Id (Get-NetUDPEndpoint -LocalPort YourPortNumberHere).OwningProcessOld answer, cmd C:\> netstat -a -b(Add -n to stop it trying to resolve hostnames, which will make it a lot faster.)Note Dane's recommendation for TCPView. It looks very useful!-a  Displays all connections and listening ports.-b  Displays the executable involved in creating each connection or listening port. In some cases well-known executables host multiple independent components, and in these cases the sequence of components involved in creating the connection        or listening port is displayed. In this case the executable name is in [] at the bottom, on top is the component it called, and so forth until TCP/IP was reached. Note that this option can be time-consuming and will fail unless you have sufficient permissions.-n  Displays addresses and port numbers in numerical form.-o  Displays the owning process ID associated with each connection."
"data_i","edited Jul 11 '22 at 05:58","
        What does cherry-picking a commit with Git mean?
    ","What does git cherry-pick <commit> do?","Cherry picking in Git means to choose a commit from one branch and apply it onto another.This is in contrast with other ways such as merge and rebase which normally apply many commits onto another branch.Make sure you are on the branch you want to apply the commit to. git switch masterExecute the following: git cherry-pick <commit-hash>N.B.:If you cherry-pick from a public branch, you should consider using git cherry-pick -x <commit-hash>This will generate a standardized commit message. This way, you (and your co-workers) can still keep track of the origin of the commit and may avoid merge conflicts in the future.If you have notes attached to the commit they do not follow the cherry-pick. To bring them over as well, You have to use: git notes copy <from> <to>Additional links:git official guide page"
"data_i","edited Jul 11 '22 at 06:07","
        I ran into a merge conflict. How do I abort the merge?
    ","I used git pull and had a merge conflict:unmerged:   some_file.txtYou are in the middle of a conflicted merge.How do I abandon my changes to the file and keep only the pulled changes?","Since your pull was unsuccessful then HEAD (not HEAD^) is the last ""valid"" commit on your branch:git reset --hard HEADThe other piece you want is to let their changes over-ride your changes.  Older versions of git allowed you to use the ""theirs"" merge strategy:git pull --strategy=theirs remote_branchBut this has since been removed, as explained in this message by Junio Hamano (the Git maintainer).  As noted in the link, instead you would do this:git fetch origingit reset --hard origin"
"data_i","edited Apr 01 '22 at 12:08","
        How do I delete a file or folder in Python?
    ","How do I delete a file or folder?","os.remove() removes a file.os.rmdir() removes an empty directory.shutil.rmtree() deletes a directory and all its contents.Path objects from the Python 3.4+ pathlib module also expose these instance methods:pathlib.Path.unlink() removes a file or symbolic link.pathlib.Path.rmdir() removes an empty directory."
"data_i","edited Aug 13 '18 at 10:51","
        Should I use the datetime or timestamp data type in MySQL?
    ","Would you recommend using a datetime or a timestamp field, and why (using MySQL)? I'm working with PHP on the server side.","Timestamps in MySQL are generally used to track changes to records, and are often updated every time the record is changed. If you want to store a specific value you should use a datetime field.If you meant that you want to decide between using a UNIX timestamp or a native MySQL datetime field, go with the native DATETIME format. You can do calculations within MySQL that way(""SELECT DATE_ADD(my_datetime, INTERVAL 1 DAY)"") and it is simple to change the format of the value to a UNIX timestamp (""SELECT UNIX_TIMESTAMP(my_datetime)"") when you query the record if you want to operate on it with PHP."
"data_i","asked Sep 26 '18 at 16:43","
        Git is not working after macOS Update (xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools)
    ","I updated to the latest OS, and/or restarted my computer (this happens on every major update, but this time all I did was restart my computer on 2022-09-13)This morning I navigated to my work's codebase in the Command Line on my MacBook pro, typed in ""git status"" in the repository and received an error:(IN 9/2022, this error was much different, but I didn't capture it)xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrungit will not work!How do I fix git, and command line tools?","The problem is that Xcode Command-line Tools needs to be updated.** UPDATED FOR Sept. 2022 M1 MacBook Pro **After opening the terminal after a restart, I tried to go to my code, and do a git status, and I got an error and prompt for command line software agreement.So press space until you get to the [agree, print, cancel] option, so careful hit space to scroll down to the end, if you blow past It you have to run a command to get it back. Use sudo xcodebuild -license to get to it again.Just be careful on scrolling down and enter agree and press return and it will launch into an update.Then I tried to use git after the install, and it prompted me to install Xcode tools again.I followed my own advice from previous years (see below), and went to https://developer.apple.com/download/more/ and downloaded""Command Line Tools for Xcode 14"" (You have to log in with your Apple ID, so have that login readily available.** I am not sure if this step is needed, but I did it all the same as that's what worked the previous years.Before you can use git, you need to reboot. This completed the install and git is now working.Solutions for previous years, these may or may not be valid these days as the downloads page has changed significantly:PREVIOUS YEARS SOLUTIONS, probably #2 is most helpful.** Solution #1 **Go back to your terminal and enter:xcode-select --installYou'll then receive the following output:xcode-select: note: install requested for command line developer toolsYou will then be prompted in a window to update Xcode Command Line tools. (which may take a while)Open a new terminal window and your development tools should be returned.Addition: With any major or semi-major update you'll need to update the command line tools in order to get them functioning properly again. Check Xcode with any update. This goes beyond Mojave...After that restart your terminalAlternatively, IF that fails, and it very well might.... you'll get a pop-up box saying ""Software not found on server"", see below!Solution #2and you hit xcode-select --install and it doesn't find the software, log into Apple Developer, and install it via webpage.Log in or sign up here:https://developer.apple.com/download/more/Look for: ""Command Line Tools for Xcode 14.x"" in the list of downloadsThen click the dmg and download."
"data_i","edited Jan 30 '18 at 01:18","
        Is there a unique Android device ID?
    ","Do Android devices have a unique ID, and if so, what is a simple way to access it using Java?","Settings.Secure#ANDROID_ID returns the Android ID as an unique for each user 64-bit hex string.import android.provider.Settings.Secure;private String android_id = Secure.getString(getContext().getContentResolver(),                                                        Secure.ANDROID_ID);Also read Best practices for unique identifiers: https://developer.android.com/training/articles/user-data-ids"
"data_i","edited Jul 04 '22 at 21:14","
        How do I set, clear, and toggle a single bit?
    ","How do I set, clear, and toggle a bit?","Setting a bitUse the bitwise OR operator (|) to set a bit.number |= 1UL << n;That will set the nth bit of number. n should be zero, if you want to set the 1st bit and so on upto n-1, if you want to set the nth bit.Use 1ULL if number is wider than unsigned long; promotion of 1UL << n doesn't happen until after evaluating 1UL << n where it's undefined behaviour to shift by more than the width of a long.  The same applies to all the rest of the examples.Clearing a bitUse the bitwise AND operator (&) to clear a bit.number &= ~(1UL << n);That will clear the nth bit of number. You must invert the bit string with the bitwise NOT operator (~), then AND it.Toggling a bitThe XOR operator (^) can be used to toggle a bit.number ^= 1UL << n;That will toggle the nth bit of number.Checking a bitYou didn't ask for this, but I might as well add it.To check a bit, shift the number n to the right, then bitwise AND it:bit = (number >> n) & 1U;That will put the value of the nth bit of number into the variable bit.Changing the nth bit to xSetting the nth bit to either 1 or 0 can be achieved with the following on a 2's complement C++ implementation:number ^= (-x ^ number) & (1UL << n);Bit n will be set if x is 1, and cleared if x is 0.  If x has some other value, you get garbage.  x = !!x will booleanize it to 0 or 1.To make this independent of 2's complement negation behaviour (where -1 has all bits set, unlike on a 1's complement or sign/magnitude C++ implementation), use unsigned negation.number ^= (-(unsigned long)x ^ number) & (1UL << n);orunsigned long newbit = !!x;    // Also booleanize to force 0 or 1number ^= (-newbit ^ number) & (1UL << n);It's generally a good idea to use unsigned types for portable bit manipulation.ornumber = (number & ~(1UL << n)) | (x << n);(number & ~(1UL << n)) will clear the nth bit and (x << n) will set the nth bit to x.It's also generally a good idea to not to copy/paste code in general and so many people use preprocessor macros (like the community wiki answer further down) or some sort of encapsulation."
"data_i","edited Jul 11 '22 at 06:47","
        How do you push a tag to a remote repository using Git?
    ","I added a tag to the master branch on my machine:git tag mytag masterHow do I push this to the remote repository? Running git push gives the message:Everything up-to-dateHowever, the remote repository does not contain my tag.","To push a single tag:git push origin <tag_name>And the following command should push all tags (not recommended):# not recommendedgit push --tags"
"data_i","asked Feb 27 '09 at 19:53","
        How can I know which radio button is selected via jQuery?
    ","I have two radio buttons and want to post the value of the selected one.How can I get the value with jQuery?I can get all of them like this:$(""form :radio"")How do I know which one is selected?","To get the value of the selected radioName item of a form with id myForm:$('input[name=radioName]:checked', '#myForm').val()Here's an example:$('#myForm input').on('change', function() {  alert($('input[name=radioName]:checked', '#myForm').val());});<script src=""https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js""></script><form id=""myForm"">  <fieldset>    <legend>Choose radioName</legend>    <label><input type=""radio"" name=""radioName"" value=""1"" /> 1</label> <br />    <label><input type=""radio"" name=""radioName"" value=""2"" /> 2</label> <br />    <label><input type=""radio"" name=""radioName"" value=""3"" /> 3</label> <br />  </fieldset></form>"
"data_i","edited Apr 25 '22 at 00:44","
        How do I change the size of figures drawn with Matplotlib?
    ","How do I change the size of figure drawn with Matplotlib?","figure tells you the call signature:from matplotlib.pyplot import figurefigure(figsize=(8, 6), dpi=80)figure(figsize=(1,1)) would create an inch-by-inch image, which would be 80-by-80 pixels unless you also give a different dpi argument."
"data_i","edited Jun 13 '22 at 00:11","
        Manually raising (throwing) an exception in Python
    ","How do I raise an exception in Python so that it can later be caught via an except block?","How do I manually throw/raise an exception in Python?Use the most specific Exception constructor that semantically fits your issue.Be specific in your message, e.g.:raise ValueError('A very specific bad thing happened.')Don't raise generic exceptionsAvoid raising a generic Exception. To catch it, you'll have to catch all other more specific exceptions that subclass it.Problem 1: Hiding bugsraise Exception('I know Python!') # Don't! If you catch, likely to hide bugs.For example:def demo_bad_catch():    try:        raise ValueError('Represents a hidden bug, do not catch this')        raise Exception('This is the exception you expect to handle')    except Exception as error:        print('Caught this error: ' + repr(error))>>> demo_bad_catch()Caught this error: ValueError('Represents a hidden bug, do not catch this',)Problem 2: Won't catchAnd more specific catches won't catch the general exception:def demo_no_catch():    try:        raise Exception('general exceptions not caught by specific handling')    except ValueError as e:        print('we will not catch exception: Exception') >>> demo_no_catch()Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""<stdin>"", line 3, in demo_no_catchException: general exceptions not caught by specific handlingBest Practices: raise statementInstead, use the most specific Exception constructor that semantically fits your issue.raise ValueError('A very specific bad thing happened')which also handily allows an arbitrary number of arguments to be passed to the constructor:raise ValueError('A very specific bad thing happened', 'foo', 'bar', 'baz') These arguments are accessed by the args attribute on the Exception object. For example:try:    some_code_that_may_raise_our_value_error()except ValueError as err:    print(err.args)prints('message', 'foo', 'bar', 'baz')    In Python 2.5, an actual message attribute was added to BaseException in favor of encouraging users to subclass Exceptions and stop using args, but the introduction of message and the original deprecation of args has been retracted.Best Practices: except clauseWhen inside an except clause, you might want to, for example, log that a specific type of error happened, and then re-raise. The best way to do this while preserving the stack trace is to use a bare raise statement. For example:logger = logging.getLogger(__name__)try:    do_something_in_app_that_breaks_easily()except AppError as error:    logger.error(error)    raise                 # just this!    # raise AppError      # Don't do this, you'll lose the stack trace!Don't modify your errors... but if you insist.You can preserve the stacktrace (and error value) with sys.exc_info(), but this is way more error prone and has compatibility problems between Python 2 and 3, prefer to use a bare raise to re-raise.To explain - the sys.exc_info() returns the type, value, and traceback.type, value, traceback = sys.exc_info()This is the syntax in Python 2 - note this is not compatible with Python 3:raise AppError, error, sys.exc_info()[2] # avoid this.# Equivalently, as error *is* the second object:raise sys.exc_info()[0], sys.exc_info()[1], sys.exc_info()[2]If you want to, you can modify what happens with your new raise - e.g. setting new args for the instance:def error():    raise ValueError('oops!')def catch_error_modify_message():    try:        error()    except ValueError:        error_type, error_instance, traceback = sys.exc_info()        error_instance.args = (error_instance.args[0] + ' <modification>',)        raise error_type, error_instance, tracebackAnd we have preserved the whole traceback while modifying the args. Note that this is not a best practice and it is invalid syntax in Python 3 (making keeping compatibility much harder to work around).>>> catch_error_modify_message()Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""<stdin>"", line 3, in catch_error_modify_message  File ""<stdin>"", line 2, in errorValueError: oops! <modification>In Python 3:raise error.with_traceback(sys.exc_info()[2])Again: avoid manually manipulating tracebacks. It's less efficient and more error prone. And if you're using threading and sys.exc_info you may even get the wrong traceback (especially if you're using exception handling for control flow - which I'd personally tend to avoid.)Python 3, Exception chainingIn Python 3, you can chain Exceptions, which preserve tracebacks:raise RuntimeError('specific message') from errorBe aware:this does allow changing the error type raised, andthis is not compatible with Python 2.Deprecated Methods:These can easily hide and even get into production code. You want to raise an exception, and doing them will raise an exception, but not the one intended!Valid in Python 2, but not in Python 3 is the following:raise ValueError, 'message' # Don't do this, it's deprecated!Only valid in much older versions of Python (2.4 and lower), you may still see people raising strings:raise 'message' # really really wrong. don't do this.In all modern versions, this will actually raise a TypeError, because you're not raising a BaseException type. If you're not checking for the right exception and don't have a reviewer that's aware of the issue, it could get into production.Example UsageI raise Exceptions to warn consumers of my API if they're using it incorrectly:def api_func(foo):    '''foo should be either 'baz' or 'bar'. returns something very useful.'''    if foo not in _ALLOWED_ARGS:        raise ValueError('{foo} wrong, use ""baz"" or ""bar""'.format(foo=repr(foo)))Create your own error types when apropos""I want to make an error on purpose, so that it would go into the except""You can create your own error types, if you want to indicate something specific is wrong with your application, just subclass the appropriate point in the exception hierarchy:class MyAppLookupError(LookupError):    '''raise this when there's a lookup error for my app'''and usage:if important_key not in resource_dict and not ok_to_be_missing:    raise MyAppLookupError('resource is missing, and that is not ok.')"
"data_i","edited Sep 13 '22 at 08:02","
        How to store objects in HTML5 localStorage/sessionStorage
    ","I'd like to store a JavaScript object in HTML5 localStorage, but my object is apparently being converted to a string.I can store and retrieve primitive JavaScript types and arrays using localStorage, but objects don't seem to work.  Should they?Here's my code:var testObject = { 'one': 1, 'two': 2, 'three': 3 };console.log('typeof testObject: ' + typeof testObject);console.log('testObject properties:');for (var prop in testObject) {    console.log('  ' + prop + ': ' + testObject[prop]);}// Put the object into storagelocalStorage.setItem('testObject', testObject);// Retrieve the object from storagevar retrievedObject = localStorage.getItem('testObject');console.log('typeof retrievedObject: ' + typeof retrievedObject);console.log('Value of retrievedObject: ' + retrievedObject);The console output istypeof testObject: objecttestObject properties:  one: 1  two: 2  three: 3typeof retrievedObject: stringValue of retrievedObject: [object Object]It looks to me like the setItem method is converting the input to a string before storing it.I see this behavior in Safari, Chrome, and Firefox, so I assume it's my misunderstanding of the HTML5 Web Storage specification, not a browser-specific bug or limitation.I've tried to make sense of the structured clone algorithm described in 2 Common infrastructure.  I don't fully understand what it's saying, but maybe my problem has to do with my object's properties not being enumerable (???).Is there an easy workaround?Update: The W3C eventually changed their minds about the structured-clone specification, and decided to change the spec to match the implementations.  See 12111 – spec for Storage object getItem(key) method does not match implementation behavior. So this question is no longer 100% valid, but the answers still may be of interest.","Looking at the Apple, Mozilla and Mozilla again documentation, the functionality seems to be limited to handle only string key/value pairs.A workaround can be to stringify your object before storing it, and later parse it when you retrieve it:var testObject = { 'one': 1, 'two': 2, 'three': 3 };// Put the object into storagelocalStorage.setItem('testObject', JSON.stringify(testObject));// Retrieve the object from storagevar retrievedObject = localStorage.getItem('testObject');console.log('retrievedObject: ', JSON.parse(retrievedObject));"
"data_i","edited Jul 04 '22 at 21:41","
        When should static_cast, dynamic_cast, const_cast, and reinterpret_cast be used?
    ","What are the proper uses of:static_castdynamic_castconst_castreinterpret_cast(type)value (C-style cast)type(value) (function-style cast)How does one decide which to use in which specific cases?","static_cast is the first cast you should attempt to use. It does things like implicit conversions between types (such as int to float, or pointer to void*), and it can also call explicit conversion functions (or implicit ones). In many cases, explicitly stating static_cast isn't necessary, but it's important to note that the T(something) syntax is equivalent to (T)something and should be avoided (more on that later). A T(something, something_else) is safe, however, and guaranteed to call the constructor.static_cast can also cast through inheritance hierarchies. It is unnecessary when casting upwards (towards a base class), but when casting downwards it can be used as long as it doesn't cast through virtual inheritance. It does not do checking, however, and it is undefined behavior to static_cast down a hierarchy to a type that isn't actually the type of the object.const_cast can be used to remove or add const to a variable; no other C++ cast is capable of removing it (not even reinterpret_cast). It is important to note that modifying a formerly const value is only undefined if the original variable is const; if you use it to take the const off a reference to something that wasn't declared with const, it is safe. This can be useful when overloading member functions based on const, for instance. It can also be used to add const to an object, such as to call a member function overload.const_cast also works similarly on volatile, though that's less common.dynamic_cast is exclusively used for handling polymorphism. You can cast a pointer or reference to any polymorphic type to any other class type (a polymorphic type has at least one virtual function, declared or inherited). You can use it for more than just casting downwards – you can cast sideways or even up another chain. The dynamic_cast will seek out the desired object and return it if possible. If it can't, it will return nullptr in the case of a pointer, or throw std::bad_cast in the case of a reference.dynamic_cast has some limitations, though. It doesn't work if there are multiple objects of the same type in the inheritance hierarchy (the so-called 'dreaded diamond') and you aren't using virtual inheritance. It also can only go through public inheritance - it will always fail to travel through protected or private inheritance. This is rarely an issue, however, as such forms of inheritance are rare.reinterpret_cast is the most dangerous cast, and should be used very sparingly. It turns one type directly into another — such as casting the value from one pointer to another, or storing a pointer in an int, or all sorts of other nasty things. Largely, the only guarantee you get with reinterpret_cast is that normally if you cast the result back to the original type, you will get the exact same value (but not if the intermediate type is smaller than the original type). There are a number of conversions that reinterpret_cast cannot do, too. It's used primarily for particularly weird conversions and bit manipulations, like turning a raw data stream into actual data, or storing data in the low bits of a pointer to aligned data.C-style cast and function-style cast are casts using (type)object or type(object), respectively, and are functionally equivalent. They are defined as the first of the following which succeeds:const_caststatic_cast (though ignoring access restrictions)static_cast (see above), then const_castreinterpret_castreinterpret_cast, then const_castIt can therefore be used as a replacement for other casts in some instances, but can be extremely dangerous because of the ability to devolve into a reinterpret_cast, and the latter should be preferred when explicit casting is needed, unless you are sure static_cast will succeed or reinterpret_cast will fail. Even then, consider the longer, more explicit option.C-style casts also ignore access control when performing a static_cast, which means that they have the ability to perform an operation that no other cast can. This is mostly a kludge, though, and in my mind is just another reason to avoid C-style casts."
"data_i","asked Jan 24 '13 at 05:44","
        How to add images to README.md on GitHub?
    ","Recently I joined GitHub. I hosted some projects there.I need to include some images in my README File. I don't know how to do that.I searched about this, but all I got was some links which tell me to ""host images on web and specify the image path in README.md file"".Is there any way to do this without hosting the images on any third-party web hosting services?","Try this markdown:![alt text](http://url/to/img.png)I think you can link directly to the raw version of an image if it's stored in your repository. i.e.![alt text](https://github.com/[username]/[reponame]/blob/[branch]/image.jpg?raw=true)"
"data_i","edited Apr 06 '18 at 08:01","
        Why is printing ""B"" dramatically slower than printing ""#""?
    ","I generated two matrices of 1000 x 1000:First Matrix: O and #.Second Matrix: O and B.Using the following code, the first matrix took 8.52 seconds to complete:Random r = new Random();for (int i = 0; i < 1000; i++) {    for (int j = 0; j < 1000; j++) {        if(r.nextInt(4) == 0) {            System.out.print(""O"");        } else {            System.out.print(""#"");        }    }   System.out.println(""""); }With this code, the second matrix took 259.152 seconds to complete:Random r = new Random();for (int i = 0; i < 1000; i++) {    for (int j = 0; j < 1000; j++) {        if(r.nextInt(4) == 0) {            System.out.print(""O"");        } else {            System.out.print(""B""); //only line changed        }    }    System.out.println("""");}What is the reason behind the dramatically different run times?As suggested in the comments, printing only System.out.print(""#""); takes 7.8871 seconds, whereas System.out.print(""B""); gives still printing....As others who pointed out that it works for them normally, I tried Ideone.com for instance, and both pieces of code execute at the same speed.Test Conditions:I ran this test from Netbeans 7.2, with the output into its consoleI used System.nanoTime() for measurements","Pure speculation is that you're using a terminal that attempts to do word-wrapping rather than character-wrapping, and treats B as a word character but # as a non-word character. So when it reaches the end of a line and searches for a place to break the line, it sees a # almost immediately and happily breaks there; whereas with the B, it has to keep searching for longer, and may have more text to wrap (which may be expensive on some terminals, e.g., outputting backspaces, then outputting spaces to overwrite the letters being wrapped).But that's pure speculation."
"data_i","edited Oct 17 '19 at 10:22","
        Deleting an element from an array in PHP
    ","Is there an easy way to delete an element from an array using PHP, such that foreach ($array) no longer includes that element?I thought that setting it to null would do it, but apparently it does not work.","There are different ways to delete an array element, where some are more useful for some specific tasks than others.Deleting a single array elementIf you want to delete just one array element you can use unset() or alternatively \array_splice().If you know the value and don’t know the key to delete the element you can use \array_search() to get the key. This only works if the element does not occur more than once, since \array_search returns the first hit only.unset()Note that when you use unset() the array keys won’t change. If you want to reindex the keys you can use \array_values() after unset(), which will convert all keys to numerically enumerated keys starting from 0.Code:$array = [0 => ""a"", 1 => ""b"", 2 => ""c""];unset($array[1]);          // ↑ Key which you want to deleteOutput:[    [0] => a    [2] => c]\array_splice() methodIf you use \array_splice() the keys will automatically be reindexed, but the associative keys won’t change — as opposed to \array_values(), which will convert all keys to numerical keys.\array_splice() needs the offset, not the key, as the second parameter.Code:$array = [0 => ""a"", 1 => ""b"", 2 => ""c""];\array_splice($array, 1, 1);                   // ↑ Offset which you want to deleteOutput:[    [0] => a    [1] => c]array_splice(), same as unset(), take the array by reference. You don’t assign the return values of those functions back to the array.Deleting multiple array elementsIf you want to delete multiple array elements and don’t want to call unset() or \array_splice() multiple times you can use the functions \array_diff() or \array_diff_key() depending on whether you know the values or the keys of the elements which you want to delete.\array_diff() methodIf you know the values of the array elements which you want to delete, then you can use \array_diff(). As before with unset() it won’t change the keys of the array.Code:$array = [0 => ""a"", 1 => ""b"", 2 => ""c"", 3 => ""c""];$array = \array_diff($array, [""a"", ""c""]);                          // └────────┘                          // Array values which you want to deleteOutput:[    [1] => b]\array_diff_key() methodIf you know the keys of the elements which you want to delete, then you want to use \array_diff_key(). You have to make sure you pass the keys as keys in the second parameter and not as values. Keys won’t reindex.Code:$array = [0 => ""a"", 1 => ""b"", 2 => ""c""];$array = \array_diff_key($array, [0 => ""xy"", ""2"" => ""xy""]);                               // ↑           ↑                               // Array keys which you want to deleteOutput:[    [1] => b]If you want to use unset() or \array_splice() to delete multiple elements with the same value you can use \array_keys() to get all the keys for a specific value and then delete all elements.\array_filter() methodIf you want to delete all elements with a specific value in the array you can use \array_filter().Code:$array = [0 => ""a"", 1 => ""b"", 2 => ""c""];$array = \array_filter($array, static function ($element) {    return $element !== ""b"";    //                   ↑    // Array value which you want to delete});Output:[    [0] => a    [1] => c]"
"data_i","edited Jul 11 '22 at 06:50","
        How do I modify a specific commit?
    ","I have the following commit history:HEADHEAD~HEAD~2HEAD~3git commit --amend modifies the current HEAD commit. But how do I modify HEAD~3?","Use git rebase. For example, to modify commit bbc643cd, run:$ git rebase --interactive 'bbc643cd^'Please note the caret ^ at the end of the command, because you need actually to rebase back to the commit before the one you wish to modify.In the default editor, modify pick to edit in the line mentioning bbc643cd.Save the file and exit. git will interpret and automatically execute the commands in the file. You will find yourself in the previous situation in which you just had created commit bbc643cd.At this point, bbc643cd is your last commit and you can easily amend it. Make your changes and then commit them with the command:$ git commit --all --amend --no-editAfter that, return back to the previous HEAD commit using:$ git rebase --continueWARNING: Note that this will change the SHA-1 of that commit as well as all children -- in other words, this rewrites the history from that point forward. You can break repos doing this if you push using the command git push --force."
"data_i","edited Aug 10 '22 at 19:30","
        What does "" 2>&1 "" mean?
    ","To combine stderr and stdout into the stdout stream, we append this to a command:2>&1e.g. to see the first few errors from compiling g++ main.cpp:g++ main.cpp 2>&1 | headWhat does 2>&1 mean, in detail?","File descriptor 1 is the standard output (stdout).File descriptor 2 is the standard error (stderr).At first, 2>1 may look like a good way to redirect stderr to stdout. However, it will actually be interpreted as ""redirect stderr to a file named 1"".& indicates that what follows and precedes is a file descriptor, and not a filename. Thus, we use 2>&1. Consider >& to be a redirect merger operator."
"data_i","edited Jul 24 '20 at 23:25","
        How can I check for ""undefined"" in JavaScript?
    ","What is the most appropriate way to test if a variable is undefined in JavaScript?I've seen several possible ways:if (window.myVariable)Orif (typeof(myVariable) != ""undefined"")Orif (myVariable) // This throws an error if undefined. Should this be in Try/Catch?","If you are interested in finding out whether a variable has been declared regardless of its value, then using the in operator is the safest way to go. Consider this example:// global scopevar theFu; // theFu has been declared, but its value is undefinedtypeof theFu; // ""undefined""But this may not be the intended result for some cases, since the variable or property was declared but just not initialized. Use the in operator for a more robust check.""theFu"" in window; // true""theFoo"" in window; // falseIf you are interested in knowing whether the variable hasn't been declared or has the value undefined, then use the typeof operator, which is guaranteed to return a string:if (typeof myVar !== 'undefined')Direct comparisons against undefined are troublesome as undefined can be overwritten. window.undefined = ""foo"";""foo"" == undefined // trueAs @CMS pointed out, this has been patched in ECMAScript 5th ed., and undefined is non-writable.if (window.myVar) will also include these falsy values, so it's not very robust:false0""""NaNnullundefinedThanks to @CMS for pointing out that your third case - if (myVariable) can also throw an error in two cases. The first is when the variable hasn't been defined which throws a ReferenceError. // abc was never declared.if (abc) {    // ReferenceError: abc is not defined} The other case is when the variable has been defined, but has a getter function which throws an error when invoked. For example,// or it's a property that can throw an errorObject.defineProperty(window, ""myVariable"", {     get: function() { throw new Error(""W00t?""); },     set: undefined });if (myVariable) {    // Error: W00t?}"
"data_i","edited Jul 02 '22 at 04:10","
        How do I split a list into equally-sized chunks?
    ","How do I split a list of arbitrary length into equal sized chunks?Related question: How to iterate over a list in chunks","Here's a generator that yields evenly-sized chunks:def chunks(lst, n):    """"""Yield successive n-sized chunks from lst.""""""    for i in range(0, len(lst), n):        yield lst[i:i + n]import pprintpprint.pprint(list(chunks(range(10, 75), 10)))[[10, 11, 12, 13, 14, 15, 16, 17, 18, 19], [20, 21, 22, 23, 24, 25, 26, 27, 28, 29], [30, 31, 32, 33, 34, 35, 36, 37, 38, 39], [40, 41, 42, 43, 44, 45, 46, 47, 48, 49], [50, 51, 52, 53, 54, 55, 56, 57, 58, 59], [60, 61, 62, 63, 64, 65, 66, 67, 68, 69], [70, 71, 72, 73, 74]]For Python 2, using xrange instead of range:def chunks(lst, n):    """"""Yield successive n-sized chunks from lst.""""""    for i in xrange(0, len(lst), n):        yield lst[i:i + n]Below is a list comprehension one-liner. The method above is preferable, though, since using named functions makes code easier to understand. For Python 3:[lst[i:i + n] for i in range(0, len(lst), n)]For Python 2:[lst[i:i + n] for i in xrange(0, len(lst), n)]"
"data_i","edited Jul 08 '22 at 06:20","
        Git fetch remote branch
    ","The remote contains various branches such as origin/daves_branch:$ git branch -rorigin/HEAD -> origin/masterorigin/daves_branchorigin/masterHow do I checkout daves_branch locally so that it tracks origin/daves_branch? I tried:$ git fetch origin discover$ git checkout discover","Update: Using Git SwitchAll of the information written below was accurate, but a new command, git switch has been added that simplifies the effort.If daves_branch exists on the remote repository, but not on your local branch, you can simply type:git switch daves_branchSince you do not have the branch locally, this will automatically make switch look on the remote repo.  It will then also automatically set up remote branch tracking.Note that if daves_branch doesn't exist locally you'll need to git fetch first before using switch.Original PostYou need to create a local branch that tracks a remote branch. The following command will create a local branch named daves_branch, tracking the remote branch origin/daves_branch. When you push your changes the remote branch will be updated.For most recent versions of Git:git checkout --track origin/daves_branch--track is shorthand for git checkout -b [branch] [remotename]/[branch] where [remotename] is origin in this case and [branch] is twice the same, daves_branch in this case.For Git 1.5.6.5 you needed this:git checkout --track -b daves_branch origin/daves_branchFor Git 1.7.2.3 and higher, this is enough (it might have started earlier, but this is the earliest confirmation I could find quickly):git checkout daves_branchNote that with recent Git versions, this command will not create a local branch and will put you in a 'detached HEAD' state. If you want a local branch, use the --track option.Full details are here: 3.5 Git Branching - Remote Branches, Tracking Branches"
"data_i","edited Jul 04 '22 at 21:45","
        What is the difference between #include  and #include ""filename""?
    ","What is the difference between using angle brackets and quotes in an include directive?#include <filename>#include ""filename""","What differs is the locations in which the preprocessor searches for the file to be included.#include <filename>   The preprocessor searches in an implementation-defined manner, normally in directories pre-designated by the compiler/IDE. This method is normally used to include header files for the C standard library and other header files associated with the target platform.#include ""filename""   The preprocessor also searches in an implementation-defined manner, but one that is normally used to include programmer-defined header files and typically includes same directory as the file containing the directive (unless an absolute path is given).For GCC, a more complete description is available in the GCC documentation on search paths."
"data_i","edited Jul 10 '22 at 22:35","
        How do I print colored text to the terminal?
    ","How do I output colored text to the terminal in Python?","This somewhat depends on what platform you are on. The most common way to do this is by printing ANSI escape sequences. For a simple example, here's some Python code from the Blender build scripts:class bcolors:    HEADER = '\033[95m'    OKBLUE = '\033[94m'    OKCYAN = '\033[96m'    OKGREEN = '\033[92m'    WARNING = '\033[93m'    FAIL = '\033[91m'    ENDC = '\033[0m'    BOLD = '\033[1m'    UNDERLINE = '\033[4m'To use code like this, you can do something like:print(bcolors.WARNING + ""Warning: No active frommets remain. Continue?"" + bcolors.ENDC)Or, with Python 3.6+:print(f""{bcolors.WARNING}Warning: No active frommets remain. Continue?{bcolors.ENDC}"")This will work on unixes including OS X, Linux and Windows (provided you use ANSICON, or in Windows 10 provided you enable VT100 emulation). There are ANSI codes for setting the color, moving the cursor, and more.If you are going to get complicated with this (and it sounds like you are if you are writing a game), you should look into the ""curses"" module, which handles a lot of the complicated parts of this for you. The Python Curses HowTO is a good introduction.If you are not using extended ASCII (i.e., not on a PC), you are stuck with the ASCII characters below 127, and '#' or '@' is probably your best bet for a block. If you can ensure your terminal is using a IBM extended ASCII character set, you have many more options. Characters 176, 177, 178 and 219 are the ""block characters"".Some modern text-based programs, such as ""Dwarf Fortress"", emulate text mode in a graphical mode, and use images of the classic PC font. You can find some of these bitmaps that you can use on the Dwarf Fortress Wiki see (user-made tilesets).The Text Mode Demo Contest has more resources for doing graphics in text mode."
"data_i","edited Sep 10 '17 at 19:21","
        How to append something to an array?
    ","How do I append an object (such as a string or number) to an array in JavaScript?          ","Use the Array.prototype.push method to append values to the end of an array:// initialize arrayvar arr = [  ""Hi"",  ""Hello"",  ""Bonjour""];// append new value to the arrayarr.push(""Hola"");console.log(arr);You can use the push() function to append more than one value to an array in a single call:// initialize arrayvar arr = [""Hi"", ""Hello"", ""Bonjour"", ""Hola""];// append multiple values to the arrayarr.push(""Salut"", ""Hey"");// display all valuesfor (var i = 0; i < arr.length; i++) {  console.log(arr[i]);}UpdateIf you want to add the items of one array to another array, you can use firstArray.concat(secondArray):var arr = [  ""apple"",  ""banana"",  ""cherry""];// Do not forget to assign the result as, unlike push, concat does not change the existing arrayarr = arr.concat([  ""dragonfruit"",  ""elderberry"",  ""fig""]);console.log(arr);UpdateJust an addition to this answer if you want to prepend any value to the start of an array (i.e. first index) then you can use Array.prototype.unshift for this purpose.var arr = [1, 2, 3];arr.unshift(0);console.log(arr);It also supports appending multiple values at once just like push.UpdateAnother way with ES6 syntax is to return a new array with the spread syntax. This leaves the original array unchanged, but returns a new array with new items appended, compliant with the spirit of functional programming.const arr = [  ""Hi"",  ""Hello"",  ""Bonjour"",];const newArr = [  ...arr,  ""Salut"",];console.log(newArr);"
"data_i","edited May 11 '20 at 09:13","
        Is there a standard function to check for null, undefined, or blank variables in JavaScript?
    ","Is there a universal JavaScript function that checks that a variable has a value and ensures that it's not undefined or null? I've got this code, but I'm not sure if it covers all cases:function isEmpty(val){    return (val === undefined || val == null || val.length <= 0) ? true : false;}","You can just check if the variable has a truthy value or not. That meansif( value ) {}will evaluate to true if value is not:nullundefinedNaNempty string ("""")0falseThe above list represents all possible falsy values in ECMA-/Javascript. Find it in the specification at the ToBoolean section.Furthermore, if you do not know whether a variable exists (that means, if it was declared) you should check with the typeof operator. For instanceif( typeof foo !== 'undefined' ) {    // foo could get resolved and it's defined}If you can be sure that a variable is declared at least, you should directly check if it has a truthy value like shown above."
"data_i","edited Jul 10 '20 at 18:31","
        Length of a JavaScript object
    ","I have a JavaScript object. Is there a built-in or accepted best practice way to get the length of this object?const myObject = new Object();myObject[""firstname""] = ""Gareth"";myObject[""lastname""] = ""Simpson"";myObject[""age""] = 21;","Updated answerHere's an update as of 2016 and widespread deployment of ES5 and beyond.  For IE9+ and all other modern ES5+ capable browsers, you can use Object.keys() so the above code just becomes:var size = Object.keys(myObj).length;This doesn't have to modify any existing prototype since Object.keys() is now built-in.Edit: Objects can have symbolic properties that can not be returned via Object.key method. So the answer would be incomplete without mentioning them.Symbol type was added to the language to create unique identifiers for object properties. The main benefit of the Symbol type is the prevention of overwrites.Object.keys or Object.getOwnPropertyNames does not work for symbolic properties. To return them you need to use Object.getOwnPropertySymbols.var person = {  [Symbol('name')]: 'John Doe',  [Symbol('age')]: 33,  ""occupation"": ""Programmer""};const propOwn = Object.getOwnPropertyNames(person);console.log(propOwn.length); // 1let propSymb = Object.getOwnPropertySymbols(person);console.log(propSymb.length); // 2Older answerThe most robust answer (i.e. that captures the intent of what you're trying to do while causing the fewest bugs) would be:Object.size = function(obj) {  var size = 0,    key;  for (key in obj) {    if (obj.hasOwnProperty(key)) size++;  }  return size;};// Get the size of an objectconst myObj = {}var size = Object.size(myObj);There's a sort of convention in JavaScript that you don't add things to Object.prototype, because it can break enumerations in various libraries. Adding methods to Object is usually safe, though."
"data_i","edited Apr 01 '22 at 12:14","
        How do I access environment variables in Python?
    ","How do I get the value of an environment variable in Python?","Environment variables are accessed through os.environ:import osprint(os.environ['HOME'])To see a list of all environment variables:print(os.environ)If a key is not present, attempting to access it will raise a KeyError. To avoid this:# Returns `None` if key doesn't existprint(os.environ.get('KEY_THAT_MIGHT_EXIST'))# Returns `default_value` if key doesn't existprint(os.environ.get('KEY_THAT_MIGHT_EXIST', default_value))# Returns `default_value` if key doesn't existprint(os.getenv('KEY_THAT_MIGHT_EXIST', default_value))"
"data_i","edited Apr 29 '22 at 20:16","
        How do I modify the URL without reloading the page?
    ","Is there a way I can modify the URL of the current page without reloading the page?I would like to access the portion before the # hash if possible.I only need to change the portion after the domain, so it's not like I'm violating cross-domain policies. window.location.href = ""www.mysite.com/page2.php"";  // this reloads","This can now be done in Chrome, Safari, Firefox 4+, and Internet Explorer 10pp4+!See this question's answer for more information:Updating address bar with new URL without hash or reloading the pageExample: function processAjaxData(response, urlPath){     document.getElementById(""content"").innerHTML = response.html;     document.title = response.pageTitle;     window.history.pushState({""html"":response.html,""pageTitle"":response.pageTitle},"""", urlPath); }You can then use window.onpopstate to detect the back/forward button navigation:window.onpopstate = function(e){    if(e.state){        document.getElementById(""content"").innerHTML = e.state.html;        document.title = e.state.pageTitle;    }};For a more in-depth look at manipulating browser history, see this MDN article."
"data_i","edited Jan 14 '21 at 23:51","
        How do I get the current date in JavaScript?
    ","How do I get the current date in JavaScript?","Use new Date() to generate a new Date object containing the current date and time.var today = new Date();var dd = String(today.getDate()).padStart(2, '0');var mm = String(today.getMonth() + 1).padStart(2, '0'); //January is 0!var yyyy = today.getFullYear();today = mm + '/' + dd + '/' + yyyy;document.write(today);This will give you today's date in the format of mm/dd/yyyy.Simply change today = mm +'/'+ dd +'/'+ yyyy; to whatever format you wish."
"data_i","edited Aug 07 '22 at 23:06","
        Convert string ""Jun 1 2005 1:33PM"" into datetime
    ","How do I convert the following string to a datetime object?""Jun 1 2005  1:33PM""","datetime.strptime parses an input string in the user-specified format into a timezone-naive datetime object:>>> from datetime import datetime>>> datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')datetime.datetime(2005, 6, 1, 13, 33)To obtain a date object using an existing datetime object, convert it using .date():>>> datetime.strptime('Jun 1 2005', '%b %d %Y').date()date(2005, 6, 1)Links:strptime docs: Python 2, Python 3strptime/strftime format string docs: Python 2, Python 3strftime.org format string cheatsheetNotes:strptime = ""string parse time""strftime = ""string format time"""
"data_i","edited Jan 01 '20 at 01:06","
        How can I check if a program exists from a Bash script?
    ","How would I validate that a program exists, in a way that will either return an error and exit, or continue with the script?It seems like it should be easy, but it's been stumping me.","AnswerPOSIX compatible:command -v <the_command>Example use:if ! command -v <the_command> &> /dev/nullthen    echo ""<the_command> could not be found""    exitfiFor Bash specific environments:hash <the_command> # For regular commands. Or...type <the_command> # To check built-ins and keywordsExplanationAvoid which. Not only is it an external process you're launching for doing very little (meaning builtins like hash, type or command are way cheaper), you can also rely on the builtins to actually do what you want, while the effects of external commands can easily vary from system to system.Why care?Many operating systems have a which that doesn't even set an exit status, meaning the if which foo won't even work there and will always report that foo exists, even if it doesn't (note that some POSIX shells appear to do this for hash too).Many operating systems make which do custom and evil stuff like change the output or even hook into the package manager.So, don't use which. Instead use one of these:command -v foo >/dev/null 2>&1 || { echo >&2 ""I require foo but it's not installed.  Aborting.""; exit 1; }type foo >/dev/null 2>&1 || { echo >&2 ""I require foo but it's not installed.  Aborting.""; exit 1; }hash foo 2>/dev/null || { echo >&2 ""I require foo but it's not installed.  Aborting.""; exit 1; }(Minor side-note: some will suggest 2>&- is the same 2>/dev/null but shorter – this is untrue.  2>&- closes FD 2 which causes an error in the program when it tries to write to stderr, which is very different from successfully writing to it and discarding the output (and dangerous!))If your hash bang is /bin/sh then you should care about what POSIX says. type and hash's exit codes aren't terribly well defined by POSIX, and hash is seen to exit successfully when the command doesn't exist (haven't seen this with type yet).  command's exit status is well defined by POSIX, so that one is probably the safest to use.If your script uses bash though, POSIX rules don't really matter anymore and both type and hash become perfectly safe to use. type now has a -P to search just the PATH and hash has the side-effect that the command's location will be hashed (for faster lookup next time you use it), which is usually a good thing since you probably check for its existence in order to actually use it.As a simple example, here's a function that runs gdate if it exists, otherwise date:gnudate() {    if hash gdate 2>/dev/null; then        gdate ""$@""    else        date ""$@""    fi}Alternative with a complete feature setYou can use scripts-common to reach your need.To check if something is installed, you can do:checkBin <the_command> || errorMessage ""This tool requires <the_command>. Install it please, and then run this tool again."""
"data_i","edited Dec 20 '21 at 13:00","
        What is the --save option for npm install?
    ","I saw some tutorial where the command was:npm install --saveWhat does the --save option mean?","Update npm 5:As of npm 5.0.0, installed modules are added as a dependency by default, so the --save option is no longer needed. The other save options still exist and are listed in the documentation for npm install.Original answer:Before version 5, NPM simply installed a package under node_modules by default. When you were trying to install dependencies for your app/module, you would need to first install them, and then add them (along with the appropriate version number) to the dependencies section of your package.json.The --save option instructed NPM to include the package inside of the dependencies section of your package.json automatically, thus saving you an additional step.In addition, there are the complementary options --save-dev and --save-optional which save the package under devDependencies and optionalDependencies, respectively. This is useful when installing development-only packages, like grunt or your testing library."
"data_i","edited Jun 14 '18 at 04:03","
        How do I pass command line arguments to a Node.js program?
    ","I have a web server written in Node.js and I would like to launch with a specific folder. I'm not sure how to access arguments in JavaScript. I'm running node like this:$ node server.js folderhere server.js is my server code. Node.js help says this is possible:$ node -hUsage: node [options] script.js [arguments]How would I access those arguments in JavaScript? Somehow I was not able to find this information on the web.","Standard Method (no library)The arguments are stored in process.argvHere are the node docs on handling command line args:process.argv is an array containing the command line arguments. The first element will be 'node', the second element will be the name of the JavaScript file. The next elements will be any additional command line arguments.// print process.argvprocess.argv.forEach(function (val, index, array) {  console.log(index + ': ' + val);});This will generate:$ node process-2.js one two=three four0: node1: /Users/mjr/work/node/process-2.js2: one3: two=three4: four"
"data_i","edited Jul 08 '22 at 06:50","
        How do I clone a Git repository into a specific folder?
    ","The command git clone git@github.com:whatever creates a directory named whatever containing a Git repository:./    whatever/        .gitI want the contents of the Git repository cloned into my current directory ./ instead:./    .git","Option A:git clone git@github.com:whatever folder-nameErgo, for right here use:git clone git@github.com:whatever .Option B:Move the .git folder, too. Note that the .git folder is hidden in most graphical file explorers, so be sure to show hidden files.mv /where/it/is/right/now/* /where/I/want/it/mv /where/it/is/right/now/.* /where/I/want/it/The first line grabs all normal files, the second line grabs dot-files. It is also possibe to do it in one line by enabling dotglob (i.e. shopt -s dotglob) but that is probably a bad solution if you are asking the question this answer answers.Better yet:Keep your working copy somewhere else, and create a symbolic link. Like this:ln -s /where/it/is/right/now /the/path/I/want/to/useFor your case this would be something like:ln -sfn /opt/projectA/prod/public /httpdocs/publicWhich easily could be changed to test if you wanted it, i.e.:ln -sfn /opt/projectA/test/public /httpdocs/publicwithout moving files around. Added -fn in case someone is copying these lines (-f is force,  -n avoid some often unwanted interactions with already and non-existing links).If you just want it to work, use Option A, if someone else is going to look at what you have done, use Option C."
"data_i","edited Sep 13 '22 at 14:18","
        How can I save an activity state using the save instance state?
    ","I've been working on the Android SDK platform, and it is a little unclear how to save an application's state. So given this minor re-tooling of the 'Hello, Android' example:package com.android.hello;import android.app.Activity;import android.os.Bundle;import android.widget.TextView;public class HelloAndroid extends Activity {  private TextView mTextView = null;  /** Called when the activity is first created. */  @Override  public void onCreate(Bundle savedInstanceState) {    super.onCreate(savedInstanceState);    mTextView = new TextView(this);    if (savedInstanceState == null) {       mTextView.setText(""Welcome to HelloAndroid!"");    } else {       mTextView.setText(""Welcome back."");    }    setContentView(mTextView);  }}I thought it would be enough for the simplest case, but it always responds with the first message, no matter how I navigate away from the app.I'm sure the solution is as simple as overriding onPause or something like that, but I've been poking away in the documentation for 30 minutes or so and haven't found anything obvious.","You need to override onSaveInstanceState(Bundle savedInstanceState) and write the application state values you want to change to the Bundle parameter like this:@Overridepublic void onSaveInstanceState(Bundle savedInstanceState) {  super.onSaveInstanceState(savedInstanceState);  // Save UI state changes to the savedInstanceState.  // This bundle will be passed to onCreate if the process is  // killed and restarted.  savedInstanceState.putBoolean(""MyBoolean"", true);  savedInstanceState.putDouble(""myDouble"", 1.9);  savedInstanceState.putInt(""MyInt"", 1);  savedInstanceState.putString(""MyString"", ""Welcome back to Android"");  // etc.}The Bundle is essentially a way of storing a NVP (""Name-Value Pair"") map, and it will get passed in to onCreate() and also onRestoreInstanceState() where you would then extract the values from activity like this:@Overridepublic void onRestoreInstanceState(Bundle savedInstanceState) {  super.onRestoreInstanceState(savedInstanceState);  // Restore UI state from the savedInstanceState.  // This bundle has also been passed to onCreate.  boolean myBoolean = savedInstanceState.getBoolean(""MyBoolean"");  double myDouble = savedInstanceState.getDouble(""myDouble"");  int myInt = savedInstanceState.getInt(""MyInt"");  String myString = savedInstanceState.getString(""MyString"");}Or from a fragment.@Overridepublic void onViewStateRestored(@Nullable Bundle savedInstanceState) {    super.onViewStateRestored(savedInstanceState);    // Restore UI state from the savedInstanceState.    // This bundle has also been passed to onCreate.    boolean myBoolean = savedInstanceState.getBoolean(""MyBoolean"");    double myDouble = savedInstanceState.getDouble(""myDouble"");    int myInt = savedInstanceState.getInt(""MyInt"");    String myString = savedInstanceState.getString(""MyString"");}You would usually use this technique to store instance values for your application (selections, unsaved text, etc.)."
"data_i","edited Jan 04 '20 at 19:07","
        How do I detect a click outside an element?
    ","I have some HTML menus, which I show completely when a user clicks on the head of these menus. I would like to hide these elements when the user clicks outside the menus' area.Is something like this possible with jQuery?$(""#menuscontainer"").clickOutsideThisElement(function() {    // Hide the menus});","Note: Using stopPropagation is something that should be avoided as it breaks normal event flow in the DOM. See this CSS Tricks article for more information. Consider using this method instead.Attach a click event to the document body which closes the window. Attach a separate click event to the container which stops propagation to the document body.$(window).click(function() {  //Hide the menus if visible});$('#menucontainer').click(function(event){  event.stopPropagation();});"
"data_i","edited Oct 07 '21 at 05:46","
        HTTP GET with request body
    ","I'm developing a new RESTful webservice for our application.When doing a GET on certain entities, clients can request the contents of the entity.If they want to add some parameters (for example sorting a list) they can add these parameters in the query string.Alternatively I want people to be able to specify these parameters in the request body.HTTP/1.1 does not seem to explicitly forbid this. This will allow them to specify more information, might make it easier to specify complex XML requests.My questions:Is this a good idea altogether?Will HTTP clients have issues with using request bodies within a GET request?https://www.rfc-editor.org/rfc/rfc2616","Roy Fielding's comment about including a body with a GET request.Yes. In other words, any HTTP request message is allowed to contain a message body, and thus must parse messages with that in mind. Server semantics for GET, however, are restricted such that a body, if any, has no semantic meaning to the request. The requirements on parsing are separate from the requirements on method semantics.So, yes, you can send a body with GET, and no, it is never useful to do so.This is part of the layered design of HTTP/1.1 that will become clear again once the spec is partitioned (work in progress).....RoyYes, you can send a request body with GET but it should not have any meaning. If you give it meaning by parsing it on the server and changing your response based on its contents, then you are ignoring this recommendation in the HTTP/1.1 spec, section 4.3:...if the request method does not include defined semantics for an entity-body, then the message-body SHOULD be ignored when handling the request.And the description of the GET method in the HTTP/1.1 spec, section 9.3:The GET method means retrieve whatever information ([...]) is identified by the Request-URI.which states that the request-body is not part of the identification of the resource in a GET request, only the request URI.UpdateThe RFC2616 referenced as ""HTTP/1.1 spec"" is now obsolete. In 2014 it was replaced by RFCs 7230-7237. Quote ""the message-body SHOULD be ignored when handling the request"" has been deleted. It's now just ""Request message framing is independent of method semantics, even if the method doesn't define any use for a message body"" The 2nd quote ""The GET method means retrieve whatever information ... is identified by the Request-URI"" was deleted.  - From a commentFrom the HTTP 1.1 2014 Spec:A payload within a GET request message has no defined semantics; sending a payload body on a GET request might cause some existing implementations to reject the request."
"data_i","edited Sep 16 '19 at 05:12","
        What is the difference between the 'COPY' and 'ADD' commands in a Dockerfile?
    ","What is the difference between the COPY and ADD commands in a Dockerfile, and when would I use one over the other?COPY <src> <dest>The COPY instruction will copy new files from <src> and add them to the container's filesystem at path <dest>ADD <src> <dest>The ADD instruction will copy new files from <src> and add them to the container's filesystem at path <dest>.","You should check the ADD and COPY documentation for a more detailed description of their behaviors, but in a nutshell, the major difference is that ADD can do more than COPY:ADD allows <src> to be a URLReferring to comments below, the ADD documentation states that:If  is a local tar archive in a recognized compression format (identity, gzip, bzip2 or xz) then it is unpacked as a directory. Resources from remote URLs are not decompressed.Note that the Best practices for writing Dockerfiles suggests using COPY where the magic of ADD is not required. Otherwise, you (since you had to look up this answer) are likely to get surprised someday when you mean to copy keep_this_archive_intact.tar.gz into your container, but instead, you spray the contents onto your filesystem."
"data_i","edited Aug 07 '22 at 20:12","
        How do I see the differences between two branches?
    ","How do I see the differences between branches branch_1 and branch_2?","Use git diff.git diff [<options>] <commit>..​<commit> [--] [<path>…​]<commit> is a branch name, a commit hash, or a shorthand symbolic reference.Examples:  git diff abc123..def567,  git diff HEAD..origin/master.That will produce the diff between the tips of the two branches. If you'd prefer to find the diff from their common ancestor to test, you can use three dots instead of two:git diff <commit>...<commit>To check which files differ, not how the content differs, use --name-only:git diff --name-only <commit>..​<commit>Note that in the <commit>..<commit> (two dot) syntax, the dots are optional; the following is synonymous:git diff commit1 commit2"
"data_i","edited Mar 01 '22 at 15:09","
        What are the correct version numbers for C#?
    ","What are the correct version numbers for C#? What came out when? Why can't I find any answers about C# 3.5?This question is primarily to aid those who are searching for an answer using an incorrect version number, e.g. C# 3.5. The hope is that anyone failing to find an answer with the wrong version number will find this question and then search again with the right version number.","C# language version history:These are the versions of C# known about at the time of this writing:C# 1.0 released with .NET 1.0 and VS2002 (January 2002)C# 1.2 (bizarrely enough); released with .NET 1.1 and VS2003 (April 2003). First version to call Dispose on IEnumerators which implemented IDisposable. A few other small features.C# 2.0 released with .NET 2.0 and VS2005 (November 2005). Major new features: generics, anonymous methods, nullable types, and iterator blocksC# 3.0 released with .NET 3.5 and VS2008 (November 2007). Major new features: lambda expressions, extension methods, expression trees, anonymous types, implicit typing (var), and query expressionsC# 4.0 released with .NET 4 and VS2010 (April 2010). Major new features: late binding (dynamic), delegate and interface generic variance, more COM support, named arguments, tuple data type and optional parametersC# 5.0 released with .NET 4.5 and VS2012 (August 2012). Major features: async programming, and caller info attributes. Breaking change: loop variable closure.C# 6.0 released with .NET 4.6 and VS2015 (July 2015). Implemented by Roslyn. Features: initializers for automatically implemented properties, using directives to import static members, exception filters, element initializers, await in catch and finally, extension Add methods in collection initializers.C# 7.0 released with .NET 4.7 and VS2017 (March 2017). Major new features: tuples, ref locals and ref return, pattern matching (including pattern-based switch statements), inline out parameter declarations, local functions, binary literals, digit separators, and arbitrary async returns.C# 7.1 released with VS2017 v15.3 (August 2017). New features: async main, tuple member name inference, default expression, and pattern matching with generics.C# 7.2 released with VS2017 v15.5 (November 2017). New features: private protected access modifier, Span<T>, aka interior pointer, aka stackonly struct, and everything else.C# 7.3 released with VS2017 v15.7 (May 2018). New features: enum, delegate and unmanaged generic type constraints. ref reassignment. Unsafe improvements: stackalloc initialization, unpinned indexed fixed buffers, custom fixed statements. Improved overloading resolution. Expression variables in initializers and queries. == and != defined for tuples. Auto-properties' backing fields can now be targeted by attributes.C# 8.0 released with .NET Core 3.0 and VS2019 v16.3 (September 2019). Major new features: nullable reference-types, asynchronous streams, indices and ranges, readonly members, using declarations, default interface methods, static local functions, and enhancement of interpolated verbatim strings.C# 9.0 released with .NET 5.0 and VS2019 v16.8 (November 2020). Major new features: init-only properties, records, with-expressions, data classes, positional records, top-level programs, improved pattern matching (simple type patterns, relational patterns, logical patterns), improved target typing (target-type new expressions, target typed ?? and ?), and covariant returns. Minor features: relax ordering of ref and partial modifiers, parameter null checking, lambda discard parameters, native ints, attributes on local functions, function pointers, static lambdas, extension GetEnumerator, module initializers, and extending partial.C# 10.0 released with .NET 6.0 (November 2021). Major new features: record structs, struct parameterless constructors, interpolated string handlers, global using directives, file-scoped namespace declarations, extended property patterns, const interpolated strings, mixed assignment and declaration in deconstruction, async method builders (via attributes) for individual methods, the CallerArgumentExpression attribute for parameters, enhanced #line pragmas.In response to the OP's question:What are the correct version numbers for C#? What came out when? Why can't I find any answers about C# 3.5?There is no such thing as C# 3.5 - the cause of confusion here is that the C# 3.0 is present in .NET 3.5. The language and framework are versioned independently, however - as is the CLR, which is at version 2.0 for .NET 2.0 through 3.5, .NET 4 introducing CLR 4.0, service packs notwithstanding. The CLR in .NET 4.5 has various improvements, but the versioning is unclear: in some places it may be referred to as CLR 4.5 (this MSDN page used to refer to it that way, for example), but the Environment.Version property still reports 4.0.xxx.As of May 3, 2017, the C# Language Team created a history of C# versions and features on their GitHub repository: Features Added in C# Language Versions. There is also a page that tracks upcoming and recently implemented language features."
"data_i","edited Jul 24 '18 at 11:59","
        How does database indexing work?
    ","Given that indexing is so important as your data set increases in size, can someone explain how indexing works at a database-agnostic level?For information on queries to index a field, check out How do I index a database column.","Why is it needed?When data is stored on disk-based storage devices, it is stored as blocks of data. These blocks are accessed in their entirety, making them the atomic disk access operation. Disk blocks are structured in much the same way as linked lists; both contain a section for data, a pointer to the location of the next node (or block), and both need not be stored contiguously.Due to the fact that a number of records can only be sorted on one field, we can state that searching on a field that isn’t sorted requires a Linear Search which requires (N+1)/2 block accesses (on average), where N is the number of blocks that the table spans. If that field is a non-key field (i.e. doesn’t contain unique entries) then the entire tablespace must be searched at N block accesses.Whereas with a sorted field, a Binary Search may be used, which has log2 N block accesses. Also since the data is sorted given a non-key field, the rest of the table doesn’t need to be searched for duplicate values, once a higher value is found. Thus the performance increase is substantial.What is indexing?Indexing is a way of sorting a number of records on multiple fields. Creating an index on a field in a table creates another data structure which holds the field value, and a pointer to the record it relates to. This index structure is then sorted, allowing Binary Searches to be performed on it.The downside to indexing is that these indices require additional space on the disk since the indices are stored together in a table using the MyISAM engine, this file can quickly reach the size limits of the underlying file system if many fields within the same table are indexed.How does it work?Firstly, let’s outline a sample database table schema;Field name       Data type      Size on diskid (Primary key) Unsigned INT   4 bytesfirstName        Char(50)       50 byteslastName         Char(50)       50 bytesemailAddress     Char(100)      100 bytesNote: char was used in place of varchar to allow for an accurate size on disk value.This sample database contains five million rows and is unindexed. The performance of several queries will now be analyzed. These are a query using the id (a sorted key field) and one using the firstName (a non-key unsorted field).Example 1 - sorted vs unsorted fieldsGiven our sample database of r = 5,000,000 records of a fixed size giving a record length of R = 204 bytes and they are stored in a table using the MyISAM engine which is using the default block size B = 1,024 bytes. The blocking factor of the table would be bfr = (B/R) = 1024/204 = 5 records per disk block. The total number of blocks required to hold the table is N = (r/bfr) = 5000000/5 = 1,000,000 blocks.A linear search on the id field would require an average of N/2 = 500,000 block accesses to find a value, given that the id field is a key field. But since the id field is also sorted, a binary search can be conducted requiring an average of log2 1000000 = 19.93 = 20 block accesses. Instantly we can see this is a drastic improvement.Now the firstName field is neither sorted nor a key field, so a binary search is impossible, nor are the values unique, and thus the table will require searching to the end for an exact N = 1,000,000 block accesses. It is this situation that indexing aims to correct.Given that an index record contains only the indexed field and a pointer to the original record, it stands to reason that it will be smaller than the multi-field record that it points to. So the index itself requires fewer disk blocks than the original table, which therefore requires fewer block accesses to iterate through. The schema for an index on the firstName field is outlined below;Field name       Data type      Size on diskfirstName        Char(50)       50 bytes(record pointer) Special        4 bytesNote: Pointers in MySQL are 2, 3, 4 or 5 bytes in length depending on the size of the table.Example 2  - indexingGiven our sample database of r = 5,000,000 records with an index record length of R = 54 bytes and using the default block size B = 1,024 bytes. The blocking factor of the index would be bfr = (B/R) = 1024/54 = 18 records per disk block. The total number of blocks required to hold the index is N = (r/bfr) = 5000000/18 = 277,778 blocks.Now a search using the firstName field can utilize the index to increase performance. This allows for a binary search of the index with an average of log2 277778 = 18.08 = 19 block accesses. To find the address of the actual record, which requires a further block access to read, bringing the total to 19 + 1 = 20 block accesses, a far cry from the 1,000,000 block accesses required to find a firstName match in the non-indexed table.When should it be used?Given that creating an index requires additional disk space (277,778 blocks extra from the above example, a ~28% increase), and that too many indices can cause issues arising from the file systems size limits, careful thought must be used to select the correct fields to index.Since indices are only used to speed up the searching for a matching field within the records, it stands to reason that indexing fields used only for output would be simply a waste of disk space and processing time when doing an insert or delete operation, and thus should be avoided. Also given the nature of a binary search, the cardinality or uniqueness of the data is important. Indexing on a field with a cardinality of 2 would split the data in half, whereas a cardinality of 1,000 would return approximately 1,000 records. With such a low cardinality the effectiveness is reduced to a linear sort, and the query optimizer will avoid using the index if the cardinality is less than 30% of the record number, effectively making the index a waste of space."
"data_i","edited Apr 21 '19 at 19:20","
        I need an unordered list without any bullets
    ","I have created an unordered list. I feel the bullets in the unordered list are bothersome, so I want to remove them. Is it possible to have a list without bullets?","You can remove bullets by setting the list-style-type to none on the CSS for the parent element (typically a <ul>), for example:ul {  list-style-type: none;}You might also want to add padding: 0 and margin: 0 to that if you want to remove indentation as well.See Listutorial for a great walkthrough of list formatting techniques."
"data_i","edited Jun 06 '22 at 03:38","
        Find the current directory and file's directory
    ","How do I determine:the current directory (where I was in the terminal when I ran the Python script), andwhere the Python file I am executing is?","To get the full path to the directory a Python file is contained in, write this in that file:import os dir_path = os.path.dirname(os.path.realpath(__file__))(Note that the incantation above won't work if you've already used os.chdir() to change your current working directory, since the value of the __file__ constant is relative to the current working directory and is not changed by an os.chdir() call.)To get the current working directory use import oscwd = os.getcwd()Documentation references for the modules, constants and functions used above:The os and os.path modules.The __file__ constantos.path.realpath(path) (returns ""the canonical path of the specified filename, eliminating any symbolic links encountered in the path"")os.path.dirname(path) (returns ""the directory name of pathname path"")os.getcwd() (returns ""a string representing the current working directory"")os.chdir(path) (""change the current working directory to path"")"
"data_i","asked May 06 '15 at 15:32","
        Why is ""1000000000000000 in range(1000000000000001)"" so fast in Python 3?
    ","It is my understanding that the range() function, which is actually an object type in Python 3, generates its contents on the fly, similar to a generator.This being the case, I would have expected the following line to take an inordinate amount of time because, in order to determine whether 1 quadrillion is in the range, a quadrillion values would have to be generated:1_000_000_000_000_000 in range(1_000_000_000_000_001)Furthermore: it seems that no matter how many zeroes I add on, the calculation more or less takes the same amount of time (basically instantaneous).I have also tried things like this, but the calculation is still almost instant:# count by tens1_000_000_000_000_000_000_000 in range(0,1_000_000_000_000_000_000_001,10)If I try to implement my own range function, the result is not so nice!def my_crappy_range(N):    i = 0    while i < N:        yield i        i += 1    returnWhat is the range() object doing under the hood that makes it so fast?Martijn Pieters's answer was chosen for its completeness, but also see abarnert's first answer for a good discussion of what it means for range to be a full-fledged sequence in Python 3, and some information/warning regarding potential inconsistency for __contains__ function optimization across Python implementations. abarnert's other answer goes into some more detail and provides links for those interested in the history behind the optimization in Python 3 (and lack of optimization of xrange in Python 2). Answers by poke and by wim provide the relevant C source code and explanations for those who are interested.","The Python 3 range() object doesn't produce numbers immediately; it is a smart sequence object that produces numbers on demand. All it contains is your start, stop and step values, then as you iterate over the object the next integer is calculated each iteration.The object also implements the object.__contains__ hook, and calculates if your number is part of its range. Calculating is a (near) constant time operation *. There is never a need to scan through all possible integers in the range.From the range() object documentation:The advantage of the range type over a regular list or tuple is that a range object will always take the same (small) amount of memory, no matter the size of the range it represents (as it only stores the start, stop and step values, calculating individual items and subranges as needed).So at a minimum, your range() object would do:class my_range:    def __init__(self, start, stop=None, step=1, /):        if stop is None:            start, stop = 0, start        self.start, self.stop, self.step = start, stop, step        if step < 0:            lo, hi, step = stop, start, -step        else:            lo, hi = start, stop        self.length = 0 if lo > hi else ((hi - lo - 1) // step) + 1    def __iter__(self):        current = self.start        if self.step < 0:            while current > self.stop:                yield current                current += self.step        else:            while current < self.stop:                yield current                current += self.step    def __len__(self):        return self.length    def __getitem__(self, i):        if i < 0:            i += self.length        if 0 <= i < self.length:            return self.start + i * self.step        raise IndexError('my_range object index out of range')    def __contains__(self, num):        if self.step < 0:            if not (self.stop < num <= self.start):                return False        else:            if not (self.start <= num < self.stop):                return False        return (num - self.start) % self.step == 0This is still missing several things that a real range() supports (such as the .index() or .count() methods, hashing, equality testing, or slicing), but should give you an idea.I also simplified the __contains__ implementation to only focus on integer tests; if you give a real range() object a non-integer value (including subclasses of int), a slow scan is initiated to see if there is a match, just as if you use a containment test against a list of all the contained values. This was done to continue to support other numeric types that just happen to support equality testing with integers but are not expected to support integer arithmetic as well. See the original Python issue that implemented the containment test.* Near constant time because Python integers are unbounded and so math operations also grow in time as N grows, making this a O(log N) operation. Since it’s all executed in optimised C code and Python stores integer values in 30-bit chunks, you’d run out of memory before you saw any performance impact due to the size of the integers involved here."
"data_i","edited Jul 11 '22 at 06:58","
        How do I change the author and committer name/email for multiple commits?
    ","How do I change the author for a range of commits?","NOTE: This answer changes SHA1s, so take care when using it on a branch that has already been pushed. If you only want to fix the spelling of a name or update an old email, Git lets you do this without rewriting history using .mailmap. See my other answer.Using RebaseFirst, if you haven't already done so, you will likely want to fix your name in git-config:git config --global user.name ""New Author Name""git config --global user.email ""<email@address.example>""This is optional, but it will also make sure to reset the committer name, too, assuming that's what you need.To rewrite metadata for a range of commits using a rebase, dogit rebase -r <some commit before all of your bad commits> \    --exec 'git commit --amend --no-edit --reset-author'--exec will run the git commit step after each commit is rewritten (as if you ran git commit && git rebase --continue repeatedly).If you also want to change your first commit (also called the 'root' commit), you will have to add --root to the rebase call.This will change both the committer and the author to your user.name/user.email configuration. If you did not want to change that config, you can use --author ""New Author Name <email@address.example>"" instead of --reset-author. Note that doing so will not update the committer -- just the author.Single CommitIf you just want to change the most recent commit, a rebase is not necessary. Just amend the commit: git commit --amend --no-edit --reset-authorFor older Git clients (pre-July 2020)-r,--rebase-merges may not exist for you. As a replacement, you can use -p. Note that -p has serious issues and is now deprecated."
"data_i","edited Dec 06 '21 at 14:49","
        Determine installed PowerShell version
    ","How can I determine what version of PowerShell is installed on a computer, and indeed if it is installed at all?","Use $PSVersionTable.PSVersion to determine the engine version. If the variable does not exist, it is safe to assume the engine is version 1.0.Note that $Host.Version and (Get-Host).Version are not reliable - they reflectthe version of the host only, not the engine. PowerGUI,PowerShellPLUS, etc. are all hosting applications, andthey will set the host's version to reflect their productversion — which is entirely correct, but not what you're looking for.PS C:\> $PSVersionTable.PSVersionMajor  Minor  Build  Revision-----  -----  -----  --------4      0      -1     -1"
"data_i","edited Jul 17 '22 at 06:20","
        ssh ""permissions are too open""
    ","I get the following error from ssh:Permissions 0777 for '/Users/username/.ssh/id_rsa' are too open.It is recommended that your private key files are NOT accessible by others.This private key will be ignored.What permissions should I give to the id_rsa file?","The keys need to be read-writable only by you:chmod 600 ~/.ssh/id_rsaAlternatively, the keys can be only readable by you (this also blocks your write access):chmod 400 ~/.ssh/id_rsa600 appears to be better in most cases, because you don't need to change file permissions later to edit it. (See the comments for more nuances)The relevant portion from the manpage (man ssh) ~/.ssh/id_rsa         Contains the private key for authentication.  These files contain sensitive          data and should be readable by the user but not         accessible by others (read/write/execute).  ssh will simply ignore a private          key file if it is                       accessible by others.  It is possible to specify a         passphrase when generating the key which will be used to encrypt the sensitive          part of this file using 3DES. ~/.ssh/identity.pub ~/.ssh/id_dsa.pub ~/.ssh/id_ecdsa.pub ~/.ssh/id_rsa.pub         Contains the public key for authentication.  These files are not sensitive and          can (but need not) be readable by anyone."
"data_i","edited Aug 11 '22 at 19:14","
        Find the version of an installed npm package
    ","How can I find the version of an installed Node.js or npm package?This prints the version of npm itself:npm -v <package-name>This prints a cryptic error:npm version <package-name>This prints the package version on the registry (i.e., the latest version available):npm view <package-name> versionHow do I get the installed version?","Use npm list for local packages or npm list -g for globally installed packages.You can find the version of a specific package by passing its name as an argument. For example, npm list grunt will result in:projectName@projectVersion /path/to/project/folder└── grunt@0.4.1Alternatively, you can just run npm list without passing a package name as an argument to see the versions of all your packages:├─┬ cli-color@0.1.6│ └── es5-ext@0.7.1├── coffee-script@1.3.3├── less@1.3.0├─┬ sentry@0.1.2│ ├── file@0.2.1│ └── underscore@1.3.3└── uglify-js@1.2.6You can also add --depth=0 argument to list installed packages without their dependencies."
"data_i","edited Jun 03 '19 at 17:02","
        Flash CS4 refuses to let go
    ","I have a Flash project, and it has many source files. I have a fairly heavily-used class, call it Jenine. I recently (and, perhaps, callously) relocated Jenine from one namespace to another. I thought we were ready - I thought it was time. The new Jenine was better in every way - she had lost some code bloat, she had decoupled herself from a few vestigial class relationships, and she had finally come home to the namespace that she had always secretly known in her heart was the one she truly belonged to. She was among her own kind.Unfortunately, Flash would have none of that. Perhaps it had formed an attachment. Perhaps it didn't want Jenine to be decoupled. Either way, it clung to the old, perfect version of Jenine in its memory. It refused to move on. It ignored her (function) calls. It tried to forget her new, public interfaces. Instead, every instance of Jenine that it constructed was always a copy of the old version, down to its classpath:var jenineInstance:Jenine = new Jenine();trace( getQualifiedClassName(jenineInstance));// Should print: com.newnamespace.subspace::Jenine// Prints: com.oldnamespace.subspace::Jenine// Ah, young love!We fought. I'm not proud of some of the things I said or did. In the end, in a towering fit of rage, I deleted all references of Jenine completely. She was utterly, completely erased from the system. My cursor fell upon the ""Empty Trash"" menu option like the cold lid of a casket.I don't think Flash ever recovered. To this day it still clings to the memory of Jenine. Her old, imperfect definitions still float through my project like abandoned ghosts. Whenever I force Flash to compile, it still lovingly inserts her into my movie, nestling her definition in amongst the other, living classes, like a small shrine. I wonder if they can see her.Flash and I don't really talk anymore. I write my code, it compiles it. There's a new girl in town named Summer who looks almost identical to Jenine, as if someone had just copied her source-code wholesale into a new class, but Flash hasn't shown any interest. Most days it just mopes around and writes bad poetry in my comments when it thinks I'm not looking.I hope no one else has had a similar experience, that this is just a singular, painful ripple in the horrifying dark lagoon that is the Flash code-base. Does anyone have any idea how to erase whatever cache the compiler is using?","Flash still has the ASO file, which is the compiled byte code for your classes. On Windows, you can see the ASO files here:C:\Documents and Settings\username\Local Settings\Application Data\Adobe\Flash CS4\en\Configuration\Classes\asoOn a Mac, the directory structure is similar in /Users/username/Library/Application Support/ You can remove those files by hand, or in Flash you can select Control->Delete ASO files to remove them."
"data_i","edited May 31 '18 at 01:59","
        How can I create an executable JAR with dependencies using Maven?
    ","I want to package my project in a single executable JAR for distribution.How can I make a Maven project package all dependency JARs into my output JAR?","<build>  <plugins>    <plugin>      <artifactId>maven-assembly-plugin</artifactId>      <configuration>        <archive>          <manifest>            <mainClass>fully.qualified.MainClass</mainClass>          </manifest>        </archive>        <descriptorRefs>          <descriptorRef>jar-with-dependencies</descriptorRef>        </descriptorRefs>      </configuration>    </plugin>  </plugins></build>and you run it withmvn clean compile assembly:singleCompile goal should be added before assembly:single or otherwise the code on your own project is not included.See more details in comments.Commonly this goal is tied to a build phase to execute automatically. This ensures the JAR is built when executing mvn install or performing a deployment/release.<build>  <plugins>    <plugin>      <artifactId>maven-assembly-plugin</artifactId>      <configuration>        <archive>          <manifest>            <mainClass>fully.qualified.MainClass</mainClass>          </manifest>        </archive>        <descriptorRefs>          <descriptorRef>jar-with-dependencies</descriptorRef>        </descriptorRefs>      </configuration>      <executions>        <execution>          <id>make-assembly</id> <!-- this is used for inheritance merges -->          <phase>package</phase> <!-- bind to the packaging phase -->          <goals>            <goal>single</goal>          </goals>        </execution>      </executions>    </plugin>  </plugins></build>"
"data_i","edited Oct 01 '16 at 08:08","
        How can I prevent SQL injection in PHP?
    ","If user input is inserted without modification into an SQL query, then the application becomes vulnerable to SQL injection, like in the following example:$unsafe_variable = $_POST['user_input']; mysql_query(""INSERT INTO `table` (`column`) VALUES ('$unsafe_variable')"");That's because the user can input something like value'); DROP TABLE table;--, and the query becomes:INSERT INTO `table` (`column`) VALUES('value'); DROP TABLE table;--')What can be done to prevent this from happening?","The correct way to avoid SQL injection attacks, no matter which database you use, is to separate the data from SQL, so that data stays data and will never be interpreted as commands by the SQL parser. It is possible to create an SQL statement with correctly formatted data parts, but if you don't fully understand the details, you should always use prepared statements and parameterized queries. These are SQL statements that are sent to and parsed by the database server separately from any parameters. This way it is impossible for an attacker to inject malicious SQL.You basically have two options to achieve this:Using PDO (for any supported database driver):$stmt = $pdo->prepare('SELECT * FROM employees WHERE name = :name');$stmt->execute([ 'name' => $name ]);foreach ($stmt as $row) {    // Do something with $row}Using MySQLi (for MySQL):$stmt = $dbConnection->prepare('SELECT * FROM employees WHERE name = ?');$stmt->bind_param('s', $name); // 's' specifies the variable type => 'string'$stmt->execute();$result = $stmt->get_result();while ($row = $result->fetch_assoc()) {    // Do something with $row}If you're connecting to a database other than MySQL, there is a driver-specific second option that you can refer to (for example, pg_prepare() and pg_execute() for PostgreSQL). PDO is the universal option.Correctly setting up the connectionPDONote that when using PDO to access a MySQL database real prepared statements are not used by default. To fix this you have to disable the emulation of prepared statements. An example of creating a connection using PDO is:$dbConnection = new PDO('mysql:dbname=dbtest;host=127.0.0.1;charset=utf8mb4', 'user', 'password');$dbConnection->setAttribute(PDO::ATTR_EMULATE_PREPARES, false);$dbConnection->setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);In the above example, the error mode isn't strictly necessary, but it is advised to add it. This way PDO will inform you of all MySQL errors by means of throwing the PDOException.What is mandatory, however, is the first setAttribute() line, which tells PDO to disable emulated prepared statements and use real prepared statements. This makes sure the statement and the values aren't parsed by PHP before sending it to the MySQL server (giving a possible attacker no chance to inject malicious SQL).Although you can set the charset in the options of the constructor, it's important to note that 'older' versions of PHP (before 5.3.6) silently ignored the charset parameter in the DSN.MysqliFor mysqli we have to follow the same routine:mysqli_report(MYSQLI_REPORT_ERROR | MYSQLI_REPORT_STRICT); // error reporting$dbConnection = new mysqli('127.0.0.1', 'username', 'password', 'test');$dbConnection->set_charset('utf8mb4'); // charsetExplanationThe SQL statement you pass to prepare is parsed and compiled by the database server. By specifying parameters (either a ? or a named parameter like :name in the example above) you tell the database engine where you want to filter on. Then when you call execute, the prepared statement is combined with the parameter values you specify.The important thing here is that the parameter values are combined with the compiled statement, not an SQL string. SQL injection works by tricking the script into including malicious strings when it creates SQL to send to the database. So by sending the actual SQL separately from the parameters, you limit the risk of ending up with something you didn't intend.Any parameters you send when using a prepared statement will just be treated as strings (although the database engine may do some optimization so parameters may end up as numbers too, of course). In the example above, if the $name variable contains 'Sarah'; DELETE FROM employees the result would simply be a search for the string ""'Sarah'; DELETE FROM employees"", and you will not end up with an empty table.Another benefit of using prepared statements is that if you execute the same statement many times in the same session it will only be parsed and compiled once, giving you some speed gains.Oh, and since you asked about how to do it for an insert, here's an example (using PDO):$preparedStatement = $db->prepare('INSERT INTO table (column) VALUES (:column)');$preparedStatement->execute([ 'column' => $unsafeValue ]);Can prepared statements be used for dynamic queries?While you can still use prepared statements for the query parameters, the structure of the dynamic query itself cannot be parametrized and certain query features cannot be parametrized.For these specific scenarios, the best thing to do is use a whitelist filter that restricts the possible values.// Value whitelist// $dir can only be 'DESC', otherwise it will be 'ASC'if (empty($dir) || $dir !== 'DESC') {   $dir = 'ASC';}"
"data_i","edited Jun 12 '20 at 08:46","
        Encode URL in JavaScript?
    ","How do you safely encode a URL using JavaScript such that it can be put into a GET string?var myUrl = ""http://example.com/index.html?param=1&anotherParam=2"";var myOtherUrl = ""http://example.com/index.html?url="" + myUrl;I assume that you need to encode the myUrl variable on that second line?","Check out the built-in function encodeURIComponent(str) and encodeURI(str).In your case, this should work:var myOtherUrl =        ""http://example.com/index.html?url="" + encodeURIComponent(myUrl);"
"data_i","edited Apr 28 '22 at 21:38","
        From inside of a Docker container, how do I connect to the localhost of the machine?
    ","So I have a Nginx running inside a docker container, I have a mysql running on the host system, I want to connect to the MySql from within my container. MySql is only binding to the localhost device.Is there any way to connect to this MySql or any other program on localhost from within this docker container?This question is different from ""How to get the IP address of the docker host from inside a docker container"" due to the fact that the IP address of the docker host could be the public IP or the private IP in the network which may or may not be reachable from within the docker container (I mean public IP if hosted at AWS or something). Even if you have the IP address of the docker host it does not mean you can connect to docker host from within the container given that IP address as your Docker network may be overlay, host, bridge, macvlan, none etc which restricts the reachability of that IP address.","Edit:If you are using Docker-for-mac or Docker-for-Windows 18.03+, just connect to your mysql service using the host host.docker.internal (instead of the 127.0.0.1 in your connection string).If you are using Docker-for-Linux 20.10.0+, you can also use the host host.docker.internal if you started your Docker container with the --add-host host.docker.internal:host-gateway option.Otherwise, read belowTLDRUse --network=""host"" in your docker run command, then 127.0.0.1 in your docker container will point to your docker host.Note: This mode only works on Docker for Linux, per the documentation.Note on docker container networking modesDocker offers different networking modes when running containers. Depending on the mode you choose you would connect to your MySQL database running on the docker host differently.docker run --network=""bridge"" (default)Docker creates a bridge named docker0 by default. Both the docker host and the docker containers have an IP address on that bridge.on the Docker host, type sudo ip addr show docker0 you will have an output looking like:[vagrant@docker:~] $ sudo ip addr show docker04: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default    link/ether 56:84:7a:fe:97:99 brd ff:ff:ff:ff:ff:ff    inet 172.17.42.1/16 scope global docker0       valid_lft forever preferred_lft forever    inet6 fe80::5484:7aff:fefe:9799/64 scope link       valid_lft forever preferred_lft foreverSo here my docker host has the IP address 172.17.42.1 on the docker0 network interface.Now start a new container and get a shell on it: docker run --rm -it ubuntu:trusty bash and within the container type ip addr show eth0 to discover how its main network interface is set up:root@e77f6a1b3740:/# ip addr show eth0863: eth0: <BROADCAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 66:32:13:f0:f1:e3 brd ff:ff:ff:ff:ff:ff    inet 172.17.1.192/16 scope global eth0       valid_lft forever preferred_lft forever    inet6 fe80::6432:13ff:fef0:f1e3/64 scope link       valid_lft forever preferred_lft foreverHere my container has the IP address 172.17.1.192. Now look at the routing table:root@e77f6a1b3740:/# routeKernel IP routing tableDestination     Gateway         Genmask         Flags Metric Ref    Use Ifacedefault         172.17.42.1     0.0.0.0         UG    0      0        0 eth0172.17.0.0      *               255.255.0.0     U     0      0        0 eth0So the IP Address of the docker host 172.17.42.1 is set as the default route and is accessible from your container.root@e77f6a1b3740:/# ping 172.17.42.1PING 172.17.42.1 (172.17.42.1) 56(84) bytes of data.64 bytes from 172.17.42.1: icmp_seq=1 ttl=64 time=0.070 ms64 bytes from 172.17.42.1: icmp_seq=2 ttl=64 time=0.201 ms64 bytes from 172.17.42.1: icmp_seq=3 ttl=64 time=0.116 msdocker run --network=""host""Alternatively you can run a docker container with network settings set to host. Such a container will share the network stack with the docker host and from the container point of view, localhost (or 127.0.0.1) will refer to the docker host.Be aware that any port opened in your docker container would be opened on the docker host. And this without requiring the -p or -P docker run option.IP config on my docker host:[vagrant@docker:~] $ ip addr show eth02: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 08:00:27:98:dc:aa brd ff:ff:ff:ff:ff:ff    inet 10.0.2.15/24 brd 10.0.2.255 scope global eth0       valid_lft forever preferred_lft forever    inet6 fe80::a00:27ff:fe98:dcaa/64 scope link       valid_lft forever preferred_lft foreverand from a docker container in host mode:[vagrant@docker:~] $ docker run --rm -it --network=host ubuntu:trusty ip addr show eth02: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 08:00:27:98:dc:aa brd ff:ff:ff:ff:ff:ff    inet 10.0.2.15/24 brd 10.0.2.255 scope global eth0       valid_lft forever preferred_lft forever    inet6 fe80::a00:27ff:fe98:dcaa/64 scope link       valid_lft forever preferred_lft foreverAs you can see both the docker host and docker container share the exact same network interface and as such have the same IP address.Connecting to MySQL from containersbridge modeTo access MySQL running on the docker host from containers in bridge mode, you need to make sure the MySQL service is listening for connections on the 172.17.42.1 IP address.To do so, make sure you have either bind-address = 172.17.42.1 or bind-address = 0.0.0.0 in your MySQL config file (my.cnf).If you need to set an environment variable with the IP address of the gateway, you can run the following code in a container :export DOCKER_HOST_IP=$(route -n | awk '/UG[ \t]/{print $2}')then in your application, use the DOCKER_HOST_IP environment variable to open the connection to MySQL.Note: if you use bind-address = 0.0.0.0 your MySQL server will listen for connections on all network interfaces. That means your MySQL server could be reached from the Internet ; make sure to setup firewall rules accordingly.Note 2: if you use bind-address = 172.17.42.1 your MySQL server won't listen for connections made to 127.0.0.1. Processes running on the docker host that would want to connect to MySQL would have to use the 172.17.42.1 IP address.host modeTo access MySQL running on the docker host from containers in host mode, you can keep bind-address = 127.0.0.1 in your MySQL configuration and all you need to do is to connect to 127.0.0.1 from your containers:[vagrant@docker:~] $ docker run --rm -it --network=host mysql mysql -h 127.0.0.1 -uroot -pEnter password:Welcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 36Server version: 5.5.41-0ubuntu0.14.04.1 (Ubuntu)Copyright (c) 2000, 2014, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.mysql>note: Do use mysql -h 127.0.0.1 and not mysql -h localhost; otherwise the MySQL client would try to connect using a unix socket."
"data_i","edited Jul 17 '22 at 00:30","
        How to change the commit author for a single commit?
    ","I want to change the author of one specific commit in the history. It's not the latest commit.Related: How do I change the author and committer name/email for multiple commits?","Interactive rebase off of a point earlier in the history than the commit you need to modify (git rebase -i <earliercommit>). In the list of commits being rebased, change the text from pick to edit next to the hash of the one you want to modify. Then when git prompts you to change the commit, use this:git commit --amend --author=""Author Name <email@address.com>"" --no-editFor example, if your commit history is A-B-C-D-E-F with F as HEAD, and you want to change the author of C and D, then you would...Specify git rebase -i B (here is an example of what you will see after executing the git rebase -i B command)if you need to edit A, use git rebase -i --rootChange the lines for both C and D from pick to editExit the editor (for vim, this would be pressing Esc and then typing :wq).Once the rebase started, it would first pause at CYou would git commit --amend --author=""Author Name <email@address.com>""Then git rebase --continueIt would pause again at DThen you would git commit --amend --author=""Author Name <email@address.com>"" againgit rebase --continueThe rebase would complete.Use git push -f to update your origin with the updated commits."
"data_i","edited May 25 '18 at 23:17","
        Ignore files that have already been committed to a Git repository
    ","I have an already initialized Git repository that I added a .gitignore file to. How can I refresh the file index so the files I want ignored get ignored?","To untrack a single file that has already been added/initialized to your repository, i.e., stop tracking the file but not delete it from your system use: git rm --cached filenameTo untrack every file that is now in your .gitignore:First commit any outstanding code changes, and then, run this command:git rm -r --cached .This removes any changed files from the index(staging area), then just run:git add .Commit it:git commit -m "".gitignore is now working""To undo git rm --cached filename, use git add filename.Make sure to commit all your important changes before running git add .Otherwise, you will lose any changes to other files.Please be careful, when you push this to a repository and pull from somewhere else into a state where those files are still tracked, the files will be DELETED"
"data_i","edited Dec 31 '20 at 01:19","
        How do I get a YouTube video thumbnail from the YouTube API?
    ","If I have a YouTube video URL, is there any way to use PHP and cURL to get the associated thumbnail from the YouTube API?","Each YouTube video has four generated images. They are predictably formatted as follows:https://img.youtube.com/vi/<insert-youtube-video-id-here>/0.jpghttps://img.youtube.com/vi/<insert-youtube-video-id-here>/1.jpghttps://img.youtube.com/vi/<insert-youtube-video-id-here>/2.jpghttps://img.youtube.com/vi/<insert-youtube-video-id-here>/3.jpgThe first one in the list is a full size image and others are thumbnail images. The default thumbnail image (i.e., one of 1.jpg, 2.jpg, 3.jpg) is:https://img.youtube.com/vi/<insert-youtube-video-id-here>/default.jpgFor the high quality version of the thumbnail use a URL similar to this:https://img.youtube.com/vi/<insert-youtube-video-id-here>/hqdefault.jpgThere is also a medium quality version of the thumbnail, using a URL similar to the HQ:https://img.youtube.com/vi/<insert-youtube-video-id-here>/mqdefault.jpgFor the standard definition version of the thumbnail, use a URL similar to this:https://img.youtube.com/vi/<insert-youtube-video-id-here>/sddefault.jpgFor the maximum resolution version of the thumbnail use a URL similar to this:https://img.youtube.com/vi/<insert-youtube-video-id-here>/maxresdefault.jpgAll of the above URLs are available over HTTP too. Additionally, the slightly shorter hostname i3.ytimg.com works in place of img.youtube.com in the example URLs above.Alternatively, you can use the YouTube Data API (v3) to get thumbnail images."
"data_i","edited Aug 08 '22 at 10:04","
        How do I install pip on Windows?
    ","pip is a replacement for easy_install. But should I install pip using easy_install on Windows? Is there a better way?","Python 2.7.9+ and 3.4+Good news! Python 3.4 (released March 2014) and Python 2.7.9 (released December 2014) ship with Pip. This is the best feature of any Python release. It makes the community's wealth of libraries accessible to everyone. Newbies are no longer excluded from using community libraries by the prohibitive difficulty of setup. In shipping with a package manager, Python joins Ruby, Node.js, Haskell, Perl, Go—almost every other contemporary language with a majority open-source community. Thank you, Python.If you do find that pip is not available when using Python 3.4+ or Python 2.7.9+, simply execute e.g.:py -3 -m ensurepipOf course, that doesn't mean Python packaging is problem solved. The experience remains frustrating. I discuss this in the Stack Overflow question Does Python have a package/module management system?.And, alas for everyone using Python 2.7.8 or earlier (a sizable portion of the community). There's no plan to ship Pip to you. Manual instructions follow.Python 2 ≤ 2.7.8 and Python 3 ≤ 3.3Flying in the face of its 'batteries included' motto, Python ships without a package manager. To make matters worse, Pip was—until recently—ironically difficult to install.Official instructionsPer https://pip.pypa.io/en/stable/installing/#do-i-need-to-install-pip:Download get-pip.py, being careful to save it as a .py file rather than .txt. Then, run it from the command prompt:python get-pip.pyYou possibly need an administrator command prompt to do this. Follow Start a Command Prompt as an Administrator (Microsoft TechNet).This installs the pip package, which (in Windows) contains ...\Scripts\pip.exe that path must be in PATH environment variable to use pip from the command line (see the second part of 'Alternative Instructions' for adding it to your PATH,Alternative instructionsThe official documentation tells users to install Pip and each of its dependencies from source. That's tedious for the experienced and prohibitively difficult for newbies.For our sake, Christoph Gohlke prepares Windows installers (.msi) for popular Python packages. He builds installers for all Python versions, both 32 and 64 bit. You need to:Install setuptoolsInstall pipFor me, this installed Pip at C:\Python27\Scripts\pip.exe. Find pip.exe on your computer, then add its folder (for example, C:\Python27\Scripts) to your path (Start / Edit environment variables). Now you should be able to run pip from the command line. Try installing a package:pip install httpieThere you go (hopefully)! Solutions for common problems are given below:Proxy problemsIf you work in an office, you might be behind an HTTP proxy. If so, set the environment variables http_proxy and https_proxy. Most Python applications (and other free software) respect these. Example syntax:http://proxy_url:porthttp://username:password@proxy_url:portIf you're really unlucky, your proxy might be a Microsoft NTLM proxy. Free software can't cope. The only solution is to install a free software friendly proxy that forwards to the nasty proxy. http://cntlm.sourceforge.net/Unable to find vcvarsall.batPython modules can be partly written in C or C++. Pip tries to compile from source. If you don't have a C/C++ compiler installed and configured, you'll see this cryptic error message.Error: Unable to find vcvarsall.batYou can fix that by installing a C++ compiler such as MinGW or Visual C++. Microsoft actually ships one specifically for use with Python. Or try Microsoft Visual C++ Compiler for Python 2.7.Often though it's easier to check Christoph's site for your package."
"data_i","edited Jan 24 '18 at 15:53","
        Is there an equivalent of 'which' on the Windows command line?
    ","As I sometimes have path problems, where one of my own cmd scripts is hidden (shadowed) by another program (earlier on the path), I would like to be able to find the full path to a program on the Windows command line, given just its name.Is there an equivalent to the UNIX command 'which'?On UNIX, which command prints the full path of the given command to easily find and repair these shadowing problems.","Windows Server 2003 and later (i.e. anything after Windows XP 32 bit) provide the where.exe program which does some of what which does, though it matches all types of files, not just executable commands.  (It does not match built-in shell commands like cd.)  It will even accept wildcards, so where nt* finds all files in your %PATH% and current directory whose names start with nt.Try where /? for help.Note that Windows PowerShell defines where as an alias for the Where-Object cmdlet, so if you want where.exe, you need to type the full name instead of omitting the .exe extension. Alternatively, you can set an alias for it:Set-Alias which where.exeUpdate: Using Get-Command (alias: gcm) is recommended since it's native to PS and will get all command types: aliases, cmdlets, executables, and functions. Example:gcm notepad*"
"data_i","asked Mar 03 '09 at 10:13","
        Do I cast the result of malloc?
    ","In this question, someone suggested in a comment that I should not cast the result of malloc. i.e., I should do this:int *sieve = malloc(sizeof(*sieve) * length);rather than:int *sieve = (int *) malloc(sizeof(*sieve) * length);Why would this be the case?","TL;DRint *sieve = (int *) malloc(sizeof(int) * length);has two problems. The cast and that you're using the type instead of variable as argument for sizeof. Instead, do like this:int *sieve = malloc(sizeof *sieve * length);Long versionNo; you don't cast the result, since:It is unnecessary, as void * is automatically and safely promoted to any other pointer type in this case.It adds clutter to the code, casts are not very easy to read (especially if the pointer type is long).It makes you repeat yourself, which is generally bad.It can hide an error if you forgot to include <stdlib.h>. This can cause crashes (or, worse, not cause a crash until way later in some totally different part of the code). Consider what happens if pointers and integers are differently sized; then you're hiding a warning by casting and might lose bits of your returned address. Note: as of C99 implicit functions are gone from C, and this point is no longer relevant since there's no automatic assumption that undeclared functions return int.As a clarification, note that I said ""you don't cast"", not ""you don't need to cast"". In my opinion, it's a failure to include the cast, even if you got it right. There are simply no benefits to doing it, but a bunch of potential risks, and including the cast indicates that you don't know about the risks.Also note, as commentators point out, that the above talks about straight C, not C++. I very firmly believe in C and C++ as separate languages.To add further, your code needlessly repeats the type information (int) which can cause errors. It's better to de-reference the pointer being used to store the return value, to ""lock"" the two together:int *sieve = malloc(length * sizeof *sieve);This also moves the length to the front for increased visibility, and drops the redundant parentheses with sizeof; they are only needed when the argument is a type name. Many people seem to not know (or ignore) this, which makes their code more verbose. Remember: sizeof is not a function! :)While moving length to the front may increase visibility in some rare cases, one should also pay attention that in the general case, it should be better to write the expression as:int *sieve = malloc(sizeof *sieve * length);Since keeping the sizeof first, in this case, ensures multiplication is done with at least size_t math.Compare: malloc(sizeof *sieve * length * width) vs. malloc(length * width * sizeof *sieve) the second may overflow the length * width when width and length are smaller types than size_t."
"data_i","edited Jun 11 '14 at 04:55","
        How do I make Git ignore file mode (chmod) changes?
    ","I have a project in which I have to change the mode of files with chmod to 777 while developing, but which should not change in the main repo. Git picks up on chmod -R 777 . and marks all files as changed. Is there a way to make Git ignore mode changes that have been made to files?","Try:git config core.fileMode falseFrom git-config(1):core.fileMode    Tells Git if the executable bit of files in the working tree    is to be honored.    Some filesystems lose the executable bit when a file that is    marked as executable is checked out, or checks out a    non-executable file with executable bit on. git-clone(1)    or git-init(1) probe the filesystem to see if it handles the     executable bit correctly and this variable is automatically    set as necessary.    A repository, however, may be on a filesystem that handles    the filemode correctly, and this variable is set to true when    created, but later may be made accessible from another    environment that loses the filemode (e.g. exporting ext4    via CIFS mount, visiting a Cygwin created repository with Git    for Windows or Eclipse). In such a case it may be necessary    to set this variable to false. See git-update-index(1).    The default is true (when core.filemode is not specified    in the config file).The -c flag can be used to set this option for one-off commands:git -c core.fileMode=false diffTyping the -c core.fileMode=false can be bothersome and so you can set this flag for all git repos or just for one git repo:# this will set your the flag for your user for all git repos (modifies `$HOME/.gitconfig`)git config --global core.fileMode false# this will set the flag for one git repo (modifies `$current_git_repo/.git/config`)git config core.fileMode falseAdditionally, git clone and git init explicitly set core.fileMode to true in the repo config as discussed in Git global core.fileMode false overridden locally on cloneWarningcore.fileMode is not the best practice and should be used carefully. This setting only covers the executable bit of mode and never the read/write bits. In many cases you think you need this setting because you did something like chmod -R 777, making all your files executable. But in most projects most files don't need and should not be executable for security reasons.The proper way to solve this kind of situation is to handle folder and file permission separately, with something like:find . -type d -exec chmod a+rwx {} \; # Make folders traversable and read/writefind . -type f -exec chmod a+rw {} \;  # Make files read/writeIf you do that, you'll never need to use core.fileMode, except in very rare environment."
"data_i","edited Apr 07 '15 at 00:55","
        How can I get query string values in JavaScript?
    ","Is there a plugin-less way of retrieving query string values via jQuery (or without)? If so, how? If not, is there a plugin which can do so?","Update: Jan-2022Using Proxy() is faster than using Object.fromEntries() and better supportedconst params = new Proxy(new URLSearchParams(window.location.search), {  get: (searchParams, prop) => searchParams.get(prop),});// Get the value of ""some_key"" in eg ""https://example.com/?some_key=some_value""let value = params.some_key; // ""some_value""Update: June-2021For a specific case when you need all query params:const urlSearchParams = new URLSearchParams(window.location.search);const params = Object.fromEntries(urlSearchParams.entries());Update: Sep-2018You can use URLSearchParams which is simple and has decent (but not complete) browser support.const urlParams = new URLSearchParams(window.location.search);const myParam = urlParams.get('myParam');OriginalYou don't need jQuery for that purpose. You can use just some pure JavaScript:function getParameterByName(name, url = window.location.href) {    name = name.replace(/[\[\]]/g, '\\$&');    var regex = new RegExp('[?&]' + name + '(=([^&#]*)|&|#|$)'),        results = regex.exec(url);    if (!results) return null;    if (!results[2]) return '';    return decodeURIComponent(results[2].replace(/\+/g, ' '));}Usage:// query string: ?foo=lorem&bar=&bazvar foo = getParameterByName('foo'); // ""lorem""var bar = getParameterByName('bar'); // """" (present with empty value)var baz = getParameterByName('baz'); // """" (present with no value)var qux = getParameterByName('qux'); // null (absent)NOTE: If a parameter is present several times (?foo=lorem&foo=ipsum), you will get the first value (lorem). There is no standard about this and usages vary, see for example this question: Authoritative position of duplicate HTTP GET query keys.NOTE: The function is case-sensitive. If you prefer case-insensitive parameter name, add 'i' modifier to RegExpNOTE: If you're getting a no-useless-escape eslint error, you can replace name = name.replace(/[\[\]]/g, '\\$&'); with name = name.replace(/[[\]]/g, '\\$&').This is an update based on the new URLSearchParams specs to achieve the same result more succinctly. See answer titled ""URLSearchParams"" below."
"data_i","edited Oct 25 '21 at 13:08","
        How can I transition height: 0; to height: auto; using CSS?
    ","I am trying to make a <ul> slide down using CSS transitions.The <ul> starts off at height: 0;. On hover, the height is set to height:auto;. However, this is causing it to simply appear, not transition,If I do it from height: 40px; to height: auto;, then it will slide up to height: 0;, and then suddenly jump to the correct height.How else could I do this without using JavaScript?#child0 {  height: 0;  overflow: hidden;  background-color: #dedede;  -moz-transition: height 1s ease;  -webkit-transition: height 1s ease;  -o-transition: height 1s ease;  transition: height 1s ease;}#parent0:hover #child0 {  height: auto;}#child40 {  height: 40px;  overflow: hidden;  background-color: #dedede;  -moz-transition: height 1s ease;  -webkit-transition: height 1s ease;  -o-transition: height 1s ease;  transition: height 1s ease;}#parent40:hover #child40 {  height: auto;}h1 {  font-weight: bold;}The only difference between the two snippets of CSS is one has height: 0, the other height: 40.<hr><div id=""parent0"">  <h1>Hover me (height: 0)</h1>  <div id=""child0"">Some content    <br>Some content    <br>Some content    <br>Some content    <br>Some content    <br>Some content    <br>  </div></div><hr><div id=""parent40"">  <h1>Hover me (height: 40)</h1>  <div id=""child40"">Some content    <br>Some content    <br>Some content    <br>Some content    <br>Some content    <br>Some content    <br>  </div></div>","Use max-height in the transition and not height. And set a value on max-height to something bigger than your box will ever get.See JSFiddle demo provided by Chris Jordan in another answer here.#menu #list {    max-height: 0;    transition: max-height 0.15s ease-out;    overflow: hidden;    background: #d5d5d5;}#menu:hover #list {    max-height: 500px;    transition: max-height 0.25s ease-in;}<div id=""menu"">    <a>hover me</a>    <ul id=""list"">        <!-- Create a bunch, or not a bunch, of li's to see the timing. -->        <li>item</li>        <li>item</li>        <li>item</li>        <li>item</li>        <li>item</li>    </ul></div>"
"data_i","edited Jul 17 '22 at 06:23","
        How do I refresh a page using JavaScript?
    ","How do I refresh a page using JavaScript?","Use location.reload().For example, to reload whenever an element with id=""something"" is clicked:$('#something').click(function() {    location.reload();});The reload() function takes an optional parameter that can be set to true to force a reload from the server rather than the cache. The parameter defaults to false, so by default the page may reload from the browser's cache."
"data_i","edited May 02 '13 at 06:45","
        Check if a given key already exists in a dictionary
    ","I wanted to test if a key exists in a dictionary before updating the value for the key.I wrote the following code:if 'key1' in dict.keys():  print ""blah""else:  print ""boo""I think this is not the best way to accomplish this task. Is there a better way to test for a key in the dictionary?","in tests for the existence of a key in a dict:d = {""key1"": 10, ""key2"": 23}if ""key1"" in d:    print(""this will execute"")if ""nonexistent key"" in d:    print(""this will not"")Use dict.get() to provide a default value when the key does not exist:d = {}for i in range(10):    d[i] = d.get(i, 0) + 1To provide a default value for every key, either use dict.setdefault() on each assignment:d = {}for i in range(10):    d[i] = d.setdefault(i, 0) + 1or use defaultdict from the collections module:from collections import defaultdictd = defaultdict(int)for i in range(10):    d[i] += 1"
"data_i","edited Feb 29 '20 at 23:30","
        Why shouldn't I use mysql_* functions in PHP?
    ","What are the technical reasons for why one shouldn't use mysql_* functions? (e.g. mysql_query(), mysql_connect() or mysql_real_escape_string())?Why should I use something else even if they work on my site?If they don't work on my site, why do I get errors like Warning: mysql_connect(): No such file or directory","The MySQL extension:Is not under active developmentIs officially deprecated as of PHP 5.5 (released June 2013).Has been removed entirely as of PHP 7.0 (released December 2015)This means that as of 31 Dec 2018 it does not exist in any supported version of PHP. If you are using a version of PHP which supports it, you are using a version which doesn't get security problems fixed.Lacks an OO interfaceDoesn't support:Non-blocking, asynchronous queriesPrepared statements or parameterized queriesStored proceduresMultiple StatementsTransactionsThe ""new"" password authentication method (on by default in MySQL 5.6; required in 5.7)Any of the new functionality in MySQL 5.1 or laterSince it is deprecated, using it makes your code less future proof. Lack of support for prepared statements is particularly important as they provide a clearer, less error-prone method of escaping and quoting external data than manually escaping it with a separate function call.See the comparison of SQL extensions."
"data_i","edited Nov 29 '21 at 07:19","
        Open a URL in a new tab (and not a new window)
    ","I'm trying to open a URL in a new tab, as opposed to a popup window.I've seen related questions where the responses would look something like:window.open(url,'_blank');window.open(url);But none of them worked for me, the browser still tried to open a popup window.","This is a trick,function openInNewTab(url) {  window.open(url, '_blank').focus();}// Or justwindow.open(url, '_blank').focus();In most cases, this should happen directly in the onclick handler for the link to prevent pop-up blockers, and the default ""new window"" behavior. You could do it this way, or by adding an event listener to your DOM object.<div onclick=""openInNewTab('www.test.com');"">Something To Click On</div>Reference: Open a URL in a new tab using JavaScript"
"data_i","edited Aug 06 '20 at 09:36","
        What's the difference between dependencies, devDependencies and peerDependencies in npm package.json file?
    ","This documentation answers my question very poorly. I didn't understand those explanations. Can someone say in simpler words? Maybe with examples if it's hard to choose simple words?EDIT also added peerDependencies, which is closely related and might cause confusion.","Summary of important behavior differences:dependencies are installed on both:npm install from a directory that contains package.jsonnpm install $package on any other directorydevDependencies are:also installed on npm install on a directory that contains package.json, unless you pass the --production flag (go upvote Gayan Charith's answer), or if the NODE_ENV=production environment variable is setnot installed on npm install ""$package"" on any other directory, unless you give it the --dev option.are not installed transitively.peerDependencies:before 3.0: are always installed if missing, and raise an error if multiple incompatible versions of the dependency would be used by different dependencies.expected to start on 3.0 (untested): give a warning if missing on npm install, and you have to solve the dependency yourself manually. When running, if the dependency is missing, you get an error (mentioned by @nextgentech) This explains it nicely: https://flaviocopes.com/npm-peer-dependencies/in version 7 peerDependencies are automatically installed unless an upstream dependency conflict is present that cannot be automatically resolvedTransitivity (mentioned by Ben Hutchison):dependencies are installed transitively: if A requires B, and B requires C, then C gets installed, otherwise, B could not work, and neither would A.devDependencies is not installed transitively. E.g. we don't need to test B to test A, so B's testing dependencies can be left out.Related options not discussed here:bundledDependencies which is discussed on the following question: Advantages of bundledDependencies over normal dependencies in npmoptionalDependencies (mentioned by Aidan Feldman)devDependenciesdependencies are required to run, devDependencies only to develop, e.g.: unit tests, CoffeeScript to JavaScript transpilation, minification, ...If you are going to develop a package, you download it (e.g. via git clone), go to its root which contains package.json, and run:npm installSince you have the actual source, it is clear that you want to develop it, so by default, both dependencies (since you must, of course, run to develop) and devDependency dependencies are also installed.If however, you are only an end user who just wants to install a package to use it, you will do from any directory:npm install ""$package""In that case, you normally don't want the development dependencies, so you just get what is needed to use the package: dependencies.If you really want to install development packages in that case, you can set the dev configuration option to true, possibly from the command line as:npm install ""$package"" --devThe option is false by default since this is a much less common case.peerDependencies(Tested before 3.0)Source: https://nodejs.org/en/blog/npm/peer-dependencies/With regular dependencies, you can have multiple versions of the dependency: it's simply installed inside the node_modules of the dependency.E.g. if dependency1 and dependency2 both depend on dependency3 at different versions the project tree will look like:root/node_modules/                 |                 +- dependency1/node_modules/                 |                          |                 |                          +- dependency3 v1.0/                 |                 |                 +- dependency2/node_modules/                                            |                                            +- dependency3 v2.0/Plugins, however, are packages that normally don't require the other package, which is called the host in this context. Instead:plugins are required by the hostplugins offer a standard interface that the host expects to findonly the host will be called directly by the user, so there must be a single version of it.E.g. if dependency1 and dependency2 peer depend on dependency3, the project tree will look like:root/node_modules/                 |                 +- dependency1/                 |                 +- dependency2/                 |                 +- dependency3 v1.0/This happens even though you never mention dependency3 in your package.json file.I think this is an instance of the Inversion of Control design pattern.A prototypical example of peer dependencies is Grunt, the host, and its plugins.For example, on a Grunt plugin like https://github.com/gruntjs/grunt-contrib-uglify, you will see that:grunt is a peer-dependencythe only require('grunt') is under tests/: it's not actually used by the program.Then, when the user will use a plugin, he will implicitly require the plugin from the Gruntfile by adding a grunt.loadNpmTasks('grunt-contrib-uglify') line, but it's grunt that the user will call directly.This would not work then if each plugin required a different Grunt version.ManualI think the documentation answers the question quite well, maybe you are just not familiar enough with node / other package managers. I probably only understand it because I know a bit about Ruby bundler.The key line is:These things will be installed when doing npm link or npm install from the root of a package and can be managed like any other npm configuration parameter. See npm-config(7) for more on the topic.And then under npm-config(7) find dev:Default: falseType: BooleanInstall dev-dependencies along with packages."
"data_i","edited Jul 28 '22 at 09:10","
        Renaming column names in Pandas
    ","I want to change the column labels of a Pandas DataFrame from['$a', '$b', '$c', '$d', '$e']to['a', 'b', 'c', 'd', 'e']","Rename Specific ColumnsUse the df.rename() function and refer the columns to be renamed. Not all the columns have to be renamed:df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})# Or rename the existing DataFrame (rather than creating a copy) df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)Minimal Code Exampledf = pd.DataFrame('x', index=range(3), columns=list('abcde'))df   a  b  c  d  e0  x  x  x  x  x1  x  x  x  x  x2  x  x  x  x  xThe following methods all work and produce the same output:df2 = df.rename({'a': 'X', 'b': 'Y'}, axis=1)  # new methoddf2 = df.rename({'a': 'X', 'b': 'Y'}, axis='columns')df2 = df.rename(columns={'a': 'X', 'b': 'Y'})  # old method  df2   X  Y  c  d  e0  x  x  x  x  x1  x  x  x  x  x2  x  x  x  x  xRemember to assign the result back, as the modification is not-inplace. Alternatively, specify inplace=True:df.rename({'a': 'X', 'b': 'Y'}, axis=1, inplace=True)df   X  Y  c  d  e0  x  x  x  x  x1  x  x  x  x  x2  x  x  x  x  x From v0.25, you can also specify errors='raise' to raise errors if an invalid column-to-rename is specified. See v0.25 rename() docs.Reassign Column HeadersUse df.set_axis() with axis=1 and inplace=False (to return a copy).df2 = df.set_axis(['V', 'W', 'X', 'Y', 'Z'], axis=1, inplace=False)df2   V  W  X  Y  Z0  x  x  x  x  x1  x  x  x  x  x2  x  x  x  x  xThis returns a copy, but you can modify the DataFrame in-place by setting inplace=True (this is the default behaviour for versions <=0.24 but is likely to change in the future).You can also assign headers directly:df.columns = ['V', 'W', 'X', 'Y', 'Z']df   V  W  X  Y  Z0  x  x  x  x  x1  x  x  x  x  x2  x  x  x  x  x"
"data_i","edited Aug 11 '16 at 13:32","
        How can I recursively find all files in current and subfolders based on wildcard matching?
    ","How can I recursively find all files in current and subfolders based on wildcard matching?","Use find:find . -name ""foo*""find needs a starting point, so the . (dot) points to the current directory."
"data_i","edited Jul 22 '21 at 10:25","
        How can I fix 'android.os.NetworkOnMainThreadException'?
    ","I got an error while running my Android project for RssReader. Code:URL url = new URL(urlToRssFeed);SAXParserFactory factory = SAXParserFactory.newInstance();SAXParser parser = factory.newSAXParser();XMLReader xmlreader = parser.getXMLReader();RssHandler theRSSHandler = new RssHandler();xmlreader.setContentHandler(theRSSHandler);InputSource is = new InputSource(url.openStream());xmlreader.parse(is);return theRSSHandler.getFeed();And it shows the below error:android.os.NetworkOnMainThreadExceptionHow can I fix this issue?","NOTE : AsyncTask was deprecated in API level 30.AsyncTask | Android DevelopersThis exception is thrown when an application attempts to perform a networking operation on its main thread. Run your code in AsyncTask:class RetrieveFeedTask extends AsyncTask<String, Void, RSSFeed> {    private Exception exception;    protected RSSFeed doInBackground(String... urls) {        try {            URL url = new URL(urls[0]);            SAXParserFactory factory = SAXParserFactory.newInstance();            SAXParser parser = factory.newSAXParser();            XMLReader xmlreader = parser.getXMLReader();            RssHandler theRSSHandler = new RssHandler();            xmlreader.setContentHandler(theRSSHandler);            InputSource is = new InputSource(url.openStream());            xmlreader.parse(is);            return theRSSHandler.getFeed();        } catch (Exception e) {            this.exception = e;            return null;        } finally {            is.close();        }    }    protected void onPostExecute(RSSFeed feed) {        // TODO: check this.exception        // TODO: do something with the feed    }}How to execute the task:In MainActivity.java file you can add this line within your oncreate() methodnew RetrieveFeedTask().execute(urlToRssFeed);Don't forget to add this to AndroidManifest.xml file:<uses-permission android:name=""android.permission.INTERNET""/>"
"data_i","edited May 01 '18 at 10:30","
        How do I check if a string contains a specific word?
    ","Consider:$a = 'How are you?';if ($a contains 'are')    echo 'true';Suppose I have the code above, what is the correct way to write the statement if ($a contains 'are')?","Now with PHP 8 you can do this using str_contains:if (str_contains('How are you', 'are')) {     echo 'true';}RFCBefore PHP 8You can use the strpos() function which is used to find the occurrence of one string inside another one:$haystack = 'How are you?';$needle   = 'are';if (strpos($haystack, $needle) !== false) {    echo 'true';}Note that the use of !== false is deliberate (neither != false nor === true will return the desired result); strpos() returns either the offset at which the needle string begins in the haystack string, or the boolean false if the needle isn't found. Since 0 is a valid offset and 0 is ""falsey"", we can't use simpler constructs like !strpos($a, 'are')."
"data_i","edited Sep 16 '20 at 07:13","
        How do I vertically center text with CSS?
    ","I have a <div> element which contains text and I want to align the contents of this <div> vertically center.Here is my <div> style:#box {  height: 170px;  width: 270px;  background: #000;  font-size: 48px;  color: #FFF;  text-align: center;}<div id=""box"">  Lorem ipsum dolor sit</div>What is the best way to achieve this goal?","You can try this basic approach:div {  height: 100px;  line-height: 100px;  text-align: center;  border: 2px dashed #f69c55;}<div>  Hello World!</div>It only works for a single line of text though, because we set the line's height to the same height as the containing box element.A more versatile approachThis is another way to align text vertically. This solution will work for a single line and multiple lines of text, but it still requires a fixed height container:div {  height: 100px;  line-height: 100px;  text-align: center;  border: 2px dashed #f69c55;}span {  display: inline-block;  vertical-align: middle;  line-height: normal;}<div>  <span>Hello World!</span></div>The CSS just sizes the <div>, vertically center aligns the <span> by setting the <div>'s line-height equal to its height, and makes the <span> an inline-block with vertical-align: middle. Then it sets the line-height back to normal for the <span>, so its contents will flow naturally inside the block.Simulating table displayAnd here is another option, which may not work on older browsers that don't support display: table and display: table-cell (basically just Internet Explorer 7). Using CSS we simulate table behavior (since tables support vertical alignment), and the HTML is the same as the second example:div {  display: table;  height: 100px;  width: 100%;  text-align: center;  border: 2px dashed #f69c55;}span {  display: table-cell;  vertical-align: middle;}<div>  <span>Hello World!</span></div>Using absolute positioningThis technique uses an absolutely positioned element setting top, bottom, left and right to 0. It is described in more detail in an article in Smashing Magazine, Absolute Horizontal And Vertical Centering In CSS.div {  display: flex;  justify-content: center;  align-items: center;  height: 100px;  width: 100%;  border: 2px dashed #f69c55;}<div>  <span>Hello World!</span></div>"
"data_i","edited Sep 11 '22 at 08:31","
        How do I parse a string to a float or int?
    ","How can I convert a str to float?""545.2222""  →  545.2222How can I convert a str to int?""31""        →  31For the reverse, see Convert integer to string in Python and Converting a float to a string without rounding it.Please instead use How can I read inputs as numbers? to close duplicate questions where OP received a string from user input and immediately wants to convert it, or was hoping for input (in 3.x) to convert the type automatically.",">>> a = ""545.2222"">>> float(a)545.22220000000004>>> int(float(a))545"
"data_i","edited Apr 01 '22 at 11:57","
        How can I remove a key from a Python dictionary?
    ","Is there a one-line way of deleting a key from a dictionary without raising a KeyError?if 'key' in my_dict:    del my_dict['key']","To delete a key regardless of whether it is in the dictionary, use the two-argument form of dict.pop():my_dict.pop('key', None)This will return my_dict[key] if key exists in the dictionary, and None otherwise. If the second parameter is not specified (i.e. my_dict.pop('key')) and key does not exist, a KeyError is raised.To delete a key that is guaranteed to exist, you can also use:del my_dict['key']This will raise a KeyError if the key is not in the dictionary."
"data_i","edited Oct 22 '18 at 21:20","
        How do I split a string on a delimiter in Bash?
    ","I have this string stored in a variable:IN=""bla@some.com;john@home.com""Now I would like to split the strings by ; delimiter so that I have:ADDR1=""bla@some.com""ADDR2=""john@home.com""I don't necessarily need the ADDR1 and ADDR2 variables. If they are elements of an array that's even better.After suggestions from the answers below, I ended up with the following which is what I was after:#!/usr/bin/env bashIN=""bla@some.com;john@home.com""mails=$(echo $IN | tr "";"" ""\n"")for addr in $mailsdo    echo ""> [$addr]""doneOutput:> [bla@some.com]> [john@home.com]There was a solution involving setting Internal_field_separator (IFS) to ;. I am not sure what happened with that answer, how do you reset IFS back to default?RE: IFS solution, I tried this and it works, I keep the old IFS and then restore it:IN=""bla@some.com;john@home.com""OIFS=$IFSIFS=';'mails2=$INfor x in $mails2do    echo ""> [$x]""doneIFS=$OIFSBTW, when I tried mails2=($IN)I only got the first string when printing it in loop, without brackets around $IN it works.","You can set the internal field separator (IFS) variable, and then let it parse into an array. When this happens in a command, then the assignment to IFS only takes place to that single command's environment (to read ). It then parses the input according to the IFS variable value into an array, which we can then iterate over.This example will parse one line of items separated by ;, pushing it into an array:IFS=';' read -ra ADDR <<< ""$IN""for i in ""${ADDR[@]}""; do  # process ""$i""doneThis other example is for processing the whole content of $IN, each time one line of input separated by ;:while IFS=';' read -ra ADDR; do  for i in ""${ADDR[@]}""; do    # process ""$i""  donedone <<< ""$IN"""
"data_i","edited Nov 26 '18 at 16:21","
        Can (a== 1 && a ==2 && a==3) ever evaluate to true?
    ","Moderator note: Please resist the urge to edit the code or remove this notice. The pattern of whitespace may be part of the question and therefore should not be tampered with unnecessarily. If you are in the ""whitespace is insignificant"" camp, you should be able to accept the code as is.Is it ever possible that (a== 1 && a ==2 && a==3) could evaluate to true in JavaScript?This is an interview question asked by a major tech company. It happened two weeks back, but I'm still trying to find the answer. I know we never write such code in our day-to-day job, but I'm curious.","If you take advantage of how == works, you could simply create an object with a custom toString (or valueOf) function that changes what it returns each time it is used such that it satisfies all three conditions.const a = {  i: 1,  toString: function () {    return a.i++;  }}if(a == 1 && a == 2 && a == 3) {  console.log('Hello World!');}The reason this works is due to the use of the loose equality operator. When using loose equality, if one of the operands is of a different type than the other, the engine will attempt to convert one to the other. In the case of an object on the left and a number on the right, it will attempt to convert the object to a number by first calling valueOf if it is callable, and failing that, it will call toString. I used toString in this case simply because it's what came to mind, valueOf would make more sense. If I instead returned a string from toString, the engine would have then attempted to convert the string to a number giving us the same end result, though with a slightly longer path."
"data_i","edited Aug 08 '22 at 11:50","
        Homebrew install specific version of formula?
    ","How do I install a specific version of a formula in homebrew?  For example, postgresql-8.4.4 instead of the latest 9.0.","TLDR: brew install postgresql@8.4.4 See answer below for more details.*(I’ve re-edited my answer to give a more thorough workflow for installing/using older software versions with homebrew. Feel free to add a note if you found the old version better.)Let’s start with the simplest case:1) Check, whether the version is already installed (but not activated)When homebrew installs a new formula, it puts it in a versioned directory like /usr/local/Cellar/postgresql/9.3.1. Only symbolic links to this folder are then installed globally. In principle, this makes it pretty easy to switch between two installed versions. (*)If you have been using homebrew for longer and never removed older versions (using, for example brew cleanup), chances are that some older version of your program may still be around. If you want to simply activate that previous version, brew switch is the easiest way to do this.Check with brew info postgresql (or brew switch postgresql <TAB>) whether the older version is installed:$ brew info postgresqlpostgresql: stable 9.3.2 (bottled)http://www.postgresql.org/Conflicts with: postgres-xc/usr/local/Cellar/postgresql/9.1.5 (2755 files, 37M)  Built from source/usr/local/Cellar/postgresql/9.3.2 (2924 files, 39M) *  Poured from bottleFrom: https://github.com/Homebrew/homebrew/commits/master/Library/Formula/postgresql.rb# … and some moreWe see that some older version is already installed. We may activate it using brew switch:$ brew switch postgresql 9.1.5Cleaning /usr/local/Cellar/postgresql/9.1.5Cleaning /usr/local/Cellar/postgresql/9.3.2384 links created for /usr/local/Cellar/postgresql/9.1.5Let’s double-check what is activated:$ brew info postgresqlpostgresql: stable 9.3.2 (bottled)http://www.postgresql.org/Conflicts with: postgres-xc/usr/local/Cellar/postgresql/9.1.5 (2755 files, 37M) *  Built from source/usr/local/Cellar/postgresql/9.3.2 (2924 files, 39M)  Poured from bottleFrom: https://github.com/Homebrew/homebrew/commits/master/Library/Formula/postgresql.rb# … and some moreNote that the star * has moved to the newly activated version(*) Please note that brew switch only works as long as all dependencies of the older version are still around. In some cases, a rebuild of the older version may become necessary. Therefore, using brew switch is mostly useful when one wants to switch between two versions not too far apart.2) Check, whether the version is available as a tapEspecially for larger software projects, it is very probably that there is a high enough demand for several (potentially API incompatible) major versions of a certain piece of software. As of March 2012, Homebrew 0.9 provides a mechanism for this: brew tap & the homebrew versions repository.That versions repository may include backports of older versions for several formulae. (Mostly only the large and famous ones, but of course they’ll also have several formulae for postgresql.)brew search postgresql will show you where to look:$ brew search postgresqlpostgresqlhomebrew/versions/postgresql8    homebrew/versions/postgresql91homebrew/versions/postgresql9    homebrew/versions/postgresql92We can simply install it by typing$ brew install homebrew/versions/postgresql8Cloning into '/usr/local/Library/Taps/homebrew-versions'...remote: Counting objects: 1563, done.remote: Compressing objects: 100% (943/943), done.remote: Total 1563 (delta 864), reused 1272 (delta 620)Receiving objects: 100% (1563/1563), 422.83 KiB | 339.00 KiB/s, done.Resolving deltas: 100% (864/864), done.Checking connectivity... done.Tapped 125 formula==> Downloading http://ftp.postgresql.org/pub/source/v8.4.19/postgresql-8.4.19.tar.bz2# …Note that this has automatically tapped the homebrew/versions tap. (Check with brew tap, remove with brew untap homebrew/versions.) The following would have been equivalent:$ brew tap homebrew/versions$ brew install postgresql8As long as the backported version formulae stay up-to-date, this approach is probably the best way to deal with older software.3) Try some formula from the pastThe following approaches are listed mostly for completeness. Both try to resurrect some undead formula from the brew repository. Due to changed dependencies, API changes in the formula spec or simply a change in the download URL, things may or may not work.Since the whole formula directory is a git repository, one can install specific versions using plain git commands. However, we need to find a way to get to a commit where the old version was available.a) historic timesBetween August 2011 and October 2014, homebrew had a brew versions command, which spat out all available versions with their respective SHA hashes. As of October 2014, you have to do a brew tap homebrew/boneyard before you can use it. As the name of the tap suggests, you should probably only do this as a last resort.E.g.$ brew versions postgresqlWarning: brew-versions is unsupported and may be removed soon.Please use the homebrew-versions tap instead:  https://github.com/Homebrew/homebrew-versions9.3.2    git checkout 3c86d2b Library/Formula/postgresql.rb9.3.1    git checkout a267a3e Library/Formula/postgresql.rb9.3.0    git checkout ae59e09 Library/Formula/postgresql.rb9.2.4    git checkout e3ac215 Library/Formula/postgresql.rb9.2.3    git checkout c80b37c Library/Formula/postgresql.rb9.2.2    git checkout 9076baa Library/Formula/postgresql.rb9.2.1    git checkout 5825f62 Library/Formula/postgresql.rb9.2.0    git checkout 2f6cbc6 Library/Formula/postgresql.rb9.1.5    git checkout 6b8d25f Library/Formula/postgresql.rb9.1.4    git checkout c40c7bf Library/Formula/postgresql.rb9.1.3    git checkout 05c7954 Library/Formula/postgresql.rb9.1.2    git checkout dfcc838 Library/Formula/postgresql.rb9.1.1    git checkout 4ef8fb0 Library/Formula/postgresql.rb9.0.4    git checkout 2accac4 Library/Formula/postgresql.rb9.0.3    git checkout b782d9d Library/Formula/postgresql.rbAs you can see, it advises against using it. Homebrew spits out all versions it can find with its internal heuristic and shows you a way to retrieve the old formulae. Let’s try it.# First, go to the homebrew base directory$ cd $( brew --prefix )# Checkout some old formula$ git checkout 6b8d25f Library/Formula/postgresql.rb$ brew install postgresql# … installingNow that the older postgresql version is installed, we can re-install the latest formula in order to keep our repository clean:$ git checkout -- Library/Formula/postgresql.rbbrew switch is your friend to change between the old and the new.b) prehistoric timesFor special needs, we may also try our own digging through the homebrew repo.$ cd Library/Taps/homebrew/homebrew-core && git log -S'8.4.4' -- Formula/postgresql.rbgit log -S looks for all commits in which the string '8.4.4' was either added or removed in the file Library/Taps/homebrew/homebrew-core/Formula/postgresql.rb. We get two commits as a result.commit 7dc7ccef9e1ab7d2fc351d7935c96a0e0b031552Author: Aku KotkavuoDate:   Sun Sep 19 18:03:41 2010 +0300    Update PostgreSQL to 9.0.0.    Signed-off-by: Adam Vandenbergcommit fa992c6a82eebdc4cc36a0c0d2837f4c02f3f422Author: David HöppnerDate:   Sun May 16 12:35:18 2010 +0200    postgresql: update version to 8.4.4Obviously, fa992c6a82eebdc4cc36a0c0d2837f4c02f3f422 is the commit we’re interested in. As this commit is pretty old, we’ll try to downgrade the complete homebrew installation (that way, the formula API is more or less guaranteed to be valid):$ git checkout -b postgresql-8.4.4 fa992c6a82eebdc4cc36a0c0d2837f4c02f3f422$ brew install postgresql$ git checkout master$ git branch -d postgresql-8.4.4You may skip the last command to keep the reference in your git repository.One note: When checking out the older commit, you temporarily downgrade your homebrew installation. So, you should be careful as some commands in homebrew might be different to the most recent version.4) Manually write a formulaIt’s not too hard and you may then upload it to your own repository. Used to be Homebrew-Versions, but that is now discontinued.A.) Bonus: PinningIf you want to keep a certain version of, say postgresql, around and stop it from being updated when you do the natural brew update; brew upgrade procedure, you can pin a formula:$ brew pin postgresqlPinned formulae are listed in /usr/local/Library/PinnedKegs/ and once you want to bring in the latest changes and updates, you can unpin it again:$ brew unpin postgresql"
"data_i","edited Mar 12 '21 at 12:19","
        Using async/await with a forEach loop
    ","Are there any issues with using async/await in a forEach loop? I'm trying to loop through an array of files and await on the contents of each file.import fs from 'fs-promise'async function printFiles () {  const files = await getFilePaths() // Assume this works fine  files.forEach(async (file) => {    const contents = await fs.readFile(file, 'utf8')    console.log(contents)  })}printFiles()This code does work, but could something go wrong with this? I had someone tell me that you're not supposed to use async/await in a higher-order function like this, so I just wanted to ask if there was any issue with this.","Sure the code does work, but I'm pretty sure it doesn't do what you expect it to do. It just fires off multiple asynchronous calls, but the printFiles function does immediately return after that.Reading in sequenceIf you want to read the files in sequence, you cannot use forEach indeed. Just use a modern for … of loop instead, in which await will work as expected:async function printFiles () {  const files = await getFilePaths();  for (const file of files) {    const contents = await fs.readFile(file, 'utf8');    console.log(contents);  }}Reading in parallelIf you want to read the files in parallel, you cannot use forEach indeed. Each of the async callback function calls does return a promise, but you're throwing them away instead of awaiting them. Just use map instead, and you can await the array of promises that you'll get with Promise.all:async function printFiles () {  const files = await getFilePaths();  await Promise.all(files.map(async (file) => {    const contents = await fs.readFile(file, 'utf8')    console.log(contents)  }));}"
"data_i","edited Mar 29 '22 at 10:02","
        How do I get the last element of a list?
    ","How do I get the last element of a list?","some_list[-1] is the shortest and most Pythonic.In fact, you can do much more with this syntax. The some_list[-n] syntax gets the nth-to-last element. So some_list[-1] gets the last element, some_list[-2] gets the second to last, etc, all the way down to some_list[-len(some_list)], which gives you the first element.You can also set list elements in this way. For instance:>>> some_list = [1, 2, 3]>>> some_list[-1] = 5 # Set the last element>>> some_list[-2] = 3 # Set the second to last element>>> some_list[1, 3, 5]Note that getting a list item by index will raise an IndexError if the expected item doesn't exist. This means that some_list[-1] will raise an exception if some_list is empty, because an empty list can't have a last element."
"data_i","edited May 28 '20 at 00:58","
        Does a finally block always get executed in Java?
    ","Considering this code, can I be absolutely sure that the finally block always executes, no matter what something() is?try {      something();      return success;  }  catch (Exception e) {       return failure;  }  finally {      System.out.println(""I don't know if this will get printed out"");}","Yes, finally will be called after the execution of the try or catch code blocks.The only times finally won't be called are:If you invoke System.exit()If you invoke Runtime.getRuntime().halt(exitStatus)If the JVM crashes firstIf the JVM reaches an infinite loop (or some other non-interruptable, non-terminating statement) in the try or catch blockIf the OS forcibly terminates the JVM process; e.g., kill -9 <pid> on UNIXIf the host system dies; e.g., power failure, hardware error, OS panic, et ceteraIf the finally block is going to be executed by a daemon thread and all other non-daemon threads exit before finally is called"
"data_i","edited Jul 10 '18 at 15:04","
        Extract filename and extension in Bash
    ","I want to get the filename (without extension) and the extension separately.The best solution I found so far is:NAME=`echo ""$FILE"" | cut -d'.' -f1`EXTENSION=`echo ""$FILE"" | cut -d'.' -f2`This is wrong because it doesn't work if the file name contains multiple . characters. If, let's say, I have a.b.js, it will consider a and b.js, instead of a.b and js.It can be easily done in Python withfile, ext = os.path.splitext(path)but I'd prefer not to fire up a Python interpreter just for this, if possible.Any better ideas?","First, get file name without the path:filename=$(basename -- ""$fullfile"")extension=""${filename##*.}""filename=""${filename%.*}""Alternatively, you can focus on the last '/' of the path instead of the '.' which should work even if you have unpredictable file extensions:filename=""${fullfile##*/}""You may want to check the documentation :On the web at section ""3.5.3 Shell Parameter Expansion""In the bash manpage at section called ""Parameter Expansion"""
"data_i","edited Jun 14 '22 at 23:32","
        Scroll to an element with jQuery
    ","I have this input element:  <input type=""text"" class=""textfield"" value="""" id=""subject"" name=""subject"">Then I have some other elements, like other  tag's & <textarea> tag's, etc...When the user clicks on the <input id=""#subject"">, the page should scroll to the page's last element, and it should do so with a nice animation (It should be a scroll to bottom and not to top).The last item of the page is a submit button with #submit:<input type=""submit"" class=""submit"" id=""submit"" name=""submit"" value=""Ok, Done."">The animation should not be too fast and should be fluid.I am running the latest jQuery version. I prefer to not install any plugin but to use the default jQuery features to achieve this.","Assuming you have a button with the id button, try this example:$(""#button"").click(function() {    $([document.documentElement, document.body]).animate({        scrollTop: $(""#elementtoScrollToID"").offset().top    }, 2000);});I got the code from the article Smoothly scroll to an element without a jQuery plugin. And I have tested it on the example below.<html>    <script src=""https://ajax.googleapis.com/ajax/libs/jquery/1.5.1/jquery.min.js""></script>    <script>        $(document).ready(function (){            $(""#click"").click(function (){                $('html, body').animate({                    scrollTop: $(""#div1"").offset().top                }, 2000);            });        });    </script>    <div id=""div1"" style=""height: 1000px; width 100px"">        Test    </div>    <br/>    <div id=""div2"" style=""height: 1000px; width 100px"">        Test 2    </div>    <button id=""click"">Click me</button></html>"
"data_i","edited Sep 18 '22 at 23:12","
        PowerShell says ""execution of scripts is disabled on this system.""
    ","I am trying to run a cmd file that calls a PowerShell script from cmd.exe, but I am getting this error:Management_Install.ps1 cannot be loaded because the execution of scripts is disabled on this system.I ran this command:Set-ExecutionPolicy -ExecutionPolicy UnrestrictedWhen I run Get-ExecutionPolicy from PowerShell, it returns Unrestricted.Get-ExecutionPolicyOutput:Unrestrictedcd ""C:\Projects\Microsoft.Practices.ESB\Source\Samples\Management Portal\Install\Scripts""powershell .\Management_Install.ps1 1WARNING: Running x86 PowerShell...File C:\Projects\Microsoft.Practices.ESB\Source\Samples\Management Portal\Install\Scripts\Management_Install.ps1 cannot be loaded because the execution of scripts is disabled on this system. Please see ""get-help about_signing"" for more details.At line:1 char:25.\Management_Install.ps1 <<<<  1CategoryInfo          : NotSpecified: (:) [], PSSecurityExceptionFullyQualifiedErrorId : RuntimeExceptionC:\Projects\Microsoft.Practices.ESB\Source\Samples\Management Portal\Install\Scripts> PAUSEPress any key to continue . . .The system is Windows Server 2008 R2.What am I doing wrong?","If you're using Windows Server 2008 R2 then there is an x64 and x86 version of PowerShell both of which have to have their execution policies set. Did you set the execution policy on both hosts?As an Administrator, you can set the execution policy by typing this into your PowerShell window:Set-ExecutionPolicy RemoteSignedFor more information, see Using the Set-ExecutionPolicy Cmdlet.When you are done, you can set the policy back to its default value with:Set-ExecutionPolicy RestrictedYou may see an error:Access to the registry key'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\PowerShell\1\ShellIds\Microsoft.PowerShell' is denied. To change the execution policy for the default (LocalMachine) scope,   start Windows PowerShell with the ""Run as administrator"" option. To change the execution policy for the current user,   run ""Set-ExecutionPolicy -Scope CurrentUser"".So you may need to run the command like this (as seen in comments):Set-ExecutionPolicy RemoteSigned -Scope CurrentUser"
"data_i","edited Aug 16 '22 at 15:48","
        Adding a table row in jQuery
    ","I'm using jQuery to add an additional row to a table as the last row.I have done it this way:$('#myTable').append('<tr><td>my data</td><td>more data</td></tr>');Are there limitations to what you can add to a table like this (such as inputs, selects, number of rows)? Is there a different way to do it?","The approach you suggest is not guaranteed to give you the result you're looking for - what if you had a tbody for example:<table id=""myTable"">  <tbody>    <tr>...</tr>    <tr>...</tr>  </tbody></table>You would end up with the following:<table id=""myTable"">  <tbody>    <tr>...</tr>    <tr>...</tr>  </tbody>  <tr>...</tr></table>I would therefore recommend this approach instead:$('#myTable tr:last').after('<tr>...</tr><tr>...</tr>');You can include anything within the after() method as long as it's valid HTML, including multiple rows as per the example above.Update: Revisiting this answer following recent activity with this question. eyelidlessness makes a good comment that there will always be a tbody in the DOM; this is true, but only if there is at least one row. If you have no rows, there will be no tbody unless you have specified one yourself.DaRKoN_ suggests appending to the tbody rather than adding content after the last tr. This gets around the issue of having no rows, but still isn't bulletproof as you could theoretically have multiple tbody elements and the row would get added to each of them.Weighing everything up, I'm not sure there is a single one-line solution that accounts for every single possible scenario. You will need to make sure the jQuery code tallies with your markup.I think the safest solution is probably to ensure your table always includes at least one tbody in your markup, even if it has no rows. On this basis, you can use the following which will work however many rows you have (and also account for multiple tbody elements):$('#myTable > tbody:last-child').append('<tr>...</tr><tr>...</tr>');"
"data_i","edited Sep 12 '20 at 15:48","
        How to mkdir only if a directory does not already exist?
    ","I am writing a shell script to run under the KornShell (ksh) on AIX. I would like to use the mkdir command to create a directory. But the directory may already exist, in which case I do not want to do anything. So I want to either test to see that the directory does not exist, or suppress the ""File exists"" error that mkdir throws when it tries to create an existing directory. How can I best do this?","Try mkdir -p:mkdir -p fooNote that this will also create any intermediate directories that don't exist; for instance,mkdir -p foo/bar/bazwill create directories foo, foo/bar, and foo/bar/baz if they don't exist.Some implementation like GNU mkdir include mkdir --parents as a more readable alias, but this is not specified in POSIX/Single Unix Specification and not available on many common platforms like macOS, various BSDs, and various commercial Unixes, so it should be avoided.If you want an error when parent directories don't exist, and want to create the directory if it doesn't exist, then you can test for the existence of the directory first:[ -d foo ] || mkdir foo"
"data_i","edited Feb 27 '20 at 19:37","
        Compare two dates with JavaScript
    ","Can someone suggest a way to compare the values of two dates greater than, less than, and not in the past using JavaScript? The values will be coming from text boxes.","The Date object will do what you want - construct one for each date, then compare them using the >, <, <= or >=.The ==, !=, ===, and !== operators require you to use date.getTime() as invar d1 = new Date();var d2 = new Date(d1);var same = d1.getTime() === d2.getTime();var notSame = d1.getTime() !== d2.getTime();to be clear just checking for equality directly with the date objects won't workvar d1 = new Date();var d2 = new Date(d1);console.log(d1 == d2);   // prints false (wrong!) console.log(d1 === d2);  // prints false (wrong!)console.log(d1 != d2);   // prints true  (wrong!)console.log(d1 !== d2);  // prints true  (wrong!)console.log(d1.getTime() === d2.getTime()); // prints true (correct)I suggest you use drop-downs or some similar constrained form of date entry rather than text boxes, though, lest you find yourself in input validation hell.For the curious, date.getTime() documentation:Returns the numeric value of the specified date as the number of milliseconds since January 1, 1970, 00:00:00 UTC. (Negative values are returned for prior times.)"
"data_i","edited Jul 28 '20 at 21:38","
        What does O(log n) mean exactly?
    ","I am learning about Big O Notation running times and amortized times.  I understand the notion of O(n) linear time, meaning that the size of the input affects the growth of the algorithm proportionally...and the same goes for, for example, quadratic time O(n2) etc..even algorithms, such as permutation generators, with O(n!) times, that grow by factorials.For example, the following function is O(n) because the algorithm grows in proportion to its input n:f(int n) {  int i;  for (i = 0; i < n; ++i)    printf(""%d"", i);}Similarly, if there was a nested loop, the time would be O(n2).But what exactly is O(log n)?  For example, what does it mean to say that the height of a complete binary tree is O(log n)?I do know (maybe not in great detail) what Logarithm is, in the sense that:  log10 100 = 2, but I cannot understand how to identify a function with a logarithmic time.","I cannot understand how to identify a function with a log time.The most common attributes of logarithmic running-time function are that:the choice of the next element on which to perform some action is one of several possibilities, andonly one will need to be chosen.orthe elements on which the action is performed are digits of nThis is why, for example, looking up people in a phone book is O(log n). You don't need to check every person in the phone book to find the right one; instead, you can simply divide-and-conquer by looking based on where their name is alphabetically, and in every section you only need to explore a subset of each section before you eventually find someone's phone number.Of course, a bigger phone book will still take you a longer time, but it won't grow as quickly as the proportional increase in the additional size.We can expand the phone book example to compare other kinds of operations and their running time. We will assume our phone book has businesses (the ""Yellow Pages"") which have unique names and people (the ""White Pages"") which may not have unique names. A phone number is assigned to at most one person or business. We will also assume that it takes constant time to flip to a specific page.Here are the running times of some operations we might perform on the phone book, from fastest to slowest:O(1) (in the worst case): Given the page that a business's name is on and the business name, find the phone number.O(1) (in the average case): Given the page that a person's name is on and their name, find the phone number.O(log n): Given a person's name, find the phone number by picking a random point about halfway through the part of the book you haven't searched yet, then checking to see whether the person's name is at that point. Then repeat the process about halfway through the part of the book where the person's name lies. (This is a binary search for a person's name.)O(n): Find all people whose phone numbers contain the digit ""5"".O(n): Given a phone number, find the person or business with that number.O(n log n): There was a mix-up at the printer's office, and our phone book had all its pages inserted in a random order. Fix the ordering so that it's correct by looking at the first name on each page and then putting that page in the appropriate spot in a new, empty phone book.For the below examples, we're now at the printer's office. Phone books are waiting to be mailed to each resident or business, and there's a sticker on each phone book identifying where it should be mailed to. Every person or business gets one phone book.O(n log n): We want to personalize the phone book, so we're going to find each person or business's name in their designated copy, then circle their name in the book and write a short thank-you note for their patronage.O(n2): A mistake occurred at the office, and every entry in each of the phone books has an extra ""0"" at the end of the phone number. Take some white-out and remove each zero.O(n · n!): We're ready to load the phonebooks onto the shipping dock. Unfortunately, the robot that was supposed to load the books has gone haywire: it's putting the books onto the truck in a random order! Even worse, it loads all the books onto the truck, then checks to see if they're in the right order, and if not, it unloads them and starts over. (This is the dreaded bogo sort.)O(nn): You fix the robot so that it's loading things correctly. The next day, one of your co-workers plays a prank on you and wires the loading dock robot to the automated printing systems. Every time the robot goes to load an original book, the factory printer makes a duplicate run of all the phonebooks! Fortunately, the robot's bug-detection systems are sophisticated enough that the robot doesn't try printing even more copies when it encounters a duplicate book for loading, but it still has to load every original and duplicate book that's been printed."
"data_i","edited Jul 10 '19 at 14:46","
        How do I import an SQL file using the command line in MySQL?
    ","I have a .sql file with an export from phpMyAdmin. I want to import it into a different server using the command line.I have a Windows Server 2008 R2 installation. I placed the .sql file on the C drive, and I tried this commanddatabase_name < file.sqlIt is not working. I get syntax errors.How can I import this file without a problem?Do I need to create a database first?","Try:mysql -u username -p database_name < file.sqlCheck MySQL Options.Note 1: It is better to use the full path of the SQL file file.sql.Note 2: Use -R and --triggers to keep the routines and triggers of original database. They are not copied by default.Note 3 You may have to create the (empty) database from MySQL if it doesn't exist already and the exported SQL don't contain CREATE DATABASE (exported with --no-create-db or -n option), before you can import it."
"data_i","edited Jan 05 '19 at 09:06","
        How do I determine whether an array contains a particular value in Java?
    ","I have a String[] with values like so:public static final String[] VALUES = new String[] {""AB"",""BC"",""CD"",""AE""};Given String s, is there a good way of testing whether VALUES contains s?","Arrays.asList(yourArray).contains(yourValue)Warning: this doesn't work for arrays of primitives (see the comments).Since java-8 you can now use Streams.String[] values = {""AB"",""BC"",""CD"",""AE""};boolean contains = Arrays.stream(values).anyMatch(""s""::equals);To check whether an array of int, double or long contains a value use IntStream, DoubleStream or LongStream respectively.Exampleint[] a = {1,2,3,4};boolean contains = IntStream.of(a).anyMatch(x -> x == 4);"
"data_i","edited Jun 30 '20 at 14:30","
        Set a default parameter value for a JavaScript function
    ","I would like a JavaScript function to have optional arguments which I set a default on, which get used if the value isn't defined (and ignored if the value is passed). In Ruby you can do it like this:def read_file(file, delete_after = false)  # codeendDoes this work in JavaScript?function read_file(file, delete_after = false) {  // Code}","From ES6/ES2015, default parameters are in the language specification.function read_file(file, delete_after = false) {  // Code}just works.Reference: Default Parameters - MDNDefault function parameters allow formal parameters to be initialized with default values if no value or undefined is passed.In ES6, you can simulate default named parameters via destructuring:// the `= {}` below lets you call the function without any parametersfunction myFor({ start = 5, end = 1, step = -1 } = {}) { // (A)    // Use the variables `start`, `end` and `step` here    ···}// sample call using an objectmyFor({ start: 3, end: 0 });// also OKmyFor();myFor({});Pre ES2015,There are a lot of ways, but this is my preferred method — it lets you pass in anything you want, including false or null. (typeof null == ""object"")function foo(a, b) {  a = typeof a !== 'undefined' ? a : 42;  b = typeof b !== 'undefined' ? b : 'default_b';  ...}"
"data_i","edited Jan 27 '22 at 02:30","
        Find (and kill) process locking port 3000 on Mac
    ","How do I find (and kill) processes that listen to/use my TCP ports? I'm on macOS.Sometimes, after a crash or some bug, my Rails app is locking port 3000. I can't find it using ps -ef...When runningrails serverI getAddress already in use - bind(2) (Errno::EADDRINUSE)The same issue happens when stopping Node.js process. Even after the process is stopped and the app stops running, port 3000 is locked. When starting the app again, gettingAddress already in use (Errno::EADDRINUSE)","You can try netstatnetstat -vanp tcp | grep 3000For macOS El Capitan and newer (or if your netstat doesn't support -p), use lsoflsof -i tcp:3000"
"data_i","edited Jun 04 '22 at 21:35","
        How do I sort a list of dictionaries by a value of the dictionary?
    ","How do I sort a list of dictionaries by a specific key's value? Given:[{'name': 'Homer', 'age': 39}, {'name': 'Bart', 'age': 10}]When sorted by name, it should become:[{'name': 'Bart', 'age': 10}, {'name': 'Homer', 'age': 39}]","The sorted() function takes a key= parameternewlist = sorted(list_to_be_sorted, key=lambda d: d['name']) Alternatively, you can use operator.itemgetter instead of defining the function yourselffrom operator import itemgetternewlist = sorted(list_to_be_sorted, key=itemgetter('name')) For completeness, add reverse=True to sort in descending ordernewlist = sorted(list_to_be_sorted, key=itemgetter('name'), reverse=True)"
"data_i","edited Nov 12 '08 at 20:16","
        How do I call one constructor from another in Java?
    ","Is it possible to call a constructor from another (within the same class, not from a subclass)? If yes how? And what could be the best way to call another constructor (if there are several ways to do it)?","Yes, it is possible:public class Foo {    private int x;    public Foo() {        this(1);    }    public Foo(int x) {        this.x = x;    }}To chain to a particular superclass constructor instead of one in the same class, use super instead of this. Note that you can only chain to one constructor, and it has to be the first statement in your constructor body.See also this related question, which is about C# but where the same principles apply."
"data_i","edited Nov 13 '20 at 14:40","
        How to upgrade all Python packages with pip
    ","Is it possible to upgrade all Python packages at one time with pip?Note: that there is a feature request for this on the official issue tracker.","There isn't a built-in flag yet, but you can use:pip list --outdated --format=freeze | grep -v '^\-e' | cut -d = -f 1  | xargs -n1 pip install -UFor older versions of pip:pip freeze --local | grep -v '^\-e' | cut -d = -f 1  | xargs -n1 pip install -UThe grep is to skip editable (""-e"") package definitions, as suggested by @jawache. (Yes, you could replace grep+cut with sed or awk or perl or...).The -n1 flag for xargs prevents stopping everything if updating one package fails (thanks @andsens).Note: there are infinite potential variations for this. I'm trying to keep this answer short and simple, but please do suggest variations in the comments!"
"data_i","edited Jul 08 '19 at 23:32","
        How to make a div 100% height of the browser window
    ","I have a layout with two columns - a left div and a right div.The right div has a grey background-color, and I need it to expand vertically depending on the height of the user's browser window. Right now the background-color ends at the last piece of content in that div. I've tried height:100%, min-height:100%;, etc.","There are a couple of CSS 3 measurement units called:Viewport-Percentage (or Viewport-Relative) LengthsWhat are Viewport-Percentage Lengths?From the linked W3 Candidate Recommendation above:The viewport-percentage lengths are relative to the size of the initial containing block. When the height or width of the initial containing block is changed, they are scaled accordingly.These units are vh (viewport height), vw (viewport width), vmin (viewport minimum length) and vmax (viewport maximum length).How can this be used to make a divider fill the height of the browser?For this question, we can make use of vh: 1vh is equal to 1% of the viewport's height. That is to say, 100vh is equal to the height of the browser window, regardless of where the element is situated in the DOM tree:HTML<div></div>CSSdiv {    height: 100vh;}This is literally all that's needed. Here is a JSFiddle example of this in use.What browsers support these new units?This is currently supported on all up-to-date major browsers apart from Opera Mini. Check out Can I use... for further support.How can this be used with multiple columns?In the case of the question at hand, featuring a left and a right divider, here is a JSFiddle example showing a two-column layout involving both vh and vw.How is 100vh different from 100%?Take this layout for example:<body style=""height: 100%"">    <div style=""height: 200px"">        <p style=""height: 100%; display: block;"">Hello, world!</p>    </div></body>The p tag here is set to 100% height, but because its containing div has 200 pixels height, 100% of 200 pixels becomes 200 pixels, not 100% of the body height. Using 100vh instead means that the p tag will be 100% height of the body regardless of the div height. Take a look at this accompanying JSFiddle to easily see the difference!"
"data_i","edited Jun 22 '20 at 07:53","
        Generate random string/characters in JavaScript
    ","I want a 5 character string composed of characters picked randomly from the set [a-zA-Z0-9].What's the best way to do this with JavaScript?","I think this will work for you:function makeid(length) {    var result           = '';    var characters       = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';    var charactersLength = characters.length;    for ( var i = 0; i < length; i++ ) {      result += characters.charAt(Math.floor(Math.random() *  charactersLength));   }   return result;}console.log(makeid(5));"
"data_i","edited Feb 06 '20 at 14:24","
        When to use margin vs padding in CSS
    ","When writing CSS, is there a particular rule or guideline that should be used in deciding when to use margin and when to use padding?","TL;DR: By default I use margin everywhere, except when I have a border or background and want to increase the space inside that visible box.To me, the biggest difference between padding and margin is that vertical margins auto-collapse, and padding doesn't. Consider two elements one above the other each with padding of 1em. This padding is considered to be part of the element and is always preserved. So you will end up with the content of the first element, followed by the padding of the first element, followed by the padding of the second, followed by the content of the second element. Thus the content of the two elements will end up being 2em apart.Now replace that padding with 1em margin. Margins are considered to be outside of the element, and margins of adjacent items will overlap. So in this example, you will end up with the content of the first element followed by 1em of combined margin followed by the content of the second element. So the content of the two elements is only 1em apart. This can be really useful when you know that you want to say 1em of spacing around an element, regardless of what element it is next to.The other two big differences are that padding is included in the click region and background color/image, but not the margin.div.box > div { height: 50px; width: 50px; border: 1px solid black; text-align: center; }div.padding > div { padding-top: 20px; }div.margin > div { margin-top: 20px; }<h3>Default</h3><div class=""box"">  <div>A</div>  <div>B</div>  <div>C</div></div><h3>padding-top: 20px</h3><div class=""box padding"">  <div>A</div>  <div>B</div>  <div>C</div></div><h3>margin-top: 20px; </h3><div class=""box margin"">  <div>A</div>  <div>B</div>  <div>C</div></div>"
"data_i","edited Mar 29 '22 at 09:34","
        How do I get a substring of a string in Python?
    ","I want to get a new string from the third character to the end of the string, e.g. myString[2:end]. If omitting the second part means 'till the end', and if you omit the first part, does it start from the start?",">>> x = ""Hello World!"">>> x[2:]'llo World!'>>> x[:2]'He'>>> x[:-2]'Hello Worl'>>> x[-2:]'d!'>>> x[2:-2]'llo Worl'Python calls this concept ""slicing"" and it works on more than just strings. Take a look here for a comprehensive introduction."
"data_i","edited Feb 08 '19 at 17:39","
        Make a div fill the height of the remaining screen space
    ","I am working on a web application where I want the content to fill the height of the entire screen.The page has a header, which contains a logo, and account information. This could be an arbitrary height. I want the content div to fill the rest of the page to the bottom.I have a header div and a content div. At the moment I am using a table for the layout like so:CSS and HTML#page {    height: 100%; width: 100%}#tdcontent {    height: 100%;}#content {    overflow: auto; /* or overflow: hidden; */}<table id=""page"">    <tr>        <td id=""tdheader"">            <div id=""header"">...</div>        </td>    </tr>    <tr>        <td id=""tdcontent"">            <div id=""content"">...</div>        </td>    </tr></table>The entire height of the page is filled, and no scrolling is required.For anything inside the content div, setting top: 0; will put it right underneath the header. Sometimes the content will be a real table, with its height set to 100%. Putting header inside content will not allow this to work.Is there a way to achieve the same effect without using the table?Update:Elements inside the content div will have heights set to percentages as well. So something at 100% inside the div will fill it to the bottom. As will two elements at 50%.Update 2:For instance, if the header takes up 20% of the screen's height, a table specified at 50% inside #content would take up 40% of the screen space. So far, wrapping the entire thing in a table is the only thing that works.","2015 update: the flexbox approachThere are two other answers briefly mentioning flexbox; however, that was more than two years ago, and they don't provide any examples. The specification for flexbox has definitely settled now.Note: Though CSS Flexible Boxes Layout specification is at the Candidate Recommendation stage, not all browsers have implemented it. WebKit implementation must be prefixed with -webkit-; Internet Explorer implements an old version of the spec, prefixed with -ms-; Opera 12.10 implements the latest version of the spec, unprefixed. See the compatibility table on each property for an up-to-date compatibility status.(taken from https://developer.mozilla.org/en-US/docs/Web/Guide/CSS/Flexible_boxes)All major browsers and IE11+ support Flexbox. For IE 10 or older, you can use the FlexieJS shim.To check current support you can also see here:http://caniuse.com/#feat=flexboxWorking exampleWith flexbox you can easily switch between any of your rows or columns either having fixed dimensions, content-sized dimensions or remaining-space dimensions. In my example I have set the header to snap to its content (as per the OPs question), I've added a footer to show how to add a fixed-height region and then set the content area to fill up the remaining space.html,body {  height: 100%;  margin: 0;}.box {  display: flex;  flex-flow: column;  height: 100%;}.box .row {  border: 1px dotted grey;}.box .row.header {  flex: 0 1 auto;  /* The above is shorthand for:  flex-grow: 0,  flex-shrink: 1,  flex-basis: auto  */}.box .row.content {  flex: 1 1 auto;}.box .row.footer {  flex: 0 1 40px;}<!-- Obviously, you could use HTML5 tags like `header`, `footer` and `section` --><div class=""box"">  <div class=""row header"">    <p><b>header</b>      <br />      <br />(sized to content)</p>  </div>  <div class=""row content"">    <p>      <b>content</b>      (fills remaining space)    </p>  </div>  <div class=""row footer"">    <p><b>footer</b> (fixed height)</p>  </div></div>In the CSS above, the flex property shorthands the flex-grow, flex-shrink, and flex-basis properties to establish the flexibility of the flex items. Mozilla has a good introduction to the flexible boxes model."
"data_i","edited Dec 02 '20 at 22:30","
        Docker: Copying files from Docker container to host
    ","I'm thinking of using Docker to build my dependencies on a Continuous Integration (CI) server, so that I don't have to install all the runtimes and libraries on the agents themselves. To achieve this I would need to copy the build artifacts that are built inside the container back into the host. Is that possible?","In order to copy a file from a container to the host, you can use the commanddocker cp <containerId>:/file/path/within/container /host/path/targetHere's an example:$ sudo docker cp goofy_roentgen:/out_read.jpg .Here goofy_roentgen is the container name I got from the following command:$ sudo docker psCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                                            NAMES1b4ad9311e93        bamos/openface      ""/bin/bash""         33 minutes ago      Up 33 minutes       0.0.0.0:8000->8000/tcp, 0.0.0.0:9000->9000/tcp   goofy_roentgenYou can also use (part of) the Container ID. The following command is equivalent to the first$ sudo docker cp 1b4a:/out_read.jpg ."
"data_i","edited Jul 11 '22 at 07:08","
        How do I safely merge a Git branch into master?
    ","A new branch from master is created, we call it test.There are several developers who either commit to master or create other branches and later merge into master.Let's say work on test is taking several days and you want to continuously keep test updated with commits inside master.I would do git pull origin master from test. Question 1: Is this the right approach?  Other developers could have easily worked on same files as I have worked btw.My work on test is done and I am ready to merge it back to master. Here are the two ways I can think of:A: git checkout testgit pull origin mastergit push origin testgit checkout mastergit pull origin test B: git checkout testgit pull origin mastergit checkout mastergit merge testI am not using --rebase because from my understanding, rebase will get the changes from master and stack mine on top of that hence it could overwrite changes other people made.Question 2: Which one of these two methods is right?  What is the difference there?The goal in all of this is to keep my test branch updated with the things happening in master and later I could merge them back into master hoping to keep the timeline as linear as possible.","How I would do thisgit checkout mastergit pull origin mastergit merge testgit push origin masterIf I have a local branch from a remote one, I don't feel comfortable with merging other branches than this one with the remote. Also I would not push my changes, until I'm happy with what I want to push and also I wouldn't push things at all, that are only for me and my local repository. In your description it seems, that test is only for you? So no reason to publish it.git always tries to respect yours and others changes, and so will --rebase. I don't think I can explain it appropriately, so have a look at the Git book - Rebasing or git-ready: Intro into rebasing for a little description. It's a quite cool feature"
"data_i","edited Mar 08 '20 at 23:15","
        How can I determine if a variable is 'undefined' or 'null'?
    ","How do I determine if variable is undefined or null?My code is as follows:var EmpName = $(""div#esd-names div#name"").attr('class');if(EmpName == 'undefined'){  // DO SOMETHING};<div id=""esd-names"">  <div id=""name""></div></div>But if I do this, the JavaScript interpreter halts execution.","You can use the qualities of the abstract equality operator to do this:if (variable == null){    // your code here.}Because null == undefined is true, the above code will catch both null and undefined."
"data_i","edited Dec 16 '15 at 09:42","
        Deep cloning objects
    ","I want to do something like:MyObject myObj = GetMyObj(); // Create and fill a new objectMyObject newObj = myObj.Clone();And then make changes to the new object that are not reflected in the original object.I don't often need this functionality, so when it's been necessary, I've resorted to creating a new object and then copying each property individually, but it always leaves me with the feeling that there is a better or more elegant way of handling the situation.How can I clone or deep copy an object so that the cloned object can be modified without any changes being reflected in the original object?","Whereas one approach is to implement the ICloneable interface (described here, so I won't regurgitate), here's a nice deep clone object copier I found on The Code Project a while ago and incorporated it into our code.As mentioned elsewhere, it requires your objects to be serializable.using System;using System.IO;using System.Runtime.Serialization;using System.Runtime.Serialization.Formatters.Binary;/// <summary>/// Reference Article http://www.codeproject.com/KB/tips/SerializedObjectCloner.aspx/// Provides a method for performing a deep copy of an object./// Binary Serialization is used to perform the copy./// </summary>public static class ObjectCopier{    /// <summary>    /// Perform a deep copy of the object via serialization.    /// </summary>    /// <typeparam name=""T"">The type of object being copied.</typeparam>    /// <param name=""source"">The object instance to copy.</param>    /// <returns>A deep copy of the object.</returns>    public static T Clone<T>(T source)    {        if (!typeof(T).IsSerializable)        {            throw new ArgumentException(""The type must be serializable."", nameof(source));        }        // Don't serialize a null object, simply return the default for that object        if (ReferenceEquals(source, null)) return default;        using var Stream stream = new MemoryStream();        IFormatter formatter = new BinaryFormatter();        formatter.Serialize(stream, source);        stream.Seek(0, SeekOrigin.Begin);        return (T)formatter.Deserialize(stream);    }}The idea is that it serializes your object and then deserializes it into a fresh object. The benefit is that you don't have to concern yourself about cloning everything when an object gets too complex.In case of you prefer to use the new extension methods of C# 3.0, change the method to have the following signature:public static T Clone<T>(this T source){   // ...}Now the method call simply becomes objectBeingCloned.Clone();.EDIT (January 10 2015) Thought I'd revisit this, to mention I recently started using (Newtonsoft) Json to do this, it should be lighter, and avoids the overhead of [Serializable] tags. (NB @atconway has pointed out in the comments that private members are not cloned using the JSON method)/// <summary>/// Perform a deep Copy of the object, using Json as a serialization method. NOTE: Private members are not cloned using this method./// </summary>/// <typeparam name=""T"">The type of object being copied.</typeparam>/// <param name=""source"">The object instance to copy.</param>/// <returns>The copied object.</returns>public static T CloneJson<T>(this T source){                // Don't serialize a null object, simply return the default for that object    if (ReferenceEquals(source, null)) return default;    // initialize inner objects individually    // for example in default constructor some list property initialized with some values,    // but in 'source' these items are cleaned -    // without ObjectCreationHandling.Replace default constructor values will be added to result    var deserializeSettings = new JsonSerializerSettings {ObjectCreationHandling = ObjectCreationHandling.Replace};    return JsonConvert.DeserializeObject<T>(JsonConvert.SerializeObject(source), deserializeSettings);}"
"data_i","edited Dec 07 '16 at 03:57","
        Validate decimal numbers in JavaScript - IsNumeric()
    ","What's the cleanest, most effective way to validate decimal numbers in JavaScript?Bonus points for:Clarity. Solution should be clean and simple.Cross-platform.Test cases:01. IsNumeric('-1')      => true02. IsNumeric('-1.5')    => true03. IsNumeric('0')       => true04. IsNumeric('0.42')    => true05. IsNumeric('.42')     => true06. IsNumeric('99,999')  => false07. IsNumeric('0x89f')   => false08. IsNumeric('#abcdef') => false09. IsNumeric('1.2.3')   => false10. IsNumeric('')        => false11. IsNumeric('blah')    => false","@Joel's answer is pretty close, but it will fail in the following cases:// Whitespace strings:IsNumeric(' ')    == true;IsNumeric('\t\t') == true;IsNumeric('\n\r') == true;// Number literals:IsNumeric(-1)  == false;IsNumeric(0)   == false;IsNumeric(1.1) == false;IsNumeric(8e5) == false;Some time ago I had to implement an IsNumeric function, to find out if a variable contained a numeric value, regardless of its type, it could be a String containing a numeric value (I had to consider also exponential notation, etc.), a Number object, virtually anything could be passed to that function, I couldn't make any type assumptions,  taking care of type coercion (eg. +true == 1; but true shouldn't be considered as ""numeric"").I think is worth sharing this set of +30 unit tests made to numerous function implementations, and also share the one that passes all my tests:function isNumeric(n) {    return !isNaN(parseFloat(n)) && isFinite(n);}P.S. isNaN & isFinite have a confusing behavior due to forced conversion to number. In ES6, Number.isNaN & Number.isFinite would fix these issues. Keep that in mind when using them. Update : Here's how jQuery does it now (2.2-stable): isNumeric: function(obj) {    var realStringObj = obj && obj.toString();    return !jQuery.isArray(obj) && (realStringObj - parseFloat(realStringObj) + 1) >= 0;}Update :Angular 4.3:export function isNumeric(value: any): boolean {    return !isNaN(value - parseFloat(value));}"
"data_i","edited Nov 29 '21 at 07:17","
        How do you display code snippets in MS Word preserving format and syntax highlighting?
    ","Does anyone know a way to display code in Microsoft Word documents that preserves coloring and formatting? Preferably, the method would also be unobtrusive and easy to update.I have tried to include code as regular text which looks awful and gets in the way when editing regular text.  I have also tried inserting objects, a WordPad document and Text Box, into the document then putting the code inside those objects.  The code looks much better and is easier to avoid while editing the rest of the text.  However, these objects can only span one page which makes editing a nightmare when several pages of code need to be added.Lastly, I know that there are much better editors/formats that have no problem handling this but I am stuck working with MS word.","Here is the best way, for me, to add code inside word:Go to Insert tab, Text section, click Object button (it's on the right)Choose OpenDocument Text which will open a new embedded word documentCopy and paste your code from Visual Studio / Eclipse inside this embedded word pageSave and closeAdvantagesThe result looks very nice. Here are the advantages of this method:The code keeps its original layout and colorsThe code is separated from the rest of the document, as if it was a picture or a chartSpelling errors won't be highlighted in the code (this is cool !)And it takes only few seconds."
"data_i","edited Aug 23 '21 at 08:32","
        Do a ""git export"" (like ""svn export"")?
    ","I've been wondering whether there is a good ""git export"" solution that creates a copy of a tree without the .git repository directory. There are at least three methods I know of:git clone followed by removing the .git repository directory.git checkout-index alludes to this functionality but starts with ""Just read the desired tree into the index..."" which I'm not entirely sure how to do.git-export is a third-party script that essentially does a git clone into a temporary location followed by rsync --exclude='.git' into the final destination.None of these solutions really strike me as being satisfactory. The closest one to svn export might be option 1, because both require the target directory to be empty first. But option 2 seems even better, assuming I can figure out what it means to read a tree into the index.","Probably the simplest way to achieve this is with git archive. If you really need just the expanded tree you can do something like this.git archive master | tar -x -C /somewhere/elseMost of the time that I need to 'export' something from git, I want a compressed archive in any case so I do something like this.git archive master | bzip2 >source-tree.tar.bz2ZIP archive:git archive --format zip --output /full/path/to/zipfile.zip master git help archive for more details, it's quite flexible.Be aware that even though the archive will not contain the .git directory, it will, however, contain other hidden git-specific files like .gitignore, .gitattributes, etc. If you don't want them in the archive, make sure you use the export-ignore attribute in a .gitattributes file and commit this before doing your archive. Read more...Note: If you are interested in exporting the index, the command isgit checkout-index -a -f --prefix=/destination/path/(See Greg's answer for more details)"
"data_i","edited Mar 13 '21 at 20:37","
        Check if a variable is a string in JavaScript
    ","How can I determine whether a variable is a string or something else in JavaScript?","This is what works for me:if (typeof myVar === 'string' || myVar instanceof String)// it's a stringelse// it's something else"
"data_i","edited Jul 05 '22 at 08:17","
        How do I create an HTML button that acts like a link?
    ","How do I create an HTML button that acts like a link? So that clicking the button redirects the user to a page.I want it to be accessible, and with minimal extra characters or parameters in the URL.","HTMLThe plain HTML way is to put it in a <form> wherein you specify the desired target URL in the action attribute.<form action=""https://google.com"">    <input type=""submit"" value=""Go to Google"" /></form>If necessary, set CSS display: inline; on the form to keep it in the flow with the surrounding text. Instead of <input type=""submit""> in above example, you can also use <button type=""submit"">. The only difference is that the <button> element allows children.You'd intuitively expect to be able to use <button href=""https://google.com""> analogous with the <a> element, but unfortunately no, this attribute does not exist according to HTML specification.CSSIf CSS is allowed, simply use an <a> which you style to look like a button using among others the appearance property (it's only not supported in Internet Explorer).a.button {    -webkit-appearance: button;    -moz-appearance: button;    appearance: button;    text-decoration: none;    color: initial;}<a href=""https://google.com"" class=""button"">Go to Google</a>Or pick one of those many CSS libraries like Bootstrap.<a href=""https://google.com"" class=""btn btn-primary"">Go to Google</a>JavaScriptIf JavaScript is allowed, set the window.location.href.<input type=""button"" onclick=""location.href='https://google.com';"" value=""Go to Google"" />Instead of <input type=""button""> in above example, you can also use <button>. The only difference is that the <button> element allows children."
"data_i","edited Jan 09 '20 at 18:55","
        Disable/enable an input with jQuery?
    ","$input.disabled = true;or $input.disabled = ""disabled"";Which is the standard way? And, conversely, how do you enable a disabled input?","jQuery 1.6+To change the disabled property you should use the .prop() function.$(""input"").prop('disabled', true);$(""input"").prop('disabled', false);jQuery 1.5 and belowThe .prop() function doesn't exist, but .attr() does similar:Set the disabled attribute.$(""input"").attr('disabled','disabled');To enable again, the proper method is to use .removeAttr()$(""input"").removeAttr('disabled');In any version of jQueryYou can always rely on the actual DOM object and is probably a little faster than the other two options if you are only dealing with one element:// assuming an event handler thus 'this'this.disabled = true;The advantage to using the .prop() or .attr() methods is that you can set the property for a bunch of selected items.Note: In 1.6 there is a .removeProp() method that sounds a lot like removeAttr(), but it SHOULD NOT BE USED on native properties like 'disabled'  Excerpt from the documentation:Note: Do not use this method to remove native properties such as checked, disabled, or selected. This will remove the property completely and, once removed, cannot be added again to element. Use .prop() to set these properties to false instead.In fact, I doubt there are many legitimate uses for this method, boolean props are done in such a way that you should set them to false instead of ""removing"" them like their ""attribute"" counterparts in 1.5"
"data_i","edited Sep 03 '21 at 19:15","
        Get all unique values in a JavaScript array (remove duplicates)
    ","I have an array of numbers that I need to make sure are unique. I found the code snippet below on the internet and it works great until the array has a zero in it. I found this other script here on Stack Overflow that looks almost exactly like it, but it doesn't fail.So for the sake of helping me learn, can someone help me determine where the prototype script is going wrong?Array.prototype.getUnique = function() { var o = {}, a = [], i, e; for (i = 0; e = this[i]; i++) {o[e] = 1}; for (e in o) {a.push (e)}; return a;}More answers from duplicate question:Remove duplicate values from JS arraySimilar question:Get all non-unique values (i.e.: duplicate/more than one occurrence) in an array","With JavaScript 1.6 / ECMAScript 5 you can use the native filter method of an Array in the following way to get an array with unique values:function onlyUnique(value, index, self) {  return self.indexOf(value) === index;}// usage example:var a = ['a', 1, 'a', 2, '1'];var unique = a.filter(onlyUnique);console.log(unique); // ['a', 1, 2, '1']The native method filter will loop through the array and leave only those entries that pass the given callback function onlyUnique.onlyUnique checks, if the given value is the first occurring. If not, it must be a duplicate and will not be copied.This solution works without any extra library like jQuery or prototype.js.It works for arrays with mixed value types too.For old Browsers (<ie9), that do not support the native methods filter and indexOf you can find work arounds in the MDN documentation for filter and indexOf.If you want to keep the last occurrence of a value, simply replace indexOf with lastIndexOf.With ES6 this can be shorten to:// usage example:var myArray = ['a', 1, 'a', 2, '1'];var unique = myArray.filter((v, i, a) => a.indexOf(v) === i);console.log(unique); // unique is ['a', 1, 2, '1']Thanks to Camilo Martin for hint in comment.ES6 has a native object Set to store unique values. To get an array with unique values you could now do this:var myArray = ['a', 1, 'a', 2, '1'];let unique = [...new Set(myArray)];console.log(unique); // unique is ['a', 1, 2, '1']The constructor of Set takes an iterable object, like an Array, and the spread operator ... transform the set back into an Array. Thanks to Lukas Liese for hint in comment."
"data_i","edited Apr 18 '16 at 12:09","
        How do I give text or an image a transparent background using CSS?
    ","Is it possible, using CSS only, to make the background of an element semi-transparent but have the content (text & images) of the element opaque?I'd like to accomplish this without having the text and the background as two separate elements.When trying:p {  position: absolute;  background-color: green;  filter: alpha(opacity=60);  opacity: 0.6;}span {  color: white;  filter: alpha(opacity=100);  opacity: 1;}<p>  <span>Hello world</span></p>It looks like child elements are subjected to the opacity of their parents, so opacity:1 is relative to the opacity:0.6 of the parent.","Either use a semi-transparent PNG or SVG image or use CSS:background-color: rgba(255, 0, 0, 0.5);Here's an article from css3.info, Opacity, RGBA and compromise (2007-06-03).Beware that the text still needs sufficient contrast with the background, once the underlying background shines through.<p style=""background-color: rgba(255, 0, 0, 0.5);"">  <span>Hello, World!</span></p>"
"data_i","edited Jul 17 '22 at 00:43","
        How do I ""git clone"" a repo, including its submodules?
    ","How do I clone a git repository so that it also clones its submodules?Running git clone $REPO_URL merely creates empty submodule directories.","With version 2.13 of Git and later, --recurse-submodules can be used instead of --recursive:git clone --recurse-submodules -j8 git://github.com/foo/bar.gitcd barEditor’s note: -j8 is an optional performance optimization that became available in version 2.8, and fetches up to 8 submodules at a time in parallel — see man git-clone.With version 1.9 of Git up until version 2.12 (-j flag only available in version 2.8+):git clone --recursive -j8 git://github.com/foo/bar.gitcd barWith version 1.6.5 of Git and later, you can use:git clone --recursive git://github.com/foo/bar.gitcd barFor already cloned repos, or older Git versions, use:git clone git://github.com/foo/bar.gitcd bargit submodule update --init --recursive"
"data_i","edited Feb 26 '21 at 08:05","
        Catch multiple exceptions at once?
    ","It is discouraged to simply catch System.Exception. Instead, only the ""known"" exceptions should be caught.Now, this sometimes leads to unnecessary repetitive code, for example:try{    WebId = new Guid(queryString[""web""]);}catch (FormatException){    WebId = Guid.Empty;}catch (OverflowException){    WebId = Guid.Empty;}I wonder: Is there a way to catch both exceptions and only call the WebId = Guid.Empty call once?The given example is rather simple, as it's only a GUID. But imagine code where you modify an object multiple times, and if one of the manipulations fails expectedly, you want to ""reset"" the object. However, if there is an unexpected exception, I still want to throw that higher.","Catch System.Exception and switch on the typescatch (Exception ex)            {                    if (ex is FormatException || ex is OverflowException)    {        WebId = Guid.Empty;        return;    }        throw;}"
"data_i","edited Dec 13 '17 at 04:12","
        How to change the output color of echo in Linux
    ","I am trying to print a text in the terminal using echo command. I want to print the text in a red color. How can I do that?","You can use these ANSI escape codes:Black        0;30     Dark Gray     1;30Red          0;31     Light Red     1;31Green        0;32     Light Green   1;32Brown/Orange 0;33     Yellow        1;33Blue         0;34     Light Blue    1;34Purple       0;35     Light Purple  1;35Cyan         0;36     Light Cyan    1;36Light Gray   0;37     White         1;37And then use them like this in your script:#    .---------- constant part!#    vvvv vvvv-- the code from aboveRED='\033[0;31m'NC='\033[0m' # No Colorprintf ""I ${RED}love${NC} Stack Overflow\n""which prints love in red.From @james-lim's comment, if you are using the echo command, be sure to use the -e flag to allow backslash escapes.# Continued from above exampleecho -e ""I ${RED}love${NC} Stack Overflow""(don't add ""\n"" when using echo unless you want to add an additional empty line)"
"data_i","edited Aug 26 '22 at 16:55","
        How to list only the names of files that changed between two commits
    ","I have a bunch of commits in the repository. I want to see a list of files changed between two commits - from SHA1 to SHA2.What command should I use?","git diff --name-only SHA1 SHA2where you only need to include enough of the SHA hash to identify the commits. You can also do, for examplegit diff --name-only HEAD~10 HEAD~5to see the differences between the tenth latest commit and the fifth latest (or so)."
"data_i","edited Aug 19 '18 at 17:12","
        How to make a great R reproducible example
    ","When discussing performance with colleagues, teaching, sending a bug report or searching for guidance on mailing lists and here on Stack Overflow, a reproducible example is often asked and always helpful.What are your tips for creating an excellent example? How do you paste data structures from r in a text format? What other information should you include?Are there other tricks in addition to using dput(), dump() or structure()?  When should you include library() or require() statements?  Which reserved words should one avoid, in addition to c, df, data, etc.?How does one make a great r reproducible example?","Basically, a minimal reproducible example (MRE) should enable others to exactly reproduce your issue on their machines.Please do not post images of your data, code, or console output!tl;drA MRE consists of the following items:a minimal dataset, necessary to demonstrate the problemthe minimal runnable code necessary to reproduce the issue, which can be run on the given datasetall necessary information on the used librarys, the R version, and the OS it is run on, perhaps a sessionInfo()in the case of random processes, a seed (set by set.seed()) to enable others to replicate exactly the same results as you doFor examples of good MREs, see section ""Examples"" at the bottom of help pages on the function you are using. Simply type e.g. help(mean), or short ?mean into your R console.Providing a minimal datasetUsually, sharing huge data sets is not necessary and may rather discourage others from reading your question. Therefore, it is better to use built-in datasets or create a small ""toy"" example that resembles your original data, which is actually what is meant by minimal. If for some reason you really need to share your original data, you should use a method, such as dput(), that allows others to get an exact copy of your data.Built-in datasetsYou can use one of the built-in datasets. A comprehensive list of built-in datasets can be seen with data(). There is a short description of every data set, and more information can be obtained, e.g. with ?iris, for the 'iris' data set that comes with R. Installed packages might contain additional datasets.Creating example data setsPreliminary note: Sometimes you may need special formats (i.e. classes), such as factors, dates, or time series. For these, make use of functions like: as.factor, as.Date, as.xts, ... Example:d <- as.Date(""2020-12-30"")whereclass(d)# [1] ""Date""Vectorsx <- rnorm(10)  ## random vector normal distributedx <- runif(10)  ## random vector uniformly distributed    x <- sample(1:100, 10)  ## 10 random draws out of 1, 2, ..., 100    x <- sample(LETTERS, 10)  ## 10 random draws out of built-in latin alphabetMatricesm <- matrix(1:12, 3, 4, dimnames=list(LETTERS[1:3], LETTERS[1:4]))m#   A B C  D# A 1 4 7 10# B 2 5 8 11# C 3 6 9 12Data framesset.seed(42)  ## for sake of reproducibilityn <- 6dat <- data.frame(id=1:n,                   date=seq.Date(as.Date(""2020-12-26""), as.Date(""2020-12-31""), ""day""),                  group=rep(LETTERS[1:2], n/2),                  age=sample(18:30, n, replace=TRUE),                  type=factor(paste(""type"", 1:n)),                  x=rnorm(n))dat#   id       date group age   type         x# 1  1 2020-12-26     A  27 type 1 0.0356312# 2  2 2020-12-27     B  19 type 2 1.3149588# 3  3 2020-12-28     A  20 type 3 0.9781675# 4  4 2020-12-29     B  26 type 4 0.8817912# 5  5 2020-12-30     A  26 type 5 0.4822047# 6  6 2020-12-31     B  28 type 6 0.9657529Note: Although it is widely used, better do not name your data frame df, because df() is an R function for the density (i.e. height of the curve at point x) of the F distribution and you might get a clash with it.Copying original dataIf you have a specific reason, or data that would be too difficult to construct an example from, you could provide a small subset of your original data, best by using dput.Why use dput()?dput throws all information needed to exactly reproduce your data on your console. You may simply copy the output and paste it into your question.Calling dat (from above) produces output that still lacks information about variable classes and other features if you share it in your question. Furthermore, the spaces in the type column make it difficult to do anything with it. Even when we set out to use the data, we won't manage to get important features of your data right.  id       date group age   type         x1  1 2020-12-26     A  27 type 1 0.03563122  2 2020-12-27     B  19 type 2 1.31495883  3 2020-12-28     A  20 type 3 0.9781675Subset your dataTo share a subset, use head(), subset() or the indices iris[1:4, ]. Then wrap it into dput() to give others something that can be put in R immediately. Exampledput(iris[1:4, ]) # first four rows of the iris data setConsole output to share in your question:structure(list(Sepal.Length = c(5.1, 4.9, 4.7, 4.6), Sepal.Width = c(3.5, 3, 3.2, 3.1), Petal.Length = c(1.4, 1.4, 1.3, 1.5), Petal.Width = c(0.2, 0.2, 0.2, 0.2), Species = structure(c(1L, 1L, 1L, 1L), .Label = c(""setosa"", ""versicolor"", ""virginica""), class = ""factor"")), row.names = c(NA, 4L), class = ""data.frame"")When using dput, you may also want to include only relevant columns, e.g. dput(mtcars[1:3, c(2, 5, 6)])Note: If your data frame has a factor with many levels, the dput output can be unwieldy because it will still list all the possible factor levels even if they aren't present in the subset of your data. To solve this issue, you can use the droplevels() function. Notice below how species is a factor with only one level, e.g. dput(droplevels(iris[1:4, ])). One other caveat for dput is that it will not work for keyed data.table objects or for grouped tbl_df (class grouped_df) from the tidyverse. In these cases you can convert back to a regular data frame before sharing, dput(as.data.frame(my_data)).Producing minimal codeCombined with the minimal data (see above), your code should exactly reproduce the problem on another machine by simply copying and pasting it.This should be the easy part but often isn't. What you should not do:showing all kinds of data conversions; make sure the provided data is already in the correct format (unless that is the problem, of course)copy-paste a whole script that gives an error somewhere. Try to locate which lines exactly result in the error. More often than not, you'll find out what the problem is yourself.What you should do:add which packages you use if you use any (using library())test run your code in a fresh R session to ensure the code is runnable. People should be able to copy-paste your data and your code in the console and get the same as you have.if you open connections or create files, add some code to close them or delete the files (using unlink())if you change options, make sure the code contains a statement to revert them back to the original ones. (eg op <- par(mfrow=c(1,2)) ...some code... par(op) )Providing necessary informationIn most cases, just the R version and the operating system will suffice. When conflicts arise with packages, giving the output of sessionInfo() can really help. When talking about connections to other applications (be it through ODBC or anything else), one should also provide version numbers for those, and if possible, also the necessary information on the setup.If you are running R in R Studio, using rstudioapi::versionInfo() can help report your RStudio version.If you have a problem with a specific package, you may want to provide the package version by giving the output of packageVersion(""name of the package"").SeedUsing set.seed() you may specify a seed1, i.e. the specific state, R's random number generator is fixed. This makes it possible for random functions, such as sample(), rnorm(), runif() and lots of others, to always return the same result, Example:set.seed(42)rnorm(3)# [1]  1.3709584 -0.5646982  0.3631284set.seed(42)rnorm(3)# [1]  1.3709584 -0.5646982  0.36312841Note: The output of set.seed() differs between R >3.6.0 and previous versions. Specify which R version you used for the random process, and don't be surprised if you get slightly different results when following old questions. To get the same result in such cases, you can use the RNGversion()-function before set.seed() (e.g.: RNGversion(""3.5.2""))."
"data_i","edited Jan 30 '21 at 15:25","
        Get selected text from a drop-down list (select box) using jQuery
    ","How can I get the selected text (not the selected value) from a drop-down list in jQuery?","$(""#yourdropdownid option:selected"").text();"
"data_i","edited Jul 25 '22 at 02:23","
        How do I show the changes which have been staged?
    ","I staged a few changes to be committed. How do I see the diffs of all files which are staged for the next commit? Is there a handy one-liner for this?git status only shows names of files which are staged, but I want to see the actual diffs.The git-diff(1) man page says:git diff [--options] [--] […]This form is to view the changes you made relative to the index (staging area for the next commit). In other words, the differences are what you could tell git to further add to the index but you still haven't. You can stage these changes by using git-add(1).","It should just be:git diff --cached--cached means show the changes in the cache/index (i.e. staged changes) against the current HEAD. --staged is a synonym for --cached.--staged and --cached does not point to HEAD, just difference with respect to HEAD. If you cherry pick what to commit using git add --patch (or git add -p), --staged will return what is staged."
"data_i","edited Nov 08 '21 at 12:14","
        How to update each dependency in package.json to the latest version?
    ","I copied package.json from another project and now want to bump all of the dependencies to their latest versions since this is a fresh project and I don't mind fixing something if it breaks.What's the easiest way to do this?The best way I know is to run npm info express version then update each dependency in package.json manually. There must be a better way.{  ""name"": ""myproject"",  ""description"": ""my node project"",  ""version"": ""1.0.0"",  ""engines"": {    ""node"": ""0.8.4"",    ""npm"": ""1.1.65""  },  ""private"": true,  ""dependencies"": {    ""express"": ""~3.0.3"", // how do I get these bumped to latest?    ""mongodb"": ""~1.2.5"",    ""underscore"": ""~1.4.2"",    ""rjs"": ""~2.9.0"",    ""jade"": ""~0.27.2"",    ""async"": ""~0.1.22""  }}For Yarn specific solutions refer to this Stack Overflow thread.","Looks like npm-check-updates is the only way to make this happen now.npm i -g npm-check-updatesncu -unpm installOn npm <3.11:Simply change every dependency's version to *, then run npm update --save.  (Note: broken in recent (3.11) versions of npm).Before:  ""dependencies"": {    ""express"": ""*"",    ""mongodb"": ""*"",    ""underscore"": ""*"",    ""rjs"": ""*"",    ""jade"": ""*"",    ""async"": ""*""  }After:  ""dependencies"": {    ""express"": ""~3.2.0"",    ""mongodb"": ""~1.2.14"",    ""underscore"": ""~1.4.4"",    ""rjs"": ""~2.10.0"",    ""jade"": ""~0.29.0"",    ""async"": ""~0.2.7""  }Of course, this is the blunt hammer of updating dependencies.  It's fine if—as you said—the project is empty and nothing can break.On the other hand, if you're working in a more mature project, you probably want to verify that there are no breaking changes in your dependencies before upgrading.To see which modules are outdated, just run npm outdated.  It will list any installed dependencies that have newer versions available.For Yarn specific solution, refer to this StackOverflow answer."
"data_i","edited Aug 17 '21 at 09:24","
        What is reflection and why is it useful?
    ","What is reflection, and why is it useful?I'm particularly interested in Java, but I assume the principles are the same in any language.","The name reflection is used to describe code which is able to inspect other code in the same system (or itself).For example, say you have an object of an unknown type in Java, and you would like to call a 'doSomething' method on it if one exists. Java's static typing system isn't really designed to support this unless the object conforms to a known interface, but using reflection, your code can look at the object and find out if it has a method called 'doSomething' and then call it if you want to.So, to give you a code example of this in Java (imagine the object in question is foo) :Method method = foo.getClass().getMethod(""doSomething"", null);method.invoke(foo, null);One very common use case in Java is the usage with annotations. JUnit 4, for example, will use reflection to look through your classes for methods tagged with the @Test annotation, and will then call them when running the unit test.There are some good reflection examples to get you started at http://docs.oracle.com/javase/tutorial/reflect/index.htmlAnd finally, yes, the concepts are pretty much similar in other statically typed languages which support reflection (like C#). In dynamically typed languages, the use case described above is less necessary (since the compiler will allow any method to be called on any object, failing at runtime if it does not exist), but the second case of looking for methods which are marked or work in a certain way is still common.Update from a comment:The ability to inspect the code in the system and see object types is  not reflection, but rather Type Introspection. Reflection is then the  ability to make modifications at runtime by making use of  introspection. The distinction is necessary here as some languages  support introspection, but do not support reflection. One such example  is C++"
"data_i","edited Oct 06 '19 at 14:06","
        What are the differences between .gitignore and .gitkeep?
    ","What are the differences between .gitignore and .gitkeep? Are they the same thing with a different name, or do they both serve a different function?I don't seem to be able to find much documentation on .gitkeep.",".gitkeep isn’t documented, because it’s not a feature of Git.Git cannot add a completely empty directory. People who want to track empty directories in Git have created the convention of putting files called .gitkeep in these directories. The file could be called anything; Git assigns no special significance to this name.There is a competing convention of adding a .gitignore file to the empty directories to get them tracked, but some people see this as confusing since the goal is to keep the empty directories, not ignore them; .gitignore is also used to list files that should be ignored by Git when looking for untracked files."
"data_i","edited Jul 01 '20 at 14:35","
        How to print a number with commas as thousands separators in JavaScript
    ","I am trying to print an integer in JavaScript with commas as thousands separators. For example, I want to show the number 1234567 as ""1,234,567"". How would I go about doing this? Here is how I am doing it:function numberWithCommas(x) {    x = x.toString();    var pattern = /(-?\d+)(\d{3})/;    while (pattern.test(x))        x = x.replace(pattern, ""$1,$2"");    return x;}Is there a simpler or more elegant way to do it? It would be nice if it works with floats also, but that is not necessary. It does not need to be locale-specific to decide between periods and commas. ","I used the idea from Kerry's answer, but simplified it since I was just looking for something simple for my specific purpose. Here is what I have:function numberWithCommas(x) {    return x.toString().replace(/\B(?=(\d{3})+(?!\d))/g, "","");}function numberWithCommas(x) {    return x.toString().replace(/\B(?<!\.\d*)(?=(\d{3})+(?!\d))/g, "","");}function test(x, expect) {    const result = numberWithCommas(x);    const pass = result === expect;    console.log(`${pass ? ""✓"" : ""ERROR ====>""} ${x} => ${result}`);    return pass;}let failures = 0;failures += !test(0,        ""0"");failures += !test(100,      ""100"");failures += !test(1000,     ""1,000"");failures += !test(10000,    ""10,000"");failures += !test(100000,   ""100,000"");failures += !test(1000000,  ""1,000,000"");failures += !test(10000000, ""10,000,000"");if (failures) {    console.log(`${failures} test(s) failed`);} else {    console.log(""All tests passed"");}.as-console-wrapper {    max-height: 100% !important;}The regex uses 2 lookahead assertions:a positive one to look for any point in the string that has a multiple of 3 digits in a row after it,a negative assertion to make sure that point only has exactly a multiple of 3 digits. The replacement expression puts a comma there.For example, if you pass it 123456789.01, the positive assertion will match every spot to the left of the 7 (since 789 is a multiple of 3 digits, 678 is a multiple of 3 digits, 567, etc.). The negative assertion checks that the multiple of 3 digits does not have any digits after it. 789 has a period after it so it is exactly a multiple of 3 digits, so a comma goes there. 678 is a multiple of 3 digits but it has a 9 after it, so those 3 digits are part of a group of 4, and a comma does not go there. Similarly for 567. 456789 is 6 digits, which is a multiple of 3, so a comma goes before that. 345678 is a multiple of 3, but it has a 9 after it, so no comma goes there. And so on. The \B keeps the regex from putting a comma at the beginning of the string.@neu-rah mentioned that this function adds commas in undesirable places if there are more than 3 digits after the decimal point. If this is a problem, you can use this function:function numberWithCommas(x) {    var parts = x.toString().split(""."");    parts[0] = parts[0].replace(/\B(?=(\d{3})+(?!\d))/g, "","");    return parts.join(""."");}function numberWithCommas(x) {    var parts = x.toString().split(""."");    parts[0] = parts[0].replace(/\B(?=(\d{3})+(?!\d))/g, "","");    return parts.join(""."");}function test(x, expect) {    const result = numberWithCommas(x);    const pass = result === expect;    console.log(`${pass ? ""✓"" : ""ERROR ====>""} ${x} => ${result}`);    return pass;}let failures = 0;failures += !test(0              , ""0"");failures += !test(0.123456       , ""0.123456"");failures += !test(100            , ""100"");failures += !test(100.123456     , ""100.123456"");failures += !test(1000           , ""1,000"");failures += !test(1000.123456    , ""1,000.123456"");failures += !test(10000          , ""10,000"");failures += !test(10000.123456   , ""10,000.123456"");failures += !test(100000         , ""100,000"");failures += !test(100000.123456  , ""100,000.123456"");failures += !test(1000000        , ""1,000,000"");failures += !test(1000000.123456 , ""1,000,000.123456"");failures += !test(10000000       , ""10,000,000"");failures += !test(10000000.123456, ""10,000,000.123456"");if (failures) {    console.log(`${failures} test(s) failed`);} else {    console.log(""All tests passed"");}.as-console-wrapper {    max-height: 100% !important;}@t.j.crowder pointed out that now that JavaScript has lookbehind (support info), it can be solved in the regular expression itself:function numberWithCommas(x) {    return x.toString().replace(/\B(?<!\.\d*)(?=(\d{3})+(?!\d))/g, "","");}function numberWithCommas(x) {    return x.toString().replace(/\B(?<!\.\d*)(?=(\d{3})+(?!\d))/g, "","");}function test(x, expect) {    const result = numberWithCommas(x);    const pass = result === expect;    console.log(`${pass ? ""✓"" : ""ERROR ====>""} ${x} => ${result}`);    return pass;}let failures = 0;failures += !test(0,               ""0"");failures += !test(0.123456,        ""0.123456"");failures += !test(100,             ""100"");failures += !test(100.123456,      ""100.123456"");failures += !test(1000,            ""1,000"");failures += !test(1000.123456,     ""1,000.123456"");failures += !test(10000,           ""10,000"");failures += !test(10000.123456,    ""10,000.123456"");failures += !test(100000,          ""100,000"");failures += !test(100000.123456,   ""100,000.123456"");failures += !test(1000000,         ""1,000,000"");failures += !test(1000000.123456,  ""1,000,000.123456"");failures += !test(10000000,        ""10,000,000"");failures += !test(10000000.123456, ""10,000,000.123456"");if (failures) {    console.log(`${failures} test(s) failed`);} else {    console.log(""All tests passed"");}.as-console-wrapper {    max-height: 100% !important;}(?<!\.\d*) is a negative lookbehind that says the match can't be preceded by a . followed by zero or more digits. The negative lookbehind is faster than the split and join solution (comparison), at least in V8."
"data_i","asked May 03 '11 at 19:33","
        .prop() vs .attr()
    ","So jQuery 1.6 has the new function prop().$(selector).click(function(){    //instead of:    this.getAttribute('style');    //do i use:    $(this).prop('style');    //or:    $(this).attr('style');})or in this case do they do the same thing?And if I do have to switch to using prop(), all the old attr() calls will break if i switch to 1.6?UPDATEselector = '#id'$(selector).click(function() {    //instead of:    var getAtt = this.getAttribute('style');    //do i use:    var thisProp = $(this).prop('style');    //or:    var thisAttr = $(this).attr('style');    console.log(getAtt, thisProp, thisAttr);});<script src=""https://ajax.googleapis.com/ajax/libs/jquery/1.6.0/jquery.min.js""></script><div id='id' style=""color: red;background: orange;"">test</div>(see also this fiddle: http://jsfiddle.net/maniator/JpUF2/)The console logs the getAttribute as a string, and the attr as a string, but the prop as a CSSStyleDeclaration, Why? And how does that affect my coding in the future?","Update 1 November 2012My original answer applies specifically to jQuery 1.6. My advice remains the same but jQuery 1.6.1 changed things slightly: in the face of the predicted pile of broken websites, the jQuery team reverted attr() to something close to (but not exactly the same as) its old behaviour for Boolean attributes. John Resig also blogged about it. I can see the difficulty they were in but still disagree with his recommendation to prefer attr().Original answerIf you've only ever used jQuery and not the DOM directly, this could be a confusing change, although it is definitely an improvement conceptually. Not so good for the bazillions of sites using jQuery that will break as a result of this change though.I'll summarize the main issues:You usually want prop() rather than attr().In the majority of cases, prop() does what attr() used to do. Replacing calls to attr() with prop() in your code will generally work.Properties are generally simpler to deal with than attributes. An attribute value may only be a string whereas a property can be of any type. For example, the checked property is a Boolean, the style property is an object with individual properties for each style, the size property is a number.Where both a property and an attribute with the same name exists, usually updating one will update the other, but this is not the case for certain attributes of inputs, such as value and checked: for these attributes, the property always represents the current state while the attribute (except in old versions of IE) corresponds to the default value/checkedness of the input (reflected in the defaultValue / defaultChecked property).This change removes some of the layer of magic jQuery stuck in front of attributes and properties, meaning jQuery developers will have to learn a bit about the difference between properties and attributes. This is a good thing.If you're a jQuery developer and are confused by this whole business about properties and attributes, you need to take a step back and learn a little about it, since jQuery is no longer trying so hard to shield you from this stuff. For the authoritative but somewhat dry word on the subject, there's the specs: DOM4, HTML DOM, DOM Level 2, DOM Level 3. Mozilla's DOM documentation is valid for most modern browsers and is easier to read than the specs, so you may find their DOM reference helpful. There's a section on element properties.As an example of how properties are simpler to deal with than attributes, consider a checkbox that is initially checked. Here are two possible pieces of valid HTML to do this:<input id=""cb"" type=""checkbox"" checked><input id=""cb"" type=""checkbox"" checked=""checked"">So, how do you find out if the checkbox is checked with jQuery? Look on Stack Overflow and you'll commonly find the following suggestions:if ( $(""#cb"").attr(""checked"") === true ) {...}if ( $(""#cb"").attr(""checked"") == ""checked"" ) {...}if ( $(""#cb"").is("":checked"") ) {...}This is actually the simplest thing in the world to do with the checked Boolean property, which has existed and worked flawlessly in every major scriptable browser since 1995:if (document.getElementById(""cb"").checked) {...}The property also makes checking or unchecking the checkbox trivial:document.getElementById(""cb"").checked = falseIn jQuery 1.6, this unambiguously becomes$(""#cb"").prop(""checked"", false)The idea of using the checked attribute for scripting a checkbox is unhelpful and unnecessary. The property is what you need.It's not obvious what the correct way to check or uncheck the checkbox is using the checked attributeThe attribute value reflects the default rather than the current visible state (except in some older versions of IE, thus making things still harder). The attribute tells you nothing about the whether the checkbox on the page is checked. See http://jsfiddle.net/VktA6/49/."
"data_i","edited Mar 29 '22 at 10:00","
        How do I lowercase a string in Python?
    ","Is there a way to convert a string to lowercase?""Kilometers""  →  ""kilometers""","Use str.lower():""Kilometer"".lower()"
"data_i","edited Jul 26 '22 at 23:56","
        What is the difference between CMD and ENTRYPOINT in a Dockerfile?
    ","In Dockerfiles there are two commands that look similar to me: CMD and ENTRYPOINT. But I guess that there is a (subtle?) difference between them - otherwise it would not make any sense to have two commands for the very same thing.The documentation states for CMD-The main purpose of a CMD is to provide defaults for an executing container.and for ENTRYPOINT:An ENTRYPOINT helps you to configure a container that you can run as an executable.So, what's the difference between those two commands?","Docker has a default entrypoint which is /bin/sh -c but does not have a default command.When you run docker like this:docker run -i -t ubuntu bashthe entrypoint is the default /bin/sh -c, the image is ubuntu and the command is bash.The command is run via the entrypoint. i.e., the actual thing that gets executed is /bin/sh -c bash. This allowed Docker to implement RUN quickly by relying on the shell's parser.Later on, people asked to be able to customize this, so ENTRYPOINT and --entrypoint were introduced.Everything after the image name, ubuntu in the example above, is the command and is passed to the entrypoint. When using the CMD instruction, it is exactly as if you were executingdocker run -i -t ubuntu <cmd>The parameter of the entrypoint is <cmd>.You will also get the same result if you instead type this command docker run -i -t ubuntu: a bash shell will start in the container because in the ubuntu Dockerfile a default CMD is specified:CMD [""bash""].As everything is passed to the entrypoint, you can have a very nice behavior from your images. @Jiri example is good, it shows how to use an image as a ""binary"". When using [""/bin/cat""] as entrypoint and then doing docker run img /etc/passwd, you get it, /etc/passwd is the command and is passed to the entrypoint so the end result execution is simply /bin/cat /etc/passwd.Another example would be to have any cli as entrypoint. For instance, if you have a redis image, instead of running docker run redisimg redis -H something -u toto get key, you can simply have ENTRYPOINT [""redis"", ""-H"", ""something"", ""-u"", ""toto""] and then run like this for the same result: docker run redisimg get key."
"data_i","edited Feb 17 '20 at 13:10","
        What's the difference between @Component, @Repository & @Service annotations in Spring?
    ","Can @Component, @Repository and @Service annotations be used interchangeably in Spring or do they provide any particular functionality besides acting as a notation device?In other words, if I have a Service class and I change the annotation from @Service to @Component, will it still behave the same way? Or does the annotation also influence the behavior and functionality of the class?","From Spring Documentation:The @Repository annotation is a marker for any class that fulfils therole or stereotype of a repository (also known as Data Access Objector DAO). Among the uses of this marker is the automatic translation ofexceptions, as described in Exception Translation.Spring provides further stereotype annotations: @Component, @Service,and @Controller. @Component is a generic stereotype for anySpring-managed component. @Repository, @Service, and @Controller arespecializations of @Component for more specific use cases (in thepersistence, service, and presentation layers, respectively).Therefore, you can annotate your component classes with @Component,but, by annotating them with @Repository, @Service, or @Controllerinstead, your classes are more properly suited for processing by toolsor associating with aspects.For example, these stereotype annotationsmake ideal targets for pointcuts. @Repository, @Service, and@Controller can also carry additional semantics in future releases ofthe Spring Framework. Thus, if you are choosing between using@Component or @Service for your service layer, @Service is clearly thebetter choice. Similarly, as stated earlier, @Repository is alreadysupported as a marker for automatic exception translation in yourpersistence layer.AnnotationMeaning@Componentgeneric stereotype for any Spring-managed component@Repositorystereotype for persistence layer@Servicestereotype for service layer@Controllerstereotype for presentation layer (spring-mvc)"
"data_i","edited Jul 25 '22 at 02:45","
        How do I get the hash for the current commit in Git?
    ","How do I get the hash of the current commit in Git?","To turn any extended object reference into a hash, use git-rev-parse:git rev-parse HEADorgit rev-parse --verify HEADTo retrieve the short hash:git rev-parse --short HEADTo turn references (e.g. branches and tags) into hashes, use git show-ref and git for-each-ref."
"data_i","edited May 26 '18 at 12:07","
        What is The Rule of Three?
    ","What does copying an object mean?What are the copy constructor and the copy assignment operator?When do I need to declare them myself?How can I prevent my objects from being copied?","IntroductionC++ treats variables of user-defined types with value semantics.This means that objects are implicitly copied in various contexts,and we should understand what ""copying an object"" actually means.Let us consider a simple example:class person{    std::string name;    int age;public:    person(const std::string& name, int age) : name(name), age(age)    {    }};int main(){    person a(""Bjarne Stroustrup"", 60);    person b(a);   // What happens here?    b = a;         // And here?}(If you are puzzled by the name(name), age(age) part,this is called a member initializer list.)Special member functionsWhat does it mean to copy a person object?The main function shows two distinct copying scenarios.The initialization person b(a); is performed by the copy constructor.Its job is to construct a fresh object based on the state of an existing object.The assignment b = a is performed by the copy assignment operator.Its job is generally a little more complicated,because the target object is already in some valid state that needs to be dealt with.Since we declared neither the copy constructor nor the assignment operator (nor the destructor) ourselves,these are implicitly defined for us. Quote from the standard:The [...] copy constructor and copy assignment operator, [...] and destructor are special member functions.[ Note: The implementation will implicitly declare these member functionsfor some class types when the program does not explicitly declare them.The implementation will implicitly define them if they are used. [...] end note ][n3126.pdf section 12 §1]By default, copying an object means copying its members:The implicitly-defined copy constructor for a non-union class X performs a memberwise copy of its subobjects.[n3126.pdf section 12.8 §16]The implicitly-defined copy assignment operator for a non-union class X performs memberwise copy assignmentof its subobjects.[n3126.pdf section 12.8 §30]Implicit definitionsThe implicitly-defined special member functions for person look like this:// 1. copy constructorperson(const person& that) : name(that.name), age(that.age){}// 2. copy assignment operatorperson& operator=(const person& that){    name = that.name;    age = that.age;    return *this;}// 3. destructor~person(){}Memberwise copying is exactly what we want in this case:name and age are copied, so we get a self-contained, independent person object.The implicitly-defined destructor is always empty.This is also fine in this case since we did not acquire any resources in the constructor.The members' destructors are implicitly called after the person destructor is finished:After executing the body of the destructor and destroying any automatic objects allocated within the body,a destructor for class X calls the destructors for X's direct [...] members[n3126.pdf 12.4 §6]Managing resourcesSo when should we declare those special member functions explicitly?When our class manages a resource, that is,when an object of the class is responsible for that resource.That usually means the resource is acquired in the constructor(or passed into the constructor) and released in the destructor.Let us go back in time to pre-standard C++.There was no such thing as std::string, and programmers were in love with pointers.The person class might have looked like this:class person{    char* name;    int age;public:    // the constructor acquires a resource:    // in this case, dynamic memory obtained via new[]    person(const char* the_name, int the_age)    {        name = new char[strlen(the_name) + 1];        strcpy(name, the_name);        age = the_age;    }    // the destructor must release this resource via delete[]    ~person()    {        delete[] name;    }};Even today, people still write classes in this style and get into trouble:""I pushed a person into a vector and now I get crazy memory errors!""Remember that by default, copying an object means copying its members,but copying the name member merely copies a pointer, not the character array it points to!This has several unpleasant effects:Changes via a can be observed via b.Once b is destroyed, a.name is a dangling pointer.If a is destroyed, deleting the dangling pointer yields undefined behavior.Since the assignment does not take into account what name pointed to before the assignment,sooner or later you will get memory leaks all over the place.Explicit definitionsSince memberwise copying does not have the desired effect, we must define the copy constructor and the copy assignment operator explicitly to make deep copies of the character array:// 1. copy constructorperson(const person& that){    name = new char[strlen(that.name) + 1];    strcpy(name, that.name);    age = that.age;}// 2. copy assignment operatorperson& operator=(const person& that){    if (this != &that)    {        delete[] name;        // This is a dangerous point in the flow of execution!        // We have temporarily invalidated the class invariants,        // and the next statement might throw an exception,        // leaving the object in an invalid state :(        name = new char[strlen(that.name) + 1];        strcpy(name, that.name);        age = that.age;    }    return *this;}Note the difference between initialization and assignment:we must tear down the old state before assigning to name to prevent memory leaks.Also, we have to protect against self-assignment of the form x = x.Without that check, delete[] name would delete the array containing the source string,because when you write x = x, both this->name and that.name contain the same pointer.Exception safetyUnfortunately, this solution will fail if new char[...] throws an exception due to memory exhaustion.One possible solution is to introduce a local variable and reorder the statements:// 2. copy assignment operatorperson& operator=(const person& that){    char* local_name = new char[strlen(that.name) + 1];    // If the above statement throws,    // the object is still in the same state as before.    // None of the following statements will throw an exception :)    strcpy(local_name, that.name);    delete[] name;    name = local_name;    age = that.age;    return *this;}This also takes care of self-assignment without an explicit check.An even more robust solution to this problem is the copy-and-swap idiom,but I will not go into the details of exception safety here.I only mentioned exceptions to make the following point: Writing classes that manage resources is hard.Noncopyable resourcesSome resources cannot or should not be copied, such as file handles or mutexes.In that case, simply declare the copy constructor and copy assignment operator as private without giving a definition:private:    person(const person& that);    person& operator=(const person& that);Alternatively, you can inherit from boost::noncopyable or declare them as deleted (in C++11 and above):person(const person& that) = delete;person& operator=(const person& that) = delete;The rule of threeSometimes you need to implement a class that manages a resource.(Never manage multiple resources in a single class,this will only lead to pain.)In that case, remember the rule of three:If you need to explicitly declare either the destructor,copy constructor or copy assignment operator yourself,you probably need to explicitly declare all three of them.(Unfortunately, this ""rule"" is not enforced by the C++ standard or any compiler I am aware of.)The rule of fiveFrom C++11 on, an object has 2 extra special member functions: the move constructor and move assignment. The rule of five states to implement these functions as well.An example with the signatures:class person{    std::string name;    int age;public:    person(const std::string& name, int age);        // Ctor    person(const person &) = default;                // 1/5: Copy Ctor    person(person &&) noexcept = default;            // 4/5: Move Ctor    person& operator=(const person &) = default;     // 2/5: Copy Assignment    person& operator=(person &&) noexcept = default; // 5/5: Move Assignment    ~person() noexcept = default;                    // 3/5: Dtor};The rule of zeroThe rule of 3/5 is also referred to as the rule of 0/3/5. The zero part of the rule states that you are allowed to not write any of the special member functions when creating your class.AdviceMost of the time, you do not need to manage a resource yourself,because an existing class such as std::string already does it for you.Just compare the simple code using a std::string memberto the convoluted and error-prone alternative using a char* and you should be convinced.As long as you stay away from raw pointer members, the rule of three is unlikely to concern your own code."
"data_i","edited Nov 19 '19 at 12:51","
        How can I make a div not larger than its contents?
    ","I have a layout similar to:<div>    <table>    </table></div>I would like for the div to only expand to as wide as my table becomes.","The solution is to set your div to display: inline-block."
"data_i","edited Nov 21 '19 at 16:58","
        How do I declare and initialize an array in Java?
    ","How do I declare and initialize an array in Java?","You can either use array declaration or array literal (but only when you declare and affect the variable right away, array literals cannot be used for re-assigning an array).For primitive types:int[] myIntArray = new int[3];int[] myIntArray = {1, 2, 3};int[] myIntArray = new int[]{1, 2, 3};// Since Java 8. Doc of IntStream: https://docs.oracle.com/javase/8/docs/api/java/util/stream/IntStream.htmlint [] myIntArray = IntStream.range(0, 100).toArray(); // From 0 to 99int [] myIntArray = IntStream.rangeClosed(0, 100).toArray(); // From 0 to 100int [] myIntArray = IntStream.of(12,25,36,85,28,96,47).toArray(); // The order is preserved.int [] myIntArray = IntStream.of(12,25,36,85,28,96,47).sorted().toArray(); // Sort For classes, for example String, it's the same:String[] myStringArray = new String[3];String[] myStringArray = {""a"", ""b"", ""c""};String[] myStringArray = new String[]{""a"", ""b"", ""c""};The third way of initializing is useful when you declare an array first and then initialize it, pass an array as a function argument, or return an array. The explicit type is required.String[] myStringArray;myStringArray = new String[]{""a"", ""b"", ""c""};"
"data_i","edited Jul 17 '22 at 00:42","
        How do I revert all local changes in Git managed project to previous state?
    ","I ran git status which told me everything was up to date and there were no local changes.Then I made several consecutive changes and realized I wanted to throw everything away and get back to my original state. Will this command do it for me?git reset --hard HEAD","To revert changes made to your working copy, do this:git checkout .Or equivalently, for git version >= 2.23:git restore .To revert changes made to the index (i.e., that you have added), do this. Warning this will reset all of your unpushed commits to master!:git resetTo revert a change that you have committed:git revert <commit 1> <commit 2>To remove untracked files (e.g., new files, generated files):git clean -fOr untracked directories (e.g., new or automatically generated directories):git clean -fd"
"data_i","edited Jul 25 '22 at 02:29","
        How do I delete all Git branches which have been merged?
    ","How do I delete branches which have already been merged? Can I delete them all at once, instead of deleting each branch one-by-one?","NOTE: You can add other branches to exclude like master and dev if your workflow has those as a possible ancestor. Usually I branch off of a ""sprint-start"" tag and master, dev and qa are not ancestors.First, list locally-tracking branches that were merged in remote (consider using -r flag to list all remote-tracking branches).git branch --mergedYou might see few branches you don't want to remove. We can add few arguments to skip important branches that we don't want to delete like master or a develop. The following command will skip master branch and anything that has dev in it.git branch --merged| egrep -v ""(^\*|master|main|dev)""If you want to skip, you can add it to the egrep command like the following. The branch skip_branch_name will not be deleted.git branch --merged| egrep -v ""(^\*|master|main|dev|skip_branch_name)""To delete all local branches that are already merged into the currently checked out branch:git branch --merged | egrep -v ""(^\*|master|main|dev)"" | xargs git branch -dYou can see that master and dev are excluded in case they are an ancestor.You can delete a merged local branch with:git branch -d branchnameIf it's not merged, use:git branch -D branchnameTo delete it from the remote use:git push --delete origin branchnamegit push origin :branchname    # for really old gitOnce you delete the branch from the remote, you can prune to get rid of remote tracking branches with:git remote prune originor prune individual remote tracking branches, as the other answer suggests, with:git branch -dr branchname"
"data_i","edited Jul 25 '22 at 04:58","
        See what's in a stash without applying it
    ","How do I see what is inside a stash without actually applying it?","From man git-stash (which can also be obtained via git help stash):The modifications stashed away by this command can be listed with git stash list, inspected with git stash show, and ...show [<stash>]    Show the changes recorded in the stash as a diff between the stashed    state and its original parent. When no <stash> is given, shows the    latest one. By default, the command shows the diffstat, but it will    accept any format known to git diff (e.g., git stash show -p stash@{1}    to view the second most recent stash in patch form).Note: the -p option generates a patch, as per git-diff documentation.List the stashes:git stash listShow the files in the most recent stash:git stash showShow the changes of the most recent stash:git stash show -pShow the changes of the named stash:git stash show -p stash@{1}Or in short:git stash show -p 1 "
"data_i","edited Jul 23 '20 at 15:31","
        How do I parse command line arguments in Bash?
    ","Say, I have a script that gets called with this line:./myscript -vfd ./foo/bar/someFile -o /fizz/someOtherFileor this one:./myscript -v -f -d -o /fizz/someOtherFile ./foo/bar/someFile What's the accepted way of parsing this such that in each case (or some combination of the two) $v, $f, and  $d will all be set to true and $outFile will be equal to /fizz/someOtherFile?","Bash Space-Separated (e.g., --option argument)cat >/tmp/demo-space-separated.sh <<'EOF'#!/bin/bashPOSITIONAL_ARGS=()while [[ $# -gt 0 ]]; do  case $1 in    -e|--extension)      EXTENSION=""$2""      shift # past argument      shift # past value      ;;    -s|--searchpath)      SEARCHPATH=""$2""      shift # past argument      shift # past value      ;;    --default)      DEFAULT=YES      shift # past argument      ;;    -*|--*)      echo ""Unknown option $1""      exit 1      ;;    *)      POSITIONAL_ARGS+=(""$1"") # save positional arg      shift # past argument      ;;  esacdoneset -- ""${POSITIONAL_ARGS[@]}"" # restore positional parametersecho ""FILE EXTENSION  = ${EXTENSION}""echo ""SEARCH PATH     = ${SEARCHPATH}""echo ""DEFAULT         = ${DEFAULT}""echo ""Number files in SEARCH PATH with EXTENSION:"" $(ls -1 ""${SEARCHPATH}""/*.""${EXTENSION}"" | wc -l)if [[ -n $1 ]]; then    echo ""Last line of file specified as non-opt/last argument:""    tail -1 ""$1""fiEOFchmod +x /tmp/demo-space-separated.sh/tmp/demo-space-separated.sh -e conf -s /etc /etc/hostsOutput from copy-pasting the block aboveFILE EXTENSION  = confSEARCH PATH     = /etcDEFAULT         =Number files in SEARCH PATH with EXTENSION: 14Last line of file specified as non-opt/last argument:#93.184.216.34    example.comUsagedemo-space-separated.sh -e conf -s /etc /etc/hostsBash Equals-Separated (e.g., --option=argument)cat >/tmp/demo-equals-separated.sh <<'EOF'#!/bin/bashfor i in ""$@""; do  case $i in    -e=*|--extension=*)      EXTENSION=""${i#*=}""      shift # past argument=value      ;;    -s=*|--searchpath=*)      SEARCHPATH=""${i#*=}""      shift # past argument=value      ;;    --default)      DEFAULT=YES      shift # past argument with no value      ;;    -*|--*)      echo ""Unknown option $i""      exit 1      ;;    *)      ;;  esacdoneecho ""FILE EXTENSION  = ${EXTENSION}""echo ""SEARCH PATH     = ${SEARCHPATH}""echo ""DEFAULT         = ${DEFAULT}""echo ""Number files in SEARCH PATH with EXTENSION:"" $(ls -1 ""${SEARCHPATH}""/*.""${EXTENSION}"" | wc -l)if [[ -n $1 ]]; then    echo ""Last line of file specified as non-opt/last argument:""    tail -1 $1fiEOFchmod +x /tmp/demo-equals-separated.sh/tmp/demo-equals-separated.sh -e=conf -s=/etc /etc/hostsOutput from copy-pasting the block aboveFILE EXTENSION  = confSEARCH PATH     = /etcDEFAULT         =Number files in SEARCH PATH with EXTENSION: 14Last line of file specified as non-opt/last argument:#93.184.216.34    example.comUsagedemo-equals-separated.sh -e=conf -s=/etc /etc/hostsTo better understand ${i#*=} search for ""Substring Removal"" in this guide. It is functionally equivalent to `sed 's/[^=]*=//' <<< ""$i""` which calls a needless subprocess or `echo ""$i"" | sed 's/[^=]*=//'` which calls two needless subprocesses.Using bash with getopt[s]getopt(1) limitations (older, relatively-recent getopt versions):can't handle arguments that are empty stringscan't handle arguments with embedded whitespaceMore recent getopt versions don't have these limitations. For more information, see these docs.POSIX getoptsAdditionally, the POSIX shell and others offer getopts which doen't have these limitations. I've included a simplistic getopts example.cat >/tmp/demo-getopts.sh <<'EOF'#!/bin/sh# A POSIX variableOPTIND=1         # Reset in case getopts has been used previously in the shell.# Initialize our own variables:output_file=""""verbose=0while getopts ""h?vf:"" opt; do  case ""$opt"" in    h|\?)      show_help      exit 0      ;;    v)  verbose=1      ;;    f)  output_file=$OPTARG      ;;  esacdoneshift $((OPTIND-1))[ ""${1:-}"" = ""--"" ] && shiftecho ""verbose=$verbose, output_file='$output_file', Leftovers: $@""EOFchmod +x /tmp/demo-getopts.sh/tmp/demo-getopts.sh -vf /etc/hosts foo barOutput from copy-pasting the block aboveverbose=1, output_file='/etc/hosts', Leftovers: foo barUsagedemo-getopts.sh -vf /etc/hosts foo barThe advantages of getopts are:It's more portable, and will work in other shells like dash.It can handle multiple single options like -vf filename in the typical Unix way, automatically.The disadvantage of getopts is that it can only handle short options (-h, not --help) without additional code.There is a getopts tutorial which explains what all of the syntax and variables mean.  In bash, there is also help getopts, which might be informative."
"data_i","edited Apr 01 '22 at 12:19","
        Static class variables and methods in Python
    ","How do I create static class variables or methods in Python?","Variables declared inside the class definition, but not inside a method are class or static variables:>>> class MyClass:...     i = 3...>>> MyClass.i3 As @millerdev points out, this creates a class-level i variable, but this is distinct from any instance-level i variable, so you could have>>> m = MyClass()>>> m.i = 4>>> MyClass.i, m.i>>> (3, 4)This is different from C++ and Java, but not so different from C#, where a static member can't be accessed using a reference to an instance.See what the Python tutorial has to say on the subject of classes and class objects.@Steve Johnson has already answered regarding static methods, also documented under ""Built-in Functions"" in the Python Library Reference.class C:    @staticmethod    def f(arg1, arg2, ...): ...@beidy recommends classmethods over staticmethod, as the method then receives the class type as the first argument."
"data_i","edited Nov 06 '21 at 14:38","
        Why are elementwise additions much faster in separate loops than in a combined loop?
    ","Suppose a1, b1, c1, and d1 point to heap memory, and my numerical code has the following core loop.const int n = 100000;for (int j = 0; j < n; j++) {    a1[j] += b1[j];    c1[j] += d1[j];}This loop is executed 10,000 times via another outer for loop. To speed it up, I changed the code to:for (int j = 0; j < n; j++) {    a1[j] += b1[j];}for (int j = 0; j < n; j++) {    c1[j] += d1[j];}Compiled on Microsoft Visual C++ 10.0 with full optimization and SSE2 enabled for 32-bit on a Intel Core 2 Duo (x64), the first example takes 5.5 seconds and the double-loop example takes only 1.9 seconds.Disassembly for the first loop basically looks like this (this block is repeated about five times in the full program):movsd       xmm0,mmword ptr [edx+18h]addsd       xmm0,mmword ptr [ecx+20h]movsd       mmword ptr [ecx+20h],xmm0movsd       xmm0,mmword ptr [esi+10h]addsd       xmm0,mmword ptr [eax+30h]movsd       mmword ptr [eax+30h],xmm0movsd       xmm0,mmword ptr [edx+20h]addsd       xmm0,mmword ptr [ecx+28h]movsd       mmword ptr [ecx+28h],xmm0movsd       xmm0,mmword ptr [esi+18h]addsd       xmm0,mmword ptr [eax+38h]Each loop of the double loop example produces this code (the following block is repeated about three times):addsd       xmm0,mmword ptr [eax+28h]movsd       mmword ptr [eax+28h],xmm0movsd       xmm0,mmword ptr [ecx+20h]addsd       xmm0,mmword ptr [eax+30h]movsd       mmword ptr [eax+30h],xmm0movsd       xmm0,mmword ptr [ecx+28h]addsd       xmm0,mmword ptr [eax+38h]movsd       mmword ptr [eax+38h],xmm0movsd       xmm0,mmword ptr [ecx+30h]addsd       xmm0,mmword ptr [eax+40h]movsd       mmword ptr [eax+40h],xmm0The question turned out to be of no relevance, as the behavior severely depends on the sizes of the arrays (n) and the CPU cache. So if there is further interest, I rephrase the question:Could you provide some solid insight into the details that lead to the different cache behaviors as illustrated by the five regions on the following graph?It might also be interesting to point out the differences between CPU/cache architectures, by providing a similar graph for these CPUs.Here is the full code. It uses TBB Tick_Count for higher resolution timing, which can be disabled by not defining the TBB_TIMING Macro:#include <iostream>#include <iomanip>#include <cmath>#include <string>//#define TBB_TIMING#ifdef TBB_TIMING   #include <tbb/tick_count.h>using tbb::tick_count;#else#include <time.h>#endifusing namespace std;//#define preallocate_memory new_contenum { new_cont, new_sep };double *a1, *b1, *c1, *d1;void allo(int cont, int n){    switch(cont) {      case new_cont:        a1 = new double[n*4];        b1 = a1 + n;        c1 = b1 + n;        d1 = c1 + n;        break;      case new_sep:        a1 = new double[n];        b1 = new double[n];        c1 = new double[n];        d1 = new double[n];        break;    }    for (int i = 0; i < n; i++) {        a1[i] = 1.0;        d1[i] = 1.0;        c1[i] = 1.0;        b1[i] = 1.0;    }}void ff(int cont){    switch(cont){      case new_sep:        delete[] b1;        delete[] c1;        delete[] d1;      case new_cont:        delete[] a1;    }}double plain(int n, int m, int cont, int loops){#ifndef preallocate_memory    allo(cont,n);#endif#ifdef TBB_TIMING       tick_count t0 = tick_count::now();#else    clock_t start = clock();#endif            if (loops == 1) {        for (int i = 0; i < m; i++) {            for (int j = 0; j < n; j++){                a1[j] += b1[j];                c1[j] += d1[j];            }        }    } else {        for (int i = 0; i < m; i++) {            for (int j = 0; j < n; j++) {                a1[j] += b1[j];            }            for (int j = 0; j < n; j++) {                c1[j] += d1[j];            }        }    }    double ret;#ifdef TBB_TIMING       tick_count t1 = tick_count::now();    ret = 2.0*double(n)*double(m)/(t1-t0).seconds();#else    clock_t end = clock();    ret = 2.0*double(n)*double(m)/(double)(end - start) *double(CLOCKS_PER_SEC);#endif    #ifndef preallocate_memory    ff(cont);#endif    return ret;}void main(){       freopen(""C:\\test.csv"", ""w"", stdout);    char *s = "" "";    string na[2] ={""new_cont"", ""new_sep""};    cout << ""n"";    for (int j = 0; j < 2; j++)        for (int i = 1; i <= 2; i++)#ifdef preallocate_memory            cout << s << i << ""_loops_"" << na[preallocate_memory];#else            cout << s << i << ""_loops_"" << na[j];#endif                cout << endl;    long long nmax = 1000000;#ifdef preallocate_memory    allo(preallocate_memory, nmax);#endif        for (long long n = 1L; n < nmax; n = max(n+1, long long(n*1.2)))    {        const long long m = 10000000/n;        cout << n;        for (int j = 0; j < 2; j++)            for (int i = 1; i <= 2; i++)                cout << s << plain(n, m, j, i);        cout << endl;    }}It shows FLOP/s for different values of n.","Upon further analysis of this, I believe this is (at least partially) caused by the data alignment of the four-pointers. This will cause some level of cache bank/way conflicts.If I've guessed correctly on how you are allocating your arrays, they are likely to be aligned to the page line.This means that all your accesses in each loop will fall on the same cache way. However, Intel processors have had 8-way L1 cache associativity for a while. But in reality, the performance isn't completely uniform. Accessing 4-ways is still slower than say 2-ways.EDIT: It does in fact look like you are allocating all the arrays separately.Usually when such large allocations are requested, the allocator will request fresh pages from the OS. Therefore, there is a high chance that large allocations will appear at the same offset from a page-boundary.Here's the test code:int main(){    const int n = 100000;#ifdef ALLOCATE_SEPERATE    double *a1 = (double*)malloc(n * sizeof(double));    double *b1 = (double*)malloc(n * sizeof(double));    double *c1 = (double*)malloc(n * sizeof(double));    double *d1 = (double*)malloc(n * sizeof(double));#else    double *a1 = (double*)malloc(n * sizeof(double) * 4);    double *b1 = a1 + n;    double *c1 = b1 + n;    double *d1 = c1 + n;#endif    //  Zero the data to prevent any chance of denormals.    memset(a1,0,n * sizeof(double));    memset(b1,0,n * sizeof(double));    memset(c1,0,n * sizeof(double));    memset(d1,0,n * sizeof(double));    //  Print the addresses    cout << a1 << endl;    cout << b1 << endl;    cout << c1 << endl;    cout << d1 << endl;    clock_t start = clock();    int c = 0;    while (c++ < 10000){#if ONE_LOOP        for(int j=0;j<n;j++){            a1[j] += b1[j];            c1[j] += d1[j];        }#else        for(int j=0;j<n;j++){            a1[j] += b1[j];        }        for(int j=0;j<n;j++){            c1[j] += d1[j];        }#endif    }    clock_t end = clock();    cout << ""seconds = "" << (double)(end - start) / CLOCKS_PER_SEC << endl;    system(""pause"");    return 0;}Benchmark Results:EDIT: Results on an actual Core 2 architecture machine:2 x Intel Xeon X5482 Harpertown @ 3.2 GHz:#define ALLOCATE_SEPERATE#define ONE_LOOP00600020006D0020007A002000870020seconds = 6.206#define ALLOCATE_SEPERATE//#define ONE_LOOP005E0020006B00200078002000850020seconds = 2.116//#define ALLOCATE_SEPERATE#define ONE_LOOP0057002000633520006F6A20007B9F20seconds = 1.894//#define ALLOCATE_SEPERATE//#define ONE_LOOP008C00200098352000A46A2000B09F20seconds = 1.993Observations:6.206 seconds with one loop and 2.116 seconds with two loops. This reproduces the OP's results exactly.In the first two tests, the arrays are allocated separately. You'll notice that they all have the same alignment relative to the page.In the second two tests, the arrays are packed together to break that alignment. Here you'll notice both loops are faster. Furthermore, the second (double) loop is now the slower one as you would normally expect.As @Stephen Cannon points out in the comments, there is a very likely possibility that this alignment causes false aliasing in the load/store units or the cache. I Googled around for this and found that Intel actually has a hardware counter for partial address aliasing stalls:http://software.intel.com/sites/products/documentation/doclib/stdxe/2013/~amplifierxe/pmw_dp/events/partial_address_alias.html5 Regions - ExplanationsRegion 1:This one is easy. The dataset is so small that the performance is dominated by overhead like looping and branching.Region 2:Here, as the data sizes increase, the amount of relative overhead goes down and the performance ""saturates"". Here two loops is slower because it has twice as much loop and branching overhead.I'm not sure exactly what's going on here... Alignment could still play an effect as Agner Fog mentions cache bank conflicts. (That link is about Sandy Bridge, but the idea should still be applicable to Core 2.)Region 3:At this point, the data no longer fits in the L1 cache. So performance is capped by the L1 <-> L2 cache bandwidth.Region 4:The performance drop in the single-loop is what we are observing. And as mentioned, this is due to the alignment which (most likely) causes false aliasing stalls in the processor load/store units.However, in order for false aliasing to occur, there must be a large enough stride between the datasets. This is why you don't see this in region 3.Region 5:At this point, nothing fits in the cache. So you're bound by memory bandwidth."
"data_i","edited Oct 13 '21 at 15:32","
        How do I chop/slice/trim off last character in string using Javascript?
    ","I have a string, 12345.00, and I would like it to return 12345.0.I have looked at trim, but it looks like it is only trimming whitespace and slice which I don't see how this would work. Any suggestions?","You can use the substring function:let str = ""12345.00"";str = str.substring(0, str.length - 1);console.log(str);This is the accepted answer, but as per the conversations below, the slice syntax is much clearer:let str = ""12345.00"";str = str.slice(0, -1); console.log(str);"
"data_i","edited Apr 18 '22 at 13:49","
        Generating random whole numbers in JavaScript in a specific range
    ","How can I generate random whole numbers between two specified variables in JavaScript, e.g. x = 4 and y = 8 would output any of 4, 5, 6, 7, 8?","There are some examples on the Mozilla Developer Network page:/** * Returns a random number between min (inclusive) and max (exclusive) */function getRandomArbitrary(min, max) {    return Math.random() * (max - min) + min;}/** * Returns a random integer between min (inclusive) and max (inclusive). * The value is no lower than min (or the next integer greater than min * if min isn't an integer) and no greater than max (or the next integer * lower than max if max isn't an integer). * Using Math.round() will give you a non-uniform distribution! */function getRandomInt(min, max) {    min = Math.ceil(min);    max = Math.floor(max);    return Math.floor(Math.random() * (max - min + 1)) + min;}Here's the logic behind it. It's a simple rule of three:Math.random() returns a Number between 0 (inclusive) and 1 (exclusive). So we have an interval like this:[0 .................................... 1)Now, we'd like a number between min (inclusive) and max (exclusive):[0 .................................... 1)[min .................................. max)We can use the Math.random to get the correspondent in the [min, max) interval. But, first we should factor a little bit the problem by subtracting min from the second interval:[0 .................................... 1)[min - min ............................ max - min)This gives:[0 .................................... 1)[0 .................................... max - min)We may now apply Math.random and then calculate the correspondent. Let's choose a random number:                Math.random()                    |[0 .................................... 1)[0 .................................... max - min)                    |                    x (what we need)So, in order to find x, we would do:x = Math.random() * (max - min);Don't forget to add min back, so that we get a number in the [min, max) interval:x = Math.random() * (max - min) + min;That was the first function from MDN. The second one, returns an integer between min and max, both inclusive.Now for getting integers, you could use round, ceil or floor.You could use Math.round(Math.random() * (max - min)) + min, this however gives a non-even distribution. Both, min and max only have approximately half the chance to roll:min...min+0.5...min+1...min+1.5   ...    max-0.5....max└───┬───┘└────────┬───────┘└───── ... ─────┘└───┬──┘   ← Math.round()   min          min+1                          maxWith max excluded from the interval, it has an even less chance to roll than min.With Math.floor(Math.random() * (max - min +1)) + min you have a perfectly even distribution.min.... min+1... min+2 ... max-1... max.... max+1 (is excluded from interval)|        |        |         |        |        |└───┬───┘└───┬───┘└─── ... ┘└───┬───┘└───┬───┘   ← Math.floor()   min     min+1               max-1    maxYou can't use ceil() and -1 in that equation because max now had a slightly less chance to roll, but you can roll the (unwanted) min-1 result too."
"data_i","asked Dec 12 '10 at 12:44","
        What are the basic rules and idioms for operator overloading?
    ","Note: The answers were given in a specific order, but since many users sort answers according to votes, rather than the time they were given, here's an index of the answers in the order in which they make the most sense:The General Syntax of operator overloading in C++The Three Basic Rules of Operator Overloading in C++The Decision between Member and Non-memberCommon operators to overloadAssignment OperatorInput and Output OperatorsFunction call operatorComparison operatorsArithmetic OperatorsArray SubscriptingOperators for Pointer-like TypesConversion OperatorsOverloading new and delete(Note: This is meant to be an entry to Stack Overflow's C++ FAQ. If you want to critique the idea of providing an FAQ in this form, then the posting on meta that started all this would be the place to do that. Answers to that question are monitored in the C++ chatroom, where the FAQ idea started in the first place, so your answer is very likely to get read by those who came up with the idea.)","Common operators to overloadMost of the work in overloading operators is boiler-plate code. That is little wonder, since operators are merely syntactic sugar, their actual work could be done by (and often is forwarded to) plain functions. But it is important that you get this boiler-plate code right. If you fail, either your operator’s code won’t compile or your users’ code won’t compile or your users’ code will behave surprisingly.Assignment OperatorThere's a lot to be said about assignment. However, most of it has already been said in GMan's famous Copy-And-Swap FAQ, so I'll skip most of it here, only listing the perfect assignment operator for reference:X& X::operator=(X rhs){  swap(rhs);  return *this;}Bitshift Operators (used for Stream I/O)The bitshift operators << and >>, although still used in hardware interfacing for the bit-manipulation functions they inherit from C, have become more prevalent as overloaded stream input and output operators in most applications.  For guidance overloading as bit-manipulation operators, see the section below on Binary Arithmetic Operators.  For implementing your own custom format and parsing logic when your object is used with iostreams, continue.The stream operators, among the most commonly overloaded operators, are binary infix operators for which the syntax specifies no restriction on whether they should be members or non-members.Since they change their left argument (they alter the stream’s state), they should, according to the rules of thumb, be implemented as members of their left operand’s type. However, their left operands are streams from the standard library, and while most of the stream output and input operators defined by the standard library are indeed defined as members of the stream classes, when you implement output and input operations for your own types, you cannot change the standard library’s stream types. That’s why you need to implement these operators for your own types as non-member functions.The canonical forms of the two are these:std::ostream& operator<<(std::ostream& os, const T& obj){  // write obj to stream  return os;}std::istream& operator>>(std::istream& is, T& obj){  // read obj from stream  if( /* no valid object of T found in stream */ )    is.setstate(std::ios::failbit);  return is;}When implementing operator>>, manually setting the stream’s state is only necessary when the reading itself succeeded, but the result is not what would be expected.Function call operatorThe function call operator, used to create function objects, also known as functors, must be defined as a member function, so it always has the implicit this argument of member functions. Other than this, it can be overloaded to take any number of additional arguments, including zero.Here's an example of the syntax:class foo {public:    // Overloaded call operator    int operator()(const std::string& y) {        // ...    }};Usage:foo f;int a = f(""hello"");Throughout the C++ standard library, function objects are always copied. Your own function objects should therefore be cheap to copy. If a function object absolutely needs to use data which is expensive to copy, it is better to store that data elsewhere and have the function object refer to it.Comparison operatorsThe binary infix comparison operators should, according to the rules of thumb, be implemented as non-member functions1. The unary prefix negation ! should (according to the same rules) be implemented as a member function. (but it is usually not a good idea to overload it.)The standard library’s algorithms (e.g. std::sort()) and types (e.g. std::map) will always only expect operator< to be present. However, the users of your type will expect all the other operators to be present, too, so if you define operator<, be sure to follow the third fundamental rule of operator overloading and also define all the other boolean comparison operators. The canonical way to implement them is this:inline bool operator==(const X& lhs, const X& rhs){ /* do actual comparison */ }inline bool operator!=(const X& lhs, const X& rhs){return !operator==(lhs,rhs);}inline bool operator< (const X& lhs, const X& rhs){ /* do actual comparison */ }inline bool operator> (const X& lhs, const X& rhs){return  operator< (rhs,lhs);}inline bool operator<=(const X& lhs, const X& rhs){return !operator> (lhs,rhs);}inline bool operator>=(const X& lhs, const X& rhs){return !operator< (lhs,rhs);}The important thing to note here is that only two of these operators actually do anything, the others are just forwarding their arguments to either of these two to do the actual work.The syntax for overloading the remaining binary boolean operators (||, &&) follows the rules of the comparison operators. However, it is very unlikely that you would find a reasonable use case for these2.1As with all rules of thumb, sometimes there might be reasons to break this one, too. If so, do not forget that the left-hand operand of the binary comparison operators, which for member functions will be *this, needs to be const, too. So a comparison operator implemented as a member function would have to have this signature:bool operator<(const X& rhs) const { /* do actual comparison with *this */ }(Note the const at the end.)2It should be noted that the built-in version of || and && use shortcut semantics. While the user defined ones (because they are syntactic sugar for method calls) do not use shortcut semantics. User will expect these operators to have shortcut semantics, and their code may depend on it, Therefore it is highly advised NEVER to define them.Arithmetic OperatorsUnary arithmetic operatorsThe unary increment and decrement operators come in both prefix and postfix flavor. To tell one from the other, the postfix variants take an additional dummy int argument. If you overload increment or decrement, be sure to always implement both prefix and postfix versions.Here is the canonical implementation of increment, decrement follows the same rules:class X {  X& operator++()  {    // do actual increment    return *this;  }  X operator++(int)  {    X tmp(*this);    operator++();    return tmp;  }};Note that the postfix variant is implemented in terms of prefix. Also note that postfix does an extra copy.2Overloading unary minus and plus is not very common and probably best avoided. If needed, they should probably be overloaded as member functions. 2Also note that the postfix variant does more work and is therefore less efficient to use than the prefix variant. This is a good reason to generally prefer prefix increment over postfix increment. While compilers can usually optimize away the additional work of postfix increment for built-in types, they might not be able to do the same for user-defined types (which could be something as innocently looking as a list iterator). Once you got used to do i++, it becomes very hard to remember to do ++i instead when i is not of a built-in type (plus you'd have to change code when changing a type), so it is better to make a habit of always using prefix increment, unless postfix is explicitly needed.Binary arithmetic operatorsFor the binary arithmetic operators, do not forget to obey the third basic rule operator overloading: If you provide +, also provide +=, if you provide -, do not omit -=, etc. Andrew Koenig is said to have been the first to observe that the compound assignment operators can be used as a base for their non-compound counterparts. That is, operator + is implemented in terms of +=, - is implemented in terms of -= etc.According to our rules of thumb, + and its companions should be non-members, while their compound assignment counterparts (+= etc.), changing their left argument, should be a member. Here is the exemplary code for += and +; the other binary arithmetic operators should be implemented in the same way:class X {  X& operator+=(const X& rhs)  {    // actual addition of rhs to *this    return *this;  }};inline X operator+(X lhs, const X& rhs){  lhs += rhs;  return lhs;}operator+= returns its result per reference, while operator+ returns a copy of its result. Of course, returning a reference is usually more efficient than returning a copy, but in the case of operator+, there is no way around the copying. When you write a + b, you expect the result to be a new value, which is why operator+ has to return a new value.3Also note that operator+ takes its left operand by copy rather than by const reference. The reason for this is the same as the reason giving for operator= taking its argument per copy.The bit manipulation operators ~ & | ^ << >> should be implemented in the same way as the arithmetic operators. However, (except for overloading << and >> for output and input) there are very few reasonable use cases for overloading these.3Again, the lesson to be taken from this is that a += b is, in general, more efficient than a + b and should be preferred if possible.Array SubscriptingThe array subscript operator is a binary operator which must be implemented as a class member. It is used for container-like types that allow access to their data elements by a key.The canonical form of providing these is this:class X {        value_type& operator[](index_type idx);  const value_type& operator[](index_type idx) const;  // ...};Unless you do not want users of your class to be able to change data elements returned by operator[] (in which case you can omit the non-const variant), you should always provide both variants of the operator.If value_type is known to refer to a built-in type, the const variant of the operator should better return a copy instead of a const reference:class X {  value_type& operator[](index_type idx);  value_type  operator[](index_type idx) const;  // ...};Operators for Pointer-like TypesFor defining your own iterators or smart pointers, you have to overload the unary prefix dereference operator * and the binary infix pointer member access operator ->:class my_ptr {        value_type& operator*();  const value_type& operator*() const;        value_type* operator->();  const value_type* operator->() const;};Note that these, too, will almost always need both a const and a non-const version.For the -> operator, if value_type is of class (or struct or union) type, another operator->() is called recursively, until an operator->() returns a value of non-class type.The unary address-of operator should never be overloaded.For operator->*() see this question. It's rarely used and thus rarely ever overloaded. In fact, even iterators do not overload it.Continue to Conversion Operators"
"data_i","edited Aug 26 '22 at 20:36","
        How do I delete a file from a Git repository?
    ","How can I delete ""file1.txt"" from my repository?","Use git rm.If you want to remove the file from the Git repository and the filesystem, use:git rm file1.txtgit commit -m ""remove file1.txt""But if you want to remove the file only from the Git repository and not remove it from the filesystem, use:  git rm --cached file1.txtgit commit -m ""remove file1.txt""And to push changes to remote repogit push origin branch_name"
"data_i","edited Feb 27 '19 at 14:26","
        What is JSONP, and why was it created?
    ","I understand JSON, but not JSONP. Wikipedia's document on JSON is (was) the top search result for JSONP. It says this:JSONP or ""JSON with padding"" is a JSON extension wherein a prefix is specified as an input argument of the call itself.Huh? What call? That doesn't make any sense to me. JSON is a data format. There's no call.The 2nd search result is from some guy named Remy, who writes this about JSONP:JSONP is script tag injection, passing the response from the server in to a user specified function.I can sort of understand that, but it's still not making any sense.So what is JSONP? Why was it created (what problem does it solve)? And why would I use it? Addendum: I've just created a new page for JSONP on Wikipedia; it now has a clear and thorough description of JSONP, based on jvenema's answer.","It's actually not too complicated...Say you're on domain example.com, and you want to make a request to domain example.net. To do so, you need to cross domain boundaries, a no-no in most of browserland. The one item that bypasses this limitation is <script> tags. When you use a script tag, the domain limitation is ignored, but under normal circumstances, you can't really do anything with the results, the script just gets evaluated.Enter JSONP. When you make your request to a server that is JSONP enabled, you pass a special parameter that tells the server a little bit about your page. That way, the server is able to nicely wrap up its response in a way that your page can handle. For example, say the server expects a parameter called callback to enable its JSONP capabilities. Then your request would look like:http://www.example.net/sample.aspx?callback=mycallbackWithout JSONP, this might return some basic JavaScript object, like so:{ foo: 'bar' }However, with JSONP, when the server receives the ""callback"" parameter, it wraps up the result a little differently, returning something like this:mycallback({ foo: 'bar' });As you can see, it will now invoke the method you specified. So, in your page, you define the callback function:mycallback = function(data){  alert(data.foo);};And now, when the script is loaded, it'll be evaluated, and your function will be executed. Voila, cross-domain requests!It's also worth noting the one major issue with JSONP: you lose a lot of control of the request. For example, there is no ""nice"" way to get proper failure codes back. As a result, you end up using timers to monitor the request, etc, which is always a bit suspect. The proposition for JSONRequest is a great solution to allowing cross domain scripting, maintaining security, and allowing proper control of the request.These days (2015), CORS is the recommended approach vs. JSONRequest. JSONP is still useful for older browser support, but given the security implications, unless you have no choice CORS is the better choice."
"data_i","edited May 07 '20 at 08:41","
        How to get the children of the $(this) selector?
    ","I have a layout similar to this:<div id=""...""><img src=""...""></div>and would like to use a jQuery selector to select the child img inside the div on click.To get the div, I've got this selector:$(this)How can I get the child img using a selector?","The jQuery constructor accepts a 2nd parameter called context which can be used to override the context of the selection. jQuery(""img"", this);Which is the same as using .find() like this:jQuery(this).find(""img"");If the imgs you desire are only direct descendants of the clicked element, you can also use .children():jQuery(this).children(""img"");"
"data_i","edited Jul 25 '22 at 02:37","
        Branch from a previous commit using Git
    ","If I have N commits, how do I branch from the N-3 commit?","Create the branch using a commit hash:git branch branch_name <commit-hash>Or by using a symbolic reference:git branch branch_name HEAD~3To checkout the branch while creating it, use:git checkout -b branch_name <commit-hash or HEAD~3>"
"data_i","edited Jul 25 '22 at 02:57","
        Make .gitignore ignore everything except a few files
    ","I understand that a .gitignore file cloaks specified files from Git's version control.How do I tell .gitignore to ignore everything except the files I'm tracking with Git? Something like:# Ignore everything:*# Do not ignore these files:script.pltemplate.latex","An optional prefix ! which negates the pattern; any matching file excluded by  a previous pattern will become included again. If a negated pattern matches,  this will override lower precedence patterns sources.# Ignore everything*# But not these files...!.gitignore!script.pl!template.latex# etc...# ...even if they are in subdirectories!*/# if the files to be tracked are in subdirectories!*/a/b/file1.txt!*/a/b/c/*"
"data_i","edited Jun 01 '13 at 21:34","
        What's the difference between SCSS and Sass?
    ","From what I've been reading, Sass is a language that makes CSS more powerful with variable and math support. What's the difference with SCSS? Is it supposed to be the same language? Similar? Different?","Sass is a CSS pre-processor with syntax advancements. Style sheets in the advanced syntax are processed by the program, and turned into regular CSS style sheets. However, they do not extend the CSS standard itself.CSS variables are supported and can be utilized but not as well as pre-processor variables.For the difference between SCSS and Sass, this text on the Sass documentation page should answer the question:There are two syntaxes available for Sass. The first, known as SCSS (Sassy CSS) and used throughout this reference, is an extension of the syntax of CSS. This means that every valid CSS stylesheet is a valid SCSS file with the same meaning. This syntax is enhanced with the Sass features described below. Files using this syntax have the .scss extension.The second and older syntax, known as the indented syntax (or sometimes just “Sass”), provides a more concise way of writing CSS. It uses indentation rather than brackets to indicate nesting of selectors, and newlines rather than semicolons to separate properties. Files using this syntax have the .sass extension.However, all this works only with the Sass pre-compiler which in the end creates CSS. It is not an extension to the CSS standard itself."
"data_i","edited Jan 18 '22 at 12:46","
        How can I guarantee that my enums definition doesn't change in JavaScript?
    ","Would the following make the objects fulfil all characteristics that enums have in JavaScript? Something like:my.namespace.ColorEnum = {  RED : 0,  GREEN : 1,  BLUE : 2}// later onif(currentColor == my.namespace.ColorEnum.RED) {  // whatever}Or is there some other way I can do this?","Since 1.8.5 it's possible to seal and freeze the object, so define the above as:const DaysEnum = Object.freeze({""monday"":1, ""tuesday"":2, ""wednesday"":3, ...})orconst DaysEnum = {""monday"":1, ""tuesday"":2, ""wednesday"":3, ...}Object.freeze(DaysEnum)and voila! JS enums.However, this doesn't prevent you from assigning an undesired value to a variable, which is often the main goal of enums:let day = DaysEnum.tuesdayday = 298832342 // goes through without any errorsOne way to ensure a stronger degree of type safety (with enums or otherwise) is to use a tool like TypeScript or Flow.Quotes aren't needed but I kept them for consistency."
"data_i","edited Jun 09 '20 at 09:02","
        Get the size of the screen, current web page and browser window
    ","How can I get windowWidth, windowHeight, pageWidth, pageHeight, screenWidth, screenHeight, pageX, pageY, screenX, screenY which will work in all major browsers?","You can get the size of the window or document with jQuery:// Size of browser viewport.$(window).height();$(window).width();// Size of HTML document (same as pageHeight/pageWidth in screenshot).$(document).height();$(document).width();For screen size you can use the screen object:window.screen.height;window.screen.width;"
"data_i","edited Jul 10 '22 at 21:38","
        Pull latest changes for all git submodules
    ","We're using git submodules to manage a couple of large projects that have dependencies on many other libraries we've developed. Each library is a separate repo brought into the dependent project as a submodule. During development, we often want to just go grab the latest version of every dependent submodule.How do I pull the latest changes for all git submodules?","If it's the first time you check-out a repo you need to use --init first:git submodule update --init --recursiveFor git 1.8.2 or above, the option --remote was added to support updating to latest tips of remote branches:git submodule update --recursive --remoteThis has the added benefit of respecting any ""non default"" branches specified in the .gitmodules or .git/config files (if you happen to have any, default is origin/master, in which case some of the other answers here would work as well).For git 1.7.3 or above you can use (but the below gotchas around what update does still apply):git submodule update --recursiveor:git pull --recurse-submodulesif you want to pull your submodules to latest commits instead of the current commit the repo points to.See git-submodule(1) for details"
"data_i","edited Jul 11 '16 at 18:33","
        Difference between decimal, float and double in .NET?
    ","What is the difference between decimal, float and double in .NET?When would someone use one of these?","float and double are floating binary point types (float is 32-bit; double is 64-bit). In other words, they represent a number like this:10001.10010110011The binary number and the location of the binary point are both encoded within the value.decimal is a floating decimal point type. In other words, they represent a number like this:12345.65789Again, the number and the location of the decimal point are both encoded within the value – that's what makes decimal still a floating point type instead of a fixed point type.The important thing to note is that humans are used to representing non-integers in a decimal form, and expect exact results in decimal representations; not all decimal numbers are exactly representable in binary floating point – 0.1, for example – so if you use a binary floating point value you'll actually get an approximation to 0.1. You'll still get approximations when using a floating decimal point as well – the result of dividing 1 by 3 can't be exactly represented, for example.As for what to use when:For values which are ""naturally exact decimals"" it's good to use decimal. This is usually suitable for any concepts invented by humans: financial values are the most obvious example, but there are others too. Consider the score given to divers or ice skaters, for example.For values which are more artefacts of nature which can't really be measured exactly anyway, float/double are more appropriate. For example, scientific data would usually be represented in this form. Here, the original values won't be ""decimally accurate"" to start with, so it's not important for the expected results to maintain the ""decimal accuracy"". Floating binary point types are much faster to work with than decimals."
"data_i","edited Apr 30 '22 at 08:13","
        Generate random number between two numbers in JavaScript
    ","Is there a way to generate a random number in a specified range with JavaScript ?For example: a specified range from 1 to 6 were the random number could be either 1, 2, 3, 4, 5, or 6.","function randomIntFromInterval(min, max) { // min and max included   return Math.floor(Math.random() * (max - min + 1) + min)}const rndInt = randomIntFromInterval(1, 6)console.log(rndInt)What it does ""extra"" is it allows random intervals that do not start with 1.So you can get a random number from 10 to 15 for example. Flexibility."
"data_i","edited Oct 29 '19 at 09:54","
        Indent multiple lines quickly in vi
    ","It should be trivial, and it might even be in the help, but I can't figure out how to navigate it. How do I indent multiple lines quickly in vi?","Use the > command. To indent five lines, 5>>. To mark a block of lines and indent it, Vjj> to indent three lines (Vim only). To indent a curly-braces block, put your cursor on one of the curly braces and use >% or from anywhere inside block use >iB.If you’re copying blocks of text around and need to align the indent of a block in its new location, use ]p instead of just p. This aligns the pasted block with the surrounding text.Also, the shiftwidth setting allows you to control how many spaces to indent."
"data_i","edited Aug 20 '20 at 20:39","
        $(document).ready equivalent without jQuery
    ","I have a script that uses $(document).ready, but it doesn't use anything else from jQuery. I'd like to lighten it up by removing the jQuery dependency.How can I implement my own $(document).ready functionality without using jQuery? I know that  using window.onload will not be the same, as window.onload fires after all images, frames, etc. have been loaded.","There is a standards based replacement,DOMContentLoaded that is supported by over 99% of browsers, though not IE8:document.addEventListener(""DOMContentLoaded"", function(event) {   //do work});jQuery's native function is much more complicated than just window.onload, as depicted below.function bindReady(){    if ( readyBound ) return;    readyBound = true;    // Mozilla, Opera and webkit nightlies currently support this event    if ( document.addEventListener ) {        // Use the handy event callback        document.addEventListener( ""DOMContentLoaded"", function(){            document.removeEventListener( ""DOMContentLoaded"", arguments.callee, false );            jQuery.ready();        }, false );    // If IE event model is used    } else if ( document.attachEvent ) {        // ensure firing before onload,        // maybe late but safe also for iframes        document.attachEvent(""onreadystatechange"", function(){            if ( document.readyState === ""complete"" ) {                document.detachEvent( ""onreadystatechange"", arguments.callee );                jQuery.ready();            }        });        // If IE and not an iframe        // continually check to see if the document is ready        if ( document.documentElement.doScroll && window == window.top ) (function(){            if ( jQuery.isReady ) return;            try {                // If IE is used, use the trick by Diego Perini                // http://javascript.nwbox.com/IEContentLoaded/                document.documentElement.doScroll(""left"");            } catch( error ) {                setTimeout( arguments.callee, 0 );                return;            }            // and execute any waiting functions            jQuery.ready();        })();    }    // A fallback to window.onload, that will always work    jQuery.event.add( window, ""load"", jQuery.ready );}"
"data_i","edited Feb 26 '20 at 22:22","
        How do I get a consistent byte representation of strings in C# without manually specifying an encoding?
    ","How do I convert a string to a byte[] in .NET (C#) without manually specifying a specific encoding?I'm going to encrypt the string. I can encrypt it without converting, but I'd still like to know why encoding comes to play here.Also, why should encoding even be taken into consideration? Can't I simply get what bytes the string has been stored in? Why is there a dependency on character encodings?","Contrary to the answers here, you DON'T need to worry about encoding if the bytes don't need to be interpreted!Like you mentioned, your goal is, simply, to ""get what bytes the string has been stored in"".(And, of course, to be able to re-construct the string from the bytes.)For those goals, I honestly do not understand why people keep telling you that you need the encodings. You certainly do NOT need to worry about encodings for this.Just do this instead:static byte[] GetBytes(string str){    byte[] bytes = new byte[str.Length * sizeof(char)];    System.Buffer.BlockCopy(str.ToCharArray(), 0, bytes, 0, bytes.Length);    return bytes;}// Do NOT use on arbitrary bytes; only use on GetBytes's output on the SAME systemstatic string GetString(byte[] bytes){    char[] chars = new char[bytes.Length / sizeof(char)];    System.Buffer.BlockCopy(bytes, 0, chars, 0, bytes.Length);    return new string(chars);}As long as your program (or other programs) don't try to interpret the bytes somehow, which you obviously didn't mention you intend to do, then there is nothing wrong with this approach! Worrying about encodings just makes your life more complicated for no real reason.Additional benefit to this approach: It doesn't matter if the string contains invalid characters, because you can still get the data and reconstruct the original string anyway!It will be encoded and decoded just the same, because you are just looking at the bytes.If you used a specific encoding, though, it would've given you trouble with encoding/decoding invalid characters."
"data_i","edited Apr 13 '18 at 11:44","
        Should 'using' directives be inside or outside the namespace?
    ","I have been running StyleCop over some C# code, and it keeps reporting that my using directives should be inside the namespace.Is there a technical reason for putting the using directives inside instead of outside the namespace?","There is actually a (subtle) difference between the two. Imagine you have the following code in File1.cs:// File1.csusing System;namespace Outer.Inner{    class Foo    {        static void Bar()        {            double d = Math.PI;        }    }}Now imagine that someone adds another file (File2.cs) to the project that looks like this:// File2.csnamespace Outer{    class Math    {    }}The compiler searches Outer before looking at those using directives outside the namespace, so it finds Outer.Math instead of System.Math. Unfortunately (or perhaps fortunately?), Outer.Math has no PI member, so File1 is now broken.This changes if you put the using inside your namespace declaration, as follows:// File1b.csnamespace Outer.Inner{    using System;    class Foo    {        static void Bar()        {            double d = Math.PI;        }    }}Now the compiler searches System before searching Outer, finds System.Math, and all is well.Some would argue that Math might be a bad name for a user-defined class, since there's already one in System; the point here is just that there is a difference, and it affects the maintainability of your code.It's also interesting to note what happens if Foo is in namespace Outer, rather than Outer.Inner. In that case, adding Outer.Math in File2 breaks File1 regardless of where the using goes. This implies that the compiler searches the innermost enclosing namespace before it looks at any using directive."
"data_i","edited Aug 16 '22 at 16:06","
        How to format numbers as currency strings
    ","I would like to format a price in JavaScript. I'd like a function which takes a float as an argument and returns a string formatted like this:""$ 2,500.00""How can I do this?","Intl.NumberFormatJavaScript has a number formatter (part of the Internationalization API).// Create our number formatter.var formatter = new Intl.NumberFormat('en-US', {  style: 'currency',  currency: 'USD',  // These options are needed to round to whole numbers if that's what you want.  //minimumFractionDigits: 0, // (this suffices for whole numbers, but will print 2500.10 as $2,500.1)  //maximumFractionDigits: 0, // (causes 2500.99 to be printed as $2,501)});formatter.format(2500); /* $2,500.00 */Use undefined in place of the first argument ('en-US' in the example) to use the system locale (the user locale in case the code is running in a browser). Further explanation of the locale code.Here's a list of the currency codes.Intl.NumberFormat vs Number.prototype.toLocaleStringA final note comparing this to the older .toLocaleString. They both offer essentially the same functionality. However, toLocaleString in its older incarnations (pre-Intl) does not actually support locales: it uses the system locale. So when debugging old browsers, be sure that you're using the correct version (MDN suggests to check for the existence of Intl). There isn't any need to worry about this at all if you don't care about old browsers or just use the shim.Also, the performance of both is the same for a single item, but if you have a lot of numbers to format, using Intl.NumberFormat is ~70 times faster. Therefore, it's usually best to use Intl.NumberFormat and instantiate only once per page load. Anyway, here's the equivalent usage of toLocaleString:(2500).toLocaleString('en-US', {  style: 'currency',  currency: 'USD',}); /* $2,500.00 */Some notes on browser support and Node.jsBrowser support is no longer an issue nowadays with 98% support globally, 99% in the US and 99+% in the EUThere is a shim to support it on fossilized browsers (like Internet Explorer 8), should you really need toNode.js before v13 only supports en-US out of the box. One solution is to install full-icu, see here for more informationHave a look at CanIUse for more information"
"data_i","edited Aug 29 '20 at 01:23","
        What are MVP and MVC and what is the difference?
    ","When looking beyond the RAD (drag-drop and configure) way of building user interfaces that many tools encourage you are likely to come across three design patterns called Model-View-Controller, Model-View-Presenter and Model-View-ViewModel. My question has three parts to it:What issues do these patterns address?How are they similar?How are they different?","Model-View-PresenterIn MVP, the Presenter contains the UI business logic for the View. All invocations from the View delegate directly to the Presenter. The Presenter is also decoupled directly from the View and talks to it through an interface. This is to allow mocking of the View in a unit test. One common attribute of MVP is that there has to be a lot of two-way dispatching. For example, when someone clicks the ""Save"" button, the event handler delegates to the Presenter's ""OnSave"" method. Once the save is completed, the Presenter will then call back the View through its interface so that the View can display that the save has completed.MVP tends to be a very natural pattern for achieving separated presentation in WebForms. The reason is that the View is always created first by the ASP.NET runtime. You can find out more about both variants.Two primary variationsPassive View: The View is as dumb as possible and contains almost zero logic. A Presenter is a middle man that talks to the View and the Model. The View and Model are completely shielded from one another. The Model may raise events, but the Presenter subscribes to them for updating the View. In Passive View there is no direct data binding, instead, the View exposes setter properties that the Presenter uses to set the data. All state is managed in the Presenter and not the View.Pro: maximum testability surface; clean separation of the View and ModelCon: more work (for example all the setter properties) as you are doing all the data binding yourself.Supervising Controller: The Presenter handles user gestures. The View binds to the Model directly through data binding. In this case, it's the Presenter's job to pass off the Model to the View so that it can bind to it. The Presenter will also contain logic for gestures like pressing a button, navigation, etc.Pro: by leveraging data binding the amount of code is reduced.Con: there's a less testable surface (because of data binding), and there's less encapsulation in the View since it talks directly to the Model.Model-View-ControllerIn the MVC, the Controller is responsible for determining which View to display in response to any action including when the application loads. This differs from MVP where actions route through the View to the Presenter. In MVC, every action in the View correlates with a call to a Controller along with an action. In the web, each action involves a call to a URL on the other side of which there is a Controller who responds. Once that Controller has completed its processing, it will return the correct View. The sequence continues in that manner throughout the life of the application:    Action in the View        -> Call to Controller        -> Controller Logic        -> Controller returns the View.One other big difference about MVC is that the View does not directly bind to the Model. The view simply renders and is completely stateless. In implementations of MVC, the View usually will not have any logic in the code behind. This is contrary to MVP where it is absolutely necessary because, if the View does not delegate to the Presenter, it will never get called.Presentation ModelOne other pattern to look at is the Presentation Model pattern. In this pattern, there is no Presenter. Instead, the View binds directly to a Presentation Model. The Presentation Model is a Model crafted specifically for the View. This means this Model can expose properties that one would never put on a domain model as it would be a violation of separation-of-concerns. In this case, the Presentation Model binds to the domain model and may subscribe to events coming from that Model. The View then subscribes to events coming from the Presentation Model and updates itself accordingly. The Presentation Model can expose commands which the view uses for invoking actions. The advantage of this approach is that you can essentially remove the code-behind altogether as the PM completely encapsulates all of the behavior for the view. This pattern is a very strong candidate for use in WPF applications and is also called Model-View-ViewModel.There is a MSDN article about the Presentation Model and a section in the Composite Application Guidance for WPF (former Prism) about Separated Presentation Patterns"
"data_i","edited Jul 31 '18 at 20:09","
        JavaScript equivalent to printf/String.Format
    ","I'm looking for a good JavaScript equivalent of the C/PHP printf() or for C#/Java programmers, String.Format() (IFormatProvider for .NET).My basic requirement is a thousand separator format for numbers for now, but something that handles lots of combinations (including dates) would be good.I realize Microsoft's Ajax library provides a version of String.Format(), but we don't want the entire overhead of that framework.","Current JavaScriptFrom ES6 on you could use template strings:let soMany = 10;console.log(`This is ${soMany} times easier!`);// ""This is 10 times easier!See Kim's answer below for details.Older answerTry sprintf() for JavaScript.If you really want to do a simple format method on your own, don’t do the replacements successively but do them simultaneously.Because most of the other proposals that are mentioned fail when a replace string of previous replacement does also contain a format sequence like this:""{0}{1}"".format(""{1}"", ""{0}"")Normally you would expect the output to be {1}{0} but the actual output is {1}{1}. So do a simultaneously replacement instead like in fearphage’s suggestion."
"data_i","edited Aug 17 '21 at 09:22","
        ""implements Runnable"" vs ""extends Thread"" in Java
    ","From what time I've spent with threads in Java, I've found these two ways to write threads:With implements Runnable:public class MyRunnable implements Runnable {    public void run() {        //Code    }}//Started with a ""new Thread(new MyRunnable()).start()"" callOr, with extends Thread:public class MyThread extends Thread {    public MyThread() {        super(""MyThread"");    }    public void run() {        //Code    }}//Started with a ""new MyThread().start()"" callIs there any significant difference in these two blocks of code?","Yes: implements Runnable is the preferred way to do it, IMO. You're not really specialising the thread's behaviour.  You're just giving it something to run. That means composition is the philosophically ""purer"" way to go.In practical terms, it means you can implement Runnable and extend from another class as well... and you can also implement Runnable via a lambda expression as of Java 8."
"data_i","edited Sep 05 '21 at 10:28","
        How can I save username and password in Git?
    ","I want to use a push and pull automatically in Git Extensions, Sourcetree or any other Git GUI without entering my username and password in a prompt, every time.So how can I save my credentials in Git?","Attention: This method saves the credentials in plaintext on your PC's disk. Everyone on your computer can access it, e.g. malicious NPM modules.Rungit config --global credential.helper storethengit pullprovide a username and password and those details will then be remembered later. The credentials are stored in a file on the disk, with the disk permissions of ""just user readable/writable"" but still in plaintext.If you want to change the password latergit pullWill fail, because the password is incorrect, git then removes the offending user+password from the ~/.git-credentials file, so now re-rungit pullto provide a new password so it works as earlier."
"data_i","edited Jan 03 '20 at 13:45","
        Vertically align text to top within a UILabel
    ","I have a UILabel with space for two lines of text. Sometimes, when the text is too short, this text is displayed in the vertical center of the label.How do I vertically align the text to always be at the top of the UILabel?","There's no way to set the vertical-align on a UILabel, but you can get the same effect by changing the label's frame. I've made my labels orange so you can see clearly what's happening.Here's the quick and easy way to do this:    [myLabel sizeToFit];If you have a label with longer text that will make more than one line, set numberOfLines to 0 (zero here means an unlimited number of lines).    myLabel.numberOfLines = 0;    [myLabel sizeToFit];Longer VersionI'll make my label in code so that you can see what's going on. You can set up most of this in Interface Builder too. My setup is a View-Based App with a background image I made in Photoshop to show margins (20 points). The label is an attractive orange color so you can see what's going on with the dimensions.- (void)viewDidLoad{    [super viewDidLoad];    // 20 point top and left margin. Sized to leave 20 pt at right.    CGRect labelFrame = CGRectMake(20, 20, 280, 150);    UILabel *myLabel = [[UILabel alloc] initWithFrame:labelFrame];    [myLabel setBackgroundColor:[UIColor orangeColor]];    NSString *labelText = @""I am the very model of a modern Major-General, I've information vegetable, animal, and mineral"";    [myLabel setText:labelText];    // Tell the label to use an unlimited number of lines    [myLabel setNumberOfLines:0];    [myLabel sizeToFit];    [self.view addSubview:myLabel];}Some limitations of using sizeToFit come into play with center- or right-aligned text. Here's what happens:    // myLabel.textAlignment = NSTextAlignmentRight;    myLabel.textAlignment = NSTextAlignmentCenter;    [myLabel setNumberOfLines:0];    [myLabel sizeToFit];The label is still sized with a fixed top-left corner. You can save the original label's width in a variable and set it after sizeToFit, or give it a fixed width to counter these problems:    myLabel.textAlignment = NSTextAlignmentCenter;    [myLabel setNumberOfLines:0];    [myLabel sizeToFit];    CGRect myFrame = myLabel.frame;    // Resize the frame's width to 280 (320 - margins)    // width could also be myOriginalLabelFrame.size.width    myFrame = CGRectMake(myFrame.origin.x, myFrame.origin.y, 280, myFrame.size.height);    myLabel.frame = myFrame;Note that sizeToFit will respect your initial label's minimum width. If you start with a label 100 wide and call sizeToFit on it, it will give you back a (possibly very tall) label with 100 (or a little less) width. You might want to set your label to the minimum width you want before resizing.Some other things to note:Whether lineBreakMode is respected depends on how it's set. NSLineBreakByTruncatingTail (the default) is ignored after sizeToFit, as are the other two truncation modes (head and middle). NSLineBreakByClipping is also ignored. NSLineBreakByCharWrapping works as usual. The frame width is still narrowed to fit to the rightmost letter.Mark Amery gave a fix for NIBs and Storyboards using Auto Layout in the comments:If your label is included in a nib or storyboard as a subview of the view of a ViewController that uses autolayout, then putting your sizeToFit call into viewDidLoad won't work, because autolayout sizes and positions the subviews after viewDidLoad is called and will immediately undo the effects of your sizeToFit call. However, calling sizeToFit from within viewDidLayoutSubviews will work.My Original Answer (for posterity/reference):This uses the NSString method sizeWithFont:constrainedToSize:lineBreakMode: to calculate the frame height needed to fit a string, then sets the origin and width.Resize the frame for the label using the text you want to insert. That way you can accommodate any number of lines.CGSize maximumSize = CGSizeMake(300, 9999);NSString *dateString = @""The date today is January 1st, 1999"";UIFont *dateFont = [UIFont fontWithName:@""Helvetica"" size:14];CGSize dateStringSize = [dateString sizeWithFont:dateFont         constrainedToSize:maximumSize         lineBreakMode:self.dateLabel.lineBreakMode];CGRect dateFrame = CGRectMake(10, 10, 300, dateStringSize.height);self.dateLabel.frame = dateFrame;"
"data_i","edited Apr 01 '22 at 12:23","
        How to print without a newline or space
    ","Example in C:for (int i = 0; i < 4; i++)    printf(""."");Output:....In Python:>>> for i in range(4): print('.')....>>> print('.', '.', '.', '.'). . . .In Python, print will add a \n or space. How can I avoid that? I'd like to know how to ""append"" strings to stdout.","In Python 3, you can use the sep= and end= parameters of the print function:To not add a newline to the end of the string:print('.', end='')To not add a space between all the function arguments you want to print:print('a', 'b', 'c', sep='')You can pass any string to either parameter, and you can use both parameters at the same time.If you are having trouble with buffering, you can flush the output by adding flush=True keyword argument:print('.', end='', flush=True)Python 2.6 and 2.7From Python 2.6 you can either import the print function from Python 3 using the __future__ module:from __future__ import print_functionwhich allows you to use the Python 3 solution above.However, note that the flush keyword is not available in the version of the print function imported from __future__ in Python 2; it only works in Python 3, more specifically 3.3 and later. In earlier versions you'll still need to flush manually with a call to sys.stdout.flush(). You'll also have to rewrite all other print statements in the file where you do this import.Or you can use sys.stdout.write()import syssys.stdout.write('.')You may also need to callsys.stdout.flush()to ensure stdout is flushed immediately."
"data_i","edited Sep 18 '20 at 03:00","
        What is the purpose of .PHONY in a Makefile?
    ","What does .PHONY mean in a Makefile? I have gone through this, but it is too complicated.Can somebody explain it to me in simple terms?","By default, Makefile targets are ""file targets"" - they are used to build files from other files. Make assumes its target is a file, and this makes writing Makefiles relatively easy:foo: bar  create_one_from_the_other foo barHowever, sometimes you want your Makefile to run commands that do not represent physical files in the file system. Good examples for this are the common targets ""clean"" and ""all"". Chances are this isn't the case, but you may potentially have a file named clean in your main directory. In such a case Make will be confused because by default the clean target would be associated with this file and Make will only run it when the file doesn't appear to be up-to-date with regards to its dependencies.These special targets are called phony and you can explicitly tell Make they're not associated with files, e.g.:.PHONY: cleanclean:  rm -rf *.oNow make clean will run as expected even if you do have a file named clean.In terms of Make, a phony target is simply a target that is always out-of-date, so whenever you ask make <phony_target>, it will run, independent from the state of the file system. Some common make targets that are often phony are: all, install, clean, distclean, TAGS, info, check."
"data_i","edited Jul 07 '19 at 14:58","
        What's the simplest way to print a Java array?
    ","In Java, arrays don't override toString(), so if you try to print one directly, you get the className + '@' + the hex of the hashCode of the array, as defined by Object.toString():int[] intArray = new int[] {1, 2, 3, 4, 5};System.out.println(intArray);     // prints something like '[I@3343c8b3'But usually, we'd actually want something more like [1, 2, 3, 4, 5]. What's the simplest way of doing that? Here are some example inputs and outputs:// Array of primitives:int[] intArray = new int[] {1, 2, 3, 4, 5};//output: [1, 2, 3, 4, 5]// Array of object references:String[] strArray = new String[] {""John"", ""Mary"", ""Bob""};//output: [John, Mary, Bob]","Since Java 5 you can use Arrays.toString(arr) or Arrays.deepToString(arr) for arrays within arrays. Note that the Object[] version calls .toString() on each object in the array. The output is even decorated in the exact way you're asking.Examples:Simple Array:String[] array = new String[] {""John"", ""Mary"", ""Bob""};System.out.println(Arrays.toString(array));Output:[John, Mary, Bob]Nested Array:String[][] deepArray = new String[][] {{""John"", ""Mary""}, {""Alice"", ""Bob""}};System.out.println(Arrays.toString(deepArray));//output: [[Ljava.lang.String;@106d69c, [Ljava.lang.String;@52e922]System.out.println(Arrays.deepToString(deepArray));Output:[[John, Mary], [Alice, Bob]]double Array:double[] doubleArray = { 7.0, 9.0, 5.0, 1.0, 3.0 };System.out.println(Arrays.toString(doubleArray));Output:[7.0, 9.0, 5.0, 1.0, 3.0 ]int Array:int[] intArray = { 7, 9, 5, 1, 3 };System.out.println(Arrays.toString(intArray));Output:[7, 9, 5, 1, 3 ]"
"data_i","edited Apr 12 '19 at 13:18","
        How to replace a character by a newline in Vim
    ","I'm trying to replace each , in the current file by a new line::%s/,/\n/g But it inserts what looks like a ^@ instead of an actual newline. The file is not in DOS mode or anything.What should I do?If you are curious, like me, check the question Why is \r a newline for Vim? as well.","Use \r instead of \n.Substituting by \n inserts a null character into the text. To get a newline, use \r. When searching for a newline, you’d still use \n, however. This asymmetry is due to the fact that \n and \r do slightly different things:\n matches an end of line (newline), whereas \r matches a carriage return. On the other hand, in substitutions \n inserts a null character whereas \r inserts a newline (more precisely, it’s treated as the input CR). Here’s a small, non-interactive example to illustrate this, using the Vim command line feature (in other words, you can copy and paste the following into a terminal to run it). xxd shows a hexdump of the resulting file.echo bar > test(echo 'Before:'; xxd test) > output.txtvim test '+s/b/\n/' '+s/a/\r/' +wq(echo 'After:'; xxd test) >> output.txtmore output.txtBefore:0000000: 6261 720a                                bar.After:0000000: 000a 720a                                ..r.In other words, \n has inserted the byte 0x00 into the text; \r has inserted the byte 0x0a."
"data_i","edited Sep 28 '21 at 16:11","
        Finding duplicate values in a SQL table
    ","It's easy to find duplicates with one field:SELECT email, COUNT(email) FROM usersGROUP BY emailHAVING COUNT(email) > 1So if we have a tableID   NAME   EMAIL1    John   asd@asd.com2    Sam    asd@asd.com3    Tom    asd@asd.com4    Bob    bob@asd.com5    Tom    asd@asd.comThis query will give us John, Sam, Tom, Tom because they all have the same email.However, what I want is to get duplicates with the same email and name.That is, I want to get ""Tom"", ""Tom"".The reason I need this: I made a mistake, and allowed inserting duplicate name and email values. Now I need to remove/change the duplicates, so I need to find them first.","SELECT    name, email, COUNT(*)FROM    usersGROUP BY    name, emailHAVING     COUNT(*) > 1Simply group on both of the columns.Note: the older ANSI standard is to have all non-aggregated columns in the GROUP BY but this has changed with the idea of ""functional dependency"":In relational database theory, a functional dependency is a constraint between two sets of attributes in a relation from a database. In other words, functional dependency is a constraint that describes the relationship between attributes in a relation.Support is not consistent:Recent PostgreSQL supports it.SQL Server (as at SQL Server 2017) still requires all non-aggregated columns in the GROUP BY.MySQL is unpredictable and you need sql_mode=only_full_group_by:GROUP BY lname ORDER BY showing wrong results;Which is the least expensive aggregate function in the absence of ANY() (see comments in accepted answer).Oracle isn't mainstream enough (warning: humour, I don't know about Oracle)."
"data_i","edited Jun 21 '22 at 21:20","
        How do I generate a random integer in C#?
    ","How do I generate a random integer in C#?","The Random class is used to create random numbers. (Pseudo-random that is of course.).Example:Random rnd = new Random();int month  = rnd.Next(1, 13);  // creates a number between 1 and 12int dice   = rnd.Next(1, 7);   // creates a number between 1 and 6int card   = rnd.Next(52);     // creates a number between 0 and 51If you are going to create more than one random number, you should keep the Random instance and reuse it. If you create new instances too close in time, they will produce the same series of random numbers as the random generator is seeded from the system clock."
"data_i","edited May 15 '20 at 02:44","
        What does the ??!??! operator do in C?
    ","I saw a line of C that looked like this:!ErrorHasOccured() ??!??! HandleError();It compiled correctly and seems to run ok. It seems like it's checking if an error has occurred, and if it has, it handles it. But I'm not really sure what it's actually doing or how it's doing it. It does look like the programmer is trying express their feelings about errors.I have never seen the ??!??! before in any programming language, and I can't find documentation for it anywhere. (Google doesn't help with search terms like ??!??!). What does it do and how does the code sample work?","??! is a trigraph that translates to |. So it says:!ErrorHasOccured() || HandleError();which, due to short circuiting, is equivalent to:if (ErrorHasOccured())    HandleError();Guru of the Week (deals with C++ but relevant here), where I picked this up.Possible origin of trigraphs or as @DwB points out in the comments it's more likely due to EBCDIC being difficult (again). This discussion on the IBM developerworks board seems to support that theory.From ISO/IEC 9899:1999 §5.2.1.1, footnote 12 (h/t @Random832):The trigraph sequences enable the input of characters that are not defined in the Invariant Code Set asdescribed in ISO/IEC 646, which is a subset of the seven-bit US ASCII code set."
"data_i","edited Mar 13 '19 at 10:58","
        Iterate through object properties
    ","var obj = {    name: ""Simon"",    age: ""20"",    clothing: {        style: ""simple"",        hipster: false    }}for(var propt in obj){    console.log(propt + ': ' + obj[propt]);}How does the variable propt represent the properties of the object? It's not a built-in method or property. Why does it come up with every property in the object?","Iterating over properties requires this additional hasOwnProperty check: for (var prop in obj) {    if (Object.prototype.hasOwnProperty.call(obj, prop)) {        // do stuff    }}It's necessary because an object's prototype contains additional properties for the object which are technically part of the object. These additional properties are inherited from the base object class, but are still properties of obj.hasOwnProperty simply checks to see if this is a property specific to this class, and not one inherited from the base class.It's also possible to call hasOwnProperty through the object itself:if (obj.hasOwnProperty(prop)) {    // do stuff}But this will fail if the object has an unrelated field with the same name:var obj = { foo: 42, hasOwnProperty: 'lol' };obj.hasOwnProperty('foo');  // TypeError: hasOwnProperty is not a functionThat's why it's safer to call it through Object.prototype instead:var obj = { foo: 42, hasOwnProperty: 'lol' };Object.prototype.hasOwnProperty.call(obj, 'foo');  // true"
"data_i","edited Oct 25 '21 at 23:00","
        Showing which files have changed between two revisions
    ","I want to merge two branches that have been separated for a while and wanted to know which files have been modified.Came across this link: http://linux.yyz.us/git-howto.html which was quite useful.The tools to compare branches I've come across are:git diff master..branchgit log master..branchgit shortlog master..branchWas wondering if there's something like ""git status master..branch"" to only see those files that are different between the two branches.Without creating a new tool, I think this is the closest you can get to do that now (which of course will show repeats if a file was modified more than once):git diff master..branch | grep ""^diff""Was wondering if there's something I missed...","To compare the current branch against main branch:$ git diff --name-status mainTo compare any two branches:$ git diff --name-status firstbranch..yourBranchNameThere is more options to git diff in the official documentation (and specifically --name-status option)."
"data_i","edited Jul 04 '22 at 21:56","
        What is the copy-and-swap idiom?
    ","What is the copy-and-swap idiom and when should it be used? What problems does it solve? Does it change for C++11?Related:What are your favorite C++ Coding Style idioms:  Copy-swapCopy constructor and = operator overload in C++: is a common function possible?What is copy elision and how it optimizes copy-and-swap idiomC++: dynamically allocating an array of objects?","OverviewWhy do we need the copy-and-swap idiom?Any class that manages a resource (a wrapper, like a smart pointer) needs to implement The Big Three. While the goals and implementation of the copy-constructor and destructor are straightforward, the copy-assignment operator is arguably the most nuanced and difficult. How should it be done? What pitfalls need to be avoided?The copy-and-swap idiom is the solution, and elegantly assists the assignment operator in achieving two things: avoiding code duplication, and providing a strong exception guarantee.How does it work?Conceptually, it works by using the copy-constructor's functionality to create a local copy of the data, then takes the copied data with a swap function, swapping the old data with the new data. The temporary copy then destructs, taking the old data with it. We are left with a copy of the new data.In order to use the copy-and-swap idiom, we need three things: a working copy-constructor, a working destructor (both are the basis of any wrapper, so should be complete anyway), and a swap function.A swap function is a non-throwing function that swaps two objects of a class, member for member. We might be tempted to use std::swap instead of providing our own, but this would be impossible; std::swap uses the copy-constructor and copy-assignment operator within its implementation, and we'd ultimately be trying to define the assignment operator in terms of itself!(Not only that, but unqualified calls to swap will use our custom swap operator, skipping over the unnecessary construction and destruction of our class that std::swap would entail.)An in-depth explanationThe goalLet's consider a concrete case. We want to manage, in an otherwise useless class, a dynamic array. We start with a working constructor, copy-constructor, and destructor:#include <algorithm> // std::copy#include <cstddef> // std::size_tclass dumb_array{public:    // (default) constructor    dumb_array(std::size_t size = 0)        : mSize(size),          mArray(mSize ? new int[mSize]() : nullptr)    {    }    // copy-constructor    dumb_array(const dumb_array& other)        : mSize(other.mSize),          mArray(mSize ? new int[mSize] : nullptr)    {        // note that this is non-throwing, because of the data        // types being used; more attention to detail with regards        // to exceptions must be given in a more general case, however        std::copy(other.mArray, other.mArray + mSize, mArray);    }    // destructor    ~dumb_array()    {        delete [] mArray;    }private:    std::size_t mSize;    int* mArray;};This class almost manages the array successfully, but it needs operator= to work correctly.A failed solutionHere's how a naive implementation might look:// the hard partdumb_array& operator=(const dumb_array& other){    if (this != &other) // (1)    {        // get rid of the old data...        delete [] mArray; // (2)        mArray = nullptr; // (2) *(see footnote for rationale)        // ...and put in the new        mSize = other.mSize; // (3)        mArray = mSize ? new int[mSize] : nullptr; // (3)        std::copy(other.mArray, other.mArray + mSize, mArray); // (3)    }    return *this;}And we say we're finished; this now manages an array, without leaks. However, it suffers from three problems, marked sequentially in the code as (n).The first is the self-assignment test.This check serves two purposes: it's an easy way to prevent us from running needless code on self-assignment, and it protects us from subtle bugs (such as deleting the array only to try and copy it). But in all other cases it merely serves to slow the program down, and act as noise in the code; self-assignment rarely occurs, so most of the time this check is a waste.It would be better if the operator could work properly without it.The second is that it only provides a basic exception guarantee. If new int[mSize] fails, *this will have been modified. (Namely, the size is wrong and the data is gone!)For a strong exception guarantee, it would need to be something akin to: dumb_array& operator=(const dumb_array& other) {     if (this != &other) // (1)     {         // get the new data ready before we replace the old         std::size_t newSize = other.mSize;         int* newArray = newSize ? new int[newSize]() : nullptr; // (3)         std::copy(other.mArray, other.mArray + newSize, newArray); // (3)         // replace the old data (all are non-throwing)         delete [] mArray;         mSize = newSize;         mArray = newArray;     }     return *this; }The code has expanded! Which leads us to the third problem: code duplication.Our assignment operator effectively duplicates all the code we've already written elsewhere, and that's a terrible thing.In our case, the core of it is only two lines (the allocation and the copy), but with more complex resources this code bloat can be quite a hassle. We should strive to never repeat ourselves.(One might wonder: if this much code is needed to manage one resource correctly, what if my class manages more than one?While this may seem to be a valid concern, and indeed it requires non-trivial try/catch clauses, this is a non-issue.That's because a class should manage one resource only!)A successful solutionAs mentioned, the copy-and-swap idiom will fix all these issues. But right now, we have all the requirements except one: a swap function. While The Rule of Three successfully entails the existence of our copy-constructor, assignment operator, and destructor, it should really be called ""The Big Three and A Half"": any time your class manages a resource it also makes sense to provide a swap function.We need to add swap functionality to our class, and we do that as follows†:class dumb_array{public:    // ...    friend void swap(dumb_array& first, dumb_array& second) // nothrow    {        // enable ADL (not necessary in our case, but good practice)        using std::swap;        // by swapping the members of two objects,        // the two objects are effectively swapped        swap(first.mSize, second.mSize);        swap(first.mArray, second.mArray);    }    // ...};(Here is the explanation why public friend swap.) Now not only can we swap our dumb_array's, but swaps in general can be more efficient; it merely swaps pointers and sizes, rather than allocating and copying entire arrays. Aside from this bonus in functionality and efficiency, we are now ready to implement the copy-and-swap idiom.Without further ado, our assignment operator is:dumb_array& operator=(dumb_array other) // (1){    swap(*this, other); // (2)    return *this;}And that's it! With one fell swoop, all three problems are elegantly tackled at once.Why does it work?We first notice an important choice: the parameter argument is taken by-value. While one could just as easily do the following (and indeed, many naive implementations of the idiom do):dumb_array& operator=(const dumb_array& other){    dumb_array temp(other);    swap(*this, temp);    return *this;}We lose an important optimization opportunity. Not only that, but this choice is critical in C++11, which is discussed later. (On a general note, a remarkably useful guideline is as follows: if you're going to make a copy of something in a function, let the compiler do it in the parameter list.‡)Either way, this method of obtaining our resource is the key to eliminating code duplication: we get to use the code from the copy-constructor to make the copy, and never need to repeat any bit of it. Now that the copy is made, we are ready to swap.Observe that upon entering the function that all the new data is already allocated, copied, and ready to be used. This is what gives us a strong exception guarantee for free: we won't even enter the function if construction of the copy fails, and it's therefore not possible to alter the state of *this. (What we did manually before for a strong exception guarantee, the compiler is doing for us now; how kind.)At this point we are home-free, because swap is non-throwing. We swap our current data with the copied data, safely altering our state, and the old data gets put into the temporary. The old data is then released when the function returns. (Where upon the parameter's scope ends and its destructor is called.)Because the idiom repeats no code, we cannot introduce bugs within the operator. Note that this means we are rid of the need for a self-assignment check, allowing a single uniform implementation of operator=. (Additionally, we no longer have a performance penalty on non-self-assignments.)And that is the copy-and-swap idiom.What about C++11?The next version of C++, C++11, makes one very important change to how we manage resources: the Rule of Three is now The Rule of Four (and a half). Why? Because not only do we need to be able to copy-construct our resource, we need to move-construct it as well.Luckily for us, this is easy:class dumb_array{public:    // ...    // move constructor    dumb_array(dumb_array&& other) noexcept ††        : dumb_array() // initialize via default constructor, C++11 only    {        swap(*this, other);    }    // ...};What's going on here? Recall the goal of move-construction: to take the resources from another instance of the class, leaving it in a state guaranteed to be assignable and destructible.So what we've done is simple: initialize via the default constructor (a C++11 feature), then swap with other; we know a default constructed instance of our class can safely be assigned and destructed, so we know other will be able to do the same, after swapping.(Note that some compilers do not support constructor delegation; in this case, we have to manually default construct the class. This is an unfortunate but luckily trivial task.)Why does that work?That is the only change we need to make to our class, so why does it work? Remember the ever-important decision we made to make the parameter a value and not a reference:dumb_array& operator=(dumb_array other); // (1)Now, if other is being initialized with an rvalue, it will be move-constructed. Perfect. In the same way C++03 let us re-use our copy-constructor functionality by taking the argument by-value, C++11 will automatically pick the move-constructor when appropriate as well. (And, of course, as mentioned in previously linked article, the copying/moving of the value may simply be elided altogether.)And so concludes the copy-and-swap idiom.Footnotes*Why do we set mArray to null? Because if any further code in the operator throws, the destructor of dumb_array might be called; and if that happens without setting it to null, we attempt to delete memory that's already been deleted! We avoid this by setting it to null, as deleting null is a no-operation.†There are other claims that we should specialize std::swap for our type, provide an in-class swap along-side a free-function swap, etc. But this is all unnecessary: any proper use of swap will be through an unqualified call, and our function will be found through ADL. One function will do.‡The reason is simple: once you have the resource to yourself, you may swap and/or move it (C++11) anywhere it needs to be. And by making the copy in the parameter list, you maximize optimization.††The move constructor should generally be noexcept, otherwise some code (e.g. std::vector resizing logic) will use the copy constructor even when a move would make sense. Of course, only mark it noexcept if the code inside doesn't throw exceptions."
"data_i","edited Aug 10 '21 at 17:32","
        How to get an enum value from a string value in Java
    ","Say I have an enum which is justpublic enum Blah {    A, B, C, D}and I would like to find the enum value of a string, for example ""A"" which would be Blah.A. How would it be possible to do this?Is the Enum.valueOf() the method I need? If so, how would I use this?","Yes, Blah.valueOf(""A"") will give you Blah.A.Note that the name must be an exact match, including case: Blah.valueOf(""a"") and Blah.valueOf(""A "") both throw an IllegalArgumentException.The static methods valueOf() and values() are created at compile time and do not appear in source code. They do appear in Javadoc, though; for example, Dialog.ModalityType shows both methods."
"data_i","edited Jun 04 '22 at 21:43","
        Calling a function of a module by using its name (a string)
    ","How do I call a function, using a string with the function's name? For example:import foofunc_name = ""bar""call(foo, func_name)  # calls foo.bar()","Given a module foo with method bar:import foobar = getattr(foo, 'bar')result = bar()getattr can similarly be used on class instance bound methods, module-level methods, class methods... the list goes on."
"data_i","edited Aug 20 '21 at 16:15","
        How to concatenate text from multiple rows into a single text string in SQL Server
    ","Consider a database table holding names, with three rows:PeterPaulMaryIs there an easy way to turn this into a single string of Peter, Paul, Mary?","If you are on SQL Server 2017 or Azure, see Mathieu Renda answer.I had a similar issue when I was trying to join two tables with one-to-many relationships. In SQL 2005 I found that XML PATH method can handle the concatenation of the rows very easily.If there is a table called STUDENTSSubjectID       StudentName----------      -------------1               Mary1               John1               Sam2               Alaina2               EdwardResult I expected was:SubjectID       StudentName----------      -------------1               Mary, John, Sam2               Alaina, EdwardI used the following T-SQL:SELECT Main.SubjectID,       LEFT(Main.Students,Len(Main.Students)-1) As ""Students""FROM    (        SELECT DISTINCT ST2.SubjectID,             (                SELECT ST1.StudentName + ',' AS [text()]                FROM dbo.Students ST1                WHERE ST1.SubjectID = ST2.SubjectID                ORDER BY ST1.SubjectID                FOR XML PATH (''), TYPE            ).value('text()[1]','nvarchar(max)') [Students]        FROM dbo.Students ST2    ) [Main]You can do the same thing in a more compact way if you can concat the commas at the beginning and use substring to skip the first one so you don't need to do a sub-query:SELECT DISTINCT ST2.SubjectID,     SUBSTRING(        (            SELECT ','+ST1.StudentName  AS [text()]            FROM dbo.Students ST1            WHERE ST1.SubjectID = ST2.SubjectID            ORDER BY ST1.SubjectID            FOR XML PATH (''), TYPE        ).value('text()[1]','nvarchar(max)'), 2, 1000) [Students]FROM dbo.Students ST2"
"data_i","edited Dec 17 '20 at 09:13","
        How do I break a string in YAML over multiple lines?
    ","In YAML, I have a string that's very long. I want to keep this within the 80-column (or so) view of my editor, so I'd like to break the string. What's the syntax for this?In other words, I have this:Key: 'this is my very very very very very very long string'and I'd like to have this (or something to this effect):Key: 'this is my very very very ' +     'long string'I'd like to use quotes as above, so I don't need to escape anything within the string.","There are 5 6 NINE (or 63*, depending how you count) different ways to write multi-line strings in YAML.TL;DRUse > most of the time: interior line breaks are stripped out, although you get one at the end:  key: >    Your long    string here.Use | if you want those linebreaks to be preserved as \n (for instance, embedded markdown with paragraphs).  key: |    ### Heading    * Bullet    * PointsUse >- or |- instead if you don't want a linebreak appended at the end.Use ""..."" if you need to split lines in the middle of words or want to literally type linebreaks as \n:  key: ""Antidisestab\   lishmentarianism.\n\nGet on it.""YAML is crazy.Block scalar styles (>, |)These allow characters such as \ and "" without escaping, and add a new line (\n) to the end of your string.> Folded style removes single newlines within the string (but adds one at the end, and converts double newlines to singles):Key: >  this is my very very very  long string→ this is my very very very long string\nExtra leading space is retained and causes extra newlines. See note below.Advice: Use this. Usually this is what you want.| Literal styleturns every newline within the string into a literal newline, and adds one at the end:Key: |  this is my very very very   long string→ this is my very very very\nlong string\nHere's the official definition from the YAML Spec 1.2Scalar content can be written in block notation, using a literal style (indicated by “|”) where all line breaks are significant. Alternatively, they can be written with the folded style (denoted by “>”) where each line break is folded to a space unless it ends an empty or a more-indented line.Advice: Use this for inserting formatted text (especially Markdown) as a value.Block styles with block chomping indicator (>-, |-, >+, |+)You can control the handling of the final new line in the string, and any trailing blank lines (\n\n) by adding a block chomping indicator character:>, |: ""clip"": keep the line feed, remove the trailing blank lines.>-, |-: ""strip"": remove the line feed, remove the trailing blank lines.>+, |+: ""keep"": keep the line feed, keep trailing blank lines.""Flow"" scalar styles ( , "", ')These have limited escaping, and construct a single-line string with no new line characters. They can begin on the same line as the key, or with additional newlines first, which are stripped. Doubled newline characters become one newline.plain style (no escaping, no  # or :  combinations, first character can't be "", ' or many other punctuation characters ):Key: this is my very very very   long stringAdvice: Avoid. May look convenient, but you're liable to shoot yourself in the foot by accidentally using forbidden punctuation and triggering a syntax error.double-quoted style (\ and "" must be escaped by \, newlines can be inserted with a literal \n sequence, lines can be concatenated without spaces with trailing \):Key: ""this is my very very \""very\"" loooo\  ng string.\n\nLove, YAML.""→ ""this is my very very \""very\"" loooong string.\n\nLove, YAML."" Advice: Use in very specific situations. This is the only way you can break a very long token (like a URL) across lines without adding spaces. And maybe adding newlines mid-line is conceivably useful.single-quoted style (literal ' must be doubled, no special characters, possibly useful for expressing strings starting with double quotes):Key: 'this is my very very ""very""  long string, isn''t it.'→ ""this is my very very \""very\"" long string, isn't it.""Advice: Avoid. Very few benefits, mostly inconvenience.Block styles with indentation indicatorsJust in case the above isn't enough for you, you can add a ""block indentation indicator"" (after your block chomping indicator, if you have one):- >8        My long string        starts over here- |+1 This one starts hereNote: Leading spaces in Folded style (>)If you insert extra spaces at the start of not-the-first lines in Folded style, they will be kept, with a bonus newline. (This doesn't happen with flow styles.) Section 6.5:In addition, folding does not apply to line breaks surrounding text lines that contain leading white space. Note that such a more-indented line may consist only of such leading white space.- >    my long      string                        many spaces above- my long      string                        many spaces above    → [""my long\n  string\n                \nmany spaces above\n"",""my long string\nmany spaces above""]SummaryIn this table, _ means space character. \n means ""newline character"" (\n in JavaScript) except under ""Other features"". ""Leading space"" applies after the first line (which establishes the indent)>|""'>->+|-|+Spaces/newlines converted as:Trailing space →______Leading space  →\n_\n_\n_\n_\n_\n_Single newline →_\n_____\n\nDouble newline →\n\n\n\n\n\n\n\n\n\n\n\nFinal newline  →\n\n\n\nFinal double newline →\n\n\n\nHow to create a literal:Single quote''''''''''Double quote""""""\""""""""""""Backslash\\\\\\\\\\Other featuresIn-line newlines with \n✅Spaceless newlines with \✅ # or :  in value✅✅✅✅✅✅✅✅Can start on sameline as key✅✅✅ExamplesNote the trailing spaces on the line before ""spaces.""- >  very ""long""  'string' with  paragraph gap, \n and          spaces.- |   very ""long""  'string' with  paragraph gap, \n and          spaces.- very ""long""  'string' with  paragraph gap, \n and          spaces.- ""very \""long\""  'string' with  paragraph gap, \n and          s\  p\  a\  c\  e\  s.""- 'very ""long""  ''string'' with  paragraph gap, \n and          spaces.'- >-   very ""long""  'string' with  paragraph gap, \n and          spaces.[  ""very \""long\"" 'string' with\nparagraph gap, \\n and         spaces.\n"",   ""very \""long\""\n'string' with\n\nparagraph gap, \\n and        \nspaces.\n"",   ""very \""long\"" 'string' with\nparagraph gap, \\n and spaces."",   ""very \""long\"" 'string' with\nparagraph gap, \n and spaces."",   ""very \""long\"" 'string' with\nparagraph gap, \\n and spaces."",   ""very \""long\"" 'string' with\nparagraph gap, \\n and         spaces.""]*2 block styles, each with 2 possible block chomping indicators (or none), and with 9 possible indentation indicators (or none), 1 plain style and 2 quoted styles: 2 x (2 + 1) x (9 + 1) + 1 + 2 = 63Some of this information has also been summarised here."
"data_i","edited Dec 24 '21 at 15:45","
        How do you parse and process HTML/XML in PHP?
    ","How can one parse HTML/XML and extract information from it?","Native XML ExtensionsI prefer using one of the native XML extensions since they come bundled with PHP, are usually faster than all the 3rd party libs and give me all the control I need over the markup.DOMThe DOM extension allows you to operate on XML documents through the DOM API with PHP 5. It is an implementation of the W3C's Document Object Model Core Level 3, a platform- and language-neutral interface that allows programs and scripts to dynamically access and update the content, structure and style of documents.DOM is capable of parsing and modifying real world (broken) HTML and it can do XPath queries. It is based on libxml.It takes some time to get productive with DOM, but that time is well worth it IMO. Since DOM is a language-agnostic interface, you'll find implementations in many languages, so if you need to change your programming language, chances are you will already know how to use that language's DOM API then.How to use the DOM extension has been covered extensively on StackOverflow, so if you choose to use it, you can be sure most of the issues you run into can be solved by searching/browsing Stack Overflow.A basic usage example and a general conceptual overview are available in other answers.XMLReaderThe XMLReader extension is an XML pull parser. The reader acts as a cursor going forward on the document stream and stopping at each node on the way.XMLReader, like DOM, is based on libxml. I am not aware of how to trigger the HTML Parser Module, so chances are using XMLReader for parsing broken HTML might be less robust than using DOM where you can explicitly tell it to use libxml's HTML Parser Module.A basic usage example is available in another answer.XML ParserThis extension lets you create XML parsers and then define handlers for different XML events. Each XML parser also has a few parameters you can adjust.The XML Parser library is also based on libxml, and implements a SAX style XML push parser. It may be a better choice for memory management than DOM or SimpleXML, but will be more difficult to work with than the pull parser implemented by XMLReader.SimpleXmlThe SimpleXML extension provides a very simple and easily usable toolset to convert XML to an object that can be processed with normal property selectors and array iterators.SimpleXML is an option when you know the HTML is valid XHTML. If you need to parse broken HTML, don't even consider SimpleXml because it will choke.A basic usage example is available, and there are lots of additional examples in the PHP Manual.3rd Party Libraries (libxml based)If you prefer to use a 3rd-party lib, I'd suggest using a lib that actually uses DOM/libxml underneath instead of string parsing.FluentDomFluentDOM provides a jQuery-like fluent XML interface for the DOMDocument in PHP. Selectors are written in XPath or CSS (using a CSS to XPath converter). Current versions extend the DOM implementing standard interfaces and add features from the DOM Living Standard. FluentDOM can load formats like JSON, CSV, JsonML, RabbitFish and others. Can be installed via Composer.HtmlPageDomWa72\HtmlPageDom is a PHP library for easy manipulation of HTMLdocuments using DOM. It requires DomCrawler from Symfony2components for traversingthe DOM tree and extends it by adding methods for manipulating theDOM tree of HTML documents.phpQueryphpQuery is a server-side, chainable, CSS3 selector driven Document Object Model (DOM) API based on jQuery JavaScript Library.The library is written in PHP5 and provides additional Command Line Interface (CLI).This is described as ""abandonware and buggy: use at your own risk"" but does appear to be minimally maintained.laminas-domThe Laminas\Dom component (formerly Zend_DOM) provides tools for working with DOM documents and structures. Currently, we offer Laminas\Dom\Query, which provides a unified interface for querying DOM documents utilizing both XPath and CSS selectors.This package is considered feature-complete, and is now in security-only maintenance mode.fDOMDocumentfDOMDocument extends the standard DOM to use exceptions at all occasions of errors instead of PHP warnings or notices. They also add various custom methods and shortcuts for convenience and to simplify the usage of DOM.sabre/xmlsabre/xml is a library that wraps and extends the XMLReader and XMLWriter classes to create a simple ""xml to object/array"" mapping system and design pattern. Writing and reading XML is single-pass and can therefore be fast and require low memory on large xml files.FluidXMLFluidXML is a PHP library for manipulating XML with a concise and fluent API.It leverages XPath and the fluent programming pattern to be fun and effective.3rd-Party (not libxml-based)The benefit of building upon DOM/libxml is that you get good performance out of the box because you are based on a native extension. However, not all 3rd-party libs go down this route. Some of them listed belowPHP Simple HTML DOM ParserAn HTML DOM parser written in PHP5+ lets you manipulate HTML in a very easy way!Require PHP 5+.Supports invalid HTML.Find tags on an HTML page with selectors just like jQuery.Extract contents from HTML in a single line.I generally do not recommend this parser. The codebase is horrible and the parser itself is rather slow and memory hungry. Not all jQuery Selectors (such as child selectors) are possible. Any of the libxml based libraries should outperform this easily.PHP Html ParserPHPHtmlParser is a simple, flexible, html parser which allows you to select tags using any css selector, like jQuery. The goal is to assiste in the development of tools which require a quick, easy way to scrape html, whether it's valid or not! This project was original supported by sunra/php-simple-html-dom-parser but the support seems to have stopped so this project is my adaptation of his previous work.Again, I would not recommend this parser. It is rather slow with high CPU usage. There is also no function to clear memory of created DOM objects. These problems scale particularly with nested loops. The documentation itself is inaccurate and misspelled, with no responses to fixes since 14 Apr 16.HTML 5You can use the above for parsing HTML5, but there can be quirks due to the markup HTML5 allows. So for HTML5 you may want to consider using a dedicated parser. Note that these are written in PHP, so suffer from slower performance and increased memory usage compared to a compiled extension in a lower-level language.HTML5DomDocumentHTML5DOMDocument extends the native DOMDocument library. It fixes some bugs and adds some new functionality.Preserves html entities (DOMDocument does not)Preserves void tags (DOMDocument does not)Allows inserting HTML code that moves the correct parts to their proper places (head elements are inserted in the head, body elements in the body)Allows querying the DOM with CSS selectors (currently available: *, tagname, tagname#id, #id, tagname.classname, .classname, tagname.classname.classname2, .classname.classname2, tagname[attribute-selector], [attribute-selector], div, p, div p, div > p, div + p, and p ~ ul.)Adds support for element->classList.Adds support for element->innerHTML.Adds support for element->outerHTML.HTML5HTML5 is a standards-compliant HTML5 parser and writer written entirely in PHP. It is stable and used in many production websites, and has well over five million downloads.HTML5 provides the following features.An HTML5 serializerSupport for PHP namespacesComposer supportEvent-based (SAX-like) parserA DOM tree builderInteroperability with QueryPathRuns on PHP 5.3.0 or newerRegular ExpressionsLast and least recommended, you can extract data from HTML with regular expressions. In general using Regular Expressions on HTML is discouraged.Most of the snippets you will find on the web to match markup are brittle. In most cases they are only working for a very particular piece of HTML. Tiny markup changes, like adding whitespace somewhere, or adding, or changing attributes in a tag, can make the RegEx fails when it's not properly written. You should know what you are doing before using RegEx on HTML.HTML parsers already know the syntactical rules of HTML. Regular expressions have to be taught for each new RegEx you write. RegEx are fine in some cases, but it really depends on your use-case.You can write more reliable parsers, but writing a complete and reliable custom parser with regular expressions is a waste of time when the aforementioned libraries already exist and do a much better job on this.Also see Parsing Html The Cthulhu WayBooksIf you want to spend some money, have a look atPHP Architect's Guide to Webscraping with PHPI am not affiliated with PHP Architect or the authors."
"data_i","edited Feb 03 '17 at 15:20","
        Why doesn't GCC optimize a*a*a*a*a*a to (a*a*a)*(a*a*a)?
    ","I am doing some numerical optimization on a scientific application. One thing I noticed is that GCC will optimize the call pow(a,2) by compiling it into a*a, but the call pow(a,6) is not optimized and will actually call the library function pow, which greatly slows down the performance. (In contrast, Intel C++ Compiler, executable icc, will eliminate the library call for pow(a,6).) What I am curious about is that when I replaced pow(a,6) with a*a*a*a*a*a using GCC 4.5.1 and options ""-O3 -lm -funroll-loops -msse4"", it uses 5 mulsd instructions:movapd  %xmm14, %xmm13mulsd   %xmm14, %xmm13mulsd   %xmm14, %xmm13mulsd   %xmm14, %xmm13mulsd   %xmm14, %xmm13mulsd   %xmm14, %xmm13while if I write (a*a*a)*(a*a*a), it will producemovapd  %xmm14, %xmm13mulsd   %xmm14, %xmm13mulsd   %xmm14, %xmm13mulsd   %xmm13, %xmm13which reduces the number of multiply instructions to 3. icc has similar behavior.Why do compilers not recognize this optimization trick?","Because Floating Point Math is not Associative.  The way you group the operands in floating point multiplication has an effect on the numerical accuracy of the answer.As a result, most compilers are very conservative about reordering floating point calculations unless they can be sure that the answer will stay the same, or unless you tell them you don't care about numerical accuracy.  For example: the -fassociative-math option of gcc which allows gcc to reassociate floating point operations, or even the -ffast-math option which allows even more aggressive tradeoffs of accuracy against speed."
"data_i","edited Jul 25 '22 at 02:42","
        How do I recover a dropped stash in Git?
    ","I frequently use git stash and git stash pop to save and restore changes in my working tree. Yesterday, I had some changes in my working tree that I had stashed and popped, and then I made more changes to my working tree. I'd like to go back and review yesterday's stashed changes, but git stash pop appears to remove all references to the associated commit.I know that if I use git stash then .git/refs/stash contains the reference of the commit used to create the stash. And .git/logs/refs/stash contains the whole stash. But those references are gone after git stash pop. I know that the commit is still in my repository somewhere, but I don't know what it was.Is there an easy way to recover yesterday's stash commit reference?","Once you know the hash of the stash commit you dropped, you can apply it as a stash:git stash apply $stash_hashOr, you can create a separate branch for it withgit branch recovered $stash_hashAfter that, you can do whatever you want with all the normal tools. When you’re done, just blow the branch away.Finding the hashIf you have only just popped it and the terminal is still open, you will still have the hash value printed by git stash pop on screen (thanks, Dolda).Otherwise, you can find it using this for Linux, Unix or Git Bash for Windows:git fsck --no-reflog | awk '/dangling commit/ {print $3}'...or using PowerShell for Windows:git fsck --no-reflog | select-string 'dangling commit' | foreach { $_.ToString().Split("" "")[2] }This will show you all the commits at the tips of your commit graph which are no longer referenced from any branch or tag – every lost commit, including every stash commit you’ve ever created, will be somewhere in that graph.The easiest way to find the stash commit you want is probably to pass that list to gitk:gitk --all $( git fsck --no-reflog | awk '/dangling commit/ {print $3}' )...or see the answer from emragins if using PowerShell for Windows.This will launch a repository browser showing you every single commit in the repository ever, regardless of whether it is reachable or not.You can replace gitk there with something like git log --graph --oneline --decorate if you prefer a nice graph on the console over a separate GUI app.To spot stash commits, look for commit messages of this form:        WIP on somebranch: commithash Some old commit messageNote: The commit message will only be in this form (starting with ""WIP on"") if you did not supply a message when you did git stash."
"data_i","edited Apr 06 '18 at 14:40","
        How do I center text horizontally and vertically in a TextView?
    ","How do I center the text horizontally and vertically in a TextView, so that it appears exactly in the middle of the TextView in Android?","I'm assuming you're using XML layout.<TextView      android:layout_width=""match_parent""     android:layout_height=""match_parent""     android:gravity=""center""    android:text=""@string/**yourtextstring**""/>You can also use gravity center_vertical or center_horizontal according to your need.As @stealthcopter commented, in java: .setGravity(Gravity.CENTER);.And for Kotlin users, .gravity = Gravity.CENTER"
"data_i","edited Jan 05 '22 at 21:38","
        What is a non-capturing group in regular expressions?
    ","How are non-capturing groups, i.e., (?:), used in regular expressions and what are they good for?","Let me try to explain this with an example.Consider the following text:http://stackoverflow.com/https://stackoverflow.com/questions/tagged/regexNow, if I apply the regex below over it...(https?|ftp)://([^/\r\n]+)(/[^\r\n]*)?... I would get the following result:Match ""http://stackoverflow.com/""     Group 1: ""http""     Group 2: ""stackoverflow.com""     Group 3: ""/""Match ""https://stackoverflow.com/questions/tagged/regex""     Group 1: ""https""     Group 2: ""stackoverflow.com""     Group 3: ""/questions/tagged/regex""But I don't care about the protocol -- I just want the host and path of the URL. So, I change the regex to include the non-capturing group (?:).(?:https?|ftp)://([^/\r\n]+)(/[^\r\n]*)?Now, my result looks like this:Match ""http://stackoverflow.com/""     Group 1: ""stackoverflow.com""     Group 2: ""/""Match ""https://stackoverflow.com/questions/tagged/regex""     Group 1: ""stackoverflow.com""     Group 2: ""/questions/tagged/regex""See? The first group has not been captured. The parser uses it to match the text, but ignores it later, in the final result.EDIT:As requested, let me try to explain groups too.Well, groups serve many purposes. They can help you to extract exact information from a bigger match (which can also be named), they let you rematch a previous matched group, and can be used for substitutions. Let's try some examples, shall we?Imagine you have some kind of XML or HTML (be aware that regex may not be the best tool for the job, but it is nice as an example). You want to parse the tags, so you could do something like this (I have added spaces to make it easier to understand):   \<(?<TAG>.+?)\> [^<]*? \</\k<TAG>\>or   \<(.+?)\> [^<]*? \</\1\>The first regex has a named group (TAG), while the second one uses a common group. Both regexes do the same thing: they use the value from the first group (the name of the tag) to match the closing tag. The difference is that the first one uses the name to match the value, and the second one uses the group index (which starts at 1).Let's try some substitutions now. Consider the following text:Lorem ipsum dolor sit amet consectetuer feugiat fames malesuada pretium egestas.Now, let's use this dumb regex over it:\b(\S)(\S)(\S)(\S*)\bThis regex matches words with at least 3 characters, and uses groups to separate the first three letters. The result is this:Match ""Lorem""     Group 1: ""L""     Group 2: ""o""     Group 3: ""r""     Group 4: ""em""Match ""ipsum""     Group 1: ""i""     Group 2: ""p""     Group 3: ""s""     Group 4: ""um""...Match ""consectetuer""     Group 1: ""c""     Group 2: ""o""     Group 3: ""n""     Group 4: ""sectetuer""...So, if we apply the substitution string:$1_$3$2_$4... over it, we are trying to use the first group, add an underscore, use the third group, then the second group, add another underscore, and then the fourth group. The resulting string would be like the one below.L_ro_em i_sp_um d_lo_or s_ti_ a_em_t c_no_sectetuer f_ue_giat f_ma_es m_la_esuada p_er_tium e_eg_stas.You can use named groups for substitutions too, using ${name}.To play around with regexes, I recommend http://regex101.com/, which offers a good amount of details on how the regex works; it also offers a few regex engines to choose from."
"data_i","edited Dec 22 '21 at 19:18","
        How to change the cursor into a hand when a user hovers over a list item?
    ","I've got a list, and I have a click handler for its items:<ul>  <li>foo</li>  <li>goo</li></ul>How can I change the mouse pointer into a hand pointer (like when hovering over a button)? Right now the pointer turns into a text selection pointer when I hover over the list items.","In light of the passage of time, as people have mentioned, you can now safely just use:li { cursor: pointer; }"
"data_i","edited May 31 '20 at 14:55","
        PostgreSQL: Show tables in PostgreSQL
    ","What's the equivalent to show tables (from MySQL) in PostgreSQL?","From the psql command line interface,First, choose your database\c database_nameThen, this shows all tables in the current schema:\dtProgrammatically (or from the psql interface too, of course):SELECT * FROM pg_catalog.pg_tables;The system tables live in the pg_catalog database."
"data_i","edited Jul 22 '22 at 20:24","
        How to leave/exit/deactivate a Python virtualenv
    ","I'm using virtualenv and the virtualenvwrapper. I can switch between virtualenv's just fine using the workon command.me@mymachine:~$ workon env1(env1)me@mymachine:~$ workon env2(env2)me@mymachine:~$ workon env1(env1)me@mymachine:~$ How do I exit all virtual environments and work on my system environment again? Right now, the only way I have of getting back to me@mymachine:~$ is to exit the shell and start a new one. That's kind of annoying. Is there a command to work on ""nothing"", and if so, what is it? If such a command does not exist, how would I go about creating it?","Usually, activating a virtualenv gives you a shell function named:$ deactivatewhich puts things back to normal.I have just looked specifically again at the code for virtualenvwrapper, and, yes, it too supports deactivate as the way to escape from all virtualenvs.If you are trying to leave an Anaconda environment, the command depends upon your version of conda. Recent versions (like 4.6) install a conda function directly in your shell, in which case you run:conda deactivateOlder conda versions instead implement deactivation using a stand-alone script:source deactivate"
"data_i","edited Nov 26 '19 at 20:20","
        How to write a switch statement in Ruby
    ","How do I write a switch statement in Ruby?","Ruby uses the case expression instead.case xwhen 1..5  ""It's between 1 and 5""when 6  ""It's 6""when ""foo"", ""bar""  ""It's either foo or bar""when String  ""You passed a string""else  ""You gave me #{x} -- I have no idea what to do with that.""endRuby compares the object in the when clause with the object in the case clause using the === operator. For example, 1..5 === x, and not x === 1..5. This allows for sophisticated when clauses as seen above. Ranges, classes and all sorts of things can be tested for rather than just equality.Unlike switch statements in many other languages, Ruby’s case does not have fall-through, so there is no need to end each when with a break. You can also specify multiple matches in a single when clause like when ""foo"", ""bar""."
"data_i","edited Aug 22 '22 at 08:58","
        How do I determine if an object has an attribute in Python?
    ","How do I determine if an object has some attribute? For example:>>> a = SomeClass()>>> a.propertyTraceback (most recent call last):  File ""<stdin>"", line 1, in <module>AttributeError: SomeClass instance has no attribute 'property'How do I tell if a has the attribute property before using it?","Try hasattr():if hasattr(a, 'property'):    a.propertySee zweiterlinde's answer below, who offers good advice about asking forgiveness! A very pythonic approach!The general practice in python is that, if the property is likely to be there most of the time, simply call it and either let the exception propagate, or trap it with a try/except block. This will likely be faster than hasattr. If the property is likely to not be there most of the time, or you're not sure, using hasattr will probably be faster than repeatedly falling into an exception block."
"data_i","edited Mar 03 '20 at 11:48","
        What is the best way to give a C# auto-property an initial value?
    ","How do you give a C# auto-property an initial value?I either use the constructor, or revert to the old syntax.  Using the Constructor:class Person {    public Person()    {        Name = ""Initial Name"";    }    public string Name { get; set; }}Using normal property syntax  (with an initial value)private string name = ""Initial Name"";public string Name {    get     {        return name;    }    set    {        name = value;    }}Is there a better way?","In C# 5 and earlier, to give auto implemented properties an initial value, you have to do it in a constructor.Since C# 6.0, you can specify initial value in-line. The syntax is:public int X { get; set; } = x; // C# 6 or higherDefaultValueAttribute is intended to be used by the VS designer (or any other consumer) to specify a default value, not an initial value. (Even if in designed object, initial value is the default value).At compile time DefaultValueAttribute will not impact the generated IL and it will not be read to initialize the property to that value (see DefaultValue attribute is not working with my Auto Property).Example of attributes that impact the IL are ThreadStaticAttribute, CallerMemberNameAttribute, ..."
"data_i","edited Jul 24 '22 at 22:55","
        Get selected value in dropdown list using JavaScript
    ","How do I get the selected value from a dropdown list using JavaScript?<form>  <select id=""ddlViewBy"">    <option value=""1"">test1</option>    <option value=""2"" selected=""selected"">test2</option>    <option value=""3"">test3</option>  </select></form>","Given a select element that looks like this:<select id=""ddlViewBy"">  <option value=""1"">test1</option>  <option value=""2"" selected=""selected"">test2</option>  <option value=""3"">test3</option></select>Running this code:var e = document.getElementById(""ddlViewBy"");var value = e.value;var text = e.options[e.selectedIndex].text;Results in:value == 2text == ""test2""Interactive example:var e = document.getElementById(""ddlViewBy"");function onChange() {  var value = e.value;  var text = e.options[e.selectedIndex].text;  console.log(value, text);}e.onchange = onChange;onChange();<form>  <select id=""ddlViewBy"">    <option value=""1"">test1</option>    <option value=""2"" selected=""selected"">test2</option>    <option value=""3"">test3</option>  </select></form>"
"data_i","edited Jun 08 '20 at 20:42","
        Vim clear last search highlighting
    ","After doing a search in Vim, I get all the occurrences highlighted. How can I disable that?  I now do another search for something gibberish that can't be found.Is there a way to just temporarily disable the highlight and then re-enable it when needed again?","To turn off highlighting until the next search::nohOr turn off highlighting completely:set nohlsearchOr, to toggle it:set hlsearch!nnoremap <F3> :set hlsearch!<CR>"
"data_i","edited Jun 06 '22 at 03:43","
        How can I randomly select an item from a list?
    ","How do I retrieve an item at random from the following list?foo = ['a', 'b', 'c', 'd', 'e']","Use random.choice():import randomfoo = ['a', 'b', 'c', 'd', 'e']print(random.choice(foo))For cryptographically secure random choices (e.g., for generating a passphrase from a wordlist), use secrets.choice():import secretsfoo = ['battery', 'correct', 'horse', 'staple']print(secrets.choice(foo))secrets is new in Python 3.6. On older versions of Python you can use the random.SystemRandom class:import randomsecure_random = random.SystemRandom()print(secure_random.choice(foo))"
"data_i","edited Aug 28 '22 at 02:26","
        Importing files from different folder
    ","I have this folder structure:application├── app│   └── folder│       └── file.py└── app2    └── some_folder        └── some_file.pyHow can I import a function from file.py, from within some_file.py? I tried:from application.app.folder.file import func_namebut it doesn't work.","Note: This answer was intended for a very specific question. For most programmers coming here from a search engine, this is not the answer you are looking for. Typically you would structure your files into packages (see other answers) instead of modifying the search path.By default, you can't. When importing a file, Python only searches the directory that the entry-point script is running from and sys.path which includes locations such as the package installation directory (it's actually a little more complex than this, but this covers most cases).However, you can add to the Python path at runtime:    # some_file.py    import sys    # caution: path[0] is reserved for script path (or '' in REPL)    sys.path.insert(1, '/path/to/application/app/folder')    import file"
"data_i","edited Apr 12 '22 at 01:07","
        JavaScript check if variable exists (is defined/initialized)
    ","Which method of checking if a variable has been initialized is better/correct?(Assuming the variable could hold anything (string, int, object, function, etc.))if (elem) { // or !elemorif (typeof elem !== 'undefined') {orif (elem != null) {","You want the typeof operator. Specifically:if (typeof variable !== 'undefined') {    // the variable is defined}"
"data_i","edited Dec 27 '16 at 02:52","
        How does PHP 'foreach' actually work?
    ","Let me prefix this by saying that I know what foreach is, does and how to use it. This question concerns how it works under the bonnet, and I don't want any answers along the lines of ""this is how you loop an array with foreach"".For a long time I assumed that foreach worked with the array itself. Then I found many references to the fact that it works with a copy of the array, and I have since assumed this to be the end of the story. But I recently got into a discussion on the matter, and after a little experimentation found that this was not in fact 100% true.Let me show what I mean. For the following test cases, we will be working with the following array:$array = array(1, 2, 3, 4, 5);Test case 1:foreach ($array as $item) {  echo ""$item\n"";  $array[] = $item;}print_r($array);/* Output in loop:    1 2 3 4 5   $array after loop: 1 2 3 4 5 1 2 3 4 5 */This clearly shows that we are not working directly with the source array - otherwise the loop would continue forever, since we are constantly pushing items onto the array during the loop. But just to be sure this is the case:Test case 2:foreach ($array as $key => $item) {  $array[$key + 1] = $item + 2;  echo ""$item\n"";}print_r($array);/* Output in loop:    1 2 3 4 5   $array after loop: 1 3 4 5 6 7 */This backs up our initial conclusion, we are working with a copy of the source array during the loop, otherwise we would see the modified values during the loop. But...If we look in the manual, we find this statement:When foreach first starts executing, the internal array pointer is automatically reset to the first element of the array.Right... this seems to suggest that foreach relies on the array pointer of the source array. But we've just proved that we're not working with the source array, right? Well, not entirely.Test case 3:// Move the array pointer on one to make sure it doesn't affect the loopvar_dump(each($array));foreach ($array as $item) {  echo ""$item\n"";}var_dump(each($array));/* Output  array(4) {    [1]=>    int(1)    [""value""]=>    int(1)    [0]=>    int(0)    [""key""]=>    int(0)  }  1  2  3  4  5  bool(false)*/So, despite the fact that we are not working directly with the source array, we are working directly with the source array pointer - the fact that the pointer is at the end of the array at the end of the loop shows this. Except this can't be true - if it was, then test case 1 would loop forever.The PHP manual also states:As foreach relies on the internal array pointer changing it within the loop may lead to unexpected behavior.Well, let's find out what that ""unexpected behavior"" is (technically, any behavior is unexpected since I no longer know what to expect).Test case 4:foreach ($array as $key => $item) {  echo ""$item\n"";  each($array);}/* Output: 1 2 3 4 5 */Test case 5:foreach ($array as $key => $item) {  echo ""$item\n"";  reset($array);}/* Output: 1 2 3 4 5 */...nothing that unexpected there, in fact it seems to support the ""copy of source"" theory.The QuestionWhat is going on here? My C-fu is not good enough for me to able to extract a proper conclusion simply by looking at the PHP source code, I would appreciate it if someone could translate it into English for me.It seems to me that foreach works with a copy of the array, but sets the array pointer of the source array to the end of the array after the loop.Is this correct and the whole story?If not, what is it really doing?Is there any situation where using functions that adjust the array pointer (each(), reset() et al.) during a foreach could affect the outcome of the loop?","foreach supports iteration over three different kinds of values:ArraysNormal objectsTraversable objectsIn the following, I will try to explain precisely how iteration works in different cases. By far the simplest case is Traversable objects, as for these foreach is essentially only syntax sugar for code along these lines:foreach ($it as $k => $v) { /* ... */ }/* translates to: */if ($it instanceof IteratorAggregate) {    $it = $it->getIterator();}for ($it->rewind(); $it->valid(); $it->next()) {    $v = $it->current();    $k = $it->key();    /* ... */}For internal classes, actual method calls are avoided by using an internal API that essentially just mirrors the Iterator interface on the C level.Iteration of arrays and plain objects is significantly more complicated. First of all, it should be noted that in PHP ""arrays"" are really ordered dictionaries and they will be traversed according to this order (which matches the insertion order as long as you didn't use something like sort). This is opposed to iterating by the natural order of the keys (how lists in other languages often work) or having no defined order at all (how dictionaries in other languages often work).The same also applies to objects, as the object properties can be seen as another (ordered) dictionary mapping property names to their values, plus some visibility handling. In the majority of cases, the object properties are not actually stored in this rather inefficient way. However, if you start iterating over an object, the packed representation that is normally used will be converted to a real dictionary. At that point, iteration of plain objects becomes very similar to iteration of arrays (which is why I'm not discussing plain-object iteration much in here).So far, so good. Iterating over a dictionary can't be too hard, right? The problems begin when you realize that an array/object can change during iteration. There are multiple ways this can happen:If you iterate by reference using foreach ($arr as &$v) then $arr is turned into a reference and you can change it during iteration.In PHP 5 the same applies even if you iterate by value, but the array was a reference beforehand: $ref =& $arr; foreach ($ref as $v)Objects have by-handle passing semantics, which for most practical purposes means that they behave like references. So objects can always be changed during iteration.The problem with allowing modifications during iteration is the case where the element you are currently on is removed. Say you use a pointer to keep track of which array element you are currently at. If this element is now freed, you are left with a dangling pointer (usually resulting in a segfault).There are different ways of solving this issue. PHP 5 and PHP 7 differ significantly in this regard and I'll describe both behaviors in the following. The summary is that PHP 5's approach was rather dumb and lead to all kinds of weird edge-case issues, while PHP 7's more involved approach results in more predictable and consistent behavior.As a last preliminary, it should be noted that PHP uses reference counting and copy-on-write to manage memory. This means that if you ""copy"" a value, you actually just reuse the old value and increment its reference count (refcount). Only once you perform some kind of modification a real copy (called a ""duplication"") will be done. See You're being lied to for a more extensive introduction on this topic.PHP 5Internal array pointer and HashPointerArrays in PHP 5 have one dedicated ""internal array pointer"" (IAP), which properly supports modifications: Whenever an element is removed, there will be a check whether the IAP points to this element. If it does, it is advanced to the next element instead.While foreach does make use of the IAP, there is an additional complication: There is only one IAP, but one array can be part of multiple foreach loops:// Using by-ref iteration here to make sure that it's really// the same array in both loops and not a copyforeach ($arr as &$v1) {    foreach ($arr as &$v) {        // ...    }}To support two simultaneous loops with only one internal array pointer, foreach performs the following shenanigans: Before the loop body is executed, foreach will back up a pointer to the current element and its hash into a per-foreach HashPointer. After the loop body runs, the IAP will be set back to this element if it still exists. If however the element has been removed, we'll just use wherever the IAP is currently at. This scheme mostly-kinda-sort of works, but there's a lot of weird behavior you can get out of it, some of which I'll demonstrate below.Array duplicationThe IAP is a visible feature of an array (exposed through the current family of functions), as such changes to the IAP count as modifications under copy-on-write semantics. This, unfortunately, means that foreach is in many cases forced to duplicate the array it is iterating over. The precise conditions are:The array is not a reference (is_ref=0). If it's a reference, then changes to it are supposed to propagate, so it should not be duplicated.The array has refcount>1. If refcount is 1, then the array is not shared and we're free to modify it directly.If the array is not duplicated (is_ref=0, refcount=1), then only its refcount will be incremented (*). Additionally, if foreach by reference is used, then the (potentially duplicated) array will be turned into a reference.Consider this code as an example where duplication occurs:function iterate($arr) {    foreach ($arr as $v) {}}$outerArr = [0, 1, 2, 3, 4];iterate($outerArr);Here, $arr will be duplicated to prevent IAP changes on $arr from leaking to $outerArr. In terms of the conditions above, the array is not a reference (is_ref=0) and is used in two places (refcount=2). This requirement is unfortunate and an artifact of the suboptimal implementation (there is no concern of modification during iteration here, so we don't really need to use the IAP in the first place).(*) Incrementing the refcount here sounds innocuous, but violates copy-on-write (COW) semantics: This means that we are going to modify the IAP of a refcount=2 array, while COW dictates that modifications can only be performed on refcount=1 values. This violation results in user-visible behavior change (while a COW is normally transparent) because the IAP change on the iterated array will be observable -- but only until the first non-IAP modification on the array. Instead, the three ""valid"" options would have been a) to always duplicate, b) do not increment the refcount and thus allowing the iterated array to be arbitrarily modified in the loop or c) don't use the IAP at all (the PHP 7 solution).Position advancement orderThere is one last implementation detail that you have to be aware of to properly understand the code samples below. The ""normal"" way of looping through some data structure would look something like this in pseudocode:reset(arr);while (get_current_data(arr, &data) == SUCCESS) {    code();    move_forward(arr);}However foreach, being a rather special snowflake, chooses to do things slightly differently:reset(arr);while (get_current_data(arr, &data) == SUCCESS) {    move_forward(arr);    code();}Namely, the array pointer is already moved forward before the loop body runs. This means that while the loop body is working on element $i, the IAP is already at element $i+1. This is the reason why code samples showing modification during iteration will always unset the next element, rather than the current one.Examples: Your test casesThe three aspects described above should provide you with a mostly complete impression of the idiosyncrasies of the foreach implementation and we can move on to discuss some examples. The behavior of your test cases is simple to explain at this point:In test cases 1 and 2 $array starts off with refcount=1, so it will not be duplicated by foreach: Only the refcount is incremented. When the loop body subsequently modifies the array (which has refcount=2 at that point), the duplication will occur at that point. Foreach will continue working on an unmodified copy of $array.In test case 3, once again the array is not duplicated, thus foreach will be modifying the IAP of the $array variable. At the end of the iteration, the IAP is NULL (meaning iteration has done), which each indicates by returning false.In test cases 4 and 5 both each and reset are by-reference functions. The $array has a refcount=2 when it is passed to them, so it has to be duplicated. As such foreach will be working on a separate array again.Examples: Effects of current in foreachA good way to show the various duplication behaviors is to observe the behavior of the  current() function inside a foreach loop. Consider this example:foreach ($array as $val) {    var_dump(current($array));}/* Output: 2 2 2 2 2 */Here you should know that current() is a by-ref function (actually: prefer-ref), even though it does not modify the array. It has to be in order to play nice with all the other functions like next which are all by-ref. By-reference passing implies that the array has to be separated and thus $array and the foreach-array will be different. The reason you get 2 instead of 1 is also mentioned above: foreach advances the array pointer before running the user code, not after. So even though the code is at the first element, foreach already advanced the pointer to the second.Now lets try a small modification:$ref = &$array;foreach ($array as $val) {    var_dump(current($array));}/* Output: 2 3 4 5 false */Here we have the is_ref=1 case, so the array is not copied (just like above). But now that it is a reference, the array no longer has to be duplicated when passing to the by-ref current() function. Thus current() and foreach work on the same array. You still see the off-by-one behavior though, due to the way foreach advances the pointer.You get the same behavior when doing by-ref iteration:foreach ($array as &$val) {    var_dump(current($array));}/* Output: 2 3 4 5 false */Here the important part is that foreach will make $array an is_ref=1 when it is iterated by reference, so basically you have the same situation as above.Another small variation, this time we'll assign the array to another variable:$foo = $array;foreach ($array as $val) {    var_dump(current($array));}/* Output: 1 1 1 1 1 */Here the refcount of the $array is 2 when the loop is started, so for once we actually have to do the duplication upfront. Thus $array and the array used by foreach will be completely separate from the outset. That's why you get the position of the IAP wherever it was before the loop (in this case it was at the first position).Examples: Modification during iterationTrying to account for modifications during iteration is where all our foreach troubles originated, so it serves to consider some examples for this case.Consider these nested loops over the same array (where by-ref iteration is used to make sure it really is the same one):foreach ($array as &$v1) {    foreach ($array as &$v2) {        if ($v1 == 1 && $v2 == 1) {            unset($array[1]);        }        echo ""($v1, $v2)\n"";    }}// Output: (1, 1) (1, 3) (1, 4) (1, 5)The expected part here is that (1, 2) is missing from the output because element 1 was removed. What's probably unexpected is that the outer loop stops after the first element. Why is that?The reason behind this is the nested-loop hack described above: Before the loop body runs, the current IAP position and hash is backed up into a HashPointer. After the loop body it will be restored, but only if the element still exists, otherwise the current IAP position (whatever it may be) is used instead. In the example above this is exactly the case: The current element of the outer loop has been removed, so it will use the IAP, which has already been marked as finished by the inner loop!Another consequence of the HashPointer backup+restore mechanism is that changes to the IAP through reset() etc. usually do not impact foreach. For example, the following code executes as if the reset() were not present at all:$array = [1, 2, 3, 4, 5];foreach ($array as &$value) {    var_dump($value);    reset($array);}// output: 1, 2, 3, 4, 5The reason is that, while reset() temporarily modifies the IAP, it will be restored to the current foreach element after the loop body. To force reset() to make an effect on the loop, you have to additionally remove the current element, so that the backup/restore mechanism fails:$array = [1, 2, 3, 4, 5];$ref =& $array;foreach ($array as $value) {    var_dump($value);    unset($array[1]);    reset($array);}// output: 1, 1, 3, 4, 5But, those examples are still sane. The real fun starts if you remember that the HashPointer restore uses a pointer to the element and its hash to determine whether it still exists. But: Hashes have collisions, and pointers can be reused! This means that, with a careful choice of array keys, we can make foreach believe that an element that has been removed still exists, so it will jump directly to it. An example:$array = ['EzEz' => 1, 'EzFY' => 2, 'FYEz' => 3];$ref =& $array;foreach ($array as $value) {    unset($array['EzFY']);    $array['FYFY'] = 4;    reset($array);    var_dump($value);}// output: 1, 4Here we should normally expect the output 1, 1, 3, 4 according to the previous rules. How what happens is that 'FYFY' has the same hash as the removed element 'EzFY', and the allocator happens to reuse the same memory location to store the element. So foreach ends up directly jumping to the newly inserted element, thus short-cutting the loop.Substituting the iterated entity during the loopOne last odd case that I'd like to mention, it is that PHP allows you to substitute the iterated entity during the loop. So you can start iterating on one array and then replace it with another array halfway through. Or start iterating on an array and then replace it with an object:$arr = [1, 2, 3, 4, 5];$obj = (object) [6, 7, 8, 9, 10];$ref =& $arr;foreach ($ref as $val) {    echo ""$val\n"";    if ($val == 3) {        $ref = $obj;    }}/* Output: 1 2 3 6 7 8 9 10 */As you can see in this case PHP will just start iterating the other entity from the start once the substitution has happened.PHP 7Hashtable iteratorsIf you still remember, the main problem with array iteration was how to handle removal of elements mid-iteration. PHP 5 used a single internal array pointer (IAP) for this purpose, which was somewhat suboptimal, as one array pointer had to be stretched to support multiple simultaneous foreach loops and interaction with reset() etc. on top of that.PHP 7 uses a different approach, namely, it supports creating an arbitrary amount of external, safe hashtable iterators. These iterators have to be registered in the array, from which point on they have the same semantics as the IAP: If an array element is removed, all hashtable iterators pointing to that element will be advanced to the next element.This means that foreach will no longer use the IAP at all. The foreach loop will be absolutely no effect on the results of current() etc. and its own behavior will never be influenced by functions like  reset() etc.Array duplicationAnother important change between PHP 5 and PHP 7 relates to array duplication. Now that the IAP is no longer used, by-value array iteration will only do a refcount increment (instead of duplication the array) in all cases. If the array is modified during the foreach loop, at that point a duplication will occur (according to copy-on-write) and foreach will keep working on the old array.In most cases, this change is transparent and has no other effect than better performance. However, there is one occasion where it results in different behavior, namely the case where the array was a reference beforehand:$array = [1, 2, 3, 4, 5];$ref = &$array;foreach ($array as $val) {    var_dump($val);    $array[2] = 0;}/* Old output: 1, 2, 0, 4, 5 *//* New output: 1, 2, 3, 4, 5 */Previously by-value iteration of reference-arrays was special cases. In this case, no duplication occurred, so all modifications of the array during iteration would be reflected by the loop. In PHP 7 this special case is gone: A by-value iteration of an array will always keep working on the original elements, disregarding any modifications during the loop.This, of course, does not apply to by-reference iteration. If you iterate by-reference all modifications will be reflected by the loop. Interestingly, the same is true for by-value iteration of plain objects:$obj = new stdClass;$obj->foo = 1;$obj->bar = 2;foreach ($obj as $val) {    var_dump($val);    $obj->bar = 42;}/* Old and new output: 1, 42 */This reflects the by-handle semantics of objects (i.e. they behave reference-like even in by-value contexts).ExamplesLet's consider a few examples, starting with your test cases:Test cases 1 and 2 retain the same output: By-value array iteration always keep working on the original elements. (In this case, even refcounting and duplication behavior is exactly the same between PHP 5 and PHP 7).Test case 3 changes: Foreach no longer uses the IAP, so each() is not affected by the loop. It will have the same output before and after.Test cases 4 and 5 stay the same: each() and reset() will duplicate the array before changing the IAP, while foreach still uses the original array. (Not that the IAP change would have mattered, even if the array was shared.)The second set of examples was related to the behavior of current() under different reference/refcounting configurations. This no longer makes sense, as current() is completely unaffected by the loop, so its return value always stays the same.However, we get some interesting changes when considering modifications during iteration. I hope you will find the new behavior saner. The first example:$array = [1, 2, 3, 4, 5];foreach ($array as &$v1) {    foreach ($array as &$v2) {        if ($v1 == 1 && $v2 == 1) {            unset($array[1]);        }        echo ""($v1, $v2)\n"";    }}// Old output: (1, 1) (1, 3) (1, 4) (1, 5)// New output: (1, 1) (1, 3) (1, 4) (1, 5)//             (3, 1) (3, 3) (3, 4) (3, 5)//             (4, 1) (4, 3) (4, 4) (4, 5)//             (5, 1) (5, 3) (5, 4) (5, 5) As you can see, the outer loop no longer aborts after the first iteration. The reason is that both loops now have entirely separate hashtable iterators, and there is no longer any cross-contamination of both loops through a shared IAP.Another weird edge case that is fixed now, is the odd effect you get when you remove and add elements that happen to have the same hash:$array = ['EzEz' => 1, 'EzFY' => 2, 'FYEz' => 3];foreach ($array as &$value) {    unset($array['EzFY']);    $array['FYFY'] = 4;    var_dump($value);}// Old output: 1, 4// New output: 1, 3, 4Previously the HashPointer restore mechanism jumped right to the new element because it ""looked"" like it's the same as the removed element (due to colliding hash and pointer). As we no longer rely on the element hash for anything, this is no longer an issue."
"data_i","edited Apr 11 '19 at 11:54","
        How do I set a variable to the output of a command in Bash?
    ","I have a pretty simple script that is something like the following:#!/bin/bashVAR1=""$1""MOREF='sudo run command against $VAR1 | grep name | cut -c7-'echo $MOREFWhen I run this script from the command line and pass it the arguments, I am not getting any output.  However, when I run the commands contained within the $MOREF variable, I am able to get output.How can one take the results of a command that needs to be run within a script, save it to a variable, and then output that variable on the screen?","In addition to backticks `command`, command substitution can be done with $(command) or ""$(command)"", which I find easier to read, and allows for nesting.OUTPUT=$(ls -1)echo ""${OUTPUT}""MULTILINE=$(ls \   -1)echo ""${MULTILINE}""Quoting ("") does matter to preserve multi-line variable values; it is optional on the right-hand side of an assignment, as word splitting is not performed, so OUTPUT=$(ls -1) would work fine."
"data_i","edited Oct 12 '21 at 12:25","
        What is a JavaBean exactly?
    ","I understood, I think, that a ""Bean"" is a Java-class with properties and getters/setters. As much as I understand, it is the equivalent of a C struct. Is that true?Also, is there a real syntactic difference between a JavaBean and a regular class? Is there any special definition or an Interface?Basically, why is there a term for this?Also what does the Serializable interface mean?","A JavaBean is just a standard. It is a regular Java class, except it follows certain conventions:All properties are private (use getters/setters)A public no-argument constructorImplements Serializable.That's it. It's just a convention.  Lots of libraries depend on it though.With respect to Serializable, from the API documentation:Serializability of a class is enabled by the class implementing thejava.io.Serializable interface. Classes that do not implement thisinterface will not have any of their state serialized or deserialized.All subtypes of a serializable class are themselves serializable. Theserialization interface has no methods or fields and serves only toidentify the semantics of being serializable.In other words, serializable objects can be written to streams, and hence files, object databases, anything really.Also, there is no syntactic difference between a JavaBean and another class -- a class is a JavaBean if it follows the standards.There is a term for it, because the standard allows libraries to programmatically do things with class instances you define in a predefined way. For example, if a library wants to stream any object you pass into it, it knows it can because your object is serializable (assuming the library requires your objects be proper JavaBeans)."
"data_i","edited Oct 14 '20 at 12:57","
        How to copy files from host to Docker container?
    ","I am trying to build a backup and restore solution for the Docker containers that we work with.I have Docker base image that I have created, ubuntu:base, and do not want have to rebuild it each time with a Docker file to add files to it.I want to create a script that runs from the host machine and creates a new container using the ubuntu:base Docker image and then copies files into that container.How can I copy files from the host to the container?","The cp command can be used to copy files.One specific file can be copied TO the container like:docker cp foo.txt container_id:/foo.txtOne specific file can be copied FROM the container like:docker cp container_id:/foo.txt foo.txtFor emphasis, container_id is a container ID, not an image ID. (Use docker ps to view listing which includes container_ids.)Multiple files contained by the folder src can be copied into the target folder using:docker cp src/. container_id:/targetdocker cp container_id:/src/. targetReference: Docker CLI docs for cpIn Docker versions prior to 1.8 it was only possible to copy files from a container to the host. Not from the host to a container."
"data_i","edited Jun 26 '20 at 17:28","
        When should I use double or single quotes in JavaScript?
    ","console.log(""double""); vs. console.log('single');I see more and more JavaScript libraries out there using single quotes when handling strings. What are the reasons to use one over the other?I thought they're pretty much interchangeable.","The most likely reason for use of single vs. double in different libraries is programmer preference and/or API consistency. Other than being consistent, use whichever best suits the string.Using the other type of quote as a literal:alert('Say ""Hello""');alert(""Say 'Hello'"");This can get complicated:alert(""It's \""game\"" time."");alert('It\'s ""game"" time.');Another option, new in ECMAScript 6, is template literals which use the backtick character:alert(`Use ""double"" and 'single' quotes in the same string`);alert(`Escape the \` back-tick character and the \${ dollar-brace sequence in a string`);Template literals offer a clean syntax for: variable interpolation, multi-line strings, and more.Note that JSON is formally specified to use double quotes, which may be worth considering depending on system requirements."
"data_i","edited Apr 11 '22 at 21:42","
        How can I select an element with multiple classes in jQuery?
    ","I want to select all the elements that have the two classes a and b.<element class=""a b"">So, only the elements that have both classes.When I use $("".a, .b"") it gives me the union, but I want the intersection.","If you want to match only elements with both classes (an intersection, like a logical AND), just write the selectors together without spaces in between:$('.a.b')The order is not relevant, so you can also swap the classes:$('.b.a')So to match a div element that has an ID of a with classes b and c, you would write:$('div#a.b.c')(In practice, you most likely don't need to get that specific, and an ID or class selector by itself is usually enough: $('#a').)"
"data_i","edited Aug 17 '20 at 09:58","
        What are valid values for the id attribute in HTML?
    ","When creating the id attributes for HTML elements, what rules are there for the value?","For HTML 4, the answer is technically:ID and NAME tokens must begin with a letter ([A-Za-z]) and may be followed by any number of letters, digits ([0-9]), hyphens (""-""), underscores (""_""), colons ("":""), and periods (""."").HTML 5 is even more permissive, saying only that an id must contain at least one character and may not contain any space characters.The id attribute is case sensitive in XHTML.As a purely practical matter, you may want to avoid certain characters. Periods, colons and '#' have special meaning in CSS selectors, so you will have to escape those characters using a backslash in CSS or a double backslash in a selector string passed to jQuery. Think about how often you will have to escape a character in your stylesheets or code before you go crazy with periods and colons in ids.For example, the HTML declaration <div id=""first.name""></div> is valid. You can select that element in CSS as #first\.name and in jQuery like so: $('#first\\.name'). But if you forget the backslash, $('#first.name'), you will have a perfectly valid selector looking for an element with id first and also having class name. This is a bug that is easy to overlook. You might be happier in the long run choosing the id first-name (a hyphen rather than a period), instead.You can simplify your development tasks by strictly sticking to a naming convention. For example, if you limit yourself entirely to lower-case characters and always separate words with either hyphens or underscores (but not both, pick one and never use the other), then you have an easy-to-remember pattern. You will never wonder ""was it firstName or FirstName?"" because you will always know that you should type first_name. Prefer camel case? Then limit yourself to that, no hyphens or underscores, and always, consistently use either upper-case or lower-case for the first character, don't mix them.A now very obscure problem was that at least one browser, Netscape 6, incorrectly treated id attribute values as case-sensitive. That meant that if you had typed id=""firstName"" in your HTML (lower-case 'f') and #FirstName { color: red } in your CSS (upper-case 'F'), that buggy browser would have failed to set the element's color to red. At the time of this edit, April 2015, I hope you aren't being asked to support Netscape 6. Consider this a historical footnote."
"data_i","asked Jun 03 '09 at 06:46","
        Get int value from enum in C#
    ","I have a class called Questions (plural). In this class there is an enum called Question (singular) which looks like this.public enum Question{    Role = 2,    ProjectFunding = 3,    TotalEmployee = 4,    NumberOfServers = 5,    TopBusinessConcern = 6}In the Questions class I have a get(int foo) function that returns a Questions object for that foo. Is there an easy way to get the integer value off the enum so I can do something like this Questions.Get(Question.Role)?","Just cast the enum, e.g.int something = (int) Question.Role;The above will work for the vast majority of enums you see in the wild, as the default underlying type for an enum is int.However, as cecilphillip points out, enums can have different underlying types.If an enum is declared as a uint, long, or ulong, it should be cast to the type of the enum; e.g. forenum StarsInMilkyWay:long {Sun = 1, V645Centauri = 2 .. Wolf424B = 2147483649};you should uselong something = (long)StarsInMilkyWay.Wolf424B;"
"data_i","asked May 26 '17 at 17:03","
        Do I commit the package-lock.json file created by npm 5?
    ","npm 5 was released today and one of the new features include deterministic installs with the creation of a package-lock.json file.Is this file supposed to be kept in source control?I'm assuming it's similar to yarn.lock and composer.lock, both of which are supposed to be kept in source control. ","Yes, package-lock.json is intended to be checked into source control. If you're using npm 5+, you may see this notice on the command line: created a lockfile as package-lock.json. You should commit this file. According to npm help package-lock.json:package-lock.json is automatically generated for any operations where npmmodifies either the node_modules tree, or package.json. It describes theexact tree that was generated, such that subsequent installs are able togenerate identical trees, regardless of intermediate dependency updates.This file is intended to be committed into source repositories, and servesvarious purposes:Describe a single representation of a dependency tree such that teammates, deployments, and continuous integration are guaranteed to install exactly the same dependencies.Provide a facility for users to ""time-travel"" to previous states of node_modules without having to commit the directory itself.To facilitate greater visibility of tree changes through readable source control diffs.And optimize the installation process by allowing npm to skip repeated metadata resolutions for previously-installed packages.One key detail about package-lock.json is that it cannot be published, and itwill be ignored if found in any place other than the toplevel package. It sharesa format with npm-shrinkwrap.json, which is essentially the same file, butallows publication. This is not recommended unless deploying a CLI tool orotherwise using the publication process for producing production packages.If both package-lock.json and npm-shrinkwrap.json are present in the root ofa package, package-lock.json will be completely ignored."
"data_i","edited Jun 30 '22 at 03:57","
        How do you assert that a certain exception is thrown in JUnit tests?
    ","How can I use JUnit idiomatically to test that some code throws an exception?While I can certainly do something like this:@Testpublic void testFooThrowsIndexOutOfBoundsException() {  boolean thrown = false;  try {    foo.doStuff();  } catch (IndexOutOfBoundsException e) {    thrown = true;  }  assertTrue(thrown);}I recall that there is an annotation or an Assert.xyz or something that is far less kludgy and far more in-the-spirit of JUnit for these sorts of situations.","It depends on the JUnit version and what assert libraries you use.For JUnit5 and 4.13 see answer https://stackoverflow.com/a/2935935/2986984If you use assertJ or google-truth, see answer  https://stackoverflow.com/a/41019785/2986984The original answer for JUnit <= 4.12 was:@Test(expected = IndexOutOfBoundsException.class)public void testIndexOutOfBoundsException() {    ArrayList emptyList = new ArrayList();    Object o = emptyList.get(0);}Though answer https://stackoverflow.com/a/31826781/2986984 has more options for JUnit <= 4.12.Reference : JUnit Test-FAQ"
"data_i","edited Dec 06 '19 at 20:52","
        What is Inversion of Control?
    ","Inversion of Control (IoC) can be quite confusing when it is first encountered.What is it?Which problem does it solve?When is it appropriate to use and when not?","The Inversion-of-Control (IoC) pattern, is about providing any kind of callback (which controls reaction), instead of acting ourself directly (in other words, inversion and/or redirecting control to external handler/controller). The Dependency-Injection (DI) pattern is a more specific version of IoC pattern, and is all about removing dependencies from your code.Every DI implementation can be considered IoC, but one should not call it IoC, because implementing Dependency-Injection is harder than callback (Don't lower your product's worth by using general term ""IoC"" instead).For DI example, say your application has a text-editor component, and you want to provide spell checking. Your standard code would look something like this:public class TextEditor {    private SpellChecker checker;    public TextEditor() {        this.checker = new SpellChecker();    }}What we've done here creates a dependency between the TextEditor and the SpellChecker.In an IoC scenario we would instead do something like this:public class TextEditor {    private IocSpellChecker checker;    public TextEditor(IocSpellChecker checker) {        this.checker = checker;    }}In the first code example we are instantiating SpellChecker (this.checker = new SpellChecker();), which means the TextEditor class directly depends on the SpellChecker class.In the second code example we are creating an abstraction by having the SpellChecker dependency class in TextEditor's constructor signature (not initializing dependency in class). This allows us to call the dependency then pass it to the TextEditor class like so:SpellChecker sc = new SpellChecker(); // dependencyTextEditor textEditor = new TextEditor(sc);Now the client creating the TextEditor class has control over which SpellChecker implementation to use because we're injecting the dependency into the TextEditor signature."
"data_i","edited Jul 30 '19 at 14:15","
        HTML 5: Is it , , or ?
    ","I've tried checking other answers, but I'm still confused — especially after seeing W3schools HTML 5 reference.I thought HTML 4.01 was supposed to ""allow"" single-tags to just be <img> and <br>. Then XHTML came along with <img /> and <br /> (where someone said that the space is there for older browsers).Now I'm wondering how I'm supposed to format my code when practicing HTML 5. Is it <br>, <br/> or <br />?","Simply <br> is sufficient.The other forms are there for compatibility with XHTML; to make it possible to write the same code as XHTML, and have it also work as HTML. Some systems that generate HTML may be based on XML generators, and thus do not have the ability to output just a bare <br> tag; if you're using such a system, it's fine to use <br/>, it's just not necessary if you don't need to do it.Very few people actually use XHTML, however. You need to serve your content as application/xhtml+xml for it to be interpreted as XHTML, and that will not work in old versions of IE - it will also mean that any small error you make will prevent your page from being displayed in browsers that do support XHTML. So, most of what looks like XHTML on the web is actually being served, and interpreted, as HTML. See Serving XHTML as text/html Considered Harmful for some more information."
"data_i","edited Nov 04 '18 at 11:11","
        What is 'Context' on Android?
    ","In Android programming, what exactly is a Context class and what is it used for?I read about it on the developer site, but I am unable to understand it clearly.","Putting it simply:As the name suggests, it's the context of the current state of the application/object. It lets newly-created objects understand what has been going on. Typically you call it to get information regarding another part of your program (activity and package/application).You can get the context by invoking getApplicationContext(), getContext(), getBaseContext() or this (when in a class that extends from Context, such as the Application, Activity, Service and IntentService classes).Typical uses of context:Creating new objects:Creating new views, adapters, listeners: TextView tv = new TextView(getContext()); ListAdapter adapter = new SimpleCursorAdapter(getApplicationContext(), ...);Accessing standard common resources:Services like LAYOUT_INFLATER_SERVICE, SharedPreferences: context.getSystemService(LAYOUT_INFLATER_SERVICE) getApplicationContext().getSharedPreferences(*name*, *mode*);Accessing components implicitly:Regarding content providers, broadcasts, intent getApplicationContext().getContentResolver().query(uri, ...);"
"data_i","edited May 13 '20 at 00:03","
        How to delete from a text file, all lines that contain a specific string?
    ","How would I use sed to delete all lines in a text file that contain a specific string?","To remove the line and print the output to standard out:sed '/pattern to match/d' ./infileTo directly modify the file – does not work with BSD sed:sed -i '/pattern to match/d' ./infileSame, but for BSD sed (Mac OS X and FreeBSD) – does not work with GNU sed:sed -i '' '/pattern to match/d' ./infileTo directly modify the file (and create a backup) – works with BSD and GNU sed:sed -i.bak '/pattern to match/d' ./infile"
"data_i","edited Apr 01 '22 at 12:03","
        How do I get the number of elements in a list in Python?
    ","How do I get the number of elements in the list items?items = [""apple"", ""orange"", ""banana""]# There are 3 items.","The len() function can be used with several different types in Python - both built-in types and library types. For example:>>> len([1, 2, 3])3"
"data_i","edited Nov 11 '15 at 19:22","
        How do I empty an array in JavaScript?
    ","Is there a way to empty an array and if so possibly with .remove()?For instance, A = [1,2,3,4];How can I empty that?","Ways to clear an existing array A:Method 1(this was my original answer to the question)A = [];This code will set the variable A to a new empty array. This is perfect if you don't have references to the original array A anywhere else because this actually creates a brand new (empty) array. You should be careful with this method because if you have referenced this array from another variable or property, the original array will remain unchanged. Only use this if you only reference the array by its original variable A.This is also the fastest solution.This code sample shows the issue you can encounter when using this method:var arr1 = ['a','b','c','d','e','f'];var arr2 = arr1;  // Reference arr1 by another variable arr1 = [];console.log(arr2); // Output ['a','b','c','d','e','f']Method 2 (as suggested by Matthew Crumley)A.length = 0This will clear the existing array by setting its length to 0. Some have argued that this may not work in all implementations of JavaScript, but it turns out that this is not the case. It also works when using ""strict mode"" in ECMAScript 5 because the length property of an array is a read/write property.Method 3 (as suggested by Anthony)A.splice(0,A.length)Using .splice() will work perfectly, but since the .splice() function will return an array with all the removed items, it will actually return a copy of the original array. Benchmarks suggest that this has no effect on performance whatsoever.Method 4 (as suggested by tanguy_k)while(A.length > 0) {    A.pop();}This solution is not very succinct, and it is also the slowest solution, contrary to earlier benchmarks referenced in the original answer.PerformanceOf all the methods of clearing an existing array, methods 2 and 3 are very similar in performance and are a lot faster than method 4. See this benchmark.As pointed out by Diadistis in their answer below, the original benchmarks that were used to determine the performance of the four methods described above were flawed. The original benchmark reused the cleared array so the second iteration was clearing an array that was already empty.The following benchmark fixes this flaw: http://jsben.ch/#/hyj65. It clearly shows that methods #2 (length property) and #3 (splice) are the fastest (not counting method #1 which doesn't change the original array).This has been a hot topic and the cause of a lot of controversy. There are actually many correct answers and because this answer has been marked as the accepted answer for a very long time, I will include all of the methods here."
"data_i","edited Nov 02 '18 at 23:23","
        How to decide when to use Node.js?
    ","I am new to this kind of stuff, but lately I've been hearing a lot about how good Node.js is. Considering how much I love working with jQuery and JavaScript in general, I can't help but wonder how to decide when to use Node.js. The web application I have in mind is something like Bitly - takes some content, archives it. From all the homework I have been doing in the last few days, I obtained the following information. Node.js is a command-line tool that can be run as a regular web server and lets one run JavaScript programsutilizes the great V8 JavaScript engineis very good when you need to do several things at the same timeis event-based so all the wonderful Ajax-like stuff can be done on the server sidelets us share code between the browser and the backendlets us talk with MySQLSome of the sources that I have come across are:Diving into Node.js – Introduction and InstallationUnderstanding NodeJSNode by Example (Archive.is)Let’s Make a Web App: NodePadConsidering that Node.js can be run almost out-of-the-box on Amazon's EC2 instances, I am trying to understand what type of problems require Node.js as opposed to any of the mighty kings out there like PHP, Python and Ruby. I understand that it really depends on the expertise one has on a language, but my question falls more into the general category of: When to use a particular framework and what type of problems is it particularly suited for?","You did a great job of summarizing what's awesome about Node.js. My feeling is that Node.js is especially suited for applications where you'd like to maintain a persistent connection from the browser back to the server. Using a technique known as ""long-polling"", you can write an application that sends updates to the user in real time. Doing long polling on many of the web's giants, like Ruby on Rails or Django, would create immense load on the server, because each active client eats up one server process. This situation amounts to a tarpit attack. When you use something like Node.js, the server has no need of maintaining separate threads for each open connection.  This means you can create a browser-based chat application in Node.js that takes almost no system resources to serve a great many clients. Any time you want to do this sort of long-polling, Node.js is a great option.  It's worth mentioning that Ruby and Python both have tools to do this sort of thing (eventmachine and twisted, respectively), but that Node.js does it exceptionally well, and from the ground up. JavaScript is exceptionally well situated to a callback-based concurrency model, and it excels here. Also, being able to serialize and deserialize with JSON native to both the client and the server is pretty nifty. I look forward to reading other answers here, this is a fantastic question. It's worth pointing out that Node.js is also great for situations in which you'll be reusing a lot of code across the client/server gap. The Meteor framework makes this really easy, and a lot of folks are suggesting this might be the future of web development. I can say from experience that it's a whole lot of fun to write code in Meteor, and a big part of this is spending less time thinking about how you're going to restructure your data, so the code that runs in the browser can easily manipulate it and pass it back. Here's an article on Pyramid and long-polling, which turns out to be very easy to set up with a little help from gevent: TicTacToe and Long Polling with Pyramid."
"data_i","edited Feb 19 '21 at 19:14","
        Vertically align text next to an image?
    ","Why won't vertical-align: middle work?  And yet, vertical-align: top does work.span{  vertical-align: middle;}<div>  <img src=""https://via.placeholder.com/30"" alt=""small img"" />  <span>Doesn't work.</span></div>","Actually, in this case it's quite simple: apply the vertical align to the image. Since it's all in one line, it's really the image you want aligned, not the text.<!-- moved ""vertical-align:middle"" style from span to img --><div>  <img style=""vertical-align:middle"" src=""https://via.placeholder.com/60x60"" alt=""A grey image showing text 60 x 60"">  <span style="""">Works.</span></div>Tested in FF3.Now you can use flexbox for this type of layout..box {   display: flex;   align-items:center;}<div class=""box"">    <img src=""https://via.placeholder.com/60x60"">    <span style="""">Works.</span></div>"
"data_i","edited Mar 01 '22 at 17:18","
        How to check if a variable is set in Bash
    ","How do I know if a variable is set in Bash?For example, how do I check if the user gave the first parameter to a function?function a {    # if $1 is set ?}","(Usually) The right wayif [ -z ${var+x} ]; then echo ""var is unset""; else echo ""var is set to '$var'""; fiwhere ${var+x} is a parameter expansion which evaluates to nothing if var is unset, and substitutes the string x otherwise.Quotes DigressionQuotes can be omitted (so we can say ${var+x} instead of ""${var+x}"") because this syntax & usage guarantees this will only expand to something that does not require quotes (since it either expands to x (which contains no word breaks so it needs no quotes), or to nothing (which results in [ -z  ], which conveniently evaluates to the same value (true) that [ -z """" ] does as well)).However, while quotes can be safely omitted, and it was not immediately obvious to all (it wasn't even apparent to the first author of this quotes explanation who is also a major Bash coder), it would sometimes be better to write the solution with quotes as [ -z ""${var+x}"" ], at the very small possible cost of an O(1) speed penalty.  The first author also added this as a comment next to the code using this solution giving the URL to this answer, which now also includes the explanation for why the quotes can be safely omitted.(Often) The wrong wayif [ -z ""$var"" ]; then echo ""var is blank""; else echo ""var is set to '$var'""; fiThis is often wrong because it doesn't distinguish between a variable that is unset and a variable that is set to the empty string. That is to say, if var='', then the above solution will output ""var is blank"".The distinction between unset and ""set to the empty string"" is essential in situations where the user has to specify an extension, or additional list of properties, and that not specifying them defaults to a non-empty value, whereas specifying the empty string should make the script use an empty extension or list of additional properties.The distinction may not be essential in every scenario though. In those cases  [ -z ""$var"" ] will be just fine."
"data_i","edited Apr 09 '22 at 07:00","
        How do I print curly-brace characters in a string while using .format?
    ","Non-working example:print("" \{ Hello \} {0} "".format(42))Desired output: {Hello} 42 ","You need to double the {{ and }}:>>> x = "" {{ Hello }} {0} "">>> print(x.format(42))' { Hello } 42 'Here's the relevant part of the Python documentation for format string syntax:Format strings contain “replacement fields” surrounded by curly braces {}. Anything that is not contained in braces is considered literal text, which is copied unchanged to the output. If you need to include a brace character in the literal text, it can be escaped by doubling: {{ and }}."
"data_i","edited Sep 23 '22 at 14:04","
        Limiting floats to two decimal points
    ","I want a to be rounded to 13.95. I tried using round, but I get:>>> a13.949999999999999>>> round(a, 2)13.949999999999999For the analogous issue with the standard library Decimal class, see How can I format a decimal to always show 2 decimal places?.","You are running into the old problem with floating point numbers that not all numbers can be represented exactly. The command line is just showing you the full floating point form from memory.With floating point representation, your rounded version is the same number. Since computers are binary, they store floating point numbers as an integer and then divide it by a power of two so 13.95 will be represented in a similar fashion to 125650429603636838/(2**53).Double precision numbers have 53 bits (16 digits) of precision and regular floats have 24 bits (8 digits) of precision. The floating point type in Python uses double precision to store the values.For example,>>> 125650429603636838/(2**53)13.949999999999999>>> 234042163/(2**24)13.949999988079071>>> a = 13.946>>> print(a)13.946>>> print(""%.2f"" % a)13.95>>> round(a,2)13.949999999999999>>> print(""%.2f"" % round(a, 2))13.95>>> print(""{:.2f}"".format(a))13.95>>> print(""{:.2f}"".format(round(a, 2)))13.95>>> print(""{:.15f}"".format(round(a, 2)))13.949999999999999If you are after only two decimal places (to display a currency value, for example), then you have a couple of better choices:Use integers and store values in cents, not dollars and then divide by 100 to convert to dollars.Or use a fixed point number like decimal."
"data_i","edited Sep 02 '21 at 23:14","
        When should I use 'self' over '$this'?
    ","In PHP 5, what is the difference between using self and $this?When is each appropriate?","Short AnswerUse $this to refer to the current  object. Use self to refer to the  current class. In other words, use  $this->member for non-static members,  use self::$member for static members.Full AnswerHere is an example of correct usage of $this and self for non-static and static member variables:<?phpclass X {    private $non_static_member = 1;    private static $static_member = 2;    function __construct() {        echo $this->non_static_member . ' '           . self::$static_member;    }}new X();?>Here is an example of incorrect usage of $this and self for non-static and static member variables:<?phpclass X {    private $non_static_member = 1;    private static $static_member = 2;    function __construct() {        echo self::$non_static_member . ' '           . $this->static_member;    }}new X();?>Here is an example of polymorphism with $this for member functions:<?phpclass X {    function foo() {        echo 'X::foo()';    }    function bar() {        $this->foo();    }}class Y extends X {    function foo() {        echo 'Y::foo()';    }}$x = new Y();$x->bar();?>Here is an example of suppressing polymorphic behaviour by using self for member functions:<?phpclass X {    function foo() {        echo 'X::foo()';    }    function bar() {        self::foo();    }}class Y extends X {    function foo() {        echo 'Y::foo()';    }}$x = new Y();$x->bar();?>The idea is that $this->foo() calls the foo() member function of whatever  is the exact type of the current object. If the object is of type X, it thus calls X::foo(). If the object is of type Y, it calls Y::foo(). But with self::foo(), X::foo() is always called.From http://www.phpbuilder.com/board/showthread.php?t=10354489:By http://board.phpbuilder.com/member.php?145249-laserlight"
"data_i","edited Dec 24 '16 at 22:57","
        Should I use Vagrant or Docker for creating an isolated environment?
    ","I use Ubuntu for development and deployment and have a need for creating an isolated environment. I am considering either Vagrant or Docker for this purpose. What are the pros and cons, or how do these solutions compare?","Disclaimer: I wrote Vagrant! But because I wrote Vagrant, I spend most of my time living in the DevOps world which includes software like Docker. I work with a lot of companies using Vagrant and many use Docker, and I see how the two interplay.Before I talk too much, a direct answer: in your specific scenario (yourself working alone, working on Linux, using Docker in production), you can stick with Docker alone and simplify things. In many other scenarios (I discuss further), it isn't so easy.It isn't correct to directly compare Vagrant to Docker. In some scenarios, they do overlap, and in the vast majority, they don't. Actually, the more apt comparison would be Vagrant versus something like Boot2Docker (minimal OS that can run Docker). Vagrant is a level above Docker in terms of abstractions, so it isn't a fair comparison in most cases.Vagrant launches things to run apps/services for the purpose of development. This can be on VirtualBox, VMware. It can be remote like AWS, OpenStack. Within those, if you use containers, Vagrant doesn't care, and embraces that: it can automatically install, pull down, build, and run Docker containers, for example. With Vagrant 1.6, Vagrant has docker-based development environments, and supports using Docker with the same workflow as Vagrant across Linux, Mac, and Windows. Vagrant doesn't try to replace Docker here, it embraces Docker practices.Docker specifically runs Docker containers. If you're comparing directly to Vagrant: it is specifically a more specific (can only run Docker containers), less flexible (requires Linux or Linux host somewhere) solution. Of course if you're talking about production or CI, there is no comparison to Vagrant! Vagrant doesn't live in these environments, and so Docker should be used. If your organization runs only Docker containers for all their projects and only has developers running on Linux, then okay, Docker could definitely work for you! Otherwise, I don't see a benefit to attempting to use Docker alone, since you lose a lot of what Vagrant has to offer, which have real business/productivity benefits:Vagrant can launch VirtualBox, VMware, AWS, OpenStack, etc. machines. It doesn't matter what you need, Vagrant can launch it. If you are using Docker, Vagrant can install Docker on any of these so you can use them for that purpose.Vagrant is a single workflow for all your projects. Or to put another way, it is just one thing people have to learn to run a project whether it is in a Docker container or not. If, for example, in the future, a competitor arises to compete directly with Docker, Vagrant will be able to run that too. Vagrant works on Windows (back to XP), Mac (back to 10.5), and Linux (back to kernel 2.6). In all three cases, the workflow is the same. If you use Docker, Vagrant can launch a machine (VM or remote) that can run Docker on all three of these systems.Vagrant knows how to configure some advanced or non-trivial things like networking and syncing folders. For example: Vagrant knows how to attach a static IP to a machine or forward ports, and the configuration is the same no matter what system you use (VirtualBox, VMware, etc.) For synced folders, Vagrant provides multiple mechanisms to get your local files over to the remote machine (VirtualBox shared folders, NFS, rsync, Samba [plugin], etc.). If you're using Docker, even Docker with a VM without Vagrant, you would have to manually do this or they would have to reinvent Vagrant in this case.Vagrant 1.6 has first-class support for docker-based development environments. This will not launch a virtual machine on Linux, and will automatically launch a virtual machine on Mac and Windows. The end result is that working with Docker is uniform across all platforms, while Vagrant still handles the tedious details of things such as networking, synced folders, etc.To address specific counter arguments that I've heard in favor of using Docker instead of Vagrant:""It is less moving parts"" - Yes, it can be, if you use Docker exclusively for every project. Even then, it is sacrificing flexibility for Docker lock-in. If you ever decide to not use Docker for any project, past, present, or future, then you'll have more moving parts. If you had used Vagrant, you have that one moving part that supports the rest.""It is faster!"" - Once you have the host that can run Linux containers, Docker is definitely faster at running a container than any virtual machine would be to launch. But launching a virtual machine (or remote machine) is a one-time cost. Over the course of the day, most Vagrant users never actually destroy their VM. It is a strange optimization for development environments. In production, where Docker really shines, I understand the need to quickly spin up/down containers.I hope now its clear to see that it is very difficult, and I believe not correct, to compare Docker to Vagrant. For dev environments, Vagrant is more abstract, more general. Docker (and the various ways you can make it behave like Vagrant) is a specific use case of Vagrant, ignoring everything else Vagrant has to offer. In conclusion: in highly specific use cases, Docker is certainly a possible replacement for Vagrant. In most use cases, it is not. Vagrant doesn't hinder your usage of Docker; it actually does what it can to make that experience smoother. If you find this isn't true, I'm happy to take suggestions to improve things, since a goal of Vagrant is to work equally well with any system.Hope this clears things up!"
"data_i","edited May 01 '18 at 10:15","
        What is the scope of variables in JavaScript?
    ","What is the scope of variables in javascript? Do they have the same scope inside as opposed to outside a function? Or does it even matter? Also, where are the variables stored if they are defined globally?","TLDRJavaScript has lexical (also called static) scoping and closures. This means you can tell the scope of an identifier by looking at the source code.The four scopes are:Global - visible by everythingFunction - visible within a function (and its sub-functions and blocks)Block - visible within a block (and its sub-blocks)Module - visible within a moduleOutside of the special cases of global and module scope, variables are declared using var (function scope), let (block scope), and const (block scope). Most other forms of identifier declaration have block scope in strict mode.OverviewScope is the region of the codebase over which an identifier is valid.A lexical environment is a mapping between identifier names and the values associated with them.Scope is formed of a linked nesting of lexical environments, with each level in the nesting corresponding to a lexical environment of an ancestor execution context.These linked lexical environments form a scope ""chain"". Identifier resolution is the process of searching along this chain for a matching identifier.Identifier resolution only occurs in one direction: outwards. In this way, outer lexical environments cannot ""see"" into inner lexical environments.There are three pertinent factors in deciding the scope of an identifier in JavaScript:How an identifier was declaredWhere an identifier was declaredWhether you are in strict mode or non-strict modeSome of the ways identifiers can be declared:var, let and constFunction parametersCatch block parameterFunction declarationsNamed function expressionsImplicitly defined properties on the global object (i.e., missing out var in non-strict mode)import statementsevalSome of the locations identifiers can be declared:Global contextFunction bodyOrdinary blockThe top of a control structure (e.g., loop, if, while, etc.)Control structure bodyModulesDeclaration StylesvarIdentifiers declared using var have function scope, apart from when they are declared directly in the global context, in which case they are added as properties on the global object and have global scope. There are separate rules for their use in eval functions.let and constIdentifiers declared using let and const have block scope, apart from when they are declared directly in the global context, in which case they have global scope.Note: let, const and var are all hoisted. This means that their logical position of definition is the top of their enclosing scope (block or function). However, variables declared using let and const cannot be read or assigned to until control has passed the point of declaration in the source code. The interim period is known as the temporal dead zone.function f() {    function g() {        console.log(x)    }    let x = 1    g()}f() // 1 because x is hoisted even though declared with `let`!Function parameter namesFunction parameter names are scoped to the function body. Note that there is a slight complexity to this. Functions declared as default arguments close over the parameter list, and not the body of the function.Function declarationsFunction declarations have block scope in strict mode and function scope in non-strict mode. Note: non-strict mode is a complicated set of emergent rules based on the quirky historical implementations of different browsers.Named function expressionsNamed function expressions are scoped to themselves (e.g., for the purpose of recursion).Implicitly defined properties on the global objectIn non-strict mode, implicitly defined properties on the global object have global scope, because the global object sits at the top of the scope chain. In strict mode, these are not permitted.evalIn eval strings, variables declared using var will be placed in the current scope, or, if eval is used indirectly, as properties on the global object.ExamplesThe following will throw a ReferenceError because the namesx, y, and z have no meaning outside of the function f.function f() {    var x = 1    let y = 1    const z = 1}console.log(typeof x) // undefined (because var has function scope!)console.log(typeof y) // undefined (because the body of the function is a block)console.log(typeof z) // undefined (because the body of the function is a block)The following will throw a ReferenceError for y and z, but not for x, because the visibility of x is not constrained by the block. Blocks that define the bodies of control structures like if, for, and while, behave similarly.{    var x = 1    let y = 1    const z = 1}console.log(x) // 1console.log(typeof y) // undefined because `y` has block scopeconsole.log(typeof z) // undefined because `z` has block scopeIn the following, x is visible outside of the loop because var has function scope:for(var x = 0; x < 5; ++x) {}console.log(x) // 5 (note this is outside the loop!)...because of this behavior, you need to be careful about closing over variables declared using var in loops. There is only one instance of variable x declared here, and it sits logically outside of the loop.The following prints 5, five times, and then prints 5 a sixth time for the console.log outside the loop:for(var x = 0; x < 5; ++x) {    setTimeout(() => console.log(x)) // closes over the `x` which is logically positioned at the top of the enclosing scope, above the loop}console.log(x) // note: visible outside the loopThe following prints undefined because x is block-scoped. The callbacks are run one by one asynchronously. New behavior for let variables means that each anonymous function closed over a different variable named x (unlike it would have done with var), and so integers 0 through 4 are printed.:for(let x = 0; x < 5; ++x) {    setTimeout(() => console.log(x)) // `let` declarations are re-declared on a per-iteration basis, so the closures capture different variables}console.log(typeof x) // undefinedThe following will NOT throw a ReferenceError because the visibility of x is not constrained by the block; it will, however, print undefined because the variable has not been initialised (because of the if statement).if(false) {    var x = 1}console.log(x) // here, `x` has been declared, but not initialisedA variable declared at the top of a for loop using let is scoped to the body of the loop:for(let x = 0; x < 10; ++x) {} console.log(typeof x) // undefined, because `x` is block-scopedThe following will throw a ReferenceError because the visibility of x is constrained by the block:if(false) {    let x = 1}console.log(typeof x) // undefined, because `x` is block-scopedVariables declared using var, let or const are all scoped to modules:// module1.jsvar x = 0export function f() {}//module2.jsimport f from 'module1.js'console.log(x) // throws ReferenceErrorThe following will declare a property on the global object because variables declared using var within the global context are added as properties to the global object:var x = 1console.log(window.hasOwnProperty('x')) // truelet and const in the global context do not add properties to the global object, but still have global scope:let x = 1console.log(window.hasOwnProperty('x')) // falseFunction parameters can be considered to be declared in the function body:function f(x) {}console.log(typeof x) // undefined, because `x` is scoped to the functionCatch block parameters are scoped to the catch-block body:try {} catch(e) {}console.log(typeof e) // undefined, because `e` is scoped to the catch blockNamed function expressions are scoped only to the expression itself:(function foo() { console.log(foo) })()console.log(typeof foo) // undefined, because `foo` is scoped to its own expressionIn non-strict mode, implicitly defined properties on the global object are globally scoped. In strict mode, you get an error.x = 1 // implicitly defined property on the global object (no ""var""!)console.log(x) // 1console.log(window.hasOwnProperty('x')) // trueIn non-strict mode, function declarations have function scope. In strict mode, they have block scope.'use strict'{    function foo() {}}console.log(typeof foo) // undefined, because `foo` is block-scopedHow it works under the hoodScope is defined as the lexical region of code over which an identifier is valid.In JavaScript, every function-object has a hidden [[Environment]] reference that is a reference to the lexical environment of the execution context (stack frame) within which it was created.When you invoke a function, the hidden [[Call]] method is called. This method creates a new execution context and establishes a link between the new execution context and the lexical environment of the function-object. It does this by copying the [[Environment]] value on the function-object, into an outer reference field on the lexical environment of the new execution context.Note that this link between the new execution context and the lexical environment of the function object is called a closure.Thus, in JavaScript, scope is implemented via lexical environments linked together in a ""chain"" by outer references. This chain of lexical environments is called the scope chain, and identifier resolution occurs by searching up the chain for a matching identifier.Find out more."
"data_i","edited Jun 01 '20 at 21:32","
        How to convert a string to an integer in JavaScript?
    ","How do I convert a string to an integer in JavaScript?","The simplest way would be to use the native Number function:var x = Number(""1000"")If that doesn't work for you, then there are the parseInt, unary plus, parseFloat with floor, and Math.round methods.parseInt:var x = parseInt(""1000"", 10); // you want to use radix 10    // so you get a decimal number even with a leading 0 and an old browser ([IE8, Firefox 20, Chrome 22 and older][1])unary plusif your string is already in the form of an integer:var x = +""1000"";if your string is or might be a float and you want an integer:var x = Math.floor(""1000.01""); //floor automatically converts string to numberor, if you're going to be using Math.floor several times:var floor = Math.floor;var x = floor(""1000.01"");If you're the type who forgets to put the radix in when you call parseInt, you can use parseFloat and round it however you like. Here I use floor.var floor = Math.floor;var x = floor(parseFloat(""1000.01""));Interestingly, Math.round (like Math.floor) will do a string to number conversion, so if you want the number rounded (or if you have an integer in the string), this is a great way, maybe my favorite:var round = Math.round;var x = round(""1000""); //equivalent to round(""1000"",0)"
"data_i","edited Aug 14 '18 at 03:09","
        How to exit in Node.js
    ","What is the command that is used to exit? (i.e terminate the Node.js process)","Call the global process object's exit method:process.exit()From the docs:process.exit([exitcode])Ends the process with the specified code. If omitted, exit with a 'success' code 0.To exit with a 'failure' code:process.exit(1);The shell that executed node should see the exit code as 1."
"data_i","edited Jul 27 '22 at 22:34","
        How do I calculate someone's age based on a DateTime type birthday?
    ","Given a DateTime representing a person's birthday, how do I calculate their age in years?","An easy to understand and simple solution.// Save today's date.var today = DateTime.Today;// Calculate the age.var age = today.Year - birthdate.Year;// Go back to the year in which the person was born in case of a leap yearif (birthdate.Date > today.AddYears(-age)) age--;However, this assumes you are looking for the western idea of the age and not using East Asian reckoning."
"data_i","edited Jul 25 '16 at 21:47","
        Daylight saving time and time zone best practices
    ","I am hoping to make this question and the answers to it the definitive guide to dealing with daylight saving time, in particular for dealing with the actual change overs. If you have anything to add, please doMany systems are dependent on keeping accurate time, the problem is with changes to time due to daylight savings - moving the clock forward or backwards.For instance, one has business rules in an order taking system that depend on the time of the order - if the clock changes, the rules might not be as clear. How should the time of the order be persisted? There are of course an endless number of scenarios - this one is simply an illustrative one.How have you dealt with the daylight saving issue? What assumptions are part of your solution? (looking for context here)As important, if not more so:What did you try that did not work? Why did it not work?I would be interested in programming, OS, data persistence and other pertinent aspects of the issue.General answers are great, but I would also like to see details especially if they are only available on one platform.","Summary of answers and other data: (please add yours)Do:Whenever you are referring to an exact moment in time, persist the time according to a unified standard that is not affected by daylight savings. (GMT and UTC are equivalent with this regard, but it is preferred to use the term UTC. Notice that UTC is also known as Zulu or Z time.)If instead you choose to persist a (past) time using a local time value, include the local time offset for this particular time from UTC (this offset may change throughout the year), such that the timestamp can later be interpreted unambiguously.In some cases, you may need to store both the UTC time and the equivalent local time.  Often this is done with two separate fields, but some platforms support a datetimeoffset type that can store both in a single field.When storing timestamps as a numeric value, use Unix time - which is the number of whole seconds since 1970-01-01T00:00:00Z (excluding leap seconds).  If you require higher precision, use milliseconds instead.  This value should always be based on UTC, without any time zone adjustment.If you might later need to modify the timestamp, include the original time zone ID so you can determine if the offset may have changed from the original value recorded.When scheduling future events, usually local time is preferred instead of UTC, as it is common for the offset to change.  See answer, and blog post.When storing whole dates, such as birthdays and anniversaries, do not convert to UTC or any other time zone.When possible, store in a date-only data type that does not include a time of day.If such a type is not available, be sure to always ignore the time-of-day when interpreting the value.  If you cannot be assured that the time-of-day will be ignored, choose 12:00 Noon, rather than 00:00 Midnight as a more safe representative time on that day.Remember that time zone offsets are not always an integer number of hours (for example, Indian Standard Time is UTC+05:30, and Nepal uses UTC+05:45).If using Java, use java.time for Java 8 and later.Much of that java.time functionality is back-ported to Java 6 & 7 in the ThreeTen-Backport library.Further adapted for early Android (< 26) in the ThreeTenABP library.These projects officially supplant the venerable Joda-Time, now in maintenance-mode. Joda-Time, ThreeTen-Backport, ThreeTen-Extra, java.time classes, and JSR 310 are led by the same man, Stephen Colebourne.If using .NET, consider using Noda Time.If using .NET without Noda Time, consider that DateTimeOffset is often a better choice than DateTime.If using Perl, use DateTime.If using Python 3.9 or later, use the built-in zoneinfo for working with time zones.  Otherwise, use dateutil or arrow.  The older pytz library can generally be avoided.If using JavaScript, avoid using the older moment.js or moment-timezone libraries, as they are no longer actively maintained.  See the Moment.js project status for more details.  Instead, consider Luxon, date-fns, day.js, or js-joda.If using PHP > 5.2, use the native time zones conversions provided by DateTime, and DateTimeZone classes. Be careful when using DateTimeZone::listAbbreviations() - see answer. To keep PHP with up to date Olson data, install periodically the timezonedb PECL package; see answer.If using C++, be sure to use a library that uses the properly implements the IANA timezone database.  These include cctz, ICU, and Howard Hinnant's ""tz"" library.  In C++20 the latter is adopted into the standard <chrono> library.Do not use Boost for time zone conversions.  While its API claims to support standard IANA (aka ""zoneinfo"") identifiers, it crudely maps them to POSIX-style data, without considering the rich history of changes each zone may have had.  (Also, the file has fallen out of maintenance.)If using Rust, use chrono.Most business rules use civil time, rather than UTC or GMT.  Therefore, plan to convert UTC timestamps to a local time zone before applying application logic.Remember that time zones and offsets are not fixed and may change. For instance, historically US and UK used the same dates to 'spring forward' and 'fall back'. However, in 2007 the US changed the dates that the clocks get changed on. This now means that for 48 weeks of the year the difference between London time and New York time is 5 hours and for 4 weeks (3 in the spring, 1 in the autumn) it is 4 hours. Be aware of items like this in any calculations that involve multiple zones.Consider the type of time (actual event time, broadcast time, relative time, historical time, recurring time) what elements (timestamp, time zone offset and time zone name) you need to store for correct retrieval - see ""Types of Time"" in this answer.Keep your OS, database and application tzdata files in sync, between themselves and the rest of the world.On servers, set hardware clocks and OS clocks to UTC rather than a local time zone.Regardless of the previous bullet point, server-side code, including web sites, should never expect the local time zone of the server to be anything in particular.  see answer.Prefer working with time zones on a case-by-case basis in your application code, rather than globally through config file settings or defaults.Use NTP services on all servers.If using FAT32, remember that timestamps are stored in local time, not UTC.When dealing with recurring events (weekly TV show, for example), remember that the time changes with DST and will be different across time zones.Always query date-time values as lower-bound inclusive, upper-bound exclusive (>=, <).Don't:Do not confuse a ""time zone"", such as America/New_York with a ""time zone offset"", such as -05:00.  They are two different things.  See the timezone tag wiki.Do not use JavaScript's Date object to perform date and time calculations in older web browsers, as ECMAScript 5.1 and lower has a design flaw that may use daylight saving time incorrectly.  (This was fixed in ECMAScript 6 / 2015).Never trust the client's clock. It may very well be incorrect.Don't tell people to ""always use UTC everywhere"".  This widespread advice is shortsighted of several valid scenarios that are described earlier in this document.  Instead, use the appropriate time reference for the data you are working with.  (Timestamping can use UTC, but future time scheduling and date-only values should not.)Testing:When testing, make sure you test countries in the Western, Eastern, Northern and Southern hemispheres (in fact in each quarter of the globe, so 4 regions), with both DST in progress and not (gives 8), and a country that does not use DST (another 4 to cover all regions, making 12 in total).Test transition of DST, i.e. when you are currently in summer time, select a time value from winter.Test boundary cases, such as a timezone that is UTC+12, with DST, making the local time UTC+13 in summer and even places that are UTC+13 in winterTest all third-party libraries and applications and make sure they handle time zone data correctly.Test half-hour time zones, at least.Reference:The detailed timezone tag wiki page on Stack OverflowOlson database, aka Tz_databaseIETF draft procedures for maintaining the Olson databaseSources for Time Zone and DSTISO format (ISO 8601)Mapping between Olson database and Windows Time Zone Ids, from the Unicode ConsortiumTime Zone page on WikipediaStackOverflow questions tagged dstStackOverflow questions tagged timezoneDealing with DST - Microsoft DateTime best practicesNetwork Time Protocol on WikipediaOther:Lobby your representative to end the abomination that is DST. We can always hope...Lobby for Earth Standard Time"
"data_i","edited Jun 20 '20 at 09:12","
        How does JavaScript .prototype work?
    ","I'm not that into dynamic programming languages but I've written my fair share of JavaScript code. I never really got my head around this prototype-based programming, does any one know how this works?var obj = new Object();obj.prototype.test = function() { alert('Hello?'); };var obj2 = new obj();obj2.test();I remember a lot discussion I had with people a while back (I'm not exactly sure what I'm doing) but as I understand it, there's no concept of a class. It's just an object, and instances of those objects are clones of the original, right?But what is the exact purpose of this "".prototype"" property in JavaScript? How does it relate to instantiating objects?Update: correct wayvar obj = new Object(); // not a functional objectobj.prototype.test = function() { alert('Hello?'); }; // this is wrong!function MyObject() {} // a first class functional objectMyObject.prototype.test = function() { alert('OK'); } // OKAlso these slides really helped a lot.","In a language implementing classical inheritance like Java, C# or C++ you start by creating a class--a blueprint for your objects--and then you can create new objects from that class or you can extend the class, defining a new class that augments the original class.In JavaScript you first create an object (there is no concept of class), then you can augment your own object or create new objects from it. It's not difficult, but a little foreign and hard to metabolize for somebody used to the classical way.Example://Define a functional object to hold persons in JavaScriptvar Person = function(name) {  this.name = name;};//Add dynamically to the already defined object a new getterPerson.prototype.getName = function() {  return this.name;};//Create a new object of type Personvar john = new Person(""John"");//Try the getteralert(john.getName());//If now I modify person, also John gets the updatesPerson.prototype.sayMyName = function() {  alert('Hello, my name is ' + this.getName());};//Call the new method on johnjohn.sayMyName();Until now I've been extending the base object, now I create another object and then inheriting from Person.//Create a new object of type Customer by defining its constructor. It's not //related to Person for now.var Customer = function(name) {    this.name = name;};//Now I link the objects and to do so, we link the prototype of Customer to //a new instance of Person. The prototype is the base that will be used to //construct all new instances and also, will modify dynamically all already //constructed objects because in JavaScript objects retain a pointer to the //prototypeCustomer.prototype = new Person();     //Now I can call the methods of Person on the Customer, let's try, first //I need to create a Customer.var myCustomer = new Customer('Dream Inc.');myCustomer.sayMyName();//If I add new methods to Person, they will be added to Customer, but if I//add new methods to Customer they won't be added to Person. Example:Customer.prototype.setAmountDue = function(amountDue) {    this.amountDue = amountDue;};Customer.prototype.getAmountDue = function() {    return this.amountDue;};//Let's try:       myCustomer.setAmountDue(2000);alert(myCustomer.getAmountDue());var Person = function (name) {    this.name = name;};Person.prototype.getName = function () {    return this.name;};var john = new Person(""John"");alert(john.getName());Person.prototype.sayMyName = function () {    alert('Hello, my name is ' + this.getName());};john.sayMyName();var Customer = function (name) {    this.name = name;};Customer.prototype = new Person();var myCustomer = new Customer('Dream Inc.');myCustomer.sayMyName();Customer.prototype.setAmountDue = function (amountDue) {    this.amountDue = amountDue;};Customer.prototype.getAmountDue = function () {    return this.amountDue;};myCustomer.setAmountDue(2000);alert(myCustomer.getAmountDue());While as said I can't call setAmountDue(), getAmountDue() on a Person.//The following statement generates an error.john.setAmountDue(1000);"
"data_i","edited Jul 26 '19 at 09:03","
        Viewing unpushed Git commits
    ","How can I view any local commits I've made, that haven't yet been pushed to the remote repository? Occasionally, git status will print out that my branch is X commits ahead of origin/master, but not always.Is this a bug with my install of Git, or am I missing something?","This gives a log of all commits between origin/master and HEAD:git log origin/master..HEADWhen HEAD is on the master branch, this gives a log of unpushed commits.Similarly, to view the diff:git diff origin/master..HEAD"
"data_i","edited Jul 24 '22 at 23:13","
        How do I change permissions for a folder and its subfolders/files?
    ","How do I change the permissions of a folder and all its subfolders and files?This only applies to the /opt/lampp/htdocs folder, not its contents:chmod 775 /opt/lampp/htdocsHow do I set chmod 755 for all of the  /opt/lampp/htdocs folder's current contents, as well as automatically in the future for new folders/files created under it?Related: How can I set a default 'chmod' in a Linux terminal?","The other answers are correct, in that chmod -R 755 will set these permissions to all files and subfolders in the tree. But why on earth would you want to? It might make sense for the directories, but why set the execute bit on all the files?I suspect what you really want to do is set the directories to 755 and either leave the files alone or set them to 644. For this, you can use the find command. For example:To change all the directories to 755 (drwxr-xr-x):find /opt/lampp/htdocs -type d -exec chmod 755 {} \;To change all the files to 644 (-rw-r--r--):find /opt/lampp/htdocs -type f -exec chmod 644 {} \;Some splainin': (thanks @tobbez)chmod 755 {} specifies the command that will be executed by find for each directorychmod 644 {} specifies the command that will be executed by find for each file{} is replaced by the path; the semicolon tells find that this is the end of the command it's supposed to execute\; the semicolon is escaped, otherwise it would be interpreted by the shell instead of find"
"data_i","edited Nov 16 '19 at 23:34","
        How can I symlink a file in Linux?
    ","I want to make a symbolic link in Linux. I have written this Bash command where the first path is the folder I want link into and the second path is the compiled source. ln -s '+basebuild+'/IpDome-kernel/kernel /home/build/sandbox/gen2/basebuild/IpDome-kernel/kernal Is this correct?","To create a new symlink (will fail if symlink exists already):ln -s /path/to/file /path/to/symlinkTo create or update a symlink:ln -sf /path/to/file /path/to/symlink"
"data_i","edited Dec 09 '19 at 12:52","
        When do you use Git rebase instead of Git merge?
    ","When is it recommended to use Git rebase vs. Git merge?Do I still need to merge after a successful rebase?","Short VersionMerge takes all the changes in one branch and merges them into another branch in one commit.Rebase says I want the point at which I branched to move to a new starting pointSo when do you use either one?MergeLet's say you have created a branch for the purpose of developing a single feature.  When you want to bring those changes back to master, you probably want merge (you don't care about maintaining all of the interim commits).RebaseA second scenario would be if you started doing some development and then another developer made an unrelated change. You probably want to pull and then rebase to base your changes from the current version from the repository."
"data_i","edited Nov 14 '16 at 20:14","
        How do I format a Microsoft JSON date?
    ","I'm taking my first crack at Ajax with jQuery. I'm getting my data onto my page, but I'm having some trouble with the JSON data that is returned for Date data types. Basically, I'm getting a string back that looks like this:/Date(1224043200000)/From someone totally new to JSON - How do I format this to a short date format? Should this be handled somewhere in the jQuery code? I've tried the jQuery.UI.datepicker plugin using $.datepicker.formatDate() without any success.FYI: Here's the solution I came up with using a combination of the answers here:function getMismatch(id) {  $.getJSON(""Main.aspx?Callback=GetMismatch"",    { MismatchId: id },    function (result) {      $(""#AuthMerchId"").text(result.AuthorizationMerchantId);      $(""#SttlMerchId"").text(result.SettlementMerchantId);      $(""#CreateDate"").text(formatJSONDate(Date(result.AppendDts)));      $(""#ExpireDate"").text(formatJSONDate(Date(result.ExpiresDts)));      $(""#LastUpdate"").text(formatJSONDate(Date(result.LastUpdateDts)));      $(""#LastUpdatedBy"").text(result.LastUpdateNt);      $(""#ProcessIn"").text(result.ProcessIn);    }  );  return false;}function formatJSONDate(jsonDate) {  var newDate = dateFormat(jsonDate, ""mm/dd/yyyy"");  return newDate;}This solution got my object from the callback method and displayed the dates on the page properly using the date format library.","eval() is not necessary. This will work fine:var date = new Date(parseInt(jsonDate.substr(6)));The substr() function takes out the /Date( part, and the parseInt() function gets the integer and ignores the )/ at the end. The resulting number is passed into the Date constructor.I have intentionally left out the radix (the 2nd argument to parseInt); see my comment below.Also, I completely agree with Rory's comment: ISO-8601 dates are preferred over this old format - so this format generally shouldn't be used for new development.For ISO-8601 formatted JSON dates, just pass the string into the Date constructor:var date = new Date(jsonDate); //no ugly parsing needed; full timezone support"
"data_i","edited Jun 09 '22 at 11:31","
        C++11 introduced a standardized memory model. What does it mean? And how is it going to affect C++ programming?
    ","C++11 introduced a standardized memory model, but what exactly does that mean? And how is it going to affect C++ programming?This article (by Gavin Clarke who quotes Herb Sutter) says that,The memory model means that C++ codenow has a standardized library to callregardless of who made the compilerand on what platform it's running.There's a standard way to control howdifferent threads talk to theprocessor's memory.""When you are talking about splitting[code] across different cores that'sin the standard, we are talking aboutthe memory model. We are going tooptimize it without breaking thefollowing assumptions people are goingto make in the code,"" Sutter said.Well, I can memorize this and similar paragraphs available online (as I've had my own memory model since birth :P) and can even post as an answer to questions asked by others, but to be honest, I don't exactly understand this.C++ programmers used to develop multi-threaded applications even before, so how does it matter if it's POSIX threads, or Windows threads, or C++11 threads? What are the benefits? I want to understand the low-level details.I also get this feeling that the C++11 memory model is somehow related to C++11 multi-threading support, as I often see these two together. If it is, how exactly? Why should they be related?I don't know how the internals of multi-threading work, and what memory model means in general.","First, you have to learn to think like a Language Lawyer.The C++ specification does not make reference to any particular compiler, operating system, or CPU.  It makes reference to an abstract machine that is a generalization of actual systems.  In the Language Lawyer world, the job of the programmer is to write code for the abstract machine; the job of the compiler is to actualize that code on a concrete machine.  By coding rigidly to the spec, you can be certain that your code will compile and run without modification on any system with a compliant C++ compiler, whether today or 50 years from now.The abstract machine in the C++98/C++03 specification is fundamentally single-threaded.  So it is not possible to write multi-threaded C++ code that is ""fully portable"" with respect to the spec.  The spec does not even say anything about the atomicity of memory loads and stores or the order in which loads and stores might happen, never mind things like mutexes.Of course, you can write multi-threaded code in practice for particular concrete systems – like pthreads or Windows.  But there is no standard way to write multi-threaded code for C++98/C++03.The abstract machine in C++11 is multi-threaded by design.  It also has a well-defined memory model; that is, it says what the compiler may and may not do when it comes to accessing memory.Consider the following example, where a pair of global variables are accessed concurrently by two threads:           Global           int x, y;Thread 1            Thread 2x = 17;             cout << y << "" "";y = 37;             cout << x << endl;What might Thread 2 output?Under C++98/C++03, this is not even Undefined Behavior; the question itself is meaningless because the standard does not contemplate anything called a ""thread"".Under C++11, the result is Undefined Behavior, because loads and stores need not be atomic in general.  Which may not seem like much of an improvement...  And by itself, it's not.But with C++11, you can write this:           Global           atomic<int> x, y;Thread 1                 Thread 2x.store(17);             cout << y.load() << "" "";y.store(37);             cout << x.load() << endl;Now things get much more interesting.  First of all, the behavior here is defined.  Thread 2 could now print 0 0 (if it runs before Thread 1), 37 17 (if it runs after Thread 1), or 0 17 (if it runs after Thread 1 assigns to x but before it assigns to y).What it cannot print is 37 0, because the default mode for atomic loads/stores in C++11 is to enforce sequential consistency.  This just means all loads and stores must be ""as if"" they happened in the order you wrote them within each thread, while operations among threads can be interleaved however the system likes.  So the default behavior of atomics provides both atomicity and ordering for loads and stores.Now, on a modern CPU, ensuring sequential consistency can be expensive.  In particular, the compiler is likely to emit full-blown memory barriers between every access here.  But if your algorithm can tolerate out-of-order loads and stores; i.e., if it requires atomicity but not ordering; i.e., if it can tolerate 37 0 as output from this program, then you can write this:           Global           atomic<int> x, y;Thread 1                            Thread 2x.store(17,memory_order_relaxed);   cout << y.load(memory_order_relaxed) << "" "";y.store(37,memory_order_relaxed);   cout << x.load(memory_order_relaxed) << endl;The more modern the CPU, the more likely this is to be faster than the previous example.Finally, if you just need to keep particular loads and stores in order, you can write:           Global           atomic<int> x, y;Thread 1                            Thread 2x.store(17,memory_order_release);   cout << y.load(memory_order_acquire) << "" "";y.store(37,memory_order_release);   cout << x.load(memory_order_acquire) << endl;This takes us back to the ordered loads and stores – so 37 0 is no longer a possible output – but it does so with minimal overhead.  (In this trivial example, the result is the same as full-blown sequential consistency; in a larger program, it would not be.)Of course, if the only outputs you want to see are 0 0 or 37 17, you can just wrap a mutex around the original code.  But if you have read this far, I bet you already know how that works, and this answer is already longer than I intended :-).So, bottom line. Mutexes are great, and C++11 standardizes them. But sometimes for performance reasons you want lower-level primitives (e.g., the classic double-checked locking pattern).  The new standard provides high-level gadgets like mutexes and condition variables, and it also provides low-level gadgets like atomic types and the various flavors of memory barrier.  So now you can write sophisticated, high-performance concurrent routines entirely within the language specified by the standard, and you can be certain your code will compile and run unchanged on both today's systems and tomorrow's.Although to be frank, unless you are an expert and working on some serious low-level code, you should probably stick to mutexes and condition variables.  That's what I intend to do.For more on this stuff, see this blog post."
"data_i","edited Dec 19 '20 at 00:09","
        Why can templates only be implemented in the header file?
    ","Quote from The C++ standard library: a tutorial and handbook:The only portable way of using templates at the moment is to implement them in header files by using inline functions.Why is this?(Clarification: header files are not the only portable solution. But they are the most convenient portable solution.)","Caveat: It is not necessary to put the implementation in the header file, see the alternative solution at the end of this answer.Anyway, the reason your code is failing is that, when instantiating a template, the compiler creates a new class with the given template argument. For example:template<typename T>struct Foo{    T bar;    void doSomething(T param) {/* do stuff using T */}};// somewhere in a .cppFoo<int> f; When reading this line, the compiler will create a new class (let's call it FooInt), which is equivalent to the following:struct FooInt{    int bar;    void doSomething(int param) {/* do stuff using int */}}Consequently, the compiler needs to have access to the implementation of the methods, to instantiate them with the template argument (in this case int). If these implementations were not in the header, they wouldn't be accessible, and therefore the compiler wouldn't be able to instantiate the template.A common solution to this is to write the template declaration in a header file, then implement the class in an implementation file (for example .tpp), and include this implementation file at the end of the header.Foo.htemplate <typename T>struct Foo{    void doSomething(T param);};#include ""Foo.tpp""Foo.tpptemplate <typename T>void Foo<T>::doSomething(T param){    //implementation}This way, implementation is still separated from declaration, but is accessible to the compiler.Alternative solutionAnother solution is to keep the implementation separated, and explicitly instantiate all the template instances you'll need:Foo.h// no implementationtemplate <typename T> struct Foo { ... };Foo.cpp// implementation of Foo's methods// explicit instantiationstemplate class Foo<int>;template class Foo<float>;// You will only be able to use Foo with int or floatIf my explanation isn't clear enough, you can have a look at the C++ Super-FAQ on this subject."
"data_i","edited Apr 12 '22 at 15:21","
        Remove duplicate values from JS array
    ","I have a very simple JavaScript array that may or may not contain duplicates.var names = [""Mike"",""Matt"",""Nancy"",""Adam"",""Jenny"",""Nancy"",""Carl""];I need to remove the duplicates and put the unique values in a new array.I could point to all the codes that I've tried but I think it's useless because they don't work. I accept jQuery solutions too.Similar question:Get all non-unique values (i.e.: duplicate/more than one occurrence) in an array","TL;DRUsing the Set constructor and the spread syntax:uniq = [...new Set(array)];""Smart"" but naïve wayuniqueArray = a.filter(function(item, pos) {    return a.indexOf(item) == pos;})Basically, we iterate over the array and, for each element, check if the first position of this element in the array is equal to the current position. Obviously, these two positions are different for duplicate elements.Using the 3rd (""this array"") parameter of the filter callback we can avoid a closure of the array variable:uniqueArray = a.filter(function(item, pos, self) {    return self.indexOf(item) == pos;})Although concise, this algorithm is not particularly efficient for large arrays (quadratic time).Hashtables to the rescuefunction uniq(a) {    var seen = {};    return a.filter(function(item) {        return seen.hasOwnProperty(item) ? false : (seen[item] = true);    });}This is how it's usually done. The idea is to place each element in a hashtable and then check for its presence instantly. This gives us linear time, but has at least two drawbacks:since hash keys can only be strings or symbols in JavaScript, this code doesn't distinguish numbers and ""numeric strings"". That is, uniq([1,""1""]) will return just [1]for the same reason, all objects will be considered equal: uniq([{foo:1},{foo:2}]) will return just [{foo:1}].That said, if your arrays contain only primitives and you don't care about types (e.g. it's always numbers), this solution is optimal.The best from two worldsA universal solution combines both approaches: it uses hash lookups for primitives and linear search for objects.function uniq(a) {    var prims = {""boolean"":{}, ""number"":{}, ""string"":{}}, objs = [];    return a.filter(function(item) {        var type = typeof item;        if(type in prims)            return prims[type].hasOwnProperty(item) ? false : (prims[type][item] = true);        else            return objs.indexOf(item) >= 0 ? false : objs.push(item);    });}sort | uniqAnother option is to sort the array first, and then remove each element equal to the preceding one:function uniq(a) {    return a.sort().filter(function(item, pos, ary) {        return !pos || item != ary[pos - 1];    });}Again, this doesn't work with objects (because all objects are equal for sort). Additionally, we silently change the original array as a side effect - not good! However, if your input is already sorted, this is the way to go (just remove sort from the above).Unique by...Sometimes it's desired to uniquify a list based on some criteria other than just equality, for example, to filter out objects that are different, but share some property. This can be done elegantly by passing a callback. This ""key"" callback is applied to each element, and elements with equal ""keys"" are removed. Since key is expected to return a primitive, hash table will work fine here:function uniqBy(a, key) {    var seen = {};    return a.filter(function(item) {        var k = key(item);        return seen.hasOwnProperty(k) ? false : (seen[k] = true);    })}A particularly useful key() is JSON.stringify which will remove objects that are physically different, but ""look"" the same:a = [[1,2,3], [4,5,6], [1,2,3]]b = uniqBy(a, JSON.stringify)console.log(b) // [[1,2,3], [4,5,6]]If the key is not primitive, you have to resort to the linear search:function uniqBy(a, key) {    var index = [];    return a.filter(function (item) {        var k = key(item);        return index.indexOf(k) >= 0 ? false : index.push(k);    });}In ES6 you can use a Set:function uniqBy(a, key) {    let seen = new Set();    return a.filter(item => {        let k = key(item);        return seen.has(k) ? false : seen.add(k);    });}or a Map:function uniqBy(a, key) {    return [        ...new Map(            a.map(x => [key(x), x])        ).values()    ]}which both also work with non-primitive keys.First or last?When removing objects by a key, you might to want to keep the first of ""equal"" objects or the last one.Use the Set variant above to keep the first, and the Map to keep the last:function uniqByKeepFirst(a, key) {    let seen = new Set();    return a.filter(item => {        let k = key(item);        return seen.has(k) ? false : seen.add(k);    });}function uniqByKeepLast(a, key) {    return [        ...new Map(            a.map(x => [key(x), x])        ).values()    ]}//data = [    {a:1, u:1},    {a:2, u:2},    {a:3, u:3},    {a:4, u:1},    {a:5, u:2},    {a:6, u:3},];console.log(uniqByKeepFirst(data, it => it.u))console.log(uniqByKeepLast(data, it => it.u))LibrariesBoth underscore and Lo-Dash provide uniq methods. Their algorithms are basically similar to the first snippet above and boil down to this:var result = [];a.forEach(function(item) {     if(result.indexOf(item) < 0) {         result.push(item);     }});This is quadratic, but there are nice additional goodies, like wrapping native indexOf, ability to uniqify by a key (iteratee in their parlance), and optimizations for already sorted arrays.If you're using jQuery and can't stand anything without a dollar before it, it goes like this:  $.uniqArray = function(a) {        return $.grep(a, function(item, pos) {            return $.inArray(item, a) === pos;        });  }which is, again, a variation of the first snippet.PerformanceFunction calls are expensive in JavaScript, therefore the above solutions, as concise as they are, are not particularly efficient. For maximal performance, replace filter with a loop and get rid of other function calls:function uniq_fast(a) {    var seen = {};    var out = [];    var len = a.length;    var j = 0;    for(var i = 0; i < len; i++) {         var item = a[i];         if(seen[item] !== 1) {               seen[item] = 1;               out[j++] = item;         }    }    return out;}This chunk of ugly code does the same as the snippet #3 above, but an order of magnitude faster (as of 2017 it's only twice as fast - JS core folks are doing a great job!)function uniq(a) {    var seen = {};    return a.filter(function(item) {        return seen.hasOwnProperty(item) ? false : (seen[item] = true);    });}function uniq_fast(a) {    var seen = {};    var out = [];    var len = a.length;    var j = 0;    for(var i = 0; i < len; i++) {         var item = a[i];         if(seen[item] !== 1) {               seen[item] = 1;               out[j++] = item;         }    }    return out;}/////var r = [0,1,2,3,4,5,6,7,8,9],    a = [],    LEN = 1000,    LOOPS = 1000;while(LEN--)    a = a.concat(r);var d = new Date();for(var i = 0; i < LOOPS; i++)    uniq(a);document.write('<br>uniq, ms/loop: ' + (new Date() - d)/LOOPS)var d = new Date();for(var i = 0; i < LOOPS; i++)    uniq_fast(a);document.write('<br>uniq_fast, ms/loop: ' + (new Date() - d)/LOOPS)ES6ES6 provides the Set object, which makes things a whole lot easier:function uniq(a) {   return Array.from(new Set(a));}orlet uniq = a => [...new Set(a)];Note that, unlike in python, ES6 sets are iterated in insertion order, so this code preserves the order of the original array.However, if you need an array with unique elements, why not use sets right from the beginning?GeneratorsA ""lazy"", generator-based version of uniq can be built on the same basis:take the next value from the argumentif it's been seen already, skip itotherwise, yield it and add it to the set of already seen valuesfunction* uniqIter(a) {    let seen = new Set();    for (let x of a) {        if (!seen.has(x)) {            seen.add(x);            yield x;        }    }}// example:function* randomsBelow(limit) {    while (1)        yield Math.floor(Math.random() * limit);}// note that randomsBelow is endlesscount = 20;limit = 30;for (let r of uniqIter(randomsBelow(limit))) {    console.log(r);    if (--count === 0)        break}// exercise for the reader: what happens if we set `limit` less than `count` and why"
"data_i","edited Jun 20 '21 at 07:56","
        What are drawbacks or disadvantages of singleton pattern?
    ","The singleton pattern is a fully paid up member of the GoF's patterns book, but it lately seems rather orphaned by the developer world. I still use quite a lot of singletons, especially for factory classes, and while you have to be a bit careful about multithreading issues (like any class actually), I fail to see why they are so awful.Stack Overflow especially seems to assume that everyone agrees that Singletons are evil. Why?Please support your answers with ""facts, references, or specific expertise""","Paraphrased from Brian Button:They are generally used as a global instance, why is that so bad? Because you hide the dependencies of your application in your code, instead of exposing them through the interfaces. Making something global to avoid passing it around is a code smell.They violate the single responsibility principle: by virtue of the fact that they control their own creation and lifecycle.They inherently cause code to be tightly coupled. This makes faking them out under test rather difficult in many cases.They carry state around for the lifetime of the application. Another hit to testing since you can end up with a situation where tests need to be ordered which is a big no no for unit tests. Why? Because each unit test should be independent from the other."
"data_i","edited Sep 08 '22 at 21:27","
        What do 'real', 'user' and 'sys' mean in the output of time(1)?
    ","$ time fooreal        0m0.003suser        0m0.000ssys         0m0.004s$What do real, user and sys mean in the output of time? Which one is meaningful when benchmarking my app?","Real, User and Sys process time statisticsOne of these things is not like the other.  Real refers to actual elapsed time; User and Sys refer to CPU time used only by the process.Real is wall clock time - time from start to finish of the call.  This is all elapsed time including time slices used by other processes and time the process spends blocked (for example if it is waiting for I/O to complete).User is the amount of CPU time spent in user-mode code (outside the kernel) within the process.  This is only actual CPU time used in executing the process.  Other processes and time the process spends blocked do not count towards this figure.Sys is the amount of CPU time spent in the kernel within the process.  This means executing CPU time spent in system calls within the kernel, as opposed to library code, which is still running in user-space.  Like 'user', this is only CPU time used by the process.  See below for a brief description of kernel mode (also known as 'supervisor' mode) and the system call mechanism.User+Sys will tell you how much actual CPU time your process used.  Note that this is across all CPUs, so if the process has multiple threads (and this process is running on a computer with more than one processor) it could potentially exceed the wall clock time reported by Real (which usually occurs).  Note that in the output these figures include the User and Sys time of all child processes (and their descendants) as well when they could have been collected, e.g. by wait(2) or waitpid(2), although the underlying system calls return the statistics for the process and its children separately.Origins of the statistics reported by time (1)The statistics reported by time are gathered from various system calls.  'User' and 'Sys' come from wait (2) (POSIX) or times (2) (POSIX), depending on the particular system.  'Real' is calculated from a start and end time gathered from the gettimeofday (2) call.  Depending on the version of the system, various other statistics such as the number of context switches may also be gathered by time.On a multi-processor machine, a multi-threaded process or a process forking children could have an elapsed time smaller than the total CPU time - as different threads or processes may run in parallel.  Also, the time statistics reported come from different origins, so times recorded for very short running tasks may be subject to rounding errors, as the example given by the original poster shows.A brief primer on Kernel vs. User modeOn Unix, or any protected-memory operating system, 'Kernel' or 'Supervisor' mode refers to a privileged mode that the CPU can operate in.  Certain privileged actions that could affect security or stability can only be done when the CPU is operating in this mode; these actions are not available to application code.  An example of such an action might be manipulation of the MMU to gain access to the address space of another process.  Normally, user-mode code cannot do this (with good reason), although it can request shared memory from the kernel, which could be read or written by more than one process.  In this case, the shared memory is explicitly requested from the kernel through a secure mechanism and both processes have to explicitly attach to it in order to use it.The privileged mode is usually referred to as 'kernel' mode because the kernel is executed by the CPU running in this mode.  In order to switch to kernel mode you have to issue a specific instruction (often called a trap) that switches the CPU to running in kernel mode and runs code from a specific location held in a jump table.  For security reasons, you cannot switch to kernel mode and execute arbitrary code - the traps are managed through a table of addresses that cannot be written to unless the CPU is running in supervisor mode.  You trap with an explicit trap number and the address is looked up in the jump table; the kernel has a finite number of controlled entry points.The 'system' calls in the C library (particularly those described in Section 2 of the man pages) have a user-mode component, which is what you actually call from your C program.  Behind the scenes, they may issue one or more system calls to the kernel to do specific services such as I/O, but they still also have code running in user-mode.  It is also quite possible to directly issue a trap to kernel mode from any user space code if desired, although you may need to write a snippet of assembly language to set up the registers correctly for the call.More about 'sys'There are things that your code cannot do from user mode - things like allocating memory or accessing hardware (HDD, network, etc.). These are under the supervision of the kernel, and it alone can do them. Some operations like malloc orfread/fwrite will invoke these kernel functions and that then will count as 'sys' time. Unfortunately it's not as simple as ""every call to malloc will be counted in 'sys' time"". The call to malloc will do some processing of its own (still counted in 'user' time) and then somewhere along the way it may call the function in kernel (counted in 'sys' time). After returning from the kernel call, there will be some more time in 'user' and then malloc will return to your code. As for when the switch happens, and how much of it is spent in kernel mode... you cannot say. It depends on the implementation of the library. Also, other seemingly innocent functions might also use malloc and the like in the background, which will again have some time in 'sys' then."
"data_i","edited Sep 23 '21 at 21:06","
        Retrieve the position (X,Y) of an HTML element
    ","I want to know how to get the X and Y position of HTML elements such as img and div in JavaScript.","The correct approach is to use element.getBoundingClientRect():var rect = element.getBoundingClientRect();console.log(rect.top, rect.right, rect.bottom, rect.left);Internet Explorer has supported this since as long as you are likely to care about and it was finally standardized in CSSOM Views. All other browsers adopted it a long time ago.Some browsers also return height and width properties, though this is non-standard.  If you're worried about older browser compatibility, check this answer's revisions for an optimised degrading implementation.The values returned by element.getBoundingClientRect() are relative to the viewport.  If you need it relative to another element, simply subtract one rectangle from the other:var bodyRect = document.body.getBoundingClientRect(),    elemRect = element.getBoundingClientRect(),    offset   = elemRect.top - bodyRect.top;alert('Element is ' + offset + ' vertical pixels from <body>');"
"data_i","edited Feb 04 '22 at 18:49","
        Why is reading lines from stdin much slower in C++ than Python?
    ","I wanted to compare reading lines of string input from stdin using Python and C++ and was shocked to see my C++ code run an order of magnitude slower than the equivalent Python code. Since my C++ is rusty and I'm not yet an expert Pythonista, please tell me if I'm doing something wrong or if I'm misunderstanding something.(TLDR answer: include the statement: cin.sync_with_stdio(false) or just use fgets instead.TLDR results: scroll all the way down to the bottom of my question and look at the table.)C++ code:#include <iostream>#include <time.h>using namespace std;int main() {    string input_line;    long line_count = 0;    time_t start = time(NULL);    int sec;    int lps;    while (cin) {        getline(cin, input_line);        if (!cin.eof())            line_count++;    };    sec = (int) time(NULL) - start;    cerr << ""Read "" << line_count << "" lines in "" << sec << "" seconds."";    if (sec > 0) {        lps = line_count / sec;        cerr << "" LPS: "" << lps << endl;    } else        cerr << endl;    return 0;}// Compiled with:// g++ -O3 -o readline_test_cpp foo.cppPython Equivalent:#!/usr/bin/env pythonimport timeimport syscount = 0start = time.time()for line in  sys.stdin:    count += 1delta_sec = int(time.time() - start_time)if delta_sec >= 0:    lines_per_sec = int(round(count/delta_sec))    print(""Read {0} lines in {1} seconds. LPS: {2}"".format(count, delta_sec,       lines_per_sec))Here are my results:$ cat test_lines | ./readline_test_cppRead 5570000 lines in 9 seconds. LPS: 618889$ cat test_lines | ./readline_test.pyRead 5570000 lines in 1 seconds. LPS: 5570000I should note that I tried this both under Mac OS X v10.6.8 (Snow Leopard) and Linux 2.6.32 (Red Hat Linux 6.2). The former is a MacBook Pro, and the latter is a very beefy server, not that this is too pertinent.$ for i in {1..5}; do echo ""Test run $i at `date`""; echo -n ""CPP:""; cat test_lines | ./readline_test_cpp ; echo -n ""Python:""; cat test_lines | ./readline_test.py ; doneTest run 1 at Mon Feb 20 21:29:28 EST 2012CPP:   Read 5570001 lines in 9 seconds. LPS: 618889Python:Read 5570000 lines in 1 seconds. LPS: 5570000Test run 2 at Mon Feb 20 21:29:39 EST 2012CPP:   Read 5570001 lines in 9 seconds. LPS: 618889Python:Read 5570000 lines in 1 seconds. LPS: 5570000Test run 3 at Mon Feb 20 21:29:50 EST 2012CPP:   Read 5570001 lines in 9 seconds. LPS: 618889Python:Read 5570000 lines in 1 seconds. LPS: 5570000Test run 4 at Mon Feb 20 21:30:01 EST 2012CPP:   Read 5570001 lines in 9 seconds. LPS: 618889Python:Read 5570000 lines in 1 seconds. LPS: 5570000Test run 5 at Mon Feb 20 21:30:11 EST 2012CPP:   Read 5570001 lines in 10 seconds. LPS: 557000Python:Read 5570000 lines in  1 seconds. LPS: 5570000Tiny benchmark addendum and recapFor completeness, I thought I'd update the read speed for the same file on the same box with the original (synced) C++ code. Again, this is for a 100M line file on a fast disk. Here's the comparison, with several solutions/approaches:ImplementationLines per secondpython (default)3,571,428cin (default/naive)819,672cin (no sync)12,500,000fgets14,285,714wc (not fair comparison)54,644,808","tl;dr: Because of different default settings in C++ requiring more system calls.By default, cin is synchronized with stdio, which causes it to avoid any input buffering.  If you add this to the top of your main, you should see much better performance:std::ios_base::sync_with_stdio(false);Normally, when an input stream is buffered, instead of reading one character at a time, the stream will be read in larger chunks.  This reduces the number of system calls, which are typically relatively expensive.  However, since the FILE* based stdio and iostreams often have separate implementations and therefore separate buffers, this could lead to a problem if both were used together.  For example:int myvalue1;cin >> myvalue1;int myvalue2;scanf(""%d"",&myvalue2);If more input was read by cin than it actually needed, then the second integer value wouldn't be available for the scanf function, which has its own independent buffer.  This would lead to unexpected results.To avoid this, by default, streams are synchronized with stdio.  One common way to achieve this is to have cin read each character one at a time as needed using stdio functions.  Unfortunately, this introduces a lot of overhead.  For small amounts of input, this isn't a big problem, but when you are reading millions of lines, the performance penalty is significant.Fortunately, the library designers decided that you should also be able to disable this feature to get improved performance if you knew what you were doing, so they provided the sync_with_stdio method. From this link (emphasis added):If the synchronization is turned off, the C++ standard streams are allowed to buffer their I/O independently, which may be considerably faster in some cases."
"data_i","edited Nov 22 '21 at 03:40","
        How can I add new array elements at the beginning of an array in JavaScript?
    ","I have a need to add or prepend elements at the beginning of an array.For example, if my array looks like below:[23, 45, 12, 67]And the response from my AJAX call is 34, I want the updated array to be like the following:[34, 23, 45, 12, 67]Currently I am planning to do it like this:var newArray = [];newArray.push(response);for (var i = 0; i < theArray.length; i++) {    newArray.push(theArray[i]);}theArray = newArray;delete newArray;Is there a better way to do this? Does JavaScript have any built-in functionality that does this?The complexity of my method is O(n) and it would be really interesting to see better implementations.","Use unshift. It's like push, except it adds elements to the beginning of the array instead of the end.unshift/push - add an element to the beginning/end of an arrayshift/pop  - remove and return the first/last element of an arrayA simple diagram...   unshift -> [array] <- push   shift   <- [array] -> pop and chart:          add  remove  start  end   push    X                   X    pop           X            Xunshift    X             X  shift           X      XCheck out the MDN Array documentation. Virtually every language that has the ability to push/pop elements from an array will also have the ability to unshift/shift (sometimes called push_front/pop_front) elements, you should never have to implement these yourself.As pointed out in the comments, if you want to avoid mutating your original array, you can use concat, which concatenates two or more arrays together. You can use this to functionally push a single element onto the front or back of an existing array; to do so, you need to turn the new element into a single element array:const array = [3, 2, 1]const newFirstElement = 4const newArray = [newFirstElement].concat(array) // [ 4, 3, 2, 1 ]console.log(newArray);concat can also append items. The arguments to concat can be of any type; they are implicitly wrapped in a single-element array, if they are not already an array:const array = [3, 2, 1]const newLastElement = 0// Both of these lines are equivalent:const newArray1 = array.concat(newLastElement) // [ 3, 2, 1, 0 ]const newArray2 = array.concat([newLastElement]) // [ 3, 2, 1, 0 ]console.log(newArray1);console.log(newArray2);"
"data_i","edited Jan 27 '21 at 07:11","
        Programmatically navigate using React router
    ","With react-router I can use the Link element to create links which are natively handled by react router. I see internally it calls this.context.transitionTo(...).I want to do a navigation. Not from a link, but from a dropdown selection (as an example). How can I do this in code? What is this.context? I saw the Navigation mixin, but can I do this without mixins?","React Router v5.1.0 with hooksThere is a new useHistory hook in React Router >5.1.0 if you are using React >16.8.0 and functional components.import { useHistory } from ""react-router-dom"";function HomeButton() {  const history = useHistory();  function handleClick() {    history.push(""/home"");  }  return (    <button type=""button"" onClick={handleClick}>      Go home    </button>  );}React Router v4With v4 of React Router, there are three approaches that you can take to programmatic routing within components.Use the withRouter higher-order component.Use composition and render a <Route>Use the context.React Router is mostly a wrapper around the history library. history handles interaction with the browser's window.history for you with its browser and hash histories. It also provides a memory history which is useful for environments that don't have a global history. This is particularly useful in mobile app development (react-native) and unit testing with Node.A history instance has two methods for navigating: push and replace. If you think of the history as an array of visited locations, push will add a new location to the array and replace will replace the current location in the array with the new one. Typically you will want to use the push method when you are navigating.In earlier versions of React Router, you had to create your own history instance, but in v4 the <BrowserRouter>, <HashRouter>, and <MemoryRouter> components will create a browser, hash, and memory instances for you. React Router makes the properties and methods of the history instance associated with your router available through the context, under the router object.1. Use the withRouter higher-order componentThe withRouter higher-order component will inject the history object as a prop of the component. This allows you to access the push and replace methods without having to deal with the context.import { withRouter } from 'react-router-dom'// this also works with react-router-nativeconst Button = withRouter(({ history }) => (  <button    type='button'    onClick={() => { history.push('/new-location') }}  >    Click Me!  </button>))2. Use composition and render a <Route>The <Route> component isn't just for matching locations. You can render a pathless route and it will always match the current location. The <Route> component passes the same props as withRouter, so you will be able to access the history methods through the history prop.import { Route } from 'react-router-dom'const Button = () => (  <Route render={({ history}) => (    <button      type='button'      onClick={() => { history.push('/new-location') }}    >      Click Me!    </button>  )} />)3. Use the context*But you probably should notThe last option is one that you should only use if you feel comfortable working with React's context model (React's Context API is stable as of v16).const Button = (props, context) => (  <button    type='button'    onClick={() => {      // context.history.push === history.push      context.history.push('/new-location')    }}  >    Click Me!  </button>)// you need to specify the context type so that it// is available within the componentButton.contextTypes = {  history: React.PropTypes.shape({    push: React.PropTypes.func.isRequired  })}1 and 2 are the simplest choices to implement, so for most use cases, they are your best bets."
"data_i","edited Oct 07 '20 at 13:30","
        How do I create an Excel (.XLS and .XLSX) file in C# without installing Microsoft Office?
    ","How can I create an Excel spreadsheet with C# without requiring Excel to be installed on the machine that's running the code?","You can use a library called ExcelLibrary. It's a free, open source library posted on Google Code:ExcelLibraryThis looks to be a port of the PHP ExcelWriter that you mentioned above. It will not write to the new .xlsx format yet, but they are working on adding that functionality in.It's very simple, small and easy to use. Plus it has a DataSetHelper that lets you use DataSets and DataTables to easily work with Excel data.ExcelLibrary seems to still only work for the older Excel format (.xls files), but may be adding support in the future for newer 2007/2010 formats. You can also use EPPlus, which works only for Excel 2007/2010 format files (.xlsx files). There's also NPOI which works with both.There are a few known bugs with each library as noted in the comments. In all, EPPlus seems to be the best choice as time goes on. It seems to be more actively updated and documented as well.Also, as noted by @АртёмЦарионов below, EPPlus has support for Pivot Tables and ExcelLibrary may have some support (Pivot table issue in ExcelLibrary)Here are a couple links for quick reference:ExcelLibrary - GNU Lesser GPLEPPlus - GNU (LGPL) - No longer maintainedEPPlus 5 - Polyform Noncommercial - Starting May 2020NPOI - Apache LicenseHere some example code for ExcelLibrary:Here is an example taking data from a database and creating a workbook from it. Note that the ExcelLibrary code is the single line at the bottom://Create the data set and tableDataSet ds = new DataSet(""New_DataSet"");DataTable dt = new DataTable(""New_DataTable"");//Set the locale for eachds.Locale = System.Threading.Thread.CurrentThread.CurrentCulture;dt.Locale = System.Threading.Thread.CurrentThread.CurrentCulture;//Open a DB connection (in this example with OleDB)OleDbConnection con = new OleDbConnection(dbConnectionString);con.Open();//Create a query and fill the data table with the data from the DBstring sql = ""SELECT Whatever FROM MyDBTable;"";OleDbCommand cmd = new OleDbCommand(sql, con);OleDbDataAdapter adptr = new OleDbDataAdapter();adptr.SelectCommand = cmd;adptr.Fill(dt);con.Close();//Add the table to the data setds.Tables.Add(dt);//Here's the easy part. Create the Excel worksheet from the data setExcelLibrary.DataSetHelper.CreateWorkbook(""MyExcelFile.xls"", ds);Creating the Excel file is as easy as that. You can also manually create Excel files, but the above functionality is what really impressed me."
"data_i","edited Jun 20 '18 at 16:30","
        How can I git stash a specific file?
    ","How can I stash a specific file leaving the others currently modified out of the stash I am about to save?For example, if git status gives me this:younker % gst      # On branch master# Your branch is ahead of 'origin/master' by 1 commit.## Changes not staged for commit:#   (use ""git add <file>..."" to update what will be committed)#   (use ""git checkout -- <file>..."" to discard changes in working directory)##   modified:   app/controllers/cart_controller.php#   modified:   app/views/cart/welcome.thtml#no changes added to commit (use ""git add"" and/or ""git commit -a"")and I only want to stash app/views/cart/welcome.thtml, how would I do that? Something like (but of course this does not work):git stash save welcome_cart app/views/cart/welcome.thtml","EDIT: Since git 2.13, there is a command to save a specific path to the stash: git stash push <path>. For example: git stash push -m welcome_cart app/views/cart/welcome.thtmlOLD ANSWER:You can do that using git stash --patch (or git stash -p) -- you'll enter interactive mode where you'll be presented with each hunk that was changed. Use n to skip the files that you don't want to stash, y when you encounter the one that you want to stash, and q to quit and leave the remaining hunks unstashed.  a will stash the shown hunk and the rest of the hunks in that file.Not the most user-friendly approach, but it gets the work done if you really need it."
"data_i","edited Jul 17 '22 at 00:46","
        How do I fetch all Git branches?
    ","I cloned a Git repository containing many branches. However, git branch only shows one:$ git branch* masterHow would I pull all the branches locally so when I do git branch, it shows the following?$ git branch* master* staging* etc...","TL;DR answergit branch -r | grep -v '\->' | sed ""s,\x1B\[[0-9;]*[a-zA-Z],,g"" | while read remote; do git branch --track ""${remote#origin/}"" ""$remote""; donegit fetch --allgit pull --all(It seems that pull fetches all branches from all remotes, but I always fetch first just to be sure.)Run the first command only if there are remote branches on the server that aren't tracked by your local branches.Complete answerYou can fetch all branches from all remotes like this:git fetch --allIt's basically a power move.fetch updates local copies of remote branches so this is always safe for your local branches BUT:fetch will not update local branches (which track remote branches); if you want to update your local branches you still need to pull every branch.fetch will not create local branches (which track remote branches), you have to do this manually. If you want to list all remote branches:git branch -aTo update local branches which track remote branches:git pull --allHowever, this can be still insufficient. It will work only for your local branches which track remote branches. To track all remote branches execute this oneliner BEFORE git pull --all:git branch -r | grep -v '\->' | sed ""s,\x1B\[[0-9;]*[a-zA-Z],,g"" | while read remote; do git branch --track ""${remote#origin/}"" ""$remote""; doneP.S. AFAIK git fetch --all and git remote update are equivalent.Kamil Szot's comment, which folks have found useful.I had to use:for remote in `git branch -r`; do git branch --track ${remote#origin/} $remote; donebecause your code created local branches named origin/branchname andI was getting ""refname 'origin/branchname' is ambiguous whenever Ireferred to it."
"data_i","edited Jan 25 '22 at 23:38","
        How do I delete an exported environment variable?
    ","Before installing gnuplot, I set the environment variable GNUPLOT_DRIVER_DIR = /home/gnuplot/build/src. During the installation, something went wrong.I want to remove the GNUPLOT_DRIVER_DIR environment variable. How can I achieve it?","unset is the command you're looking for.unset GNUPLOT_DRIVER_DIR"
"data_i","edited Aug 11 '21 at 12:23","
        How to use java.net.URLConnection to fire and handle HTTP requests
    ","Use of java.net.URLConnection is asked about pretty often here, and the Oracle tutorial is too concise about it.That tutorial basically only shows how to fire a GET request and read the response. It doesn't explain anywhere how to use it to, among others, perform a POST request, set request headers, read response headers, deal with cookies, submit a HTML form, upload a file, etc.So, how can I use java.net.URLConnection to fire and handle ""advanced"" HTTP requests?","First a disclaimer beforehand: the posted code snippets are all basic examples. You'll need to handle trivial IOExceptions and RuntimeExceptions like NullPointerException, ArrayIndexOutOfBoundsException and consorts yourself.In case you're developing for Android instead of Java, note also that since introduction of API level 28, cleartext HTTP requests are disabled by default. You are encouraged to use HttpsURLConnection, but if it is really necessary, cleartext can be enabled in the Application Manifest.PreparingWe first need to know at least the URL and the charset. The parameters are optional and depend on the functional requirements.String url = ""http://example.com"";String charset = ""UTF-8"";  // Or in Java 7 and later, use the constant: java.nio.charset.StandardCharsets.UTF_8.name()String param1 = ""value1"";String param2 = ""value2"";// ...String query = String.format(""param1=%s&param2=%s"",    URLEncoder.encode(param1, charset),    URLEncoder.encode(param2, charset));The query parameters must be in name=value format and be concatenated by &. You would normally also URL-encode the query parameters with the specified charset using URLEncoder#encode().The String#format() is just for convenience. I prefer it when I would need the String concatenation operator + more than twice.Firing an HTTP GET request with (optionally) query parametersIt's a trivial task. It's the default request method.URLConnection connection = new URL(url + ""?"" + query).openConnection();connection.setRequestProperty(""Accept-Charset"", charset);InputStream response = connection.getInputStream();// ...Any query string should be concatenated to the URL using ?. The Accept-Charset header may hint the server what encoding the parameters are in. If you don't send any query string, then you can leave the Accept-Charset header away. If you don't need to set any headers, then you can even use the URL#openStream() shortcut method.InputStream response = new URL(url).openStream();// ...Either way, if the other side is an HttpServlet, then its doGet() method will be called and the parameters will be available by HttpServletRequest#getParameter().For testing purposes, you can print the response body to standard output as below:try (Scanner scanner = new Scanner(response)) {    String responseBody = scanner.useDelimiter(""\\A"").next();    System.out.println(responseBody);}Firing an HTTP POST request with query parametersSetting the URLConnection#setDoOutput() to true implicitly sets the request method to POST. The standard HTTP POST as web forms do is of type application/x-www-form-urlencoded wherein the query string is written to the request body.URLConnection connection = new URL(url).openConnection();connection.setDoOutput(true); // Triggers POST.connection.setRequestProperty(""Accept-Charset"", charset);connection.setRequestProperty(""Content-Type"", ""application/x-www-form-urlencoded;charset="" + charset);try (OutputStream output = connection.getOutputStream()) {    output.write(query.getBytes(charset));}InputStream response = connection.getInputStream();// ...Note: whenever you'd like to submit a HTML form programmatically, don't forget to take the name=value pairs of any <input type=""hidden""> elements into the query string and of course also the name=value pair of the <input type=""submit""> element which you'd like to ""press"" programmatically (because that's usually been used in the server side to distinguish if a button was pressed and if so, which one).You can also cast the obtained URLConnection to HttpURLConnection and use its HttpURLConnection#setRequestMethod() instead. But if you're trying to use the connection for output you still need to set URLConnection#setDoOutput() to true.HttpURLConnection httpConnection = (HttpURLConnection) new URL(url).openConnection();httpConnection.setRequestMethod(""POST"");// ...Either way, if the other side is an HttpServlet, then its doPost() method will be called and the parameters will be available by HttpServletRequest#getParameter().Actually firing the HTTP requestYou can fire the HTTP request explicitly with URLConnection#connect(), but the request will automatically be fired on demand when you want to get any information about the HTTP response, such as the response body using URLConnection#getInputStream() and so on. The above examples does exactly that, so the connect() call is in fact superfluous.Gathering HTTP response informationHTTP response status:You need an HttpURLConnection here. Cast it first if necessary.    int status = httpConnection.getResponseCode();HTTP response headers: for (Entry<String, List<String>> header : connection.getHeaderFields().entrySet()) {     System.out.println(header.getKey() + ""="" + header.getValue()); }HTTP response encoding:When the Content-Type contains a charset parameter, then the response body is likely text based and we'd like to process the response body with the server-side specified character encoding then.    String contentType = connection.getHeaderField(""Content-Type"");    String charset = null;    for (String param : contentType.replace("" "", """").split("";"")) {        if (param.startsWith(""charset="")) {            charset = param.split(""="", 2)[1];            break;        }    }    if (charset != null) {        try (BufferedReader reader = new BufferedReader(new InputStreamReader(response, charset))) {            for (String line; (line = reader.readLine()) != null;) {                // ... System.out.println(line)?            }        }    } else {        // It's likely binary content, use InputStream/OutputStream.    }Maintaining the sessionThe server side session is usually backed by a cookie. Some web forms require that you're logged in and/or are tracked by a session. You can use the CookieHandler API to maintain cookies. You need to prepare a CookieManager with a CookiePolicy of ACCEPT_ALL before sending all HTTP requests.// First set the default cookie manager.CookieHandler.setDefault(new CookieManager(null, CookiePolicy.ACCEPT_ALL));// All the following subsequent URLConnections will use the same cookie manager.URLConnection connection = new URL(url).openConnection();// ...connection = new URL(url).openConnection();// ...connection = new URL(url).openConnection();// ...Note that this is known to not always work properly in all circumstances. If it fails for you, then best is to manually gather and set the cookie headers. You basically need to grab all Set-Cookie headers from the response of the login or the first GET request and then pass this through the subsequent requests.// Gather all cookies on the first request.URLConnection connection = new URL(url).openConnection();List<String> cookies = connection.getHeaderFields().get(""Set-Cookie"");// ...// Then use the same cookies on all subsequent requests.connection = new URL(url).openConnection();for (String cookie : cookies) {    connection.addRequestProperty(""Cookie"", cookie.split("";"", 2)[0]);}// ...The split("";"", 2)[0] is there to get rid of cookie attributes which are irrelevant for the server side like expires, path, etc. Alternatively, you could also use cookie.substring(0, cookie.indexOf(';')) instead of split().Streaming modeThe HttpURLConnection will by default buffer the entire request body before actually sending it, regardless of whether you've set a fixed content length yourself using connection.setRequestProperty(""Content-Length"", contentLength);. This may cause OutOfMemoryExceptions whenever you concurrently send large POST requests (e.g. uploading files). To avoid this, you would like to set the HttpURLConnection#setFixedLengthStreamingMode().httpConnection.setFixedLengthStreamingMode(contentLength);But if the content length is really not known beforehand, then you can make use of chunked streaming mode by setting the HttpURLConnection#setChunkedStreamingMode() accordingly. This will set the HTTP Transfer-Encoding header to chunked which will force the request body being sent in chunks. The below example will send the body in chunks of 1 KB.httpConnection.setChunkedStreamingMode(1024);User-AgentIt can happen that a request returns an unexpected response, while it works fine with a real web browser. The server side is probably blocking requests based on the User-Agent request header. The URLConnection will by default set it to Java/1.6.0_19 where the last part is obviously the JRE version. You can override this as follows:connection.setRequestProperty(""User-Agent"", ""Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36""); // Do as if you're using Chrome 41 on Windows 7.Use the User-Agent string from a recent browser.Error handlingIf the HTTP response code is 4nn (Client Error) or 5nn (Server Error), then you may want to read the HttpURLConnection#getErrorStream() to see if the server has sent any useful error information.InputStream error = ((HttpURLConnection) connection).getErrorStream();If the HTTP response code is -1, then something went wrong with connection and response handling. The HttpURLConnection implementation is in older JREs somewhat buggy with keeping connections alive. You may want to turn it off by setting the http.keepAlive system property to false. You can do this programmatically in the beginning of your application by:System.setProperty(""http.keepAlive"", ""false"");Uploading filesYou'd normally use multipart/form-data encoding for mixed POST content (binary and character data). The encoding is in more detail described in RFC2388.String param = ""value"";File textFile = new File(""/path/to/file.txt"");File binaryFile = new File(""/path/to/file.bin"");String boundary = Long.toHexString(System.currentTimeMillis()); // Just generate some unique random value.String CRLF = ""\r\n""; // Line separator required by multipart/form-data.URLConnection connection = new URL(url).openConnection();connection.setDoOutput(true);connection.setRequestProperty(""Content-Type"", ""multipart/form-data; boundary="" + boundary);try (    OutputStream output = connection.getOutputStream();    PrintWriter writer = new PrintWriter(new OutputStreamWriter(output, charset), true);) {    // Send normal param.    writer.append(""--"" + boundary).append(CRLF);    writer.append(""Content-Disposition: form-data; name=\""param\"""").append(CRLF);    writer.append(""Content-Type: text/plain; charset="" + charset).append(CRLF);    writer.append(CRLF).append(param).append(CRLF).flush();    // Send text file.    writer.append(""--"" + boundary).append(CRLF);    writer.append(""Content-Disposition: form-data; name=\""textFile\""; filename=\"""" + textFile.getName() + ""\"""").append(CRLF);    writer.append(""Content-Type: text/plain; charset="" + charset).append(CRLF); // Text file itself must be saved in this charset!    writer.append(CRLF).flush();    Files.copy(textFile.toPath(), output);    output.flush(); // Important before continuing with writer!    writer.append(CRLF).flush(); // CRLF is important! It indicates end of boundary.    // Send binary file.    writer.append(""--"" + boundary).append(CRLF);    writer.append(""Content-Disposition: form-data; name=\""binaryFile\""; filename=\"""" + binaryFile.getName() + ""\"""").append(CRLF);    writer.append(""Content-Type: "" + URLConnection.guessContentTypeFromName(binaryFile.getName())).append(CRLF);    writer.append(""Content-Transfer-Encoding: binary"").append(CRLF);    writer.append(CRLF).flush();    Files.copy(binaryFile.toPath(), output);    output.flush(); // Important before continuing with writer!    writer.append(CRLF).flush(); // CRLF is important! It indicates end of boundary.    // End of multipart/form-data.    writer.append(""--"" + boundary + ""--"").append(CRLF).flush();}If the other side is an HttpServlet, then its doPost() method will be called and the parts will be available by HttpServletRequest#getPart() (note, thus not getParameter() and so on!). The getPart() method is however relatively new, it's introduced in Servlet 3.0 (Glassfish 3, Tomcat 7, etc.). Prior to Servlet 3.0, your best choice is using Apache Commons FileUpload to parse a multipart/form-data request. Also see this answer for examples of both the FileUpload and the Servelt 3.0 approaches.Dealing with untrusted or misconfigured HTTPS sitesIn case you're developing for Android instead of Java, be careful: the workaround below may save your day if you don't have correct certificates deployed during development. But you should not use it for production. These days (April 2021) Google will not allow your app be distributed on Play Store if they detect insecure hostname verifier, see https://support.google.com/faqs/answer/7188426.Sometimes you need to connect an HTTPS URL, perhaps because you're writing a web scraper. In that case, you may likely face a javax.net.ssl.SSLException: Not trusted server certificate on some HTTPS sites who doesn't keep their SSL certificates up to date, or a java.security.cert.CertificateException: No subject alternative DNS name matching [hostname] found or javax.net.ssl.SSLProtocolException: handshake alert: unrecognized_name on some misconfigured HTTPS sites.The following one-time-run static initializer in your web scraper class should make HttpsURLConnection more lenient as to those HTTPS sites and thus not throw those exceptions anymore.static {    TrustManager[] trustAllCertificates = new TrustManager[] {        new X509TrustManager() {            @Override            public X509Certificate[] getAcceptedIssuers() {                return null; // Not relevant.            }            @Override            public void checkClientTrusted(X509Certificate[] certs, String authType) {                // Do nothing. Just allow them all.            }            @Override            public void checkServerTrusted(X509Certificate[] certs, String authType) {                // Do nothing. Just allow them all.            }        }    };    HostnameVerifier trustAllHostnames = new HostnameVerifier() {        @Override        public boolean verify(String hostname, SSLSession session) {            return true; // Just allow them all.        }    };    try {        System.setProperty(""jsse.enableSNIExtension"", ""false"");        SSLContext sc = SSLContext.getInstance(""SSL"");        sc.init(null, trustAllCertificates, new SecureRandom());        HttpsURLConnection.setDefaultSSLSocketFactory(sc.getSocketFactory());        HttpsURLConnection.setDefaultHostnameVerifier(trustAllHostnames);    }    catch (GeneralSecurityException e) {        throw new ExceptionInInitializerError(e);    }}Last wordsThe Apache HttpComponents HttpClient is much more convenient in this all :)HttpClient TutorialHttpClient ExamplesParsing and extracting HTMLIf all you want is parsing and extracting data from HTML, then better use a HTML parser like Jsoup.What are the pros/cons of leading HTML parsers in JavaHow to scan and extract a webpage in Java"
"data_i","edited Sep 02 '22 at 02:00","
        How do I name and retrieve a Git stash by name?
    ","How do I save/apply a stash with a name? I don't want to have to look up its index number in git stash list. I tried git stash save ""my_stash_name"", but that only changes the stash description, and the corresponding git apply ""my_stash_name"" doesn't work.","To save a stash with a message:git stash push -m ""my_stash_name""To list stashes:git stash listAll the stashes are stored in a stack.To apply and remove the nth stash:git stash pop stash@{n}To apply and remove a stash by name:git stash pop stash^{/my_stash_name}To apply the nth stash:git stash apply stash@{n}To apply a stash by name:git stash apply stash^{/my_stash_name}"
"data_i","edited Feb 04 '22 at 21:06","
        What's the difference between a method and a function?
    ","Can someone provide a simple explanation of methods vs. functions in OOP context?","A function is a piece of code that is called by name. It can be passed data to operate on (i.e. the parameters) and can optionally return data (the return value). All data that is passed to a function is explicitly passed.A method is a piece of code that is called by a name that is associated with an object. In most respects it is identical to a function except for two key differences:A method is implicitly passed the object on which it was called.A method is able to operate on data that is contained within the class (remembering that an object is an instance of a class - the class is the definition, the object is an instance of that data).(this is a simplified explanation, ignoring issues of scope etc.)"
"data_i","edited Apr 11 '21 at 09:19","
        How can I see the changes in a Git commit?
    ","When I do git diff COMMIT I see the changes between that commit and HEAD (as far as I know), but I would like to see the changes that were made by that single commit.I haven't found any obvious options on diff / log that will give me that output.","To see the diff for a particular COMMIT hash, where COMMIT is the hash of the commit:git diff COMMIT~ COMMIT will show you the difference between that COMMIT's ancestor and the COMMIT. See the man pages for git diff for details about the command and gitrevisions about the ~ notation and its friends.Alternatively, git show COMMIT will do something very similar. (The commit's data, including its diff - but not for merge commits.) See the git show manpage.(also git diff COMMIT will show you the difference between that COMMIT and the head.)"
"data_i","edited Apr 27 '20 at 07:03","
        What is a smart pointer and when should I use one?
    ","What is a smart pointer and when should I use one?","UPDATEThis answer is rather old, and so describes what was 'good' at the time, which was smart pointers provided by the Boost library. Since C++11, the standard library has provided sufficient smart pointers types, and so you should favour the use of std::unique_ptr, std::shared_ptr and std::weak_ptr. There was also std::auto_ptr. It was very much like a scoped pointer, except that it also had the ""special"" dangerous ability to be copied — which also unexpectedly transfers ownership.It was deprecated in C++11 and removed in C++17, so you shouldn't use it.std::auto_ptr<MyObject> p1 (new MyObject());std::auto_ptr<MyObject> p2 = p1; // Copy and transfer ownership.                                  // p1 gets set to empty!p2->DoSomething(); // Works.p1->DoSomething(); // Oh oh. Hopefully raises some NULL pointer exception.OLD ANSWERA smart pointer is a class that wraps a 'raw' (or 'bare') C++ pointer, to manage the lifetime of the object being pointed to. There is no single smart pointer type, but all of them try to abstract a raw pointer in a practical way.Smart pointers should be preferred over raw pointers. If you feel you need to use pointers (first consider if you really do), you would normally want to use a smart pointer as this can alleviate many of the problems with raw pointers, mainly forgetting to delete the object and leaking memory.With raw pointers, the programmer has to explicitly destroy the object when it is no longer useful.// Need to create the object to achieve some goalMyObject* ptr = new MyObject(); ptr->DoSomething(); // Use the object in some waydelete ptr; // Destroy the object. Done with it.// Wait, what if DoSomething() raises an exception...?A smart pointer by comparison defines a policy as to when the object is destroyed. You still have to create the object, but you no longer have to worry about destroying it.SomeSmartPtr<MyObject> ptr(new MyObject());ptr->DoSomething(); // Use the object in some way.// Destruction of the object happens, depending // on the policy the smart pointer class uses.// Destruction would happen even if DoSomething() // raises an exceptionThe simplest policy in use involves the scope of the smart pointer wrapper object, such as implemented by boost::scoped_ptr or std::unique_ptr. void f(){    {       std::unique_ptr<MyObject> ptr(new MyObject());       ptr->DoSomethingUseful();    } // ptr goes out of scope --       // the MyObject is automatically destroyed.    // ptr->Oops(); // Compile error: ""ptr"" not defined                    // since it is no longer in scope.}Note that std::unique_ptr instances cannot be copied. This prevents the pointer from being deleted multiple times (incorrectly). You can, however, pass references to it around to other functions you call.std::unique_ptrs are useful when you want to tie the lifetime of the object to a particular block of code, or if you embedded it as member data inside another object, the lifetime of that other object. The object exists until the containing block of code is exited, or until the containing object is itself destroyed.A more complex smart pointer policy involves reference counting the pointer. This does allow the pointer to be copied. When the last ""reference"" to the object is destroyed, the object is deleted. This policy is implemented by boost::shared_ptr and std::shared_ptr.void f(){    typedef std::shared_ptr<MyObject> MyObjectPtr; // nice short alias    MyObjectPtr p1; // Empty    {        MyObjectPtr p2(new MyObject());        // There is now one ""reference"" to the created object        p1 = p2; // Copy the pointer.        // There are now two references to the object.    } // p2 is destroyed, leaving one reference to the object.} // p1 is destroyed, leaving a reference count of zero.   // The object is deleted.Reference counted pointers are very useful when the lifetime of your object is much more complicated, and is not tied directly to a particular section of code or to another object.There is one drawback to reference counted pointers — the possibility of creating a dangling reference:// Create the smart pointer on the heapMyObjectPtr* pp = new MyObjectPtr(new MyObject())// Hmm, we forgot to destroy the smart pointer,// because of that, the object is never destroyed!Another possibility is creating circular references:struct Owner {   std::shared_ptr<Owner> other;};std::shared_ptr<Owner> p1 (new Owner());std::shared_ptr<Owner> p2 (new Owner());p1->other = p2; // p1 references p2p2->other = p1; // p2 references p1// Oops, the reference count of of p1 and p2 never goes to zero!// The objects are never destroyed!To work around this problem, both Boost and C++11 have defined a weak_ptr to define a weak (uncounted) reference to a shared_ptr."
"data_i","edited Nov 08 '18 at 19:09","
        Is there a way to run Python on Android?
    ","We are working on an S60 version and this platform has a nice Python API..However, there is nothing official about Python on Android, but since Jython exists, is there a way to let the snake and the robot work together??","One way is to use Kivy:Open source Python library for rapid development of applications  that make use of innovative user interfaces, such as multi-touch apps.Kivy runs on Linux, Windows, OS X, Android and iOS. You can run the same [python] code on all supported platforms.Kivy Showcase app "
"data_i","edited Apr 20 '22 at 20:10","
        How to check if a column exists in a SQL Server table
    ","I need to add a specific column if it does not exist. I have something like the following, but it always returns false:IF EXISTS(SELECT *          FROM   INFORMATION_SCHEMA.COLUMNS          WHERE  TABLE_NAME = 'myTableName'                 AND COLUMN_NAME = 'myColumnName') How can I check if a column exists in a table of the SQL Server database?","SQL Server 2005 onwards:IF EXISTS(SELECT 1 FROM sys.columns           WHERE Name = N'columnName'          AND Object_ID = Object_ID(N'schemaName.tableName'))BEGIN    -- Column ExistsENDMartin Smith's version is shorter:IF COL_LENGTH('schemaName.tableName', 'columnName') IS NOT NULLBEGIN    -- Column ExistsEND"
"data_i","edited May 24 '22 at 03:26","
        How to return only the Date from a SQL Server DateTime datatype
    ","SELECT GETDATE()Returns: 2008-09-22 15:24:13.790I want that date part without the time part: 2008-09-22 00:00:00.000How can I get that?","SELECT DATEADD(dd, 0, DATEDIFF(dd, 0, @your_date))for exampleSELECT DATEADD(dd, 0, DATEDIFF(dd, 0, GETDATE()))gives me2008-09-22 00:00:00.000Pros:No varchar<->datetime conversions requiredNo need to think about locale"
"data_i","edited Jan 29 '17 at 19:05","
        Download a specific tag with Git
    ","I'm trying to figure out how I can download a particular tag of a Git repository - it's one version behind the current version.I saw there was a tag for the previous version on the git web page, with object name of something long hex number. But the version name is ""Tagged release 1.1.5"" according the site.I tried a command like this (with names changed):git clone http://git.abc.net/git/abc.git my_abcAnd I did get something - a directory, a bunch of subdirectories, etc.  If it's the whole repository, how do I get at the version I'm seeking? If not, how do I download that particular version? ","$ git clonewill give you the whole repository.After the clone, you can list the tags with $ git tag -l and then checkout a specific tag:$ git checkout tags/<tag_name>Even better, checkout and create a branch (otherwise you will be on a branch named after the revision number of tag):$ git checkout tags/<tag_name> -b <branch_name>"
"data_i","edited Jul 04 '22 at 22:44","
        How do I profile C++ code running on Linux?
    ","How do I find areas of my code that run slowly in a C++ application running on Linux?","If your goal is to use a profiler, use one of the suggested ones.However, if you're in a hurry and you can manually interrupt your program under the debugger while it's being subjectively slow, there's a simple way to find performance problems.Just halt it several times, and each time look at the call stack. If there is some code that is wasting some percentage of the time, 20% or 50% or whatever, that is the probability that you will catch it in the act on each sample. So, that is roughly the percentage of samples on which you will see it. There is no educated guesswork required. If you do have a guess as to what the problem is, this will prove or disprove it.You may have multiple performance problems of different sizes. If you clean out any one of them, the remaining ones will take a larger percentage, and be easier to spot, on subsequent passes. This magnification effect, when compounded over multiple problems, can lead to truly massive speedup factors.Caveat: Programmers tend to be skeptical of this technique unless they've used it themselves. They will say that profilers give you this information, but that is only true if they sample the entire call stack, and then let you examine a random set of samples. (The summaries are where the insight is lost.) Call graphs don't give you the same information, because They don't summarize at the instruction level, andThey give confusing summaries in the presence of recursion.They will also say it only works on toy programs, when actually it works on any program, and it seems to work better on bigger programs, because they tend to have more problems to find. They will say it sometimes finds things that aren't problems, but that is only true if you see something once. If you see a problem on more than one sample, it is real.P.S. This can also be done on multi-thread programs if there is a way to collect call-stack samples of the thread pool at a point in time, as there is in Java.P.P.S As a rough generality, the more layers of abstraction you have in your software, the more likely you are to find that that is the cause of performance problems (and the opportunity to get speedup).Added: It might not be obvious, but the stack sampling technique works equally well in the presence of recursion. The reason is that the time that would be saved by removal of an instruction is approximated by the fraction of samples containing it, regardless of the number of times it may occur within a sample.Another objection I often hear is: ""It will stop someplace random, and it will miss the real problem"".This comes from having a prior concept of what the real problem is.A key property of performance problems is that they defy expectations.Sampling tells you something is a problem, and your first reaction is disbelief.That is natural, but you can be sure if it finds a problem it is real, and vice-versa.Added: Let me make a Bayesian explanation of how it works.  Suppose there is some instruction I (call or otherwise) which is on the call stack some fraction f of the time (and thus costs that much). For simplicity, suppose we don't know what f is, but assume it is either 0.1, 0.2, 0.3, ... 0.9, 1.0, and the prior probability of each of these possibilities is 0.1, so all of these costs are equally likely a-priori.Then suppose we take just 2 stack samples, and we see instruction I on both samples, designated observation o=2/2. This gives us new estimates of the frequency f of I, according to this:Prior                                    P(f=x) x  P(o=2/2|f=x) P(o=2/2&&f=x)  P(o=2/2&&f >= x)  P(f >= x | o=2/2)0.1    1     1             0.1          0.1            0.259740260.1    0.9   0.81          0.081        0.181          0.470129870.1    0.8   0.64          0.064        0.245          0.6363636360.1    0.7   0.49          0.049        0.294          0.7636363640.1    0.6   0.36          0.036        0.33           0.8571428570.1    0.5   0.25          0.025        0.355          0.9220779220.1    0.4   0.16          0.016        0.371          0.9636363640.1    0.3   0.09          0.009        0.38           0.9870129870.1    0.2   0.04          0.004        0.384          0.9974025970.1    0.1   0.01          0.001        0.385          1                  P(o=2/2) 0.385                The last column says that, for example, the probability that f >= 0.5 is 92%, up from the prior assumption of 60%.Suppose the prior assumptions are different. Suppose we assume P(f=0.1) is .991 (nearly certain), and all the other possibilities are almost impossible (0.001). In other words, our prior certainty is that I is cheap. Then we get:Prior                                    P(f=x) x  P(o=2/2|f=x) P(o=2/2&& f=x)  P(o=2/2&&f >= x)  P(f >= x | o=2/2)0.001  1    1              0.001        0.001          0.0727272730.001  0.9  0.81           0.00081      0.00181        0.1316363640.001  0.8  0.64           0.00064      0.00245        0.1781818180.001  0.7  0.49           0.00049      0.00294        0.2138181820.001  0.6  0.36           0.00036      0.0033         0.240.001  0.5  0.25           0.00025      0.00355        0.2581818180.001  0.4  0.16           0.00016      0.00371        0.2698181820.001  0.3  0.09           0.00009      0.0038         0.2763636360.001  0.2  0.04           0.00004      0.00384        0.2792727270.991  0.1  0.01           0.00991      0.01375        1                  P(o=2/2) 0.01375                Now it says P(f >= 0.5) is 26%, up from the prior assumption of 0.6%. So Bayes allows us to update our estimate of the probable cost of I. If the amount of data is small, it doesn't tell us accurately what the cost is, only that it is big enough to be worth fixing.Yet another way to look at it is called the Rule Of Succession.If you flip a coin 2 times, and it comes up heads both times, what does that tell you about the probable weighting of the coin?The respected way to answer is to say that it's a Beta distribution, with average value (number of hits + 1) / (number of tries + 2) = (2+1)/(2+2) = 75%.(The key is that we see I more than once. If we only see it once, that doesn't tell us much except that f > 0.)So, even a very small number of samples can tell us a lot about the cost of instructions that it sees. (And it will see them with a frequency, on average, proportional to their cost. If n samples are taken, and f is the cost, then I will appear on nf+/-sqrt(nf(1-f)) samples. Example, n=10, f=0.3, that is 3+/-1.4 samples.)Added: To give an intuitive feel for the difference between measuring and random stack sampling:There are profilers now that sample the stack, even on wall-clock time, but what comes out is measurements (or hot path, or hot spot, from which a ""bottleneck"" can easily hide). What they don't show you (and they easily could) is the actual samples themselves. And if your goal is to find the bottleneck, the number of them you need to see is, on average, 2 divided by the fraction of time it takes.So if it takes 30% of time, 2/.3 = 6.7 samples, on average, will show it, and the chance that 20 samples will show it is 99.2%.Here is an off-the-cuff illustration of the difference between examining measurements and examining stack samples.The bottleneck could be one big blob like this, or numerous small ones, it makes no difference.Measurement is horizontal; it tells you what fraction of time specific routines take.Sampling is vertical.If there is any way to avoid what the whole program is doing at that moment, and if you see it on a second sample, you've found the bottleneck.That's what makes the difference - seeing the whole reason for the time being spent, not just how much."
"data_i","edited Mar 26 '18 at 06:18","
        What's the difference between INNER JOIN, LEFT JOIN, RIGHT JOIN and FULL JOIN?
    ","What's the difference between INNER JOIN, LEFT JOIN, RIGHT JOIN and FULL JOIN in MySQL?","Reading this original article on The Code Project will help you a lot: Visual Representation of SQL Joins.Also check this post: SQL SERVER – Better Performance – LEFT JOIN or NOT IN?.Find original one at: Difference between JOIN and OUTER JOIN in MySQL."
"data_i","edited Mar 29 '22 at 09:37","
        How to remove an element from a list by index
    ","How do I remove an element from a list by index?I found list.remove(), but this slowly scans the list for an item by value.","Use del and specify the index of the element you want to delete:>>> a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]>>> del a[-1]>>> a[0, 1, 2, 3, 4, 5, 6, 7, 8]Also supports slices:>>> del a[2:4]>>> a[0, 1, 4, 5, 6, 7, 8, 9]Here is the section from the tutorial."
"data_i","edited Feb 01 '19 at 21:35","
        Throw away local commits in Git
    ","Due to some bad cherry-picking, my local Git repository is currently five commits ahead of the origin, and not in a good state. I want to get rid of all these commits and start over again.Obviously, deleting my working directory and re-cloning would do it, but downloading everything from GitHub again seems like overkill, and not a good use of my time.Maybe git revert is what I need, but I don't want to end up 10 commits ahead of the origin (or even six), even if it does get the code itself back to the right state. I just want to pretend the last half-hour never happened.Is there a simple command that will do this? It seems like an obvious use case, but I'm not finding any examples of it.Note that this question is specifically about commits, not about:untracked filesunstaged changesstaged, but uncommitted changes","If your excess commits are only visible to you, you can just do git reset --hard origin/<branch_name> to move back to where the origin is. This will reset the state of the repository to the previous commit, and it will discard all local changes.Doing a git revert makes new commits to remove old commits in a way that keeps everyone's history sane."
"data_i","edited Nov 20 '12 at 11:27","
        How do you stash an untracked file?
    ","I have changes to a file, plus a new file, and would like to use git stash to put them away while I switch to another task.  But git stash by itself stashes only the changes to the existing file; the new file remains in my working tree, cluttering up my future work.  How do I stash this untracked file?","To stash your working directory including untracked files (especially those that are in the .gitignore) then you probably want to use this cmd:git stash --include-untrackedAlternatively, you can use the shorthand -u instead of --include-untracked, or simply git stash --all which stashes all files, including untracked and ignored files. This bahaviour changed in 2018, so make sure your git is up to date.Warning: there seems to be (or have been) situations in which contents of ignored directories could be deleted permanently. See this archived website for more information."
"data_i","edited Jun 06 '22 at 03:59","
        Determine the type of an object?
    ","Is there a simple way to determine if a variable is a list, dictionary, or something else?","There are two built-in functions that help you identify the type of an object. You can use type()  if you need the exact type of an object, and isinstance() to check an object’s type against something. Usually, you want to use isinstance() most of the times since it is very robust and also supports type inheritance.To get the actual type of an object, you use the built-in type() function. Passing an object as the only parameter will return the type object of that object:>>> type([]) is listTrue>>> type({}) is dictTrue>>> type('') is strTrue>>> type(0) is intTrueThis of course also works for custom types:>>> class Test1 (object):        pass>>> class Test2 (Test1):        pass>>> a = Test1()>>> b = Test2()>>> type(a) is Test1True>>> type(b) is Test2TrueNote that type() will only return the immediate type of the object, but won’t be able to tell you about type inheritance.>>> type(b) is Test1FalseTo cover that, you should use the isinstance function. This of course also works for built-in types:>>> isinstance(b, Test1)True>>> isinstance(b, Test2)True>>> isinstance(a, Test1)True>>> isinstance(a, Test2)False>>> isinstance([], list)True>>> isinstance({}, dict)Trueisinstance() is usually the preferred way to ensure the type of an object because it will also accept derived types. So unless you actually need the type object (for whatever reason), using isinstance() is preferred over type().The second parameter of isinstance() also accepts a tuple of types, so it’s possible to check for multiple types at once. isinstance will then return true, if the object is of any of those types:>>> isinstance([], (tuple, list, set))True"
"data_i","edited Oct 28 '20 at 09:21","
        Short circuit Array.forEach like calling break
    ","[1,2,3].forEach(function(el) {    if(el === 1) break;});How can I do this using the new forEach method in JavaScript? I've tried return;, return false; and break. break crashes and return does nothing but continue iteration.","There's no built-in ability to break in forEach. To interrupt execution you would have to throw an exception of some sort. eg.var BreakException = {};try {  [1, 2, 3].forEach(function(el) {    console.log(el);    if (el === 2) throw BreakException;  });} catch (e) {  if (e !== BreakException) throw e;}JavaScript exceptions aren't terribly pretty. A traditional for loop might be more appropriate if you really need to break inside it. Use Array#someInstead, use Array#some:[1, 2, 3].some(function(el) {  console.log(el);  return el === 2;});This works because some returns true as soon as any of the callbacks, executed in array order, return true, short-circuiting the execution of the rest.some, its inverse every (which will stop on a return false), and forEach are all ECMAScript Fifth Edition methods which will need to be added to the Array.prototype on browsers where they're missing."
"data_i","edited Dec 24 '19 at 04:33","
        How to lazy load images in ListView in Android
    ","I am using a ListView to display some images and captions associated with those images. I am getting the images from the Internet. Is there a way to lazy load images so while the text displays, the UI is not blocked and images are displayed as they are downloaded? The total number of images is not fixed.","Here's what I created to hold the images that my app is currently displaying. Please note that the ""Log"" object in use here is my custom wrapper around the final Log class inside Android.package com.wilson.android.library;/* Licensed to the Apache Software Foundation (ASF) under one or morecontributor license agreements.  See the NOTICE filedistributed with this work for additional informationregarding copyright ownership.  The ASF licenses this fileto you under the Apache License, Version 2.0 (the""License""); you may not use this file except in compliancewith the License.  You may obtain a copy of the License athttp://www.apache.org/licenses/LICENSE-2.0Unless required by applicable law or agreed to in writing,software distributed under the License is distributed on an""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANYKIND, either express or implied.  See the License for thespecific language governing permissions and limitationsunder the License.*/import java.io.IOException;public class DrawableManager {    private final Map<String, Drawable> drawableMap;    public DrawableManager() {        drawableMap = new HashMap<String, Drawable>();    }    public Drawable fetchDrawable(String urlString) {        if (drawableMap.containsKey(urlString)) {            return drawableMap.get(urlString);        }        Log.d(this.getClass().getSimpleName(), ""image url:"" + urlString);        try {            InputStream is = fetch(urlString);            Drawable drawable = Drawable.createFromStream(is, ""src"");            if (drawable != null) {                drawableMap.put(urlString, drawable);                Log.d(this.getClass().getSimpleName(), ""got a thumbnail drawable: "" + drawable.getBounds() + "", ""                        + drawable.getIntrinsicHeight() + "","" + drawable.getIntrinsicWidth() + "", ""                        + drawable.getMinimumHeight() + "","" + drawable.getMinimumWidth());            } else {              Log.w(this.getClass().getSimpleName(), ""could not get thumbnail"");            }            return drawable;        } catch (MalformedURLException e) {            Log.e(this.getClass().getSimpleName(), ""fetchDrawable failed"", e);            return null;        } catch (IOException e) {            Log.e(this.getClass().getSimpleName(), ""fetchDrawable failed"", e);            return null;        }    }    public void fetchDrawableOnThread(final String urlString, final ImageView imageView) {        if (drawableMap.containsKey(urlString)) {            imageView.setImageDrawable(drawableMap.get(urlString));        }        final Handler handler = new Handler(Looper.getMainLooper()) {            @Override            public void handleMessage(Message message) {                imageView.setImageDrawable((Drawable) message.obj);            }        };        Thread thread = new Thread() {            @Override            public void run() {                //TODO : set imageView to a ""pending"" image                Drawable drawable = fetchDrawable(urlString);                Message message = handler.obtainMessage(1, drawable);                handler.sendMessage(message);            }        };        thread.start();    }    private InputStream fetch(String urlString) throws MalformedURLException, IOException {        DefaultHttpClient httpClient = new DefaultHttpClient();        HttpGet request = new HttpGet(urlString);        HttpResponse response = httpClient.execute(request);        return response.getEntity().getContent();    }}"
"data_i","edited Sep 21 '18 at 15:00","
        PostgreSQL ""DESCRIBE TABLE""
    ","How do you perform the equivalent of Oracle's DESCRIBE TABLE in PostgreSQL (using the psql command)?","Try this (in the psql command-line tool):\d+ tablenameSee the manual for more info."
"data_i","edited Jan 03 '21 at 22:04","
        How to reload .bashrc settings without logging out and back in again?
    ","If I make changes to .bashrc, how do I reload it without logging out and back in?","You can enter the long form command:source ~/.bashrcor you can use the shorter version of the command:. ~/.bashrc"
"data_i","edited Feb 15 '21 at 00:29","
        Could not open a connection to your authentication agent
    ","I am running into this error of: $ git push heroku masterWarning: Permanently added the RSA host key for IP address '50.19.85.132' to the list of known hosts.!  Your key with fingerprint b7:fd:15:25:02:8e:5f:06:4f:1c:af:f3:f0:c3:c2:65 is not authorized to access bitstarter.I tried to add the keys and I get this error below:$ ssh-add ~/.ssh/id_rsa.pubCould not open a connection to your authentication agent.","Did You Start ssh-agent?You might need to start ssh-agent before you run the ssh-add command:eval `ssh-agent -s`ssh-addNote that this will start the agent for msysgit Bash on Windows. If you're using a different shell or operating system, you might need to use a variant of the command, such as those listed in the other answers.See the following answers:ssh-add complains: Could not open a connection to your authentication agentGit push requires username and password (contains detailed instructions on how to use ssh-agent)How to run (git/ssh) authentication agent?.Could not open a connection to your authentication agentTo automatically start ssh-agent and allow a single instance to work in multiple console windows, see Start ssh-agent on login.Why do we need to use eval instead of just ssh-agent?SSH needs two things in order to use ssh-agent: an ssh-agent instance running in the background, and an environment variable set that tells SSH which socket it should use to connect to the agent (SSH_AUTH_SOCK IIRC). If you just run ssh-agent then the agent will start, but SSH will have no idea where to find it.from this comment.Public vs Private KeysAlso, whenever I use ssh-add, I always add private keys to it. The file ~/.ssh/id_rsa.pub looks like a public key, I'm not sure if that will work.  Do you have a ~/.ssh/id_rsa file? If you open it in a text editor, does it say it's a private key?"
"data_i","asked Nov 17 '09 at 17:26","
        Comparing Java enum members: == or equals()?
    ","I know that Java enums are compiled to classes with private constructors and a bunch of public static members. When comparing two members of a given enum, I've always used .equals(), e.g.public useEnums(SomeEnum a){    if(a.equals(SomeEnum.SOME_ENUM_VALUE))    {        ...    }    ...}However, I just came across some code that uses the equals operator == instead of .equals():public useEnums2(SomeEnum a){    if(a == SomeEnum.SOME_ENUM_VALUE)    {        ...    }    ...}Which operator is the one I should be using?","Both are technically correct. If you look at the source code for .equals(), it simply defers to ==.I use ==, however, as that will be null safe."
"data_i","edited May 26 '12 at 20:37","
        RegEx match open tags except XHTML self-contained tags
    ","I need to match all of these opening tags:<p><a href=""foo"">But not these:<br /><hr class=""foo"" />I came up with this and wanted to make sure I've got it right. I am only capturing the a-z.<([a-z]+) *[^/]*?>I believe it says:Find a less-than, thenFind (and capture) a-z one or more times, thenFind zero or more spaces, thenFind any character zero or more times, greedy, except /, thenFind a greater-thanDo I have that right? And more importantly, what do you think?","You can't parse [X]HTML with regex. Because HTML can't be parsed by regex. Regex is not a tool that can be used to correctly parse HTML. As I have answered in HTML-and-regex questions here so many times before, the use of regex will not allow you to consume HTML. Regular expressions are a tool that is insufficiently sophisticated to understand the constructs employed by HTML. HTML is not a regular language and hence cannot be parsed by regular expressions. Regex queries are not equipped to break down HTML into its meaningful parts. so many times but it is not getting to me. Even enhanced irregular regular expressions as used by Perl are not up to the task of parsing HTML. You will never make me crack. HTML is a language of sufficient complexity that it cannot be parsed by regular expressions. Even Jon Skeet cannot parse HTML using regular expressions. Every time you attempt to parse HTML with regular expressions, the unholy child weeps the blood of virgins, and Russian hackers pwn your webapp. Parsing HTML with regex summons tainted souls into the realm of the living. HTML and regex go together like love, marriage, and ritual infanticide. The <center> cannot hold it is too late. The force of regex and HTML together in the same conceptual space will destroy your mind like so much watery putty. If you parse HTML with regex you are giving in to Them and their blasphemous ways which doom us all to inhuman toil for the One whose Name cannot be expressed in the Basic Multilingual Plane, he comes. HTML-plus-regexp will liquify the n​erves of the sentient whilst you observe, your psyche withering in the onslaught of horror. Rege̿̔̉x-based HTML parsers are the cancer that is killing StackOverflow it is too late it is too late we cannot be saved the transgression of a chi͡ld ensures regex will consume all living tissue (except for HTML which it cannot, as previously prophesied) dear lord help us how can anyone survive this scourge using regex to parse HTML has doomed humanity to an eternity of dread torture and security holes using regex as a tool to process HTML establishes a breach between this world and the dread realm of c͒ͪo͛ͫrrupt entities (like SGML entities, but more corrupt) a mere glimpse of the world of reg​ex parsers for HTML will ins​tantly transport a programmer's consciousness into a world of ceaseless screaming, he comes, the pestilent slithy regex-infection wil​l devour your HT​ML parser, application and existence for all time like Visual Basic only worse he comes he comes do not fi​ght he com̡e̶s, ̕h̵i​s un̨ho͞ly radiańcé destro҉ying all enli̍̈́̂̈́ghtenment, HTML tags lea͠ki̧n͘g fr̶ǫm ̡yo​͟ur eye͢s̸ ̛l̕ik͏e liq​uid pain, the song of re̸gular exp​ression parsing will exti​nguish the voices of mor​tal man from the sp​here I can see it can you see ̲͚̖͔̙î̩́t̲͎̩̱͔́̋̀ it is beautiful t​he final snuffing of the lie​s of Man ALL IS LOŚ͖̩͇̗̪̏̈́T ALL I​S LOST the pon̷y he comes he c̶̮omes he comes the ich​or permeates all MY FACE MY FACE ᵒh god no NO NOO̼O​O NΘ stop the an​*̶͑̾̾​̅ͫ͏̙̤g͇̫͛͆̾ͫ̑͆l͖͉̗̩̳̟̍ͫͥͨe̠̅s ͎a̧͈͖r̽̾̈́͒͑e n​ot rè̑ͧ̌aͨl̘̝̙̃ͤ͂̾̆ ZA̡͊͠͝LGΌ ISͮ̂҉̯͈͕̹̘̱ TO͇̹̺ͅƝ̴ȳ̳ TH̘Ë͖́̉ ͠P̯͍̭O̚​N̐Y̡ H̸̡̪̯ͨ͊̽̅̾̎Ȩ̬̩̾͛ͪ̈́̀́͘ ̶̧̨̱̹̭̯ͧ̾ͬC̷̙̲̝͖ͭ̏ͥͮ͟Oͮ͏̮̪̝͍M̲̖͊̒ͪͩͬ̚̚͜Ȇ̴̟̟͙̞ͩ͌͝S̨̥̫͎̭ͯ̿̔̀ͅHave you tried using an XML parser instead?Moderator's NoteThis post is locked to prevent inappropriate edits to its content. The post looks exactly as it is supposed to look - there are no problems with its content. Please do not flag it for our attention."
"data_i","edited Mar 29 '22 at 09:31","
        How to determine a Python variable's type?
    ","How do I see the type of a variable? (e.g. unsigned 32 bit)","Use the type() builtin function:>>> i = 123>>> type(i)<type 'int'>>>> type(i) is intTrue>>> i = 123.456>>> type(i)<type 'float'>>>> type(i) is floatTrueTo check if a variable is of a given type, use isinstance:>>> i = 123>>> isinstance(i, int)True>>> isinstance(i, (float, str, set, dict))FalseNote that Python doesn't have the same types as C/C++, which appears to be your question."
"data_i","edited Jun 02 '21 at 17:39","
        Is there a way to cache https credentials for pushing commits?
    ","I recently switched to synchronizing my repositories to https:// on GitHub (due to firewall issues), and it asks for a password every time.Is there a way to cache the credentials, instead of authenticating every time that git push?","Since Git 1.7.9 (released 2012), there is a neat mechanism in Git to avoid having to type your password all the time for HTTP / HTTPS, called credential helpers.You can just use one of the following credential helpers:git config --global credential.helper cacheThe credential.helper cache value tells Git to keep your password cached in memory for a particular amount of minutes. The default is 15 minutes, you can set a longer timeout with:# Cache for 1 hourgit config --global credential.helper ""cache --timeout=3600""# Cache for 1 daygit config --global credential.helper ""cache --timeout=86400""# Cache for 1 weekgit config --global credential.helper ""cache --timeout=604800""You can also store your credentials permanently if so desired, see the other answers below.GitHub's help also suggests that if you're on Mac OS X and used Homebrew to install Git, you can use the native Mac OS X keystore with:git config --global credential.helper osxkeychainFor Windows, there is a helper called Git Credential Manager for Windows or wincred in msysgit.git config --global credential.helper wincred # obsoleteWith Git for Windows 2.7.3+ (March 2016):git config --global credential.helper managerFor Linux, you would use (in 2011) gnome-keyring(or other keyring implementation such as KWallet).Nowadays (2020), that would be (on Linux)Fedorasudo dnf install git-credential-libsecretgit config --global credential.helper /usr/libexec/git-core/git-credential-libsecretUbuntusudo apt-get install libsecret-1-0 libsecret-1-devcd /usr/share/doc/git/contrib/credential/libsecretsudo makegit config --global credential.helper /usr/share/doc/git/contrib/credential/libsecret/git-credential-libsecret"
"data_i","edited May 23 '22 at 14:49","
        What is the ""N+1 selects problem"" in ORM (Object-Relational Mapping)?
    ","The ""N+1 selects problem"" is generally stated as a problem in Object-Relational mapping (ORM) discussions, and I understand that it has something to do with having to make a lot of database queries for something that seems simple in the object world.Does anybody have a more detailed explanation of the problem?","Let's say you have a collection of Car objects (database rows), and each Car has a collection of Wheel objects (also rows).  In other words, Car → Wheel is a 1-to-many relationship.Now, let's say you need to iterate through all the cars, and for each one, print out a list of the wheels. The naive O/R implementation would do the following:SELECT * FROM Cars;And then for each Car:SELECT * FROM Wheel WHERE CarId = ?In other words, you have one select for the Cars, and then N additional selects, where N is the total number of cars.Alternatively, one could get all wheels and perform the lookups in memory:SELECT * FROM Wheel;This reduces the number of round-trips to the database from N+1 to 2.Most ORM tools give you several ways to prevent N+1 selects.Reference: Java Persistence with Hibernate, chapter 13."
"data_i","edited Oct 02 '18 at 21:43","
        Copy array by value
    ","When copying an array in JavaScript to another array:var arr1 = ['a','b','c'];var arr2 = arr1;arr2.push('d');  //Now, arr1 = ['a','b','c','d']I realized that arr2 refers to the same array as arr1, rather than a new, independent array. How can I copy the array to get two independent arrays?","Use this:let oldArray = [1, 2, 3, 4, 5];let newArray = oldArray.slice();console.log({newArray});Basically, the slice() operation clones the array and returns a reference to a new array.Also note that:For references, strings and numbers (and not the actual object), slice() copies object references into the new array. Both the original and new array refer to the same object. If a referenced object changes, the changes are visible to both the new and original arrays.Primitives such as strings and numbers are immutable, so changes to the string or number are impossible."
"data_i","edited Jul 17 '22 at 00:52","
        Remove file from latest commit
    ","How do I remove a file from the latest commit?","I think other answers here are wrong, because this is a question of moving the mistakenly committed files back to the staging area from the previous commit, without cancelling the changes done to them. This can be done like Paritosh Singh suggested:git reset --soft HEAD^ orgit reset --soft HEAD~1Then reset the unwanted files in order to leave them out from the commit (the old way):git reset HEAD path/to/unwanted_fileNote, that since Git 2.23.0 one can (the new way):git restore --staged path/to/unwanted_fileNow commit again, you can even re-use the same commit message:git commit -c ORIG_HEAD  "
"data_i","edited Jan 18 '20 at 09:40","
        NPM vs. Bower vs. Browserify vs. Gulp vs. Grunt vs. Webpack
    ","I'm trying to summarize my knowledge about the most popular JavaScript package managers, bundlers, and task runners. Please correct me if I'm wrong:npm & bower are package managers. They just download the dependencies and don't know how to build projects on their own. What they know is to call webpack/gulp/grunt after fetching all the dependencies.bower is like npm, but builds a flattened dependency trees (unlike npm which does it recursively). Meaning npm fetches the dependencies for each dependency (may fetch the same a few times), while bower expects you to manually include sub-dependencies. Sometimes bower and npm are used together for front-end and back-end respectively (since each megabyte might matter in front-end).grunt and gulp are task runners to automate everything that can be automated (i.e. compile CSS/Sass, optimize images, make a bundle and minify/transpile it).grunt vs. gulp (is like maven vs. gradle or configuration vs. code). Grunt is based on configuring separate independent tasks, each task opens/handles/closes file. Gulp requires less amount of code and is based on Node streams, which allows it to build pipe chains (w/o reopening the same file) and makes it faster. webpack (webpack-dev-server) - for me it's a task runner with hot reloading of changes which allows you to forget about all JS/CSS watchers. npm/bower + plugins may replace task runners. Their abilities often intersect so there are different implications if you need to use gulp/grunt over npm + plugins. But task runners are definitely better for complex tasks (e.g. ""on each build create bundle, transpile from ES6 to ES5, run it at all browsers emulators, make screenshots and deploy to dropbox through ftp"").browserify allows packaging node modules for browsers. browserify vs node's require is actually AMD vs CommonJS.Questions:What is webpack & webpack-dev-server? Official documentation says it's a module bundler but for me it's just a task runner. What's the difference?Where would you use browserify? Can't we do the same with node/ES6 imports? When would you use gulp/grunt over npm + plugins?Please provide examples when you need to use a combination","Webpack and BrowserifyWebpack and Browserify do pretty much the same job, which is processing your code to be used in a target environment (mainly browser, though you can target other environments like Node). Result of such processing is one or more bundles - assembled scripts suitable for targeted environment. For example, let's say you wrote ES6 code divided into modules and want to be able to run it in a browser. If those modules are Node modules, the browser won't understand them since they exist only in the Node environment. ES6 modules also won't work in older browsers like IE11. Moreover, you might have used experimental language features (ES next proposals) that browsers don't implement yet so running such script would just throw errors. Tools like Webpack and Browserify solve these problems by translating such code to a form a browser is able to execute. On top of that, they make it possible to apply a huge variety of optimisations on those bundles.However, Webpack and Browserify differ in many ways, Webpack offers many tools by default (e.g. code splitting), while Browserify can do this only after downloading plugins but using both leads to very similar results. It comes down to personal preference (Webpack is trendier). Btw, Webpack is not a task runner, it is just processor of your files (it processes them by so called loaders and plugins) and it can be run (among other ways) by a task runner.Webpack Dev ServerWebpack Dev Server provides a similar solution to Browsersync - a development server where you can deploy your app rapidly as you are working on it, and verify your development progress immediately, with the dev server automatically refreshing the browser on code changes or even propagating changed code to browser without reloading with so called hot module replacement.Task runners vs NPM scriptsI've been using Gulp for its conciseness and easy task writing, but have later found out I need neither Gulp nor Grunt at all. Everything I have ever needed could have been done using NPM scripts to run 3rd-party tools through their API. Choosing between Gulp, Grunt or NPM scripts depends on taste and experience of your team.While tasks in Gulp or Grunt are easy to read even for people not so familiar with JS, it is yet another tool to require and learn and I personally prefer to narrow my dependencies and make things simple. On the other hand, replacing these tasks with the combination of NPM scripts and (propably JS) scripts which run those 3rd party tools (eg. Node script configuring and running rimraf for cleaning purposes) might be more challenging. But in the majority of cases, those three are equal in terms of their results.ExamplesAs for the examples, I suggest you have a look at this React starter project, which shows you a nice combination of NPM and JS scripts covering the whole build and deploy process. You can find those NPM scripts in package.json in the root folder, in a property named scripts. There you will mostly encounter commands like babel-node tools/run start. Babel-node is a CLI tool (not meant for production use), which at first compiles ES6 file tools/run (run.js file located in tools) - basically a runner utility. This runner takes a function as an argument and executes it, which in this case is start - another utility (start.js) responsible for bundling source files (both client and server) and starting the application and development server (the dev server will be probably either Webpack Dev Server or Browsersync).Speaking more precisely, start.js creates both client and server side bundles, starts an express server and after a successful launch initializes Browser-sync, which at the time of writing looked like this (please refer to react starter project for the newest code).const bs = Browsersync.create();  bs.init({      ...(DEBUG ? {} : { notify: false, ui: false }),      proxy: {        target: host,        middleware: [wpMiddleware, ...hotMiddlewares],      },      // no need to watch '*.js' here, webpack will take care of it for us,      // including full page reloads if HMR won't work      files: ['build/content/**/*.*'],}, resolve)The important part is proxy.target, where they set server address they want to proxy, which could be http://localhost:3000, and Browsersync starts a server listening on http://localhost:3001, where the generated assets are served with automatic change detection and hot module replacement. As you can see, there is another configuration property files with individual files or patterns Browser-sync watches for changes and reloads the browser if some occur, but as the comment says, Webpack takes care of watching js sources by itself with HMR, so they cooperate there.Now I don't have any equivalent example of such Grunt or Gulp configuration, but with Gulp (and somewhat similarly with Grunt) you would write individual tasks in gulpfile.js likegulp.task('bundle', function() {  // bundling source files with some gulp plugins like gulp-webpack maybe});gulp.task('start', function() {  // starting server and stuff});where you would be doing essentially pretty much the same things as in the starter-kit, this time with task runner, which solves some problems for you, but presents its own issues and some difficulties during learning the usage, and as I say, the more dependencies you have, the more can go wrong. And that is the reason I like to get rid of such tools."
"data_i","edited Apr 22 '19 at 21:44","
        Loop through an array of strings in Bash?
    ","I want to write a script that loops through 15 strings (array possibly?) Is that possible?Something like:for databaseName in listOfNamesthen  # Do somethingend","You can use it like this:## declare an array variabledeclare -a arr=(""element1"" ""element2"" ""element3"")## now loop through the above arrayfor i in ""${arr[@]}""do   echo ""$i""   # or do whatever with individual element of the arraydone# You can access them using echo ""${arr[0]}"", ""${arr[1]}"" alsoAlso works for multi-line array declarationdeclare -a arr=(""element1""                 ""element2"" ""element3""                ""element4""                )"
"data_i","edited Feb 22 '17 at 03:52","
        What is the optimal algorithm for the game 2048?
    ","I have recently stumbled upon the game 2048. You merge similar tiles by moving them in any of the four directions to make ""bigger"" tiles. After each move, a new tile appears at random empty position with a value of either 2 or 4. The game terminates when all the boxes are filled and there are no moves that can merge tiles, or you create a tile with a value of 2048.One, I need to follow a well-defined strategy to reach the goal. So, I thought of writing a program for it.My current algorithm:while (!game_over) {    for each possible move:        count_no_of_merges_for_2-tiles and 4-tiles    choose the move with a large number of merges}What I am doing is at any point, I will try to merge the tiles with values 2 and 4, that is, I try to have 2 and 4 tiles, as minimum as possible. If I try it this way, all other tiles were automatically getting merged and the strategy seems good.But, when I actually use this algorithm, I only get around 4000 points before the game terminates. Maximum points AFAIK is slightly more than 20,000 points which is way larger than my current score. Is there a better algorithm than the above?","I developed a 2048 AI using expectimax optimization, instead of the minimax search used by @ovolve's algorithm. The AI simply performs maximization over all possible moves, followed by expectation over all possible tile spawns (weighted by the probability of the tiles, i.e. 10% for a 4 and 90% for a 2). As far as I'm aware, it is not possible to prune expectimax optimization (except to remove branches that are exceedingly unlikely), and so the algorithm used is a carefully optimized brute force search.PerformanceThe AI in its default configuration (max search depth of 8) takes anywhere from 10ms to 200ms to execute a move, depending on the complexity of the board position. In testing, the AI achieves an average move rate of 5-10 moves per second over the course of an entire game. If the search depth is limited to 6 moves, the AI can easily execute 20+ moves per second, which makes for some interesting watching.To assess the score performance of the AI, I ran the AI 100 times (connected to the browser game via remote control). For each tile, here are the proportions of games in which that tile was achieved at least once:2048: 100%4096: 100%8192: 100%16384: 94%32768: 36%The minimum score over all runs was 124024; the maximum score achieved was 794076. The median score is 387222. The AI never failed to obtain the 2048 tile (so it never lost the game even once in 100 games); in fact, it achieved the 8192 tile at least once in every run!Here's the screenshot of the best run:This game took 27830 moves over 96 minutes, or an average of 4.8 moves per second. ImplementationMy approach encodes the entire board (16 entries) as a single 64-bit integer (where tiles are the nybbles, i.e. 4-bit chunks). On a 64-bit machine, this enables the entire board to be passed around in a single machine register.Bit shift operations are used to extract individual rows and columns. A single row or column is a 16-bit quantity, so a table of size 65536 can encode transformations which operate on a single row or column. For example, moves are implemented as 4 lookups into a precomputed ""move effect table"" which describes how each move affects a single row or column (for example, the ""move right"" table contains the entry ""1122 -> 0023"" describing how the row [2,2,4,4] becomes the row [0,0,4,8] when moved to the right).Scoring is also done using table lookup. The tables contain heuristic scores computed on all possible rows/columns, and the resultant score for a board is simply the sum of the table values across each row and column.This board representation, along with the table lookup approach for movement and scoring, allows the AI to search a huge number of game states in a short period of time (over 10,000,000 game states per second on one core of my mid-2011 laptop).The expectimax search itself is coded as a recursive search which alternates between ""expectation"" steps (testing all possible tile spawn locations and values, and weighting their optimized scores by the probability of each possibility), and ""maximization"" steps (testing all possible moves and selecting the one with the best score). The tree search terminates when it sees a previously-seen position (using a transposition table), when it reaches a predefined depth limit, or when it reaches a board state that is highly unlikely (e.g. it was reached by getting 6 ""4"" tiles in a row from the starting position). The typical search depth is 4-8 moves.HeuristicsSeveral heuristics are used to direct the optimization algorithm towards favorable positions. The precise choice of heuristic has a huge effect on the performance of the algorithm. The various heuristics are weighted and combined into a positional score, which determines how ""good"" a given board position is. The optimization search will then aim to maximize the average score of all possible board positions. The actual score, as shown by the game, is not used to calculate the board score, since it is too heavily weighted in favor of merging tiles (when delayed merging could produce a large benefit).Initially, I used two very simple heuristics, granting ""bonuses"" for open squares and for having large values on the edge. These heuristics performed pretty well, frequently achieving 16384 but never getting to 32768.Petr Morávek (@xificurk) took my AI and added two new heuristics. The first heuristic was a penalty for having non-monotonic rows and columns which increased as the ranks increased, ensuring that  non-monotonic rows of small numbers would not strongly affect the score, but non-monotonic rows of large numbers hurt the score substantially. The second heuristic counted the number of potential merges (adjacent equal values) in addition to open spaces. These two heuristics served to push the algorithm towards monotonic boards (which are easier to merge), and towards board positions with lots of merges (encouraging it to align merges where possible for greater effect).Furthermore, Petr also optimized the heuristic weights using a ""meta-optimization"" strategy (using an algorithm called CMA-ES), where the weights themselves were adjusted to obtain the highest possible average score.The effect of these changes are extremely significant. The algorithm went from achieving the 16384 tile around 13% of the time to achieving it over 90% of the time, and the algorithm began to achieve 32768 over 1/3 of the time (whereas the old heuristics never once produced a 32768 tile).I believe there's still room for improvement on the heuristics. This algorithm definitely isn't yet ""optimal"", but I feel like it's getting pretty close.That the AI achieves the 32768 tile in over a third of its games is a huge milestone; I will be surprised to hear if any human players have achieved 32768 on the official game (i.e. without using tools like savestates or undo). I think the 65536 tile is within reach!You can try the AI for yourself. The code is available at https://github.com/nneonneo/2048-ai."
"data_i","edited Jul 30 '22 at 20:57","
        How do I count the occurrences of a list item?
    ","Given a single item, how do I count occurrences of it in a list, in Python?A related but different problem is counting occurrences of each different element in a collection, getting a dictionary or list as a histogram result instead of a single integer. For that problem, see Using a dictionary to count the items in a list.","If you only want a single item's count, use the count method:>>> [1, 2, 3, 4, 1, 4, 1].count(1)3Important: this is very slow if you are counting multiple different itemsEach count call goes over the entire list of n elements. Calling count in a loop n times means n * n total checks, which can be catastrophic for performance.If you want to count multiple items, use Counter, which only does n total checks."
"data_i","asked Sep 15 '09 at 08:31","
        How do you merge two Git repositories?
    ","Consider the following scenario:I have developed a small experimental project A in its own Git repo. It has now matured, and I'd like A to be part of larger project B, which has its own big repository. I'd now like to add A as a subdirectory of B.How do I merge A into B, without losing history on any side?","If you want to merge project-a into project-b:cd path/to/project-bgit remote add project-a /path/to/project-agit fetch project-a --tagsgit merge --allow-unrelated-histories project-a/master # or whichever branch you want to mergegit remote remove project-aTaken from: git merge different repositories?This method worked pretty well for me, it's shorter and in my opinion a lot cleaner.In case you want to put project-a into a subdirectory, you can use git-filter-repo (filter-branch is discouraged). Run the following commands before the commands above:cd path/to/project-agit filter-repo --to-subdirectory-filter project-aAn example of merging 2 big repositories, putting one of them into a subdirectory: https://gist.github.com/x-yuri/9890ab1079cf4357d6f269d073fd9731Note: The --allow-unrelated-histories parameter only exists since git >= 2.9. See Git - git merge Documentation / --allow-unrelated-historiesUpdate: Added --tags as suggested by @jstadler in order to keep tags."
"data_i","edited May 23 '17 at 12:34","
        How does data binding work in AngularJS?
    ","How does data binding work in the AngularJS framework?I haven't found technical details on their site. It's more or less clear how it works when data is propagated from view to model. But how does AngularJS track changes of model properties without setters and getters?I found that there are JavaScript watchers that may do this work. But they are not supported in Internet Explorer 6 and Internet Explorer 7. So how does AngularJS know that I changed for example the following and reflected this change on a view?myobject.myproperty=""new value"";","AngularJS remembers the value and compares it to a previous value. This is basic dirty-checking. If there is a change in value, then it fires the change event.The $apply() method, which is what you call when you are transitioning from a non-AngularJS world into an AngularJS world, calls $digest(). A digest is just plain old dirty-checking. It works on all browsers and is totally predictable.To contrast dirty-checking (AngularJS) vs change listeners (KnockoutJS and Backbone.js): While dirty-checking may seem simple, and even inefficient (I will address that later), it turns out that it is semantically correct all the time, while change listeners have lots of weird corner cases and need things like dependency tracking to make it more semantically correct. KnockoutJS dependency tracking is a clever feature for a problem which AngularJS does not have.Issues with change listeners:The syntax is atrocious, since browsers do not support it natively. Yes, there are proxies, but they are not semantically correct in all cases, and of course there are no proxies on old browsers. The bottom line is that dirty-checking allows you to do POJO, whereas KnockoutJS and Backbone.js force you to inherit from their classes, and access your data through accessors.Change coalescence. Suppose you have an array of items. Say you want to add items into an array, as you are looping to add, each time you add you are firing events on change, which is rendering the UI. This is very bad for performance. What you want is to update the UI only once, at the end. The change events are too fine-grained.Change listeners fire immediately on a setter, which is a problem, since the change listener can further change data, which fires more change events. This is bad since on your stack you may have several change events happening at once. Suppose you have two arrays which need to be kept in sync for whatever reason. You can only add to one or the other, but each time you add you fire a change event, which now has an inconsistent view of the world. This is a very similar problem to thread locking, which JavaScript avoids since each callback executes exclusively and to completion. Change events break this since setters can have far-reaching consequences which are not intended and non obvious, which creates the thread problem all over again. It turns out that what you want to do is to delay the listener execution, and guarantee, that only one listener runs at a time, hence any code is free to change data, and it knows that no other code runs while it is doing so.What about performance?So it may seem that we are slow, since dirty-checking is inefficient. This is where we need to look at real numbers rather than just have theoretical arguments, but first let's define some constraints.Humans are:Slow — Anything faster than 50 ms is imperceptible to humans and thus can be considered as ""instant"".Limited — You can't really show more than about 2000 pieces of information to a human on a single page. Anything more than that is really bad UI, and humans can't process this anyway.So the real question is this: How many comparisons can you do on a browser in 50 ms? This is a hard question to answer as many factors come into play, but here is a test case: http://jsperf.com/angularjs-digest/6 which creates 10,000 watchers. On a modern browser this takes just under 6 ms. On Internet Explorer 8 it takes about 40 ms. As you can see, this is not an issue even on slow browsers these days. There is a caveat: The comparisons need to be simple to fit into the time limit... Unfortunately it is way too easy to add a slow comparison into AngularJS, so it is easy to build slow applications when you don't know what you are doing. But we hope to have an answer by providing an instrumentation module, which would show you which are the slow comparisons.It turns out that video games and GPUs use the dirty-checking approach, specifically because it is consistent. As long as they get over the monitor refresh rate (typically 50-60 Hz, or every 16.6-20 ms), any performance over that is a waste, so you're better off drawing more stuff, than getting FPS higher."
"data_i","edited Nov 16 '18 at 00:14","
        How to read a file line-by-line into a list?
    ","How do I read every line of a file in Python and store each line as an element in a list? I want to read the file line by line and append each line to the end of the list.","This code will read the entire file into memory and remove all whitespace characters (newlines and spaces) from the end of each line:with open(filename) as file:    lines = file.readlines()    lines = [line.rstrip() for line in lines]If you're working with a large file, then you should instead read and process it line-by-line:with open(filename) as file:    for line in file:        print(line.rstrip())In Python 3.8 and up you can use a while loop with the walrus operator like so:with open(filename) as file:    while (line := file.readline().rstrip()):        print(line)Depending on what you plan to do with your file and how it was encoded, you may also want to manually set the access mode and character encoding:with open(filename, 'r', encoding='UTF-8') as file:    while (line := file.readline().rstrip()):        print(line)"
"data_i","edited Aug 19 '18 at 18:08","
        How to replace master branch in Git, entirely, from another branch?
    ","I have two branches in my Git repository:masterseotweaks (created originally from master)I created seotweaks with the intention of quickly merging it back into master. However, that was three months ago and the code in this branch is 13 versions ahead of master.It has effectively become our working master branch as all the code in master is more or less obsolete now.Very bad practice I know, lesson learned.Do you know how I can replace all of the contents of the master branch with those in seotweaks?I could just delete everything in master and merge, but this does not feel like best practice.","You should be able to use the ""ours"" merge strategy to overwrite master with seotweaks like this:git checkout seotweaksgit merge -s ours mastergit checkout mastergit merge seotweaksThe result should be your master is now essentially seotweaks.  (-s ours is short for --strategy=ours)From the docs about the 'ours' strategy:This resolves any number of heads, but the resulting tree of the merge is always that of the current branch head, effectively ignoring all changes from all other branches. It is meant to be used to supersede old development history of side branches. Note that this is different from the -Xours option to the recursive merge strategy.Update from comments: If you get fatal: refusing to merge unrelated histories, then change the second line to this: git merge --allow-unrelated-histories -s ours master"
"data_i","edited Sep 01 '18 at 19:04","
        How do I iterate over a range of numbers defined by variables in Bash?
    ","How do I iterate over a range of numbers in Bash when the range is given by a variable?I know I can do this (called ""sequence expression"" in the Bash documentation): for i in {1..5}; do echo $i; doneWhich gives:1   2   3   4   5Yet, how can I replace either of the range endpoints with a variable? This doesn't work:END=5for i in {1..$END}; do echo $i; doneWhich prints:{1..5}","for i in $(seq 1 $END); do echo $i; doneedit: I prefer seq over the other methods because I can actually remember it ;)"
"data_i","edited Sep 06 '11 at 10:49","
        Preview an image before it is uploaded
    ","I want to be able to preview a file (image) before it is uploaded.  The preview action should be executed all in the browser without using Ajax to upload the image.How can I do this?","imgInp.onchange = evt => {  const [file] = imgInp.files  if (file) {    blah.src = URL.createObjectURL(file)  }}<form runat=""server"">  <input accept=""image/*"" type='file' id=""imgInp"" />  <img id=""blah"" src=""#"" alt=""your image"" /></form>"
"data_i","edited Jul 04 '20 at 04:05","
        Why is using ""for...in"" for array iteration a bad idea?
    ","I've been told not to use for...in with arrays in JavaScript. Why not?","The reason is that one construct:var a = []; // Create a new empty array.a[5] = 5;   // Perfectly legal JavaScript that resizes the array.for (var i = 0; i < a.length; i++) {    // Iterate over numeric indexes from 0 to 5, as everyone expects.    console.log(a[i]);}/* Will display:   undefined   undefined   undefined   undefined   undefined   5*/can sometimes be totally different from the other:var a = [];a[5] = 5;for (var x in a) {    // Shows only the explicitly set index of ""5"", and ignores 0-4    console.log(x);}/* Will display:   5*/Also consider that JavaScript libraries might do things like this, which will affect any array you create:// Somewhere deep in your JavaScript library...Array.prototype.foo = 1;// Now you have no idea what the below code will do.var a = [1, 2, 3, 4, 5];for (var x in a){    // Now foo is a part of EVERY array and     // will show up here as a value of 'x'.    console.log(x);}/* Will display:   0   1   2   3   4   foo*/"
"data_i","edited Apr 01 '22 at 02:51","
        Why is it string.join(list) instead of list.join(string)?
    ","This has always confused me. It seems like this would be nicer:[""Hello"", ""world""].join(""-"")Than this:""-"".join([""Hello"", ""world""])Is there a specific reason it is like this?","It's because any iterable can be joined (e.g, list, tuple, dict, set), but its contents and the ""joiner"" must be strings.For example:'_'.join(['welcome', 'to', 'stack', 'overflow'])'_'.join(('welcome', 'to', 'stack', 'overflow'))'welcome_to_stack_overflow'Using something other than strings will raise the following error:TypeError: sequence item 0: expected str instance, int found"
"data_i","edited May 15 '19 at 16:11","
        Disable same origin policy in Chrome
    ","Is there any way to disable the Same-origin policy on Google's Chrome browser?","Close chrome (or chromium) and restart with the --disable-web-security argument. I just tested this and verified that I can access the contents of an iframe with src=""http://google.com"" embedded in a page served from ""localhost"" (tested under chromium 5 / ubuntu). For me the exact command was:Note  :  Kill all chrome instances before running commandchromium-browser --disable-web-security --user-data-dir=""[some directory here]""The browser will warn you that ""you are using an unsupported command line"" when it first opens, which you can ignore.From the chromium source:// Don't enforce the same-origin policy. (Used by people testing their sites.)const wchar_t kDisableWebSecurity[] = L""disable-web-security"";Before Chrome 48, you could just use:chromium-browser --disable-web-security"
"data_i","edited Jan 13 '20 at 10:16","
        Get current URL with jQuery?
    ","I am using jQuery. How do I get the path of the current URL and assign it to a variable?Example URL:http://localhost/menuname.de?foo=bar&amp;number=0","To get the path, you can use:var pathname = window.location.pathname; // Returns path only (/path/example.html)var url      = window.location.href;     // Returns full URL (https://example.com/path/example.html)var origin   = window.location.origin;   // Returns base URL (https://example.com)"
"data_i","edited Jan 07 '19 at 17:41","
        Java inner class and static nested class
    ","What is the main difference between an inner class and a static nested class in Java? Does design / implementation play a role in choosing one of these?","From the Java Tutorial:Nested classes are divided into two categories: static and non-static. Nested classes that are declared static are simply called static nested classes. Non-static nested classes are called inner classes. Static nested classes are accessed using the enclosing class name:OuterClass.StaticNestedClassFor example, to create an object for the static nested class, use this syntax:OuterClass.StaticNestedClass nestedObject = new OuterClass.StaticNestedClass();Objects that are instances of an inner class exist within an instance of the outer class. Consider the following classes:class OuterClass {    ...    class InnerClass {        ...    }}An instance of InnerClass can exist only within an instance of OuterClass and has direct access to the methods and fields of its enclosing instance.To instantiate an inner class, you must first instantiate the outer class. Then, create the inner object within the outer object with this syntax:OuterClass outerObject = new OuterClass()OuterClass.InnerClass innerObject = outerObject.new InnerClass();see: Java Tutorial - Nested ClassesFor completeness note that there is also such a thing as an inner class without an enclosing instance:class A {  int t() { return 1; }  static A a =  new A() { int t() { return 2; } };}Here, new A() { ... } is an inner class defined in a static context and does not have an enclosing instance."
"data_i","edited Jun 06 '22 at 05:13","
        Delete an element from a dictionary
    ","How do I delete an item from a dictionary in Python?Without modifying the original dictionary, how do I obtain another dict with the item removed?","The del statement removes an element:del d[key]Note that this mutates the existing dictionary, so the contents of the dictionary changes for anybody else who has a reference to the same instance. To return a new dictionary, make a copy of the dictionary:def removekey(d, key):    r = dict(d)    del r[key]    return rThe dict() constructor makes a shallow copy. To make a deep copy, see the copy module.Note that making a copy for every dict del/assignment/etc. means you're going from constant time to linear time, and also using linear space. For small dicts, this is not a problem. But if you're planning to make lots of copies of large dicts, you probably want a different data structure, like a HAMT (as described in this answer)."
"data_i","edited Nov 18 '21 at 20:24","
        How do I recursively grep all directories and subdirectories?
    ","How do I recursively grep all directories and subdirectories?find . | xargs grep ""texthere"" *","grep -r ""texthere"" .The first parameter represents the regular expression to search for, while the second one represents the directory that should be searched. In this case, . means the current directory.Note: This works for GNU grep, and on some platforms like Solaris you must specifically use GNU grep as opposed to legacy implementation.  For Solaris this is the ggrep command.   "
"data_i","edited Apr 10 '22 at 12:59","
        How do I check if a variable is an array in JavaScript?
    ","How do I check if a variable is an array in JavaScript?if (variable.constructor == Array)","There are several ways of checking if an variable is an array or not. The best solution is the one you have chosen.variable.constructor === ArrayThis is the fastest method on Chrome, and most likely all other browsers. All arrays are objects, so checking the constructor property is a fast process for JavaScript engines.If you are having issues with finding out if an objects property is an array, you must first check if the property is there.variable.prop && variable.prop.constructor === ArraySome other ways are:Array.isArray(variable)Update May 23, 2019 using Chrome 75, shout out to @AnduAndrici for having me revisit this with his questionThis last one is, in my opinion the ugliest, and it is one of the slowest fastest. Running about 1/5 the speed as the first example. This guy is about 2-5% slower, but it's pretty hard to tell. Solid to use! Quite impressed by the outcome. Array.prototype, is actually an array. you can read more about it here https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/isArrayvariable instanceof ArrayThis method runs about 1/3 the speed as the first example. Still pretty solid, looks cleaner, if you're all about pretty code and not so much on performance. Note that checking for numbers does not work as variable instanceof Number always returns false. Update: instanceof now goes 2/3 the speed!So yet another updateObject.prototype.toString.call(variable) === '[object Array]';This guy is the slowest for trying to check for an Array. However, this is a one stop shop for any type you're looking for. However, since you're looking for an array, just use the fastest method above.Also, I ran some test: http://jsperf.com/instanceof-array-vs-array-isarray/35 So have some fun and check it out.Note: @EscapeNetscape has created another test as jsperf.com is down. http://jsben.ch/#/QgYAV I wanted to make sure the original link stay for whenever jsperf comes back online."
"data_i","edited Mar 15 '18 at 08:35","
        What is the effect of extern ""C"" in C++?
    ","What exactly does putting extern ""C"" into C++ code do?For example:extern ""C"" {   void foo();}","extern ""C"" makes a function-name in C++ have C linkage (compiler does not mangle the name) so that client C code can link to (use) your function using a C compatible header file that contains just the declaration of your function. Your function definition is contained in a binary format (that was compiled by your C++ compiler) that the client C linker will then link to using the C name.Since C++ has overloading of function names and C does not, the C++ compiler cannot just use the function name as a unique id to link to, so it mangles the name by adding information about the arguments.  A C compiler does not need to mangle the name since you can not overload function names in C.  When you state that a function has extern ""C"" linkage in C++, the C++ compiler does not add argument/parameter type information to the name used for linkage.Just so you know, you can specify extern ""C"" linkage to each individual declaration/definition explicitly or use a block to group a sequence of declarations/definitions to have a certain linkage:extern ""C"" void foo(int);extern ""C""{   void g(char);   int i;}If you care about the technicalities, they are listed in section 7.5 of the C++03 standard, here is a brief summary (with emphasis on extern ""C""):extern ""C"" is a linkage-specificationEvery compiler is required to provide ""C"" linkageA linkage specification shall occur only in namespace scopeAll function types, function names and variable names have a language linkage  See Richard's Comment: Only function names and variable names with external linkage have a language linkageTwo function types with distinct language linkages are distinct types even if otherwise identicalLinkage specs nest, inner one determines the final linkageextern ""C"" is ignored for class membersAt most one function with a particular name can have ""C"" linkage (regardless of namespace)extern ""C"" forces a function to have external linkage (cannot make it static)   See Richard's comment:  static inside extern ""C"" is valid; an entity so declared has internal linkage, and so does not have a language linkageLinkage from C++ to objects defined in other languages and to objects defined in C++ from other languages is implementation-defined and language-dependent. Only where the object layout strategies of two language implementations are similar enough can such linkage be achieved"
"data_i","edited May 08 '19 at 09:01","
        Does Java support default parameter values?
    ","I came across some Java code that had the following structure:public MyParameterizedFunction(String param1, int param2){    this(param1, param2, false);}public MyParameterizedFunction(String param1, int param2, boolean param3){    //use all three parameters here}I know that in C++ I can assign a parameter a default value.  For example:void MyParameterizedFunction(String param1, int param2, bool param3=false);Does Java support this kind of syntax?  Are there any reasons why this two step syntax is preferable?","No, the structure you found is how Java handles it (that is, with overloading instead of default parameters).For constructors, See Effective Java: Programming Language Guide's Item 1 tip (Consider static factory methods instead of constructors) if the overloading is getting complicated. For other methods, renaming some cases or using a parameter object can help. This is when you have enough complexity that differentiating is difficult. A definite case is where you have to differentiate using the order of parameters, not just number and type."
"data_i","edited Dec 06 '21 at 06:35","
        How do I break out of nested loops in Java?
    ","I've got a nested loop construct like this:for (Type type : types) {    for (Type t : types2) {         if (some condition) {             // Do something and break...             break; // Breaks out of the inner loop         }    }}Now how can I break out of both loops? I've looked at similar questions, but none concerns Java specifically. I couldn't apply these solutions because most used gotos.I don't want to put the inner loop in a different method.I don't want to return the loops. When breaking I'm finished with the execution of the loop block.","Like other answerers, I'd definitely prefer to put the loops in a different method, at which point you can just return to stop iterating completely. This answer just shows how the requirements in the question can be met.You can use break with a label for the outer loop. For example:public class Test {    public static void main(String[] args) {        outerloop:        for (int i=0; i < 5; i++) {            for (int j=0; j < 5; j++) {                if (i * j > 6) {                    System.out.println(""Breaking"");                    break outerloop;                }                System.out.println(i + "" "" + j);            }        }        System.out.println(""Done"");    }}This prints:0 00 10 20 30 41 01 11 21 31 42 02 12 22 3BreakingDone"
"data_i","edited Nov 19 '16 at 13:42","
        How to stop tracking and ignore changes to a file in Git?
    ","I have cloned a project that includes some .csproj files. I don't need/like my local csproj files being tracked by Git (or being brought up when creating a patch), but clearly they are needed in the project.I have added *.csproj to my LOCAL .gitignore, but the files are already in the repo.When I type git status, it shows my changes to csproj which I am not interested in keeping track of or submitting for patches.How do I remove the ""tracking of"" these files from my personal repo (but keep them in the source so I can use them) so that I don't see the changes when I do a status (or create a patch)?Is there a correct/canonical way to handle this situation?","Just calling git rm --cached on each of the files you want to remove from revision control should be fine. As long as your local ignore patterns are correct you won't see these files included in the output of git status.Note that this solution removes the files from the repository, so all developers would need to maintain their own local (non-revision controlled) copies of the fileTo prevent git from detecting changes in these files you should also use this command:git update-index --assume-unchanged [path]What you probably want to do: (from below @Ryan Taylor answer)This is to tell git you want your own independent version of the file or folder. For instance, you don't want to overwrite (or delete)  production/staging config files.git update-index --skip-worktree <path-name>The full answer is here in this URL: http://source.kohlerville.com/2009/02/untrack-files-in-git/"
"data_i","edited Mar 25 '22 at 05:36","
        How can I update NodeJS and NPM to their latest versions?
    ","I just installed Node.js & NPM (Node Package Manager)I installed NPM for access to additional Node.js Modules.After I installed Node.js & NPM I noticed that neither were the latest versions available.I would like to know: How do I upgrade Node.js, NPM, and my Node.js Modules to their latest versions?Do I need to uninstall Node.js & NPM and reinstall the latest versions?Here is the link to what I have tried so far. This link is a section from npm.","Use:npm update -g npmSee the docs for the update command:npm update [-g] [<pkg>...]This command will update all the packages listed to the latest version (specified by the tag config), respecting semver.Additionally, see the documentation on Node.js and NPM installation and Upgrading NPM.The following original answer is from the old FAQ that no longer exists, but should work for Linux and Mac:How do I update npm?npm install -g npmPlease note that this command will remove your current version of npm. Make sure to use sudo npm install -g npm if on a Mac.You can also update all outdated local packages by doing npm update without any arguments, or global packages by doing npm update -g.Occasionally, the version of npm will progress such that the current version cannot be properly installed with the version that you have installed already. (Consider, if there is ever a bug in the update command.) In those cases, you can do this:curl https://www.npmjs.com/install.sh | shTo update Node.js itself, I recommend you use nvm, the Node Version Manager."
"data_i","edited Jul 02 '21 at 18:10","
        How to compare files from two different branches
    ","I have a script that works fine in one branch and is broken in another. I want to look at the two versions side-by-side and see what's different. Is there a way to do this?To be clear I'm not looking for a compare tool (I use Beyond Compare). I'm looking for a Git diff command that will allow me to compare the master version to my current branch version to see what has changed. I'm not in the middle of a merge or anything. I just want to say something likegit diff mybranch/myfile.cs master/myfile.cs","git diff can show you the difference between two commits:git diff mybranch master -- myfile.csOr, equivalently:git diff mybranch..master -- myfile.csNote you must specify the relative path to the file. So if the file were in the src directory, you'd say src/myfile.cs instead of myfile.cs.Using the latter syntax, if either side is HEAD it may be omitted (e.g., master.. compares master to HEAD).You may also be interested in mybranch...master (from git diff documentation):This form is to view the changes on the branch containing and up to the second <commit>, starting at a common ancestor of both <commit>. git diff A...B is equivalent to git diff $(git-merge-base A B) B.In other words, this will give a diff of changes in master since it diverged from mybranch (but without new changes since then in mybranch).In all cases, the -- separator before the file name indicates the end of command line flags. This is optional unless Git will get confused if the argument refers to a commit or a file, but including it is not a bad habit to get into. See Dietrich Epp's answer to Meaning of Git checkout double dashes for a few examples.The same arguments can be passed to git difftool if you have one configured."
"data_i","edited May 12 '19 at 09:30","
        What is move semantics?
    ","I just finished listening to the Software Engineering radio podcast interview with Scott Meyers regarding C++0x. Most of the new features made sense to me, and I am actually excited about C++0x now, with the exception of one. I still don't get move semantics... What is it exactly?","I find it easiest to understand move semantics with example code. Let's start with a very simple string class which only holds a pointer to a heap-allocated block of memory:#include <cstring>#include <algorithm>class string{    char* data;public:    string(const char* p)    {        size_t size = std::strlen(p) + 1;        data = new char[size];        std::memcpy(data, p, size);    }Since we chose to manage the memory ourselves, we need to follow the rule of three. I am going to defer writing the assignment operator and only implement the destructor and the copy constructor for now:    ~string()    {        delete[] data;    }    string(const string& that)    {        size_t size = std::strlen(that.data) + 1;        data = new char[size];        std::memcpy(data, that.data, size);    }The copy constructor defines what it means to copy string objects. The parameter const string& that binds to all expressions of type string which allows you to make copies in the following examples:string a(x);                                    // Line 1string b(x + y);                                // Line 2string c(some_function_returning_a_string());   // Line 3Now comes the key insight into move semantics. Note that only in the first line where we copy x is this deep copy really necessary, because we might want to inspect x later and would be very surprised if x had changed somehow. Did you notice how I just said x three times (four times if you include this sentence) and meant the exact same object every time? We call expressions such as x ""lvalues"".The arguments in lines 2 and 3 are not lvalues, but rvalues, because the underlying string objects have no names, so the client has no way to inspect them again at a later point in time.rvalues denote temporary objects which are destroyed at the next semicolon (to be more precise: at the end of the full-expression that lexically contains the rvalue). This is important because during the initialization of b and c, we could do whatever we wanted with the source string, and the client couldn't tell a difference!C++0x introduces a new mechanism called ""rvalue reference"" which, among other things,allows us to detect rvalue arguments via function overloading. All we have to do is write a constructor with an rvalue reference parameter. Inside that constructor we can do anything we want with the source, as long as we leave it in some valid state:    string(string&& that)   // string&& is an rvalue reference to a string    {        data = that.data;        that.data = nullptr;    }What have we done here? Instead of deeply copying the heap data, we have just copied the pointer and then set the original pointer to null (to prevent 'delete[]' from source object's destructor from releasing our 'just stolen data'). In effect, we have ""stolen"" the data that originally belonged to the source string. Again, the key insight is that under no circumstance could the client detect that the source had been modified. Since we don't really do a copy here, we call this constructor a ""move constructor"". Its job is to move resources from one object to another instead of copying them.Congratulations, you now understand the basics of move semantics! Let's continue by implementing the assignment operator. If you're unfamiliar with the copy and swap idiom, learn it and come back, because it's an awesome C++ idiom related to exception safety.    string& operator=(string that)    {        std::swap(data, that.data);        return *this;    }};Huh, that's it? ""Where's the rvalue reference?"" you might ask. ""We don't need it here!"" is my answer :)Note that we pass the parameter that by value, so that has to be initialized just like any other string object. Exactly how is that going to be initialized? In the olden days of C++98, the answer would have been ""by the copy constructor"". In C++0x, the compiler chooses between the copy constructor and the move constructor based on whether the argument to the assignment operator is an lvalue or an rvalue.So if you say a = b, the copy constructor will initialize that (because the expression b is an lvalue), and the assignment operator swaps the contents with a freshly created, deep copy. That is the very definition of the copy and swap idiom -- make a copy, swap the contents with the copy, and then get rid of the copy by leaving the scope. Nothing new here.But if you say a = x + y, the move constructor will initialize that (because the expression x + y is an rvalue), so there is no deep copy involved, only an efficient move.that is still an independent object from the argument, but its construction was trivial,since the heap data didn't have to be copied, just moved. It wasn't necessary to copy it because x + y is an rvalue, and again, it is okay to move from string objects denoted by rvalues.To summarize, the copy constructor makes a deep copy, because the source must remain untouched.The move constructor, on the other hand, can just copy the pointer and then set the pointer in the source to null. It is okay to ""nullify"" the source object in this manner, because the client has no way of inspecting the object again.I hope this example got the main point across. There is a lot more to rvalue references and move semantics which I intentionally left out to keep it simple. If you want more details please see my supplementary answer."
"data_i","edited Apr 10 '18 at 06:26","
        Easiest way to convert int to string in C++
    ","What is the easiest way to convert from int to equivalent string in C++.  I am aware of two methods. Is there any easier way?(1)int a = 10;char *intStr = itoa(a);string str = string(intStr);(2)int a = 10;stringstream ss;ss << a;string str = ss.str();","C++11 introduces std::stoi (and variants for each numeric type) and std::to_string, the counterparts of the C atoi and itoa but expressed in term of std::string.#include <string> std::string s = std::to_string(42);is therefore the shortest way I can think of. You can even omit naming the type, using the auto keyword:auto s = std::to_string(42);Note: see [string.conversions] (21.5 in n3242)"
"data_i","edited Sep 14 '21 at 11:01","
        Interfaces vs Types in TypeScript
    ","What is the difference between these statements (interface vs type) in TypeScript?interface X {    a: number    b: string}type X = {    a: number    b: string};","2019 UpdateThe current answers and the official documentation are outdated. And for those new to TypeScript, the terminology used isn't clear without examples. Below is a list of up-to-date differences.1. Objects / FunctionsBoth can be used to describe the shape of an object or a function signature. But the syntax differs.Interfaceinterface Point {  x: number;  y: number;}interface SetPoint {  (x: number, y: number): void;}Type aliastype Point = {  x: number;  y: number;};type SetPoint = (x: number, y: number) => void;2. Other TypesUnlike an interface, the type alias can also be used for other types such as primitives, unions, and tuples.// primitivetype Name = string;// objecttype PartialPointX = { x: number; };type PartialPointY = { y: number; };// uniontype PartialPoint = PartialPointX | PartialPointY;// tupletype Data = [number, string];3. ExtendBoth can be extended, but again, the syntax differs. Additionally, note that an interface and type alias are not mutually exclusive. An interface can extend a type alias, and vice versa.Interface extends interfaceinterface PartialPointX { x: number; }interface Point extends PartialPointX { y: number; }Type alias extends type aliastype PartialPointX = { x: number; };type Point = PartialPointX & { y: number; };Interface extends type aliastype PartialPointX = { x: number; };interface Point extends PartialPointX { y: number; }Type alias extends interfaceinterface PartialPointX { x: number; }type Point = PartialPointX & { y: number; };4. ImplementsA class can implement an interface or type alias, both in the same exact way. Note however that a class and interface are considered static blueprints. Therefore, they can not implement / extend a type alias that names a union type.interface Point {  x: number;  y: number;}class SomePoint implements Point {  x = 1;  y = 2;}type Point2 = {  x: number;  y: number;};class SomePoint2 implements Point2 {  x = 1;  y = 2;}type PartialPoint = { x: number; } | { y: number; };// FIXME: can not implement a union typeclass SomePartialPoint implements PartialPoint {  x = 1;  y = 2;}5. Declaration mergingUnlike a type alias, an interface can be defined multiple times, and will be treated as a single interface (with members of all declarations being merged).// These two declarations become:// interface Point { x: number; y: number; }interface Point { x: number; }interface Point { y: number; }const point: Point = { x: 1, y: 2 };"
"data_i","edited May 19 '21 at 09:41","
        Find object by id in an array of JavaScript objects
    ","I've got an array:myArray = [{'id':'73','foo':'bar'},{'id':'45','foo':'bar'}, etc.]I'm unable to change the structure of the array. I'm being passed an id of 45, and I want to get 'bar' for that object in the array. How do I do this in JavaScript or using jQuery?","Use the find() method:myArray.find(x => x.id === '45').foo;From MDN:The find() method returns the first value in the array, if an element in the array satisfies the provided testing function. Otherwise undefined is returned.If you want to find its index instead, use findIndex():myArray.findIndex(x => x.id === '45');From MDN:The findIndex() method returns the index of the first element in the array that satisfies the provided testing function. Otherwise -1 is returned.If you want to get an array of matching elements, use the filter() method instead:myArray.filter(x => x.id === '45');This will return an array of objects. If you want to get an array of foo properties, you can do this with the map() method:myArray.filter(x => x.id === '45').map(x => x.foo);Side note: methods like find() or filter(), and arrow functions are not supported by older browsers (like IE), so if you want to support these browsers, you should transpile your code using Babel (with the polyfill)."
"data_i","edited Sep 25 '20 at 22:52","
        Check if a value is an object in JavaScript
    ","How do you check if a value is an object in JavaScript?","If typeof yourVariable === 'object', it's an object or null.If you want null, arrays or functions to be excluded, just make it:if (    typeof yourVariable === 'object' &&    !Array.isArray(yourVariable) &&    yourVariable !== null) {    executeSomeCode();}"
"data_i","edited Jun 06 '22 at 04:14","
        Delete a column from a Pandas DataFrame
    ","To delete a column in a DataFrame, I can successfully use:del df['column_name']But why can't I use the following?del df.column_nameSince it is possible to access the column/Series as df.column_name, I expected this to work.","The best way to do this in Pandas is to use drop:df = df.drop('column_name', axis=1)where 1 is the axis number (0 for rows and 1 for columns.)To delete the column without having to reassign df you can do:df.drop('column_name', axis=1, inplace=True)Finally, to drop by column number instead of by column label, try this to delete, e.g. the 1st, 2nd and 4th columns:df = df.drop(df.columns[[0, 1, 3]], axis=1)  # df.columns is zero-based pd.IndexAlso working with ""text"" syntax for the columns:df.drop(['column_nameA', 'column_nameB'], axis=1, inplace=True)Note: Introduced in v0.21.0 (October 27, 2017), the drop() method accepts index/columns keywords as an alternative to specifying the axis.So we can now just do:df = df.drop(columns=['column_nameA', 'column_nameB'])"
"data_i","edited Mar 13 '20 at 11:03","
        How to copy Docker images from one host to another without using a repository
    ","How do I transfer a Docker image from one machine to another one without using a repository, no matter private or public?I create my own image in VirtualBox, and when it is finished I try to deploy to other machines to have real usage.Since it is based on my own based image (like Red Hat Linux), it cannot be recreated from a Dockerfile. My dockerfile isn't easily portable.Are there simple commands I can use? Or another solution?","You will need to save the Docker image as a tar file:docker save -o <path for generated tar file> <image name>Then copy your image to a new system with regular file transfer tools such as cp, scp or rsync(preferred for big files). After that you will have to load the image into Docker:docker load -i <path to image tar file>PS: You may need to sudo all commands.EDIT: You should add filename (not just directory) with -o, for example:docker save -o c:/myfile.tar centos:16"
"data_i","edited Apr 06 '19 at 01:35","
        How do I format XML in Notepad++?
    ","I have Notepad++ and I got some XML code which is very long. When I pasted it in Notepad++ there was a long line of code (difficult to read and work with).I want to know if there is a simple way to make the text readable (by readable I mean properly tabbed code).I can do it manually, but I want a permanent solution to this as I have faced this several times. I am sure there is a way to do this as I have done it once before a couple of years back, maybe with Visual Studio or some other editor, I don't remember.But can Notepad++ do it?","Try Plugins -> XML Tools -> Pretty Print (libXML) or (XML only - with line breaks Ctrl + Alt + Shift + B)You may need to install XML Tools using your plugin manager in order to get this option in your menu.In my experience, libXML gives nice output but only if the file is 100% correctly formed."
"data_i","edited Feb 21 '20 at 18:38","
        Config Error: This configuration section cannot be used at this path
    ","I've encountered an error deploying a site to a server.  When trying to load the home page, or access authentication on the new site in IIS, I get the error:Config Error: This configuration section cannot be used at this path.  This happens when the section is locked at a parent level. Locking is  either by default (overrideModeDefault=""Deny""), or set explicitly by a  location tag with overrideMode=""Deny"" or the legacy  allowOverride=""false"".More detail can be found here, in Scenario 7 matches my hex error code.The solution given on the linked site above is to set Allow for overrideModeDefault in the section mentioned in my error, in the applicationHost.config file.  In my case,  under Security in system.webServer.  But if I look at the applicationHost.config on my local computer, where the site is properly deployed already, that section is set to Deny.If this solution is correct, how is my local instance running just fine with the same web.config?  According to my applicationHost.config, that section should be locked, but it's not.  I'd prefer to not change the applicationHost.config file, because there are many other sites running on that server.  Is there another solution?","I had the same problem. Don't remember where I found it on the web, but here is what I did:Click ""Start button""in the search box, enter ""Turn windows features on or off""in the features window, Click: ""Internet Information Services""Click: ""World Wide Web Services""Click: ""Application Development Features""Check (enable) the features. I checked all but CGI.btw, I'm using Windows 7. Many comments over the years have certified this works all the way up to Windows 10 and Server 2019, as well."
"data_i","edited Jul 03 '16 at 23:27","
        How do CSS triangles work?
    ","There're plenty of different CSS shapes over at CSS Tricks - Shapes of CSS and I'm particularly puzzled with a triangle:#triangle-up {  width: 0;  height: 0;  border-left: 50px solid transparent;  border-right: 50px solid transparent;  border-bottom: 100px solid red;}<div id=""triangle-up""></div>How and why does it work?","CSS Triangles: A Tragedy in Five ActsAs alex said, borders of equal width butt up against each other at 45 degree angles:When you have no top border, it looks like this:Then you give it a width of 0......and a height of 0......and finally, you make the two side borders transparent:That results in a triangle."
"data_i","edited Aug 23 '16 at 15:39","
        LEFT JOIN vs. LEFT OUTER JOIN in SQL Server
    ","What is the difference between LEFT JOIN and LEFT OUTER JOIN?","As per the documentation: FROM (Transact-SQL):<join_type> ::=     [ { INNER | { { LEFT | RIGHT | FULL } [ OUTER ] } } [ <join_hint> ] ]    JOINThe keyword OUTER is marked as optional (enclosed in square brackets). In this specific case, whether you specify OUTER or not makes no difference.  Note that while the other elements of the join clause is also marked as optional, leaving them out will make a difference.For instance, the entire type-part of the JOIN clause is optional, in which case the default is INNER if you just specify JOIN. In other words, this is legal:SELECT *FROM A JOIN B ON A.X = B.YHere's a list of equivalent syntaxes:A LEFT JOIN B            A LEFT OUTER JOIN BA RIGHT JOIN B           A RIGHT OUTER JOIN BA FULL JOIN B            A FULL OUTER JOIN BA INNER JOIN B           A JOIN BAlso take a look at the answer I left on this other SO question: SQL left join vs multiple tables on FROM line?."
"data_i","edited Dec 29 '15 at 08:21","
        ""Debug certificate expired"" error in Eclipse Android plugins
    ","I am using Eclipse Android plugins to build a project, but I amgetting this error in the console window:[2010-02-03 10:31:14 - androidVNC]Error generating final archive:Debug certificate expired on 1/30/10 2:35 PM!How do I fix it?","Delete your debug certificate under ~/.android/debug.keystore on Linux and Mac OS X; the directory is something like %USERPROFILE%/.androidon Windows.The Eclipse plugin should then generate a new certificate when you next try to build a debug package. You may need to clean and then build to generate the certificate."
"data_i","edited Nov 15 '15 at 15:02","
        Difference between static class and singleton pattern?
    ","What real (i.e. practical) difference exists between a static class and a singleton pattern?Both can be invoked without instantiation, both provide only one ""Instance"" and neither of them is thread-safe. Is there any other difference?","What makes you say that either a singleton or a static method isn't thread-safe? Usually both should be implemented to be thread-safe.The big difference between a singleton and a bunch of static methods is that singletons can implement interfaces (or derive from useful base classes, although that's less common, in my experience), so you can pass around the singleton as if it were ""just another"" implementation."
"data_i","edited Mar 08 '22 at 09:36","
        Writing to files in Node.js
    ","I've been trying to find a way to write to a file when using Node.js, but with no success. How can I do that?","There are a lot of details in the File System API. The most common way is:const fs = require('fs');fs.writeFile(""/tmp/test"", ""Hey there!"", function(err) {    if(err) {        return console.log(err);    }    console.log(""The file was saved!"");}); // Orfs.writeFileSync('/tmp/test-sync', 'Hey there!');"
"data_i","edited Oct 11 '16 at 02:32","
        What is tail recursion?
    ","Whilst starting to learn lisp, I've come across the term tail-recursive. What does it mean exactly?","Consider a simple function that adds the first N natural numbers. (e.g. sum(5) = 0 + 1 + 2 + 3 + 4 + 5 = 15).Here is a simple JavaScript implementation that uses recursion:function recsum(x) {    if (x === 0) {        return 0;    } else {        return x + recsum(x - 1);    }}If you called recsum(5), this is what the JavaScript interpreter would evaluate:recsum(5)5 + recsum(4)5 + (4 + recsum(3))5 + (4 + (3 + recsum(2)))5 + (4 + (3 + (2 + recsum(1))))5 + (4 + (3 + (2 + (1 + recsum(0)))))5 + (4 + (3 + (2 + (1 + 0))))5 + (4 + (3 + (2 + 1)))5 + (4 + (3 + 3))5 + (4 + 6)5 + 1015Note how every recursive call has to complete before the JavaScript interpreter begins to actually do the work of calculating the sum.Here's a tail-recursive version of the same function:function tailrecsum(x, running_total = 0) {    if (x === 0) {        return running_total;    } else {        return tailrecsum(x - 1, running_total + x);    }}Here's the sequence of events that would occur if you called tailrecsum(5), (which would effectively be tailrecsum(5, 0), because of the default second argument).tailrecsum(5, 0)tailrecsum(4, 5)tailrecsum(3, 9)tailrecsum(2, 12)tailrecsum(1, 14)tailrecsum(0, 15)15In the tail-recursive case, with each evaluation of the recursive call, the running_total is updated.Note: The original answer used examples from Python. These have been changed to JavaScript, since Python interpreters don't support tail call optimization. However, while tail call optimization is part of the ECMAScript 2015 spec, most JavaScript interpreters don't support it."
"data_i","edited May 15 '14 at 15:15","
        Regular cast vs. static_cast vs. dynamic_cast
    ","I've been writing C and C++ code for almost twenty years, but there's one aspect of these languages that I've never really understood. I've obviously used regular casts i.e.MyClass *m = (MyClass *)ptr;all over the place, but there seem to be two other types of casts, and I don't know the difference. What's the difference between the following lines of code?MyClass *m = (MyClass *)ptr;MyClass *m = static_cast<MyClass *>(ptr);MyClass *m = dynamic_cast<MyClass *>(ptr);","static_caststatic_cast is used for cases where you basically want to reverse an implicit conversion, with a few restrictions and additions. static_cast performs no runtime checks. This should be used if you know that you refer to an object of a specific type, and thus a check would be unnecessary. Example:void func(void *data) {  // Conversion from MyClass* -> void* is implicit  MyClass *c = static_cast<MyClass*>(data);  ...}int main() {  MyClass c;  start_thread(&func, &c)  // func(&c) will be called      .join();}In this example, you know that you passed a MyClass object, and thus there isn't any need for a runtime check to ensure this.dynamic_castdynamic_cast is useful when you don't know what the dynamic type of the object is. It returns a null pointer if the object referred to doesn't contain the type casted to as a base class (when you cast to a reference, a bad_cast exception is thrown in that case).if (JumpStm *j = dynamic_cast<JumpStm*>(&stm)) {  ...} else if (ExprStm *e = dynamic_cast<ExprStm*>(&stm)) {  ...}You can not use dynamic_cast for downcast (casting to a derived class) if the argument type is not polymorphic. For example, the following code is not valid, because Base doesn't contain any virtual function:struct Base { };struct Derived : Base { };int main() {  Derived d; Base *b = &d;  dynamic_cast<Derived*>(b); // Invalid}An ""up-cast"" (cast to the base class) is always valid with both static_cast and dynamic_cast, and also without any cast, as an ""up-cast"" is an implicit conversion (assuming the base class is accessible, i.e. it's a public inheritance).Regular CastThese casts are also called C-style cast. A C-style cast is basically identical to trying out a range of sequences of C++ casts, and taking the first C++ cast that works, without ever considering dynamic_cast. Needless to say, this is much more powerful as it combines all of const_cast, static_cast and reinterpret_cast, but it's also unsafe, because it does not use dynamic_cast.In addition, C-style casts not only allow you to do this, but they also allow you to safely cast to a private base-class, while the ""equivalent"" static_cast sequence would give you a compile-time error for that.Some people prefer C-style casts because of their brevity. I use them for numeric casts only, and use the appropriate C++ casts when user defined types are involved, as they provide stricter checking."
"data_i","edited Oct 08 '17 at 11:33","
        Make the current Git branch a master branch
    ","I have a repository in Git. I made a branch, then did some changes both to the master and to the branch.Then, tens of commits later, I realized the branch is in much better state than the master, so I want the branch to ""become"" the master and disregard the changes on master.I cannot merge it, because I don't want to keep the changes on master. What should I do?Extra: In this case, the 'old' master has already been push-ed to another repository such as GitHub. How does this change things?","The problem with the other two answers is that the new master doesn't have the old master as an ancestor, so when you push it, everyone else will get messed up. This is what you want to do:git checkout better_branchgit merge --strategy=ours master    # keep the content of this branch, but record a mergegit checkout mastergit merge better_branch             # fast-forward master up to the mergeIf you want your history to be a little clearer, I'd recommend adding some information to the merge commit message to make it clear what you've done. Change the second line to:git merge --strategy=ours --no-commit mastergit commit          # add information to the template merge message"
"data_i","edited May 26 '22 at 08:19","
        How to create an array containing 1...N
    ","I'm looking for any alternatives to the below for creating a JavaScript array containing 1 through to N where N is only known at runtime.var foo = [];for (var i = 1; i <= N; i++) {   foo.push(i);}To me it feels like there should be a way of doing this without the loop.","In ES6 using Array from() and keys() methods.Array.from(Array(10).keys())//=> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]Shorter version using spread operator.[...Array(10).keys()]//=> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]Start from 1 by passing map function to Array from(), with an object with a length property:Array.from({length: 10}, (_, i) => i + 1)//=> [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
"data_i","edited Apr 08 '21 at 13:32","
        How to get a Docker container's IP address from the host
    ","Is there a command I can run to get the container's IP address right from the host after a new container is created?Basically, once Docker creates the container, I want to roll my own code deployment and container configuration scripts.","The --format option of inspect comes to the rescue.Modern Docker client syntax is:docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' container_name_or_idOld Docker client syntax is:docker inspect --format '{{ .NetworkSettings.IPAddress }}' container_name_or_idThese commands will return the Docker container's IP address.As mentioned in the comments: if you are on Windows, use double quotes "" instead of single quotes ' around the curly braces."
"data_i","edited May 10 '20 at 11:21","
        How can I display a JavaScript object?
    ","How do I display the content of a JavaScript object in a string format like when we alert a variable?The same formatted way I want to display an object.","Use native JSON.stringify method.Works with nested objects and all major browsers support this method.str = JSON.stringify(obj);str = JSON.stringify(obj, null, 4); // (Optional) beautiful indented output.console.log(str); // Logs output to dev tools console.alert(str); // Displays output using window.alert()Link to Mozilla API Reference and other examples.obj = JSON.parse(str); // Reverses above operation (Just in case if needed.)Use a custom JSON.stringify replacer if youencounter this Javascript error""Uncaught TypeError: Converting circular structure to JSON"""
"data_i","edited Oct 25 '21 at 08:56","
        How do I remedy ""The breakpoint will not currently be hit. No symbols have been loaded for this document."" warning?
    ","A C# desktop application (on the Visual Studio Express/Community edition) worked, but then it didn't work 5 seconds later.I tried the following:Ensure debug configuration, debug flag, and full debug information are set on all assemblies.Delete all bin and obj folders and all DLL files related to the project from my entire machine.Recreate projects causing the problem from scratch.Reboot.I have two Windows Forms projects in the solution. One of them loads the debug information, one doesn't. They both refer to the assembly I'm trying to get debug information on in exactly the same way in the project file. Any ideas?I want to add here, mostly for myself when I come back to review this question, that symbols are not loaded until the assembly is loaded, and the assembly is not loaded until it is needed. If the breakpoint is in a library that is only used in one function in your main assembly, the symbols will not be loaded (and it will show the breakpoint as not being hit) until that function is called.","Start debugging, as soon as you've arrived at a breakpoint or used Debug > Break All, use Debug > Windows > Modules.  You'll see a list of all the assemblies that are loaded into the process.  Locate the one you want to get debug info for.  Right-click it and select Symbol Load Information.  You'll get a dialog that lists all the directories where it looked for the .pdb file for the assembly.  Verify that list against the actual .pdb location.  Make sure it doesn't find an old one.In normal projects, the assembly and its .pdb file should always have been copied by the IDE into the same folder as your .exe, i.e. the bin\Debug folder of your project.  Make sure you remove one from the GAC if you've been playing with it."
"data_i","edited Jul 08 '20 at 00:24","
        Abort Ajax requests using jQuery
    ","Is it possible that using jQuery, I cancel/abort an Ajax request that I have not yet received the response from?","Most of the jQuery Ajax methods return an XMLHttpRequest (or the equivalent) object, so you can just use abort().See the documentation:abort Method (MSDN). Cancels the current HTTP request.abort() (MDN). If the request has been sent already, this method will abort the request.var xhr = $.ajax({    type: ""POST"",    url: ""some.php"",    data: ""name=John&location=Boston"",    success: function(msg){       alert( ""Data Saved: "" + msg );    }});//kill the requestxhr.abort()UPDATE:As of jQuery 1.5 the returned object is a wrapper for the native XMLHttpRequest object called jqXHR. This object appears to expose all of the native properties and methods so the above example still works. See The jqXHR Object (jQuery API documentation).UPDATE 2:As of jQuery 3, the ajax method now returns a promise with extra methods (like abort), so the above code still works, though the object being returned is not an xhr any more. See the 3.0 blog here. UPDATE 3: xhr.abort() still works on jQuery 3.x. Don't assume the update 2 is correct. More info on jQuery Github repository."
"data_i","edited Jun 13 '22 at 00:45","
        How do I pad a string with zeroes?
    ","How do I pad a numeric string with zeroes to the left, so that the string has a specific length?","To pad strings:>>> n = '4'>>> print(n.zfill(3))004To pad numbers:>>> n = 4>>> print(f'{n:03}') # Preferred method, python >= 3.6004>>> print('%03d' % n)004>>> print(format(n, '03')) # python >= 2.6004>>> print('{0:03d}'.format(n))  # python >= 2.6 + python 3004>>> print('{foo:03d}'.format(foo=n))  # python >= 2.6 + python 3004>>> print('{:03d}'.format(n))  # python >= 2.7 + python3004String formatting documentation."
"data_i","edited Sep 15 '21 at 02:17","
        What is the difference between an interface and abstract class?
    ","What exactly is the difference between an interface and an abstract class?","InterfacesAn interface is a contract: The person writing the interface says, ""hey, I accept things looking that way"", and the person using the interface says ""OK, the class I write looks that way"".An interface is an empty shell. There are only the signatures of the methods, which implies that the methods do not have a body. The interface can't do anything. It's just a pattern.For example (pseudo code):// I say all motor vehicles should look like this:interface MotorVehicle{    void run();    int getFuel();}// My team mate complies and writes vehicle looking that wayclass Car implements MotorVehicle{    int fuel;    void run()    {        print(""Wrroooooooom"");    }    int getFuel()    {        return this.fuel;    }}Implementing an interface consumes very little CPU, because it's not a class, just a bunch of names, and therefore there isn't any expensive look-up to do. It's great when it matters, such as in embedded devices.Abstract classesAbstract classes, unlike interfaces, are classes. They are more expensive to use, because there is a look-up to do when you inherit from them.Abstract classes look a lot like interfaces, but they have something more: You can define a behavior for them. It's more about a person saying, ""these classes should look like that, and they have that in common, so fill in the blanks!"".For example:// I say all motor vehicles should look like this:abstract class MotorVehicle{    int fuel;    // They ALL have fuel, so lets implement this for everybody.    int getFuel()    {         return this.fuel;    }    // That can be very different, force them to provide their    // own implementation.    abstract void run();}// My teammate complies and writes vehicle looking that wayclass Car extends MotorVehicle{    void run()    {        print(""Wrroooooooom"");    }}ImplementationWhile abstract classes and interfaces are supposed to be different concepts, the implementations make that statement sometimes untrue. Sometimes, they are not even what you think they are.In Java, this rule is strongly enforced, while in PHP, interfaces are abstract classes with no method declared.In Python, abstract classes are more a programming trick you can get from the ABC module and is actually using metaclasses, and therefore classes. And interfaces are more related to duck typing in this language and it's a mix between conventions and special methods that call descriptors (the __method__ methods).As usual with programming, there is theory, practice, and practice in another language :-)"
"data_i","edited Nov 01 '19 at 13:01","
        How to check if the string is empty?
    ","Does Python have something like an empty string variable where you can do:if myString == string.empty:Regardless, what's the most elegant way to check for empty string values? I find hard coding """" every time for checking an empty string not as good.","Empty strings are ""falsy"" (python 2 or python 3 reference), which means they are considered false in a Boolean context, so you can just do this:if not myString:This is the preferred way if you know that your variable is a string.  If your variable could also be some other type then you should use:if myString == """":See the documentation on Truth Value Testing for other values that are false in Boolean contexts."
"data_i","edited Apr 09 '22 at 07:04","
        How do I remove a trailing newline?
    ","How do I remove the last character of a string if it is a newline?""abc\n""  -->  ""abc""","Try the method rstrip() (see doc Python 2 and Python 3)>>> 'test string\n'.rstrip()'test string'Python's rstrip() method strips all kinds of trailing whitespace by default, not just one newline as Perl does with chomp.>>> 'test string \n \r\n\n\r \n\n'.rstrip()'test string'To strip only newlines:>>> 'test string \n \r\n\n\r \n\n'.rstrip('\n')'test string \n \r\n\n\r 'In addition to rstrip(), there are also the methods strip() and lstrip(). Here is an example with the three of them:>>> s = ""   \n\r\n  \n  abc   def \n\r\n  \n  "">>> s.strip()'abc   def'>>> s.lstrip()'abc   def \n\r\n  \n  '>>> s.rstrip()'   \n\r\n  \n  abc   def'"
"data_i","edited Jul 05 '16 at 19:34","
        Detecting an ""invalid date"" Date instance in JavaScript
    ","I'd like to tell the difference between valid and invalid date objects in JS, but couldn't figure out how:var d = new Date(""foo"");console.log(d.toString()); // shows 'Invalid Date'console.log(typeof d); // shows 'object'console.log(d instanceof Date); // shows 'true'Any ideas for writing an isValidDate function?Ash recommended Date.parse for parsing date strings, which gives an authoritative way to check if the date string is valid.What I would prefer, if possible, is have my API accept a Date instance and to be able to check/assert whether it's valid or not. Borgar's solution does that, but I need to test it across browsers. I also wonder whether there's a more elegant way.Ash made me consider not having my API accept Date instances at all, this would be easiest to validate.Borgar suggested testing for a Date instance, and then testing for the Date's time value. If the date is invalid, the time value is NaN. I checked with ECMA-262 and this behavior is in the standard, which is exactly what I'm looking for.","Here's how I would do it:if (Object.prototype.toString.call(d) === ""[object Date]"") {  // it is a date  if (isNaN(d)) { // d.getTime() or d.valueOf() will also work    // date object is not valid  } else {    // date object is valid  }} else {  // not a date object}Update [2018-05-31]: If you are not concerned with Date objects from other JS contexts (external windows, frames, or iframes), this simpler form may be preferred:function isValidDate(d) {  return d instanceof Date && !isNaN(d);}Update [2021-02-01]: Please note that there is a fundamental difference between ""invalid dates"" (2013-13-32) and ""invalid date objects"" (new Date('foo')). This answer does not deal with validating date input, only if a Date instance is valid."
"data_i","edited Oct 07 '20 at 12:39","
        How do I auto-resize an image to fit a 'div' container?
    ","How do you auto-resize a large image so that it will fit into a smaller width div container whilst maintaining its width:height ratio?Example: stackoverflow.com - when an image is inserted onto the editor panel and the image is too large to fit onto the page, the image is automatically resized.","Do not apply an explicit width or height to the image tag. Instead, give it:max-width:100%;max-height:100%;Also, height: auto; if you want to specify a width only.Example: http://jsfiddle.net/xwrvxser/1/img {    max-width: 100%;    max-height: 100%;}.portrait {    height: 80px;    width: 30px;}.landscape {    height: 30px;    width: 80px;}.square {    height: 75px;    width: 75px;}Portrait Div<div class=""portrait"">    <img src=""http://i.stack.imgur.com/xkF9Q.jpg""></div>Landscape Div<div class=""landscape"">    <img src=""http://i.stack.imgur.com/xkF9Q.jpg""></div>Square Div<div class=""square"">    <img src=""http://i.stack.imgur.com/xkF9Q.jpg""></div>"
"data_i","edited Nov 12 '19 at 08:43","
        How to get screen dimensions as pixels in Android
    ","I created some custom elements, and I want to programmatically place them to the upper right corner (n pixels from the top edge and m pixels from the right edge). Therefore I need to get the screen width and screen height and then set position:int px = screenWidth - m;int py = screenHeight - n;How do I get screenWidth and screenHeight in the main Activity?","If you want the display dimensions in pixels you can use getSize:Display display = getWindowManager().getDefaultDisplay();Point size = new Point();display.getSize(size);int width = size.x;int height = size.y;If you're not in an Activity you can get the default Display via WINDOW_SERVICE:WindowManager wm = (WindowManager) context.getSystemService(Context.WINDOW_SERVICE);Display display = wm.getDefaultDisplay();If you are in a fragment and want to acomplish this just use Activity.WindowManager (in Xamarin.Android) or getActivity().getWindowManager() (in java).Before getSize was introduced (in API level 13), you could use the getWidth and getHeight methods that are now deprecated:Display display = getWindowManager().getDefaultDisplay(); int width = display.getWidth();  // deprecatedint height = display.getHeight();  // deprecatedFor the use case, you're describing, however, a margin/padding in the layout seems more appropriate.Another way is: DisplayMetricsA structure describing general information about a display, such as its size, density, and font scaling. To access the DisplayMetrics members, initialize an object like this:DisplayMetrics metrics = new DisplayMetrics();getWindowManager().getDefaultDisplay().getMetrics(metrics);We can use widthPixels to get information for:""The absolute width of the display in pixels.""Example:Log.d(""ApplicationTagName"", ""Display width in px is "" + metrics.widthPixels);API level 30 updatefinal WindowMetrics metrics = windowManager.getCurrentWindowMetrics(); // Gets all excluding insets final WindowInsets windowInsets = metrics.getWindowInsets(); Insets insets = windowInsets.getInsetsIgnoringVisibility(WindowInsets.Type.navigationBars()         | WindowInsets.Type.displayCutout()); int insetsWidth = insets.right + insets.left; int insetsHeight = insets.top + insets.bottom; // Legacy size that Display#getSize reports final Rect bounds = metrics.getBounds(); final Size legacySize = new Size(bounds.width() - insetsWidth,         bounds.height() - insetsHeight);"
"data_i","edited Jun 13 '22 at 00:23","
        How do I append to a file?
    ","How do I append to a file instead of overwriting it?","Set the mode in open() to ""a"" (append) instead of ""w"" (write):with open(""test.txt"", ""a"") as myfile:    myfile.write(""appended text"")The documentation lists all the available modes."
"data_i","edited Jun 13 '22 at 00:33","
        Static methods in Python?
    ","Can I define a static method which I can call directly on the class instance? e.g.,MyClass.the_static_method()","Yep, using the staticmethod decorator:class MyClass(object):    @staticmethod    def the_static_method(x):        print(x)MyClass.the_static_method(2)  # outputs 2Note that some code might use the old method of defining a static method, using staticmethod as a function rather than a decorator. This should only be used if you have to support ancient versions of Python (2.2 and 2.3):class MyClass(object):    def the_static_method(x):        print(x)    the_static_method = staticmethod(the_static_method)MyClass.the_static_method(2)  # outputs 2This is entirely identical to the first example (using @staticmethod), just not using the nice decorator syntax.Finally, use staticmethod sparingly! There are very few situations where static-methods are necessary in Python, and I've seen them used many times where a separate ""top-level"" function would have been clearer.The following is verbatim from the documentation::A static method does not receive an implicit first argument. To declare a static method, use this idiom:class C:    @staticmethod    def f(arg1, arg2, ...): ...The @staticmethod form is a function decorator – see the description of function definitions in Function definitions for details.It can be called either on the class (such as C.f()) or on an instance (such as C().f()). The instance is ignored except for its class.Static methods in Python are similar to those found in Java or C++. For a more advanced concept, see classmethod().For more information on static methods, consult the documentation on the standard type hierarchy in The standard type hierarchy.New in version 2.2.Changed in version 2.4: Function decorator syntax added."
"data_i","edited Oct 18 '16 at 08:41","
        How to exit from PostgreSQL command line utility: psql
    ","What command or short key can I use to exit the PostgreSQL command line utility psql?","Type \q and then press ENTER to quit psql.UPDATE: 19-OCT-2018As of PostgreSQL 11, the keywords ""quit"" and ""exit"" in the PostgreSQL command-line interface have been included to help make it easier to leave the command-line tool."
"data_i","edited Apr 25 '22 at 04:43","
        Can't bind to 'ngModel' since it isn't a known property of 'input'
    ","I have this simple input in my component which uses [(ngModel)] :<input type=""text"" [(ngModel)]=""test"" placeholder=""foo"" />And I get the following error when I launch my app, even if the component is not displayed.zone.js:461 Unhandled Promise rejection: Template parse errors:Can't bind to 'ngModel' since it isn't a known property of 'input'.Here is the component.ts:import { Component, EventEmitter, Input, OnInit, Output } from '@angular/core';import { Intervention } from '../../model/intervention';@Component({   selector: 'intervention-details',   templateUrl: 'app/intervention/details/intervention.details.html',   styleUrls: ['app/intervention/details/intervention.details.css']})    export class InterventionDetails{   @Input() intervention: Intervention;       public test : string = ""toto"";}","Yes, that's it. In the app.module.ts file, I just added:import { FormsModule } from '@angular/forms';[...]@NgModule({  imports: [    [...]    FormsModule  ],  [...]})"
"data_i","edited Nov 29 '21 at 07:23","
        Click through div to underlying elements
    ","I have a div that has background:transparent, along with border. Underneath this div, I have more elements.Currently,  I'm able to click the underlying elements when I click outside of the overlay div. However, I'm unable to click the underlying elements when clicking directly on the overlay div. I want to be able to click through this div so that I can click on the underlying elements.","Yes, you CAN do this. Using pointer-events: none along with CSS conditional statements for IE11 (does not work in IE10 or below), you can get a cross browser compatible solution for this problem.Using AlphaImageLoader, you can even put transparent .PNG/.GIFs in the overlay div and have clicks flow through to elements underneath.CSS:pointer-events: none;background: url('your_transparent.png');IE11 conditional:filter:progid:DXImageTransform.Microsoft.AlphaImageLoader(src='your_transparent.png', sizingMethod='scale');background: none !important;Here is a basic example page with all the code."
"data_i","edited Jan 11 '18 at 10:49","
        Undo working copy modifications of one file in Git?
    ","After the last commit, I modified a bunch of files in my working copy, but I want to undo the changes to one of those files, as in reset it to the same state as the most recent commit.However, I only want to undo the working copy changes of just that one file alone, nothing else with it.How do I do that?","You can usegit checkout -- fileYou can do it without the -- (as suggested by nimrodm), but if the filename looks like a branch or tag (or other revision identifier), it may get confused, so using -- is best.You can also check out a particular version of a file:git checkout v1.2.3 -- file         # tag v1.2.3git checkout stable -- file         # stable branchgit checkout origin/master -- file  # upstream mastergit checkout HEAD -- file           # the version from the most recent commitgit checkout HEAD^ -- file          # the version before the most recent commit"
"data_i","edited Oct 27 '18 at 10:01","
        How does Git handle symbolic links?
    ","If I have a file or directory that is a symbolic link and I commit it to a Git repository, what happens to it?I would assume that it leaves it as a symbolic link until the file is deleted and then if you pull the file back from an old version it just creates a normal file.What does it do when I delete the file it references? Does it just commit the dangling link?","From linux symlink manual (assuming you are in Linux):A symbolic link is a special type of file whose contents are a string that is the pathname of another file, the file to which the link refers.  (The contents of a symbolic link can be read using readlink(2).)So a symbolic link is one more file, just as a README.md or a Makefile. Git just stores the contents of the link (i.e. the aforementioned path of the file system object that it links to) in a 'blob' just like it would for any other file. It then stores the name, mode and type (including the fact that it is a symlink) in the tree object that represents its containing directory.When you checkout a tree containing the link, it restores the object as a symlink regardless of whether the target file system object exists or not.If you delete the file that the symlink references it doesn't affect the Git-controlled symlink in any way. You will have a dangling reference. It is up to the user to either remove or change the link to point to something valid if needed."
"data_i","edited Apr 20 '20 at 02:29","
        What is the difference between a process and a thread?
    ","What is the technical difference between a process and a thread?I get the feeling a word like 'process' is overused and there are also hardware and software threads. How about light-weight processes in languages like Erlang? Is there a definitive reason to use one term over the other?","Both processes and threads are independent sequences of execution. The typical difference is that threads (of the same process) run in a shared memory space, while processes run in separate memory spaces.I'm not sure what ""hardware"" vs ""software"" threads you might be referring to. Threads are an operating environment feature, rather than a CPU feature (though the CPU typically has operations that make threads efficient).Erlang uses the term ""process"" because it does not expose a shared-memory multiprogramming model. Calling them ""threads"" would imply that they have shared memory."
"data_i","edited Nov 12 '20 at 15:36","
        How to generate a random alpha-numeric string
    ","I've been looking for a simple Java algorithm to generate a pseudo-random alpha-numeric string.  In my situation it would be used as a unique session/key identifier that would ""likely"" be unique over 500K+ generation (my needs don't really require anything much more sophisticated).  Ideally, I would be able to specify a length depending on my uniqueness needs. For example, a generated string of length 12 might look something like ""AEYGF7K0DM1X"".  ","AlgorithmTo generate a random string, concatenate characters drawn randomly from the set of acceptable symbols until the string reaches the desired length.ImplementationHere's some fairly simple and very flexible code for generating random identifiers. Read the information that follows for important application notes.public class RandomString {    /**     * Generate a random string.     */    public String nextString() {        for (int idx = 0; idx < buf.length; ++idx)            buf[idx] = symbols[random.nextInt(symbols.length)];        return new String(buf);    }    public static final String upper = ""ABCDEFGHIJKLMNOPQRSTUVWXYZ"";    public static final String lower = upper.toLowerCase(Locale.ROOT);    public static final String digits = ""0123456789"";    public static final String alphanum = upper + lower + digits;    private final Random random;    private final char[] symbols;    private final char[] buf;    public RandomString(int length, Random random, String symbols) {        if (length < 1) throw new IllegalArgumentException();        if (symbols.length() < 2) throw new IllegalArgumentException();        this.random = Objects.requireNonNull(random);        this.symbols = symbols.toCharArray();        this.buf = new char[length];    }    /**     * Create an alphanumeric string generator.     */    public RandomString(int length, Random random) {        this(length, random, alphanum);    }    /**     * Create an alphanumeric strings from a secure generator.     */    public RandomString(int length) {        this(length, new SecureRandom());    }    /**     * Create session identifiers.     */    public RandomString() {        this(21);    }}Usage examplesCreate an insecure generator for 8-character identifiers:RandomString gen = new RandomString(8, ThreadLocalRandom.current());Create a secure generator for session identifiers:RandomString session = new RandomString();Create a generator with easy-to-read codes for printing. The strings are longer than full alphanumeric strings to compensate for using fewer symbols:String easy = RandomString.digits + ""ACEFGHJKLMNPQRUVWXYabcdefhijkprstuvwx"";RandomString tickets = new RandomString(23, new SecureRandom(), easy);Use as session identifiersGenerating session identifiers that are likely to be unique is not good enough, or you could just use a simple counter. Attackers hijack sessions when predictable identifiers are used.There is tension between length and security. Shorter identifiers are easier to guess, because there are fewer possibilities. But longer identifiers consume more storage and bandwidth. A larger set of symbols helps, but might cause encoding problems if identifiers are included in URLs or re-entered by hand.The underlying source of randomness, or entropy, for session identifiers should come from a random number generator designed for cryptography. However, initializing these generators can sometimes be computationally expensive or slow, so effort should be made to re-use them when possible.Use as object identifiersNot every application requires security. Random assignment can be an efficient way for multiple entities to generate identifiers in a shared space without any coordination or partitioning. Coordination can be slow, especially in a clustered or distributed environment, and splitting up a space causes problems when entities end up with shares that are too small or too big.Identifiers generated without taking measures to make them unpredictable should be protected by other means if an attacker might be able to view and manipulate them, as happens in most web applications. There should be a separate authorization system that protects objects whose identifier can be guessed by an attacker without access permission.Care must be also be taken to use identifiers that are long enough to make collisions unlikely given the anticipated total number of identifiers. This is referred to as ""the birthday paradox."" The probability of a collision, p, is approximately n2/(2qx), where n is the number of identifiers actually generated, q is the number of distinct symbols in the alphabet, and x is the length of the identifiers. This should be a very small number, like 2‑50 or less.Working this out shows that the chance of collision among 500k 15-character identifiers is about 2‑52, which is probably less likely than undetected errors from cosmic rays, etc.Comparison with UUIDsAccording to their specification, UUIDs are not designed to be unpredictable, and should not be used as session identifiers.UUIDs in their standard format take a lot of space: 36 characters for only 122 bits of entropy. (Not all bits of a ""random"" UUID are selected randomly.) A randomly chosen alphanumeric string packs more entropy in just 21 characters.UUIDs are not flexible; they have a standardized structure and layout. This is their chief virtue as well as their main weakness. When collaborating with an outside party, the standardization offered by UUIDs may be helpful. For purely internal use, they can be inefficient."
"data_i","edited Jan 16 '20 at 08:18","
        How do I get PHP errors to display?
    ","I have checked my PHP ini file (php.ini) and display_errors is set and also error reporting is E_ALL. I have restarted my Apache webserver.I have even put these lines at the top of my script, and it doesn't even catch simple parse errors. For example, I declare variables with a ""$"" and I don't close statements"";"". But all my scripts show a blank page on these errors, but I want to actually see the errors in my browser output. error_reporting(E_ALL);ini_set('display_errors', 1);What is left to do?","This always works for me:ini_set('display_errors', '1');ini_set('display_startup_errors', '1');error_reporting(E_ALL);However, this doesn't make PHP to show parse errors - the only way to show those errors is to modify your php.ini with this line:display_errors = on(if you don't have access to php.ini, then putting this line in .htaccess might work too):php_flag display_errors 1"
"data_i","edited Jun 02 '18 at 15:14","
        What's the difference between the atomic and nonatomic attributes?
    ","What do atomic and nonatomic mean in property declarations?@property(nonatomic, retain) UITextField *userName;@property(atomic, retain) UITextField *userName;@property(retain) UITextField *userName;What is the operational difference between these three?","The last two are identical; ""atomic"" is the default behavior (note that it is not actually a keyword; it is specified only by the absence of nonatomic -- atomic was added as a keyword in recent versions of llvm/clang).Assuming that you are @synthesizing the method implementations, atomic vs. non-atomic changes the generated code.  If you are writing your own setter/getters, atomic/nonatomic/retain/assign/copy are merely advisory.  (Note:  @synthesize is now the default behavior in recent versions of LLVM.  There is also no need to declare instance variables;  they will be synthesized automatically, too, and will have an _ prepended to their name to prevent accidental direct access).With ""atomic"", the synthesized setter/getter will ensure that a whole value is always returned from the getter or set by the setter, regardless of setter activity on any other thread.   That is, if thread A is in the middle of the getter while thread B calls the setter, an actual viable value -- an autoreleased object, most likely -- will be returned to the caller in A.In nonatomic, no such guarantees are made.   Thus, nonatomic is considerably faster than ""atomic"".What ""atomic"" does not do is make any guarantees about thread safety.  If thread A is calling the getter simultaneously with thread B and C calling the setter with different values, thread A may get any one of the three values returned -- the one prior to any setters being called or either of the values passed into the setters in B and C.  Likewise, the object may end up with the value from B or C, no way to tell.Ensuring data integrity -- one of the primary challenges of multi-threaded programming -- is achieved by other means.Adding to this:atomicity of a single property also cannot guarantee thread safety when multiple dependent properties are in play.Consider: @property(atomic, copy) NSString *firstName; @property(atomic, copy) NSString *lastName; @property(readonly, atomic, copy) NSString *fullName;In this case, thread A could be renaming the object by calling setFirstName: and then calling setLastName:.   In the meantime, thread B may call fullName in between thread A's two calls and will receive the new first name coupled with the old last name.To address this, you need a transactional model.   I.e. some other kind of synchronization and/or exclusion that allows one to exclude access to fullName while the dependent properties are being updated."
"data_i","edited Dec 28 '18 at 17:01","
        How can I remove a commit on GitHub?
    ","I ""accidentally"" pushed a commit to GitHub.Is it possible to remove this commit?I want to revert my GitHub repository as it was before this commit.","Note: please see an alternative to git rebase -i in the comments below—git reset --soft HEAD^First, remove the commit on your local repository. You can do this using git rebase -i. For example, if it's your last commit, you can do git rebase -i HEAD~2 and delete the second line within the editor window that pops up.Then, force push to GitHub by using git push origin +branchName --forceSee Git Magic Chapter 5: Lessons of History - And Then Some for more information (i.e. if you want to remove older commits).Oh, and if your working tree is dirty, you have to do a git stash first, and then a git stash apply after."
"data_i","edited Aug 01 '16 at 08:25","
        Detach (move) subdirectory into separate Git repository
    ","I have a Git repository which contains a number of subdirectories. Now I have found that one of the subdirectories is unrelated to the other and should be detached to a separate repository.How can I do this while keeping the history of the files within the subdirectory?I guess I could make a clone and remove the unwanted parts of each clone, but I suppose this would give me the complete tree when checking out an older revision etc. This might be acceptable, but I would prefer to be able to pretend that the two repositories doesn't have a shared history.Just to make it clear, I have the following structure:XYZ/    .git/    XY1/    ABC/    XY2/But I would like this instead:XYZ/    .git/    XY1/    XY2/ABC/    .git/    ABC/","The Easy Way™It turns out that this is such a common and useful practice that the overlords of Git made it really easy, but you have to have a newer version of Git (>= 1.7.11 May 2012). See the appendix for how to install the latest Git. Also, there's a real-world example in the walkthrough below.Prepare the old repo cd <big-repo> git subtree split -P <name-of-folder> -b <name-of-new-branch>Note: <name-of-folder> must NOT contain leading or trailing characters.  For instance, the folder named subproject MUST be passed as subproject, NOT ./subproject/Note for Windows users: When your folder depth is > 1, <name-of-folder> must have *nix style folder separator (/). For instance, the folder named path1\path2\subproject MUST be passed as path1/path2/subprojectCreate the new repo mkdir ~/<new-repo> && cd ~/<new-repo> git init git pull </path/to/big-repo> <name-of-new-branch>Link the new repo to GitHub or wherever git remote add origin <git@github.com:user/new-repo.git> git push -u origin masterCleanup inside <big-repo>, if desired git rm -rf <name-of-folder>Note: This leaves all the historical references in the repository. See the Appendix below if you're actually concerned about having committed a password or you need to decreasing the file size of your .git folder.WalkthroughThese are the same steps as above, but following my exact steps for my repository instead of using <meta-named-things>.Here's a project I have for implementing JavaScript browser modules in node:tree ~/node-browser-compatnode-browser-compat├── ArrayBuffer├── Audio├── Blob├── FormData├── atob├── btoa├── location└── navigatorI want to split out a single folder, btoa, into a separate Git repositorycd ~/node-browser-compat/git subtree split -P btoa -b btoa-onlyI now have a new branch, btoa-only, that only has commits for btoa and I want to create a new repository.mkdir ~/btoa/ && cd ~/btoa/git initgit pull ~/node-browser-compat btoa-onlyNext, I create a new repo on GitHub or Bitbucket, or whatever and add it as the origingit remote add origin git@github.com:node-browser-compat/btoa.gitgit push -u origin masterHappy day!Note: If you created a repo with a README.md, .gitignore and LICENSE, you will need to pull first:git pull origin mastergit push origin masterLastly, I'll want to remove the folder from the bigger repogit rm -rf btoaAppendixLatest Git on macOSTo get the latest version of Git using Homebrew:brew install gitLatest Git on Ubuntusudo apt-get updatesudo apt-get install gitgit --versionIf that doesn't work (you have a very old version of Ubuntu), trysudo add-apt-repository ppa:git-core/ppasudo apt-get updatesudo apt-get install gitIf that still doesn't work, trysudo chmod +x /usr/share/doc/git/contrib/subtree/git-subtree.shsudo ln -s \/usr/share/doc/git/contrib/subtree/git-subtree.sh \/usr/lib/git-core/git-subtreeThanks to rui.araujo from the comments.Clearing your historyBy default removing files from Git doesn't actually remove them, it just commits that they aren't there anymore. If you want to actually remove the historical references (i.e. you committed a password), you need to do this:git filter-branch --prune-empty --tree-filter 'rm -rf <name-of-folder>' HEADAfter that, you can check that your file or folder no longer shows up in the Git history at allgit log -- <name-of-folder> # should show nothingHowever, you can't ""push"" deletes to GitHub and the like. If you try, you'll get an error and you'll have to git pull before you can git push - and then you're back to having everything in your history.So if you want to delete history from the ""origin"" - meaning to delete it from GitHub, Bitbucket, etc - you'll need to delete the repo and re-push a pruned copy of the repo. But wait - there's more! - if you're really concerned about getting rid of a password or something like that you'll need to prune the backup (see below).Making .git smallerThe aforementioned delete history command still leaves behind a bunch of backup files - because Git is all too kind in helping you to not ruin your repo by accident. It will eventually delete orphaned files over the days and months, but it leaves them there for a while in case you realize that you accidentally deleted something you didn't want to.So if you really want to empty the trash to reduce the clone size of a repo immediately you have to do all of this really weird stuff:rm -rf .git/refs/original/ && \git reflog expire --all && \git gc --aggressive --prune=nowgit reflog expire --all --expire-unreachable=0git repack -A -dgit pruneThat said, I'd recommend not performing these steps unless you know that you need to - just in case you did prune the wrong subdirectory, y'know? The backup files shouldn't get cloned when you push the repo, they'll just be in your local copy.Credithttp://psionides.eu/2010/02/04/sharing-code-between-projects-with-git-subtree/Remove a directory permanently from githttp://blogs.atlassian.com/2013/05/alternatives-to-git-submodule-git-subtree/How to remove unreferenced blobs from my git repo"
"data_i","edited Feb 16 '21 at 15:24","
        How do I fix a Git detached head?
    ","I was doing some work in my repository and noticed a file had local changes. I didn't want them anymore so I deleted the file, thinking I can just checkout a fresh copy. I wanted to do the Git equivalent ofsvn up .Using git pull didn't seem to work. Some random searching led me to a site where someone recommended doinggit checkout HEAD^ src/(src is the directory containing the deleted file).Now I find out I have a detached head. I have no idea what that is. How can I undo?","Detached head means you are no longer on a branch, you have checked out a single commit in the history (in this case the commit previous to HEAD, i.e. HEAD^).If you want to delete your changes associated with the detached HEADYou only need to checkout the branch you were on, e.g.git checkout masterNext time you have changed a file and want to restore it to the state it is in the index, don't delete the file first, just dogit checkout -- path/to/fooThis will restore the file foo to the state it is in the index.If you want to keep your changes associated with the detached HEADRun git branch tmp - this will save your changes in a new branch called tmp.Run git checkout masterIf you would like to incorporate the changes you made into master, run git merge tmp from the master branch. You should be on the master branch after running git checkout master."
"data_i","asked Jan 28 '11 at 00:18","
        Comments in Markdown
    ","How do you write a comment in Markdown, i.e. text that is not rendered in the HTML output? I found nothing on the Markdown project.","I believe that all the previously proposed solutions (apart from those that require specific implementations) result in the comments being included in the output HTML, even if they are not displayed.If you want a comment that is strictly for yourself (readers of the converted document should not be able to see it, even with ""view source"") you could (ab)use the link labels (for use with reference style links) that are available in the core Markdown specification:http://daringfireball.net/projects/markdown/syntax#linkThat is:[comment]: <> (This is a comment, it will not be included)[comment]: <> (in  the output file unless you use it in)[comment]: <> (a reference style link.)Or you could go further:[//]: <> (This is also a comment.)To improve platform compatibility (and to save one keystroke) it is also possible to use # (which is a legitimate hyperlink target) instead of <>:[//]: # (This may be the most platform independent comment)For maximum portability it is important to insert a blank line before and after this type of comments, because some Markdown parsers do not work correctly when definitions brush up against regular text. The most recent research with Babelmark shows that blank lines before and after are both important. Some parsers will output the comment if there is no blank line before, and some parsers will exclude the following line if there is no blank line after.In general, this approach should work with most Markdown parsers, since it's part of the core specification. (even if the behavior when multiple links are defined, or when a link is defined but never used, is not strictly specified)."
"data_i","edited Oct 17 '19 at 13:25","
        Inserting multiple rows in a single SQL query?
    ","I have multiple set of data to insert at once, say 4 rows. My table has three columns: Person, Id and Office.INSERT INTO MyTable VALUES (""John"", 123, ""Lloyds Office"");INSERT INTO MyTable VALUES (""Jane"", 124, ""Lloyds Office"");INSERT INTO MyTable VALUES (""Billy"", 125, ""London Office"");INSERT INTO MyTable VALUES (""Miranda"", 126, ""Bristol Office"");Can I insert all 4 rows in a single SQL statement?","In SQL Server 2008 you can insert multiple rows using a single SQL INSERT statement.INSERT INTO MyTable ( Column1, Column2 ) VALUES( Value1, Value2 ), ( Value1, Value2 )For reference to this have a look at MOC Course 2778A - Writing SQL Queries in SQL Server 2008.For example:INSERT INTO MyTable  ( Column1, Column2, Column3 )VALUES  ('John', 123, 'Lloyds Office'),   ('Jane', 124, 'Lloyds Office'),   ('Billy', 125, 'London Office'),  ('Miranda', 126, 'Bristol Office');"
"data_i","edited Apr 02 '14 at 12:50","
        How to do case insensitive search in Vim
    ","I'd like to search for an upper case word, for example COPYRIGHT in a file. I tried performing a search like:/copyright/i    # Doesn't workbut it doesn't work.  I know that in Perl, if I give the i flag into a regex it will turn the regex into a case-insensitive regex. It seems that Vim  has its own way to indicate a case-insensitive regex.","You can use the \c escape sequence anywhere in the pattern. For example:/\ccopyright or /copyright\c or even /copyri\cghtTo do the inverse (case sensitive matching), use \C (capital C) instead."
"data_i","edited Apr 07 '21 at 23:39","
        How can I count all the lines of code in a directory recursively?
    ","We've got a PHP application and want to count all the lines of code under a specific directory and its subdirectories.We don't need to ignore comments, as we're just trying to get a rough idea.wc -l *.php That command works great for a given directory, but it ignores subdirectories. I was thinking the following comment might work, but it is returning 74, which is definitely not the case...find . -name '*.php' | wc -lWhat's the correct syntax to feed in all the files from a directory resursively?","Try:find . -name '*.php' | xargs wc -lor (when file names include special characters such as spaces)find . -name '*.php' | sed 's/.*/""&""/' | xargs  wc -lThe SLOCCount tool may help as well.It will give an accurate source lines of code count for whateverhierarchy you point it at, as well as some additional stats.Sorted output:find . -name '*.php' | xargs wc -l | sort -nr"
"data_i","edited Apr 03 '14 at 11:10","
        What do two question marks together mean in C#?
    ","Ran across this line of code:FormsAuth = formsAuth ?? new FormsAuthenticationWrapper();What do the two question marks mean, is it some kind of ternary operator?It's hard to look up in Google.","It's the null coalescing operator, and quite like the ternary (immediate-if) operator. See also ?? Operator - MSDN.FormsAuth = formsAuth ?? new FormsAuthenticationWrapper();expands to:FormsAuth = formsAuth != null ? formsAuth : new FormsAuthenticationWrapper();which further expands to:if(formsAuth != null)    FormsAuth = formsAuth;else    FormsAuth = new FormsAuthenticationWrapper();In English, it means ""If whatever is to the left is not null, use that, otherwise use what's to the right.""Note that you can use any number of these in sequence. The following statement will assign the first non-null Answer# to Answer (if all Answers are null then the Answer is null):string Answer = Answer1 ?? Answer2 ?? Answer3 ?? Answer4;Also it's worth mentioning while the expansion above is conceptually equivalent, the result of each expression is only evaluated once. This is important if for example an expression is a method call with side effects. (Credit to @Joey for pointing this out.)"
"data_i","edited Aug 16 '22 at 15:49","
        How to detect a mobile device using jQuery
    ","Is there a way to detect whether or not a user is using a mobile device in jQuery? Something similar to the CSS @media attribute? I would like to run a different script if the browser is on a handheld device.The jQuery $.browser function is not what I am looking for.","Editor's note: user agent detection is not a recommended technique for modern web apps. See the comments below this answer for confirmation of this fact. It is suggested to use one of the other answers using feature detection and/or media queries.Instead of using jQuery you can use simple JavaScript to detect it:if( /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent) ) { // some code..}Or you can combine them both to make it more accessible through jQuery...$.browser.device = (/android|webos|iphone|ipad|ipod|blackberry|iemobile|opera mini/i.test(navigator.userAgent.toLowerCase()));Now $.browser will return ""device"" for all above devicesNote: $.browser removed on jQuery v1.9.1. But you can use this by using jQuery migration plugin CodeA more thorough version:var isMobile = false; //initiate as false// device detectionif(/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|ipad|iris|kindle|Android|Silk|lge |maemo|midp|mmp|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows (ce|phone)|xda|xiino/i.test(navigator.userAgent)     || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(navigator.userAgent.substr(0,4))) {     isMobile = true;}"
"data_i","edited Jan 07 '22 at 09:22","
        How can I delete all of my Git stashes at once?
    ","How can I delete all of my Git stashes at once?Specifically I mean, with typing in one command.","The following command deletes all your stashes:git stash clearFrom the git documentation:clearRemove all the stashed states.IMPORTANT WARNING: Those states will then be subject to pruning, and may be impossible to recover (...)."
"data_i","edited Sep 17 '19 at 13:47","
        What's the difference between a proxy server and a reverse proxy server?
    ","What is the difference between a proxy server and a reverse proxy server?","The previous answers were accurate, but perhaps too terse.I will try to add some examples.First of all, the word ""proxy"" describes someone or something acting on behalf of someone else.In the computer realm, we are talking about one server acting on the behalf of another computer.For the purposes of accessibility, I will limit my discussion to web proxies - however, the idea of a proxy is not limited to websites.FORWARD proxyMost discussion of web proxies refers to the type of proxy known as a ""forward proxy.""The proxy event, in this case, is that the ""forward proxy"" retrieves data from another web site on behalf of the original requestee.A tale of 3 computers (part I)For an example, I will list three computers connected to the internet.X = your computer, or ""client"" computer on the internetY = the proxy web site, proxy.example.orgZ = the web site you want to visit, www.example.netNormally, one would connect directly from X --> Z.However, in some scenarios, it is better for Y --> Z on behalf of X,which chains as follows: X --> Y --> Z.Reasons why X would want to use a forward proxy server:Here is a (very) partial list of uses of a forward proxy server:1) X is unable to access Z directlybecausea) Someone with administrative authority over X's internet connection has decided to block all access to site Z.Examples:The Storm Worm virus is spreading by tricking people into visiting familypostcards2008.com, so the system administrator has blocked access to the site to prevent users from inadvertently infecting themselves.Employees at a large company have been wasting too much time on facebook.com, so management wants access blocked during business hours.A local elementary school disallows internet access to the playboy.com website.A government is unable to control the publishing of news, so it controls access to news instead, by blocking sites such as wikipedia.org. See TOR or FreeNet.b) The administrator of Z has blocked X.Examples:The administrator of Z has noticed hacking attempts coming from X, so the administrator has decided to block X's IP address (and/or netrange).Z is a forum website.  X is spamming the forum. Z blocks X.REVERSE proxyA tale of 3 computers (part II)For this example, I will list three computers connected to the internet.X = your computer, or ""client"" computer on the internetY = the reverse proxy web site, proxy.example.comZ = the web site you want to visit, www.example.netNormally, one would connect directly from X --> Z.However, in some scenarios, it is better for the administrator of Z to restrict or disallow direct access and force visitors to go through Y first.So, as before, we have data being retrieved by Y --> Z on behalf of X, which chains as follows: X --> Y --> Z.What is different this time compared to a ""forward proxy,"" is that this time the user X does not know he is accessing Z, because the user X only sees he is communicating with Y.The server Z is invisible to clients and only the reverse proxy Y is visible externally. A reverse proxy requires no (proxy) configuration on the client side.The client X thinks he is only communicating with Y (X --> Y), but the reality is that Y forwarding all communication (X --> Y --> Z again).Reasons why Z would want to set up a reverse proxy server:1) Z wants to force all traffic to its web site to pass through Y first.a) Z has a large web site that millions of people want to see, but a single web server cannot handle all the traffic. So Z sets up many servers and puts a reverse proxy on the internet that will send users to the server closest to them when they try to visit Z. This is part of how the Content Distribution Network (CDN) concept works.Examples:Apple Trailers uses AkamaiJquery.com hosts its JavaScript files using CloudFront CDN (sample).etc.2) The administrator of Z is worried about retaliation for content hosted on the server and does not want to expose the main server directly to the public.a) Owners of Spam brands such as ""Canadian Pharmacy"" appear to have thousands of servers, while in reality having most websites hosted on far fewer servers. Additionally, abuse complaints about the spam will only shut down the public servers, not the main server.In the above scenarios, Z has the ability to choose Y.Links to topics from the post:Content Delivery NetworkLists of CDNshttp://www.mytestbox.com/miscellaneous/content-delivery-networks-cdn-list/http://blog.streamingmedia.com/the_business_of_online_vi/2008/01/updated-list-of.htmlForward proxy software (server side)PHP-Proxycgi-proxyphproxy  (discontinued)glypeInternet censorship wiki: List of Web Proxiessquid  (apparently, can also work as a reverse proxy)Reverse proxy software for HTTP (server side)Apache mod_proxy (can also work as a forward proxy for HTTP)nginx  (used on hulu.com, spam sites, etc.)HAProxyCaddy Webserverlighthttpdperlbal (written for livejournal)portfusionpoundvarnish cache (written by a FreeBSD kernel guru)reposeReverse proxy software for TCP (server side)balancedelegatepenportfusionpure load balancer (web site defunct)python directorSee also:Wikipedia - Content Delivery NetworkWikipedia - Category:Reverse_proxyWikipedia - Load BalancingWikipedia - Scalability"
"data_i","edited Jul 10 '22 at 23:00","
        How do I exclude a directory when using `find`?
    ","How do I exclude a specific directory when searching for *.js files using find?find . -name '*.js'","If -prune doesn't work for you, this will:find -name ""*.js"" -not -path ""./directory/*""Caveat: requires traversing all of the unwanted directories."
"data_i","edited Jul 25 '15 at 13:42","
        What is the 'new' keyword in JavaScript?
    ","The new keyword in JavaScript can be quite confusing when it is first encountered, as people tend to think that JavaScript is not an object-oriented programming language.What is it?What problems does it solve?When is it appropriate and when not?","It does 5 things:It creates a new object.  The type of this object is simply object.It sets this new object's internal, inaccessible, [[prototype]] (i.e. __proto__) property to be the constructor function's external, accessible, prototype object (every function object automatically has a prototype property).It makes the this variable point to the newly created object.It executes the constructor function, using the newly created object whenever this is mentioned.It returns the newly created object, unless the constructor function returns a non-null object reference. In this case, that object reference is returned instead.Note: constructor function refers to the function after the new keyword, as in new ConstructorFunction(arg1, arg2)Once this is done, if an undefined property of the new object is requested, the script will check the object's [[prototype]] object for the property instead. This is how you can get something similar to traditional class inheritance in JavaScript. The most difficult part about this is point number 2.  Every object (including functions) has this internal property called [[prototype]]. It can only be set at object creation time, either with new, with Object.create, or based on the literal (functions default to Function.prototype, numbers to Number.prototype, etc.). It can only be read with Object.getPrototypeOf(someObject). There is no other way to set or read this value.Functions, in addition to the hidden [[prototype]] property, also have a property called prototype, and it is this that you can access, and modify, to provide inherited properties and methods for the objects you make.Here is an example:ObjMaker = function() {this.a = 'first';};// ObjMaker is just a function, there's nothing special about it that makes // it a constructor.ObjMaker.prototype.b = 'second';// like all functions, ObjMaker has an accessible prototype property that // we can alter. I just added a property called 'b' to it. Like // all objects, ObjMaker also has an inaccessible [[prototype]] property// that we can't do anything withobj1 = new ObjMaker();// 3 things just happened.// A new, empty object was created called obj1.  At first obj1 was the same// as {}. The [[prototype]] property of obj1 was then set to the current// object value of the ObjMaker.prototype (if ObjMaker.prototype is later// assigned a new object value, obj1's [[prototype]] will not change, but you// can alter the properties of ObjMaker.prototype to add to both the// prototype and [[prototype]]). The ObjMaker function was executed, with// obj1 in place of this... so obj1.a was set to 'first'.obj1.a;// returns 'first'obj1.b;// obj1 doesn't have a property called 'b', so JavaScript checks // its [[prototype]]. Its [[prototype]] is the same as ObjMaker.prototype// ObjMaker.prototype has a property called 'b' with value 'second'// returns 'second'It's like class inheritance because now, any objects you make using new ObjMaker() will also appear to have inherited the 'b' property.If you want something like a subclass, then you do this:SubObjMaker = function () {};SubObjMaker.prototype = new ObjMaker(); // note: this pattern is deprecated!// Because we used 'new', the [[prototype]] property of SubObjMaker.prototype// is now set to the object value of ObjMaker.prototype.// The modern way to do this is with Object.create(), which was added in ECMAScript 5:// SubObjMaker.prototype = Object.create(ObjMaker.prototype);SubObjMaker.prototype.c = 'third';  obj2 = new SubObjMaker();// [[prototype]] property of obj2 is now set to SubObjMaker.prototype// Remember that the [[prototype]] property of SubObjMaker.prototype// is ObjMaker.prototype. So now obj2 has a prototype chain!// obj2 ---> SubObjMaker.prototype ---> ObjMaker.prototypeobj2.c;// returns 'third', from SubObjMaker.prototypeobj2.b;// returns 'second', from ObjMaker.prototypeobj2.a;// returns 'first', from SubObjMaker.prototype, because SubObjMaker.prototype // was created with the ObjMaker function, which assigned a for usI read a ton of rubbish on this subject before finally finding this page, where this is explained very well with nice diagrams."
"data_i","edited Mar 22 '17 at 16:23","
        Prefer composition over inheritance?
    ","Why prefer composition over inheritance?  What trade-offs are there for each approach?  When should you choose inheritance over composition?","Prefer composition over inheritance as it is more malleable / easy to modify later, but do not use a compose-always approach. With composition, it's easy to change behavior on the fly with Dependency Injection / Setters. Inheritance is more rigid as most languages do not allow you to derive from more than one type. So the goose is more or less cooked once you derive from TypeA.My acid test for the above is:  Does TypeB want to expose the complete interface (all public methods no less) of TypeA such that TypeB can be used where TypeA is expected? Indicates Inheritance. e.g. A Cessna biplane will expose the complete interface of an airplane, if not more. So that makes it fit to derive from Airplane. Does TypeB want only some/part of the behavior exposed by TypeA? Indicates need for Composition. e.g. A Bird may need only the fly behavior of an Airplane. In this case, it makes sense to extract it out as an interface / class / both and make it a member of both classes.Update: Just came back to my answer and it seems now that it is incomplete without a specific mention of Barbara Liskov's Liskov Substitution Principle as a test for 'Should I be inheriting from this type?'"
"data_i","edited Jul 25 '14 at 21:23","
        How do I commit case-sensitive only filename changes in Git?
    ","I have changed a few files name by  de-capitalize the first letter, as in Name.jpg to name.jpg. Git does not recognize this changes and I had to delete the files and upload them again. Is there a way that Git can be case-sensitive when checking for changes in file names? I have not made any changes to the file itself. ","As long as you're just renaming a file, and not a folder, you can just use git mv:git mv -f yOuRfIlEnAmE yourfilename(As of a change in Git 2.0.1, the -f flag in the incantation above is superfluous, but it was needed in older Git versions.)"
"data_i","edited May 29 '20 at 19:47","
        Looping through the content of a file in Bash
    ","How do I iterate through each line of a text file with Bash?With this script:echo ""Start!""for p in (peptides.txt)do    echo ""${p}""doneI get this output on the screen:Start!./runPep.sh: line 3: syntax error near unexpected token `('./runPep.sh: line 3: `for p in (peptides.txt)'(Later I want to do something more complicated with $p than just output to the screen.)The environment variable SHELL is (from env):SHELL=/bin/bash/bin/bash --version output:GNU bash, version 3.1.17(1)-release (x86_64-suse-linux-gnu)Copyright (C) 2005 Free Software Foundation, Inc.cat /proc/version output:Linux version 2.6.18.2-34-default (geeko@buildhost) (gcc version 4.1.2 20061115 (prerelease) (SUSE Linux)) #1 SMP Mon Nov 27 11:46:27 UTC 2006The file peptides.txt contains:RKEKNVQIPKKLLQKQYFHQLEKMNVKIPKKLLQKGDLSTALEVAIDCYEKQYFHQLEKMNVKIPENIYRRKEKNVQVLAKHGKLQDAINILGFMKLEDVALQILL","One way to do it is:while read p; do  echo ""$p""done <peptides.txtAs pointed out in the comments, this has the side effects of trimming leading whitespace, interpreting backslash sequences, and skipping the last line if it's missing a terminating linefeed. If these are concerns, you can do:while IFS="""" read -r p || [ -n ""$p"" ]do  printf '%s\n' ""$p""done < peptides.txtExceptionally, if the loop body may read from standard input, you can open the file using a different file descriptor:while read -u 10 p; do  ...done 10<peptides.txtHere, 10 is just an arbitrary number (different from 0, 1, 2)."
"data_i","edited Sep 30 '20 at 05:51","
        Scroll to the top of the page using JavaScript?
    ","How do I scroll to the top of the page using JavaScript? The scrollbar instantly jumping to the top of the page is desirable too as I'm not looking to achieve smooth scrolling.","If you don't need the change to animate then you don't need to use any special plugins - I'd just use the native JavaScript window.scrollTo() method -- passing in 0, 0 will scroll the page to the top left instantly.window.scrollTo(xCoord, yCoord);ParametersxCoord is the pixel along the horizontal axis.yCoord is the pixel along the vertical axis."
"data_i","edited Sep 01 '19 at 13:05","
        How do I make a placeholder for a 'select' box?
    ","I'm using placeholders for text inputs which is working out just fine. But I'd like to use a placeholder for my selectboxes as well. Of course I can just use this code:<select>    <option value="""">Select your option</option>    <option value=""hurr"">Durr</option></select>But the 'Select your option' is in black instead of lightgrey. So my solution could possibly be CSS-based. jQuery is fine too.This only makes the option grey in the dropdown (so after clicking the arrow):option:first {    color: #999;}The question is: How do people create placeholders in selectboxes? But it has already been answered, cheers.And using this results in the selected value always being grey (even after selecting a real option):select {    color: #999;}","A non-CSS - no JavaScript/jQuery answer:<label>Option name<select>    <option value="""" disabled selected>Select your option</option>    <option value=""hurr"">Durr</option></select></label>Update (December 2021):This works for latest Firefox, Chrome, and Safari. It used to not work for many browsers in the past, as pointed out in the comments."
"data_i","edited Sep 12 '21 at 22:36","
        How to efficiently count the number of keys/properties of an object in JavaScript
    ","What's the fastest way to count the number of keys/properties of an object? Is it possible to do this without iterating over the object?  I.e., without doing:var count = 0;for (k in myobj) if (myobj.hasOwnProperty(k)) ++count;(Firefox did provide a magic __count__ property, but this was removed somewhere around version 4.)","To do this in any ES5-compatible environment, such as Node.js, Chrome, Internet Explorer 9+, Firefox 4+, or Safari 5+:Object.keys(obj).lengthBrowser compatibilityObject.keys documentation (includes a method you can add to non-ES5 browsers)"
"data_i","edited May 11 '16 at 13:36","
        What is TypeScript and why would I use it in place of JavaScript?
    ","Can you please describe what the TypeScript language is?What can it do that JavaScript or available libraries cannot do, that would give me reason to consider it?","I originally wrote this answer when TypeScript was still  hot-off-the-presses. Five years later, this is an OK overview, but look   at Lodewijk's answer below for more depth1000ft view...TypeScript is a superset of JavaScript which primarily provides optional static typing, classes and interfaces. One of the big benefits is to enable IDEs to provide a richer environment for spotting common errors as you type the code.To get an idea of what I mean, watch Microsoft's introductory video on the language.For a large JavaScript project, adopting TypeScript might result in more robust software, while still being deployable where a regular JavaScript application would run.It is open source, but you only get the clever Intellisense as you type if you use a supported IDE. Initially, this was only Microsoft's Visual Studio (also noted in blog post from Miguel de Icaza). These days, other IDEs offer TypeScript support too.Are there other technologies like it?There's CoffeeScript, but that really serves a different purpose. IMHO, CoffeeScript provides readability for humans, but TypeScript also provides deep readability for tools through its optional static typing (see this recent blog post for a little more critique). There's also Dart but that's a full on replacement for JavaScript (though it can produce JavaScript code)ExampleAs an example, here's some TypeScript (you can play with this in the TypeScript Playground)class Greeter {    greeting: string;    constructor (message: string) {        this.greeting = message;    }    greet() {        return ""Hello, "" + this.greeting;    }}  And here's the JavaScript it would producevar Greeter = (function () {    function Greeter(message) {        this.greeting = message;    }    Greeter.prototype.greet = function () {        return ""Hello, "" + this.greeting;    };    return Greeter;})();Notice how the TypeScript defines the type of member variables and class method parameters. This is removed when translating to JavaScript, but used by the IDE and compiler to spot errors, like passing a numeric type to the constructor.It's also capable of inferring types which aren't explicitly declared, for example, it would determine the greet() method returns a string.Debugging TypeScriptMany browsers and IDEs offer direct debugging support through sourcemaps. See this Stack Overflow question for more details: Debugging TypeScript code with Visual StudioWant to know more?I originally wrote this answer when TypeScript was still hot-off-the-presses. Check out Lodewijk's answer to this question for some more current detail."
"data_i","edited Jun 13 '22 at 01:03","
        How do I measure elapsed time in Python?
    ","I want to measure the time it took to execute a function. I couldn't get timeit to work:import timeitstart = timeit.timeit()print(""hello"")end = timeit.timeit()print(end - start)","Use time.time() to measure the elapsed wall-clock time between two points:import timestart = time.time()print(""hello"")end = time.time()print(end - start)This gives the execution time in seconds.Another option since Python 3.3 might be to use perf_counter or process_time, depending on your requirements. Before 3.3 it was recommended to use time.clock (thanks Amber). However, it is currently deprecated:On Unix, return the current processor time as a floating point numberexpressed in seconds. The precision, and in fact the very definitionof the meaning of “processor time”, depends on that of the C functionof the same name.On Windows, this function returns wall-clock seconds elapsed since thefirst call to this function, as a floating point number, based on theWin32 function QueryPerformanceCounter(). The resolution is typicallybetter than one microsecond.Deprecated since version 3.3: The behaviour of this function dependson the platform: use perf_counter() or process_time() instead,depending on your requirements, to have a well defined behaviour."
"data_i","edited Apr 26 '22 at 10:06","
        How to duplicate a whole line in Vim?
    ","How do I duplicate a whole line in Vim in a similar way to Ctrl+D in IntelliJ IDEA/ Resharper or Ctrl+Alt+↑/↓ in Eclipse?","yy or Y to copy the line (mnemonic: yank)ordd to delete the line (Vim copies what you deleted into a clipboard-like ""register"", like a cut operation)thenp to paste the copied or deleted text after the current lineorP to paste the copied or deleted text before the current line"
"data_i","edited Mar 02 '17 at 18:33","
        What is the difference between Bower and npm?
    ","What is the fundamental difference between bower and npm? Just want something plain and simple. I've seen some of my colleagues use bower and npm interchangeably in their projects.","All package managers have many downsides. You just have to pick which you can live with.Historynpm started out managing node.js modules (that's why packages go into node_modules by default), but it works for the front-end too when combined with Browserify or webpack.Bower is created solely for the front-end and is optimized with that in mind.Size of reponpm is much, much larger than bower, including general purpose JavaScript (like country-data for country information or sorts for sorting functions that is usable on the front end or the back end).Bower has a much smaller amount of packages.Handling of styles etcBower includes styles etc.npm is focused on JavaScript. Styles are either downloaded separately or required by something like npm-sass or sass-npm.Dependency handlingThe biggest difference is that npm does nested dependencies (but is flat by default) while Bower requires a flat dependency tree (puts the burden of dependency resolution on the user).A nested dependency tree means that your dependencies can have their own dependencies which can have their own, and so on. This allows for two modules to require different versions of the same dependency and still work. Note since npm v3, the dependency tree will be flat by default (saving space) and only nest where needed, e.g., if two dependencies need their own version of Underscore.Some projects use both: they use Bower for front-end packages and npm for developer tools like Yeoman, Grunt, Gulp, JSHint, CoffeeScript, etc.ResourcesNested Dependencies - Insight into why node_modules works the way it does"
"data_i","edited Aug 28 '15 at 16:12","
        Why does this code using random strings print ""hello world""?
    ","The following print statement would print ""hello world"".Could anyone explain this?System.out.println(randomString(-229985452) + "" "" + randomString(-147909649));And randomString() looks like this:public static String randomString(int i){    Random ran = new Random(i);    StringBuilder sb = new StringBuilder();    while (true)    {        int k = ran.nextInt(27);        if (k == 0)            break;        sb.append((char)('`' + k));    }    return sb.toString();}","The other answers explain why, but here is how.Given an instance of Random:Random r = new Random(-229985452)The first 6 numbers that r.nextInt(27) generates are:851212150and the first 6 numbers that r.nextInt(27) generates given Random r = new Random(-147909649) are:2315181240Then just add those numbers to the integer representation of the character ` (which is 96):8  + 96 = 104 --> h5  + 96 = 101 --> e12 + 96 = 108 --> l12 + 96 = 108 --> l15 + 96 = 111 --> o23 + 96 = 119 --> w15 + 96 = 111 --> o18 + 96 = 114 --> r12 + 96 = 108 --> l4  + 96 = 100 --> d"
"data_i","edited Sep 03 '17 at 16:06","
        What is a NullReferenceException, and how do I fix it?
    ","I have some code and when it executes, it throws a NullReferenceException, saying:Object reference not set to an instance of an object.What does this mean, and what can I do to fix this error?","What is the cause?Bottom LineYou are trying to use something that is null (or Nothing in VB.NET). This means you either set it to null, or you never set it to anything at all.Like anything else, null gets passed around. If it is null in method ""A"", it could be that method ""B"" passed a null to method ""A"".null can have different meanings:Object variables that are uninitialized and hence point to nothing. In this case, if you access members of such objects, it causes a NullReferenceException.The developer is using null intentionally to indicate there is no meaningful value available. Note that C# has the concept of nullable datatypes for variables (like database tables can have nullable fields) - you can assign null to them to indicate there is no value stored in it, for example int? a = null; (which is a shortcut for Nullable<int> a = null;) where the question mark indicates it is allowed to store null in variable a. You can check that either with if (a.HasValue) {...} or with if (a==null) {...}. Nullable variables, like a this example, allow to access the value via a.Value explicitly, or just as normal via a. Note that accessing it via a.Value throws an InvalidOperationException instead of a NullReferenceException if a is null - you should do the check beforehand, i.e. if you have another non-nullable variable int b; then you should do assignments like if (a.HasValue) { b = a.Value; } or shorter if (a != null) { b = a; }.The rest of this article goes into more detail and shows mistakes that many programmers often make which can lead to a NullReferenceException.More SpecificallyThe runtime throwing a NullReferenceException always means the same thing: you are trying to use a reference, and the reference is not initialized (or it was once initialized, but is no longer initialized).This means the reference is null, and you cannot access members (such as methods) through a null reference. The simplest case:string foo = null;foo.ToUpper();This will throw a NullReferenceException at the second line because you can't call the instance method ToUpper() on a string reference pointing to null.DebuggingHow do you find the source of a NullReferenceException? Apart from looking at the exception itself, which will be thrown exactly at the location where it occurs, the general rules of debugging in Visual Studio apply: place strategic breakpoints and inspect your variables, either by hovering the mouse over their names, opening a (Quick)Watch window or using the various debugging panels like Locals and Autos.If you want to find out where the reference is or isn't set, right-click its name and select ""Find All References"". You can then place a breakpoint at every found location and run your program with the debugger attached. Every time the debugger breaks on such a breakpoint, you need to determine whether you expect the reference to be non-null, inspect the variable, and verify that it points to an instance when you expect it to.By following the program flow this way, you can find the location where the instance should not be null, and why it isn't properly set.ExamplesSome common scenarios where the exception can be thrown:Genericref1.ref2.ref3.memberIf ref1 or ref2 or ref3 is null, then you'll get a NullReferenceException. If you want to solve the problem, then find out which one is null by rewriting the expression to its simpler equivalent:var r1 = ref1;var r2 = r1.ref2;var r3 = r2.ref3;r3.memberSpecifically, in HttpContext.Current.User.Identity.Name, the HttpContext.Current could be null, or the User property could be null, or the Identity property could be null.Indirectpublic class Person {    public int Age { get; set; }}public class Book {    public Person Author { get; set; }}public class Example {    public void Foo()     {        Book b1 = new Book();        int authorAge = b1.Author.Age; // You never initialized the Author property.                                       // there is no Person to get an Age from.    }}If you want to avoid the child (Person) null reference, you could initialize it in the parent (Book) object's constructor.Nested Object InitializersThe same applies to nested object initializers:Book b1 = new Book {    Author = { Age = 45 } };This translates to:Book b1 = new Book();b1.Author.Age = 45;While the new keyword is used, it only creates a new instance of Book, but not a new instance of Person, so the Author the property is still null.Nested Collection Initializerspublic class Person {    public ICollection<Book> Books { get; set; }}public class Book {    public string Title { get; set; }}The nested collection Initializers behave the same:Person p1 = new Person {    Books = {         new Book { Title = ""Title1"" },         new Book { Title = ""Title2"" },    }};This translates to:Person p1 = new Person();p1.Books.Add(new Book { Title = ""Title1"" });p1.Books.Add(new Book { Title = ""Title2"" });The new Person only creates an instance of Person, but the Books collection is still null. The collection Initializer syntax does not create a collectionfor p1.Books, it only translates to the p1.Books.Add(...) statements.Arrayint[] numbers = null;int n = numbers[0]; // numbers is null. There is no array to index.Array ElementsPerson[] people = new Person[5];people[0].Age = 20 // people[0] is null. The array was allocated but not                   // initialized. There is no Person to set the Age for.Jagged Arrayslong[][] array = new long[1][];array[0][0] = 3; // is null because only the first dimension is yet initialized.                 // Use array[0] = new long[2]; first.Collection/List/DictionaryDictionary<string, int> agesForNames = null;int age = agesForNames[""Bob""]; // agesForNames is null.                               // There is no Dictionary to perform the lookup.Range Variable (Indirect/Deferred)public class Person {    public string Name { get; set; }}var people = new List<Person>();people.Add(null);var names = from p in people select p.Name;string firstName = names.First(); // Exception is thrown here, but actually occurs                                  // on the line above.  ""p"" is null because the                                  // first element we added to the list is null.Events (C#)public class Demo{    public event EventHandler StateChanged;        protected virtual void OnStateChanged(EventArgs e)    {                StateChanged(this, e); // Exception is thrown here                                // if no event handlers have been attached                               // to StateChanged event    }}(Note: The VB.NET compiler inserts null checks for event usage, so it's not necessary to check events for Nothing in VB.NET.)Bad Naming Conventions:If you named fields differently from locals, you might have realized that you never initialized the field.public class Form1{    private Customer customer;        private void Form1_Load(object sender, EventArgs e)     {        Customer customer = new Customer();        customer.Name = ""John"";    }        private void Button_Click(object sender, EventArgs e)    {        MessageBox.Show(customer.Name);    }}This can be solved by following the convention to prefix fields with an underscore:    private Customer _customer;ASP.NET Page Life cycle:public partial class Issues_Edit : System.Web.UI.Page{    protected TestIssue myIssue;    protected void Page_Load(object sender, EventArgs e)    {        if (!IsPostBack)        {             // Only called on first load, not when button clicked             myIssue = new TestIssue();         }    }            protected void SaveButton_Click(object sender, EventArgs e)    {        myIssue.Entry = ""NullReferenceException here!"";    }}ASP.NET Session Values// if the ""FirstName"" session value has not yet been set,// then this line will throw a NullReferenceExceptionstring firstName = Session[""FirstName""].ToString();ASP.NET MVC empty view modelsIf the exception occurs when referencing a property of @Model in an ASP.NET MVC View, you need to understand that the Model gets set in your action method, when you return a view. When you return an empty model (or model property) from your controller, the exception occurs when the views access it:// Controllerpublic class Restaurant:Controller{    public ActionResult Search()    {        return View();  // Forgot the provide a Model here.    }}// Razor view @foreach (var restaurantSearch in Model.RestaurantSearch)  // Throws.{}    <p>@Model.somePropertyName</p> <!-- Also throws -->WPF Control Creation Order and EventsWPF controls are created during the call to InitializeComponent in the order they appear in the visual tree.  A NullReferenceException will be raised in the case of early-created controls with event handlers, etc., that fire during InitializeComponent which reference late-created controls.For example:<Grid>    <!-- Combobox declared first -->    <ComboBox Name=""comboBox1""               Margin=""10""              SelectedIndex=""0""               SelectionChanged=""comboBox1_SelectionChanged"">       <ComboBoxItem Content=""Item 1"" />       <ComboBoxItem Content=""Item 2"" />       <ComboBoxItem Content=""Item 3"" />    </ComboBox>            <!-- Label declared later -->    <Label Name=""label1""            Content=""Label""           Margin=""10"" /></Grid>Here comboBox1 is created before label1. If comboBox1_SelectionChanged attempts to reference `label1, it will not yet have been created.private void comboBox1_SelectionChanged(object sender, SelectionChangedEventArgs e){    label1.Content = comboBox1.SelectedIndex.ToString(); // NullReferenceException here!!}Changing the order of the declarations in the XAML (i.e., listing label1 before comboBox1, ignoring issues of design philosophy) would at least resolve the NullReferenceException here.Cast with asvar myThing = someObject as Thing;This doesn't throw an InvalidCastException but returns a null when the cast fails (and when someObject is itself null). So be aware of that.LINQ FirstOrDefault() and SingleOrDefault()The plain versions First() and Single() throw exceptions when there is nothing. The ""OrDefault"" versions return null in that case. So be aware of that.foreachforeach throws when you try to iterate on a null collection. Usually caused by unexpected null result from methods that return collections.List<int> list = null;    foreach(var v in list) { } // NullReferenceException hereMore realistic example - select nodes from XML document. Will throw if nodes are not found but initial debugging shows that all properties valid:foreach (var node in myData.MyXml.DocumentNode.SelectNodes(""//Data""))Ways to AvoidExplicitly check for null and ignore null values.If you expect the reference sometimes to be null, you can check for it being null before accessing instance members:void PrintName(Person p){    if (p != null)     {        Console.WriteLine(p.Name);    }}Explicitly check for null and provide a default value.Methods you call expecting an instance can return null, for example when the object being sought cannot be found. You can choose to return a default value when this is the case:string GetCategory(Book b) {    if (b == null)        return ""Unknown"";    return b.Category;}Explicitly check for null from method calls and throw a custom exception.You can also throw a custom exception, only to catch it in the calling code:string GetCategory(string bookTitle) {    var book = library.FindBook(bookTitle);  // This may return null    if (book == null)        throw new BookNotFoundException(bookTitle);  // Your custom exception    return book.Category;}Use Debug.Assert if a value should never be null, to catch the problem earlier than the exception occurs.When you know during development that a method could, but never should return null, you can use Debug.Assert() to break as soon as possible when it does occur:string GetTitle(int knownBookID) {    // You know this should never return null.    var book = library.GetBook(knownBookID);      // Exception will occur on the next line instead of at the end of this method.    Debug.Assert(book != null, ""Library didn't return a book for known book ID."");    // Some other code    return book.Title; // Will never throw NullReferenceException in Debug mode.}Though this check will not end up in your release build, causing it to throw the NullReferenceException again when book == null at runtime in release mode.Use GetValueOrDefault() for nullable value types to provide a default value when they are null.DateTime? appointment = null;Console.WriteLine(appointment.GetValueOrDefault(DateTime.Now));// Will display the default value provided (DateTime.Now), because appointment is null.appointment = new DateTime(2022, 10, 20);Console.WriteLine(appointment.GetValueOrDefault(DateTime.Now));// Will display the appointment date, not the defaultUse the null coalescing operator: ?? [C#] or If() [VB].The shorthand to providing a default value when a null is encountered:IService CreateService(ILogger log, Int32? frobPowerLevel){   var serviceImpl = new MyService(log ?? NullLog.Instance);    // Note that the above ""GetValueOrDefault()"" can also be rewritten to use   // the coalesce operator:   serviceImpl.FrobPowerLevel = frobPowerLevel ?? 5;}Use the null condition operator: ?. or ?[x] for arrays (available in C# 6 and VB.NET 14):This is also sometimes called the safe navigation or Elvis (after its shape) operator. If the expression on the left side of the operator is null, then the right side will not be evaluated, and null is returned instead. That means cases like this:var title = person.Title.ToUpper();If the person does not have a title, this will throw an exception because it is trying to call ToUpper on a property with a null value.In C# 5 and below, this can be guarded with:var title = person.Title == null ? null : person.Title.ToUpper();Now the title variable will be null instead of throwing an exception. C# 6 introduces a shorter syntax for this:var title = person.Title?.ToUpper();This will result in the title variable being null, and the call to ToUpper is not made if person.Title is null.Of course, you still have to check title for null or use the null condition operator together with the null coalescing operator (??) to supply a default value:// regular null checkint titleLength = 0;if (title != null)    titleLength = title.Length; // If title is null, this would throw NullReferenceException    // combining the `?` and the `??` operatorint titleLength = title?.Length ?? 0;Likewise, for arrays you can use ?[i] as follows:int[] myIntArray = null;var i = 5;int? elem = myIntArray?[i];if (!elem.HasValue) Console.WriteLine(""No value"");This will do the following: If myIntArray is null, the expression returns null and you can safely check it. If it contains an array, it will do the same as:elem = myIntArray[i]; and returns the ith element.Use null context (available in C# 8):Introduced in C# 8, null contexts and nullable reference types perform static analysis on variables and provide a compiler warning if a value can be potentially null or have been set to null. The nullable reference types allow types to be explicitly allowed to be null.The nullable annotation context and nullable warning context can be set for a project using the Nullable element in your csproj file. This element configures how the compiler interprets the nullability of types and what warnings are generated. Valid settings are:enable: The nullable annotation context is enabled. The nullable warning context is enabled. Variables of a reference type, string, for example, are non-nullable. All nullability warnings are enabled.disable: The nullable annotation context is disabled. The nullable warning context is disabled. Variables of a reference type are oblivious, just like earlier versions of C#. All nullability warnings are disabled.safeonly: The nullable annotation context is enabled. The nullable warning context is safeonly. Variables of a reference type are non-nullable. All safety nullability warnings are enabled.warnings: The nullable annotation context is disabled. The nullable warning context is enabled. Variables of a reference type are oblivious. All nullability warnings are enabled.safeonlywarnings: The nullable annotation context is disabled. The nullable warning context is safeonly.Variables of a reference type are oblivious. All safety nullability warnings are enabled.A nullable reference type is noted using the same syntax as nullable value types: a ? is appended to the type of the variable.Special techniques for debugging and fixing null derefs in iteratorsC# supports ""iterator blocks"" (called ""generators"" in some other popular languages). NullReferenceException can be particularly tricky to debug in iterator blocks because of deferred execution:public IEnumerable<Frob> GetFrobs(FrobFactory f, int count){    for (int i = 0; i < count; ++i)    yield return f.MakeFrob();}...FrobFactory factory = whatever;IEnumerable<Frobs> frobs = GetFrobs();...foreach(Frob frob in frobs) { ... }If whatever results in null then MakeFrob will throw. Now, you might think that the right thing to do is this:// DON'T DO THISpublic IEnumerable<Frob> GetFrobs(FrobFactory f, int count){   if (f == null)       throw new ArgumentNullException(""f"", ""factory must not be null"");   for (int i = 0; i < count; ++i)      yield return f.MakeFrob();}Why is this wrong?  Because the iterator block does not actually run until the foreach!  The call to GetFrobs simply returns an object which when iterated will run the iterator block.By writing a null check like this you prevent the NullReferenceException, but you move the NullArgumentException to the point of the iteration, not to the point of the call, and that is very confusing to debug.The correct fix is:// DO THISpublic IEnumerable<Frob> GetFrobs(FrobFactory f, int count){   // No yields in a public method that throws!   if (f == null)        throw new ArgumentNullException(""f"", ""factory must not be null"");   return GetFrobsForReal(f, count);}private IEnumerable<Frob> GetFrobsForReal(FrobFactory f, int count){   // Yields in a private method   Debug.Assert(f != null);   for (int i = 0; i < count; ++i)        yield return f.MakeFrob();}That is, make a private helper method that has the iterator block logic and a public surface method that does the null check and returns the iterator. Now when GetFrobs is called, the null check happens immediately, and then GetFrobsForReal executes when the sequence is iterated.If you examine the reference source for LINQ to Objects you will see that this technique is used throughout. It is slightly more clunky to write, but it makes debugging nullity errors much easier. Optimize your code for the convenience of the caller, not the convenience of the author.A note on null dereferences in unsafe codeC# has an ""unsafe"" mode which is, as the name implies, extremely dangerous because the normal safety mechanisms which provide memory safety and type safety are not enforced. You should not be writing unsafe code unless you have a thorough and deep understanding of how memory works.In unsafe mode, you should be aware of two important facts:dereferencing a null pointer produces the same exception as dereferencing a null referencedereferencing an invalid non-null pointer can produce that exception in some circumstancesTo understand why that is, it helps to understand how .NET produces NullReferenceException in the first place. (These details apply to .NET running on Windows; other operating systems use similar mechanisms.)Memory is virtualized in Windows; each process gets a virtual memory space of many ""pages"" of memory that are tracked by the operating system. Each page of memory has flags set on it that determine how it may be used: read from, written to, executed, and so on. The lowest page is marked as ""produce an error if ever used in any way"".Both a null pointer and a null reference in C# are internally represented as the number zero, and so any attempt to dereference it into its corresponding memory storage causes the operating system to produce an error. The .NET runtime then detects this error and turns it into the NullReferenceException.That's why dereferencing both a null pointer and a null reference produces the same exception.What about the second point? Dereferencing any invalid pointer that falls in the lowest page of virtual memory causes the same operating system error, and thereby the same exception.Why does this make sense?  Well, suppose we have a struct containing two ints, and an unmanaged pointer equal to null. If we attempt to dereference the second int in the struct, the CLR will not attempt to access the storage at location zero; it will access the storage at location four. But logically this is a null dereference because we are getting to that address via the null.If you are working with unsafe code and you get a NullReferenceException, just be aware that the offending pointer need not be null. It can be any location in the lowest page, and this exception will be produced."
"data_i","edited Jul 24 '22 at 23:41","
        How do I split a string in Java?
    ","I want to split the string ""004-034556"" into two strings by the delimiter ""-"":part1 = ""004"";part2 = ""034556"";That means the first string will contain the characters before '-', and the second string will contain the characters after '-'.I also want to check if the string has '-' in it.","Use the appropriately named method String#split().String string = ""004-034556"";String[] parts = string.split(""-"");String part1 = parts[0]; // 004String part2 = parts[1]; // 034556Note that split's argument is assumed to be a regular expression, so remember to escape special characters if necessary.there are 12 characters with special meanings: the backslash \, the caret ^, the dollar sign $, the period or dot ., the vertical bar or pipe symbol |, the question mark ?, the asterisk or star *, the plus sign +, the opening parenthesis (, the closing parenthesis ), and the opening square bracket [, the opening curly brace {, These special characters are often called ""metacharacters"".For instance, to split on a period/dot . (which means ""any character"" in regex), use either backslash \ to escape the individual special character like so split(""\\.""), or use character class [] to represent literal character(s) like so split(""[.]""), or use Pattern#quote() to escape the entire string like so split(Pattern.quote(""."")).String[] parts = string.split(Pattern.quote(""."")); // Split on the exact string.To test beforehand if the string contains certain character(s), just use String#contains().if (string.contains(""-"")) {    // Split it.} else {    throw new IllegalArgumentException(""String "" + string + "" does not contain -"");}Note, this does not take a regular expression. For that, use String#matches() instead.If you'd like to retain the split character in the resulting parts, then make use of positive lookaround. In case you want to have the split character to end up in left hand side, use positive lookbehind by prefixing ?<= group on the pattern.String string = ""004-034556"";String[] parts = string.split(""(?<=-)"");String part1 = parts[0]; // 004-String part2 = parts[1]; // 034556In case you want to have the split character to end up in right hand side, use positive lookahead by prefixing ?= group on the pattern.String string = ""004-034556"";String[] parts = string.split(""(?=-)"");String part1 = parts[0]; // 004String part2 = parts[1]; // -034556If you'd like to limit the number of resulting parts, then you can supply the desired number as 2nd argument of split() method.String string = ""004-034556-42"";String[] parts = string.split(""-"", 2);String part1 = parts[0]; // 004String part2 = parts[1]; // 034556-42"
"data_i","edited Aug 13 '18 at 13:38","
        Remove tracking branches no longer on remote
    ","Is there a simple way to delete all tracking branches whose remote equivalent no longer exists?Example:Branches (local and remote)masterorigin/masterorigin/bug-fix-aorigin/bug-fix-borigin/bug-fix-cLocally, I only have a master branch. Now I need to work on bug-fix-a, so I check it out, work on it, and push changes to the remote. Next I do the same with bug-fix-b.Branches (local and remote)masterbug-fix-abug-fix-borigin/masterorigin/bug-fix-aorigin/bug-fix-borigin/bug-fix-cNow I have local branches master, bug-fix-a, bug-fix-b. The Master branch maintainer will merge my changes into master and delete all branches he has already merged.So the current state is now:Branches (local and remote)masterbug-fix-abug-fix-borigin/masterorigin/bug-fix-cNow I would like to call some command to delete branches (in this case bug-fix-a, bug-fix-b), which are no longer represented in the remote repository.It would be something like the existing command git remote prune origin, but more like git local prune origin.","git remote prune origin prunes tracking branches not on the remote.git branch --merged lists branches that have been merged into the current branch.xargs git branch -d deletes branches listed on standard input.Be careful deleting branches listed by git branch --merged. The list could include master or other branches you'd prefer not to delete.To give yourself the opportunity to edit the list before deleting branches, you could do the following in one line:git branch --merged >/tmp/merged-branches && \  vi /tmp/merged-branches && xargs git branch -d </tmp/merged-branches"
"data_i","edited Sep 17 '14 at 03:45","
        How to move an element into another element?
    ","I would like to move one DIV element inside another. For example, I want to move this (including all children):<div id=""source"">...</div>into this:<div id=""destination"">...</div>so that I have this:<div id=""destination"">  <div id=""source"">    ...  </div></div>","You may want to use the appendTo function (which adds to the end of the element):$(""#source"").appendTo(""#destination"");Alternatively you could use the prependTo function (which adds to the beginning of the element):$(""#source"").prependTo(""#destination"");Example:$(""#appendTo"").click(function() {  $(""#moveMeIntoMain"").appendTo($(""#main""));});$(""#prependTo"").click(function() {  $(""#moveMeIntoMain"").prependTo($(""#main""));});#main {  border: 2px solid blue;  min-height: 100px;}.moveMeIntoMain {  border: 1px solid red;}<script src=""https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js""></script><div id=""main"">main</div><div id=""moveMeIntoMain"" class=""moveMeIntoMain"">move me to main</div><button id=""appendTo"">appendTo main</button><button id=""prependTo"">prependTo main</button>"
"data_i","edited Sep 11 '22 at 04:13","
        How do I check if a string represents a number (float or int)?
    ","How do I check if a string represents a numeric value in Python?def is_number(s):    try:        float(s)        return True    except ValueError:        return FalseThe above works, but it seems clunky.If what you are testing comes from user input, it is still a string even if it represents an int or a float. See How can I read inputs as numbers? for converting the input, and Asking the user for input until they give a valid response for ensuring that the input represents an int or float (or other requirements) before proceeding.","For non-negative (unsigned) integers only, use isdigit():>>> a = ""03523"">>> a.isdigit()True>>> b = ""963spam"">>> b.isdigit()FalseDocumentation for isdigit(): Python2, Python3For Python 2 Unicode strings:isnumeric()."
"data_i","edited Dec 20 '17 at 01:01","
        Why should text files end with a newline?
    ","I assume everyone here is familiar with the adage that all text files should end with a newline. I've known of this ""rule"" for years but I've always wondered — why?","Because that’s how the POSIX standard defines a line:3.206 LineA sequence of zero or more non- <newline> characters plus a terminating <newline> character.Therefore, lines not ending in a newline character aren't considered actual lines. That's why some programs have problems processing the last line of a file if it isn't newline terminated.There's at least one hard advantage to this guideline when working on a terminal emulator: All Unix tools expect this convention and work with it. For instance, when concatenating files with cat, a file terminated by newline will have a different effect than one without:$ more a.txtfoo$ more b.txtbar$ more c.txtbaz$ cat {a,b,c}.txtfoobarbazAnd, as the previous example also demonstrates, when displaying the file on the command line (e.g. via more), a newline-terminated file results in a correct display. An improperly terminated file might be garbled (second line).For consistency, it’s very helpful to follow this rule – doing otherwise will incur extra work when dealing with the default Unix tools.Think about it differently: If lines aren’t terminated by newline, making commands such as cat useful is much harder: how do you make a command to concatenate files such thatit puts each file’s start on a new line, which is what you want 95% of the time; butit allows merging the last and first line of two files, as in the example above between b.txt and c.txt?Of course this is solvable but you need to make the usage of cat more complex (by adding positional command line arguments, e.g. cat a.txt --no-newline b.txt c.txt), and now the command rather than each individual file controls how it is pasted together with other files. This is almost certainly not convenient.… Or you need to introduce a special sentinel character to mark a line that is supposed to be continued rather than terminated. Well, now you’re stuck with the same situation as on POSIX, except inverted (line continuation rather than line termination character).Now, on non POSIX compliant systems (nowadays that’s mostly Windows), the point is moot: files don’t generally end with a newline, and the (informal) definition of a line might for instance be “text that is separated by newlines” (note the emphasis). This is entirely valid. However, for structured data (e.g. programming code) it makes parsing minimally more complicated: it generally means that parsers have to be rewritten. If a parser was originally written with the POSIX definition in mind, then it might be easier to modify the token stream rather than the parser — in other words, add an “artificial newline” token to the end of the input."
"data_i","asked Dec 12 '10 at 12:30","
        Who is listening on a given TCP port on Mac OS X?
    ","On Linux, I can use netstat -pntl | grep $PORT or fuser -n tcp $PORT to find out which process (PID) is listening on the specified TCP port. How do I get the same information on Mac OS X?","On macOS Big Sur and later, use this command:sudo lsof -i -P | grep LISTEN | grep :$PORTor to just see just IPv4:sudo lsof -nP -i4TCP:$PORT | grep LISTENOn older versions, use one of the following forms:sudo lsof -nP -iTCP:$PORT | grep LISTENsudo lsof -nP -i:$PORT | grep LISTENSubstitute $PORT with the port number or a comma-separated list of port numbers.Prepend sudo (followed by a space) if you need information on ports below #1024.The -n flag is for displaying IP addresses instead of host names. This makes the command execute much faster, because DNS lookups to get the host names can be slow (several seconds or a minute for many hosts).The -P flag is for displaying raw port numbers instead of resolved names like http, ftp or more esoteric service names like dpserve, socalia.See the comments for more options.For completeness, because frequently used together:To kill the PID:sudo kill -9 <PID># kill -9 60401"
"data_i","edited Jan 24 '19 at 18:50","
        How can I set the default value for an HTML  element?
    ","I thought that adding a ""value"" attribute set on the <select> element below would cause the <option> containing my provided ""value"" to be selected by default:<select name=""hall"" id=""hall"" value=""3"">  <option>1</option>  <option>2</option>  <option>3</option>  <option>4</option>  <option>5</option></select>However, this did not work as I had expected. How can I set which <option> element is selected by default?","Set selected=""selected"" for the option you want to be the default.<option selected=""selected"">3</option>"
"data_i","edited Apr 01 '21 at 09:14","
        How to align checkboxes and their labels consistently cross-browsers
    ","This is one of the minor CSS problems that plague me constantly.How do folks around Stack Overflow vertically align checkboxes and their labels consistently cross-browser?Whenever I align them correctly in Safari (usually using vertical-align: baseline on the input), they're completely off in Firefox and IE.Fix it in Firefox, and Safari and IE are inevitably messed up. I waste time on this every time I code a form.Here's the standard code that I work with:<form>    <div>        <label><input type=""checkbox"" /> Label text</label>    </div></form>I usually use Eric Meyer's reset, so form elements are relatively clean of overrides. Looking forward to any tips or tricks that you have to offer!","Warning!  This answer is too old and doesn't work on modern browsers.I'm not the poster of this answer, but at the time of writing this, this is the most voted answer by far in both positive and negative votes (+1035 -17), and it's still marked as accepted answer (probably because the original poster of the question is the one who wrote this answer).As already noted many times in the comments, this answer does not work on most browsers anymore (and seems to be failing to do that since 2013).After over an hour of tweaking, testing, and trying different styles of markup, I think I may have a decent solution.  The requirements for this particular project were:Inputs must be on their own line.Checkbox inputs need to align vertically with the label text similarly (if not identically) across all browsers.If the label text wraps, it needs to be indented (so no wrapping down underneath the checkbox).Before I get into any explanation, I'll just give you the code:label {  display: block;  padding-left: 15px;  text-indent: -15px;}input {  width: 13px;  height: 13px;  padding: 0;  margin:0;  vertical-align: bottom;  position: relative;  top: -1px;  *overflow: hidden;}<form>  <div>    <label><input type=""checkbox"" /> Label text</label>  </div></form>Here is the working example in JSFiddle.This code assumes that you're using a reset like Eric Meyer's that doesn't override form input margins and padding (hence putting margin and padding resets in the input CSS).  Obviously in a live environment you'll probably be nesting/overriding stuff to support other input elements, but I wanted to keep things simple.Things to note:The *overflow declaration is an inline IE hack (the star-property hack).  Both IE 6 and 7 will notice it, but Safari and Firefox will properly ignore it. I think it might be valid CSS, but you're still better off with conditional comments; just used it for simplicity.As best I can tell, the only vertical-align statement that was consistent across browsers was vertical-align: bottom.  Setting this and then relatively positioning upwards behaved almost identically in Safari, Firefox and IE with only a pixel or two of discrepancy.The major problem in working with alignment is that IE sticks a bunch of mysterious space around input elements.  It isn't padding or margin, and it's damned persistent.  Setting a width and height on the checkbox and then overflow: hidden for some reason cuts off the extra space and allows IE's positioning to act very similarly to Safari and Firefox.Depending on your text sizing, you'll no doubt need to adjust the relative positioning, width, height, and so forth to get things looking right.Hope this helps someone else!  I haven't tried this specific technique on any projects other than the one I was working on this morning, so definitely pipe up if you find something that works more consistently.Warning! This answer is too old and doesn't work on modern browsers."
"data_i","edited Apr 01 '21 at 16:56","
        How to send a header using a HTTP request through a cURL call?
    ","I wish to send a header to my Apache server on a Linux box.  How can I achieve this via a cURL call?","man curl:   -H/--header <header>          (HTTP)  Extra header to use when getting a web page. You may specify          any number of extra headers. Note that if you should  add  a  custom          header that has the same name as one of the internal ones curl would          use, your externally set header will be used instead of the internal          one.  This  allows  you  to make even trickier stuff than curl would          normally do. You should not replace internally set  headers  without          knowing  perfectly well what you're doing. Remove an internal header          by giving a replacement without content on the  right  side  of  the          colon, as in: -H ""Host:"".          curl  will  make sure that each header you add/replace get sent with          the proper end of line marker, you should thus not  add  that  as  a          part  of the header content: do not add newlines or carriage returns          they will only mess things up for you.          See also the -A/--user-agent and -e/--referer options.          This option can be used multiple times to add/replace/remove  multi-          ple headers.Example 1: Single Headercurl --header ""X-MyHeader: 123"" www.google.comExample 2: Mutliple Headerscurl --header ""Accept: text/javascript"" --header ""X-Test: hello"" -v www.google.comYou can see the request that curl sent by adding the -v option."
"data_i","edited Mar 16 '16 at 17:39","
        Image Processing: Algorithm Improvement for 'Coca-Cola Can' Recognition
    ","One of the most interesting projects I've worked on in the past couple of years was a project about image processing. The goal was to develop a system to be able to recognize Coca-Cola 'cans' (note that I'm stressing the word 'cans', you'll see why in a minute). You can see a sample below, with the can recognized in the green rectangle with scale and rotation.Some constraints on the project:The background could be very noisy.The can could have any scale or rotation or even orientation (within reasonable limits).The image could have some degree of fuzziness (contours might not be entirely straight).There could be Coca-Cola bottles in the image, and the algorithm should only detect the can!The brightness of the image could vary a lot (so you can't rely ""too much"" on color detection).The can could be partly hidden on the sides or the middle and possibly partly hidden behind a bottle.There could be no can at all in the image, in which case you had to find nothing and write a message saying so.So you could end up with tricky things like this (which in this case had my algorithm totally fail):I did this project a while ago, and had a lot of fun doing it, and I had a decent implementation. Here are some details about my implementation:Language: Done in C++ using OpenCV library.Pre-processing: For the image pre-processing, i.e. transforming the image into a more raw form to give to the algorithm, I used 2 methods:Changing color domain from RGB to HSV and filtering based on ""red"" hue, saturation above a certain threshold to avoid orange-like colors, and filtering of low value to avoid dark tones. The end result was a binary black and white image, where all white pixels would represent the pixels that match this threshold. Obviously there is still a lot of crap in the image, but this reduces the number of dimensions you have to work with.Noise filtering using median filtering (taking the median pixel value of all neighbors and replace the pixel by this value) to reduce noise.Using Canny Edge Detection Filter to get the contours of all items after 2 precedent steps.Algorithm: The algorithm itself I chose for this task was taken from this awesome book on feature extraction and called Generalized Hough Transform (pretty different from the regular Hough Transform). It basically says a few things:You can describe an object in space without knowing its analytical equation (which is the case here).It is resistant to image deformations such as scaling and rotation, as it will basically test your image for every combination of scale factor and rotation factor.It uses a base model (a template) that the algorithm will ""learn"".Each pixel remaining in the contour image will vote for another pixel which will supposedly be the center (in terms of gravity) of your object, based on what it learned from the model.In the end, you end up with a heat map of the votes, for example here all the pixels of the contour of the can will vote for its gravitational center, so you'll have a lot of votes in the same pixel corresponding to the center, and will see a peak in the heat map as below:Once you have that, a simple threshold-based heuristic can give you the location of the center pixel, from which you can derive the scale and rotation and then plot your little rectangle around it (final scale and rotation factor will obviously be relative to your original template). In theory at least...Results: Now, while this approach worked in the basic cases, it was severely lacking in some areas:It is extremely slow! I'm not stressing this enough. Almost a full day was needed to process the 30 test images, obviously because I had a very high scaling factor for rotation and translation, since some of the cans were very small.It was completely lost when bottles were in the image, and for some reason almost always found the bottle instead of the can (perhaps because bottles were bigger, thus had more pixels, thus more votes)Fuzzy images were also no good, since the votes ended up in pixel at random locations around the center, thus ending with a very noisy heat map.In-variance in translation and rotation was achieved, but not in orientation, meaning that a can that was not directly facing the camera objective wasn't recognized.Can you help me improve my specific algorithm, using exclusively OpenCV features, to resolve the four specific issues mentioned?I hope some people will also learn something out of it as well, after all I think not only people who ask questions should learn. :)","An alternative approach would be to extract features (keypoints) using the scale-invariant feature transform (SIFT) or Speeded Up Robust Features (SURF).You can find a nice OpenCV code example in Java, C++, and Python on this page: Features2D + Homography to find a known objectBoth algorithms are invariant to scaling and rotation. Since they work with features, you can also handle occlusion (as long as enough keypoints are visible).Image source: tutorial exampleThe processing takes a few hundred ms for SIFT, SURF is bit faster, but it not suitable for real-time applications. ORB uses FAST which is weaker regarding rotation invariance.The original papersSURF: Speeded Up Robust FeaturesDistinctive Image Featuresfrom Scale-Invariant KeypointsORB: an efficient alternative to SIFT or SURF"
"data_i","edited Aug 14 '18 at 08:55","
        Why does ++[[]][+[]]+[+[]] return the string ""10""?
    ","This is valid and returns the string ""10"" in JavaScript (more examples here):console.log(++[[]][+[]]+[+[]])Why? What is happening here?","If we split it up, the mess is equal to:++[[]][+[]]+[+[]]In JavaScript, it is true that +[] === 0. + converts something into a number, and in this case it will come down to +"""" or 0 (see specification details below).Therefore, we can simplify it (++ has precendence over +):++[[]][0]+[0]Because [[]][0] means: get the first element from [[]], it is true that:[[]][0] returns the inner array ([]). Due to references it's wrong to say [[]][0] === [], but let's call the inner array A to avoid the wrong notation.++ before its operand means “increment by one and return the incremented result”. So ++[[]][0] is equivalent to Number(A) + 1 (or +A + 1).Again, we can simplify the mess into something more legible. Let's substitute [] back for A:(+[] + 1)+[0]Before +[] can coerce the array into the number 0, it needs to be coerced into a string first, which is """", again. Finally, 1 is added, which results in 1.(+[] + 1) === (+"""" + 1)(+"""" + 1) === (0 + 1)(0 + 1) === 1Let's simplify it even more:1+[0]Also, this is true in JavaScript: [0] == ""0"", because it's joining an array with one element. Joining will concatenate the elements separated by ,. With one element, you can deduce that this logic will result in the first element itself.In this case, + sees two operands: a number and an array. It’s now trying to coerce the two into the same type. First, the array is coerced into the string ""0"", next, the number is coerced into a string (""1""). Number + String === String.""1"" + ""0"" === ""10"" // Yay!Specification details for +[]:This is quite a maze, but to do +[], first it is being converted to a string because that's what + says:11.4.6 Unary + OperatorThe unary + operator converts its operand to Number type.The production UnaryExpression : + UnaryExpression is evaluated as follows:Let expr be the result of evaluating UnaryExpression.Return ToNumber(GetValue(expr)).ToNumber() says:ObjectApply the following steps:Let primValue be ToPrimitive(input argument, hint String).Return ToString(primValue).ToPrimitive() says:ObjectReturn a default value for the Object. The default value of an object is retrieved by calling the [[DefaultValue]] internal method of the object, passing the optional hint PreferredType. The behaviour of the [[DefaultValue]] internal method is defined by this specification for all native ECMAScript objects in 8.12.8.[[DefaultValue]] says:8.12.8 [[DefaultValue]] (hint)When the [[DefaultValue]] internal method of O is called with hint String, the following steps are taken:Let toString be the result of calling the [[Get]] internal method of object O with argument ""toString"".If IsCallable(toString) is true then,a. Let str be the result of calling the [[Call]] internal method of toString, with O as the this value and an empty argument list.b. If str is a primitive value, return str.The .toString of an array says:15.4.4.2 Array.prototype.toString ( )When the toString method is called, the following steps are taken:Let array be the result of calling ToObject on the this value.Let func be the result of calling the [[Get]] internal method of array with argument ""join"".If IsCallable(func) is false, then let func be the standard built-in method Object.prototype.toString (15.2.4.2).Return the result of calling the [[Call]] internal method of func providing array as the this value and an empty arguments list.So +[] comes down to +"""", because [].join() === """".Again, the + is defined as:11.4.6 Unary + OperatorThe unary + operator converts its operand to Number type.The production UnaryExpression : + UnaryExpression is evaluated as follows:Let expr be the result of evaluating UnaryExpression.Return ToNumber(GetValue(expr)).ToNumber is defined for """" as:The MV of StringNumericLiteral ::: [empty] is 0.So +"""" === 0, and thus +[] === 0."
"data_i","edited Jun 13 '22 at 01:10","
        Getting the class name of an instance
    ","How do I find out the name of the class used to create an instance of an object in Python?I'm not sure if I should use the inspect module or parse the __class__ attribute.","Have you tried the __name__ attribute of the class? ie type(x).__name__ will give you the name of the class, which I think is what you want.>>> import itertools>>> x = itertools.count(0)>>> type(x).__name__'count'If you're still using Python 2, note that the above method works with new-style classes only (in Python 3+ all classes are ""new-style"" classes). Your code might use some old-style classes. The following works for both:x.__class__.__name__"
"data_i","edited Apr 26 '20 at 03:09","
        Why should I use a pointer rather than the object itself?
    ","I'm coming from a Java background and have started working with objects in C++. But one thing that occurred to me is that people often use pointers to objects rather than the objects themselves, for example this declaration:Object *myObject = new Object;rather than:Object myObject;Or instead of using a function, let's say testFunc(), like this:myObject.testFunc();we have to write:myObject->testFunc();But I can't figure out why should we do it this way. I would assume it has to do with efficiency and speed since we get direct access to the memory address. Am I right?","It's very unfortunate that you see dynamic allocation so often. That just shows how many bad C++ programmers there are.In a sense, you have two questions bundled up into one. The first is when should we use dynamic allocation (using new)? The second is when should we use pointers?The important take-home message is that you should always use the appropriate tool for the job. In almost all situations, there is something more appropriate and safer than performing manual dynamic allocation and/or using raw pointers.Dynamic allocationIn your question, you've demonstrated two ways of creating an object. The main difference is the storage duration of the object. When doing Object myObject; within a block, the object is created with automatic storage duration, which means it will be destroyed automatically when it goes out of scope. When you do new Object(), the object has dynamic storage duration, which means it stays alive until you explicitly delete it. You should only use dynamic storage duration when you need it. That is, you should always prefer creating objects with automatic storage duration when you can.The main two situations in which you might require dynamic allocation:You need the object to outlive the current scope - that specific object at that specific memory location, not a copy of it. If you're okay with copying/moving the object (most of the time you should be), you should prefer an automatic object.You need to allocate a lot of memory, which may easily fill up the stack. It would be nice if we didn't have to concern ourselves with this (most of the time you shouldn't have to), as it's really outside the purview of C++, but unfortunately, we have to deal with the reality of the systems we're developing for.When you do absolutely require dynamic allocation, you should encapsulate it in a smart pointer or some other type that performs RAII (like the standard containers). Smart pointers provide ownership semantics of dynamically allocated objects. Take a look at std::unique_ptr and std::shared_ptr, for example. If you use them appropriately, you can almost entirely avoid performing your own memory management (see the Rule of Zero).PointersHowever, there are other more general uses for raw pointers beyond dynamic allocation, but most have alternatives that you should prefer. As before, always prefer the alternatives unless you really need pointers.You need reference semantics. Sometimes you want to pass an object using a pointer (regardless of how it was allocated) because you want the function to which you're passing it to have access that that specific object (not a copy of it). However, in most situations, you should prefer reference types to pointers, because this is specifically what they're designed for. Note this is not necessarily about extending the lifetime of the object beyond the current scope, as in situation 1 above. As before, if you're okay with passing a copy of the object, you don't need reference semantics.You need polymorphism. You can only call functions polymorphically (that is, according to the dynamic type of an object) through a pointer or reference to the object. If that's the behavior you need, then you need to use pointers or references. Again, references should be preferred.You want to represent that an object is optional by allowing a nullptr to be passed when the object is being omitted. If it's an argument, you should prefer to use default arguments or function overloads. Otherwise, you should preferably use a type that encapsulates this behavior, such as std::optional (introduced in C++17 - with earlier C++ standards, use boost::optional).You want to decouple compilation units to improve compilation time. The useful property of a pointer is that you only require a forward declaration of the pointed-to type (to actually use the object, you'll need a definition). This allows you to decouple parts of your compilation process, which may significantly improve compilation time. See the Pimpl idiom.You need to interface with a C library or a C-style library. At this point, you're forced to use raw pointers. The best thing you can do is make sure you only let your raw pointers loose at the last possible moment. You can get a raw pointer from a smart pointer, for example, by using its get member function. If a library performs some allocation for you which it expects you to deallocate via a handle, you can often wrap the handle up in a smart pointer with a custom deleter that will deallocate the object appropriately."
"data_i","edited Jan 14 '20 at 18:26","
        How can I add a key/value pair to a JavaScript object?
    ","Here is my object literal:var obj = {key1: value1, key2: value2};How can I add field key3 with value3 to the object?","There are two ways to add new properties to an object:var obj = {    key1: value1,    key2: value2};Using dot notation:obj.key3 = ""value3"";Using square bracket notation:obj[""key3""] = ""value3"";The first form is used when you know the name of the property. The second form is used when the name of the property is dynamically determined. Like in this example:var getProperty = function (propertyName) {    return obj[propertyName];};getProperty(""key1"");getProperty(""key2"");getProperty(""key3"");A real JavaScript array can be constructed using either:The Array literal notation:var arr = [];The Array constructor notation:var arr = new Array();"
"data_i","edited Aug 18 '22 at 22:16","
        Meaning of @classmethod and @staticmethod for beginner
    ","What do @classmethod and @staticmethod mean in Python, and how are they different? When should I use them, why should I use them, and how should I use them?As far as I understand, @classmethod tells a class that it's a method which should be inherited into subclasses, or... something. However, what's the point of that? Why not just define the class method without adding @classmethod or @staticmethod or any @ definitions?","Though classmethod and staticmethod are quite similar, there's a slight difference in usage for both entities: classmethod must have a reference to a class object as the first parameter, whereas staticmethod can have no parameters at all.Exampleclass Date(object):        def __init__(self, day=0, month=0, year=0):        self.day = day        self.month = month        self.year = year    @classmethod    def from_string(cls, date_as_string):        day, month, year = map(int, date_as_string.split('-'))        date1 = cls(day, month, year)        return date1    @staticmethod    def is_date_valid(date_as_string):        day, month, year = map(int, date_as_string.split('-'))        return day <= 31 and month <= 12 and year <= 3999date2 = Date.from_string('11-09-2012')is_date = Date.is_date_valid('11-09-2012')ExplanationLet's assume an example of a class, dealing with date information (this will be our boilerplate):class Date(object):        def __init__(self, day=0, month=0, year=0):        self.day = day        self.month = month        self.year = yearThis class obviously could be used to store information about certain dates (without timezone information; let's assume all dates are presented in UTC).Here we have __init__, a typical initializer of Python class instances, which receives arguments as a typical instance method, having the first non-optional argument (self) that holds a reference to a newly created instance.Class MethodWe have some tasks that can be nicely done using classmethods.Let's assume that we want to create a lot of Date class instances having date information coming from an outer source encoded as a string with format 'dd-mm-yyyy'. Suppose we have to do this in different places in the source code of our project.So what we must do here is:Parse a string to receive day, month and year as three integer variables or a 3-item tuple consisting of that variable.Instantiate Date by passing those values to the initialization call.This will look like:day, month, year = map(int, string_date.split('-'))date1 = Date(day, month, year)For this purpose, C++ can implement such a feature with overloading, but Python lacks this overloading. Instead, we can use classmethod. Let's create another constructor.    @classmethod    def from_string(cls, date_as_string):        day, month, year = map(int, date_as_string.split('-'))        date1 = cls(day, month, year)        return date1date2 = Date.from_string('11-09-2012')Let's look more carefully at the above implementation, and review what advantages we have here:We've implemented date string parsing in one place and it's reusable now.Encapsulation works fine here (if you think that you could implement string parsing as a single function elsewhere, this solution fits the OOP paradigm far better).cls is the class itself, not an instance of the class. It's pretty cool because if we inherit our Date class, all children will have from_string defined also.Static methodWhat about staticmethod? It's pretty similar to classmethod but doesn't take any obligatory parameters (like a class method or instance method does).Let's look at the next use case.We have a date string that we want to validate somehow. This task is also logically bound to the Date class we've used so far, but doesn't require instantiation of it.Here is where staticmethod can be useful. Let's look at the next piece of code:    @staticmethod    def is_date_valid(date_as_string):        day, month, year = map(int, date_as_string.split('-'))        return day <= 31 and month <= 12 and year <= 3999# usage:is_date = Date.is_date_valid('11-09-2012')So, as we can see from usage of staticmethod, we don't have any access to what the class is---it's basically just a function,  called syntactically like a method, but without access to the object and its internals (fields and other methods), which classmethod does have."
"data_i","edited May 13 '22 at 11:45","
        Proper use of the IDisposable interface
    ","I know from reading Microsoft documentation that the ""primary"" use of the IDisposable interface is to clean up unmanaged resources.To me, ""unmanaged"" means things like database connections, sockets, window handles, etc.  But, I've seen code where the Dispose() method is implemented to free managed resources, which seems redundant to me, since the garbage collector should take care of that for you.For example:public class MyCollection : IDisposable{    private List<String> _theList = new List<String>();    private Dictionary<String, Point> _theDict = new Dictionary<String, Point>();    // Die, clear it up! (free unmanaged resources)    public void Dispose()    {        _theList.clear();        _theDict.clear();        _theList = null;        _theDict = null;    }}My question is, does this make the garbage collector free memory used by MyCollection any faster than it normally would?Edit:  So far people have posted some good examples of using IDisposable to clean up unmanaged resources such as database connections and bitmaps.  But suppose that _theList in the above code contained a million strings, and you wanted to free that memory now, rather than waiting for the garbage collector.  Would the above code accomplish that?","The point of Dispose is to free unmanaged resources. It needs to be done at some point, otherwise they will never be cleaned up. The garbage collector doesn't know how to call DeleteHandle() on a variable of type IntPtr, it doesn't know whether or not it needs to call DeleteHandle().Note: What is an unmanaged resource? If you found it in the Microsoft .NET Framework: it's managed. If you went poking around MSDN yourself, it's unmanaged. Anything you've used P/Invoke calls to get outside of the nice comfy world of everything available to you in the .NET Framework is unmanaged – and you're now responsible for cleaning it up.The object that you've created needs to expose some method, that the outside world can call, in order to clean up unmanaged resources. The method can be named whatever you like:public void Cleanup()orpublic void Shutdown()But instead there is a standardized name for this method:public void Dispose()There was even an interface created, IDisposable, that has just that one method:public interface IDisposable{   void Dispose()}So you make your object expose the IDisposable interface, and that way you promise that you've written that single method to clean up your unmanaged resources:public void Dispose(){   Win32.DestroyHandle(this.CursorFileBitmapIconServiceHandle);}And you're done. Except you can do better.What if your object has allocated a 250MB System.Drawing.Bitmap (i.e. the .NET managed Bitmap class) as some sort of frame buffer? Sure, this is a managed .NET object, and the garbage collector will free it. But do you really want to leave 250MB of memory just sitting there – waiting for the garbage collector to eventually come along and free it? What if there's an open database connection? Surely we don't want that connection sitting open, waiting for the GC to finalize the object.If the user has called Dispose() (meaning they no longer plan to use the object) why not get rid of those wasteful bitmaps and database connections?So now we will:get rid of unmanaged resources (because we have to), andget rid of managed resources (because we want to be helpful)So let's update our Dispose() method to get rid of those managed objects:public void Dispose(){   //Free unmanaged resources   Win32.DestroyHandle(this.CursorFileBitmapIconServiceHandle);   //Free managed resources too   if (this.databaseConnection != null)   {      this.databaseConnection.Dispose();      this.databaseConnection = null;   }   if (this.frameBufferImage != null)   {      this.frameBufferImage.Dispose();      this.frameBufferImage = null;   }}And all is good, except you can do better!What if the person forgot to call Dispose() on your object? Then they would leak some unmanaged resources!Note: They won't leak managed resources, because eventually the garbage collector is going to run, on a background thread, and free the memory associated with any unused objects. This will include your object, and any managed objects you use (e.g. the Bitmap and the DbConnection).If the person forgot to call Dispose(), we can still save their bacon! We still have a way to call it for them: when the garbage collector finally gets around to freeing (i.e. finalizing) our object.Note: The garbage collector will eventually free all managed objects.When it does, it calls the Finalizemethod on the object. The GC doesn't know, orcare, about your Dispose method.That was just a name we chose fora method we call when we want to getrid of unmanaged stuff.The destruction of our object by the Garbage collector is the perfect time to free those pesky unmanaged resources. We do this by overriding the Finalize() method.Note: In C#, you don't explicitly override the Finalize() method.You write a method that looks like a C++ destructor, and thecompiler takes that to be your implementation of the Finalize() method:~MyObject(){    //we're being finalized (i.e. destroyed), call Dispose in case the user forgot to    Dispose(); //<--Warning: subtle bug! Keep reading!}But there's a bug in that code. You see, the garbage collector runs on a background thread; you don't know the order in which two objects are destroyed. It is entirely possible that in your Dispose() code, the managed object you're trying to get rid of (because you wanted to be helpful) is no longer there:public void Dispose(){   //Free unmanaged resources   Win32.DestroyHandle(this.gdiCursorBitmapStreamFileHandle);   //Free managed resources too   if (this.databaseConnection != null)   {      this.databaseConnection.Dispose(); //<-- crash, GC already destroyed it      this.databaseConnection = null;   }   if (this.frameBufferImage != null)   {      this.frameBufferImage.Dispose(); //<-- crash, GC already destroyed it      this.frameBufferImage = null;   }}So what you need is a way for Finalize() to tell Dispose() that it should not touch any managed resources (because they might not be there anymore), while still freeing unmanaged resources.The standard pattern to do this is to have Finalize() and Dispose() both call a third(!) method; where you pass a Boolean saying if you're calling it from Dispose() (as opposed to Finalize()), meaning it's safe to free managed resources.This internal method could be given some arbitrary name like ""CoreDispose"", or ""MyInternalDispose"", but is tradition to call it Dispose(Boolean):protected void Dispose(Boolean disposing)But a more helpful parameter name might be:protected void Dispose(Boolean itIsSafeToAlsoFreeManagedObjects){   //Free unmanaged resources   Win32.DestroyHandle(this.CursorFileBitmapIconServiceHandle);   //Free managed resources too, but only if I'm being called from Dispose   //(If I'm being called from Finalize then the objects might not exist   //anymore   if (itIsSafeToAlsoFreeManagedObjects)     {          if (this.databaseConnection != null)      {         this.databaseConnection.Dispose();         this.databaseConnection = null;      }      if (this.frameBufferImage != null)      {         this.frameBufferImage.Dispose();         this.frameBufferImage = null;      }   }}And you change your implementation of the IDisposable.Dispose() method to:public void Dispose(){   Dispose(true); //I am calling you from Dispose, it's safe}and your finalizer to:~MyObject(){   Dispose(false); //I am *not* calling you from Dispose, it's *not* safe}Note: If your object descends from an object that implements Dispose, then don't forget to call their base Dispose method when you override Dispose:public override void Dispose(){    try    {        Dispose(true); //true: safe to free managed resources    }    finally    {        base.Dispose();    }}And all is good, except you can do better!If the user calls Dispose() on your object, then everything has been cleaned up. Later on, when the garbage collector comes along and calls Finalize, it will then call Dispose again.Not only is this wasteful, but if your object has junk references to objects you already disposed of from the last call to Dispose(), you'll try to dispose them again!You'll notice in my code I was careful to remove references to objects that I've disposed, so I don't try to call Dispose on a junk object reference. But that didn't stop a subtle bug from creeping in.When the user calls Dispose(): the handle CursorFileBitmapIconServiceHandle is destroyed. Later when the garbage collector runs, it will try to destroy the same handle again.protected void Dispose(Boolean iAmBeingCalledFromDisposeAndNotFinalize){   //Free unmanaged resources   Win32.DestroyHandle(this.CursorFileBitmapIconServiceHandle); //<--double destroy    ...}The way you fix this is tell the garbage collector that it doesn't need to bother finalizing the object – its resources have already been cleaned up, and no more work is needed. You do this by calling GC.SuppressFinalize() in the Dispose() method:public void Dispose(){   Dispose(true); //I am calling you from Dispose, it's safe   GC.SuppressFinalize(this); //Hey, GC: don't bother calling finalize later}Now that the user has called Dispose(), we have:freed unmanaged resourcesfreed managed resourcesThere's no point in the GC running the finalizer – everything's taken care of.Couldn't I use Finalize to cleanup unmanaged resources?The documentation for Object.Finalize says:The Finalize method is used to perform cleanup operations on unmanaged resources held by the current object before the object is destroyed.But the MSDN documentation also says, for IDisposable.Dispose:Performs application-defined tasks associated with freeing, releasing, or resetting unmanaged resources.So which is it? Which one is the place for me to cleanup unmanaged resources? The answer is:It's your choice! But choose Dispose.You certainly could place your unmanaged cleanup in the finalizer:~MyObject(){   //Free unmanaged resources   Win32.DestroyHandle(this.CursorFileBitmapIconServiceHandle);   //A C# destructor automatically calls the destructor of its base class.}The problem with that is you have no idea when the garbage collector will get around to finalizing your object. Your un-managed, un-needed, un-used native resources will stick around until the garbage collector eventually runs. Then it will call your finalizer method; cleaning up unmanaged resources. The documentation of Object.Finalize points this out:The exact time when the finalizer executes is undefined. To ensure deterministic release of resources for instances of your class, implement a Close method or provide a IDisposable.Dispose implementation.This is the virtue of using Dispose to cleanup unmanaged resources; you get to know, and control, when unmanaged resource are cleaned up. Their destruction is ""deterministic"".To answer your original question: Why not release memory now, rather than for when the GC decides to do it? I have a facial recognition software that needs to get rid of 530 MB of internal images now, since they're no longer needed. When we don't: the machine grinds to a swapping halt.Bonus ReadingFor anyone who likes the style of this answer (explaining the why, so the how becomes obvious), I suggest you read Chapter One of Don Box's Essential COM:Direct link: Chapter 1 sample by Pearson Publishingmagnet: 84bf0b960936d677190a2be355858e80ef7542c0In 35 pages he explains the problems of using binary objects, and invents COM before your eyes. Once you realize the why of COM, the remaining 300 pages are obvious, and just detail Microsoft's implementation.I think every programmer who has ever dealt with objects or COM should, at the very least, read the first chapter. It is the best explanation of anything ever.Extra Bonus ReadingWhen everything you know is wrong archiveby Eric LippertIt is therefore very difficult indeed to write a correct finalizer,and the best advice I can give you is to not try."
"data_i","edited Jun 20 '22 at 09:24","
        How do I clone a subdirectory only of a Git repository?
    ","I have my Git repository which, at the root, has two sub directories:/finisht/staticWhen this was in SVN, /finisht was checked out in one place, while /static was checked out elsewhere, like so:svn co svn+ssh://admin@domain.example/home/admin/repos/finisht/static staticIs there a way to do this with Git?","What you are trying to do is called a sparse checkout, and that feature was added in Git 1.7.0 (Feb. 2012). The steps to do a sparse clone are as follows:mkdir <repo>cd <repo>git initgit remote add -f origin <url>This creates an empty repository with your remote, and fetches all objects but doesn't check them out. Then do:git config core.sparseCheckout trueNow you need to define which files/folders you want to actually check out. This is done by listing them in .git/info/sparse-checkout, eg:echo ""some/dir/"" >> .git/info/sparse-checkoutecho ""another/sub/tree"" >> .git/info/sparse-checkoutLast but not least, update your empty repo with the state from the remote:git pull origin masterYou will now have files ""checked out"" for some/dir and another/sub/tree on your file system (with those paths still), and no other paths present.You might want to have a look at the extended tutorial and you should probably read the official documentation for sparse checkout and read-tree.As a function:function git_sparse_clone() (  rurl=""$1"" localdir=""$2"" && shift 2  mkdir -p ""$localdir""  cd ""$localdir""  git init  git remote add -f origin ""$rurl""  git config core.sparseCheckout true  # Loops over remaining args  for i; do    echo ""$i"" >> .git/info/sparse-checkout  done  git pull origin master)Usage:git_sparse_clone ""http://github.com/tj/n"" ""./local/location"" ""/bin""Note that this will still download the whole repository from the server – only the checkout is reduced in size. At the moment it is not possible to clone only a single directory. But if you don't need the history of the repository, you can at least save on bandwidth by creating a shallow clone. See udondan's answer below for information on how to combine shallow clone and sparse checkout.As of Git 2.25.0 (Jan 2020) an experimental sparse-checkout command is added in Git:git sparse-checkout init# same as:# git config core.sparseCheckout truegit sparse-checkout set ""A/B""# same as:# echo ""A/B"" >> .git/info/sparse-checkoutgit sparse-checkout list# same as:# cat .git/info/sparse-checkout"
"data_i","edited Jul 08 '22 at 21:40","
         vs. . Which to use?
    ","When looking at most sites (including SO), most of them use:<input type=""button"" />instead of:<button></button>What are the main differences between the two, if any?Are there valid reasons to use one instead of the other?Are there valid reasons to use combine them?Does using <button> come with compatibility issues, seeing it is not very widely used?","Here's a page describing the differences (basically you can put html into a <button></button>)And another page describing why people avoid <button></button> (Hint: IE6)Another IE problem when using <button />:And while we're talking about IE, it's  got a couple of bugs related to the  width of buttons. It'll mysteriously  add extra padding when you're trying  to add styles, meaning you have to add  a tiny hack to get things under  control."
"data_i","edited Oct 18 '17 at 06:29","
        How to merge two arrays in JavaScript and de-duplicate items
    ","I have two JavaScript arrays:var array1 = [""Vijendra"",""Singh""];var array2 = [""Singh"", ""Shakya""];I want the output to be:var array3 = [""Vijendra"",""Singh"",""Shakya""];The output array should have repeated words removed.How do I merge two arrays in JavaScript so that I get only the unique items from each array in the same order they were inserted into the original arrays?","To just merge the arrays (without removing duplicates)ES5 version use Array.concat:var array1 = [""Vijendra"", ""Singh""];var array2 = [""Singh"", ""Shakya""];array1 = array1.concat(array2);console.log(array1);ES6 version use destructuringconst array1 = [""Vijendra"",""Singh""];const array2 = [""Singh"", ""Shakya""];const array3 = [...array1, ...array2];Since there is no 'built in' way to remove duplicates (ECMA-262 actually has Array.forEach which would be great for this), we have to do it manually:Array.prototype.unique = function() {    var a = this.concat();    for(var i=0; i<a.length; ++i) {        for(var j=i+1; j<a.length; ++j) {            if(a[i] === a[j])                a.splice(j--, 1);        }    }    return a;};Then, to use it:var array1 = [""Vijendra"",""Singh""];var array2 = [""Singh"", ""Shakya""];// Merges both arrays and gets unique itemsvar array3 = array1.concat(array2).unique(); This will also preserve the order of the arrays (i.e, no sorting needed).Since many people are annoyed about prototype augmentation of Array.prototype and for in loops, here is a less invasive way to use it:function arrayUnique(array) {    var a = array.concat();    for(var i=0; i<a.length; ++i) {        for(var j=i+1; j<a.length; ++j) {            if(a[i] === a[j])                a.splice(j--, 1);        }    }    return a;}var array1 = [""Vijendra"",""Singh""];var array2 = [""Singh"", ""Shakya""];    // Merges both arrays and gets unique itemsvar array3 = arrayUnique(array1.concat(array2));For those who are fortunate enough to work with browsers where ES5 is available, you can use Object.defineProperty like this:Object.defineProperty(Array.prototype, 'unique', {    enumerable: false,    configurable: false,    writable: false,    value: function() {        var a = this.concat();        for(var i=0; i<a.length; ++i) {            for(var j=i+1; j<a.length; ++j) {                if(a[i] === a[j])                    a.splice(j--, 1);            }        }        return a;    }});"
"data_i","edited Feb 24 '18 at 14:48","
        Sort a Map by values
    ","I am relatively new to Java, and often find that I need to sort a Map<Key, Value> on the values.Since the values are not unique, I find myself converting the keySet into an array, and sorting that array through array sort with a custom comparator that sorts on the value associated with the key.Is there an easier way?","Here's a generic-friendly version:public class MapUtil {    public static <K, V extends Comparable<? super V>> Map<K, V> sortByValue(Map<K, V> map) {        List<Entry<K, V>> list = new ArrayList<>(map.entrySet());        list.sort(Entry.comparingByValue());        Map<K, V> result = new LinkedHashMap<>();        for (Entry<K, V> entry : list) {            result.put(entry.getKey(), entry.getValue());        }        return result;    }}"
"data_i","edited Jun 24 '21 at 00:12","
        Select first row in each GROUP BY group?
    ","As the title suggests, I'd like to select the first row of each set of rows grouped with a GROUP BY.Specifically, if I've got a purchases table that looks like this:SELECT * FROM purchases;My Output:idcustomertotal1Joe52Sally33Joe24Sally1I'd like to query for the id of the largest purchase (total) made by each customer. Something like this:SELECT FIRST(id), customer, FIRST(total)FROM  purchasesGROUP BY customerORDER BY total DESC;Expected Output:FIRST(id)customerFIRST(total)1Joe52Sally3","DISTINCT ON is typically simplest and fastest for this in PostgreSQL.(For performance optimization for certain workloads see below.)SELECT DISTINCT ON (customer)       id, customer, totalFROM   purchasesORDER  BY customer, total DESC, id;Or shorter (if not as clear) with ordinal numbers of output columns:SELECT DISTINCT ON (2)       id, customer, totalFROM   purchasesORDER  BY 2, 3 DESC, 1;If total can be NULL, add NULLS LAST:...ORDER  BY customer, total DESC NULLS LAST, id;Works either way, but you'll want to match existing indexesdb<>fiddle hereMajor pointsDISTINCT ON is a PostgreSQL extension of the standard, where only DISTINCT on the whole SELECT list is defined.List any number of expressions in the DISTINCT ON clause, the combined row value defines duplicates. The manual:Obviously, two rows are considered distinct if they differ in at leastone column value. Null values are considered equal in thiscomparison.Bold emphasis mine.DISTINCT ON can be combined with ORDER BY. Leading expressions in ORDER BY must be in the set of expressions in DISTINCT ON, but you can rearrange order among those freely. Example.You can add additional expressions to ORDER BY to pick a particular row from each group of peers. Or, as the manual puts it:The DISTINCT ON expression(s) must match the leftmost ORDER BYexpression(s). The ORDER BY clause will normally contain additionalexpression(s) that determine the desired precedence of rows withineach DISTINCT ON group.I added id as last item to break ties:""Pick the row with the smallest id from each group sharing the highest total.""To order results in a way that disagrees with the sort order determining the first per group, you can nest above query in an outer query with another ORDER BY. Example.If total can be NULL, you most probably want the row with the greatest non-null value. Add NULLS LAST like demonstrated. See:Sort by column ASC, but NULL values first?The SELECT list is not constrained by expressions in DISTINCT ON or ORDER BY in any way:You don't have to include any of the expressions in DISTINCT ON or ORDER BY.You can include any other expression in the SELECT list. This is instrumental for replacing complex subqueries and aggregate / window functions.I tested with Postgres versions 8.3 – 15. But the feature has been there at least since version 7.1, so basically always.IndexThe perfect index for the above query would be a multi-column index spanning all three columns in matching sequence and with matching sort order:CREATE INDEX purchases_3c_idx ON purchases (customer, total DESC, id);May be too specialized. But use it if read performance for the particular query is crucial. If you have DESC NULLS LAST in the query, use the same in the index so that sort order matches and the index is perfectly applicable.Effectiveness / Performance optimizationWeigh cost and benefit before creating tailored indexes for each query. The potential of above index largely depends on data distribution.The index is used because it delivers pre-sorted data. In Postgres 9.2 or later the query can also benefit from an index only scan if the index is smaller than the underlying table. The index has to be scanned in its entirety, though. Example.For few rows per customer (high cardinality in column customer), this is very efficient. Even more so if you need sorted output anyway. The benefit shrinks with a growing number of rows per customer.Ideally, you have enough work_mem to process the involved sort step in RAM and not spill to disk. But generally setting work_mem too high can have adverse effects. Consider SET LOCAL for exceptionally big queries. Find how much you need with EXPLAIN ANALYZE. Mention of ""Disk:"" in the sort step indicates the need for more:Configuration parameter work_mem in PostgreSQL on LinuxOptimize simple query using ORDER BY date and textFor many rows per customer (low cardinality in column customer), a loose index scan (a.k.a. ""skip scan"") would be (much) more efficient, but that's not implemented up to Postgres 14. (An implementation for index-only scans is in development for Postgres 15. See here and here.)For now, there are faster query techniques to substitute for this. In particular if you have a separate table holding unique customers, which is the typical use case. But also if you don't:SELECT DISTINCT is slower than expected on my table in PostgreSQLOptimize GROUP BY query to retrieve latest row per userOptimize groupwise maximum queryQuery last N related rows per rowBenchmarksSee separate answer."
"data_i","edited Jul 25 '22 at 05:17","
        How to get just one file from another branch?
    ","I have a master branch with a file called app.js. I made changes to this file on an experiment branch.I want to apply only the changes made to app.js from experiment onto the master branch.","git checkout master               # first get back to mastergit checkout experiment -- app.js # then copy the version of app.js                                   # from branch ""experiment""See also git how to undo changes of one file?Update August 2019, Git 2.23With the new git switch and git restore commands, that would be:git switch mastergit restore --source experiment -- app.jsBy default, only the working tree is restored.If you want to update the index as well (meaning restore the file content, and add it to the index in one command):git restore --source experiment --staged --worktree -- app.js# shorter:git restore -s experiment -SW -- app.jsAs Jakub Narębski mentions in the comments:git show experiment:path/to/app.js > path/to/app.jsworks too, except that, as detailed in the SO question ""How to retrieve a single file from specific revision in Git?"", you need to use the full path from the root directory of the repo.Hence the path/to/app.js used by Jakub in his example.As Frosty mentions in the comment:you will only get the most recent state of app.jsBut, for git checkout or git show, you can actually reference any revision you want, as illustrated in the SO question ""git checkout revision of a file in git gui"":$ git show $REVISION:$FILENAME$ git checkout $REVISION -- $FILENAMEwould be the same is $FILENAME is a full path of a versioned file.$REVISION can be as shown in git rev-parse:experiment@{yesterday}:app.js # app.js as it was yesterday experiment^:app.js            # app.js on the first commit parentexperiment@{2}:app.js         # app.js two commits agoand so on.schmijos adds in the comments:you also can do this from a stash:git checkout stash -- app.jsThis is very useful if you're working on two branches and don't want to commit."
"data_i","edited Feb 09 '21 at 21:06","
        How to convert decimal to hexadecimal in JavaScript
    ","How do you convert decimal values to their hexadecimal equivalent in JavaScript?","Convert a number to a hexadecimal string with:hexString = yourNumber.toString(16);And reverse the process with:yourNumber = parseInt(hexString, 16);"
"data_i","edited Nov 26 '19 at 07:17","
        Transitions on the CSS display property
    ","I'm currently designing a CSS 'mega dropdown' menu - basically a regular CSS-only dropdown menu, but one that contains different types of content.At the moment, it appears that CSS 3 transitions don't apply to the 'display' property, i.e., you can't do any sort of transition from display: none to display: block (or any combination).Is there a way for the second-tier menu from the above example to 'fade in' when someone hovers over one of the top level menu items?I'm aware that you can use transitions on the visibility: property, but I can't think of a way to use that effectively.I've also tried using height, but that just failed miserably.I'm also aware that it's trivial to achieve this using JavaScript, but I wanted to challenge myself to use just CSS, and I think I'm coming up a little short.","You can concatenate two transitions or more, and visibility is what comes handy this time.div {  border: 1px solid #eee;}div > ul {  visibility: hidden;  opacity: 0;  transition: visibility 0s, opacity 0.5s linear;}div:hover > ul {  visibility: visible;  opacity: 1;}<div>  <ul>    <li>Item 1</li>    <li>Item 2</li>    <li>Item 3</li>  </ul></div>(Don't forget the vendor prefixes to the transition property.)More details are in this article."
"data_i","edited Apr 15 '20 at 08:11","
        Command to collapse all sections of code?
    ","In Visual Studio is there a command to collapse/expand all the sections of code in a file?","CTRL + M + O will collapse all.CTRL + M + L will expand all. (in VS 2013 - Toggle All outlining)CTRL + M + P will expand all and disable outlining.CTRL + M + M will collapse/expand the current section.CTRL + M + A will collapse all even in Html files.These controls are also in the context menu under Outlining.Right click in editor -> Outlining to find these controls.(After disabling outlining, use same steps to enable outlining.)For outlining options: Go to Tools -> Options -> Text Editor -> C# -> Advanced -> Outlining for outlining options."
"data_i","edited Aug 16 '21 at 11:14","
        How to redirect and append both standard output and standard error to a file with Bash
    ","To redirect standard output to a truncated file in Bash, I know to use:cmd > file.txtTo redirect standard output in Bash, appending to a file, I know to use:cmd >> file.txtTo redirect both standard output and standard error to a truncated file, I know to use:cmd &> file.txtHow do I redirect both standard output and standard error appending to a file? cmd &>> file.txt did not work for me.","cmd >>file.txt 2>&1Bash executes the redirects from left to right as follows:>>file.txt: Open file.txt in append mode and redirect stdout there.2>&1: Redirect stderr to ""where stdout is currently going"". In this case, that is a file opened in append mode. In other words, the &1 reuses the file descriptor which stdout currently uses."
"data_i","edited May 23 '17 at 12:26","
        Is there a reason for C#'s reuse of the variable in a foreach?
    ","When using lambda expressions or anonymous methods in C#, we have to be wary of the access to modified closure pitfall. For example:foreach (var s in strings){   query = query.Where(i => i.Prop == s); // access to modified closure   ...}Due to the modified closure, the above code will cause all of the Where clauses on the query to be based on the final value of s.As explained here, this happens because the s variable declared in foreach loop above is translated like this in the compiler:string s;while (enumerator.MoveNext()){   s = enumerator.Current;   ...}instead of like this:while (enumerator.MoveNext()){   string s;   s = enumerator.Current;   ...}As pointed out here, there are no performance advantages to declaring a variable outside the loop, and under normal circumstances the only reason I can think of for doing this is if you plan to use the variable outside the scope of the loop:string s;while (enumerator.MoveNext()){   s = enumerator.Current;   ...}var finalString = s;However variables defined in a foreach loop cannot be used outside the loop:foreach(string s in strings){}var finalString = s; // won't work: you're outside the scope.So the compiler declares the variable in a way that makes it highly prone to an error that is often difficult to find and debug, while producing no perceivable benefits.Is there something you can do with foreach loops this way that you couldn't if they were compiled with an inner-scoped variable, or is this just an arbitrary choice that was made before anonymous methods and lambda expressions were available or common, and which hasn't been revised since then?","The compiler declares the variable in a way that makes it highly prone to an error that is often difficult to find and debug, while producing no perceivable benefits.Your criticism is entirely justified.I discuss this problem in detail here:Closing over the loop variable considered harmfulIs there something you can do with foreach loops this way that you couldn't if they were compiled with an inner-scoped variable? or is this just an arbitrary choice that was made before anonymous methods and lambda expressions were available or common, and which hasn't been revised since then?The latter. The C# 1.0 specification actually did not say whether the loop variable was inside or outside the loop body, as it made no observable difference. When closure semantics were introduced in C# 2.0, the choice was made to put the loop variable outside the loop, consistent with the ""for"" loop.I think it is fair to say that all regret that decision. This is one of the worst ""gotchas"" in C#, and we are going to take the breaking change to fix it. In C# 5 the foreach loop variable will be logically inside the body of the loop, and therefore closures will get a fresh copy every time.The for loop will not be changed, and the change will not be ""back ported"" to previous versions of C#. You should therefore continue to be careful when using this idiom."
"data_i","edited Feb 23 '22 at 17:53","
        Get the last item in an array
    ","Here is my JavaScript code so far:var linkElement = document.getElementById(""BackButton"");var loc_array = document.location.href.split('/');var newT = document.createTextNode(unescape(capWords(loc_array[loc_array.length-2]))); linkElement.appendChild(newT);Currently it takes the second to last item in the array from the URL. However, I want to do a check for the last item in the array to be ""index.html"" and if so, grab the third to last item instead.","if (loc_array[loc_array.length - 1] === 'index.html') {   // do something} else {   // something else}In the event that your server serves the same file for ""index.html"" and ""inDEX.htML"" you can also use: .toLowerCase().Though, you might want to consider doing this server-side if possible: it will be cleaner and work for people without JS.EDIT - ES-2022Using ES-2022 Array.at(), the above may be written like this:if (loc_array.at(-1) === 'index.html') {   // do something} else {   // something else}"
"data_i","edited Apr 06 '20 at 13:10","
        How to randomize (shuffle) a JavaScript array?
    ","I have an array like this:var arr1 = [""a"", ""b"", ""c"", ""d""];How can I randomize / shuffle it?","The de-facto unbiased shuffle algorithm is the Fisher-Yates (aka Knuth) Shuffle.You can see a great visualization here (and the original post linked to this)function shuffle(array) {  let currentIndex = array.length,  randomIndex;  // While there remain elements to shuffle.  while (currentIndex != 0) {    // Pick a remaining element.    randomIndex = Math.floor(Math.random() * currentIndex);    currentIndex--;    // And swap it with the current element.    [array[currentIndex], array[randomIndex]] = [      array[randomIndex], array[currentIndex]];  }  return array;}// Used like sovar arr = [2, 11, 37, 42];shuffle(arr);console.log(arr);Some more info about the algorithm used."
"data_i","edited Jun 14 '13 at 19:28","
        Why do I need to do `--set-upstream` all the time?
    ","I create a new branch in Git:git branch my_branchPush it:git push origin my_branchNow say someone made some changes on the server and I want to pull from origin/my_branch. I do:git pullBut I get:You asked me to pull without telling me which branch youwant to merge with, and 'branch.my_branch.merge' inyour configuration file does not tell me, either. Pleasespecify which branch you want to use on the command line andtry again (e.g. 'git pull <repository> <refspec>').See git-pull(1) for details.If you often merge with the same branch, you may want touse something like the following in your configuration file:    [branch ""my_branch""]    remote = <nickname>    merge = <remote-ref>    [remote ""<nickname>""]    url = <url>    fetch = <refspec>See git-config(1) for details.I learned that I can make it work with:git branch --set-upstream my_branch origin/my_branchBut why do I need to do this for every branch I create? Isn't it obvious that if I push my_branch into origin/my_branch, then I would want to pull origin/my_branch into my_branch? How can I make this the default behavior?","A shortcut, which doesn't depend on remembering the syntax for git branch --set-upstream 1 is to do:git push -u origin my_branch... the first time that you push that branch. Or, to push to the current branch from a branch of the same name (handy for an alias):git push -u origin HEADYou only need to use -u once, and that sets up the association between your branch and the one at origin in the same way as git branch --set-upstream does.Personally, I think it's a good thing to have to set up that association between your branch and one on the remote explicitly.  It's just a shame that the rules are different for git push and git pull.1 It may sound silly, but I very frequently forget to specify the current branch, assuming that's the default - it's not, and the results are most confusing.Update 2012-10-11: Apparently I'm not the only person who found it easy to get wrong! Thanks to VonC for pointing out that git 1.8.0 introduces the more obvious git branch --set-upstream-to, which can be used as follows, if you're on the branch my_branch:git branch --set-upstream-to origin/my_branch... or with the short option:git branch -u origin/my_branchThis change, and its reasoning, is described in the release notes for git 1.8.0, release candidate 1:It was tempting to say git branch --set-upstream origin/master, but that tells Git to arrange the local branch origin/master to integrate with the currently checked out branch, which is highly unlikely to be what the user meant. The option is deprecated; use the new --set-upstream-to (with a short-and-sweet -u) option instead."
"data_i","edited Jul 16 '20 at 11:30","
        How can I view an old version of a file with Git?
    ","Is there a command in Git to see (either dumped to stdout, or in $PAGER or $EDITOR) a particular version of a particular file?","You can use git show with a path from the root of the repository (./ or ../ for relative pathing):$ git show REVISION:path/to/fileReplace REVISION with your actual revision (could be a Git commit SHA, a tag name, a branch name, a relative commit name, or any other way of identifying a commit in Git)For example, to view the version of file <repository-root>/src/main.c from 4 commits ago, use:$ git show HEAD~4:src/main.cGit for Windows requires forward slashes even in paths relative to the current directory.  For more information, check out the man page for git-show."
"data_i","edited Feb 14 '21 at 15:36","
        Loop inside React JSX
    ","I'm trying to do something like the following in React JSX (where ObjectRow is a separate component):<tbody>    for (var i=0; i < numrows; i++) {        <ObjectRow/>    } </tbody>I realize and understand why this isn't valid JSX, since JSX maps to function calls. However, coming from template land and being new to JSX, I am unsure how I would achieve the above (adding a component multiple times).","Think of it like you're just calling JavaScript functions. You can't use a for loop where the arguments to a function call would go:return tbody(    for (let i = 0; i < numrows; i++) {        ObjectRow()    } )See how the function tbody is being passed a for loop as an argument – leading to a syntax error.But you can make an array, and then pass that in as an argument:const rows = [];for (let i = 0; i < numrows; i++) {    rows.push(ObjectRow());}return tbody(rows);You can basically use the same structure when working with JSX:const rows = [];for (let i = 0; i < numrows; i++) {    // note: we are adding a key prop here to allow react to uniquely identify each    // element in this array. see: https://reactjs.org/docs/lists-and-keys.html    rows.push(<ObjectRow key={i} />);}return <tbody>{rows}</tbody>;Incidentally, my JavaScript example is almost exactly what that example of JSX transforms into. Play around with Babel REPL to get a feel for how JSX works."
"data_i","edited Jun 13 '22 at 01:16","
        How do I split the definition of a long string over multiple lines?
    ","I have a very long query. I would like to split it in several lines in Python. A way to do it in JavaScript would be using several sentences and joining them with a + operator (I know, maybe it's not the most efficient way to do it, but I'm not really concerned about performance in this stage, just code readability). Example:var long_string = 'some text not important. just garbage to' +                      'illustrate my example';I tried doing something similar in Python, but it didn't work, so I used \ to split the long string. However, I'm not sure if this is the only/best/pythonicest way of doing it. It looks awkward.Actual code:query = 'SELECT action.descr as ""action"", '\    'role.id as role_id,'\    'role.descr as role'\    'FROM '\    'public.role_action_def,'\    'public.role,'\    'public.record_def, '\    'public.action'\    'WHERE role.id = role_action_def.role_id AND'\    'record_def.id = role_action_def.def_id AND'\    'action.id = role_action_def.action_id AND'\    'role_action_def.account_id = ' + account_id + ' AND'\    'record_def.account_id=' + account_id + ' AND'\    'def_id=' + def_id","Are you talking about multi-line strings? Easy, use triple quotes to start and end them.s = """""" this is a very        long string if I had the        energy to type more and more ...""""""You can use single quotes too (3 of them of course at start and end) and treat the resulting string s just like any other string.NOTE: Just as with any string, anything between the starting and ending quotes becomes part of the string, so this example has a leading blank (as pointed out by @root45). This string will also contain both blanks and newlines.I.e.,:' this is a very\n        long string if I had the\n        energy to type more and more ...'Finally, one can also construct long lines in Python like this: s = (""this is a very""      ""long string too""      ""for sure ...""     )which will not include any extra blanks or newlines (this is a deliberate example showing what the effect of skipping blanks will result in):'this is a verylong string toofor sure ...'No commas required, simply place the strings to be joined together into a pair of parenthesis and be sure to account for any needed blanks and newlines."
"data_i","edited Dec 04 '18 at 18:05","
        How can I get a list of Git branches, ordered by most recent commit?
    ","I want to get a list of all the branches in a Git repository with the ""freshest"" branches at the top, where the ""freshest"" branch is the one that's been committed to most recently (and is, therefore, more likely to be one I want to pay attention to).Is there a way I can use Git to either (a) sort the list of branches by latest commit, or (b) get a list of branches together with each one's last-commit date, in some kind of machine-readable format?Worst case, I could always run git branch to get a list of all the branches, parse its output, and then git log -n 1 branchname --format=format:%ci for each one, to get each branch's commit date. But this will run on a Windows box, where spinning up a new process is relatively expensive, so launching the Git executable once per branch could get slow if there are a lot of branches. Is there a way to do all this with a single command?","Use the --sort=-committerdate option of git for-each-ref;Also available since Git 2.7.0 for git branch:Basic Usage:git for-each-ref --sort=-committerdate refs/heads/# Or using git branch (since version 2.7.0)git branch --sort=-committerdate  # DESCgit branch --sort=committerdate  # ASCResult:Advanced Usage:git for-each-ref --sort=committerdate refs/heads/ --format='%(HEAD) %(color:yellow)%(refname:short)%(color:reset) - %(color:red)%(objectname:short)%(color:reset) - %(contents:subject) - %(authorname) (%(color:green)%(committerdate:relative)%(color:reset))'Result:Pro Usage (Unix):You can put the following snippet in your ~/.gitconfig. The recentb alias accepts two arguments:refbranch: which branch the ahead and behind columns are calculated against. Default mastercount: how many recent branches to show. Default 20[alias]    # ATTENTION: All aliases prefixed with ! run in /bin/sh make sure you use sh syntax, not bash/zsh or whatever    recentb = ""!r() { refbranch=$1 count=$2; git for-each-ref --sort=-committerdate refs/heads --format='%(refname:short)|%(HEAD)%(color:yellow)%(refname:short)|%(color:bold green)%(committerdate:relative)|%(color:blue)%(subject)|%(color:magenta)%(authorname)%(color:reset)' --color=always --count=${count:-20} | while read line; do branch=$(echo \""$line\"" | awk 'BEGIN { FS = \""|\"" }; { print $1 }' | tr -d '*'); ahead=$(git rev-list --count \""${refbranch:-origin/master}..${branch}\""); behind=$(git rev-list --count \""${branch}..${refbranch:-origin/master}\""); colorline=$(echo \""$line\"" | sed 's/^[^|]*|//'); echo \""$ahead|$behind|$colorline\"" | awk -F'|' -vOFS='|' '{$5=substr($5,1,70)}1' ; done | ( echo \""ahead|behind||branch|lastcommit|message|author\\n\"" && cat) | column -ts'|';}; r""Result:"
"data_i","edited Jun 13 '22 at 01:22","
        What is the difference between venv, pyvenv, pyenv, virtualenv, virtualenvwrapper, pipenv, etc?
    ","Python 3.3 includes in its standard library the new package venv. What does it do, and how does it differ from all the other packages that match the regex (py)?(v|virtual|pip)?env?","This is my personal recommendation for beginners: start by learning virtualenv and pip, tools which work with both Python 2 and 3 and in a variety of situations, and pick up other tools once you start needing them.Now on to the answer to the question: what is the difference between these simalarly named things: venv, virtualenv, etc?PyPI packages not in the standard library:virtualenv is a very popular tool that creates isolated Python environments for Python libraries. If you're not familiar with this tool, I highly recommend learning it, as it is a very useful tool.It works by installing a bunch of files in a directory (eg: env/), and then modifying the PATH environment variable to prefix it with a custom bin directory (eg: env/bin/). An exact copy of the python or python3 binary is placed in this directory, but Python is programmed to look for libraries relative to its path first, in the environment directory. It's not part of Python's standard library, but is officially blessed by the PyPA (Python Packaging Authority). Once activated, you can install packages in the virtual environment using pip.pyenv is used to isolate Python versions. For example, you may want to test your code against Python 2.7, 3.6, 3.7 and 3.8, so you'll need a way to switch between them. Once activated, it prefixes the PATH environment variable with ~/.pyenv/shims, where there are special files matching the Python commands (python, pip). These are not copies of the Python-shipped commands; they are special scripts that decide on the fly which version of Python to run based on the PYENV_VERSION environment variable, or the .python-version file, or the ~/.pyenv/version file. pyenv also makes the process of downloading and installing multiple Python versions easier, using the command pyenv install.pyenv-virtualenv is a plugin for pyenv by the same author as pyenv, to allow you to use pyenv and virtualenv at the same time conveniently. However, if you're using Python 3.3 or later, pyenv-virtualenv will try to run python -m venv if it is available, instead of virtualenv. You can use virtualenv and pyenv together without pyenv-virtualenv, if you don't want the convenience features.virtualenvwrapper is a set of extensions to virtualenv (see docs). It gives you commands like mkvirtualenv, lssitepackages, and especially workon for switching between different virtualenv directories. This tool is especially useful if you want multiple virtualenv directories.pyenv-virtualenvwrapper is a plugin for pyenv by the same author as pyenv, to conveniently integrate virtualenvwrapper into pyenv.pipenv aims to combine Pipfile, pip and virtualenv into one command on the command-line. The virtualenv directory typically gets placed in ~/.local/share/virtualenvs/XXX, with XXX being a hash of the path of the project directory. This is different from virtualenv, where the directory is typically in the current working directory. pipenv is meant to be used when developing Python applications (as opposed to libraries). There are alternatives to pipenv, such as poetry, which I won't list here since this question is only about the packages that are similarly named.Standard library:pyvenv (not to be confused with pyenv in the previous section) is a script shipped with Python 3.3 to 3.7. It was removed from Python 3.8 as it had problems (not to mention the confusing name). Running python3 -m venv has exactly the same effect as pyvenv.venv is a package shipped with Python 3, which you can run using python3 -m venv (although for some reason some distros separate it out into a separate distro package, such as python3-venv on Ubuntu/Debian). It serves the same purpose as virtualenv, but only has a subset of its features (see a comparison here). virtualenv continues to be more popular than venv, especially since the former supports both Python 2 and 3."
"data_i","edited May 30 '18 at 11:25","
        Check existence of input argument in a Bash shell script
    ","I need to check the existence of an input argument. I have the following scriptif [ ""$1"" -gt ""-1"" ]  then echo hifiI get[: : integer expression expectedHow do I check the input argument1 first to see if it exists?","It is:if [ $# -eq 0 ]  then    echo ""No arguments supplied""fiThe $# variable will tell you the number of input arguments the script was passed.Or you can check if an argument is an empty string or not like:if [ -z ""$1"" ]  then    echo ""No argument supplied""fiThe -z switch will test if the expansion of ""$1"" is a null string or not. If it is a null string then the body is executed."
"data_i","edited Mar 22 '21 at 07:20","
        How do we control web page caching, across all browsers?
    ","Our investigations have shown us that not all browsers respect the HTTP cache directives in a uniform manner.For security reasons we do not want certain pages in our application to be cached, ever, by the web browser. This must work for at least the following browsers:Internet Explorer 6+Firefox 1.5+Safari 3+Opera 9+ChromeOur requirement came from a security test. After logging out from our website you could press the back button and view cached pages.","IntroductionThe correct minimum set of headers that works across all mentioned clients (and proxies):Cache-Control: no-cache, no-store, must-revalidatePragma: no-cacheExpires: 0The Cache-Control is per the HTTP 1.1 spec for clients and proxies (and implicitly required by some clients next to Expires). The Pragma is per the HTTP 1.0 spec for prehistoric clients. The Expires is per the HTTP 1.0 and 1.1 specs for clients and proxies. In HTTP 1.1, the Cache-Control takes precedence over Expires, so it's after all for HTTP 1.0 proxies only.If you don't care about IE6 and its broken caching when serving pages over HTTPS with only no-store, then you could omit Cache-Control: no-cache.Cache-Control: no-store, must-revalidatePragma: no-cacheExpires: 0If you don't care about IE6 nor HTTP 1.0 clients (HTTP 1.1 was introduced in 1997), then you could omit Pragma.Cache-Control: no-store, must-revalidateExpires: 0If you don't care about HTTP 1.0 proxies either, then you could omit Expires.Cache-Control: no-store, must-revalidateOn the other hand, if the server auto-includes a valid Date header, then you could theoretically omit Cache-Control too and rely on Expires only.Date: Wed, 24 Aug 2016 18:32:02 GMTExpires: 0But that may fail if e.g. the end-user manipulates the operating system date and the client software is relying on it.Other Cache-Control parameters such as max-age are irrelevant if the abovementioned Cache-Control parameters are specified. The Last-Modified header as included in most other answers here is only interesting if you actually want to cache the request, so you don't need to specify it at all.How to set it?Using PHP:header(""Cache-Control: no-cache, no-store, must-revalidate""); // HTTP 1.1.header(""Pragma: no-cache""); // HTTP 1.0.header(""Expires: 0""); // Proxies.Using Java Servlet, or Node.js:response.setHeader(""Cache-Control"", ""no-cache, no-store, must-revalidate""); // HTTP 1.1.response.setHeader(""Pragma"", ""no-cache""); // HTTP 1.0.response.setHeader(""Expires"", ""0""); // Proxies.Using ASP.NET-MVCResponse.Cache.SetCacheability(HttpCacheability.NoCache);  // HTTP 1.1.Response.Cache.AppendCacheExtension(""no-store, must-revalidate"");Response.AppendHeader(""Pragma"", ""no-cache""); // HTTP 1.0.Response.AppendHeader(""Expires"", ""0""); // Proxies.Using ASP.NET Web API:// `response` is an instance of System.Net.Http.HttpResponseMessageresponse.Headers.CacheControl = new CacheControlHeaderValue{    NoCache = true,    NoStore = true,    MustRevalidate = true};response.Headers.Pragma.ParseAdd(""no-cache"");// We can't use `response.Content.Headers.Expires` directly// since it allows only `DateTimeOffset?` values.response.Content?.Headers.TryAddWithoutValidation(""Expires"", 0.ToString()); Using ASP.NET:Response.AppendHeader(""Cache-Control"", ""no-cache, no-store, must-revalidate""); // HTTP 1.1.Response.AppendHeader(""Pragma"", ""no-cache""); // HTTP 1.0.Response.AppendHeader(""Expires"", ""0""); // Proxies.Using ASP.NET Core v3// using Microsoft.Net.Http.HeadersResponse.Headers[HeaderNames.CacheControl] = ""no-cache, no-store, must-revalidate"";Response.Headers[HeaderNames.Expires] = ""0"";Response.Headers[HeaderNames.Pragma] = ""no-cache"";Using ASP:Response.addHeader ""Cache-Control"", ""no-cache, no-store, must-revalidate"" ' HTTP 1.1.Response.addHeader ""Pragma"", ""no-cache"" ' HTTP 1.0.Response.addHeader ""Expires"", ""0"" ' Proxies.Using Ruby on Rails:headers[""Cache-Control""] = ""no-cache, no-store, must-revalidate"" # HTTP 1.1.headers[""Pragma""] = ""no-cache"" # HTTP 1.0.headers[""Expires""] = ""0"" # Proxies.Using Python/Flask:response = make_response(render_template(...))response.headers[""Cache-Control""] = ""no-cache, no-store, must-revalidate"" # HTTP 1.1.response.headers[""Pragma""] = ""no-cache"" # HTTP 1.0.response.headers[""Expires""] = ""0"" # Proxies.Using Python/Django:response[""Cache-Control""] = ""no-cache, no-store, must-revalidate"" # HTTP 1.1.response[""Pragma""] = ""no-cache"" # HTTP 1.0.response[""Expires""] = ""0"" # Proxies.Using Python/Pyramid:request.response.headerlist.extend(    (        ('Cache-Control', 'no-cache, no-store, must-revalidate'),        ('Pragma', 'no-cache'),        ('Expires', '0')    ))Using Go:responseWriter.Header().Set(""Cache-Control"", ""no-cache, no-store, must-revalidate"") // HTTP 1.1.responseWriter.Header().Set(""Pragma"", ""no-cache"") // HTTP 1.0.responseWriter.Header().Set(""Expires"", ""0"") // Proxies.Using Clojure (require Ring utils):(require '[ring.util.response :as r])(-> response  (r/header ""Cache-Control"" ""no-cache, no-store, must-revalidate"")  (r/header ""Pragma"" ""no-cache"")  (r/header ""Expires"" 0))Using Apache .htaccess file:<IfModule mod_headers.c>    Header set Cache-Control ""no-cache, no-store, must-revalidate""    Header set Pragma ""no-cache""    Header set Expires 0</IfModule>Using HTML:<meta http-equiv=""Cache-Control"" content=""no-cache, no-store, must-revalidate""><meta http-equiv=""Pragma"" content=""no-cache""><meta http-equiv=""Expires"" content=""0"">HTML meta tags vs HTTP response headersImportant to know is that when an HTML page is served over an HTTP connection, and a header is present in both the HTTP response headers and the HTML <meta http-equiv> tags, then the one specified in the HTTP response header will get precedence over the HTML meta tag. The HTML meta tag will only be used when the page is viewed from a local disk file system via a file:// URL. See also W3 HTML spec chapter 5.2.2. Take care with this when you don't specify them programmatically because the webserver can namely include some default values.Generally, you'd better just not specify the HTML meta tags to avoid confusion by starters and rely on hard HTTP response headers. Moreover, specifically those <meta http-equiv> tags are invalid in HTML5. Only the http-equiv values listed in HTML5 specification are allowed.Verifying the actual HTTP response headersTo verify the one and the other, you can see/debug them in the HTTP traffic monitor of the web browser's developer toolset. You can get there by pressing F12 in Chrome/Firefox23+/IE9+, and then opening the ""Network"" or ""Net"" tab panel, and then clicking the HTTP request of interest to uncover all detail about the HTTP request and response. The below screenshot is from Chrome:I want to set those headers on file downloads tooFirst of all, this question and answer are targeted on ""web pages"" (HTML pages), not ""file downloads"" (PDF, zip, Excel, etc). You'd better have them cached and make use of some file version identifier somewhere in the URI path or query string to force a redownload on a changed file. When applying those no-cache headers on file downloads anyway, then beware of the IE7/8 bug when serving a file download over HTTPS instead of HTTP. For detail, see IE cannot download foo.jsf. IE was not able to open this internet site. The requested site is either unavailable or cannot be found."
"data_i","edited Jun 29 '22 at 20:23","
        Vanilla JavaScript equivalent of jQuery's $.ready() - how to call a function when the page/DOM is ready for it
    ","With jQuery, we all know the wonderful .ready() function:$('document').ready(function(){});However, let's say I want to run a function that is written in standard JavaScript with no library backing it, and that I want to launch a function as soon as the page is ready to handle it. What's the proper way to approach this?I know I can do:window.onload=""myFunction()"";Or I can use the body tag:<body onload=""myFunction()"">Or I can even try at the bottom of the page after everything, but the end body or html tag like:<script type=""text/javascript"">    myFunction();</script>What is a cross-browser(old/new)-compliant method of issuing one or more functions in a manner like jQuery's $.ready()?","The simplest thing to do in the absence of a framework that does all the cross-browser compatibility for you is to just put a call to your code at the end of the body.  This is faster to execute than an onload handler because this waits only for the DOM to be ready, not for all images to load.  And, this works in every browser.<!doctype html><html><head></head><body>Your HTML here<script>// self executing function here(function() {   // your page initialization code here   // the DOM will be available here})();</script></body></html>For modern browsers (anything from IE9 and newer and any version of Chrome, Firefox or Safari), if you want to be able to implement a jQuery like $(document).ready() method that you can call from anywhere (without worrying about where the calling script is positioned), you can just use something like this:function docReady(fn) {    // see if DOM is already available    if (document.readyState === ""complete"" || document.readyState === ""interactive"") {        // call on next available tick        setTimeout(fn, 1);    } else {        document.addEventListener(""DOMContentLoaded"", fn);    }}    Usage:docReady(function() {    // DOM is loaded and ready for manipulation here});If you need full cross browser compatibility (including old versions of IE) and you don't want to wait for window.onload, then you probably should go look at how a framework like jQuery implements its $(document).ready() method.  It's fairly involved depending upon the capabilities of the browser.To give you a little idea what jQuery does (which will work wherever the script tag is placed).If supported, it tries the standard:document.addEventListener('DOMContentLoaded', fn, false);with a fallback to:window.addEventListener('load', fn, false )or for older versions of IE, it uses:document.attachEvent(""onreadystatechange"", fn);with a fallback to:window.attachEvent(""onload"", fn);And, there are some work-arounds in the IE code path that I don't quite follow, but it looks like it has something to do with frames.Here is a full substitute for jQuery's .ready() written in plain javascript:(function(funcName, baseObj) {    // The public function name defaults to window.docReady    // but you can pass in your own object and own function name and those will be used    // if you want to put them in a different namespace    funcName = funcName || ""docReady"";    baseObj = baseObj || window;    var readyList = [];    var readyFired = false;    var readyEventHandlersInstalled = false;    // call this when the document is ready    // this function protects itself against being called more than once    function ready() {        if (!readyFired) {            // this must be set to true before we start calling callbacks            readyFired = true;            for (var i = 0; i < readyList.length; i++) {                // if a callback here happens to add new ready handlers,                // the docReady() function will see that it already fired                // and will schedule the callback to run right after                // this event loop finishes so all handlers will still execute                // in order and no new ones will be added to the readyList                // while we are processing the list                readyList[i].fn.call(window, readyList[i].ctx);            }            // allow any closures held by these functions to free            readyList = [];        }    }    function readyStateChange() {        if ( document.readyState === ""complete"" ) {            ready();        }    }    // This is the one public interface    // docReady(fn, context);    // the context argument is optional - if present, it will be passed    // as an argument to the callback    baseObj[funcName] = function(callback, context) {        if (typeof callback !== ""function"") {            throw new TypeError(""callback for docReady(fn) must be a function"");        }        // if ready has already fired, then just schedule the callback        // to fire asynchronously, but right away        if (readyFired) {            setTimeout(function() {callback(context);}, 1);            return;        } else {            // add the function and context to the list            readyList.push({fn: callback, ctx: context});        }        // if document already ready to go, schedule the ready function to run        if (document.readyState === ""complete"") {            setTimeout(ready, 1);        } else if (!readyEventHandlersInstalled) {            // otherwise if we don't have event handlers installed, install them            if (document.addEventListener) {                // first choice is DOMContentLoaded event                document.addEventListener(""DOMContentLoaded"", ready, false);                // backup is window load event                window.addEventListener(""load"", ready, false);            } else {                // must be IE                document.attachEvent(""onreadystatechange"", readyStateChange);                window.attachEvent(""onload"", ready);            }            readyEventHandlersInstalled = true;        }    }})(""docReady"", window);The latest version of the code is shared publicly on GitHub at https://github.com/jfriend00/docReadyUsage:// pass a function referencedocReady(fn);// use an anonymous functiondocReady(function() {    // code here});// pass a function reference and a context// the context will be passed to the function as the first argumentdocReady(fn, context);// use an anonymous function with a contextdocReady(function(context) {    // code here that can use the context argument that was passed to docReady}, ctx);This has been tested in:IE6 and upFirefox 3.6 and upChrome 14 and upSafari 5.1 and upOpera 11.6 and upMultiple iOS devicesMultiple Android devicesWorking implementation and test bed: http://jsfiddle.net/jfriend00/YfD3C/Here's a summary of how it works:Create an IIFE (immediately invoked function expression) so we can have non-public state variables.Declare a public function docReady(fn, context)When docReady(fn, context) is called, check if the ready handler has already fired.  If so, just schedule the newly added callback to fire right after this thread of JS finishes with setTimeout(fn, 1).If the ready handler has not already fired, then add this new callback to the list of callbacks to be called later.Check if the document is already ready.  If so, execute all ready handlers.If we haven't installed event listeners yet to know when the document becomes ready, then install them now.If document.addEventListener exists, then install event handlers using .addEventListener() for both ""DOMContentLoaded"" and ""load"" events.  The ""load"" is a backup event for safety and should not be needed.If document.addEventListener doesn't exist, then install event handlers using .attachEvent() for ""onreadystatechange"" and ""onload"" events.In the onreadystatechange event, check to see if the document.readyState === ""complete"" and if so, call a function to fire all the ready handlers.In all the other event handlers, call a function to fire all the ready handlers.In the function to call all the ready handlers, check a state variable to see if we've already fired.  If we have, do nothing.  If we haven't yet been called, then loop through the array of ready functions and call each one in the order they were added.  Set a flag to indicate these have all been called so they are never executed more than once.Clear the function array so any closures they might be using can be freed.Handlers registered with docReady() are guaranteed to be fired in the order they were registered.If you call docReady(fn) after the document is already ready, the callback will be scheduled to execute as soon as the current thread of execution completes using setTimeout(fn, 1).  This allows the calling code to always assume they are async callbacks that will be called later, even if later is as soon as the current thread of JS finishes and it preserves calling order."
"data_i","edited May 11 '21 at 14:00","
        How to query MongoDB with ""like""
    ","I want to query something with SQL's like query:SELECT * FROM users  WHERE name LIKE '%m%'How can I achieve the same in MongoDB? I can't find an operator for like in the documentation.","That would have to be:db.users.find({""name"": /.*m.*/})Or, similar:db.users.find({""name"": /m/})You're looking for something that contains ""m"" somewhere (SQL's '%' operator is equivalent to regular expressions' '.*'), not something that has ""m"" anchored to the beginning of the string.Note: MongoDB uses regular expressions which are more powerful than ""LIKE"" in SQL. With regular expressions you can create any pattern that you imagine.For more information on regular expressions, refer to Regular expressions (MDN)."
"data_i","edited Jul 25 '22 at 05:11","
        Resolve Git merge conflicts in favor of their changes during a pull
    ","How do I resolve a git merge conflict in favor of pulled changes?I want to remove all conflicting changes from a working tree without having to go through all of the conflicts with git mergetool, while keeping all conflict-free changes. Preferably, I want to do this while pulling, not afterwards.","git pull -s recursive -X theirs <remoterepo or other repo>Or, simply, for the default repository:git pull -X theirsIf you're already in conflicted state...git checkout --theirs path/to/file"
"data_i","edited Jan 11 '22 at 04:07","
        Where should I put  tags in HTML markup?</a></h1>
    </div>
    <div class=""grid fw-wrap pb8 mb16 bb bc-black-075"">
        <div class=""grid--cell ws-nowrap mr16 mb8"" title=""2016-01-12 19:07:53Z"">
            <span class=""fc-light mr2"">Asked</span>
            <time itemprop=""dateCreated"" datetime=""2009-01-12T18:15:54.570"" class=""fromnow"">Jan 12 '09 at 18:15</time>
        </div>
        <div class=""grid--cell ws-nowrap mr16 mb8"">
            <span class=""fc-light mr2"">Active</span>
            <time class=""fromnow"" title=""2022-07-29T00:56:57.257"" datetime=""2022-07-29T00:56:57.257"">Jul 29 '22 at 00:56</a>
        </div>
        <div class=""grid--cell ws-nowrap mb8"" title=""Viewed 735,480 times"">
            <span class=""fc-light mr2"">Viewed</span> 7.4e+01k times
        </div>
    </div>

    <div id=""mainbar"" role=""main"" aria-label=""questions and answers"">
        <div id=""question"" class=""question"" data-questionid=""436411"" data-ownerid=""28804"" data-score=""1795"">
            
                    <div class=""post-layout"">
    <div class=""votecell post-layout--left"">
        <div class=""js-voting-container grid jc-center fd-column ai-stretch gs4 fc-black-200"" data-post-id=""436411"">
            <button class=""js-vote-up-btn grid--cell s-btn s-btn__unset c-pointer""><svg aria-hidden=""true"" class=""m0 svg-icon iconArrowUpLg"" width=""36"" height=""36"" viewBox=""0 0 36 36""><path d=""M2 26h32L18 10 2 26z""></path></svg></button>
            <div class=""js-vote-count grid--cell fc-black-500 fs-title grid fd-column ai-center"" itemprop=""upvoteCount"" data-value=""1795"">1795</div>
            
            <button class=""js-bookmark-btn s-btn s-btn__unset c-pointer py4"">
                <svg aria-hidden=""true"" class=""svg-icon iconBookmark"" width=""18"" height=""18"" viewBox=""0 0 18 18""><path d=""M6 1a2 2 0 00-2 2v14l5-4 5 4V3a2 2 0 00-2-2H6zm3.9 3.83h2.9l-2.35 1.7.9 2.77L9 7.59l-2.35 1.7.9-2.76-2.35-1.7h2.9L9 2.06l.9 2.77z""></path></svg>
                <div class=""js-bookmark-count mt4"" data-value=""909"">909</div>
            </button>
        </div>
    </div>
    <div class=""postcell post-layout--right"">
        <div class=""s-prose js-post-body"" itemprop=""text""><p>When embedding JavaScript in an HTML document, where is the proper place to put the <code>&lt;script&gt;</code> tags and included JavaScript? I seem to recall that you are not supposed to place these in the <code>&lt;head&gt;</code> section, but placing at the beginning of the <code>&lt;body&gt;</code> section is bad, too, since the JavaScript will have to be parsed before the page is rendered completely (or something like that). This seems to leave the <em>end</em> of the <code>&lt;body&gt;</code> section as a logical place for <code>&lt;script&gt;</code> tags.</p>
<p>So, where <em>is</em> the right place to put the <code>&lt;script&gt;</code> tags?</p>
<p>(This question references <a href=""../../questions/436154/why-does-the-call-to-this-jquery-function-fail-in-firefox"">this question</a>, in which it was suggested that JavaScript function calls should be moved from <code>&lt;a&gt;</code> tags to <code>&lt;script&gt;</code> tags. I'm specifically using jQuery, but more general answers are also appropriate.)</p></div>
        
        <div class=""mt24 mb12"">
            <div class=""post-taglist grid gs4 gsy fd-column"">
                <div class=""grid ps-relative"">
                    
                    <a href=""../../questions/tagged/javascript"" class=""post-tag js-gps-track"" title=""show questions tagged 'javascript'"" rel=""tag"">javascript</a>
                    
                    <a href=""../../questions/tagged/html"" class=""post-tag js-gps-track"" title=""show questions tagged 'html'"" rel=""tag"">html</a>
                    
                    <a href=""../../questions/tagged/script-tag"" class=""post-tag js-gps-track"" title=""show questions tagged 'script-tag'"" rel=""tag"">script-tag</a>
                    
                </div>
            </div>
        </div>
        
        <div class=""mb0"">
            <div class=""mt16 grid gs8 gsy fw-wrap jc-end ai-start pt4 mb16"">
                <div class=""grid--cell mr16 fl1 w96""></div>
                
                <div class=""post-signature grid--cell"">
                    
                        
                        
<div class=""s-user-card s-user-card"">
    <time class=""s-user-card--time"" datetime=""edited Jul 29 '22 at 00:56"">edited Jul 29 '22 at 00:56</time>
    <a href=""../../users/7941251/superstormer"" class=""s-avatar s-avatar__32 s-user-card--avatar"">
        <img class=""s-avatar--image"" src=""../../users/profiles/7941251.webp"" data-jdenticon-width=""32"" data-jdenticon-height=""32"" data-jdenticon-value=""SuperStormer"" />
    </a>
    <div class=""s-user-card--info"">
        <a href=""../../users/7941251/superstormer"" class=""s-user-card--link"">SuperStormer</a>
        <ul class=""s-user-card--awards"">
            <li class=""s-user-card--rep"" title=""reputation score"">4,752</li>
            <li class=""s-award-bling s-award-bling__gold"" title=""5 gold badges"">5</li>
            <li class=""s-award-bling s-award-bling__silver"" title=""20 silver badges"">20</li>
            <li class=""s-award-bling s-award-bling__bronze"" title=""32 bronze badges"">32</li>
        </ul>
    </div>
</div>

                        
                    
                </div>
                
                <div class=""post-signature  owner grid--cell"">
                    
                    
                        
<div class=""s-user-card s-user-card"">
    <time class=""s-user-card--time"" datetime=""asked Jan 12 '09 at 18:15"">asked Jan 12 '09 at 18:15</time>
    <a href=""../../users/28804/mipadi"" class=""s-avatar s-avatar__32 s-user-card--avatar"">
        <img class=""s-avatar--image"" src=""../../users/profiles/28804.webp"" data-jdenticon-width=""32"" data-jdenticon-height=""32"" data-jdenticon-value=""mipadi"" />
    </a>
    <div class=""s-user-card--info"">
        <a href=""../../users/28804/mipadi"" class=""s-user-card--link"">mipadi</a>
        <ul class=""s-user-card--awards"">
            <li class=""s-user-card--rep"" title=""reputation score"">385,646</li>
            <li class=""s-award-bling s-award-bling__gold"" title=""88 gold badges"">88</li>
            <li class=""s-award-bling s-award-bling__silver"" title=""515 silver badges"">515</li>
            <li class=""s-award-bling s-award-bling__bronze"" title=""475 bronze badges"">475</li>
        </ul>
    </div>
</div>

                    
                    
                </div>
            </div>
        </div>
    </div>
    <div class=""post-layout--right js-post-comments-component"">
        
        <div id=""comments-436411"" class=""comments js-comments-container bt bc-black-075 mt12 "" data-post-id=""436411"" data-min-length=""15"">
            <ul class=""comments-list js-comments-list"" data-remaining-comments-count=""0"" data-canpost=""false"" data-cansee=""true"" data-comments-unavailable=""false"" data-addlink-disabled=""true"">
                
                <li id=""comment-102447074"" class=""comment js-comment "" data-comment-id=""102447074"" data-comment-owner-id=""274502"" data-comment-score=""1"">
                    <div class=""js-comment-actions comment-actions"">
                        <div class=""comment-score js-comment-edit-hide"">
                            <span title=""number of 'useful comment' votes received"" class=""warm"">1</span>
                        </div>
                    </div>
                    
                    <div class=""comment-text js-comment-text-and-form"">
    <a name=""comment102447074_436411""></a>
    <div class=""comment-body js-comment-edit-hide"">
        <span class=""comment-copy"">in case you're also just looking for a simple solution and you're using some server side generator like Jekyll, i recommend including the script with it instead. so much simpler!</span>
        –&nbsp;<a href=""../../users/274502/cregox"" title=""16,997 reputation"" class=""comment-user "">cregox</a>
                <span class=""comment-date"" dir=""ltr""><a class=""comment-link"" href=""../../questions/436411/where-should-i-put-script-tags-in-html-markup#comment102447074_436411""><span title=""2019-09-20T05:17:42.643 License: CC BY-SA 4.0"" class=""relativetime-clean"">Sep 20 '19 at 05:17</span></a></span>
    </div>
</div>
                    
                </li>
                
                <li id=""comment-123839106"" class=""comment js-comment "" data-comment-id=""123839106"" data-comment-owner-id=""63550"" data-comment-score=""1"">
                    <div class=""js-comment-actions comment-actions"">
                        <div class=""comment-score js-comment-edit-hide"">
                            <span title=""number of 'useful comment' votes received"" class=""warm"">1</span>
                        </div>
                    </div>
                    
                    <div class=""comment-text js-comment-text-and-form"">
    <a name=""comment123839106_436411""></a>
    <div class=""comment-body js-comment-edit-hide"">
        <span class=""comment-copy"">If coming from a search engine looking for this: Many of the answers are not clear ***exactly where the 'script tag' should be at the end***. If the 'script' tag is ***after*** '<p>', HTML validation will result in *""[Error: Stray start tag script](https://validator.w3.org/nu/?doc=http%3A%2F%2Fpmortensen.eu%2Ftemp2%2Fscript_tag_after_ending_body_tag_but_before_ending_html_tag.html)""* (check option *""source""* and click *""check""* to see the HTML source). It should be ***before*** ''.  (The result is similar if the 'script' tag is at the very end, after the ***</p></span>
        –&nbsp;<a href=""../../users/63550/peter-mortensen"" title=""30,473 reputation"" class=""comment-user "">Peter Mortensen</a>
                <span class=""comment-date"" dir=""ltr""><a class=""comment-link"" href=""../../questions/436411/where-should-i-put-script-tags-in-html-markup#comment123839106_436411""><span title=""2021-11-21T15:22:04.513 License: CC BY-SA 4.0"" class=""relativetime-clean"">Nov 21 '21 at 15:22</span></a></span>
    </div>
</div>
                    
                </li>
                
                <li id=""comment-123841576"" class=""comment js-comment "" data-comment-id=""123841576"" data-comment-owner-id=""63550"" data-comment-score=""1"">
                    <div class=""js-comment-actions comment-actions"">
                        <div class=""comment-score js-comment-edit-hide"">
                            <span title=""number of 'useful comment' votes received"" class=""warm"">1</span>
                        </div>
                    </div>
                    
                    <div class=""comment-text js-comment-text-and-form"">
    <a name=""comment123841576_436411""></a>
    <div class=""comment-body js-comment-edit-hide"">
        <span class=""comment-copy"">This is also addressed in *[Is it wrong to place the <script> tag after the </body> tag?](https://stackoverflow.com/questions/3037725/)*.
        – Peter Mortensen
                Nov 21 '21 at 17:54
    ","Here's what happens when a browser loads a website with a <script> tag on it:Fetch the HTML page (e.g. index.html)Begin parsing the HTMLThe parser encounters a <script> tag referencing an external script file.The browser requests the script file. Meanwhile, the parser blocks and stops parsing the other HTML on your page.After some time the script is downloaded and subsequently executed.The parser continues parsing the rest of the HTML document.Step #4 causes a bad user experience. Your website basically stops loading until you've downloaded all scripts. If there's one thing that users hate it's waiting for a website to load.Why does this even happen?Any script can insert its own HTML via document.write() or other DOM manipulations. This implies that the parser has to wait until the script has been downloaded and executed before it can safely parse the rest of the document. After all, the script could have inserted its own HTML in the document.However, most JavaScript developers no longer manipulate the DOM while the document is loading. Instead, they wait until the document has been loaded before modifying it. For example:<!-- index.html --><html>    <head>        <title>My Page</title>        <script src=""my-script.js""></script>    </head>    <body>        <div id=""user-greeting"">Welcome back, user</div>    </body></html>JavaScript:// my-script.jsdocument.addEventListener(""DOMContentLoaded"", function() {    // this function runs when the DOM is ready, i.e. when the document has been parsed    document.getElementById(""user-greeting"").textContent = ""Welcome back, Bart"";});Because your browser does not know my-script.js isn't going to modify the document until it has been downloaded and executed, the parser stops parsing.Antiquated recommendationThe old approach to solving this problem was to put <script> tags at the bottom of your <body>, because this ensures the parser isn't blocked until the very end.This approach has its own problem: the browser cannot start downloading the scripts until the entire document is parsed. For larger websites with large scripts and stylesheets, being able to download the script as soon as possible is very important for performance. If your website doesn't load within 2 seconds, people will go to another website.In an optimal solution, the browser would start downloading your scripts as soon as possible, while at the same time parsing the rest of your document.The modern approachToday, browsers support the async and defer attributes on scripts. These attributes tell the browser it's safe to continue parsing while the scripts are being downloaded.async<script src=""path/to/script1.js"" async></script><script src=""path/to/script2.js"" async></script>Scripts with the async attribute are executed asynchronously. This means the script is executed as soon as it's downloaded, without blocking the browser in the meantime.This implies that it's possible that script 2 is downloaded and executed before script 1.According to http://caniuse.com/#feat=script-async, 97.78% of all browsers support this.defer<script src=""path/to/script1.js"" defer></script><script src=""path/to/script2.js"" defer></script>Scripts with the defer attribute are executed in order (i.e. first script 1, then script 2). This also does not block the browser.Unlike async scripts, defer scripts are only executed after the entire document has been loaded.According to http://caniuse.com/#feat=script-defer, 97.79% of all browsers support this. 98.06% support it at least partially.An important note on browser compatibility: in some circumstances, Internet Explorer 9 and earlier may execute deferred scripts out of order. If you need to support those browsers, please read this first!(To learn more and see some really helpful visual representations of the differences between async, defer and normal scripts check the first two links at the references section of this answer)ConclusionThe current state-of-the-art is to put scripts in the <head> tag and use the async or defer attributes. This allows your scripts to be downloaded ASAP without blocking your browser.The good thing is that your website should still load correctly on the 2% of browsers that do not support these attributes while speeding up the other 98%.Referencesasync vs defer attributesEfficiently load JavaScript with defer and asyncRemove Render-Blocking JavaScriptAsync, Defer, Modules: A Visual Cheatsheet","Just before the closing body tag, as stated on Put Scripts at the Bottom:Put Scripts at the BottomThe problem caused by scripts is that they block parallel downloads. The HTTP/1.1 specification suggests that browsers download no more than two components in parallel per hostname. If you serve your images from multiple hostnames, you can get more than two downloads to occur in parallel. While a script is downloading, however, the browser won't start any other downloads, even on different hostnames."
"data_i","edited Feb 03 '19 at 16:25","
        How do I get into a Docker container's shell?
    ","I'm getting started working with Docker. I'm using the WordPress base image and docker-compose.I'm trying to ssh into one of the containers to inspect the files/directories that were created during the initial build. I tried to run docker-compose run containername ls -la, but that didn't do anything. Even if it did, I'd rather have a console where I can traverse the directory structure, rather than run a single command. What is the right way to do this with Docker?","docker attach will let you connect to your Docker container, but this isn't really the same thing as ssh.  If your container is running a webserver, for example, docker attach will probably connect you to the stdout of the web server process.  It won't necessarily give you a shell.The docker exec command is probably what you are looking for; this will let you run arbitrary commands inside an existing container.  For example:docker exec -it <mycontainer> bashOf course, whatever command you are running must exist in the container filesystem.In the above command <mycontainer> is the name or ID of the target container.  It doesn't matter whether or not you're using docker compose; just run docker ps and use either the ID (a hexadecimal string displayed in the first column) or the name (displayed in the final column).  E.g., given:$ docker psd2d4a89aaee9        larsks/mini-httpd   ""mini_httpd -d /cont   7 days ago          Up 7 days                               web                 I can run:$ docker exec -it web ip addr1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN     link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host        valid_lft forever preferred_lft forever18: eth0: <BROADCAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP     link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.3/16 scope global eth0       valid_lft forever preferred_lft forever    inet6 fe80::42:acff:fe11:3/64 scope link        valid_lft forever preferred_lft foreverI could accomplish the same thing by running:$ docker exec -it d2d4a89aaee9 ip addrSimilarly, I could start a shell in the container;$ docker exec -it web sh/ # echo This is inside the container.This is inside the container./ # exit$"
"data_i","edited Mar 15 '19 at 19:58","
        How do you use a variable in a regular expression?
    ","I would like to create a String.replaceAll() method in JavaScript and I'm thinking that using a regex would be most terse way to do it.  However, I can't figure out how to pass a variable in to a regex.  I can do this already which will replace all the instances of ""B"" with ""A"".""ABABAB"".replace(/B/g, ""A"");But I want to do something like this:String.prototype.replaceAll = function(replaceThis, withThis) {    this.replace(/replaceThis/g, withThis);};But obviously this will only replace the text ""replaceThis""...so how do I pass this variable in to my regex string?","Instead of using the /regex\d/g syntax, you can construct a new RegExp object:var replace = ""regex\\d"";var re = new RegExp(replace,""g"");You can dynamically create regex objects this way. Then you will do:""mystring1"".replace(re, ""newstring"");"
"data_i","edited Jun 29 '20 at 18:42","
        When to use virtual destructors?
    ","I have a solid understanding of most OOP theory but the one thing that confuses me a lot is virtual destructors.I thought that the destructor always gets called no matter what and for every object in the chain.When are you meant to make them virtual and why?","Virtual destructors are useful when you might potentially delete an instance of a derived class through a pointer to base class:class Base {    // some virtual methods};class Derived : public Base{    ~Derived()    {        // Do some important cleanup    }};Here, you'll notice that I didn't declare Base's destructor to be virtual. Now, let's have a look at the following snippet:Base *b = new Derived();// use bdelete b; // Here's the problem!Since Base's destructor is not virtual and b is a Base* pointing to a Derived object, delete b has undefined behaviour:[In delete b], if the static type of the  object to be deleted is different from its dynamic type, the static  type shall be a base class of the dynamic type of the object to be  deleted and the static type shall have a virtual destructor or the  behavior is undefined.In most implementations, the call to the destructor will be resolved like any non-virtual code, meaning that the destructor of the base class will be called but not the one of the derived class, resulting in a resources leak.To sum up, always make base classes' destructors virtual when they're meant to be manipulated polymorphically.If you want to prevent the deletion of an instance through a base class pointer, you can make the base class destructor protected and nonvirtual; by doing so, the compiler won't let you call delete on a base class pointer.You can learn more about virtuality and virtual base class destructor in this article from Herb Sutter."
"data_i","edited Oct 29 '19 at 09:38","
        How to grep (search) committed code in the Git history
    ","I have deleted a file or some code in a file sometime in the past. Can I grep in the content (not in the commit messages)?A very poor solution is to grep the log:git log -p | grep <pattern>However, this doesn't return the commit hash straight away. I played around with git grep to no avail.","To search for commit content (i.e., actual lines of source, as opposed to commit messages and the like), you need to do:git grep <regexp> $(git rev-list --all)git rev-list --all | xargs git grep <expression> will work if you run into an ""Argument list too long"" error.If you want to limit the search to some subtree (for instance, ""lib/util""), you will need to pass that to the rev-list subcommand and grep as well:git grep <regexp> $(git rev-list --all -- lib/util) -- lib/utilThis will grep through all your commit text for regexp.The reason for passing the path in both commands is because rev-list will return the revisions list where all the changes to lib/util happened, but also you need to pass to grep so that it will only search in lib/util.Just imagine the following scenario: grep might find the same <regexp> on other files which are contained in the same revision returned by rev-list (even if there was no change to that file on that revision).Here are some other useful ways of searching your source:Search working tree for text matching regular expression regexp:git grep <regexp>Search working tree for lines of text matching regular expression regexp1 or regexp2:git grep -e <regexp1> [--or] -e <regexp2>Search working tree for lines of text matching regular expression regexp1 and regexp2, reporting file paths only:git grep -l -e <regexp1> --and -e <regexp2>Search working tree for files that have lines of text matching regular expression regexp1 and lines of text matching regular expression regexp2:git grep -l --all-match -e <regexp1> -e <regexp2>Search working tree for changed lines of text matching pattern:git diff --unified=0 | grep <pattern>Search all revisions for text matching regular expression regexp:git grep <regexp> $(git rev-list --all)Search all revisions between rev1 and rev2 for text matching regular expression regexp:git grep <regexp> $(git rev-list <rev1>..<rev2>)"
"data_i","edited Aug 31 '21 at 09:51","
        How can I make a UITextField move up when the keyboard is present - on starting to edit?
    ","With the iOS SDK:I have a UIView with UITextFields that bring up a keyboard. I need it to be able to:Allow scrolling of the contents of the UIScrollView to see the other text fields once the keyboard is brought upAutomatically ""jump"" (by scrolling up) or shorteningI know that I need a UIScrollView.  I've tried changing the class of my UIView to a UIScrollView, but I'm still unable to scroll the textboxes up or down.Do I need both a UIView and a UIScrollView? Does one go inside the other?What needs to be implemented in order to automatically scroll to the active text field?Ideally as much of the setup of the components as possible will be done in Interface Builder. I'd like to only write code for what needs it.Note: the UIView (or UIScrollView) that I'm working with is brought up by a tabbar (UITabBar), which needs to function as normal.I am adding the scroll bar just for when the keyboard comes up.  Even though it's not needed, I feel like it provides a better interface because then the user can scroll and change textboxes, for example.I've got it working where I change the frame size of the UIScrollView when the keyboard goes up and down. I'm simply using:-(void)textFieldDidBeginEditing:(UITextField *)textField {    //Keyboard becomes visible    scrollView.frame = CGRectMake(scrollView.frame.origin.x,                                  scrollView.frame.origin.y,    scrollView.frame.size.width,    scrollView.frame.size.height - 215 + 50);   // Resize}-(void)textFieldDidEndEditing:(UITextField *)textField {    // Keyboard will hide    scrollView.frame = CGRectMake(scrollView.frame.origin.x,                                  scrollView.frame.origin.y,                                  scrollView.frame.size.width,                                  scrollView.frame.size.height + 215 - 50); // Resize}However, this doesn't automatically ""move up"" or center the lower text fields in the visible area, which is what I would really like.","You will only need a ScrollView if the contents you have now do not fit in the iPhone screen. (If you are adding the ScrollView as the superview of the components just to make the TextField scroll up when keyboard comes up, then it's not needed.)The standard way to prevent the TextFields from being covered by the keyboard is to move the view up/down whenever the keyboard is shown.Here is some sample code:#define kOFFSET_FOR_KEYBOARD 80.0-(void)keyboardWillShow {    // Animate the current view out of the way    if (self.view.frame.origin.y >= 0)    {        [self setViewMovedUp:YES];    }    else if (self.view.frame.origin.y < 0)    {        [self setViewMovedUp:NO];    }}-(void)keyboardWillHide {    if (self.view.frame.origin.y >= 0)    {        [self setViewMovedUp:YES];    }    else if (self.view.frame.origin.y < 0)    {        [self setViewMovedUp:NO];    }}-(void)textFieldDidBeginEditing:(UITextField *)sender{    if ([sender isEqual:mailTf])    {        //move the main view, so that the keyboard does not hide it.        if  (self.view.frame.origin.y >= 0)        {            [self setViewMovedUp:YES];        }    }}//method to move the view up/down whenever the keyboard is shown/dismissed-(void)setViewMovedUp:(BOOL)movedUp{    [UIView beginAnimations:nil context:NULL];    [UIView setAnimationDuration:0.3]; // if you want to slide up the view    CGRect rect = self.view.frame;    if (movedUp)    {        // 1. move the view's origin up so that the text field that will be hidden come above the keyboard         // 2. increase the size of the view so that the area behind the keyboard is covered up.        rect.origin.y -= kOFFSET_FOR_KEYBOARD;        rect.size.height += kOFFSET_FOR_KEYBOARD;    }    else    {        // revert back to the normal state.        rect.origin.y += kOFFSET_FOR_KEYBOARD;        rect.size.height -= kOFFSET_FOR_KEYBOARD;    }    self.view.frame = rect;    [UIView commitAnimations];}- (void)viewWillAppear:(BOOL)animated{    [super viewWillAppear:animated];    // register for keyboard notifications    [[NSNotificationCenter defaultCenter] addObserver:self                                         selector:@selector(keyboardWillShow)                                             name:UIKeyboardWillShowNotification                                           object:nil];    [[NSNotificationCenter defaultCenter] addObserver:self                                         selector:@selector(keyboardWillHide)                                             name:UIKeyboardWillHideNotification                                           object:nil];}- (void)viewWillDisappear:(BOOL)animated{    [super viewWillDisappear:animated];    // unregister for keyboard notifications while not visible.    [[NSNotificationCenter defaultCenter] removeObserver:self                                             name:UIKeyboardWillShowNotification                                           object:nil];    [[NSNotificationCenter defaultCenter] removeObserver:self                                             name:UIKeyboardWillHideNotification                                           object:nil];}"
"data_i","edited Jan 11 '20 at 02:11","
        What is the difference between Promises and Observables?
    ","What is the difference between Promise and Observable in Angular?An example on each would be helpful in understanding both the cases. In what scenario can we use each case?","PromiseA Promise handles a single event when an async operation completes or fails.Note: There are Promise libraries out there that support cancellation, but ES6 Promise doesn't so far.ObservableAn Observable is like a Stream (in many languages) and allows to pass zero or more events where the callback is called for each event.Often Observable is preferred over Promise because it provides the features of Promise and more. With Observable it doesn't matter if you want to handle 0, 1, or multiple events. You can utilize the same API in each case.Observable also has the advantage over Promise to be cancellable. If the result of an HTTP request to a server or some other expensive async operation isn't needed anymore, the Subscription of an Observable allows to cancel the subscription, while a Promise will eventually call the success or failed callback even when you don't need the notification or the result it provides anymore.While a Promise starts immediately, an Observable only starts if you subscribe to it. This is why Observables are called lazy.Observable provides operators like map, forEach, reduce, ... similar to an arrayThere are also powerful operators like retry(), or replay(), ... that are often quite handy.A list of operators shipped with rxjsLazy execution allows to build up a chain of operators before the observable is executed by subscribing, to do a more declarative kind of programming."
"data_i","edited Jul 19 '21 at 11:36","
        How to loop through a plain JavaScript object with the objects as members
    ","How can I loop through all members in a JavaScript object, including values that are objects?For example, how could I loop through this (accessing the ""your_name"" and ""your_message"" for each)?var validation_messages = {    ""key_1"": {        ""your_name"": ""jimmy"",        ""your_msg"": ""hello world""    },    ""key_2"": {        ""your_name"": ""billy"",        ""your_msg"": ""foo equals bar""    }}","for (var key in validation_messages) {    // skip loop if the property is from prototype    if (!validation_messages.hasOwnProperty(key)) continue;    var obj = validation_messages[key];    for (var prop in obj) {        // skip loop if the property is from prototype        if (!obj.hasOwnProperty(prop)) continue;        // your code        alert(prop + "" = "" + obj[prop]);    }}"
"data_i","edited Jun 08 '21 at 00:10","
        AddTransient, AddScoped and AddSingleton Services Differences
    ","I want to implement dependency injection (DI) in ASP.NET Core. So after adding this code to ConfigureServices method, both ways work.What is the difference between the services.AddTransient and service.AddScoped methods in ASP.NET Core?public void ConfigureServices(IServiceCollection services){    // Add framework services.    // Add application services.    services.AddTransient<IEmailSender, AuthMessageSender>();    services.AddScoped<IEmailSender, AuthMessageSender>();}","TL;DRTransient objects are always different; a new instance is provided toevery controller and every service.Scoped objects are the same within a request, but different acrossdifferent requests.Singleton objects are the same for every object and every request.For more clarification, this example from .NET documentation shows the difference:To demonstrate the difference between these lifetime and registration options, consider a simple interface that represents one or more tasks as an operation with a unique identifier, OperationId. Depending on how we configure the lifetime for this service, the container will provide either the same or different instances of the service to the requesting class. To make it clear which lifetime is being requested, we will create one type per lifetime option:using System;namespace DependencyInjectionSample.Interfaces{    public interface IOperation    {        Guid OperationId { get; }    }    public interface IOperationTransient : IOperation    {    }    public interface IOperationScoped : IOperation    {    }    public interface IOperationSingleton : IOperation    {    }    public interface IOperationSingletonInstance : IOperation    {    }}We implement these interfaces using a single class, Operation, that accepts a GUID in its constructor, or uses a new GUID if none is provided:using System;using DependencyInjectionSample.Interfaces;namespace DependencyInjectionSample.Classes{    public class Operation : IOperationTransient, IOperationScoped, IOperationSingleton, IOperationSingletonInstance    {        Guid _guid;        public Operation() : this(Guid.NewGuid())        {        }        public Operation(Guid guid)        {            _guid = guid;        }        public Guid OperationId => _guid;    }}Next, in ConfigureServices, each type is added to the container according to its named lifetime:services.AddTransient<IOperationTransient, Operation>();services.AddScoped<IOperationScoped, Operation>();services.AddSingleton<IOperationSingleton, Operation>();services.AddSingleton<IOperationSingletonInstance>(new Operation(Guid.Empty));services.AddTransient<OperationService, OperationService>();Note that the IOperationSingletonInstance service is using a specific instance with a known ID of Guid.Empty, so it will be clear when this type is in use. We have also registered an OperationService that depends on each of the other Operation types, so that it will be clear within a request whether this service is getting the same instance as the controller, or a new one, for each operation type. All this service does is expose its dependencies as properties, so they can be displayed in the view.using DependencyInjectionSample.Interfaces;namespace DependencyInjectionSample.Services{    public class OperationService    {        public IOperationTransient TransientOperation { get; }        public IOperationScoped ScopedOperation { get; }        public IOperationSingleton SingletonOperation { get; }        public IOperationSingletonInstance SingletonInstanceOperation { get; }        public OperationService(IOperationTransient transientOperation,            IOperationScoped scopedOperation,            IOperationSingleton singletonOperation,            IOperationSingletonInstance instanceOperation)        {            TransientOperation = transientOperation;            ScopedOperation = scopedOperation;            SingletonOperation = singletonOperation;            SingletonInstanceOperation = instanceOperation;        }    }}To demonstrate the object lifetimes within and between separate individual requests to the application, the sample includes an OperationsController that requests each kind of IOperation type as well as an OperationService. The Index action then displays all of the controller’s and service’s OperationId values.using DependencyInjectionSample.Interfaces;using DependencyInjectionSample.Services;using Microsoft.AspNetCore.Mvc;namespace DependencyInjectionSample.Controllers{    public class OperationsController : Controller    {        private readonly OperationService _operationService;        private readonly IOperationTransient _transientOperation;        private readonly IOperationScoped _scopedOperation;        private readonly IOperationSingleton _singletonOperation;        private readonly IOperationSingletonInstance _singletonInstanceOperation;        public OperationsController(OperationService operationService,            IOperationTransient transientOperation,            IOperationScoped scopedOperation,            IOperationSingleton singletonOperation,            IOperationSingletonInstance singletonInstanceOperation)        {            _operationService = operationService;            _transientOperation = transientOperation;            _scopedOperation = scopedOperation;            _singletonOperation = singletonOperation;            _singletonInstanceOperation = singletonInstanceOperation;        }        public IActionResult Index()        {            // ViewBag contains controller-requested services            ViewBag.Transient = _transientOperation;            ViewBag.Scoped = _scopedOperation;            ViewBag.Singleton = _singletonOperation;            ViewBag.SingletonInstance = _singletonInstanceOperation;            // Operation service has its own requested services            ViewBag.Service = _operationService;            return View();        }    }}Now two separate requests are made to this controller action:Observe which of the OperationId values varies within a request, and between requests.Transient objects are always different; a new instance is provided to every controller and every service.Scoped objects are the same within a request, but different across different requestsSingleton objects are the same for every object and every request (regardless of whether an instance is provided in ConfigureServices)"
"data_i","edited Oct 21 '18 at 07:55","
        With arrays, why is it the case that a[5] == 5[a]?
    ","As Joel points out in Stack Overflow podcast #34, in C Programming Language (aka: K & R), there is mention of this property of arrays in C: a[5] == 5[a]Joel says that it's because of pointer arithmetic but I still don't understand. Why does a[5] == 5[a]?","The C standard defines the [] operator as follows:a[b] == *(a + b)Therefore a[5] will evaluate to:*(a + 5)and 5[a] will evaluate to:*(5 + a)a is a pointer to the first element of the array. a[5] is the value that's 5 elements further from a, which is the same as *(a + 5), and from elementary school math we know those are equal (addition is commutative)."
"data_i","edited Mar 26 '18 at 06:07","
        Insert results of a stored procedure into a temporary table
    ","How do I do a SELECT * INTO [temp table] FROM [stored procedure]? Not FROM [Table] and without defining [temp table]?Select all data from BusinessLine into tmpBusLine works fine.select *into tmpBusLinefrom BusinessLineI am trying the same, but using a stored procedure that returns data, is not quite the same.select *into tmpBusLinefromexec getBusinessLineHistory '16 Mar 2009'Output message:Msg 156, Level 15, State 1, Line 2  Incorrect syntax near the keyword  'exec'.I have read several examples of creating a temporary table with the same structure as the output stored procedure, which works fine, but it would be nice to not supply any columns.","You can use OPENROWSET for this.  Have a look.  I've also included the sp_configure code to enable Ad Hoc Distributed Queries, in case it isn't already enabled.CREATE PROC getBusinessLineHistoryASBEGIN    SELECT * FROM sys.databasesENDGOsp_configure 'Show Advanced Options', 1GORECONFIGUREGOsp_configure 'Ad Hoc Distributed Queries', 1GORECONFIGUREGOSELECT * INTO #MyTempTable FROM OPENROWSET('SQLNCLI', 'Server=(local)\SQL2008;Trusted_Connection=yes;',     'EXEC getBusinessLineHistory')SELECT * FROM #MyTempTable"
"data_i","edited Feb 26 '20 at 21:01","
        Calling the base constructor in C#
    ","If I inherit from a base class and want to pass something from the constructor of the inherited class to the constructor of the base class, how do I do that?For example, if I inherit from the Exception class I want to do something like this:class MyExceptionClass : Exception{     public MyExceptionClass(string message, string extraInfo)     {         //This is where it's all falling apart         base(message);     }}Basically what I want is to be able to pass the string message to the base Exception class.","Modify your constructor to the following so that it calls the base class constructor properly:public class MyExceptionClass : Exception{    public MyExceptionClass(string message, string extrainfo) : base(message)    {        //other stuff here    }}Note that a constructor is not something that you can call anytime within a method. That's the reason you're getting errors in your call in the constructor body."
"data_i","edited May 23 '17 at 12:34","
        How does Facebook disable the browser's integrated Developer Tools?
    ","So apparently because of the recent scams, the developer tools is exploited by people to post spam and even used to ""hack"" accounts. Facebook has blocked the developer tools, and I can't even use the console.How did they do that?? One Stack Overflow post claimed that it is not possible, but Facebook has proven them wrong.Just go to Facebook and open up the developer tools, type one character into the console, and this warning pops up. No matter what you put in, it will not get executed.How is this possible?They even blocked auto-complete in the console:","I'm a security engineer at Facebook and this is my fault. We're testing this for some users to see if it can slow down some attacks where users are tricked into pasting (malicious) JavaScript code into the browser console.Just to be clear: trying to block hackers client-side is a bad idea in general;this is to protect against a specific social engineering attack.If you ended up in the test group and are annoyed by this, sorry.I tried to make the old opt-out page (now help page)  as simple as possible while still being scary enough to stop at least some of the victims.The actual code is pretty similar to @joeldixon66's link; ours is a little more complicated for no good reason.Chrome wraps all console code inwith ((console && console._commandLineAPI) || {}) {  <code goes here>}... so the site redefines console._commandLineAPI to throw:Object.defineProperty(console, '_commandLineAPI',   { get : function() { throw 'Nooo!' } })This is not quite enough (try it!), but that's themain trick.Epilogue: The Chrome team decided that defeating the console from user-side JS was a bug and fixed the issue, rendering this technique invalid. Afterwards, additional protection was added to protect users from self-xss. "
"data_i","asked Aug 07 '13 at 03:02","
        What does ""Could not find or load main class"" mean?
    ","A common problem that new Java developers experience is that their programs fail to run with the error message:  Could not find or load main class ...What does this mean, what causes it, and how should you fix it?","The java <class-name> command syntaxFirst of all, you need to understand the correct way to launch a program using the java (or javaw) command.The normal syntax1 is this:    java [ <options> ] <class-name> [<arg> ...]where <option> is a command line option (starting with a ""-"" character), <class-name> is a fully qualified Java class name, and <arg> is an arbitrary command line argument that gets passed to your application.1 - There are some other syntaxes which are described near the end of this answer.The fully qualified name (FQN) for the class is conventionally written as you would in Java source code; e.g.    packagename.packagename2.packagename3.ClassNameHowever some versions of the java command allow you to use slashes instead of periods; e.g.    packagename/packagename2/packagename3/ClassNamewhich (confusingly) looks like a file pathname, but isn't one.  Note that the term fully qualified name is standard Java terminology ... not something I just made up to confuse you :-)Here is an example of what a java command should look like:    java -Xmx100m com.acme.example.ListUsers fred joe bertThe above is going to cause the java command to do the following:Search for the compiled version of the com.acme.example.ListUsers class.Load the class.Check that the class has a main method with signature, return type and modifiers given by public static void main(String[]).  (Note, the method argument's name is NOT part of the signature.)Call that method passing it the command line arguments (""fred"", ""joe"", ""bert"") as a String[].Reasons why Java cannot find the classWhen you get the message ""Could not find or load main class ..."", that means that the first step has failed.  The java command was not able to find the class.  And indeed, the ""..."" in the message will be the fully qualified class name that java is looking for.So why might it be unable to find the class?Reason #1 - you made a mistake with the classname argumentThe first likely cause is that you may have provided the wrong class name.  (Or ... the right class name, but in the wrong form.)   Considering the example above, here are a variety of wrong ways to specify the class name:Example #1 - a simple class name:java ListUserWhen the class is declared in a package such as com.acme.example, then you must use the full classname including the package name in the java command; e.g.java com.acme.example.ListUserExample #2 - a filename or pathname rather than a class name:java ListUser.classjava com/acme/example/ListUser.classExample #3 - a class name with the casing incorrect:java com.acme.example.listuserExample #4 - a typojava com.acme.example.mistuserExample #5 - a source filename (except for Java 11 or later; see below)java ListUser.javaExample #6 - you forgot the class name entirelyjava lots of argumentsReason #2 - the application's classpath is incorrectly specifiedThe second likely cause is that the class name is correct, but that the java command cannot find the class.  To understand this, you need to understand the concept of the ""classpath"".  This is explained well by the Oracle documentation:The java command documentationSetting the Classpath.The Java Tutorial - PATH and CLASSPATHSo ... if you have specified the class name correctly, the next thing to check is that you have specified the classpath correctly:Read the three documents linked above.  (Yes ... READ them!  It is important that a Java programmer understands at least the basics of how the Java classpath mechanisms works.)Look at command line and / or the CLASSPATH environment variable that is in effect when you run the java command.  Check that the directory names and JAR file names are correct.If there are relative pathnames in the classpath, check that they resolve correctly ... from the current directory that is in effect when you run the java command.Check that the class (mentioned in the error message) can be located on the effective classpath.Note that the classpath syntax is different for Windows versus Linux and Mac OS. (The classpath separator is ; on Windows and : on the others.  If you use the wrong separator for your platform, you won't get an explicit error message.  Instead, you will get a nonexistent file or directory on the path that will be silently ignored.)Reason #2a - the wrong directory is on the classpathWhen you put a directory on the classpath, it notionally corresponds to the root of the qualified name space.  Classes are located in the directory structure beneath that root, by mapping the fully qualified name to a pathname.  So for example, if ""/usr/local/acme/classes"" is on the class path, then when the JVM looks for a class called com.acme.example.Foon, it will look for a "".class"" file with this pathname:  /usr/local/acme/classes/com/acme/example/Foon.classIf you had put ""/usr/local/acme/classes/com/acme/example"" on the classpath, then the JVM wouldn't be able to find the class.Reason #2b - the subdirectory path doesn't match the FQNIf your classes FQN is com.acme.example.Foon, then the JVM is going to look for ""Foon.class"" in the directory ""com/acme/example"":If your directory structure doesn't match the package naming as per the pattern above, the JVM won't find your class.If you attempt rename a class by moving it, that will fail as well ... but the exception stacktrace will be different.  It is liable to say something like this:Caused by: java.lang.NoClassDefFoundError: <path> (wrong name: <name>)because the FQN in the class file doesn't match what the class loader is expecting to find.To give a concrete example, supposing that:you want to run com.acme.example.Foon class,the full file path is /usr/local/acme/classes/com/acme/example/Foon.class,your current working directory is /usr/local/acme/classes/com/acme/example/,then:# wrong, FQN is neededjava Foon# wrong, there is no `com/acme/example` folder in the current working directoryjava com.acme.example.Foon# wrong, similar to abovejava -classpath . com.acme.example.Foon# fine; relative classpath setjava -classpath ../../.. com.acme.example.Foon# fine; absolute classpath setjava -classpath /usr/local/acme/classes com.acme.example.FoonNotes:The -classpath option can be shortened to -cp in most Java releases.  Check the respective manual entries for java, javac and so on.Think carefully when choosing between absolute and relative pathnames in classpaths.  Remember that a relative pathname may ""break"" if the current directory changes.Reason #2c - dependencies missing from the classpathThe classpath needs to include all of the other (non-system) classes that your application depends on.  (The system classes are located automatically, and you rarely need to concern yourself with this.)  For the main class to load correctly, the JVM needs to find:the class itself.all classes and interfaces in the superclass hierarchy (e.g. see Java class is present in classpath but startup fails with Error: Could not find or load main class)all classes and interfaces that are referred to by means of variable or variable declarations, or method call or field access expressions.(Note: the JLS and JVM specifications allow some scope for a JVM to load classes ""lazily"", and this can affect when a classloader exception is thrown.)Reason #3 - the class has been declared in the wrong packageIt occasionally happens that someone puts a source code file into thethe wrong folder in their source code tree, or they leave out the package declaration.  If you do this in an IDE, the IDE's compiler will tell you about this immediately.  Similarly if you use a decent Java build tool, the tool will run javac in a way that will detect the problem.  However, if you build your Java code by hand, you can do it in such a way that the compiler doesn't notice the problem, and the resulting "".class"" file is not in the place that you expect it to be.Still can't find the problem?There lots of things to check, and it is easy to miss something.  Try adding the -Xdiag option to the java command line (as the first thing after java).  It will output various things about class loading, and this may offer you clues as to what the real problem is.Also, consider possible problems caused by copying and pasting invisible or non-ASCII characters from websites, documents and so on.  And consider ""homoglyphs"", where two letters or symbols look the same ... but aren't.You may run into this problem if you have invalid or incorrect signatures in META-INF/*.SF. You can try opening up the .jar in your favorite ZIP editor, and removing files from META-INF until all you have is your MANIFEST.MF.  However this is NOT RECOMMENDED in general.  (The invalid signature may be the result of someone having injected malware into the original signed JAR file.  If you erase the invalid signature, you are in infecting your application with the malware!)  The recommended approach is to get hold of JAR files with valid signatures, or rebuild them from the (authentic) original source code.Finally, you can apparently run into this problem if there is a syntax error in the MANIFEST.MF file (see https://stackoverflow.com/a/67145190/139985).Alternative syntaxes for javaThere are three alternative syntaxes for the launching Java programs using the java command.The syntax used for launching an ""executable"" JAR file is as follows:java [ <options> ] -jar <jar-file-name> [<arg> ...]e.g.java -Xmx100m -jar /usr/local/acme-example/listuser.jar fredThe name of the entry-point class (i.e. com.acme.example.ListUser) and the classpath are specified in the MANIFEST of the JAR file.The syntax for launching an application from a module (Java 9 and later) is as follows:java [ <options> ] --module <module>[/<mainclass>] [<arg> ...]The name of the entrypoint class is either defined by the <module> itself, or is given by the optional <mainclass>.From Java 11 onwards, you can use the java command to compile and run a single source code file using the following syntax:java [ <options> ] <sourcefile> [<arg> ...]where <sourcefile> is (typically) a file with the suffix "".java"".For more details, please refer to the official documentation for the java command for the Java release that you are using.IDEsA typical Java IDE has support for running Java applications in the IDE JVM itself or in a child JVM.  These are generally immune from this particular exception, because the IDE uses its own mechanisms to construct the runtime classpath, identify the main class and create the java command line.However it is still possible for this exception to occur, if you do things behind the back of the IDE.  For example, if you have previously set up an Application Launcher for your Java app in Eclipse, and you then moved the JAR file containing the ""main"" class to a different place in the file system without telling Eclipse, Eclipse would unwittingly launch the JVM with an incorrect classpath.In short, if you get this problem in an IDE, check for things like stale IDE state, broken project references or broken launcher configurations.It is also possible for an IDE to simply get confused.  IDE's are hugely complicated pieces of software comprising many interacting parts.  Many of these parts adopt various caching strategies in order to make the IDE as a whole responsive.  These can sometimes go wrong, and one possible symptom is problems when launching applications.  If you suspect this could be happening, it is worth trying other things like restarting your IDE, rebuilding the project and so on.Other ReferencesFrom the Oracle Java Tutorials - Common Problems (and Their Solutions)"
"data_i","edited Dec 08 '19 at 07:37","
        Redirect from an HTML page
    ","Is it possible to set up a basic HTML page to redirect to another page on load?","Try using:<meta http-equiv=""refresh"" content=""0; url=http://example.com/"" />Note: Place it in the <head> section.Additionally for older browsers if you add a quick link in case it doesn't refresh correctly:<p><a href=""http://example.com/"">Redirect</a></p>Will appear asRedirectThis will still allow you to get to where you're going with an additional click."
"data_i","edited Oct 18 '18 at 08:08","
        Generate random integers between 0 and 9
    ","How can I generate random integers between 0 and 9 (inclusive) in Python?For example, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9","Try random.randrange:from random import randrangeprint(randrange(10))"
"data_i","edited Jul 19 '19 at 16:36","
        Open files always in a new tab
    ","I am using Visual Studio Code 1.3.1 with the newly introduced tabs.When I click on files, the first file will open in a tab. If I do not make any changes to this file, the second clicked file will open in the same tab.How can I avoid this and make Visual Studio Code always open a new tab?","When you [single-]click a file in the left sidebar's file browser or open it from the quick open menu (Ctrl-P, type the file name, Enter), Visual Studio Code opens it in what's called ""Preview Mode"", which allows you to quickly view files.Preview Mode tabs are not kept open. As soon as you go to open another file from the sidebar, the existing Preview Mode tab (if one exists) is used. You can determine if a tab is in Preview Mode, by looking at its title in the tab bar. If the title is italic, the tab is in preview mode.To open a file for editing (i.e. don't open in Preview Mode), double-click on the file in the sidebar, or single-click it in the sidebar then double click the title of its Preview Mode tab.If you want to disable Preview Mode all together, you can do so by setting ""workbench.editor.enablePreview"": false in your settings file. You can also use the ""workbench.editor.enablePreviewFromQuickOpen"" option to disable it only from the quick open menu.Before you can disable Preview Mode, you'll need to open your Settings File.Pro Tip: You can use the Command Palette(shortcut Ctrl+Shift+P) to open your settings file, just enter ""Preferences: Open User Settings""!Once you've opened your settings file (your settings file should be located on the right), add the ""workbench.editor.enablePreview"" property, and set its value to false.You can learn more about Visual Studio Code's ""Preview Mode"", here."
"data_i","edited Jun 02 '21 at 14:26","
        Git push requires username and password
    ","I cloned a Git repository from my GitHub account to my PC.I want to work with both my PC and laptop, but with one GitHub account.When I try to push to or pull from GitHub using my PC, it requires a username and password, but not when I'm using the laptop!I don't want to type my username and password every time I interact with origin. What am I missing here?","A common cause is cloning using the default (HTTPS) instead of SSH. You can correct this by going to your repository, clicking ""Clone or download"", then clicking the ""Use SSH"" button above the URL field and updating the URL of your origin remote like this:git remote set-url origin git@github.com:username/repo.gitYou can check if you have added the remote as HTTPS or SSH using:git remote -vThis is documented at GitHub: Switching remote URLs from HTTPS to SSH."
"data_i","edited Apr 12 '21 at 01:58","
        Pretty Git branch graphs
    ","I've seen some books and articles have some really pretty looking graphs of Git branches and commits. How can I make high-quality printable images of Git history?","Update 2: I've posted an improved version of this answer to the Visualizing branch topology in Git question, since it's far more appropriate there.  That version includes lg3, which shows both the author and committer info, so you really should check it out.  Leaving this answer for historical (& rep, I'll admit) reasons, though I'm really tempted to just delete it.My two cents: I have two aliases I normally throw in my ~/.gitconfig file:[alias]lg1 = log --graph --abbrev-commit --decorate --format=format:'%C(bold blue)%h%C(reset) - %C(bold green)(%ar)%C(reset) %C(white)%s%C(reset) %C(dim white)- %an%C(reset)%C(bold yellow)%d%C(reset)' --alllg2 = log --graph --abbrev-commit --decorate --format=format:'%C(bold blue)%h%C(reset) - %C(bold cyan)%aD%C(reset) %C(bold green)(%ar)%C(reset)%C(bold yellow)%d%C(reset)%n''          %C(white)%s%C(reset) %C(dim white)- %an%C(reset)' --alllg = !""git lg1""git lg/git lg1 looks like this:and git lg2 looks like this:(Note: There now exists much more applicable answers to this question, such as fracz's, Jubobs', or Harry Lee's!)"
"data_i","edited Apr 03 '22 at 19:58","
        Installing specific package version with pip
    ","I am trying to install version 1.2.2 of MySQL_python, using a fresh virtualenv created with the --no-site-packages option. The current version shown in PyPi is 1.2.3. Is there a way to install the older version? I have tried:pip install MySQL_python==1.2.2However, when installed, it still shows MySQL_python-1.2.3-py2.6.egg-info in the site packages. Is this a problem specific to this package, or am I doing something wrong?","TL;DR:pip install -Iv (i.e. pip install -Iv MySQL_python==1.2.2)What these options mean:-I stands for --ignore-installed which will ignore the installed packages, overwriting them.-v is for verbose. You can combine for even more verbosity (i.e. -vv) up to 3 times (e.g. -Ivvv).For more information, see pip install --helpFirst, I see two issues with what you're trying to do. Since you already have an installed version, you should either uninstall the current existing driver or use pip install -I MySQL_python==1.2.2However, you'll soon find out that this doesn't work. If you look at pip's installation log, or if you do a pip install -Iv MySQL_python==1.2.2 you'll find that the PyPI URL link does not work for MySQL_python v1.2.2. You can verify this here: http://pypi.python.org/pypi/MySQL-python/1.2.2The download link 404s and the fallback URL links are re-directing infinitely due to sourceforge.net's recent upgrade and PyPI's stale URL.So to properly install the driver, you can follow these steps:pip uninstall MySQL_pythonpip install -Iv http://sourceforge.net/projects/mysql-python/files/mysql-python/1.2.2/MySQL-python-1.2.2.tar.gz/download"
"data_i","edited Feb 02 '19 at 14:21","
        What does enctype='multipart/form-data' mean?
    ","What does enctype='multipart/form-data' mean in an HTML form and when should we use it?","When you make a POST request, you have to encode the data that forms the body of the request in some way.HTML forms provide three methods of encoding.application/x-www-form-urlencoded (the default)multipart/form-datatext/plainWork was being done on adding application/json, but that has been abandoned.(Other encodings are possible with HTTP requests generated using other means than an HTML form submission. JSON is a common format for use with web services and some still use SOAP.)The specifics of the formats don't matter to most developers. The important points are:Never use text/plain.When you are writing client-side code:use multipart/form-data when your form includes any <input type=""file""> elementsotherwise you can use multipart/form-data or application/x-www-form-urlencoded but application/x-www-form-urlencoded will be more efficientWhen you are writing server-side code:Use a prewritten form handling libraryMost (such as Perl's CGI->param or the one exposed by PHP's $_POST superglobal) will take care of the differences for you. Don't bother trying to parse the raw input received by the server.Sometimes you will find a library that can't handle both formats.  Node.js's most popular library for handling form data is body-parser which cannot handle multipart requests (but has documentation that recommends some alternatives which can).If you are writing (or debugging) a library for parsing or generating the raw data, then you need to start worrying about the format. You might also want to know about it for interest's sake.application/x-www-form-urlencoded is more or less the same as a query string on the end of the URL.multipart/form-data is significantly more complicated but it allows entire files to be included in the data. An example of the result can be found in the HTML 4 specification.text/plain is introduced by HTML 5 and is useful only for debugging — from the spec: They are not reliably interpretable by computer — and I'd argue that the others combined with tools (like the Network Panel in the developer tools of most browsers) are better for that)."
"data_i","asked Jan 01 '15 at 15:47","
        Turning off eslint rule for a specific line
    ","In order to turn off linting rule for a particular line in JSHint we use the following rule:/* jshint ignore:start*/$scope.someVar = ConstructorFunction();/* jshint ignore:end */I have been trying to locate the equivalent of the above for eslint. ","To disable next line:// eslint-disable-next-line no-use-before-definevar thing = new Thing();Or use the single line syntax:var thing = new Thing(); // eslint-disable-line no-use-before-defineSee the eslint docs"
"data_i","edited Jul 02 '21 at 07:56","
        Multiple ""order by"" in LINQ
    ","I have two tables, movies and categories, and I want to get an ordered list by categoryID first and then by Name.The movie table has three columns ID, Name and CategoryID.The category table has two columns ID and Name.I tried something like the following, but it didn't work.var movies = _db.Movies.OrderBy( m => { m.CategoryID, m.Name })","This should work for you:var movies = _db.Movies.OrderBy(c => c.Category).ThenBy(n => n.Name)"
"data_i","edited Jul 25 '22 at 03:13","
        How do I undo 'git reset'?
    ","I want to undo this command:git reset HEAD~","Short answer:git reset 'HEAD@{1}'Long answer:Git keeps a log of all ref updates (e.g., checkout, reset, commit, merge). You can view it by typing:git reflogSomewhere in this list is the commit that you lost. Let's say you just typed git reset HEAD~ and want to undo it. My reflog looks like this:$ git reflog3f6db14 HEAD@{0}: HEAD~: updating HEADd27924e HEAD@{1}: checkout: moving from d27924e0fe16776f0d0f1ee2933a0334a4787b4c[...]The first line says that HEAD 0 positions ago (in other words, the current position) is 3f6db14; it was obtained by resetting to HEAD~. The second line says that HEAD 1 position ago (in other words, the state before the reset) is d27924e. It was obtained by checking out a particular commit (though that's not important right now). So, to undo the reset, run git reset HEAD@{1} (or git reset d27924e).If, on the other hand, you've run some other commands since then that update HEAD, the commit you want won't be at the top of the list, and you'll need to search through the reflog.One final note: It may be easier to look at the reflog for the specific branch you want to un-reset, say master, rather than HEAD:$ git reflog show masterc24138b master@{0}: merge origin/master: Fast-forward90a2bf9 master@{1}: merge origin/master: Fast-forward[...]This should have less noise it in than the general HEAD reflog."
"data_i","edited Mar 04 '20 at 20:27","
        How do I prompt for Yes/No/Cancel input in a Linux shell script?
    ","I want to pause input in a shell script, and prompt the user for choices.The standard Yes, No, or Cancel type question.How do I accomplish this in a typical bash prompt?","The simplest and most widely available method to get user input at a shell prompt is the read command. The best way to illustrate its use is a simple demonstration:while true; do    read -p ""Do you wish to install this program? "" yn    case $yn in        [Yy]* ) make install; break;;        [Nn]* ) exit;;        * ) echo ""Please answer yes or no."";;    esacdoneAnother method, pointed out by Steven Huwig, is Bash's select command. Here is the same example using select:echo ""Do you wish to install this program?""select yn in ""Yes"" ""No""; do    case $yn in        Yes ) make install; break;;        No ) exit;;    esacdoneWith select you don't need to sanitize the input – it displays the available choices, and you type a number corresponding to your choice. It also loops automatically, so there's no need for a while true loop to retry if they give invalid input.Also, Léa Gris demonstrated a way to make the request language agnostic in her answer. Adapting my first example to better serve multiple languages might look like this:set -- $(locale LC_MESSAGES)yesexpr=""$1""; noexpr=""$2""; yesword=""$3""; noword=""$4""while true; do    read -p ""Install (${yesword} / ${noword})? "" yn    if [[ ""$yn"" =~ $yesexpr ]]; then make install; exit; fi    if [[ ""$yn"" =~ $noexpr ]]; then exit; fi    echo ""Answer ${yesword} / ${noword}.""doneObviously other communication strings remain untranslated here (Install, Answer) which would need to be addressed in a more fully completed translation, but even a partial translation would be helpful in many cases.Finally, please check out the excellent answer by F. Hauri."
"data_i","edited Aug 25 '20 at 20:08","
        How can I avoid Java code in JSP files, using JSP 2?
    ","I'm new to Java EE and I know that something like the following three lines<%= x+1 %><%= request.getParameter(""name"") %><%! counter++; %>is an old school way of coding and in JSP version 2 there exists a method to avoid Java code in JSP files. What are the alternative JSP 2 lines, and what is this technique called?","The use of scriptlets (those <% %> things) in JSP is indeed highly discouraged since the birth of taglibs (like JSTL) and EL (Expression Language, those ${} things) way back in 2001.The major disadvantages of scriptlets are:Reusability: you can't reuse scriptlets.Replaceability: you can't make scriptlets abstract.OO-ability: you can't make use of inheritance/composition.Debuggability: if scriptlet throws an exception halfway, all you get is a blank page.Testability: scriptlets are not unit-testable.Maintainability: per saldo more time is needed to maintain mingled/cluttered/duplicated code logic.Sun Oracle itself also recommends in the JSP coding conventions to avoid use of scriptlets whenever the same functionality is possible by (tag) classes. Here are several cites of relevance:From JSP 1.2 Specification, it is highly recommended that the JSP Standard Tag Library  (JSTL) be used in your web application to help reduce the need for JSP scriptlets in your pages. Pages that use JSTL are, in general, easier to read and maintain....Where possible, avoid JSP scriptlets whenever tag libraries provide equivalent functionality. This makes pages easier to read and maintain, helps to separate business logic from presentation logic, and will make your pages easier to evolve into JSP 2.0-style pages (JSP 2.0 Specification supports but de-emphasizes the use of scriptlets)....In the spirit of adopting the model-view-controller (MVC) design pattern to reduce coupling between the presentation tier from the business logic, JSP scriptlets should not be used for writing business logic. Rather, JSP scriptlets are used if necessary to transform data (also called ""value objects"") returned from processing the client's requests into a proper client-ready format. Even then, this would be better done with a front controller servlet or a custom tag.How to replace scriptlets entirely depends on the sole purpose of the code/logic. More than often this code is to be placed in a fullworthy Java class:If you want to invoke the same Java code on every request, less-or-more regardless of the requested page, e.g. checking if a user is logged in, then implement a filter and write code accordingly in doFilter() method. E.g.:  public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws ServletException, IOException {      if (((HttpServletRequest) request).getSession().getAttribute(""user"") == null) {          ((HttpServletResponse) response).sendRedirect(""login""); // Not logged in, redirect to login page.      } else {          chain.doFilter(request, response); // Logged in, just continue request.      }  }When mapped on an appropriate <url-pattern> covering the JSP pages of interest, then you don't need to copypaste the same piece of code overall JSP pages.If you want to invoke some Java code to process a GET request, e.g. preloading some list from a database to display in some table, if necessary based on some query parameters, then implement a servlet and write code accordingly in doGet() method. E.g.:  protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {      try {          List<Product> products = productService.list(); // Obtain all products.          request.setAttribute(""products"", products); // Store products in request scope.          request.getRequestDispatcher(""/WEB-INF/products.jsp"").forward(request, response); // Forward to JSP page to display them in a HTML table.      } catch (SQLException e) {          throw new ServletException(""Retrieving products failed!"", e);      }  }This way dealing with exceptions is easier. The DB is not accessed in the midst of JSP rendering, but far before the JSP is been displayed. You still have the possibility to change the response whenever the DB access throws an exception. In the above example, the default error 500 page will be displayed which you can anyway customize by an <error-page> in web.xml.If you want to invoke some Java code to process a POST request, such as gathering data from a submitted HTML form and doing some business stuff with it (conversion, validation, saving in DB, etcetera), then implement a servlet and write code accordingly in doPost() method. E.g.:  protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {      String username = request.getParameter(""username"");      String password = request.getParameter(""password"");      User user = userService.find(username, password);      if (user != null) {          request.getSession().setAttribute(""user"", user); // Login user.          response.sendRedirect(""home""); // Redirect to home page.      } else {          request.setAttribute(""message"", ""Unknown username/password. Please retry.""); // Store error message in request scope.          request.getRequestDispatcher(""/WEB-INF/login.jsp"").forward(request, response); // Forward to JSP page to redisplay login form with error.      }  }This way dealing with different result page destinations is easier: redisplaying the form with validation errors in case of an error (in this particular example you can redisplay it using ${message} in EL), or just taking to the desired target page in case of success.If you want to invoke some Java code to control the execution plan and/or the destination of the request and the response, then implement a servlet according to the MVC's Front Controller Pattern. E.g.:  protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {      try {          Action action = ActionFactory.getAction(request);          String view = action.execute(request, response);          if (view.equals(request.getPathInfo().substring(1)) {              request.getRequestDispatcher(""/WEB-INF/"" + view + "".jsp"").forward(request, response);          } else {              response.sendRedirect(view);          }      } catch (Exception e) {          throw new ServletException(""Executing action failed."", e);      }  }Or just adopt an MVC framework like JSF, Spring MVC, Wicket, etc so that you end up with just a JSP/Facelets page and a JavaBean class without the need for a custom servlet.If you want to invoke some Java code to control the flow inside a JSP page, then you need to grab an (existing) flow control taglib like JSTL core. E.g. displaying List<Product> in a table:  <%@ taglib uri=""http://java.sun.com/jsp/jstl/core"" prefix=""c"" %>  ...  <table>      <c:forEach items=""${products}"" var=""product"">          <tr>              <td>${product.name}</td>              <td>${product.description}</td>              <td>${product.price}</td>          </tr>      </c:forEach>  </table>With XML-style tags which fit nicely among all that HTML, the code is better readable (and thus better maintainable) than a bunch of scriptlets with various opening and closing braces (""Where the heck does this closing brace belong to?""). An easy aid is to configure your web application to throw an exception whenever scriptlets are still been used by adding the following piece to web.xml:  <jsp-config>      <jsp-property-group>          <url-pattern>*.jsp</url-pattern>          <scripting-invalid>true</scripting-invalid>      </jsp-property-group>  </jsp-config>In Facelets, the successor of JSP, which is part of the Java EE provided MVC framework JSF, it is already not possible to use scriptlets. This way you're automatically forced to do things ""the right way"".If you want to invoke some Java code to access and display ""backend"" data inside a JSP page, then you need to use EL (Expression Language), those ${} things. E.g. redisplaying submitted input values:  <input type=""text"" name=""foo"" value=""${param.foo}"" />The ${param.foo} displays the outcome of request.getParameter(""foo"").If you want to invoke some utility Java code directly in the JSP page (typically public static methods), then you need to define them as EL functions. There's a standard functions taglib in JSTL, but you can also easily create functions yourself. Here's an example how JSTL fn:escapeXml is useful to prevent XSS attacks.  <%@ taglib uri=""http://java.sun.com/jsp/jstl/functions"" prefix=""fn"" %>  ...  <input type=""text"" name=""foo"" value=""${fn:escapeXml(param.foo)}"" />Note that the XSS sensitivity is in no way specifically related to Java/JSP/JSTL/EL/whatever, this problem needs to be taken into account in every web application you develop. The problem of scriptlets is that it provides no way of builtin preventions, at least not using the standard Java API. JSP's successor Facelets has already implicit HTML escaping, so you don't need to worry about XSS holes in Facelets.See also:What's the difference between JSP, Servlet and JSF?How does Servlet, ServletContext, HttpSession and HttpServletRequest/Response work?Basic MVC example with JSP, Servlet and JDBCDesign patterns in Java web applicationsHidden features of JSP/Servlet"
"data_i","edited Mar 22 '17 at 16:17","
        Parse JSON in JavaScript?
    ","I want to parse a JSON string in JavaScript. The response is something likevar response = '{""result"":true,""count"":1}';How can I get the values result and count from this?","The standard way to parse JSON in JavaScript is JSON.parse()The JSON API was introduced with ES5 (2011) and has since been implemented in >99% of browsers by market share, and Node.js. Its usage is simple:const json = '{ ""fruit"": ""pineapple"", ""fingers"": 10 }';const obj = JSON.parse(json);console.log(obj.fruit, obj.fingers);The only time you won't be able to use JSON.parse() is if you are programming for an ancient browser, such as IE 7 (2006), IE 6 (2001), Firefox 3 (2008), Safari 3.x (2009), etc. Alternatively, you may be in an esoteric JavaScript environment that doesn't include the standard APIs. In these cases, use json2.js, the reference implementation of JSON written by Douglas Crockford, the inventor of JSON. That library will provide an implementation of JSON.parse().When processing extremely large JSON files, JSON.parse() may choke because of its synchronous nature and design. To resolve this, the JSON website recommends third-party libraries such as Oboe.js and clarinet, which provide streaming JSON parsing.jQuery once had a $.parseJSON() function, but it was deprecated with jQuery 3.0. In any case, for a long time, it was nothing more than a wrapper around JSON.parse()."
"data_i","edited Nov 26 '21 at 10:29","
        Is < faster than <=?
    ","Is if (a < 901) faster than if (a <= 900)?Not exactly as in this simple example, but there are slight performance changes on loop complex code. I suppose this has to do something with generated machine code in case it's even true.","No, it will not be faster on most architectures. You didn't specify, but on x86, all of the integral comparisons will be typically implemented in two machine instructions:A test or cmp instruction, which sets EFLAGSAnd a Jcc (jump) instruction, depending on the comparison type (and code layout):jne - Jump if not equal --> ZF = 0jz - Jump if zero (equal) --> ZF = 1jg - Jump if greater --> ZF = 0 and SF = OF(etc...)Example (Edited for brevity) Compiled with $ gcc -m32 -S -masm=intel test.c    if (a < b) {        // Do something 1    }Compiles to:    mov     eax, DWORD PTR [esp+24]      ; a    cmp     eax, DWORD PTR [esp+28]      ; b    jge     .L2                          ; jump if a is >= b    ; Do something 1.L2:And    if (a <= b) {        // Do something 2    }Compiles to:    mov     eax, DWORD PTR [esp+24]      ; a    cmp     eax, DWORD PTR [esp+28]      ; b    jg      .L5                          ; jump if a is > b    ; Do something 2.L5:So the only difference between the two is a jg versus a jge instruction. The two will take the same amount of time.I'd like to address the comment that nothing indicates that the different jump instructions take the same amount of time.  This one is a little tricky to answer, but here's what I can give: In the Intel Instruction Set Reference, they are all grouped together under one common instruction, Jcc (Jump if condition is met). The same grouping is made together under the Optimization Reference Manual, in Appendix C. Latency and Throughput.Latency — The number of clock cycles that are required for theexecution core to  complete the execution of all of the μops that forman instruction.Throughput — The number of clock cycles required towait before the issue  ports are free to accept the same instructionagain. For many instructions, the  throughput of an instruction can besignificantly less than its latencyThe values for Jcc are:      Latency   ThroughputJcc     N/A        0.5with the following footnote on Jcc:Selection of conditional jump instructions should be based on the recommendation of section Section 3.4.1, “Branch Prediction Optimization,” to improve the  predictability of branches. When branches are predicted successfully, the latency of jcc is effectively zero.So, nothing in the Intel docs ever treats one Jcc instruction any differently from the others.If one thinks about the actual circuitry used to implement the instructions, one can assume that there would be simple AND/OR gates on the different bits in EFLAGS, to determine whether the conditions are met. There is then, no reason that an instruction testing two bits should take any more or less time than one testing only one (Ignoring gate propagation delay, which is much less than the clock period.)Edit: Floating PointThis holds true for x87 floating point as well:  (Pretty much same code as above, but with double instead of int.)        fld     QWORD PTR [esp+32]        fld     QWORD PTR [esp+40]        fucomip st, st(1)              ; Compare ST(0) and ST(1), and set CF, PF, ZF in EFLAGS        fstp    st(0)        seta    al                     ; Set al if above (CF=0 and ZF=0).        test    al, al        je      .L2        ; Do something 1.L2:        fld     QWORD PTR [esp+32]        fld     QWORD PTR [esp+40]        fucomip st, st(1)              ; (same thing as above)        fstp    st(0)        setae   al                     ; Set al if above or equal (CF=0).        test    al, al        je      .L5        ; Do something 2.L5:        leave        ret"
"data_i","edited Aug 25 '18 at 04:17","
        Convert form data to JavaScript object with jQuery
    ","How do I convert all elements of my form to a JavaScript object? I'd like to have some way of automatically building a JavaScript object from my form, without having to loop over each element. I do not want a string, as returned by $('#formid').serialize();, nor do I want the map returned by $('#formid').serializeArray();","serializeArray already does exactly that. You just need to massage the data into your required format:function objectifyForm(formArray) {    //serialize data function    var returnArray = {};    for (var i = 0; i < formArray.length; i++){        returnArray[formArray[i]['name']] = formArray[i]['value'];    }    return returnArray;}Watch out for hidden fields which have the same name as real inputs as they will get overwritten."
"data_i","edited Mar 16 '16 at 13:48","
        How to undo ""git commit --amend"" done instead of ""git commit""
    ","I accidentally amended my previous commit. The commit should have been separate to keep history of the changes I made to a particular file.Is there a way to undo that last commit? If I do something like git reset --hard HEAD^, the first commit also is undone.(I have not yet pushed to any remote directories)","What you need to do is to create a new commit with the same details as the current HEAD commit, but with the parent as the previous version of HEAD. git reset --soft will move the branch pointer so that the next commit happens on top of a different commit from where the current branch head is now.# Move the current head so that it's pointing at the old commit# Leave the index intact for redoing the commit.# HEAD@{1} gives you ""the commit that HEAD pointed at before # it was moved to where it currently points at"". Note that this is# different from HEAD~1, which gives you ""the commit that is the# parent node of the commit that HEAD is currently pointing to.""git reset --soft HEAD@{1}# commit the current tree using the commit details of the previous# HEAD commit. (Note that HEAD@{1} is pointing somewhere different from the# previous command. It's now pointing at the erroneously amended commit.)# The -C option takes the given commit and reuses the log message and# authorship information.git commit -C HEAD@{1}"
"data_i","edited May 05 '21 at 17:43","
        What is an undefined reference/unresolved external symbol error and how do I fix it?
    ","What are undefined reference/unresolved external symbol errors? What are common causes and how to fix/prevent them?","Compiling a C++ program takes place in several steps, as specified by 2.2 (credits to Keith Thompson for the reference):The precedence among the syntax rules of translation is specified by the following phases [see footnote].Physical source file characters are mapped, in an implementation-defined manner, to the basic source character set(introducing new-line characters for end-of-line indicators) ifnecessary. [SNIP]Each instance of a backslash character (\) immediately followed by a new-line character is deleted, splicing physical source lines toform logical source lines. [SNIP]The source file is decomposed into preprocessing tokens (2.5) and sequences of white-space characters (including comments). [SNIP]Preprocessing directives are executed, macro invocations are expanded, and _Pragma unary operator expressions are executed. [SNIP]Each source character set member in a character literal or a string literal, as well as each escape sequence and universal-character-namein a character literal or a non-raw string literal, is converted tothe corresponding member of the execution character set; [SNIP]Adjacent string literal tokens are concatenated.White-space characters separating tokens are no longer significant. Each preprocessing token is converted into a token. (2.7). Theresulting tokens are syntactically and semantically analyzed andtranslated as a translation unit. [SNIP]Translated translation units and instantiation units are combined as follows: [SNIP]All external entity references are resolved. Library components are linked to satisfy external references to entities not defined in thecurrent translation. All such translator output is collected into aprogram image which contains information needed for execution in itsexecution environment. (emphasis mine)[footnote] Implementations must behave as if these separate phases occur, although in practice different phases might be folded together.The specified errors occur during this last stage of compilation, most commonly referred to as linking. It basically means that you compiled a bunch of implementation files into object files or libraries and now you want to get them to work together.Say you defined symbol a in a.cpp. Now, b.cpp declared that symbol and used it. Before linking, it simply assumes that that symbol was defined somewhere, but it doesn't yet care where. The linking phase is responsible for finding the symbol and correctly linking it to b.cpp (well, actually to the object or library that uses it).If you're using Microsoft Visual Studio, you'll see that projects generate .lib files. These contain a table of exported symbols, and a table of imported symbols. The imported symbols are resolved against the libraries you link against, and the exported symbols are provided for the libraries that use that .lib (if any).Similar mechanisms exist for other compilers/ platforms.Common error messages are error LNK2001, error LNK1120, error LNK2019 for Microsoft Visual Studio and undefined reference to symbolName for GCC.The code:struct X{   virtual void foo();};struct Y : X{   void foo() {}};struct A{   virtual ~A() = 0;};struct B: A{   virtual ~B(){}};extern int x;void foo();int main(){   x = 0;   foo();   Y y;   B b;}will generate the following errors with GCC:/home/AbiSfw/ccvvuHoX.o: In function `main':prog.cpp:(.text+0x10): undefined reference to `x'prog.cpp:(.text+0x19): undefined reference to `foo()'prog.cpp:(.text+0x2d): undefined reference to `A::~A()'/home/AbiSfw/ccvvuHoX.o: In function `B::~B()':prog.cpp:(.text._ZN1BD1Ev[B::~B()]+0xb): undefined reference to `A::~A()'/home/AbiSfw/ccvvuHoX.o: In function `B::~B()':prog.cpp:(.text._ZN1BD0Ev[B::~B()]+0x12): undefined reference to `A::~A()'/home/AbiSfw/ccvvuHoX.o:(.rodata._ZTI1Y[typeinfo for Y]+0x8): undefined reference to `typeinfo for X'/home/AbiSfw/ccvvuHoX.o:(.rodata._ZTI1B[typeinfo for B]+0x8): undefined reference to `typeinfo for A'collect2: ld returned 1 exit statusand similar errors with Microsoft Visual Studio:1>test2.obj : error LNK2001: unresolved external symbol ""void __cdecl foo(void)"" (?foo@@YAXXZ)1>test2.obj : error LNK2001: unresolved external symbol ""int x"" (?x@@3HA)1>test2.obj : error LNK2001: unresolved external symbol ""public: virtual __thiscall A::~A(void)"" (??1A@@UAE@XZ)1>test2.obj : error LNK2001: unresolved external symbol ""public: virtual void __thiscall X::foo(void)"" (?foo@X@@UAEXXZ)1>...\test2.exe : fatal error LNK1120: 4 unresolved externalsCommon causes include:Failure to link against appropriate libraries/object files or compile implementation filesDeclared and undefined variable or function.Common issues with class-type membersTemplate implementations not visible.Symbols were defined in a C program and used in C++ code.Incorrectly importing/exporting methods/classes across modules/dll. (MSVS specific)Circular library dependencyundefined reference to `WinMain@16'Interdependent library orderMultiple source files of the same nameMistyping or not including the .lib extension when using the #pragma (Microsoft Visual Studio)Problems with template friendsInconsistent UNICODE definitionsMissing ""extern"" in const variable declarations/definitions (C++ only)Visual Studio Code not configured for a multiple file project"
"data_i","edited Jul 17 '22 at 05:07","
        LF will be replaced by CRLF in git - What is that and is it important?
    ","git initgit add .Gives the following warnings for many files:The file will have its original line endings in your working directory.warning: LF will be replaced by CRLF in <filename>.What's the difference between LF and CRLF? What should I do about the warnings?","In Unix systems the end of a line is represented with a line feed (LF). In windows a line is represented with a carriage return (CR) and a line feed (LF) thus (CRLF). when you get code from git that was uploaded from a unix system they will only have an LF.If you are a single developer working on a windows machine, and you don't care that git automatically replaces LFs to CRLFs, you can turn this warning off by typing the following in the git command linegit config core.autocrlf trueIf you want to make an intelligent decision how git should handle this, read the documentation Here is a snippetFormatting and WhitespaceFormatting and whitespace issues are some of the more frustrating and  subtle problems that many developers encounter when collaborating,  especially cross-platform. It’s very easy for patches or other  collaborated work to introduce subtle whitespace changes because  editors silently introduce them, and if your files ever touch a  Windows system, their line endings might be replaced. Git has a few  configuration options to help with these issues.core.autocrlfIf you’re programming on Windows and working with people who are not  (or vice-versa), you’ll probably run into line-ending issues at some  point. This is because Windows uses both a carriage-return character  and a linefeed character for newlines in its files, whereas Mac and  Linux systems use only the linefeed character. This is a subtle but  incredibly annoying fact of cross-platform work; many editors on  Windows silently replace existing LF-style line endings with CRLF, or  insert both line-ending characters when the user hits the enter key.Git can handle this by auto-converting CRLF line endings into LF when  you add a file to the index, and vice versa when it checks out code  onto your filesystem. You can turn on this functionality with the  core.autocrlf setting. If you’re on a Windows machine, set it to true  – this converts LF endings into CRLF when you check out code:$ git config --global core.autocrlf trueIf you’re on a Linux or Mac system that uses LF line endings, then you  don’t want Git to automatically convert them when you check out files;  however, if a file with CRLF endings accidentally gets introduced,  then you may want Git to fix it. You can tell Git to convert CRLF to  LF on commit but not the other way around by setting core.autocrlf to  input:$ git config --global core.autocrlf inputThis setup should leave you with CRLF endings in Windows checkouts,  but LF endings on Mac and Linux systems and in the repository.If you’re a Windows programmer doing a Windows-only project, then you  can turn off this functionality, recording the carriage returns in the  repository by setting the config value to false:$ git config --global core.autocrlf false"
"data_i","edited Mar 26 '18 at 06:09","
        How do I perform an IF...THEN in an SQL SELECT?
    ","How do I perform an IF...THEN in an SQL SELECT statement?For example:SELECT IF(Obsolete = 'N' OR InStock = 'Y' ? 1 : 0) AS Saleable, * FROM Product","The CASE statement is the closest to IF in SQL and is supported on all versions of SQL Server.SELECT CAST(             CASE                  WHEN Obsolete = 'N' or InStock = 'Y'                     THEN 1                  ELSE 0             END AS bit) as Saleable, *FROM ProductYou only need to use the CAST operator if you want the result as a Boolean value. If you are happy with an int, this works:SELECT CASE            WHEN Obsolete = 'N' or InStock = 'Y'               THEN 1               ELSE 0       END as Saleable, *FROM ProductCASE statements can be embedded in other CASE statements and even included in aggregates.SQL Server Denali (SQL Server 2012) adds the IIF statement which is also available in access (pointed out by Martin Smith):SELECT IIF(Obsolete = 'N' or InStock = 'Y', 1, 0) as Saleable, * FROM Product"
"data_i","edited Jun 18 '20 at 22:14","
        Can I delete a git commit but keep the changes?
    ","In one of my development branches, I made some changes to my codebase. Before I was able to complete the features I was working on, I had to switch my current branch to master to demo some features. But just using a ""git checkout master"" preserved the changes I also made in my development branch, thus breaking some of the functionality in master. So what I did was commit the changes on my development branch with a commit message ""temporary commit"" and then checkout master for the demo.Now that I'm done with the demo and back to work on my development branch, I would like to remove the ""temporary commit"" that I made while still preserving the changes I made. Is that possible?","It's as simple as this:git reset HEAD^Note: some shells treat ^ as a special character (for example some Windows shells or ZSH with globbing enabled), so you may have to quote ""HEAD^"" or use HEAD~1 in those cases.git reset without a --hard or --soft moves your HEAD to point to the specified commit, without changing any files. HEAD^ refers to the (first) parent commit of your current commit, which in your case is the commit before the temporary one.Note that another option is to carry on as normal, and then at the next commit point instead run:git commit --amend [-m … etc]which will instead edit the most recent commit, having the same effect as above.Note that this (as with nearly every git answer) can cause problems if you've already pushed the bad commit to a place where someone else may have pulled it from. Try to avoid that"
"data_i","edited Sep 28 '18 at 17:16","
        Replacements for switch statement in Python?
    ","I want to write a function in Python that returns different fixed values based on the value of an input index.  In other languages I would use a switch or case statement, but Python does not appear to have a switch statement.  What are the recommended Python solutions in this scenario?","The original answer below was written in 2008. Since then, Python 3.10 (2021) introduced the match-case statement which provides a first-class implementation of a ""switch"" for Python. For example:def f(x):    match x:        case 'a':            return 1        case 'b':            return 2        case _:            return 0   # 0 is the default case if x is not foundThe match-case statement is considerably more powerful than this simple example.You could use a dictionary:def f(x):    return {        'a': 1,        'b': 2,    }[x]"
"data_i","edited Jun 15 '20 at 20:04","
        JavaScript post request like a form submit
    ","I'm trying to direct a browser to a different page. If I wanted a GET request, I might saydocument.location.href = 'http://example.com/q=a';But the resource I'm trying to access won't respond properly unless I use a POST request. If this were not dynamically generated, I might use the HTML<form action=""http://example.com/"" method=""POST"">  <input type=""hidden"" name=""q"" value=""a""></form>Then I would just submit the form from the DOM.But really I would like JavaScript code that allows me to saypost_to_url('http://example.com/', {'q':'a'});What's the best cross browser implementation?Edit I'm sorry I was not clear. I need a solution that changes the location of the browser, just like submitting a form. If this is possible with XMLHttpRequest, it is not obvious. And this should not be asynchronous, nor use XML, so Ajax is not the answer.","Dynamically create <input>s in a form and submit it/** * sends a request to the specified url from a form. this will change the window location. * @param {string} path the path to send the post request to * @param {object} params the parameters to add to the url * @param {string} [method=post] the method to use on the form */function post(path, params, method='post') {  // The rest of this code assumes you are not using a library.  // It can be made less verbose if you use one.  const form = document.createElement('form');  form.method = method;  form.action = path;  for (const key in params) {    if (params.hasOwnProperty(key)) {      const hiddenField = document.createElement('input');      hiddenField.type = 'hidden';      hiddenField.name = key;      hiddenField.value = params[key];      form.appendChild(hiddenField);    }  }  document.body.appendChild(form);  form.submit();}Example:post('/contact/', {name: 'Johnny Bravo'});EDIT: Since this has gotten upvoted so much, I'm guessing people will be copy-pasting this a lot. So I added the hasOwnProperty check to fix any inadvertent bugs."
"data_i","edited Nov 02 '11 at 21:12","
        What is a lambda expression in C++11?
    ","What is a lambda expression in C++11? When would I use one? What class of problem do they solve that wasn't possible prior to their introduction?A few examples, and use cases would be useful. ","The problemC++ includes useful generic functions like std::for_each and std::transform, which can be very handy. Unfortunately they can also be quite cumbersome to use, particularly if the functor you would like to apply is unique to the particular function.#include <algorithm>#include <vector>namespace {  struct f {    void operator()(int) {      // do something    }  };}void func(std::vector<int>& v) {  f f;  std::for_each(v.begin(), v.end(), f);}If you only use f once and in that specific place it seems overkill to be writing a whole class just to do something trivial and one off.In C++03 you might be tempted to write something like the following, to keep the functor local:void func2(std::vector<int>& v) {  struct {    void operator()(int) {       // do something    }  } f;  std::for_each(v.begin(), v.end(), f);}however this is not allowed, f cannot be passed to a template function in C++03.The new solutionC++11 introduces lambdas allow you to write an inline, anonymous functor to replace the struct f. For small simple examples this can be cleaner to read (it keeps everything in one place) and potentially simpler to maintain, for example in the simplest form:void func3(std::vector<int>& v) {  std::for_each(v.begin(), v.end(), [](int) { /* do something here*/ });}Lambda functions are just syntactic sugar for anonymous functors.Return typesIn simple cases the return type of the lambda is deduced for you, e.g.:void func4(std::vector<double>& v) {  std::transform(v.begin(), v.end(), v.begin(),                 [](double d) { return d < 0.00001 ? 0 : d; }                 );}however when you start to write more complex lambdas you will quickly encounter cases where the return type cannot be deduced by the compiler, e.g.:void func4(std::vector<double>& v) {    std::transform(v.begin(), v.end(), v.begin(),        [](double d) {            if (d < 0.0001) {                return 0;            } else {                return d;            }        });}To resolve this you are allowed to explicitly specify a return type for a lambda function, using -> T:void func4(std::vector<double>& v) {    std::transform(v.begin(), v.end(), v.begin(),        [](double d) -> double {            if (d < 0.0001) {                return 0;            } else {                return d;            }        });}""Capturing"" variablesSo far we've not used anything other than what was passed to the lambda within it, but we can also use other variables, within the lambda. If you want to access other variables you can use the capture clause (the [] of the expression), which has so far been unused in these examples, e.g.:void func5(std::vector<double>& v, const double& epsilon) {    std::transform(v.begin(), v.end(), v.begin(),        [epsilon](double d) -> double {            if (d < epsilon) {                return 0;            } else {                return d;            }        });}You can capture by both reference and value, which you can specify using & and = respectively:[&epsilon, zeta] captures epsilon by reference and zeta by value[&] captures all variables used in the lambda by reference[=] captures all variables used in the lambda by value[&, epsilon] captures all variables used in the lambda by reference but captures epsilon by value[=, &epsilon] captures all variables used in the lambda by value but captures epsilon by referenceThe generated operator() is const by default, with the implication that captures will be const when you access them by default. This has the effect that each call with the same input would produce the same result, however you can mark the lambda as mutable to request that the operator() that is produced is not const."
"data_i","edited Sep 29 '19 at 23:33","
        How do I check if an object has a specific property in JavaScript?
    ","How do I check if an object has a specific property in JavaScript?Consider:x = {'key': 1};if ( x.hasOwnProperty('key') ) {    //Do this}Is that the best way to do it?","2022 UPDATEObject.hasOwn()Object.hasOwn() is recommended over Object.hasOwnProperty() because it works for objects created using Object.create(null) and with objects that have overridden the inherited hasOwnProperty() method. While it is possible to workaround these problems by calling Object.prototype.hasOwnProperty() on an external object, Object.hasOwn() is more intuitive.Exampleconst object1 = {  prop: 'exists'};console.log(Object.hasOwn(object1, 'prop'));// expected output: trueOriginal answerI'm really confused by the answers that have been given - most of them are just outright incorrect. Of course you can have object properties that have undefined, null, or false values. So simply reducing the property check to typeof this[property] or, even worse, x.key will give you completely misleading results.It depends on what you're looking for. If you want to know if an object physically contains a property (and it is not coming from somewhere up on the prototype chain) then object.hasOwnProperty is the way to go. All modern browsers support it. (It was missing in older versions of Safari - 2.0.1 and older - but those versions of the browser are rarely used any more.)If what you're looking for is if an object has a property on it that is iterable (when you iterate over the properties of the object, it will appear) then doing: prop in object will give you your desired effect.Since using hasOwnProperty is probably what you want, and considering that you may want a fallback method, I present to you the following solution:var obj = {    a: undefined,    b: null,    c: false};// a, b, c all foundfor ( var prop in obj ) {    document.writeln( ""Object1: "" + prop );}function Class(){    this.a = undefined;    this.b = null;    this.c = false;}Class.prototype = {    a: undefined,    b: true,    c: true,    d: true,    e: true};var obj2 = new Class();// a, b, c, d, e foundfor ( var prop in obj2 ) {    document.writeln( ""Object2: "" + prop );}function hasOwnProperty(obj, prop) {    var proto = obj.__proto__ || obj.constructor.prototype;    return (prop in obj) &&        (!(prop in proto) || proto[prop] !== obj[prop]);}if ( Object.prototype.hasOwnProperty ) {    var hasOwnProperty = function(obj, prop) {        return obj.hasOwnProperty(prop);    }}// a, b, c found in modern browsers// b, c found in Safari 2.0.1 and olderfor ( var prop in obj2 ) {    if ( hasOwnProperty(obj2, prop) ) {        document.writeln( ""Object2 w/ hasOwn: "" + prop );    }}The above is a working, cross-browser, solution to hasOwnProperty(), with one caveat: It is unable to distinguish between cases where an identical property is on the prototype and on the instance - it just assumes that it's coming from the prototype. You could shift it to be more lenient or strict, based upon your situation, but at the very least this should be more helpful."
"data_i","asked Apr 24 '11 at 17:51","
        How can I reconcile detached HEAD with master/origin?
    ","I'm new at the branching complexities of Git. I always work on a single branch and commit changes and then periodically push to my remote origin.Somewhere recently, I did a reset of some files to get them out of commit staging, and later did a rebase -i to get rid of a couple recent local commits. Now I'm in a state I don't quite understand.In my working area, git log shows exactly what I'd expect-- I'm on the right train with the commits I didn't want gone, and new ones there, etc.But I just pushed to the remote repository, and what's there is different-- a couple of the commits I'd killed in the rebase got pushed, and the new ones committed locally aren't there. I think ""master/origin"" is detached from HEAD, but I'm not 100% clear on what that means, how to visualize it with the command line tools, and how to fix it.","First, let’s clarify what HEAD is and what it means when it is detached.  HEAD is the symbolic name for the currently checked out commit. When HEAD is not detached (the “normal”1 situation: you have a branch checked out), HEAD actually points to a branch’s “ref” and the branch points to the commit. HEAD is thus “attached” to a branch. When you make a new commit, the branch that HEAD points to is updated to point to the new commit. HEAD follows automatically since it just points to the branch.git symbolic-ref HEAD yields refs/heads/masterThe branch named “master” is checked out.git rev-parse refs/heads/master yield 17a02998078923f2d62811326d130de991d1a95aThat commit is the current tip or “head” of the master branch.git rev-parse HEAD also yields 17a02998078923f2d62811326d130de991d1a95aThis is what it means to be a “symbolic ref”. It points to an object through some other reference.(Symbolic refs were originally implemented as symbolic links, but later changed to plain files with extra interpretation so that they could be used on platforms that do not have symlinks.)We have HEAD → refs/heads/master → 17a02998078923f2d62811326d130de991d1a95aWhen HEAD is detached, it points directly to a commit—instead of indirectly pointing to one through a branch. You can think of a detached HEAD as being on an unnamed branch. git symbolic-ref HEAD fails with fatal: ref HEAD is not a symbolic refgit rev-parse HEAD yields 17a02998078923f2d62811326d130de991d1a95aSince it is not a symbolic ref, it must point directly to the commit itself.We have HEAD → 17a02998078923f2d62811326d130de991d1a95aThe important thing to remember with a detached HEAD is that if the commit it points to is otherwise unreferenced (no other ref can reach it), then it will become “dangling” when you checkout some other commit. Eventually, such dangling commits will be pruned through the garbage collection process (by default, they are kept for at least 2 weeks and may be kept longer by being referenced by HEAD’s reflog).1It is perfectly fine to do “normal” work with a detached HEAD, you just have to keep track of what you are doing to avoid having to fish dropped history out of the reflog.The intermediate steps of an interactive rebase are done with a detached HEAD (partially to avoid polluting the active branch’s reflog). If you finish the full rebase operation, it will update your original branch with the cumulative result of the rebase operation and reattach HEAD to the original branch. My guess is that you never fully completed the rebase process; this will leave you with a detached HEAD pointing to the commit that was most recently processed by the rebase operation.To recover from your situation, you should create a branch that points to the commit currently pointed to by your detached HEAD:git branch tempgit checkout temp(these two commands can be abbreviated as git checkout -b temp)This will reattach your HEAD to the new temp branch.Next, you should compare the current commit (and its history) with the normal branch on which you expected to be working:git log --graph --decorate --pretty=oneline --abbrev-commit master origin/master tempgit diff master tempgit diff origin/master temp(You will probably want to experiment with the log options: add -p, leave off --pretty=… to see the whole log message, etc.)If your new temp branch looks good, you may want to update (e.g.) master to point to it:git branch -f master tempgit checkout master(these two commands can be abbreviated as git checkout -B master temp)You can then delete the temporary branch:git branch -d tempFinally, you will probably want to push the reestablished history:git push origin masterYou may need to add --force to the end of this command to push if the remote branch can not be “fast-forwarded” to the new commit (i.e. you dropped, or rewrote some existing commit, or otherwise rewrote some bit of history).If you were in the middle of a rebase operation you should probably clean it up. You can check whether a rebase was in process by looking for the directory .git/rebase-merge/. You can manually clean up the in-progress rebase by just deleting that directory (e.g. if you no longer remember the purpose and context of the active rebase operation). Usually you would use git rebase --abort, but that does some extra resetting that you probably want to avoid (it moves HEAD back to the original branch and resets it back to the original commit, which will undo some of the work we did above)."
"data_i","edited Nov 24 '21 at 13:18","
        How can I check if a string is a valid number?
    ","I'm hoping there's something in the same conceptual space as the old VB6 IsNumeric() function?","2nd October 2020: note that many bare-bones approaches are fraught with subtle bugs (eg. whitespace, implicit partial parsing, radix, coercion of arrays etc.) that many of the answers here fail to take into account. The following implementation might work for you, but note that it does not cater for number separators other than the decimal point ""."":function isNumeric(str) {  if (typeof str != ""string"") return false // we only process strings!    return !isNaN(str) && // use type coercion to parse the _entirety_ of the string (`parseFloat` alone does not do this)...         !isNaN(parseFloat(str)) // ...and ensure strings of whitespace fail}To check if a variable (including a string) is a number, check if it is not a number:This works regardless of whether the variable content is a string or number.isNaN(num)         // returns true if the variable does NOT contain a valid numberExamplesisNaN(123)         // falseisNaN('123')       // falseisNaN('1e10000')   // false (This translates to Infinity, which is a number)isNaN('foo')       // trueisNaN('10px')      // trueisNaN('')          // falseisNaN(' ')         // falseisNaN(false)       // falseOf course, you can negate this if you need to. For example, to implement the IsNumeric example you gave:function isNumeric(num){  return !isNaN(num)}To convert a string containing a number into a number:Only works if the string only contains numeric characters, else it returns NaN.+num               // returns the numeric value of the string, or NaN                    // if the string isn't purely numeric charactersExamples+'12'              // 12+'12.'             // 12+'12..'            // NaN+'.12'             // 0.12+'..12'            // NaN+'foo'             // NaN+'12px'            // NaNTo convert a string loosely to a numberUseful for converting '12px' to 12, for example:parseInt(num)      // extracts a numeric value from the                    // start of the string, or NaN.ExamplesparseInt('12')     // 12parseInt('aaa')    // NaNparseInt('12px')   // 12parseInt('foo2')   // NaN      These last three mayparseInt('12a5')   // 12       be different from whatparseInt('0x10')   // 16       you expected to see.FloatsBear in mind that, unlike +num, parseInt (as the name suggests) will convert a float into an integer by chopping off everything following the decimal point (if you want to use parseInt() because of this behaviour, you're probably better off using another method instead):+'12.345'          // 12.345parseInt(12.345)   // 12parseInt('12.345') // 12Empty stringsEmpty strings may be a little counter-intuitive. +num converts empty strings or strings with spaces to zero, and isNaN() assumes the same:+''                // 0+'   '             // 0isNaN('')          // falseisNaN('   ')       // falseBut parseInt() does not agree:parseInt('')       // NaNparseInt('   ')    // NaN"
"data_i","edited Apr 13 '15 at 16:15","
        Git diff against a stash
    ","How can I see the changes un-stashing will make to the current working tree? I would like to know what changes will be made before applying them!","See the most recent stash:git stash show -pSee an arbitrary stash:git stash show -p stash@{1}From the git stash manpages:By default, the command shows the diffstat, but it will accept any  format known to git diff (e.g., git stash show -p stash@{1} to view  the second most recent stash in patch form)."
"data_i","edited Mar 11 '17 at 13:50","
        How do I remove a key from a JavaScript object?
    ","Let's say we have an object with this format:var thisIsObject= {   'Cow' : 'Moo',   'Cat' : 'Meow',   'Dog' : 'Bark'};I wanted to do a function that removes by key:removeFromObjectByKey('Cow');","The delete operator allows you to remove a property from an object.The following examples all do the same thing.// Example 1var key = ""Cow"";delete thisIsObject[key]; // Example 2delete thisIsObject[""Cow""];// Example 3delete thisIsObject.Cow;let animals = {  'Cow': 'Moo',  'Cat': 'Meow',  'Dog': 'Bark'};delete animals.Cow;delete animals['Dog'];console.log(animals);If you're interested, read Understanding Delete for an in-depth explanation."
"data_i","edited Sep 12 '18 at 17:54","
        How do I create a Java string from the contents of a file?
    ","I've been using the idiom below for some time now. And it seems to be the most wide-spread, at least on the sites I've visited.Is there a better/different way to read a file into a string in Java?private String readFile(String file) throws IOException {    BufferedReader reader = new BufferedReader(new FileReader (file));    String         line = null;    StringBuilder  stringBuilder = new StringBuilder();    String         ls = System.getProperty(""line.separator"");    try {        while((line = reader.readLine()) != null) {            stringBuilder.append(line);            stringBuilder.append(ls);        }        return stringBuilder.toString();    } finally {        reader.close();    }}","Read all text from a fileJava 11 added the readString() method to read small files as a String, preserving line terminators:String content = Files.readString(path, encoding);For versions between Java 7 and 11, here's a compact, robust idiom, wrapped up in a utility method:static String readFile(String path, Charset encoding)  throws IOException{  byte[] encoded = Files.readAllBytes(Paths.get(path));  return new String(encoded, encoding);}Read lines of text from a fileJava 7 added a convenience method to read a file as lines of text, represented as a List<String>. This approach is ""lossy"" because the line separators are stripped from the end of each line.List<String> lines = Files.readAllLines(Paths.get(path), encoding);Java 8 added the Files.lines() method to produce a Stream<String>. Again, this method is lossy because line separators are stripped. If an IOException is encountered while reading the file, it is wrapped in an UncheckedIOException, since Stream doesn't accept lambdas that throw checked exceptions.try (Stream<String> lines = Files.lines(path, encoding)) {  lines.forEach(System.out::println);}This Stream does need a close() call; this is poorly documented on the API, and I suspect many people don't even notice Stream has a close() method. Be sure to use an ARM-block as shown.If you are working with a source other than a file, you can use the lines() method in BufferedReader instead.Memory utilizationIf your file is small enough relative to your available memory, reading the entire file at once might work fine. However, if your file is too large, reading one line at a time, processing it, and then discarding it before moving on to the next could be a better approach. Stream processing in this way can eliminate the total file size as a factor in your memory requirement.Character encodingOne thing that is missing from the sample in the original post is the character encoding. This encoding generally can't be determined from the file itself, and requires meta-data such as an HTTP header to convey this important information.The StandardCharsets class defines some constants for the encodings required of all Java runtimes:String content = readFile(""test.txt"", StandardCharsets.UTF_8);The platform default is available from the Charset class itself:String content = readFile(""test.txt"", Charset.defaultCharset());There are some special cases where the platform default is what you want, but they are rare. You should be able justify your choice, because the platform default is not portable. One example where it might be correct is when reading standard input or writing standard output.Note: This answer largely replaces my Java 6 version. The utility of Java 7 safely simplifies the code, and the old answer, which used a mapped byte buffer, prevented the file that was read from being deleted until the mapped buffer was garbage collected. You can view the old version via the ""edited"" link on this answer."
"data_i","asked Dec 03 '08 at 18:09","
        Table Naming Dilemma: Singular vs. Plural Names
    ","Academia has it that table names should be the singular of the entity that they store attributes of.  I dislike any T-SQL that requires square brackets around names, but I have renamed a Users table to the singular, forever sentencing those using the table to sometimes have to use brackets.  My gut feel is that it is more correct to stay with the singular, but my gut feel is also that brackets indicate undesirables like column names with spaces in them etc.Should I stay, or should I go?","I had same question, and after reading all answers here I definitely stay with SINGULAR, reasons:Reason 1 (Concept). You can think of bag containing apples like ""AppleBag"", it doesn't matter if contains 0, 1 or a million apples, it is always the same bag. Tables are just that, containers, the table name must describe what it contains, not how much data it contains. Additionally, the plural concept is more about a spoken language one (actually to determine whether there is one or more).Reason 2. (Convenience). it is easier come out with singular names, than with plural ones. Objects can have irregular plurals or not plural at all, but will always have a singular one (with few exceptions like News).CustomerOrderUserStatusNewsReason 3. (Aesthetic and Order). Specially in master-detail scenarios, this reads better, aligns better by name, and have more logical order (Master first, Detail second):1.Order2.OrderDetailCompared to:1.OrderDetails2.OrdersReason 4 (Simplicity). Put all together, Table Names, Primary Keys, Relationships, Entity Classes... is better to be aware of only one name (singular) instead of two (singular class, plural table, singular field, singular-plural master-detail...)CustomerCustomer.CustomerIDCustomerAddresspublic Class Customer {...}SELECT FROM Customer WHERE CustomerID = 100Once you know you are dealing with ""Customer"", you can be sure you will use the same word for all of your database interaction needs.Reason 5. (Globalization). The world is getting smaller, you may have a team of different nationalities, not everybody has English as a native language. It would be easier for a non-native English language programmer to think of ""Repository"" than of ""Repositories"", or ""Status"" instead of ""Statuses"". Having singular names can lead to fewer errors caused by typos, save time by not having to think ""is it Child or Children?"", hence improving productivity.Reason 6. (Why not?). It can even save you writing time, save you disk space, and even make your computer keyboard last longer!SELECT Customer.CustomerName FROM Customer WHERE Customer.CustomerID = 100SELECT Customers.CustomerName FROM Customers WHERE Customers.CustomerID = 103You have saved 3 letters, 3 bytes, 3 extra keyboard hits :)And finally, you can name those ones messing up with reserved names like:User > LoginUser, AppUser, SystemUser, CMSUser,...Or use the infamous square brackets [User]"
"data_i","edited May 29 '18 at 15:45","
        Insert into ... values ( SELECT ... FROM ... )
    ","I am trying to INSERT INTO a table using the input from another table. Although this is entirely feasible for many database engines, I always seem to struggle to remember the correct syntax for the SQL engine of the day (MySQL, Oracle, SQL Server, Informix, and DB2).Is there a silver-bullet syntax coming from an SQL standard (for example, SQL-92) that would allow me to insert the values without worrying about the underlying database?","Try:INSERT INTO table1 ( column1 )SELECT  col1FROM    table2  This is standard ANSI SQL and should work on any DBMSIt definitely works for:OracleMS SQL ServerMySQLPostgresSQLite v3TeradataDB2SybaseVerticaHSQLDBH2AWS RedShiftSAP HANAGoogle Spanner"
"data_i","edited Oct 25 '21 at 19:20","
        Difference between sh and Bash
    ","When writing shell programs, we often use /bin/sh and /bin/bash. I usually use bash, but I don't know what's the difference between them.What's main difference between Bash and sh?What do we need to be aware of when programming in Bash and sh?","What is sh?sh (or the Shell Command Language) is a programming language described by the POSIX standard. It has many implementations (ksh88, Dash, ...). Bash can also be considered an implementation of sh (see below).Because sh is a specification, not an implementation, /bin/sh is a symlink (or a hard link) to an actual implementation on most POSIX systems.What is Bash?Bash started as an sh-compatible implementation (although it predates the POSIX standard by a few years), but as time passed it has acquired many extensions. Many of these extensions may change the behavior of valid POSIX shell scripts, so by itself Bash is not a valid POSIX shell. Rather, it is a dialect of the POSIX shell language.Bash supports a --posix switch, which makes it more POSIX-compliant. It also tries to mimic POSIX if invoked as sh.sh = bash?For a long time, /bin/sh used to point to /bin/bash on most GNU/Linux systems. As a result, it had almost become safe to ignore the difference between the two. But that started to change recently.Some popular examples of systems where /bin/sh does not point to /bin/bash (and on some of which /bin/bash may not even exist) are:Modern Debian and Ubuntu systems, which symlink sh to dash by default;Busybox, which is usually run during the Linux system boot time as part of initramfs. It uses the ash shell implementation.BSD systems, and in general any non-Linux systems. OpenBSD uses pdksh, a descendant of the KornShell. FreeBSD's sh is a descendant of the original Unix Bourne shell.  Solaris has its own sh which for a long time was not POSIX-compliant; a free implementation is available from the Heirloom project.How can you find out what /bin/sh points to on your system?The complication is that /bin/sh could be a symbolic link or a hard link. If it's a symbolic link, a portable way to resolve it is:% file -h /bin/sh/bin/sh: symbolic link to bashIf it's a hard link, try% find -L /bin -samefile /bin/sh/bin/sh/bin/bashIn fact, the -L flag covers both symlinks and hardlinks,but the disadvantage of this method is that it is not portable —POSIX does not require find to support the -samefile option, although both GNU find and FreeBSD find support it.Shebang lineUltimately, it's up to you to decide which one to use, by writing the «shebang» line as the very first line of the script.E.g.#!/bin/shwill use sh (and whatever that happens to point to),#!/bin/bashwill use /bin/bash if it's available (and fail with an error message if it's not). Of course, you can also specify another implementation, e.g.#!/bin/dashWhich one to useFor my own scripts, I prefer sh for the following reasons:it is standardizedit is much simpler and easier to learnit is portable across POSIX systems — even if they happen not to have bash, they are required to have shThere are advantages to using bash as well. Its features make programming more convenient and similar to programming in other modern programming languages. These include things like scoped local variables and arrays. Plain sh is a very minimalistic programming language."
"data_i","edited Apr 05 '21 at 13:06","
        How Can I add HTML And CSS Into PDF
    ","I have an HTML (not XHTML) document that renders fine in Firefox 3 and IE 7.  It uses fairly basic CSS to style it and renders fine in HTML.I'm now after a way of converting it to PDF.  I have tried:DOMPDF: it had huge problems with tables.  I factored out my large nested tables and it helped (before it was just consuming up to 128M of memory then dying--thats my limit on memory in php.ini) but it makes a complete mess of tables and doesn't seem to get images.  The tables were just basic stuff with some border styles to add some lines at various points;HTML2PDF and HTML2PS: I actually had better luck with this.  It rendered some of the images (all the images are Google Chart URLs) and the table formatting was much better but it seemed to have some complexity problem I haven't figured out yet and kept dying with unknown node_type() errors.  Not sure where to go from here; andHtmldoc: this seems to work fine on basic HTML but has almost no support for CSS whatsoever so you have to do everything in HTML (I didn't realize it was still 2001 in Htmldoc-land...) so it's useless to me.I tried a Windows app called Html2Pdf Pilot that actually did a pretty decent job but I need something that at a minimum runs on Linux and ideally runs on-demand via PHP on the Webserver.What am I missing, or how can I resolve this issue?","Have a look at wkhtmltopdf . It is open source, based on webkit and free.We wrote a small tutorial here.EDIT( 2017 ):If it was to build something today, I wouldn't go that route anymore.But would use http://pdfkit.org/ instead.Probably stripping it of all its nodejs dependencies, to run in the browser."
"data_i","edited May 10 '16 at 08:20","
        Difference between StringBuilder and StringBuffer
    ","What is the main difference between StringBuffer and StringBuilder?Is there any performance issues when deciding on any one of these?","StringBuffer is synchronized, StringBuilder is not."
"data_i","edited Jun 21 '13 at 20:30","
        HTTP status code for update and delete?
    ","What status code should I set for UPDATE (PUT) and DELETE (e.g. product successfully updated)?","For a PUT request: HTTP 200, HTTP 204 should imply ""resource updated successfully"". HTTP 201 if the PUT request created a new resource.For a DELETE request: HTTP 200 or HTTP 204 should imply ""resource deleted successfully"".HTTP 202 can also be returned by either operation and would imply that the instruction was accepted by the server, but not fully applied yet. It's possible that the operation fails later, so the client shouldn't fully assume that it was  success.A client that receives a status code it doesn't recognize, but it's starting with 2 should treat it as a 200 OK.PUTIf an existing resource is modified, either the 200 (OK) or 204 (No Content) response codes SHOULD be sent to indicate successful completion of the request.DELETEA successful response SHOULD be 200 (OK) if the response includes an entity describing the status, 202 (Accepted) if the action has not yet been enacted, or 204 (No Content) if the action has been enacted but the response does not include an entity.Source: W3.org: HTTP/1.1 Method DefinitionsHTTP 200 OK: Standard response for successful HTTPrequests. The actual response willdepend on the request method used.HTTP 204 No Content: The server successfully processed the request, but is not returning any contentSource: List of HTTP status codes: 2xx Success"
"data_i","edited Dec 06 '16 at 02:22","
        Disabling Chrome cache for website development
    ","I am modifying a site's appearance (CSS modifications) but can't see the result on Chrome because of annoying persistent cache. I tried Shift+refresh but it doesn't work.How can I disable the cache temporarily or refresh the page in some way that I could see the changes?","The Chrome DevTools can disable the cache.Right-click and choose Inspect Element to open the DevTools. Or use one of the following keyboard shortcuts:F12Control+Shift+iCommand+Shift+iClick Network in the toolbar to open the network pane.Check the Disable cache checkbox at the top.Keep in mind, as a tweet from @ChromiumDev stated, this setting is only active while the devtools are open.Note that this will result in all resources being reloaded. Should you desire to disable the cache only for some resources, you can modify the HTTP header that your server sends alongside your files.If you do not want to use the Disable cache checkbox, a long press on the refresh button with the DevTools open will show a menu with the options to Hard Reload or Empty Cache and Hard Reload which should have a similar effect. Read about the difference between the options to know which option to choose. The following shortcuts are available:Command+Shift+R on MacControl+Shift+R on Windows or Linux"
"data_i","edited Oct 06 '20 at 16:30","
        Differences between Lodash and Underscore.js
    ","Why would someone prefer either the Lodash or Underscore.js utility library over the other?Lodash seems to be a drop-in replacement for underscore, the latter having been around longer.I think both are brilliant, but I do not know enough about how they work to make an educated comparison, and I would like to know more about the differences.","I created Lodash to provide more consistent cross-environment iteration support for arrays, strings, objects, and arguments objects1. It has since become a superset of Underscore.js, providing more consistent API behavior, more features (like AMD support, deep clone, and deep merge), more thorough documentation and unit tests (tests which run in Node.js, RingoJS, Rhino, Narwhal, PhantomJS, and browsers), better overall performance and optimizations for large arrays/object iteration, and more flexibility with custom builds and template pre-compilation utilities.Because Lodash is updated more frequently than Underscore.js, a lodash underscore build is provided to ensure compatibility with the latest stable version of Underscore.js.At one point I was even given push access to Underscore.js, in part because Lodash is responsible for raising more than 30 issues; landing bug fixes, new features, and performance gains in Underscore.js v1.4.x+.In addition, there are at least three Backbone.js boilerplates that include Lodash by default and Lodash is now mentioned in Backbone.js’s official documentation.Check out Kit Cambridge's post, Say ""Hello"" to Lo-Dash, for a deeper breakdown on the differences between Lodash and Underscore.js.Footnotes:Underscore.js has inconsistent support for arrays, strings, objects, and arguments objects. In newer browsers, Underscore.js methods ignore holes in arrays, ""Objects"" methods iterate arguments objects, strings are treated as array-like, and methods correctly iterate functions (ignoring their ""prototype"" property) and objects (iterating shadowed properties like ""toString"" and ""valueOf""), while in older browsers they will not. Also, Underscore.js methods, like _.clone, preserve holes in arrays, while others like _.flatten don't."
"data_i","edited Nov 23 '19 at 05:31","
        Download a single folder or directory from a GitHub repo
    ","How can I download only a specific folder or directory from a remote Git repo hosted on GitHub?Say the example GitHub repo lives here:git@github.com:foobar/Test.gitIts directory structure:Test/├── foo/ │   ├── a.py│   └── b.py   └── bar/    ├── c.py    └── d.pyI want to download only the foo folder and not clone the whole Test project.","Update Apr. 2021: there are a few tools created by the community that can do this for you:Download Directory (Credits to fregante)It has also been integrated into the excellent Refined Github chrome extension as a button in the Github web UI.GitZip (Credits to Kino - see his answer here)DownGit (Credits to Minhas Kamal - see his answer here)Note: if you're trying to download a large number of files, you may need to provide a token to these tools to avoid rate limiting.Original (manual) approach: Checking out an individual directory is not supported by git natively, but Github can do this via SVN. If you checkout your code with subversion, Github will essentially convert the repo from git to subversion on the backend, then serve up the requested directory.Here's how you can use this feature to download a specific folder. I'll use the popular javascript library lodash as an example.Navigate to the folder you want to download. Let's download /test from master branch.Modify the URL for subversion. Replace tree/master with trunk.https://github.com/lodash/lodash/tree/master/test ➜https://github.com/lodash/lodash/trunk/testDownload the folder. Go to the command line and grab the folder with SVN.svn checkout https://github.com/lodash/lodash/trunk/testYou might not see any activity immediately because Github takes up to 30 seconds to convert larger repositories, so be patient.Full URL format explanation:If you're interested in master branch, use trunk instead. So the full path is trunk/foldernameIf you're interested in foo branch, use branches/foo instead. Thefull path looks like branches/foo/foldernameProtip: You can use svn ls to see available tags and branches before downloading if you wishThat's all! Github supports more subversion features as well, including support for committing and pushing changes."
"data_i","edited Sep 16 '16 at 19:11","
        Extracting extension from filename in Python
    ","Is there a function to extract the extension from a filename?","Use os.path.splitext:>>> import os>>> filename, file_extension = os.path.splitext('/path/to/somefile.ext')>>> filename'/path/to/somefile'>>> file_extension'.ext'Unlike most manual string-splitting attempts, os.path.splitext will correctly treat /a/b.c/d as having no extension instead of having extension .c/d, and it will treat .bashrc as having no extension instead of having extension .bashrc:>>> os.path.splitext('/a/b.c/d')('/a/b.c/d', '')>>> os.path.splitext('.bashrc')('.bashrc', '')"
"data_i","edited Jun 23 '20 at 21:13","
        How can I selectively merge or pick changes from another branch in Git?
    ","I'm using Git on a new project that has two parallel -- but currently experimental -- development branches:master: import of existing codebase plus a few modifications that I'm generally sure ofexp1: experimental branch #1exp2: experimental branch #2exp1 and exp2 represent two very different architectural approaches. Until I get further along I have no way of knowing which one (if either) will work. As I make progress in one branch I sometimes have edits that would be useful in the other branch and would like to merge just those.What is the best way to merge selective changes from one development branch to another while leaving behind everything else?Approaches I've considered:git merge --no-commit followed by manual unstaging of a large number of edits that I don't want to make common between the branches.Manual copying of common files into a temporary directory followed by git checkout to move to the other branch and then more manual copying out of the temporary directory into the working tree.A variation on the above. Abandon the exp branches for now and use two additional local repositories for experimentation.  This makes the manual copying of files much more straightforward.All three of these approaches seem tedious and error-prone.  I'm hoping there is a better approach; something akin to a filter path parameter that would make git-merge more selective.","I had the exact same problem as mentioned by you above.  But I found this clearer in explaining the answer.Summary:Check out the path(s) from the branch you want to merge, $ git checkout source_branch -- <paths>...Hint: It also works without `--` like seen in the linked post.or to selectively merge hunks $ git checkout -p source_branch -- <paths>...Alternatively, use reset and then add with the option -p,    $ git reset <paths>...    $ git add -p <paths>...Finally commit $ git commit -m ""'Merge' these changes"""
"data_i","edited Aug 28 '21 at 00:43","
        Is there a ""previous sibling"" selector?
    ","The plus sign (+) is for selecting the next sibling.Is there an equivalent for the previous sibling?","No, there is no ""previous sibling"" selector.On a related note, ~ is for general successor sibling (meaning the element comes after this one, but not necessarily immediately after) and is a CSS3 selector. + is for next sibling and is CSS2.1.See Adjacent sibling combinator from Selectors Level 3 and 5.7 Adjacent sibling selectors from Cascading Style Sheets Level 2 Revision 1 (CSS 2.1) Specification."
"data_i","edited Feb 01 '19 at 00:10","
        .gitignore is ignored by Git
    ","My .gitignore file seems to be being ignored by Git - could the .gitignore file be corrupt? Which file format, locale or culture does Git expect?My .gitignore:# This is a commentdebug.lognbproject/Output from git status:# On branch master# Your branch is ahead of 'origin/master' by 1 commit.## Untracked files:#   (use ""git add <file>..."" to include in what will be committed)##       debug.log#       nbproject/nothing added to commit but untracked files present (use ""git add"" to track)I would like debug.log and nbproject/ not to appear in the untracked files list.Where should I start looking to fix this?","Even if you haven't tracked the files so far, Git seems to be able to ""know"" about them even after you add them to .gitignore.WARNING: First commit or stash your current changes, or you will lose them.Then run the following commands from the top folder of your Git repository:git rm -r --cached .git add .git commit -m ""fixed untracked files"""
"data_i","edited Apr 10 '22 at 10:24","
        How to prettyprint a JSON file?
    ","How do I pretty-print a JSON file in Python?","Use the indent= parameter of json.dump() or json.dumps() to specify how many spaces to indent by:>>> import json>>>>>> your_json = '[""foo"", {""bar"": [""baz"", null, 1.0, 2]}]'>>> parsed = json.loads(your_json)>>> print(json.dumps(parsed, indent=4))[    ""foo"",    {        ""bar"": [            ""baz"",            null,            1.0,            2        ]    }]To parse a file, use json.load():with open('filename.txt', 'r') as handle:    parsed = json.load(handle)"
"data_i","edited Nov 09 '19 at 14:31","
        Difference between == and === in JavaScript
    ","What is the difference between == and === in JavaScript?  I have also seen != and !== operators.  Are there more such operators?","Take a look here: http://longgoldenears.blogspot.com/2007/09/triple-equals-in-javascript.htmlThe 3 equal signs mean ""equality without type coercion"". Using the triple equals, the values must be equal in type as well.0 == false   // true0 === false  // false, because they are of a different type1 == ""1""     // true, automatic type conversion for value only1 === ""1""    // false, because they are of a different typenull == undefined // truenull === undefined // false'0' == false // true'0' === false // false"
"data_i","edited May 13 '21 at 11:08","
        What is the difference between an abstract method and a virtual method?
    ","What is the difference between an abstract method and a virtual method? In which cases is it recommended to use abstract or virtual methods? Which one is the best approach?","An abstract function cannot have functionality. You're basically saying, any child class MUST give their own version of this method, however it's too general to even try to implement in the parent class. A virtual function, is basically saying look, here's the functionality that may or may not be good enough for the child class. So if it is good enough, use this method, if not, then override me, and provide your own functionality."
"data_i","edited Sep 10 '21 at 15:24","
        How to find a deleted file in the project commit history?
    ","Once upon a time, there was a file in my project that I would now like to be able to get.The problem is: I have no idea of when have I deleted it and on which path it was.How can I locate the commits of this file when it existed?","If you do not know the exact path you may usegit log --all --full-history -- ""**/thefile.*""If you know the path the file was at, you can do this:git log --all --full-history -- <path-to-file>This should show a list of commits in all branches which touched that file. Then, you can find the version of the file you want, and display it with...git show <SHA> -- <path-to-file>Or restore it into your working copy with:git checkout <SHA>^ -- <path-to-file>Note the caret symbol (^), which gets the checkout prior to the one identified, because at the moment of <SHA> commit the file is deleted, we need to look at the previous commit to get the deleted file's contents"
"data_i","edited Jun 20 '20 at 09:12","
        How to vertically align an image inside a div
    ","How can you align an image inside of a containing div?ExampleIn my example, I need to vertically center the <img> in the <div> with class =""frame"":<div class=""frame"" style=""height: 25px;"">    <img src=""http://jsfiddle.net/img/logo.png"" /></div>.frame's height is fixed and the image's height is unknown. I can add new elements in .frame if that's the only solution. I'm trying to do this on Internet  Explorer 7  and later, WebKit, Gecko.See the jsfiddle here..frame {    height: 25px;      /* Equals maximum image height */    line-height: 25px;    width: 160px;    border: 1px solid red;    text-align: center;    margin: 1em 0;}img {    background: #3A6F9A;    vertical-align: middle;    max-height: 25px;    max-width: 160px;}<div class=frame>   <img src=""http://jsfiddle.net/img/logo.png"" height=250 /></div><div class=frame>   <img src=""http://jsfiddle.net/img/logo.png"" height=25 /></div><div class=frame>   <img src=""http://jsfiddle.net/img/logo.png"" height=23 /></div><div class=frame>   <img src=""http://jsfiddle.net/img/logo.png"" height=21 /></div><div class=frame>   <img src=""http://jsfiddle.net/img/logo.png"" height=19 /></div><div class=frame>    <img src=""http://jsfiddle.net/img/logo.png"" height=17 /></div><div class=frame>    <img src=""http://jsfiddle.net/img/logo.png"" height=15 /> </div><div class=frame>    <img src=""http://jsfiddle.net/img/logo.png"" height=13 /> </div><div class=frame>    <img src=""http://jsfiddle.net/img/logo.png"" height=11 /> </div><div class=frame>    <img src=""http://jsfiddle.net/img/logo.png"" height=9 /> </div><div class=frame>    <img src=""http://jsfiddle.net/img/logo.png"" height=7 /> </div><div class=frame>    <img src=""http://jsfiddle.net/img/logo.png"" height=5 /> </div><div class=frame>    <img src=""http://jsfiddle.net/img/logo.png"" height=3 /> </div>","The only (and the best cross-browser) way as I know is to use an inline-block helper with height: 100% and vertical-align: middle on both elements.So there is a solution: http://jsfiddle.net/kizu/4RPFa/4570/.frame {    height: 25px;      /* Equals maximum image height */    width: 160px;    border: 1px solid red;    white-space: nowrap; /* This is required unless you put the helper span closely near the img */    text-align: center;    margin: 1em 0;}.helper {    display: inline-block;    height: 100%;    vertical-align: middle;}img {    background: #3A6F9A;    vertical-align: middle;    max-height: 25px;    max-width: 160px;}<div class=""frame"">    <span class=""helper""></span><img src=""http://jsfiddle.net/img/logo.png"" height=250px /></div><div class=""frame"">    <span class=""helper""></span><img src=""http://jsfiddle.net/img/logo.png"" height=25px /></div><div class=""frame"">    <span class=""helper""></span><img src=""http://jsfiddle.net/img/logo.png"" height=23px /></div><div class=""frame"">    <span class=""helper""></span><img src=""http://jsfiddle.net/img/logo.png"" height=21px /></div><div class=""frame"">    <span class=""helper""></span><img src=""http://jsfiddle.net/img/logo.png"" height=19px /></div><div class=""frame"">    <span class=""helper""></span>    <img src=""http://jsfiddle.net/img/logo.png"" height=17px /></div><div class=""frame"">    <span class=""helper""></span>    <img src=""http://jsfiddle.net/img/logo.png"" height=15px /></div><div class=""frame"">    <span class=""helper""></span>    <img src=""http://jsfiddle.net/img/logo.png"" height=13px /></div><div class=""frame"">    <span class=""helper""></span>    <img src=""http://jsfiddle.net/img/logo.png"" height=11px /></div><div class=""frame"">    <span class=""helper""></span>    <img src=""http://jsfiddle.net/img/logo.png"" height=9px /></div><div class=""frame"">    <span class=""helper""></span>    <img src=""http://jsfiddle.net/img/logo.png"" height=7px /></div><div class=""frame"">    <span class=""helper""></span>    <img src=""http://jsfiddle.net/img/logo.png"" height=5px /></div><div class=""frame"">    <span class=""helper""></span>    <img src=""http://jsfiddle.net/img/logo.png"" height=3px /></div>Or, if you don't want to have an extra element in modern browsers and don't mind using Internet Explorer expressions, you can use a pseudo-element and add it to Internet Explorer using a convenient Expression, that runs only once per element, so there won't be any performance issues:The solution with :before and expression() for Internet Explorer: http://jsfiddle.net/kizu/4RPFa/4571/.frame {    height: 25px;      /* Equals maximum image height */    width: 160px;    border: 1px solid red;    white-space: nowrap;    text-align: center;    margin: 1em 0;}.frame:before,.frame_before {    content: """";    display: inline-block;    height: 100%;    vertical-align: middle;}img {    background: #3A6F9A;    vertical-align: middle;    max-height: 25px;    max-width: 160px;}/* Move this to conditional comments */.frame {    list-style:none;    behavior: expression(        function(t){            t.insertAdjacentHTML('afterBegin','<span class=""frame_before""></span>');            t.runtimeStyle.behavior = 'none';        }(this)    );}<div class=""frame""><img src=""http://jsfiddle.net/img/logo.png"" height=250px /></div><div class=""frame""><img src=""http://jsfiddle.net/img/logo.png"" height=25px /></div><div class=""frame""><img src=""http://jsfiddle.net/img/logo.png"" height=23px /></div><div class=""frame""><img src=""http://jsfiddle.net/img/logo.png"" height=21px /></div><div class=""frame""><img src=""http://jsfiddle.net/img/logo.png"" height=19px /></div><div class=""frame""><img src=""http://jsfiddle.net/img/logo.png"" height=17px /></div><div class=""frame""><img src=""http://jsfiddle.net/img/logo.png"" height=15px /></div><div class=""frame""><img src=""http://jsfiddle.net/img/logo.png"" height=13px /></div><div class=""frame""><img src=""http://jsfiddle.net/img/logo.png"" height=11px /></div><div class=""frame""><img src=""http://jsfiddle.net/img/logo.png"" height=9px /></div><div class=""frame""><img src=""http://jsfiddle.net/img/logo.png"" height=7px /></div><div class=""frame""><img src=""http://jsfiddle.net/img/logo.png"" height=5px /></div><div class=""frame""><img src=""http://jsfiddle.net/img/logo.png"" height=3px /></div>How it works:When you have two inline-block elements near each other, you can align each to other's side, so with vertical-align: middle you'll get something like this:When you have a block with fixed height (in px, em or another absolute unit), you can set the height of inner blocks in %.So, adding one inline-block with height: 100% in a block with fixed height would align another inline-block element in it (<img/> in your case) vertically near it."
"data_i","asked Nov 18 '09 at 01:36","
        How do I configure git to ignore some files locally?
    ","Can I ignore files locally without polluting the global git config for everyone else? I have untracked files that are spam in my git status but I don't want to commit git config changes for every single little random untracked file I have in my local branches.","From the relevant Git documentation:Patterns which are specific to a particular repository but which do not need to be shared with other related repositories (e.g., auxiliary files that live inside the repository but are specific to one user's workflow) should go into the $GIT_DIR/info/exclude file.The .git/info/exclude file has the same format as any .gitignore file. Another option is to set core.excludesFile to the name of a file containing global patterns.Note, if you already have unstaged changes you must run the following after editing your ignore-patterns:git update-index --assume-unchanged <file-list>Note on $GIT_DIR: This is a notation used all over the git manual simply to indicate the path to the git repository. If the environment variable is set, then it will override the location of whichever repo you're in, which probably isn't what you want.Edit: Another way is to use:git update-index --skip-worktree <file-list>Reverse it by:git update-index --no-skip-worktree <file-list>"
"data_i","edited Jun 13 '22 at 01:20","
        How do I read from stdin?
    ","How do I read from stdin? Some code golf challenges require using stdin for input.","Use the fileinput module:import fileinputfor line in fileinput.input():    passfileinput will loop through all the lines in the input specified as file names given in command-line arguments, or the standard input if no arguments are provided.Note: line will contain a trailing newline; to remove it use line.rstrip()."
"data_i","edited Sep 11 '22 at 04:18","
        What's the canonical way to check for type in Python?
    ","How do I check if an object is of a given type, or if it inherits from a given type?How do I check if the object o is of type str?Beginners often wrongly expect the string to already be ""a number"" - either expecting Python 3.x input to convert type, or expecting that a string like '1' is also simultaneously an integer. This is the wrong canonical for those questions. Please carefully read the question and then use How do I check if a string represents a number (float or int)?, How can I read inputs as numbers? and/or Asking the user for input until they give a valid response as appropriate.","Use isinstance to check if o is an instance of str or any subclass of str:if isinstance(o, str):To check if the type of o is exactly str, excluding subclasses of str:if type(o) is str:Another alternative to the above:if issubclass(type(o), str):See Built-in Functions in the Python Library Reference for relevant information.Checking for strings in Python 2For Python 2, this is a better way to check if o is a string:if isinstance(o, basestring):because this will also catch Unicode strings. unicode is not a subclass of str; whereas, both str and unicode are subclasses of basestring. In Python 3, basestring no longer exists since there's a strict separation of strings (str) and binary data (bytes).Alternatively, isinstance accepts a tuple of classes. This will return True if o is an instance of any subclass of any of (str, unicode):if isinstance(o, (str, unicode)):"
"data_i","edited Mar 23 '19 at 06:42","
        How to fix java.lang.UnsupportedClassVersionError: Unsupported major.minor version
    ","I am trying to use Notepad++ as my all-in-one tool edit, run, compile, etc.I have JRE installed, and I have setup my path variable to the .../bin directory.When I run my ""Hello world"" in Notepad++, I get this message:java.lang.UnsupportedClassVersionError: test_hello_world : Unsupported major.minor version 51.0    at java.lang.ClassLoader.defineClass1(Native Method)    at java.lang.ClassLoader.defineClassCond(Unknown Source)       .........................................I think the problem here is about versions; some versions of Java may be old or too new.How do I fix it?Should I install the JDK, and setup my path variable to the JDK instead of JRE?What is the difference between the PATH variable in JRE or JDK?","The version number shown describes the version of the JRE the class file is compatible with.The reported major numbers are:Java SE 18 = 62,Java SE 17 = 61,Java SE 16 = 60, Java SE 15 = 59,Java SE 14 = 58,Java SE 13 = 57,Java SE 12 = 56,Java SE 11 = 55,Java SE 10 = 54,Java SE 9 = 53,Java SE 8 = 52,Java SE 7 = 51,Java SE 6.0 = 50,Java SE 5.0 = 49,JDK 1.4 = 48,JDK 1.3 = 47,JDK 1.2 = 46,JDK 1.1 = 45(Source: Wikipedia)To fix the actual problem you should try to either run the Java code with a newer version of Java JRE or specify the target parameter to the Java compiler to instruct the compiler to create code compatible with earlier Java versions.For example, in order to generate class files compatible with Java 1.4, use the following command line:javac -target 1.4 HelloWorld.javaWith newer versions of the Java compiler you are likely to get a warning about the bootstrap class path not being set. More information about this error is available in a blog post New javac warning for setting an older source without bootclasspath."
"data_i","edited Dec 20 '15 at 10:19","
        How do I debug Node.js applications?
    ","How do I debug a Node.js server application?Right now I'm mostly using alert debugging with print statements like this:sys.puts(sys.inspect(someVariable));There must be a better way to debug. I know that Google Chrome has a command-line debugger. Is this debugger available for Node.js as well?","node-inspector could save the day! Use it from any browser supporting WebSocket. Breakpoints, profiler, livecoding, etc... It is really awesome.Install it with:npm install -g node-inspectorThen run:node-debug app.js"
"data_i","edited Jun 13 '22 at 01:28","
        What is the meaning of single and double underscore before an object name?
    ","What do single and double leading underscores before an object's name represent in Python?","Single UnderscoreIn a class, names with a leading underscore indicate to other programmers that the attribute or method is intended to be be used inside that class. However, privacy is not enforced in any way.Using leading underscores for functions in a module indicates it should not be imported from somewhere else.From the PEP-8 style guide:_single_leading_underscore: weak ""internal use"" indicator. E.g. from M import * does not import objects whose name starts with an underscore.Double Underscore (Name Mangling)From the Python docs:Any identifier of the form __spam (at least two leading underscores, at most one trailing underscore) is textually replaced with _classname__spam, where classname is the current class name with leading underscore(s) stripped. This mangling is done without regard to the syntactic position of the identifier, so it can be used to define class-private instance and class variables, methods, variables stored in globals, and even variables stored in instances. private to this class on instances of other classes.And a warning from the same page:Name mangling is intended to give classes an easy way to define “private” instance variables and methods, without having to worry about instance variables defined by derived classes, or mucking with instance variables by code outside the class. Note that the mangling rules are designed mostly to avoid accidents; it still is possible for a determined soul to access or modify a variable that is considered private.Example>>> class MyClass():...     def __init__(self):...             self.__superprivate = ""Hello""...             self._semiprivate = "", world!""...>>> mc = MyClass()>>> print mc.__superprivateTraceback (most recent call last):  File ""<stdin>"", line 1, in <module>AttributeError: myClass instance has no attribute '__superprivate'>>> print mc._semiprivate, world!>>> print mc.__dict__{'_MyClass__superprivate': 'Hello', '_semiprivate': ', world!'}"
"data_i","edited Dec 19 '20 at 19:14","
        What is the difference between const int*, const int * const, and int const *?
    ","I always mess up how to use const int*, const int * const, and int const * correctly. Is there a set of rules defining what you can and cannot do?I want to know all the do's and all don'ts in terms of assignments, passing to the functions, etc.","Read it backwards (as driven by Clockwise/Spiral Rule):int* - pointer to intint const * - pointer to const intint * const - const pointer to intint const * const - const pointer to const intNow the first const can be on either side of the type so:const int * == int const *const int * const == int const * constIf you want to go really crazy you can do things like this:int ** - pointer to pointer to intint ** const - a const pointer to a pointer to an intint * const * - a pointer to a const pointer to an intint const ** - a pointer to a pointer to a const intint * const * const - a const pointer to a const pointer to an int...And to make sure we are clear on the meaning of const:int a = 5, b = 10, c = 15;const int* foo;     // pointer to constant int.foo = &a;           // assignment to where foo points to./* dummy statement*/*foo = 6;           // the value of a can´t get changed through the pointer.foo = &b;           // the pointer foo can be changed.int *const bar = &c;  // constant pointer to int                       // note, you actually need to set the pointer                       // here because you can't change it later ;)*bar = 16;            // the value of c can be changed through the pointer.    /* dummy statement*/bar = &a;             // not possible because bar is a constant pointer.           foo is a variable pointer to a constant integer. This lets you change what you point to but not the value that you point to. Most often this is seen with C-style strings where you have a pointer to a const char. You may change which string you point to but you can't change the content of these strings. This is important when the string itself is in the data segment of a program and shouldn't be changed.bar is a constant or fixed pointer to a value that can be changed. This is like a reference without the extra syntactic sugar. Because of this fact, usually you would use a reference where you would use a T* const pointer unless you need to allow NULL pointers."
"data_i","edited Dec 17 '16 at 10:21","
        How are parameters sent in an HTTP POST request?
    ","In an HTTP GET request, parameters are sent as a query string:http://example.com/page?parameter=value&also=anotherIn an HTTP POST request, the parameters are not sent along with the URI.Where are the values? In the request header? In the request body? What does it look like?","The values are sent in the request body, in the format that the content type specifies.Usually the content type is application/x-www-form-urlencoded, so the request body uses the same format as the query string:parameter=value&also=anotherWhen you use a file upload in the form, you use the multipart/form-data encoding instead, which has a different format. It's more complicated, but you usually don't need to care what it looks like, so I won't show an example, but it can be good to know that it exists."
"data_i","edited May 23 '17 at 12:10","
        How do I properly force a Git push?
    ","I've set up a remote non-bare ""main"" repo and cloned it to my computer. I made some local changes, updated my local repository, and pushed the changes back to my remote repo. Things were fine up to that point.Now, I had to change something in the remote repo. Then I changed something in my local repo. I realized that the change to the remote repo was not needed. So I tried to git push from my local repo to my remote repo, but I got an error like:To prevent you from losing history, non-fast-forward updates were  rejected Merge the remote changes before pushing again.  See the 'Note  about fast-forwards' section of git push --help for details.I thought that probably agit push --forcewould force my local copy to push changes to the remote one and make it the same. It does force the update, but when I go back to the remote repo and make a commit, I notice that the files contain outdated changes (ones that the main remote repo previously had).As I mentioned in the comments to one of the answers:[I] tried forcing, but when going back to master server to save the changes, i get outdated staging. Thus, when i commit the repositories are not the same. And when i try to use git push again, i get the same error.How can I fix this issue?","Just do:git push origin <your_branch_name> --forceor if you have a specific repo:git push https://git.... --forceThis will delete your previous commit(s) and push your current one.It may not be proper, but if anyone stumbles upon this page, thought they might want a simple solution...Short flagAlso note that -f is short for --force, sogit push origin <your_branch_name> -fwill also work."
"data_i","edited Jun 15 '21 at 15:49","
        How can I merge multiple commits onto another branch as a single squashed commit?
    ","I have a remote Git server, here is the scenario which I want to perform:For each bug/feature I create a different Git branchI keep on committing my code in that Git branch with un-official Git messagesIn top repository we have to do one commit for one bug with official Git messageSo how can I merge my branch to remote branch so that they get just one commit for all my check-ins (I even want to provide commit message for this)?","Say your bug fix branch is called bugfix and you want to merge it into master:git checkout mastergit merge --squash bugfixgit commitThis will take all the commits from the bugfix branch, squash them into 1 commit, and merge it with your master branch.Explanation:git checkout masterSwitches to your master branch.git merge --squash bugfixTakes all commits from the bugfix branch and groups it for a 1 commit with your current branch.(no merge commit appears; you could resolve conflicts manually before following commit)git commitCreates a single commit from the merged changes.Omitting the -m parameter lets you modify a draft commit message containing every message from your squashed commits before finalizing your commit."
"data_i","edited Dec 02 '16 at 10:27","
        Event binding on dynamically created elements?
    ","I have a bit of code where I am looping through all the select boxes on a page and binding a .hover event to them to do a bit of twiddling with their width on mouse on/off.This happens on page ready and works just fine.The problem I have is that any select boxes I add via Ajax or DOM after the initial loop won't have the event bound.I have found this plugin (jQuery Live Query Plugin), but before I add another 5k to my pages with a plugin, I want to see if anyone knows a way to do this, either with jQuery directly or by another option.","As of jQuery 1.7 you should use jQuery.fn.on with the selector parameter filled:$(staticAncestors).on(eventName, dynamicChild, function() {});Explanation:This is called event delegation and works as followed. The event is attached to a static parent (staticAncestors) of the element that should be handled. This jQuery handler is triggered every time the event triggers on this element or one of the descendant elements. The handler then checks if the element that triggered the event matches your selector (dynamicChild). When there is a match then your custom handler function is executed.Prior to this, the recommended approach was to use live():$(selector).live( eventName, function(){} );However, live() was deprecated in 1.7 in favour of on(), and completely removed in 1.9. The live() signature:$(selector).live( eventName, function(){} );... can be replaced with the following on() signature:$(document).on( eventName, selector, function(){} );For example, if your page was dynamically creating elements with the class name dosomething you would bind the event to a parent which already exists (this is the nub of the problem here, you need something that exists to bind to, don't bind to the dynamic content), this can be (and the easiest option) is document. Though bear in mind document may not be the most efficient option.$(document).on('mouseover mouseout', '.dosomething', function(){    // what you want to happen when mouseover and mouseout     // occurs on elements that match '.dosomething'});Any parent that exists at the time the event is bound is fine. For example$('.buttons').on('click', 'button', function(){    // do something here});would apply to<div class=""buttons"">    <!-- <button>s that are generated dynamically and added here --></div>"
"data_i","asked Sep 17 '08 at 16:44","
        How does the Java 'for each' loop work?
    ","Consider:List<String> someList = new ArrayList<String>();// add ""monkey"", ""donkey"", ""skeleton key"" to someListfor (String item : someList) {    System.out.println(item);}What would the equivalent for loop look like without using the for each syntax?","for (Iterator<String> i = someIterable.iterator(); i.hasNext();) {    String item = i.next();    System.out.println(item);}Note that if you need to use i.remove(); in your loop, or access the actual iterator in some way, you cannot use the for ( : ) idiom, since the actual iterator is merely inferred.As was noted by Denis Bueno, this code works for any object that implements the Iterable interface.Also, if the right-hand side of the for (:) idiom is an array rather than an Iterable object, the internal code uses an int index counter and checks against array.length instead. See the Java Language Specification."
"data_i","edited Sep 14 '18 at 11:22","
        How to loop through all enum values in C#?
    ","This question already has an answer here:How do I enumerate an enum in C#? 26 answerspublic enum Foos{    A,    B,    C}Is there a way to loop through the possible values of Foos?Basically?foreach(Foo in Foos)","Yes you can use the ‍GetValue‍‍‍s method:var values = Enum.GetValues(typeof(Foos));Or the typed version:var values = Enum.GetValues(typeof(Foos)).Cast<Foos>();I long ago added a helper function to my private library for just such an occasion:public static class EnumUtil {    public static IEnumerable<T> GetValues<T>() {        return Enum.GetValues(typeof(T)).Cast<T>();    }}Usage:var values = EnumUtil.GetValues<Foos>();"
"data_i","asked Oct 25 '13 at 13:13","
        From an array of objects, extract value of a property as array
    ","I have JavaScript object array with the following structure:objArray = [ { foo: 1, bar: 2}, { foo: 3, bar: 4}, { foo: 5, bar: 6} ];I want to extract a field from each object, and get an array containing the values, for example field foo would give array [ 1, 3, 5 ].I can do this with this trivial approach:function getFields(input, field) {    var output = [];    for (var i=0; i < input.length ; ++i)        output.push(input[i][field]);    return output;}var result = getFields(objArray, ""foo""); // returns [ 1, 3, 5 ]Is there a more elegant or idiomatic way to do this, so that a custom utility function would be unnecessary?Note about suggested duplicate, it covers how to convert a single object to an array.","Here is a shorter way of achieving it:let result = objArray.map(a => a.foo);ORlet result = objArray.map(({ foo }) => foo)You can also check Array.prototype.map()."
"data_i","edited Apr 08 '17 at 16:21","
        How do I install pip on macOS or OS X?
    ","I spent most of the day yesterday searching for a clear answer for installing pip (package manager for Python). I can't find a good solution.How do I install it?","TLDR. On any modern Mac python3 -m ensurepipthen pip3 --version to check.pip's documentation lists the supported mechanisms to install it:https://pip.pypa.io/en/stable/installation/#supported-methodsIt is generally recommended to avoid installing pip on the OS-provided python commands, and to install Python via the official installers or using something like Homebrew or pyenv.Python 3.4+ will have ensurepip, so if you're unable to run python3 -m pip -- run python3 -m ensurepip and it'll install pip for you.If you're using an end-of-life version of Python, you can use get-pip.py instead.Old answer (outdated, and results in a broken installation)easy_install pipIf you need admin privileges to run this, try:sudo easy_install pip"
"data_i","edited Feb 27 '19 at 14:04","
        Rename package in Android Studio
    ","How do you rename packages in the new IDE Android Studio, based on IntelliJ IDEA?Is there an automatic refactoring included? I want to make bulk refactoring, but I don't know how. I worked two years with Eclipse and in Eclipse it's a one-click operation.","In Android Studio, you can do this:For example, if you want to change com.example.app to my.awesome.game, then:In your Project panel, click on the little gear icon (  )Uncheck the Compact Empty Middle Packages optionYour package directory will now be broken down into individual directoriesIndividually select each directory you want to rename, and:Right-click on itSelect RefactorClick on RenameIn the pop-up dialog, click on Rename Package instead of Rename DirectoryEnter the new name and hit RefactorClick Do Refactor in the bottomAllow a minute to let Android Studio update all changesNote: When renaming com in Android Studio, it might give a warning. In such case, select Rename AllNow open your Gradle Build File (build.gradle - Usually app or mobile). Update the applicationId in the defaultConfig to your new Package Name and Sync Gradle, if it hasn't already been updated automatically:You may need to change the package= attribute in your manifest.Clean and Rebuild.Done! Anyway, Android Studio needs to make this process a little simpler."
"data_i","edited Sep 20 '22 at 03:48","
        How do I print to stderr in Python?
    ","There are several ways to write to stderr:print >> sys.stderr, ""spam""  # Python 2 only.sys.stderr.write(""spam\n"")os.write(2, b""spam\n"")from __future__ import print_functionprint(""spam"", file=sys.stderr)What are the differences between these methods? Which method should be preferred?","I found this to be the only one short, flexible, portable and readable:# This line only if you still care about Python2from __future__ import print_functionimport sysdef eprint(*args, **kwargs):    print(*args, file=sys.stderr, **kwargs)The optional function eprint saves some repetition. It can be used in the same way as the standard print function:>>> print(""Test"")Test>>> eprint(""Test"")Test>>> eprint(""foo"", ""bar"", ""baz"", sep=""---"")foo---bar---baz"
"data_i","edited Jun 25 '19 at 16:08","
        Is JavaScript a pass-by-reference or pass-by-value language?
    ","The primitive types (number, string, etc.) are passed by value, but objects are unknown, because they can be both passed-by-value (in case we consider that a variable holding an object is in fact a reference to the object) and passed-by-reference (when we consider that the variable to the object holds the object itself).Although it doesn't really matter at the end, I want to know what is the correct way to present the arguments passing conventions. Is there an excerpt from JavaScript specification, which defines what should be the semantics regarding this?","It's interesting in JavaScript. Consider this example:function changeStuff(a, b, c){  a = a * 10;  b.item = ""changed"";  c = {item: ""changed""};}var num = 10;var obj1 = {item: ""unchanged""};var obj2 = {item: ""unchanged""};changeStuff(num, obj1, obj2);console.log(num);console.log(obj1.item);console.log(obj2.item);This produces the output:10changedunchangedIf obj1 was not a reference at all, then changing obj1.item would have no effect on the obj1 outside of the function.If the argument was a proper reference, then everything would have changed. num would be 100, and obj2.item would read ""changed"". Instead, num stays 10 and obj2.item remains ""unchanged"".Instead, the situation is that the item passed in is passed by value. But the item that is passed by value is itself a reference.Technically, this is called call-by-sharing.In practical terms, this means that if you change the parameter itself (as with num and obj2), that won't affect the item that was fed into the parameter. But if you change the internals of the parameter, that will propagate back up (as with obj1)."
"data_i","edited Nov 10 '19 at 11:47","
        Hide scroll bar, but while still being able to scroll
    ","I want to be able to scroll through the whole page, but without the scrollbar being shown.In Google Chrome it's:::-webkit-scrollbar {    display: none;}But Mozilla Firefox and Internet Explorer don't seem to work like that.I also tried this in CSS:overflow: hidden;That does hide the scrollbar, but I can't scroll any more.Is there a way I can remove the scrollbar while still being able to scroll the whole page?With just CSS or HTML, please.","Just a test which is working fine.#parent{    width: 100%;    height: 100%;    overflow: hidden;}#child{    width: 100%;    height: 100%;    overflow-y: scroll;    padding-right: 17px; /* Increase/decrease this value for cross-browser compatibility */    box-sizing: content-box; /* So the width will be 100% + 17px */}Working FiddleJavaScript:Since the scrollbar width differs in different browsers, it is better to handle it with JavaScript. If you do Element.offsetWidth - Element.clientWidth, the exact scrollbar width will show up.JavaScript Working FiddleOrUsing Position: absolute,#parent{    width: 100%;    height: 100%;    overflow: hidden;    position: relative;}#child{    position: absolute;    top: 0;    bottom: 0;    left: 0;    right: -17px; /* Increase/Decrease this value for cross-browser compatibility */    overflow-y: scroll;}Working FiddleJavaScript Working FiddleInformation:Based on this answer, I created a simple scroll plugin."
"data_i","edited Feb 03 '18 at 16:31","
        startsWith() and endsWith() functions in PHP
    ","How can I write two functions that would take a string and return if it starts with the specified character/string or ends with it?For example:$str = '|apples}';echo startsWith($str, '|'); //Returns trueecho endsWith($str, '}'); //Returns true","PHP 8.0 and higherSince PHP 8.0 you can use thestr_starts_withManualandstr_ends_with ManualExampleecho str_starts_with($str, '|');PHP before 8.0function startsWith( $haystack, $needle ) {     $length = strlen( $needle );     return substr( $haystack, 0, $length ) === $needle;}function endsWith( $haystack, $needle ) {    $length = strlen( $needle );    if( !$length ) {        return true;    }    return substr( $haystack, -$length ) === $needle;}"
"data_i","edited Mar 01 '17 at 19:32","
        Make a Bash alias that takes a parameter?
    ","I used to use CShell (csh), which lets you make an alias that takes a parameter. The notation was something likealias junk=""mv \\!* ~/.Trash""In Bash, this does not seem to work. Given that Bash has a multitude of useful features, I would assume that this one has been implemented but I am wondering how.","Bash alias does not directly accept parameters. You will have to create a function.alias does not accept parameters but a function can be called just like an alias. For example:myfunction() {    #do things with parameters like $1 such as    mv ""$1"" ""$1.bak""    cp ""$2"" ""$1""}myfunction old.conf new.conf #calls `myfunction`By the way, Bash functions defined in your .bashrc and other files are available as commands within your shell. So for instance you can call the earlier function like this $ myfunction original.conf my.conf"
"data_i","edited Sep 08 '20 at 20:35","
        Stop setInterval call in JavaScript
    ","I am using setInterval(fname, 10000); to call a function every 10 seconds in JavaScript. Is it possible to stop calling it on some event? I want the user to be able to stop the repeated refresh of data.","setInterval() returns an interval ID, which you can pass to clearInterval():var refreshIntervalId = setInterval(fname, 10000);/* later */clearInterval(refreshIntervalId);See the docs for setInterval() and clearInterval()."
"data_i","edited Oct 06 '21 at 15:36","
        Get the values from the ""GET"" parameters (JavaScript)
    ","I have a URL with some GET parameters as follows:www.test.com/t.html?a=1&b=3&c=m2-m3-m4-m5 I need to get the whole value of c. I tried to read the URL, but I got only m2. How do I do this using JavaScript?","JavaScript itself has nothing built in for handling query string parameters.Code running in a (modern) browser  can use the URL object (a Web API). URL is also implemented by Node.js:// You can get url_string from window.location.href if you want to work with// the URL of the current pagevar url_string = ""http://www.example.com/t.html?a=1&b=3&c=m2-m3-m4-m5""; var url = new URL(url_string);var c = url.searchParams.get(""c"");console.log(c);For older browsers (including Internet Explorer), you can use this polyfill.You could also use one for URLSearchParams and extract the query string to pass to it with window.location.search.substring(1).You could also use the code from the original version of this answer that predates URL. The above polyfill is robust and well tested and I strongly recommend it over this though.You could access location.search, which would give you from the ? character on to the end of the URL or the start of the fragment identifier (#foo), whichever comes first.Then you can parse it with this:function parse_query_string(query) {  var vars = query.split(""&"");  var query_string = {};  for (var i = 0; i < vars.length; i++) {    var pair = vars[i].split(""="");    var key = decodeURIComponent(pair.shift());    var value = decodeURIComponent(pair.join(""=""));    // If first entry with this name    if (typeof query_string[key] === ""undefined"") {      query_string[key] = value;      // If second entry with this name    } else if (typeof query_string[key] === ""string"") {      var arr = [query_string[key], value];      query_string[key] = arr;      // If third or later entry with this name    } else {      query_string[key].push(value);    }  }  return query_string;}var query_string = ""a=1&b=3&c=m2-m3-m4-m5"";var parsed_qs = parse_query_string(query_string);console.log(parsed_qs.c);You can get the query string from the URL of the current page with:var query = window.location.search.substring(1);var qs = parse_query_string(query);"
"data_i","edited Aug 30 '21 at 08:01","
        What does ""javascript:void(0)"" mean?
    ","<a href=""javascript:void(0)"" id=""loginlink"">login</a>I've seen such hrefs many times, but I don't know what exactly that means.","The void operator evaluates the given  expression and then returns undefined.The void operator is often used merely  to obtain the undefined primitive  value, usually using “void(0)” (which  is equivalent to “void 0”). In these  cases, the global variable undefined  can be used instead (assuming it has  not been assigned to a non-default  value).An explanation is provided here: void operator.The reason you’d want to do this with the href of a link is that normally, a javascript: URL will redirect the browser to a plain text version of the result of evaluating that JavaScript. But if the result is undefined, then the browser stays on the same page. void(0) is just a short and simple script that evaluates to undefined."
"data_i","edited Apr 06 '20 at 09:18","
        What does the [Flags] Enum Attribute mean in C#?
    ","From time to time I see an enum like the following:[Flags]public enum Options {    None    = 0,    Option1 = 1,    Option2 = 2,    Option3 = 4,    Option4 = 8}I don't understand what exactly the [Flags] attribute does.Anyone have a good explanation or example they could post?","The [Flags] attribute should be used whenever the enumerable represents a collection of possible values, rather than a single value. Such collections are often used with bitwise operators, for example:var allowedColors = MyColor.Red | MyColor.Green | MyColor.Blue;Note that the [Flags] attribute doesn't enable this by itself - all it does is allow a nice representation by the .ToString() method:enum Suits { Spades = 1, Clubs = 2, Diamonds = 4, Hearts = 8 }[Flags] enum SuitsFlags { Spades = 1, Clubs = 2, Diamonds = 4, Hearts = 8 }...var str1 = (Suits.Spades | Suits.Diamonds).ToString();           // ""5""var str2 = (SuitsFlags.Spades | SuitsFlags.Diamonds).ToString();           // ""Spades, Diamonds""It is also important to note that [Flags] does not automatically make the enum values powers of two. If you omit the numeric values, the enum will not work as one might expect in bitwise operations, because by default the values start with 0 and increment. Incorrect declaration:[Flags]public enum MyColors{    Yellow,  // 0    Green,   // 1    Red,     // 2    Blue     // 3}The values, if declared this way, will be Yellow = 0, Green = 1, Red = 2, Blue = 3. This will render it useless as flags.Here's an example of a correct declaration:[Flags]public enum MyColors{    Yellow = 1,    Green = 2,    Red = 4,    Blue = 8}To retrieve the distinct values in your property, one can do this:if (myProperties.AllowedColors.HasFlag(MyColor.Yellow)){    // Yellow is allowed...}or prior to .NET 4:if((myProperties.AllowedColors & MyColor.Yellow) == MyColor.Yellow){    // Yellow is allowed...}if((myProperties.AllowedColors & MyColor.Green) == MyColor.Green){    // Green is allowed...}    Under the coversThis works because you used powers of two in your enumeration. Under the covers, your enumeration values look like this in binary ones and zeros: Yellow: 00000001 Green:  00000010 Red:    00000100 Blue:   00001000Similarly, after you've set your property AllowedColors to Red, Green and Blue using the binary bitwise OR | operator, AllowedColors looks like this:myProperties.AllowedColors: 00001110So when you retrieve the value you are actually performing bitwise AND & on the values:myProperties.AllowedColors: 00001110             MyColor.Green: 00000010             -----------------------                            00000010 // Hey, this is the same as MyColor.Green!The None = 0 valueAnd regarding the use of 0 in your enumeration, quoting from MSDN:[Flags]public enum MyColors{    None = 0,    ....}Use None as the name of the flag enumerated constant whose value is zero. You cannot use the None enumerated constant in a bitwise AND operation to test for a flag because the result is always zero. However, you can perform a logical, not a bitwise, comparison between the numeric value and the None enumerated constant to determine whether any bits in the numeric value are set. You can find more info about the flags attribute and its usage at msdn and designing flags at msdn"
"data_i","edited Feb 09 '22 at 10:34","
        Proper way to declare custom exceptions in modern Python?
    ","What's the proper way to declare custom exception classes in modern Python? My primary goal is to follow whatever standard other exception classes have, so that (for instance) any extra string I include in the exception is printed out by whatever tool caught the exception.By ""modern Python"" I mean something that will run in Python 2.5 but be 'correct' for the Python 2.6 and Python 3.* way of doing things. And by ""custom"" I mean an Exception object that can include extra data about the cause of the error: a string, maybe also some other arbitrary object relevant to the exception.I was tripped up by the following deprecation warning in Python 2.6.2:>>> class MyError(Exception):...     def __init__(self, message):...         self.message = message... >>> MyError(""foo"")_sandbox.py:3: DeprecationWarning: BaseException.message has been deprecated as of Python 2.6It seems crazy that BaseException has a special meaning for attributes named message. I gather from PEP-352 that attribute did have a special meaning in 2.5 they're trying to deprecate away, so I guess that name (and that one alone) is now forbidden? Ugh.I'm also fuzzily aware that Exception has some magic parameter args, but I've never known how to use it. Nor am I sure it's the right way to do things going forward; a lot of the discussion I found online suggested they were trying to do away with args in Python 3.Update: two answers have suggested overriding __init__, and __str__/__unicode__/__repr__. That seems like a lot of typing, is it necessary?","Maybe I missed the question, but why not:class MyException(Exception):    passTo override something (or pass extra args), do this:class ValidationError(Exception):    def __init__(self, message, errors):                    # Call the base class constructor with the parameters it needs        super().__init__(message)                    # Now for your custom code...        self.errors = errorsThat way you could pass dict of error messages to the second param, and get to it later with e.errors.In Python 2, you have to use this slightly more complex form of super():super(ValidationError, self).__init__(message)"
"data_i","edited Mar 11 '16 at 20:04","
        How can I convert a stack trace to a string?
    ","What is the easiest way to convert the result of Throwable.getStackTrace() to a string that depicts the stacktrace?","Use Throwable.printStackTrace(PrintWriter pw) to send the stack trace to an appropriate writer.import java.io.StringWriter;import java.io.PrintWriter;// ...StringWriter sw = new StringWriter();PrintWriter pw = new PrintWriter(sw);e.printStackTrace(pw);String sStackTrace = sw.toString(); // stack trace as a stringSystem.out.println(sStackTrace);"
"data_i","edited Apr 19 '20 at 10:35","
        How to remove focus border (outline) around text/input boxes? (Chrome)
    ","Can anyone explain how to remove the orange or blue border (outline) around text/input boxes? I think it only happens on Chrome to show that the input box is active. Here's the input CSS I'm using:input {    background-color: transparent;    border: 0px solid;    height: 20px;    width: 160px;    color: #CCC;}","This border is used to show that the element is focused (i.e. you can type in the input or press the button with Enter). You can remove it with outline property, though:textarea:focus, input:focus{    outline: none;}You may want to add some other way for users to know what element has keyboard focus though for usability.Chrome will also apply highlighting to other elements such as DIV's used as modals. To prevent the highlight on those and all other elements as well, you can do:*:focus {    outline: none;}⚠️ Accessibility warningPlease notice that removing outline from input is an accessibility bad practice. Users using screen readers will not be able to see where their pointer is focused at. More info at a11yproject"
"data_i","edited Jul 01 '20 at 03:45","
        fatal error: Python.h: No such file or directory
    ","I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:gcc -Wall utilsmodule.c -o UtilcAfter executing the command, I get this error message:> utilsmodule.c:1:20: fatal error: Python.h: No such file or directorycompilation terminated.I have tried all the suggested solutions over the internet but the problem still exists. I have no problem with Python.h. I managed to locate the file on my machine.","Looks like you haven't properly installed the header files and static libraries for python dev.  Use your package manager to install them system-wide.For apt (Ubuntu, Debian...):sudo apt-get install python-dev   # for python2.x installssudo apt-get install python3-dev  # for python3.x installsFor yum (CentOS, RHEL...):sudo yum install python-devel    # for python2.x installssudo yum install python3-devel   # for python3.x installsFor dnf (Fedora...):sudo dnf install python2-devel  # for python2.x installssudo dnf install python3-devel  # for python3.x installsFor zypper (openSUSE...):sudo zypper in python-devel   # for python2.x installssudo zypper in python3-devel  # for python3.x installsFor apk (Alpine...):# This is a departure from the normal Alpine naming# scheme, which uses py2- and py3- prefixessudo apk add python2-dev  # for python2.x installssudo apk add python3-dev  # for python3.x installsFor apt-cyg (Cygwin...):apt-cyg install python-devel   # for python2.x installsapt-cyg install python3-devel  # for python3.x installsNote: python3-dev does not automatically cover all minor versions of python3, if you are using e.g. python 3.8 you may need to install python3.8-dev."
"data_i","edited Nov 08 '19 at 14:37","
        What does  do?
    ","What's the difference if one web page starts with<!DOCTYPE html> <html>   <head>     <meta http-equiv=""X-UA-Compatible"" content=""IE=edge""> and If page starts with<!DOCTYPE html> <html>   <head>      <!-- without X-UA-Compatible meta -->If there is no difference, I suppose I can just ignore the X-UA-Compatible meta header, since I just want it to be rendered in most standard mode in all IE versions.","November 2021 UpdateAs this answer is now 10+ years old my recommendation would be to leave this tag out altogether, unless you must support old legacy browsers.October 2015 UpdateThis answer was posted several years ago and now the question really should be should you even consider using the X-UA-Compatible tag on your site? with the changes Microsoft has made to its browsers (more on those below).Depending upon what Microsoft browsers you support you may not need to continue using the X-UA-Compatible tag. If you need to support IE9 or IE8, then I would recommend using the tag. If you only support the latest browsers (IE11 and/or Edge) then I would consider dropping this tag altogether. If you use Twitter Bootstrap and need to eliminate validation warnings, this tag must appear in its specified order. Additional info below:The X-UA-Compatible meta tag allows web authors to choose what version of Internet Explorer the page should be rendered as. IE11 has made changes to these modes; see the IE11 note below. Microsoft Edge, the browser that replaced IE11, only honors the X-UA-Compatible meta tag in certain circumstances. See the Microsoft Edge note below.According to Microsoft, when using the X-UA-Compatible tag, it should be as high as possible in your document head:If you are using the X-UA-Compatible META tag you want to place it as close to the top of the page's HEAD as possible. Internet Explorer begins interpreting markup using the latest version. When Internet Explorer encounters the X-UA-Compatible META tag it starts over using the designated version's engine. This is a performance hit because the browser must stop and restart analyzing the content.Here are your options:""IE=edge""""IE=11""""IE=EmulateIE11""""IE=10""""IE=EmulateIE10""""IE=9""""IE=EmulateIE9""IE=8""""IE=EmulateIE8""""IE=7""""IE=EmulateIE7""""IE=5""To attempt to understand what each means, here are definitions provided by Microsoft:Internet Explorer supports a number of document compatibility modes that enable different features and can affect the way content is displayed:Edge mode tells Internet Explorer to display content in the highest mode available. With Internet Explorer 9, this is equivalent to IE9 mode. If a future release of Internet Explorer supported a higher compatibility mode, pages set to edge mode would appear in the highest mode supported by that version. Those same pages would still appear in IE9 mode when viewed with Internet Explorer 9.Internet Explorer supports a number of document compatibility modes that enable different features and can affect the way content is displayed:IE11 mode provides the highest support available for established and emerging industry standards, including the HTML5, CSS3 and others.IE10 mode provides the highest support available for established and emerging industry standards, including the HTML5, CSS3 and others.IE9 mode provides the highest support available for established and emerging industry standards, including the HTML5 (Working Draft), W3C Cascading Style Sheets Level 3 Specification (Working Draft), Scalable Vector Graphics (SVG) 1.0 Specification, and others. [Editor Note: IE 9 does not support CSS3 animations].IE8 mode supports many established standards, including the W3C Cascading Style Sheets Level 2.1 Specification and the W3C Selectors API; it also provides limited support for the W3C Cascading Style Sheets Level 3 Specification (Working Draft) and other emerging standards.IE7 mode renders content as if it were displayed in standards mode by Internet Explorer 7, whether or not the page contains a <!DOCTYPE> directive.Emulate IE9 mode tells Internet Explorer to use the <!DOCTYPE> directive to determine how to render content. Standards mode directives are displayed in IE9 mode and quirks mode directives are displayed in IE5 mode. Unlike IE9 mode, Emulate IE9 mode respects the <!DOCTYPE> directive.Emulate IE8 mode tells Internet Explorer to use the <!DOCTYPE> directive to determine how to render content. Standards mode directives are displayed in IE8 mode and quirks mode directives are displayed in IE5 mode. Unlike IE8 mode, Emulate IE8 mode respects the <!DOCTYPE> directive.Emulate IE7 mode tells Internet Explorer to use the <!DOCTYPE> directive to determine how to render content. Standards mode directives are displayed in Internet Explorer 7 standards mode and quirks mode directives are displayed in IE5 mode. Unlike IE7 mode, Emulate IE7 mode respects the <!DOCTYPE> directive. For many web sites, this is the preferred compatibility mode.IE5 mode renders content as if it were displayed in quirks mode by Internet Explorer 7, which is very similar to the way content was displayed in Microsoft Internet Explorer 5.IE10 NOTE: As of IE10, quirks mode behaves differently than it did in earlier versions of the browser. In IE9 and earlier versions, quirks mode restricted the webpage to the features supported by IE5.5. In IE10, quirks mode conforms to the differences specified in the HTML5 specification.Personally, I always choose the http-equiv=""X-UA-Compatible"" content=""IE=edge"" meta tag, as older versions have plenty of bugs, and I do not want IE to decide to go into ""Compatibility mode"" and show my site as IE7 vs IE8 or 9. I always prefer the latest version of IE.IE11From Microsoft:Starting with IE11, edge mode is the preferred document mode; it represents the highest support for modern standards available to the browser.Use the HTML5 document type declaration to enable edge mode:<!doctype html>Edge mode was introduced in Internet Explorer 8 and has been available in each subsequent release. Note that the features supported by edge mode are limited to those supported by the specific version of the browser rendering the content.Starting with IE11, document modes are deprecated and should no longer be used, except on a temporary basis. Make sure to update sites that rely on legacy features and document modes to reflect modern standards.If you must target a specific document mode so that your site functions while you rework it to support modern standards and features, be aware that you're using a transitional feature, one that may not be available in future versions.If you currently use the x-ua-compatible header to target a legacy document mode, it's possible your site won't reflect the best experience available with IE11.Microsoft Edge (Replacement for Internet Explorer that comes bundled with Windows 10)Information on X-UA-Compatible meta tag for the ""Edge"" version of IE. From Microsoft:Introducing the “living” Edge document modeAs we announced in August 2013, we are deprecating document modes as of IE11. With our latest platform updates, the need for legacy document modes is primarily limited to Enterprise legacy web apps. With new architectural changes, these legacy document modes will be isolated from changes in the “living” Edge mode, which will help to guarantee a much higher level of compatibility for customers who depend on those modes and help us move even faster on improvements in Edge. IE will still honor document modes served by intranet sites, sites on the Compatibility View list, and when used with Enterprise Mode only.Public Internet sites will be rendered with the new Edge mode platform (ignoring X-UA-Compatible). It is our goal that Edge is the ""living"" document mode from here out and no further document modes will be introduced going forward.With the changes in Microsoft Edge to no longer support document modes in most cases, Microsoft has a tool to scan your site to check and see if it has code that is not compatible with Edge.Chrome=1 Info for IEThere is also chrome=1 that you can use or use together with one of the above options like: <meta http-equiv=""X-UA-Compatible"" content=""IE=Edge,chrome=1"">. chrome=1 is for Google's Chrome Frame which is defined as:Google Chrome Frame is an open source browser plug-in. Users who have the plug-in installed have access to Google Chrome's open web technologies and speedy JavaScript engine when they open pages in the browser.Google Chrome Frame seamlessly enhances your browsing experience in Internet Explorer. It displays Google Chrome Frame enabled sites using Google Chrome’s rendering technology, giving you access to the latest HTML5 features as well as Google Chrome’s performance and security features without in any way interrupting your usual browser usage.When Google Chrome Frame is installed, the web just gets better without you having to think about it.But for that plug-in to work you must use chrome=1 in the X-UA-Compatible meta tag.More info on Chrome Frame can be found here.Note: Google Chrome Frame only works for IE6 through IE9, and was retired on February 25, 2014. More info can be found here. Thanks to @mck for the link.Validation:HTML5:The page will validate using the W3 Validator only when using <meta http-equiv=""X-UA-Compatible"" content=""IE=Edge"">. For other values it will throw the error: A meta element with an http-equiv attribute whose value is X-UA-Compatible must have a content attribute with the value IE=edge. In other words, if you have IE=edge,chrome=1 it will not validate. I ignore this error completely as modern browsers simply ignore this line of code.If you must have completely valid code then consider doing this on the server level by setting HTTP header. As a note, Microsoft says, If both of these instructions are sent (meta and HTTP), the developer's preference (meta element) takes precedence over the web server setting (HTTP header).  See olibre's answer or bitinn's answer for more details on how to set an HTTP header.XHTMLThere isn't an issue with validation when using <meta http-equiv=""X-UA-Compatible"" content=""IE=Edge"" /> as long as the tag is properly closed (i.e. /> vs >).Twitter Bootstrap (V3 and below)This tag has been strongly recommended by the Bootstrap team since at least 2014, and Bootlint, the linter authored by the twbs team continues to throw a warning when the tag is omitted. The linter distinguishes between warnings and errors, and as such the severity of omitting this tag may be considered minor.For more information on X-UA-Compatible see Microsoft's Website Defining Document Compatibility.For more information on what IE supports see caniuse.com.For more information on Twitter Bootstrap requirements, see the bootlint project wiki page."
"data_i","edited Feb 26 '20 at 14:45","
        Warning: push.default is unset; its implicit value is changing in Git 2.0
    ","I've been using Git for a while now and have recently downloaded an update only to find this warning message come up when I try to push.warning: push.default is unset; its implicit value is changing in Git 2.0 from 'matching' to 'simple'. To squelch this message and maintain the current behavior after the default changes, use:   git config --global push.default matchingTo squelch this message and adopt the new behavior now, use:   git config --global push.default simpleI can obviously set it to one of the values mentioned, but what do they mean? What's the difference between simple and matching?If I change it on one client will I need to do anything on other clients that I share repos with?","It's explained in great detail in the docs, but I'll try to summarize:matching means git push will push all your local branches to the ones with the same name on the remote. This makes it easy to accidentally push a branch you didn't intend to. simple means git push will push only the current branch to the one that git pull would pull from, and also checks that their names match. This is a more intuitive behavior, which is why the default is getting changed to this.This setting only affects the behavior of your local client, and can be overridden by explicitly specifying which branches you want to push on the command line. Other clients can have different settings, it only affects what happens when you don't specify which branches you want to push."
"data_i","edited Jun 13 '22 at 01:39","
        Random string generation with upper case letters and digits
    ","How do I generate a string of size N, made of numbers and uppercase English letters such as:6U1S754Z4UKKU911K4","Answer in one line:''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(N))or even shorter starting with Python 3.6 using random.choices():''.join(random.choices(string.ascii_uppercase + string.digits, k=N))A cryptographically more secure version: see this post''.join(random.SystemRandom().choice(string.ascii_uppercase + string.digits) for _ in range(N))In details, with a clean function for further reuse:>>> import string>>> import random>>> def id_generator(size=6, chars=string.ascii_uppercase + string.digits):...    return ''.join(random.choice(chars) for _ in range(size))...>>> id_generator()'G5G74W'>>> id_generator(3, ""6793YUIO"")'Y3U'How does it work ?We import string, a module that contains sequences of common ASCII characters, and random, a module that deals with random generation.string.ascii_uppercase + string.digits just concatenates the list of characters representing uppercase ASCII chars and digits:>>> string.ascii_uppercase'ABCDEFGHIJKLMNOPQRSTUVWXYZ'>>> string.digits'0123456789'>>> string.ascii_uppercase + string.digits'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'Then we use a list comprehension to create a list of 'n' elements:>>> range(4) # range create a list of 'n' numbers[0, 1, 2, 3]>>> ['elem' for _ in range(4)] # we use range to create 4 times 'elem'['elem', 'elem', 'elem', 'elem']In the example above, we use [ to create the list, but we don't in the id_generator function so Python doesn't create the list in memory, but generates the elements on the fly, one by one (more about this here).Instead of asking to create 'n' times the string elem, we will ask Python to create 'n' times a random character, picked from a sequence of characters:>>> random.choice(""abcde"")'a'>>> random.choice(""abcde"")'d'>>> random.choice(""abcde"")'b'Therefore random.choice(chars) for _ in range(size) really is creating a sequence of size characters. Characters that are randomly picked from chars:>>> [random.choice('abcde') for _ in range(3)]['a', 'b', 'b']>>> [random.choice('abcde') for _ in range(3)]['e', 'b', 'e']>>> [random.choice('abcde') for _ in range(3)]['d', 'a', 'c']Then we just join them with an empty string so the sequence becomes a string:>>> ''.join(['a', 'b', 'b'])'abb'>>> [random.choice('abcde') for _ in range(3)]['d', 'c', 'b']>>> ''.join(random.choice('abcde') for _ in range(3))'dac'"
"data_i","edited Oct 30 '12 at 18:02","
        How does the vim ""write with sudo"" trick work?
    ","Many of you have probably seen the command that allows you to write on a file that needs root permission, even when you forgot to open vim with sudo::w !sudo tee %The thing is that I don't get what is exactly happening here.I have already figured this:w is for this                                                        *:w_c* *:write_c*:[range]w[rite] [++opt] !{cmd}                        Execute {cmd} with [range] lines as standard input                        (note the space in front of the '!').  {cmd} is                        executed like with "":!{cmd}"", any '!' is replaced with                        the previous command |:!|.so it passes all the lines as standard input.The !sudo tee part calls tee with administrator privileges.For all to make sense, the % should output the filename (as a parameter for tee), but I can't find references on the help for this behavior.tl;dr Could someone help me dissect this command?","In :w !sudo tee %...% means ""the current file""As eugene y pointed out, % does indeed mean ""the current file name"", which is passed to tee so that it knows which file to overwrite.(In substitution commands, it's slightly different; as :help :% shows, it's equal to 1,$ (the entire file) (thanks to @Orafu for pointing out that this does not evaluate to the filename). For example, :%s/foo/bar means ""in the current file, replace occurrences of foo with bar."" If you highlight some text before typing :s, you'll see that the highlighted lines take the place of % as your substitution range.):w isn't updating your fileOne confusing part of this trick is that you might think :w is modifying your file, but it isn't. If you opened and modified file1.txt, then ran :w file2.txt, it would be a ""save as""; file1.txt wouldn't be modified, but the current buffer contents would be sent to file2.txt.Instead of file2.txt, you can substitute a shell command to receive the buffer contents. For instance, :w !cat will just display the contents.If Vim wasn't run with sudo access, its :w can't modify a protected file, but if it passes the buffer contents to the shell, a command in the shell can be run with sudo. In this case, we use tee.Understanding teeAs for tee, picture the tee command as a T-shaped pipe in a normal bash piping situation: it directs output to specified file(s) and also sends it to standard output, which can be captured by the next piped command. For example, in ps -ax | tee processes.txt | grep 'foo', the list of processes will be written to a text file and passed along to grep.     +-----------+    tee     +------------+     |           |  --------  |            |     | ps -ax    |  --------  | grep 'foo' |     |           |     ||     |            |     +-----------+     ||     +------------+                       ||                  +---------------+               |               |               | processes.txt |               |               |               +---------------+(Diagram created with Asciiflow.)See the tee man page for more info.Tee as a hackIn the situation your question describes, using tee is a hack because we're ignoring half of what it does. sudo tee writes to our file and also sends the buffer contents to standard output, but we ignore standard output. We don't need to pass anything to another piped command in this case; we're just using tee as an alternate way of writing a file and so that we can call it with sudo.Making this trick easyYou can add this to your .vimrc to make this trick easy-to-use: just type :w!!."" Allow saving of files as sudo when I forgot to start vim using sudo.cmap w!! w !sudo tee > /dev/null %The > /dev/null part explicitly throws away the standard output, since, as I said, we don't need to pass anything to another piped command."
"data_i","edited Mar 28 '22 at 11:49","
        How do I get the row count of a Pandas DataFrame?
    ","How do I get the number of rows of a pandas dataframe df?","For a dataframe df, one can use any of the following:len(df.index)df.shape[0]df[df.columns[0]].count() (== number of non-NaN values in first column)Code to reproduce the plot:import numpy as npimport pandas as pdimport perfplotperfplot.save(    ""out.png"",    setup=lambda n: pd.DataFrame(np.arange(n * 3).reshape(n, 3)),    n_range=[2**k for k in range(25)],    kernels=[        lambda df: len(df.index),        lambda df: df.shape[0],        lambda df: df[df.columns[0]].count(),    ],    labels=[""len(df.index)"", ""df.shape[0]"", ""df[df.columns[0]].count()""],    xlabel=""Number of rows"",)"
"data_i","edited Feb 07 '18 at 18:26","
        What is the purpose of the var keyword and when should I use it (or omit it)?
    ","NOTE: This question was asked from the viewpoint of ECMAScript version 3 or 5. The answers might become outdated with the introduction of new features in the release of ECMAScript 6.What exactly is the function of the var keyword in JavaScript, and what is the difference betweenvar someNumber = 2;var someFunction = function() { doSomething; }var someObject = { }var someObject.someProperty = 5;andsomeNumber = 2;someFunction = function() { doSomething; }someObject = { }someObject.someProperty = 5;?When would you use either one, and why/what does it do?","If you're in the global scope then there's not much difference. Read Kangax's answer for explanationIf you're in a function then var will create a local variable, ""no var"" will look up the scope chain until it finds the variable or hits the global scope (at which point it will create it):// These are both globalsvar foo = 1;bar = 2;function(){    var foo = 1; // Local    bar = 2;     // Global    // Execute an anonymous function    (function()    {        var wibble = 1; // Local        foo = 2; // Inherits from scope above (creating a closure)        moo = 3; // Global    }())}If you're not doing an assignment then you need to use var:var x; // Declare x"
"data_i","asked Feb 11 '14 at 03:01","
        Why not inherit from List?
    ","When planning out my programs, I often start with a chain of thought like so:A football team is just a list of football players. Therefore, I should represent it with:var football_team = new List<FootballPlayer>();The ordering of this list represent the order in which the players are listed in the roster.But I realize later that teams also have other properties, besides the mere list of players, that must be recorded. For example, the running total of scores this season, the current budget, the uniform colors, a string representing the name of the team, etc..So then I think:Okay, a football team is just like a list of players, but additionally, it has a name (a string) and a running total of scores (an int). .NET does not provide a class for storing football teams, so I will make my own class. The most similar and relevant existing structure is List<FootballPlayer>, so I will inherit from it:class FootballTeam : List<FootballPlayer> {     public string TeamName;     public int RunningTotal }But it turns out that a guideline says you shouldn't inherit from List<T>. I'm thoroughly confused by this guideline in two respects.Why not?Apparently List is somehow optimized for performance. How so? What performance problems will I cause if I extend List? What exactly will break?Another reason I've seen is that List is provided by Microsoft, and I have no control over it, so I cannot change it later, after exposing a ""public API"". But I struggle to understand this. What is a public API and why should I care? If my current project does not and is not likely to ever have this public API, can I safely ignore this guideline? If I do inherit from List and it turns out I need a public API, what difficulties will I have?Why does it even matter? A list is a list. What could possibly change? What could I possibly want to change?And lastly, if Microsoft did not want me to inherit from List, why didn't they make the class sealed?What else am I supposed to use?Apparently, for custom collections, Microsoft has provided a Collection class which should be extended instead of List. But this class is very bare, and does not have many useful things, such as AddRange, for instance. jvitor83's answer provides a performance rationale for that particular method, but how is a slow AddRange not better than no AddRange?Inheriting from Collection is way more work than inheriting from List, and I see no benefit. Surely Microsoft wouldn't tell me to do extra work for no reason, so I can't help feeling like I am somehow misunderstanding something, and inheriting Collection is actually not the right solution for my problem.I've seen suggestions such as implementing IList. Just no. This is dozens of lines of boilerplate code which gains me nothing.Lastly, some suggest wrapping the List in something: class FootballTeam {     public List<FootballPlayer> Players; }There are two problems with this:It makes my code needlessly verbose. I must now call my_team.Players.Count instead of just my_team.Count. Thankfully, with C# I can define indexers to make indexing transparent, and forward all the methods of the internal List... But that's a lot of code! What do I get for all that work?It just plain doesn't make any sense. A football team doesn't ""have"" a list of players. It is the list of players. You don't say ""John McFootballer has joined SomeTeam's players"". You say ""John has joined SomeTeam"". You don't add a letter to ""a string's characters"", you add a letter to a string. You don't add a book to a library's books, you add a book to a library.I realize that what happens ""under the hood"" can be said to be ""adding X to Y's internal list"", but this seems like a very counter-intuitive way of thinking about the world.My question (summarized)What is the correct C# way of representing a data structure, which, ""logically"" (that is to say, ""to the human mind"") is just a list of things with a few bells and whistles?Is inheriting from List<T> always unacceptable? When is it acceptable? Why/why not? What must a programmer consider, when deciding whether to inherit from List<T> or not?","There are some good answers here. I would add to them the following points.What is the correct C# way of representing a data structure, which, ""logically"" (that is to say, ""to the human mind"") is just a list of things with a few bells and whistles?Ask any ten non-computer-programmer people who are familiar with the existence of football to fill in the blank:A football team is a particular kind of _____Did anyone say ""list of football players with a few bells and whistles"", or did they all say ""sports team"" or ""club"" or ""organization""?  Your notion that a football team is a particular kind of list of players is in your human mind and your human mind alone.List<T> is a mechanism.  Football team is a business object -- that is, an object that represents some concept that is in the business domain of the program. Don't mix those! A football team is a kind of team; it has a roster, a roster is a list of players. A roster is not a particular kind of list of players. A roster is a list of players. So make a property called Roster that is a List<Player>. And make it ReadOnlyList<Player> while you're at it, unless you believe that everyone who knows about a football team gets to delete players from the roster.Is inheriting from List<T> always unacceptable?Unacceptable to whom? Me? No.When is it acceptable?When you're building a mechanism that extends the List<T> mechanism.What must a programmer consider, when deciding whether to inherit from List<T> or not?Am I building a mechanism or a business object?But that's a lot of code! What do I get for all that work?You spent more time typing up your question that it would have taken you to write forwarding methods for the relevant members of List<T> fifty times over. You're clearly not afraid of verbosity, and we are talking about a very small amount of code here; this is a few minutes work.UPDATEI gave it some more thought and there is another reason to not model a football team as a list of players. In fact it might be a bad idea to model a football team as having a list of players too. The problem with a team as/having a list of players is that what you've got is a snapshot of the team at a moment in time. I don't know what your business case is for this class, but if I had a class that represented a football team I would want to ask it questions like ""how many Seahawks players missed games due to injury between 2003 and 2013?"" or ""What Denver player who previously played for another team had the largest year-over-year increase in yards ran?"" or ""Did the Piggers go all the way this year?""That is, a football team seems to me to be well modeled as a collection of historical facts such as when a player was recruited, injured, retired, etc. Obviously the current player roster is an important fact that should probably be front-and-center, but there may be other interesting things you want to do with this object that require a more historical perspective."
"data_i","edited Aug 28 '15 at 17:05","
        What is a monad?
    ","Having briefly looked at Haskell recently, what would be a brief, succinct, practical explanation as to what a monad essentially is?I have found most explanations I've come across to be fairly inaccessible and lacking in practical detail.","First: The term monad is a bit vacuous if you are not a mathematician. An alternative term is computation builder which is a bit more descriptive of what they are actually useful for.They are a pattern for chaining operations. It looks a bit like method chaining in object-oriented languages, but the mechanism is slightly different.The pattern is mostly used in functional languages (especially Haskell which uses monads pervasively) but can be used in any language which support higher-order functions (that is, functions which can take other functions as arguments).Arrays in JavaScript support the pattern, so let’s use that as the first example.The gist of the pattern is we have a type (Array in this case) which has a method which takes a function as argument. The operation supplied must return an instance of the same type (i.e. return an Array).First an example of method chaining which does not use the monad pattern:[1,2,3].map(x => x + 1)The result is [2,3,4]. The code does not conform to the monad pattern, since the function we are supplying as an argument returns a number, not an Array. The same logic in monad form would be:[1,2,3].flatMap(x => [x + 1])Here we supply an operation which returns an Array, so now it conforms to the pattern. The flatMap method executes the provided function for every element in the array.  It expects an array as result for each invocation (rather than single values), but merges the resulting set of arrays into a single array. So the end result is the same, the array [2,3,4].(The function argument provided to a method like map or flatMap is often called a ""callback"" in JavaScript. I will call it the ""operation"" since it is more general.)If we chain multiple operations (in the traditional way):[1,2,3].map(a => a + 1).filter(b => b != 3)Results in the array [2,4]The same chaining in monad form:[1,2,3].flatMap(a => [a + 1]).flatMap(b => b != 3 ? [b] : [])Yields the same result, the array [2,4].You will immediately notice that the monad form is quite a bit uglier than the non-monad! This just goes to show that monads are not necessarily “good”. They are a pattern which is sometimes beneficial and sometimes not.Do note that the monad pattern can be combined in a different way:[1,2,3].flatMap(a => [a + 1].flatMap(b => b != 3 ? [b] : []))Here the binding is nested rather than chained, but the result is the same. This is an important property of monads as we will see later. It means two operations combined can be treated the same as a single operation.The operation is allowed to return an array with different element types, for example transforming an array of numbers into an array of strings or something else; as long as it still an Array.This can be described a bit more formally using Typescript notation. An array has the type Array<T>, where T is the type of the elements in the array. The method flatMap() takes a function argument of the type T => Array<U> and returns an Array<U>.Generalized, a monad is any type Foo<Bar> which has a ""bind"" method which takes a function argument of type Bar => Foo<Baz> and returns a Foo<Baz>.This answers what monads are. The rest of this answer will try to explain through examples why monads can be a useful pattern in a language like Haskell which has good support for them.Haskell and Do-notationTo translate the map/filter example directly to Haskell, we replace flatMap with the >>= operator:[1,2,3] >>= \a -> [a+1] >>= \b -> if b == 3 then [] else [b] The >>= operator is the bind function in Haskell. It does the same as flatMap in JavaScript when the operand is a list, but it is overloaded with different meaning for other types.But Haskell also has a dedicated syntax for monad expressions, the do-block, which hides the bind operator altogether: do a <- [1,2,3]     b <- [a+1]     if b == 3 then [] else [b] This hides the ""plumbing"" and lets you focus on the actual operations applied at each step.In a do-block, each line is an operation. The constraint still holds that all operations in the block must return the same type. Since the first expression is a list, the other operations must also return a list.The back-arrow <- looks deceptively like an assignment, but note that this is the parameter passed in the bind. So, when the expression on the right side is a List of Integers, the variable on the left side will be a single Integer – but will be executed for each integer in the list.Example: Safe navigation (the Maybe type)Enough about lists, lets see how the monad pattern can be useful for other types.Some functions may not always return a valid value. In Haskell this is represented by the Maybe-type, which is an option that is either Just value or Nothing.Chaining operations which always return a valid value is of course straightforward:streetName = getStreetName (getAddress (getUser 17)) But what if any of the functions could return Nothing? We need to check each result individually and only pass the value to the next function if it is not Nothing:case getUser 17 of      Nothing -> Nothing       Just user ->         case getAddress user of            Nothing -> Nothing             Just address ->              getStreetName addressQuite a lot of repetitive checks! Imagine if the chain was longer. Haskell solves this with the monad pattern for Maybe:do  user <- getUser 17  addr <- getAddress user  getStreetName addrThis do-block invokes the bind-function for the Maybe type (since the result of the first expression is a Maybe). The bind-function only executes the following operation if the value is Just value, otherwise it just passes the Nothing along.Here the monad-pattern is used to avoid repetitive code. This is similar to how some other languages use macros to simplify syntax, although macros achieve the same goal in a very different way.Note that it is the combination of the monad pattern and the monad-friendly syntax in Haskell which result in the cleaner code. In a language like JavaScript without any special syntax support for monads, I doubt the monad pattern would be able to simplify the code in this case.Mutable stateHaskell does not support mutable state. All variables are constants and all values immutable. But the State type can be used to emulate programming with mutable state:add2 :: State Integer Integeradd2 = do        -- add 1 to state         x <- get         put (x + 1)         -- increment in another way         modify (+1)         -- return state         getevalState add2 7=> 9The add2 function builds a monad chain which is then evaluated with 7 as the initial state.Obviously this is something which only makes sense in Haskell. Other languages support mutable state out of the box. Haskell is generally ""opt-in"" on language features - you enable mutable state when you need it, and the type system ensures the effect is explicit. IO is another example of this.IOThe IO type is used for chaining and executing “impure” functions.Like any other practical language, Haskell has a bunch of built-in functions which interface with the outside world: putStrLine, readLine and so on. These functions are called “impure” because they either cause side effects or have non-deterministic results. Even something simple like getting the time is considered impure because the result is non-deterministic – calling it twice with the same arguments may return different values.A pure function is deterministic – its result depends purely on the arguments passed and it has no side effects on the environment beside returning a value.Haskell heavily encourages the use of pure functions – this is a major selling point of the language. Unfortunately for purists, you need some impure functions to do anything useful. The Haskell compromise is to cleanly separate pure and impure, and guarantee that there is no way that pure functions can execute impure functions, directly or indirect.This is guaranteed by giving all impure functions the IO type. The entry point in Haskell program is the main function which have the IO type, so we can execute impure functions at the top level.But how does the language prevent pure functions from executing impure functions? This is due to the lazy nature of Haskell. A function is only executed if its output is consumed by some other function. But there is no way to consume an IO value except to assign it to main. So if a function wants to execute an impure function, it has to be connected to main and have the IO type.Using monad chaining for IO operations also ensures that they are executed in a linear and predictable order, just like statements in an imperative language.This brings us to the first program most people will write in Haskell:main :: IO ()main = do         putStrLn ”Hello World”The do keyword is superfluous when there is only a single operation and therefore nothing to bind, but I keep it anyway for consistency.The () type means “void”. This special return type is only useful for IO functions called for their side effect.A longer example:main = do    putStrLn ""What is your name?""    name <- getLine    putStrLn ""hello"" ++ nameThis builds a chain of IO operations, and since they are assigned to the main function, they get executed.Comparing IO with Maybe shows the versatility of the monad pattern. For Maybe, the pattern is used to avoid repetitive code by moving conditional logic to the binding function. For IO, the pattern is used to ensure that all operations of the IO type are sequenced and that IO operations cannot ""leak"" to pure functions.Summing upIn my subjective opinion, the monad pattern is only really worthwhile in a language which has some built-in support for the pattern. Otherwise it just leads to overly convoluted code. But Haskell (and some other languages) have some built-in support which hides the tedious parts, and then the pattern can be used for a variety of useful things. Like:Avoiding repetitive code (Maybe)Adding language features like mutable state or exceptions for delimited areas of the program.Isolating icky stuff from nice stuff (IO)Embedded domain-specific languages (Parser)Adding GOTO to the language."
"data_i","edited Jul 23 '21 at 16:32","
        How do you access the matched groups in a JavaScript regular expression?
    ","I want to match a portion of a string using a regular expression and then access that parenthesized substring:    var myString = ""something format_abc""; // I want ""abc""    var arr = /(?:^|\s)format_(.*?)(?:\s|$)/.exec(myString);    console.log(arr);     // Prints: ["" format_abc"", ""abc""] .. so far so good.    console.log(arr[1]);  // Prints: undefined  (???)    console.log(arr[0]);  // Prints: format_undefined (!!!)What am I doing wrong?I've discovered that there was nothing wrong with the regular expression code above: the actual string which I was testing against was this:""date format_%A""Reporting that ""%A"" is undefined seems a very strange behaviour, but it is not directly related to this question, so I've opened a new one, Why is a matched substring returning ""undefined"" in JavaScript?.The issue was that console.log takes its parameters like a printf statement, and since the string I was logging (""%A"") had a special value, it was trying to find the value of the next parameter.","You can access capturing groups like this:var myString = ""something format_abc"";var myRegexp = /(?:^|\s)format_(.*?)(?:\s|$)/g;var myRegexp = new RegExp(""(?:^|\s)format_(.*?)(?:\s|$)"", ""g"");var match = myRegexp.exec(myString);console.log(match[1]); // abcAnd if there are multiple matches you can iterate over them:var myString = ""something format_abc"";var myRegexp = new RegExp(""(?:^|\s)format_(.*?)(?:\s|$)"", ""g"");match = myRegexp.exec(myString);while (match != null) {  // matched text: match[0]  // match start: match.index  // capturing group n: match[n]  console.log(match[0])  match = myRegexp.exec(myString);}Edit: 2019-09-10As you can see the way to iterate over multiple matches was not very intuitive. This lead to the proposal of the String.prototype.matchAll method. This new method is expected to ship in the ECMAScript 2020 specification. It gives us a clean API and solves multiple problems. It has been started to land on major browsers and JS engines as Chrome 73+ / Node 12+ and Firefox 67+.The method returns an iterator and is used as follows:const string = ""something format_abc"";const regexp = /(?:^|\s)format_(.*?)(?:\s|$)/g;const matches = string.matchAll(regexp);    for (const match of matches) {  console.log(match);  console.log(match.index)}As it returns an iterator, we can say it's lazy, this is useful when handling particularly large numbers of capturing groups, or very large strings. But if you need, the result can be easily transformed into an Array by using the spread syntax or the Array.from method:function getFirstGroup(regexp, str) {  const array = [...str.matchAll(regexp)];  return array.map(m => m[1]);}// or:function getFirstGroup(regexp, str) {  return Array.from(str.matchAll(regexp), m => m[1]);}In the meantime, while this proposal gets more wide support, you can use the official shim package.Also, the internal workings of the method are simple. An equivalent implementation using a generator function would be as follows:function* matchAll(str, regexp) {  const flags = regexp.global ? regexp.flags : regexp.flags + ""g"";  const re = new RegExp(regexp, flags);  let match;  while (match = re.exec(str)) {    yield match;  }}A copy of the original regexp is created; this is to avoid side-effects due to the mutation of the lastIndex property when going through the multple matches.Also, we need to ensure the regexp has the global flag to avoid an infinite loop.I'm also happy to see that even this StackOverflow question was referenced in the discussions of the proposal."
"data_i","edited May 14 '20 at 10:49","
        How do I completely uninstall Node.js, and reinstall from beginning (Mac OS X)
    ","My version of node is always v0.6.1-pre even after I install brew node and NVM install v0.6.19.My node version is:node -vv0.6.1-preNVM says this (after I install a version of node for the first time in one bash terminal):nvm lsv0.6.19current:    v0.6.19But when I restart bash, this is what I see:nvm lsv0.6.19current:    v0.6.1-predefault -> 0.6.19 (-> v0.6.19)So where is this phantom node 0.6.1-pre version and how can I get rid of it? I'm trying to install libraries via NPM so that I can work on a project.I tried using BREW to update before NVM, using brew update and brew install node. I've tried deleting the ""node"" directory in my /usr/local/include and the ""node"" and ""node_modules"" in my /usr/local/lib.I've tried uninstalling npm and reinstalling it following these instructions.All of this because I was trying to update an older version of node to install the ""zipstream"" library. Now there's folders in my users directory, and the node version STILL isn't up to date, even though NVM says it's using 0.6.19.Ideally, I'd like to uninstall nodejs, npm, and nvm, and just reinstall the entire thing from scratch on my system.","Apparently, there was a /Users/myusername/local folder that contained a include with node and lib with node and node_modules. How and why this was created instead of in my /usr/local folder, I do not know.Deleting these local references fixed the phantom v0.6.1-pre. If anyone has an explanation, I'll choose that as the correct answer.EDIT:You may need to do the additional instructions as well:sudo rm -rf /usr/local/{lib/node{,/.npm,_modules},bin,share/man}/{npm*,node*,man1/node*}which is the equivalent of (same as above)...sudo rm -rf /usr/local/bin/npm /usr/local/share/man/man1/node* /usr/local/lib/dtrace/node.d ~/.npm ~/.node-gyp or (same as above) broken down...To completely uninstall node + npm is to do the following:go to /usr/local/lib and delete any node and node_modulesgo to /usr/local/include and delete any node and node_modules directory if you installed with brew install node, then run brew uninstall node in your terminalcheck your Home directory for any local or lib or include folders, and delete any node or node_modules from therego to /usr/local/bin and delete any node executableYou may also need to do:sudo rm -rf /opt/local/bin/node /opt/local/include/node /opt/local/lib/node_modulessudo rm -rf /usr/local/bin/npm /usr/local/share/man/man1/node.1 /usr/local/lib/dtrace/node.dAdditionally, NVM modifies the PATH variable in $HOME/.bashrc, which must be reverted manually.Then download nvm and follow the instructions to install node. The latest versions of node come with npm, I believe, but you can also reinstall that as well."
"data_i","edited Jun 08 '22 at 14:09","
        How to convert a string to lower case in Bash
    ","Is there a way in bash to convert a string into a lower case string?For example, if I have:a=""Hi all""I want to convert it to:""hi all""","The are various ways:POSIX standardtr$ echo ""$a"" | tr '[:upper:]' '[:lower:]'hi allAWK$ echo ""$a"" | awk '{print tolower($0)}'hi allNon-POSIXYou may run into portability issues with the following examples:Bash 4.0$ echo ""${a,,}""hi allsed$ echo ""$a"" | sed -e 's/\(.*\)/\L\1/'hi all# this also works:$ sed -e 's/\(.*\)/\L\1/' <<< ""$a""hi allPerl$ echo ""$a"" | perl -ne 'print lc'hi allBashlc(){    case ""$1"" in        [A-Z])        n=$(printf ""%d"" ""'$1"")        n=$((n+32))        printf \\$(printf ""%o"" ""$n"")        ;;        *)        printf ""%s"" ""$1""        ;;    esac}word=""I Love Bash""for((i=0;i<${#word};i++))do    ch=""${word:$i:1}""    lc ""$ch""doneNote: YMMV on this one. Doesn't work for me (GNU bash version 4.2.46 and 4.0.33 (and same behaviour 2.05b.0 but nocasematch is not implemented)) even with using shopt -u nocasematch;. Unsetting that nocasematch causes [[ ""fooBaR"" == ""FOObar"" ]] to match OK BUT inside case weirdly [b-z] are incorrectly matched by [A-Z]. Bash is confused by the double-negative (""unsetting nocasematch"")! :-)"
"data_i","edited Nov 30 '19 at 15:31","
        Why does changing 0.1f to 0 slow down performance by 10x?
    ","Why does this bit of code,const float x[16] = {  1.1,   1.2,   1.3,     1.4,   1.5,   1.6,   1.7,   1.8,                       1.9,   2.0,   2.1,     2.2,   2.3,   2.4,   2.5,   2.6};const float z[16] = {1.123, 1.234, 1.345, 156.467, 1.578, 1.689, 1.790, 1.812,                     1.923, 2.034, 2.145,   2.256, 2.367, 2.478, 2.589, 2.690};float y[16];for (int i = 0; i < 16; i++){    y[i] = x[i];}for (int j = 0; j < 9000000; j++){    for (int i = 0; i < 16; i++)    {        y[i] *= x[i];        y[i] /= z[i];        y[i] = y[i] + 0.1f; // <--        y[i] = y[i] - 0.1f; // <--    }}run more than 10 times faster than the following bit (identical except where noted)?const float x[16] = {  1.1,   1.2,   1.3,     1.4,   1.5,   1.6,   1.7,   1.8,                       1.9,   2.0,   2.1,     2.2,   2.3,   2.4,   2.5,   2.6};const float z[16] = {1.123, 1.234, 1.345, 156.467, 1.578, 1.689, 1.790, 1.812,                     1.923, 2.034, 2.145,   2.256, 2.367, 2.478, 2.589, 2.690};float y[16];for (int i = 0; i < 16; i++){    y[i] = x[i];}for (int j = 0; j < 9000000; j++){    for (int i = 0; i < 16; i++)    {        y[i] *= x[i];        y[i] /= z[i];        y[i] = y[i] + 0; // <--        y[i] = y[i] - 0; // <--    }}when compiling with Visual Studio 2010 SP1. The optimization level was -02 with sse2 enabled.I haven't tested with other compilers.","Welcome to the world of denormalized floating-point! They can wreak havoc on performance!!!Denormal (or subnormal) numbers are kind of a hack to get some extra values very close to zero out of the floating point representation. Operations on denormalized floating-point can be tens to hundreds of times slower than on normalized floating-point. This is because many processors can't handle them directly and must trap and resolve them using microcode.If you print out the numbers after 10,000 iterations, you will see that they have converged to different values depending on whether 0 or 0.1 is used.Here's the test code compiled on x64:int main() {    double start = omp_get_wtime();    const float x[16]={1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,2.1,2.2,2.3,2.4,2.5,2.6};    const float z[16]={1.123,1.234,1.345,156.467,1.578,1.689,1.790,1.812,1.923,2.034,2.145,2.256,2.367,2.478,2.589,2.690};    float y[16];    for(int i=0;i<16;i++)    {        y[i]=x[i];    }    for(int j=0;j<9000000;j++)    {        for(int i=0;i<16;i++)        {            y[i]*=x[i];            y[i]/=z[i];#ifdef FLOATING            y[i]=y[i]+0.1f;            y[i]=y[i]-0.1f;#else            y[i]=y[i]+0;            y[i]=y[i]-0;#endif            if (j > 10000)                cout << y[i] << ""  "";        }        if (j > 10000)            cout << endl;    }    double end = omp_get_wtime();    cout << end - start << endl;    system(""pause"");    return 0;}Output:#define FLOATING1.78814e-007  1.3411e-007  1.04308e-007  0  7.45058e-008  6.70552e-008  6.70552e-008  5.58794e-007  3.05474e-007  2.16067e-007  1.71363e-007  1.49012e-007  1.2666e-007  1.11759e-007  1.04308e-007  1.04308e-0071.78814e-007  1.3411e-007  1.04308e-007  0  7.45058e-008  6.70552e-008  6.70552e-008  5.58794e-007  3.05474e-007  2.16067e-007  1.71363e-007  1.49012e-007  1.2666e-007  1.11759e-007  1.04308e-007  1.04308e-007//#define FLOATING6.30584e-044  3.92364e-044  3.08286e-044  0  1.82169e-044  1.54143e-044  2.10195e-044  2.46842e-029  7.56701e-044  4.06377e-044  3.92364e-044  3.22299e-044  3.08286e-044  2.66247e-044  2.66247e-044  2.24208e-0446.30584e-044  3.92364e-044  3.08286e-044  0  1.82169e-044  1.54143e-044  2.10195e-044  2.45208e-029  7.56701e-044  4.06377e-044  3.92364e-044  3.22299e-044  3.08286e-044  2.66247e-044  2.66247e-044  2.24208e-044Note how in the second run the numbers are very close to zero.Denormalized numbers are generally rare and thus most processors don't try to handle them efficiently.To demonstrate that this has everything to do with denormalized numbers, if we flush denormals to zero by adding this to the start of the code:_MM_SET_FLUSH_ZERO_MODE(_MM_FLUSH_ZERO_ON);Then the version with 0 is no longer 10x slower and actually becomes faster. (This requires that the code be compiled with SSE enabled.)This means that rather than using these weird lower precision almost-zero values, we just round to zero instead.Timings: Core i7 920 @ 3.5 GHz://  Don't flush denormals to zero.0.1f: 0.5640670   : 26.7669//  Flush denormals to zero.0.1f: 0.5871170   : 0.341406In the end, this really has nothing to do with whether it's an integer or floating-point. The 0 or 0.1f is converted/stored into a register outside of both loops. So that has no effect on performance."
"data_i","edited Jan 06 '22 at 13:47","
        How can I replace each newline (\n) with a space using sed?
    ","How can I replace a newline (""\n"") with a space ("""") using the sed command?I unsuccessfully tried:    sed 's#\n# #g' filesed 's#^$# #g' fileHow do I fix it?","sed is intended to be used on line-based input. Although it can do what you need.A better option here is to use the tr command as follows:tr '\n' ' ' < input_filenameor remove the newline characters entirely:tr -d '\n' < input.txt > output.txtor if you have the GNU version (with its long options)tr --delete '\n' < input.txt > output.txt"
"data_i","edited Jan 22 '16 at 20:19","
        Creating a div element in jQuery
    ","How do I create a div element in jQuery?","As of jQuery 1.4 you can pass attributes to a self-closed element like so:jQuery('<div>', {    id: 'some-id',    class: 'some-class some-other-class',    title: 'now this div has a title!'}).appendTo('#mySelector');Here it is in the DocsExamples can be found at jQuery 1.4 Released: The 15 New Features you Must Know ."
"data_i","edited Feb 07 '16 at 22:01","
        map function for objects (instead of arrays)
    ","I have an object:myObject = { 'a': 1, 'b': 2, 'c': 3 }I am looking for a native method, similar to Array.prototype.map that would be used as follows:newObject = myObject.map(function (value, label) {    return value * value;});// newObject is now { 'a': 1, 'b': 4, 'c': 9 }Does JavaScript have such a map function for objects? (I want this for Node.JS, so I don't care about cross-browser issues.)","There is no native map to the Object object, but how about this:var myObject = { 'a': 1, 'b': 2, 'c': 3 };Object.keys(myObject).forEach(function(key, index) {  myObject[key] *= 2;});console.log(myObject);// => { 'a': 2, 'b': 4, 'c': 6 }But you could easily iterate over an object using for ... in:var myObject = { 'a': 1, 'b': 2, 'c': 3 };for (var key in myObject) {  if (myObject.hasOwnProperty(key)) {    myObject[key] *= 2;  }}console.log(myObject);// { 'a': 2, 'b': 4, 'c': 6 }UpdateA lot of people are mentioning that the previous methods do not return a new object, but rather operate on the object itself. For that matter I wanted to add another solution that returns a new object and leaves the original object as it is:var myObject = { 'a': 1, 'b': 2, 'c': 3 };// returns a new object with the values at each key mapped using mapFn(value)function objectMap(object, mapFn) {  return Object.keys(object).reduce(function(result, key) {    result[key] = mapFn(object[key])    return result  }, {})}var newObject = objectMap(myObject, function(value) {  return value * 2})console.log(newObject);// => { 'a': 2, 'b': 4, 'c': 6 }console.log(myObject);// => { 'a': 1, 'b': 2, 'c': 3 }Array.prototype.reduce reduces an array to a single value by somewhat merging the previous value with the current. The chain is initialized by an empty object {}. On every iteration a new key of myObject is added with twice the key as the value.UpdateWith new ES6 features, there is a more elegant way to express objectMap.const objectMap = (obj, fn) =>  Object.fromEntries(    Object.entries(obj).map(      ([k, v], i) => [k, fn(v, k, i)]    )  )  const myObject = { a: 1, b: 2, c: 3 }console.log(objectMap(myObject, v => 2 * v)) "
"data_i","edited Sep 18 '19 at 17:55","
        What is the best algorithm for overriding GetHashCode?
    ","In .NET, the GetHashCode method is used in a lot of places throughout the .NET base class libraries. Implementing it properly is especially important to find items quickly in a collection or when determining equality.Is there a standard algorithm or best practice on how to implement GetHashCode for my custom classes so I don't degrade performance?","I usually go with something like the implementation given in Josh Bloch's fabulous Effective Java. It's fast and creates a pretty good hash which is unlikely to cause collisions. Pick two different prime numbers, e.g. 17 and 23, and do:public override int GetHashCode(){    unchecked // Overflow is fine, just wrap    {        int hash = 17;        // Suitable nullity checks etc, of course :)        hash = hash * 23 + field1.GetHashCode();        hash = hash * 23 + field2.GetHashCode();        hash = hash * 23 + field3.GetHashCode();        return hash;    }}As noted in comments, you may find it's better to pick a large prime to multiply by instead. Apparently 486187739 is good... and although most examples I've seen with small numbers tend to use primes, there are at least similar algorithms where non-prime numbers are often used. In the not-quite-FNV example later, for example, I've used numbers which apparently work well - but the initial value isn't a prime. (The multiplication constant is prime though. I don't know quite how important that is.)This is better than the common practice of XORing hashcodes for two main reasons. Suppose we have a type with two int fields:XorHash(x, x) == XorHash(y, y) == 0 for all x, yXorHash(x, y) == XorHash(y, x) for all x, yBy the way, the earlier algorithm is the one currently used by the C# compiler for anonymous types.This page gives quite a few options. I think for most cases the above is ""good enough"" and it's incredibly easy to remember and get right. The FNV alternative is similarly simple, but uses different constants and XOR instead of ADD as a combining operation. It looks something like the code below, but the normal FNV algorithm operates on individual bytes, so this would require modifying to perform one iteration per byte, instead of per 32-bit hash value. FNV is also designed for variable lengths of data, whereas the way we're using it here is always for the same number of field values. Comments on this answer suggest that the code here doesn't actually work as well (in the sample case tested) as the addition approach above.// Note: Not quite FNV!public override int GetHashCode(){    unchecked // Overflow is fine, just wrap    {        int hash = (int) 2166136261;        // Suitable nullity checks etc, of course :)        hash = (hash * 16777619) ^ field1.GetHashCode();        hash = (hash * 16777619) ^ field2.GetHashCode();        hash = (hash * 16777619) ^ field3.GetHashCode();        return hash;    }}Note that one thing to be aware of is that ideally you should prevent your equality-sensitive (and thus hashcode-sensitive) state from changing after adding it to a collection that depends on the hash code.As per the documentation:You can override GetHashCode for immutable reference types. In general, for mutable reference types, you should override GetHashCode only if:You can compute the hash code from fields that are not mutable; orYou can ensure that the hash code of a mutable object does not change while the object is contained in a collection that relies on its hash code.The link to the FNV article is broken but here is a copy in the Internet Archive: Eternally Confuzzled - The Art of Hashing"
"data_i","edited Sep 03 '18 at 01:39","
        How do I force a favicon refresh?
    ","I have a Grails application running locally using its own tomcat and I have just changed the favicon for a new one.  Problem is that I can not see it in any browser.  The old favicon shows up or I get no favicon at all, but not my new one.  I do not think this is a Grails issue per se, more an issue with favicons.What is supposed to happen with favicons?  How are they supposed to work?  I have numerous bookmarks in my browser which have the wrong icons and they never seem to get refreshed.  How do I force the server/browser to stop caching them?  It seems pretty silly to always cache them given they are normally only 16x16.  Why not just upload them with every visit to the page? It is not exactly a huge overhead.","To refresh your site's favicon you can force browsers to download a new version using the link tag and a query string on your filename.This is especially helpful in production environments to make sure your users get the update.<link rel=""icon"" href=""http://www.yoursite.com/favicon.ico?v=2"" />"
"data_i","edited Oct 30 '15 at 09:10","
         vs 
    ","In order to define charset for HTML5 Doctype, which notation should I use?Short:<meta charset=""utf-8"" /> Long:<meta http-equiv=""Content-Type"" content=""text/html; charset=utf-8"" />","In HTML5, they are equivalent. Use the shorter one, as it is easier to remember and type. Browser support is fine since it was designed for backwards compatibility."
"data_i","edited Jun 05 '22 at 05:12","
        How can I make a dictionary from separate lists of keys and values?
    ","I want to combine these:keys = ['name', 'age', 'food']values = ['Monty', 42, 'spam']Into a single dictionary:{'name': 'Monty', 'age': 42, 'food': 'spam'}","Like this:keys = ['a', 'b', 'c']values = [1, 2, 3]dictionary = dict(zip(keys, values))print(dictionary) # {'a': 1, 'b': 2, 'c': 3}Voila :-)  The pairwise dict constructor and zip function are awesomely useful."
"data_i","edited Oct 02 '21 at 07:17","
        How can I delete using INNER JOIN with SQL Server?
    ","I want to delete using INNER JOIN in SQL Server 2008.But I get this error:Msg 156, Level 15, State 1, Line 15Incorrect syntax near the keyword 'INNER'.My code:DELETE FROM WorkRecord2 INNER JOIN Employee         ON EmployeeRun=EmployeeNoWHERE Company = '1'     AND Date = '2013-05-06'","You need to specify what table you are deleting from. Here is a version with an alias:DELETE wFROM WorkRecord2 wINNER JOIN Employee e  ON EmployeeRun=EmployeeNoWHERE Company = '1' AND Date = '2013-05-06'"
"data_i","edited Jul 10 '22 at 00:19","
        Calculate relative time in C#
    ","Given a specific DateTime value, how do I display relative time, like:2 hours ago3 days agoa month ago","Jeff, your code is nice but could be clearer with constants (as suggested in Code Complete).const int SECOND = 1;const int MINUTE = 60 * SECOND;const int HOUR = 60 * MINUTE;const int DAY = 24 * HOUR;const int MONTH = 30 * DAY;var ts = new TimeSpan(DateTime.UtcNow.Ticks - yourDate.Ticks);double delta = Math.Abs(ts.TotalSeconds);if (delta < 1 * MINUTE)  return ts.Seconds == 1 ? ""one second ago"" : ts.Seconds + "" seconds ago"";if (delta < 2 * MINUTE)  return ""a minute ago"";if (delta < 45 * MINUTE)  return ts.Minutes + "" minutes ago"";if (delta < 90 * MINUTE)  return ""an hour ago"";if (delta < 24 * HOUR)  return ts.Hours + "" hours ago"";if (delta < 48 * HOUR)  return ""yesterday"";if (delta < 30 * DAY)  return ts.Days + "" days ago"";if (delta < 12 * MONTH){  int months = Convert.ToInt32(Math.Floor((double)ts.Days / 30));  return months <= 1 ? ""one month ago"" : months + "" months ago"";}else{  int years = Convert.ToInt32(Math.Floor((double)ts.Days / 365));  return years <= 1 ? ""one year ago"" : years + "" years ago"";}"
"data_i","edited Mar 26 '18 at 06:50","
        What is the difference between UNION and UNION ALL?
    ","What is the difference between UNION and UNION ALL?","UNION removes duplicate records (where all columns in the results are the same), UNION ALL does not.There is a performance hit when using UNION instead of UNION ALL, since the database server must do additional work to remove the duplicate rows, but usually you do not want the duplicates (especially when developing reports).To identify duplicates, records must be comparable types as well as compatible types. This will depend on the SQL system. For example the system may truncate all long text fields to make short text fields for comparison (MS Jet), or may refuse to compare binary fields (ORACLE)UNION Example:SELECT 'foo' AS bar UNION SELECT 'foo' AS barResult:+-----+| bar |+-----+| foo |+-----+1 row in set (0.00 sec)UNION ALL example:SELECT 'foo' AS bar UNION ALL SELECT 'foo' AS barResult:+-----+| bar |+-----+| foo || foo |+-----+2 rows in set (0.00 sec)"
"data_i","edited Nov 21 '19 at 16:17","
        Sorting an array of objects by property values
    ","I've got the following objects using AJAX and stored them in an array:var homes = [    {        ""h_id"": ""3"",        ""city"": ""Dallas"",        ""state"": ""TX"",        ""zip"": ""75201"",        ""price"": ""162500""    }, {        ""h_id"": ""4"",        ""city"": ""Bevery Hills"",        ""state"": ""CA"",        ""zip"": ""90210"",        ""price"": ""319250""    }, {        ""h_id"": ""5"",        ""city"": ""New York"",        ""state"": ""NY"",        ""zip"": ""00010"",        ""price"": ""962500""    }];How do I create a function to sort the objects by the price property in ascending or descending order using JavaScript only?","Sort homes by price in ascending order:homes.sort(function(a, b) {    return parseFloat(a.price) - parseFloat(b.price);});Or after ES6 version:homes.sort((a, b) => parseFloat(a.price) - parseFloat(b.price));Some documentation can be found here.For descending order, you may use homes.sort((a, b) => parseFloat(b.price) - parseFloat(a.price));"
"data_i","edited Jan 23 '18 at 23:14","
        Getting Chrome to accept self-signed localhost certificate
    ","I have created a self-signed SSL certificate for the localhost CN. Firefox accepts this certificate after initially complaining about it, as expected. Chrome and IE, however, refuse to accept it, even after adding the certificate to the system certificate store under Trusted Roots. Even though the certificate is listed as correctly installed when I click ""View certificate information"" in Chrome's HTTPS popup, it still insists the certificate cannot be trusted.What am I supposed to do to get Chrome to accept the certificate and stop complaining about it?","For localhost onlySimply paste this in your chrome:chrome://flags/#allow-insecure-localhostYou should see highlighted text saying:Allow invalid certificates for resources loaded from localhostClick Enable.Other sitesTry typing thisisunsafe anywhere on the window, and the browser should let you visit the page.-OR-For a local self-signed cert that avoids arcane commands, specialized knowledge, and manual steps try mkcert from this answer."
"data_i","edited Apr 09 '22 at 07:37","
        How do I import a module given the full path?
    ","How do I load a Python module given its full path?Note that the file can be anywhere in the filesystem.","For Python 3.5+ use (docs):import importlib.utilimport sysspec = importlib.util.spec_from_file_location(""module.name"", ""/path/to/file.py"")foo = importlib.util.module_from_spec(spec)sys.modules[""module.name""] = foospec.loader.exec_module(foo)foo.MyClass()For Python 3.3 and 3.4 use:from importlib.machinery import SourceFileLoaderfoo = SourceFileLoader(""module.name"", ""/path/to/file.py"").load_module()foo.MyClass()(Although this has been deprecated in Python 3.4.)For Python 2 use:import impfoo = imp.load_source('module.name', '/path/to/file.py')foo.MyClass()There are equivalent convenience functions for compiled Python files and DLLs.See also http://bugs.python.org/issue21436."
"data_i","edited May 06 '16 at 12:05","
        Why does Java have transient fields?
    ","Why does Java have transient fields?","The transient keyword in Java is used to indicate that a field should not be  part of the serialization (which means saved, like to a file) process.From the Java Language Specification, Java SE 7 Edition, Section 8.3.1.3. transient Fields:Variables may be marked transient toindicate that they are not part of thepersistent state of an object.For example, you may have fields that are derived from other fields, and should only be done so programmatically, rather than having the state be persisted via serialization.Here's a GalleryImage class which contains an image and a thumbnail derived from the image:class GalleryImage implements Serializable{    private Image image;    private transient Image thumbnailImage;    private void generateThumbnail()    {        // Generate thumbnail.    }    private void readObject(ObjectInputStream inputStream)            throws IOException, ClassNotFoundException    {        inputStream.defaultReadObject();        generateThumbnail();    }    }In this example, the thumbnailImage is a thumbnail image that is generated by invoking the generateThumbnail method.The thumbnailImage field is marked as transient, so only the original image is serialized rather than persisting both the original image and the thumbnail image. This means that less storage would be needed to save the serialized object. (Of course, this may or may not be desirable depending on the requirements of the system -- this is just an example.)At the time of deserialization, the readObject method is called to perform any operations necessary to restore the state of the object back to the state at which the serialization occurred. Here, the thumbnail needs to be generated, so the readObject method is overridden so that the thumbnail will be generated by calling the generateThumbnail method.For additional information, the article Discover the secrets of the Java Serialization API (which was originally available on the Sun Developer Network) has a section which discusses the use of and presents a scenario where the transient keyword is used to prevent serialization of certain fields."
"data_i","edited Sep 26 '19 at 22:24","
        What is the difference between const and readonly in C#?
    ","What is the difference between const and readonly in C#? When would you use one over the other?","Apart from the apparent difference ofhaving to declare the value at the time of a definition for a const VS readonly values can be computed dynamically but need to be assigned before the constructor exits.. after that it is frozen.const's are implicitly static. You use a ClassName.ConstantName notation to access them.There is a subtle difference. Consider a class defined in AssemblyA.public class Const_V_Readonly{  public const int I_CONST_VALUE = 2;  public readonly int I_RO_VALUE;  public Const_V_Readonly()  {     I_RO_VALUE = 3;  }}AssemblyB references AssemblyA and uses these values in code. When this is compiled:in the case of the const value, it is like a find-replace.  The value 2 is 'baked into' the AssemblyB's IL. This means that if tomorrow I update I_CONST_VALUE to 20, AssemblyB would still have 2 till I recompile it.in the case of the readonly value, it is like a ref to a memory location. The value is not baked into AssemblyB's IL. This means that if the memory location is updated, AssemblyB gets the new value without recompilation. So if I_RO_VALUE is updated to 30, you only need to build AssemblyA and all clients do not need to be recompiled.So if you are confident that the value of the constant won't change, use a const.public const int CM_IN_A_METER = 100;But if you have a constant that may change (e.g. w.r.t. precision).. or when in doubt, use a readonly.public readonly float PI = 3.14;Update: Aku needs to get a mention because he pointed this out first. Also I need to plug where I learned this: Effective C# - Bill Wagner"
"data_i","edited Jul 22 '20 at 08:35","
        How to measure time taken by a function to execute
    ","I need to get execution time in milliseconds.I originally asked this question back in 2008. The accepted answer then was to use new Date().getTime() However, we can all agree now  that using the standard performance.now() API is more appropriate. I am therefore changing the accepted answer to this one.","Using  performance.now():var startTime = performance.now()doSomething()   // <---- measured code goes between startTime and endTime    var endTime = performance.now()console.log(`Call to doSomething took ${endTime - startTime} milliseconds`)In Node.js it is required to import the performance classimporting performanceconst { performance } = require('perf_hooks');Using console.time: (living standard)console.time('doSomething')    doSomething()   // <---- The function you're measuring time for     console.timeEnd('doSomething')Note: The string being passed to the time() and timeEnd() methods must match(for the timer to finish as expected).console.time() documentations:MDN documentationNode.js documentation"
"data_i","edited Sep 19 '11 at 19:37","
        What is the difference between varchar and nvarchar?
    ","Is it just that nvarchar supports multibyte characters? If that is the case, is there really any point, other than storage concerns, to using varchars?","An nvarchar column can store any Unicode data. A varchar column is restricted to an 8-bit codepage. Some people think that varchar should be used because it takes up less space. I believe this is not the correct answer. Codepage incompatabilities are a pain, and Unicode is the cure for codepage problems. With cheap disk and memory nowadays, there is really no reason to waste time mucking around with code pages anymore.All modern operating systems and development platforms use Unicode internally. By using nvarchar rather than varchar, you can avoid doing encoding conversions every time you read from or write to the database. Conversions take time, and are prone to errors. And recovery from conversion errors is a non-trivial problem.If you are interfacing with an application that uses only ASCII, I would still recommend using Unicode in the database. The OS and database collation algorithms will work better with Unicode. Unicode avoids conversion problems when interfacing with other systems. And you will be preparing for the future. And you can always validate that your data is restricted to 7-bit ASCII for whatever legacy system you're having to maintain, even while enjoying some of the benefits of full Unicode storage."
"data_i","edited Sep 09 '16 at 15:35","
        Break a previous commit into multiple commits
    ","Without creating a branch and doing a bunch of funky work on a new branch, is it possible to break a single commit into a few different commits after it's been committed to the local repository?","git rebase -i will do it.First, start with a clean working directory: git status should show no pending modifications, deletions, or additions.Now, you have to decide which commit(s) you want to split.A) Splitting the most recent commitTo split apart your most recent commit, first:$ git reset HEAD~Now commit the pieces individually in the usual way, producing as many commits as you need.B) Splitting a commit farther backThis requires rebasing, that is, rewriting history. To specify the correct commit, you have several choices:If it is three commits back, then  $ git rebase -i HEAD~3where 3 is how many commits back it is.If it is farther back in the tree than you want to count, then  $ git rebase -i 123abcd~where 123abcd is the SHA1 of the commit you want to split up.If you are on a different branch (e.g., a feature branch) that you want to merge into master:  $ git rebase -i masterWhen you get the rebase edit screen, find the commit you want to break apart.  At the beginning of that line, replace pick with edit (e for short).  Save the buffer and exit.  Rebase will now stop just after the commit you want to edit.  Then:$ git reset HEAD~Commit the pieces individually in the usual way, producing as many commits as you need.Finally$ git rebase --continue"
"data_i","edited Jul 04 '19 at 15:37","
        Why is it important to override GetHashCode when Equals method is overridden?
    ","Given the following classpublic class Foo{    public int FooId { get; set; }    public string FooName { get; set; }    public override bool Equals(object obj)    {        Foo fooItem = obj as Foo;        if (fooItem == null)         {           return false;        }        return fooItem.FooId == this.FooId;    }    public override int GetHashCode()    {        // Which is preferred?        return base.GetHashCode();        //return this.FooId.GetHashCode();    }}I have overridden the Equals method because Foo represent a row for the Foos table.  Which is the preferred method for overriding the GetHashCode?Why is it important to override GetHashCode?","Yes, it is important if your item will be used as a key in a dictionary, or HashSet<T>, etc - since this is used (in the absence of a custom IEqualityComparer<T>) to group items into buckets. If the hash-code for two items does not match, they may never be considered equal (Equals will simply never be called).The GetHashCode() method should reflect the Equals logic; the rules are:if two things are equal (Equals(...) == true) then they must return the same value for GetHashCode()if the GetHashCode() is equal, it is not necessary for them to be the same; this is a collision, and Equals will be called to see if it is a real equality or not.In this case, it looks like ""return FooId;"" is a suitable GetHashCode() implementation. If you are testing multiple properties, it is common to combine them using code like below, to reduce diagonal collisions (i.e. so that new Foo(3,5) has a different hash-code to new Foo(5,3)):In modern frameworks, the HashCode type has methods to help you create a hashcode from multiple values; on older frameworks, you'd need to go without, so something like:unchecked // only needed if you're compiling with arithmetic checks enabled{ // (the default compiler behaviour is *disabled*, so most folks won't need this)    int hash = 13;    hash = (hash * 7) + field1.GetHashCode();    hash = (hash * 7) + field2.GetHashCode();    ...    return hash;}Oh - for convenience, you might also consider providing == and != operators when overriding Equals and GetHashCode.A demonstration of what happens when you get this wrong is here."
"data_i","edited May 15 '17 at 14:16","
        How can I get the ID of an element using jQuery?
    ","<div id=""test""></div><script>  $(document).ready(function() {    alert($('#test').id);  });  </script>Why doesn't the above work, and how should I do this?","The jQuery way:$('#test').attr('id')In your example:$(document).ready(function() {  console.log($('#test').attr('id'));});<script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js""></script><div id=""test""></div>Or through the DOM:$('#test').get(0).id;or even :$('#test')[0].id;and reason behind usage of $('#test').get(0) in JQuery or even $('#test')[0] is that $('#test') is a JQuery selector and returns an array() of results not a single element by its default functionalityan alternative for DOM selector in jquery is $('#test').prop('id')which is different from .attr() and $('#test').prop('foo') grabs the specified DOM foo property, while $('#test').attr('foo') grabs the specified HTML foo attribute and you can find more details about differences here."
"data_i","edited Sep 13 '16 at 22:48","
        How to fully delete a git repository created with init?
    ","I created a git repository with git init. I'd like to delete it entirely and init a new one.","Git keeps all of its files in the .git directory. Just remove that one and init again.If you can't find it, it's because it is hidden.In Windows 7, you need to go to your folder, click on Organize on the top left, then click on Folder and search options, then click on the View tab and click on the Show hidden files, folders and drives radio button.On a Mac OS:Open a Terminal (via Spotlight: press CMD + SPACE, type terminal and press Enter) and run:defaults write com.apple.finder AppleShowAllFiles 1 && killall FinderNote: The keyboard shortcut to show hidden files in Finder is CMD + SHIFT + . so it is no longer necessary to modify the finder config this wayYou could also type cd (the space is important), drag and drop your git repo folder from Finder to the terminal window, press return, then type rm -fr .git, then return again.On Ubuntu, use shortcut Ctrl + H."
"data_i","edited May 23 '17 at 12:34","
        Try-catch speeding up my code?
    ","I wrote some code for testing the impact of try-catch, but seeing some surprising results.static void Main(string[] args){    Thread.CurrentThread.Priority = ThreadPriority.Highest;    Process.GetCurrentProcess().PriorityClass = ProcessPriorityClass.RealTime;    long start = 0, stop = 0, elapsed = 0;    double avg = 0.0;    long temp = Fibo(1);    for (int i = 1; i < 100000000; i++)    {        start = Stopwatch.GetTimestamp();        temp = Fibo(100);        stop = Stopwatch.GetTimestamp();        elapsed = stop - start;        avg = avg + ((double)elapsed - avg) / i;    }    Console.WriteLine(""Elapsed: "" + avg);    Console.ReadKey();}static long Fibo(int n){    long n1 = 0, n2 = 1, fibo = 0;    n++;    for (int i = 1; i < n; i++)    {        n1 = n2;        n2 = fibo;        fibo = n1 + n2;    }    return fibo;}On my computer, this consistently prints out a value around 0.96..When I wrap the for loop inside Fibo() with a try-catch block like this:static long Fibo(int n){    long n1 = 0, n2 = 1, fibo = 0;    n++;    try    {        for (int i = 1; i < n; i++)        {            n1 = n2;            n2 = fibo;            fibo = n1 + n2;        }    }    catch {}    return fibo;}Now it consistently prints out 0.69... -- it actually runs faster! But why?Note: I compiled this using the Release configuration and directly ran the EXE file (outside Visual Studio).EDIT: Jon Skeet's excellent analysis shows that try-catch is somehow causing the x86 CLR to use the CPU registers in a more favorable way in this specific case (and I think we're yet to understand why). I confirmed Jon's finding that x64 CLR doesn't have this difference, and that it was faster than the x86 CLR. I also tested using int types inside the Fibo method instead of long types, and then the x86 CLR was as equally fast as the x64 CLR.UPDATE: It looks like this issue has been fixed by Roslyn. Same machine, same CLR version -- the issue remains as above when compiled with VS 2013, but the problem goes away when compiled with VS 2015. ","One of the Roslyn engineers who specializes in understanding optimization of stack usage took a look at this and reports to me that there seems to be a problem in the interaction between the way the C# compiler generates local variable stores and the way the JIT compiler does register scheduling in the corresponding x86 code. The result is suboptimal code generation on the loads and stores of the locals.For some reason unclear to all of us, the problematic code generation path is avoided when the JITter knows that the block is in a try-protected region. This is pretty weird. We'll follow up with the JITter team and see whether we can get a bug entered so that they can fix this. Also, we are working on improvements for Roslyn to the C# and VB compilers' algorithms for determining when locals can be made ""ephemeral"" -- that is, just pushed and popped on the stack, rather than allocated a specific location on the stack for the duration of the activation. We believe that the JITter will be able to do a better job of register allocation and whatnot if we give it better hints about when locals can be made ""dead"" earlier.Thanks for bringing this to our attention, and apologies for the odd behaviour. "
"data_i","edited Apr 11 '22 at 21:48","
        How can I vertically center a div element for all browsers using CSS?
    ","I want to center a div vertically with CSS. I don't want tables or JavaScript, but only pure CSS. I found some solutions, but all of them are missing Internet Explorer 6 support.<body>    <div>Div to be aligned vertically</div></body>How can I center a div vertically in all major browsers, including Internet Explorer 6?","Below is the best all-around solution I could build to vertically and horizontally center a fixed-width, flexible height content box. It was tested and worked for recent versions of Firefox, Opera, Chrome, and Safari..outer {  display: table;  position: absolute;  top: 0;  left: 0;  height: 100%;  width: 100%;}.middle {  display: table-cell;  vertical-align: middle;}.inner {  margin-left: auto;  margin-right: auto;  width: 400px;  /* Whatever width you want */}<div class=""outer"">  <div class=""middle"">    <div class=""inner"">      <h1>The Content</h1>      <p>Once upon a midnight dreary...</p>    </div>  </div></div>View A Working Example With Dynamic ContentI built in some dynamic content to test the flexibility and would love to know if anyone sees any problems with it. It should work well for centered overlays also -- lightbox, pop-up, etc."
"data_i","edited May 19 '22 at 22:01","
        Selecting multiple columns in a Pandas dataframe
    ","How do I select columns a and b from df, and save them into a new dataframe df1?index  a   b   c1      2   3   42      3   4   5Unsuccessful attempt:df1 = df['a':'b']df1 = df.ix[:, 'a':'b']","The column names (which are strings) cannot be sliced in the manner you tried.Here you have a couple of options. If you know from context which variables you want to slice out, you can just return a view of only those columns by passing a list into the __getitem__ syntax (the []'s).df1 = df[['a', 'b']]Alternatively, if it matters to index them numerically and not by their name (say your code should automatically do this without knowing the names of the first two columns) then you can do this instead:df1 = df.iloc[:, 0:2] # Remember that Python does not slice inclusive of the ending index.Additionally, you should familiarize yourself with the idea of a view into a Pandas object vs. a copy of that object. The first of the above methods will return a new copy in memory of the desired sub-object (the desired slices).Sometimes, however, there are indexing conventions in Pandas that don't do this and instead give you a new variable that just refers to the same chunk of memory as the sub-object or slice in the original object. This will happen with the second way of indexing, so you can modify it with the .copy() method to get a regular copy. When this happens, changing what you think is the sliced object can sometimes alter the original object. Always good to be on the look out for this.df1 = df.iloc[0, 0:2].copy() # To avoid the case where changing df1 also changes dfTo use iloc, you need to know the column positions (or indices). As the column positions may change, instead of hard-coding indices, you can use iloc along with get_loc function of columns method of dataframe object to obtain column indices.{df.columns.get_loc(c): c for idx, c in enumerate(df.columns)}Now you can use this dictionary to access columns through names and using iloc."
"data_i","edited Jun 14 '20 at 10:42","
        Font scaling based on width of container
    ","I'm having a hard time getting my head around font scaling.I currently have a website with a body font-size of 100%. 100% of what though? This seems to compute out at 16 pixels.I was under the impression that 100% would somehow refer to the size of the browser window, but apparently not because it's always 16 pixels whether the window is resized down to a mobile width or full-blown widescreen desktop.How can I make the text on my site scale in relation to its container? I tried using em, but this doesn't scale either.My reasoning is that things like my menu become squished when you resize, so I need to reduce the px font-size of .menuItem among other elements in relation to the width of the container. (For example, in the menu on a large desktop, 22px works perfectly. Move down to tablet width and 16px is more appropriate.)I'm aware I can add breakpoints, but I really want the text to scale as well as having extra breakpoints, otherwise, I'll end up with hundreds of breakpoints for every 100pixels decrease in width to control the text.","If the container is not the body, CSS Tricks covers all of your options in Fitting Text to a Container.If the container is the body, what you are looking for is Viewport-percentage lengths:The viewport-percentage lengths are relative to the size of the initial containing block. When the height or width of the initial containing block is changed, they are scaled accordingly. However, when the value of overflow on the root element is auto, any scroll bars are assumed not to exist.The values are:vw (% of the viewport width)vh (% of the viewport height)vi (1% of the viewport size in the direction of the root element's inline axis)vb (1% of the viewport size in the direction of the root element's block axis)vmin (the smaller of vw or vh)vmax (the larger or vw or vh)1 v* is equal to 1% of the initial containing block.Using it looks like this:p {    font-size: 4vw;}As you can see, when the viewport width increases, so do the font-size, without needing to use media queries.These values are a sizing unit, just like px or em, so they can be used to size other elements as well, such as width, margin, or padding.Browser support is pretty good, but you'll likely need a fallback, such as:p {    font-size: 16px;    font-size: 4vw;}Check out the support statistics: http://caniuse.com/#feat=viewport-units.Also, check out CSS-Tricks for a broader look: Viewport Sized TypographyHere's a nice article about setting minimum/maximum sizes and exercising a bit more control over the sizes: Precise control over responsive typographyAnd here's an article about setting your size using calc() so that the text fills the viewport: http://codepen.io/CrocoDillon/pen/fBJxuAlso, please view this article, which uses a technique dubbed 'molten leading' to adjust the line-height as well. Molten Leading in CSS"
"data_i","edited Dec 20 '14 at 15:45","
        How can I Remove .DS_Store files from a Git repository?
    ","How can I remove those annoying Mac OS X .DS_Store files from a Git repository?","Remove existing .DS_Store files from the repository:find . -name .DS_Store -print0 | xargs -0 git rm -f --ignore-unmatchAdd this line:.DS_Storeto the file .gitignore, which can be found at the top level of your repository (or create the file if it isn't there already). You can do this easily with this command in the top directory:echo .DS_Store >> .gitignoreThen commit the file to the repo:git add .gitignoregit commit -m '.DS_Store banished!'"
"data_i","edited Apr 09 '22 at 07:21","
        Why do Python classes inherit object?
    ","Why does the following class declaration inherit from object?class MyClass(object):    ...","Is there any reason for a class declaration to inherit from object?In Python 3, apart from compatibility between Python 2 and 3, no reason. In Python 2, many reasons. Python 2.x story:In Python 2.x (from 2.2 onwards) there's two styles of classes depending on the presence or absence of object as a base-class:""classic"" style classes: they don't have object as a base class:>>> class ClassicSpam:      # no base class...     pass>>> ClassicSpam.__bases__()""new"" style classes: they have, directly or indirectly (e.g inherit from a built-in type), object as a base class:>>> class NewSpam(object):           # directly inherit from object...    pass>>> NewSpam.__bases__(<type 'object'>,)>>> class IntSpam(int):              # indirectly inherit from object......    pass>>> IntSpam.__bases__(<type 'int'>,) >>> IntSpam.__bases__[0].__bases__   # ... because int inherits from object  (<type 'object'>,)Without a doubt, when writing a class you'll always want to go for new-style classes. The perks of doing so are numerous, to list some of them:Support for descriptors. Specifically, the following constructs are made possible with descriptors: classmethod: A method that receives the class as an implicit argument instead of the instance.staticmethod: A method that does not receive the implicit argument self as a first argument.properties with property: Create functions for managing the getting, setting and deleting of an attribute. __slots__: Saves memory consumptions of a class and also results in faster attribute access. Of course, it does impose limitations.The __new__ static method: lets you customize how new class instances are created. Method resolution order (MRO): in what order the base classes of a class will be searched when trying to resolve which method to call. Related to MRO, super calls. Also see, super() considered super.If you don't inherit from object, forget these. A more exhaustive description of the previous bullet points along with other perks of ""new"" style classes can be found here.One of the downsides of new-style classes is that the class itself is more memory demanding. Unless you're creating many class objects, though, I doubt this would be an issue and it's a negative sinking in a sea of positives.Python 3.x story:In Python 3, things are simplified. Only new-style classes exist (referred to plainly as classes) so, the only difference in adding object is requiring you to type in 8 more characters. This:class ClassicSpam:    passis completely equivalent (apart from their name :-) to this:class NewSpam(object):     passand to this:class Spam():    passAll have object in their __bases__.>>> [object in cls.__bases__ for cls in {Spam, NewSpam, ClassicSpam}][True, True, True]So, what should you do?In Python 2: always inherit from object explicitly. Get the perks.In Python 3: inherit from object if you are writing code that tries to be Python agnostic, that is, it needs to work both in Python 2 and in Python 3. Otherwise don't, it really makes no difference since Python inserts it for you behind the scenes."
"data_i","edited Aug 13 '15 at 23:13","
        Cycles in family tree software
    ","I am the developer of some family tree software (written in C++ and Qt). I had no problems until one of my customers mailed me a bug report. The problem is that the customer has two children with their own daughter, and, as a result, he can't use my software because of errors.Those errors are the result of my various assertions and invariants about the family graph being processed (for example, after walking a cycle, the program states that X can't be both father and grandfather of Y).How can I resolve those errors without removing all data assertions?","It seems you (and/or your company) have a fundamental misunderstanding of what a family tree is supposed to be. Let me clarify, I also work for a company that has (as one of its products) a family tree in its portfolio, and we have been struggling with similar problems.The problem, in our case, and I assume your case as well, comes from the GEDCOM format that is extremely opinionated about what a family should be. However this format contains some severe misconceptions about what a family tree really looks like.GEDCOM has many issues, such as incompatibility with same sex relations, incest, etc... Which in real life happens more often than you'd imagine (especially when going back in time to the 1700-1800).We have modeled our family tree to what happens in the real world: Events (for example, births, weddings, engagement, unions, deaths, adoptions, etc.). We do not put any restrictions on these, except for logically impossible ones (for example, one can't be one's own parent, relations need two individuals, etc...)The lack of validations gives us a more ""real world"", simpler and more flexible solution.As for this specific case, I would suggest removing the assertions as they do not hold universally.For displaying issues (that will arise) I would suggest drawing the same node as many times as needed, hinting at the duplication by lighting up all the copies on selecting one of them."
"data_i","edited Nov 27 '19 at 09:37","
        Replacing a 32-bit loop counter with 64-bit introduces crazy performance deviations with _mm_popcnt_u64 on Intel CPUs
    ","I was looking for the fastest way to popcount large arrays of data. I encountered a very weird effect: Changing the loop variable from unsigned to uint64_t made the performance drop by 50% on my PC.The Benchmark#include <iostream>#include <chrono>#include <x86intrin.h>int main(int argc, char* argv[]) {    using namespace std;    if (argc != 2) {       cerr << ""usage: array_size in MB"" << endl;       return -1;    }    uint64_t size = atol(argv[1])<<20;    uint64_t* buffer = new uint64_t[size/8];    char* charbuffer = reinterpret_cast<char*>(buffer);    for (unsigned i=0; i<size; ++i)        charbuffer[i] = rand()%256;    uint64_t count,duration;    chrono::time_point<chrono::system_clock> startP,endP;    {        startP = chrono::system_clock::now();        count = 0;        for( unsigned k = 0; k < 10000; k++){            // Tight unrolled loop with unsigned            for (unsigned i=0; i<size/8; i+=4) {                count += _mm_popcnt_u64(buffer[i]);                count += _mm_popcnt_u64(buffer[i+1]);                count += _mm_popcnt_u64(buffer[i+2]);                count += _mm_popcnt_u64(buffer[i+3]);            }        }        endP = chrono::system_clock::now();        duration = chrono::duration_cast<std::chrono::nanoseconds>(endP-startP).count();        cout << ""unsigned\t"" << count << '\t' << (duration/1.0E9) << "" sec \t""             << (10000.0*size)/(duration) << "" GB/s"" << endl;    }    {        startP = chrono::system_clock::now();        count=0;        for( unsigned k = 0; k < 10000; k++){            // Tight unrolled loop with uint64_t            for (uint64_t i=0;i<size/8;i+=4) {                count += _mm_popcnt_u64(buffer[i]);                count += _mm_popcnt_u64(buffer[i+1]);                count += _mm_popcnt_u64(buffer[i+2]);                count += _mm_popcnt_u64(buffer[i+3]);            }        }        endP = chrono::system_clock::now();        duration = chrono::duration_cast<std::chrono::nanoseconds>(endP-startP).count();        cout << ""uint64_t\t""  << count << '\t' << (duration/1.0E9) << "" sec \t""             << (10000.0*size)/(duration) << "" GB/s"" << endl;    }    free(charbuffer);}As you see, we create a buffer of random data, with the size being x megabytes where x is read from the command line. Afterwards, we iterate over the buffer and use an unrolled version of the x86 popcount intrinsic to perform the popcount. To get a more precise result, we do the popcount 10,000 times. We measure the times for the popcount. In the upper case, the inner loop variable is unsigned, in the lower case, the inner loop variable is uint64_t. I thought that this should make no difference, but the opposite is the case.The (absolutely crazy) resultsI compile it like this (g++ version: Ubuntu 4.8.2-19ubuntu1):g++ -O3 -march=native -std=c++11 test.cpp -o testHere are the results on my Haswell Core i7-4770K CPU @ 3.50 GHz, running test 1 (so 1 MB random data):unsigned  41959360000  0.401554 sec   26.113 GB/suint64_t  41959360000  0.759822 sec   13.8003 GB/sAs you see, the throughput of the uint64_t version is only half the one of the unsigned version! The problem seems to be that different assembly gets generated, but why? First, I thought of a compiler bug, so I tried clang++ (Ubuntu Clang version 3.4-1ubuntu3):clang++ -O3 -march=native -std=c++11 teest.cpp -o testResult: test 1unsigned  41959360000  0.398293 sec   26.3267 GB/suint64_t  41959360000  0.680954 sec   15.3986 GB/sSo, it is almost the same result and is still strange. But now it gets super strange. I replace the buffer size that was read from input with a constant 1, so I change:uint64_t size = atol(argv[1]) << 20;touint64_t size = 1 << 20;Thus, the compiler now knows the buffer size at compile time. Maybe it can add some optimizations! Here are the numbers for g++:unsigned  41959360000  0.509156 sec   20.5944 GB/suint64_t  41959360000  0.508673 sec   20.6139 GB/sNow, both versions are equally fast. However, the unsigned got even slower! It dropped from 26 to 20 GB/s, thus replacing a non-constant by a constant value lead to a deoptimization. Seriously, I have no clue what is going on here! But now to clang++ with the new version:unsigned  41959360000  0.677009 sec   15.4884 GB/suint64_t  41959360000  0.676909 sec   15.4906 GB/sWait, what? Now, both versions dropped to the slow number of 15 GB/s. Thus, replacing a non-constant by a constant value even lead to slow code in both cases for Clang!I asked a colleague with an Ivy Bridge CPU to compile my benchmark. He got similar results, so it does not seem to be Haswell. Because two compilers produce strange results here, it also does not seem to be a compiler bug. We do not have an AMD CPU here, so we could only test with Intel.More madness, please!Take the first example (the one with atol(argv[1])) and put a static before the variable, i.e.:static uint64_t size=atol(argv[1])<<20;Here are my results in g++:unsigned  41959360000  0.396728 sec   26.4306 GB/suint64_t  41959360000  0.509484 sec   20.5811 GB/sYay, yet another alternative. We still have the fast 26 GB/s with u32, but we managed to get u64 at least from the 13 GB/s to the 20 GB/s version! On my collegue's PC, the u64 version became even faster than the u32 version, yielding the fastest result of all. Sadly, this only works for g++, clang++ does not seem to care about static.My questionCan you explain these results? Especially:How can there be such a difference between u32 and u64?How can replacing a non-constant by a constant buffer size trigger less optimal code?How can the insertion of the static keyword make the u64 loop faster? Even faster than the original code on my collegue's computer!I know that optimization is a tricky territory, however, I never thought that such small changes can lead to a 100% difference in execution time and that small factors like a constant buffer size can again mix results totally. Of course, I always want to have the version that is able to popcount 26 GB/s. The only reliable way I can think of is copy paste the assembly for this case and use inline assembly. This is the only way I can get rid of compilers that seem to go mad on small changes. What do you think? Is there another way to reliably get the code with most performance?The DisassemblyHere is the disassembly for the various results:26 GB/s version from g++ / u32 / non-const bufsize:0x400af8:lea 0x1(%rdx),%eaxpopcnt (%rbx,%rax,8),%r9lea 0x2(%rdx),%edipopcnt (%rbx,%rcx,8),%raxlea 0x3(%rdx),%esiadd %r9,%raxpopcnt (%rbx,%rdi,8),%rcxadd $0x4,%edxadd %rcx,%raxpopcnt (%rbx,%rsi,8),%rcxadd %rcx,%raxmov %edx,%ecxadd %rax,%r14cmp %rbp,%rcxjb 0x400af813 GB/s version from g++ / u64 / non-const bufsize:0x400c00:popcnt 0x8(%rbx,%rdx,8),%rcxpopcnt (%rbx,%rdx,8),%raxadd %rcx,%raxpopcnt 0x10(%rbx,%rdx,8),%rcxadd %rcx,%raxpopcnt 0x18(%rbx,%rdx,8),%rcxadd $0x4,%rdxadd %rcx,%raxadd %rax,%r12cmp %rbp,%rdxjb 0x400c0015 GB/s version from clang++ / u64 / non-const bufsize:0x400e50:popcnt (%r15,%rcx,8),%rdxadd %rbx,%rdxpopcnt 0x8(%r15,%rcx,8),%rsiadd %rdx,%rsipopcnt 0x10(%r15,%rcx,8),%rdxadd %rsi,%rdxpopcnt 0x18(%r15,%rcx,8),%rbxadd %rdx,%rbxadd $0x4,%rcxcmp %rbp,%rcxjb 0x400e5020 GB/s version from g++ / u32&u64 / const bufsize:0x400a68:popcnt (%rbx,%rdx,1),%raxpopcnt 0x8(%rbx,%rdx,1),%rcxadd %rax,%rcxpopcnt 0x10(%rbx,%rdx,1),%raxadd %rax,%rcxpopcnt 0x18(%rbx,%rdx,1),%rsiadd $0x20,%rdxadd %rsi,%rcxadd %rcx,%rbpcmp $0x100000,%rdxjne 0x400a6815 GB/s version from clang++ / u32&u64 / const bufsize:0x400dd0:popcnt (%r14,%rcx,8),%rdxadd %rbx,%rdxpopcnt 0x8(%r14,%rcx,8),%rsiadd %rdx,%rsipopcnt 0x10(%r14,%rcx,8),%rdxadd %rsi,%rdxpopcnt 0x18(%r14,%rcx,8),%rbxadd %rdx,%rbxadd $0x4,%rcxcmp $0x20000,%rcxjb 0x400dd0Interestingly, the fastest (26 GB/s) version is also the longest! It seems to be the only solution that uses lea. Some versions use jb to jump, others use jne. But apart from that, all versions seem to be comparable. I don't see where a 100% performance gap could originate from, but I am not too adept at deciphering assembly. The slowest (13 GB/s) version looks even very short and good. Can anyone explain this?Lessons learnedNo matter what the answer to this question will be; I have learned that in really hot loops every detail can matter, even details that do not seem to have any association to the hot code. I have never thought about what type to use for a loop variable, but as you see such a minor change can make a 100% difference! Even the storage type of a buffer can make a huge difference, as we saw with the insertion of the static keyword in front of the size variable! In the future, I will always test various alternatives on various compilers when writing really tight and hot loops that are crucial for system performance.The interesting thing is also that the performance difference is still so high although I have already unrolled the loop four times. So even if you unroll, you can still get hit by major performance deviations. Quite interesting.","Culprit: False Data Dependency (and the compiler isn't even aware of it)On Sandy/Ivy Bridge and Haswell processors, the instruction:popcnt  src, destappears to have a false dependency on the destination register dest. Even though the instruction only writes to it, the instruction will wait until dest is ready before executing.  This false dependency is (now) documented by Intel as erratum HSD146 (Haswell) and SKL029 (Skylake)Skylake fixed this for lzcnt and tzcnt.Cannon Lake (and Ice Lake) fixed this for popcnt.bsf/bsr have a true output dependency: output unmodified for input=0. (But no way to take advantage of that with intrinsics - only AMD documents it and compilers don't expose it.)(Yes, these instructions all run on the same execution unit).This dependency doesn't just hold up the 4 popcnts from a single loop iteration. It can carry across loop iterations making it impossible for the processor to parallelize different loop iterations.The unsigned vs. uint64_t and other tweaks don't directly affect the problem. But they influence the register allocator which assigns the registers to the variables.In your case, the speeds are a direct result of what is stuck to the (false) dependency chain depending on what the register allocator decided to do.13 GB/s has a chain: popcnt-add-popcnt-popcnt → next iteration15 GB/s has a chain: popcnt-add-popcnt-add → next iteration20 GB/s has a chain: popcnt-popcnt → next iteration26 GB/s has a chain: popcnt-popcnt → next iterationThe difference between 20 GB/s and 26 GB/s seems to be a minor artifact of the indirect addressing. Either way, the processor starts to hit other bottlenecks once you reach this speed.To test this, I used inline assembly to bypass the compiler and get exactly the assembly I want. I also split up the count variable to break all other dependencies that might mess with the benchmarks.Here are the results:Sandy Bridge Xeon @ 3.5 GHz: (full test code can be found at the bottom)GCC 4.6.3: g++ popcnt.cpp -std=c++0x -O3 -save-temps -march=nativeUbuntu 12Different Registers: 18.6195 GB/s.L4:    movq    (%rbx,%rax,8), %r8    movq    8(%rbx,%rax,8), %r9    movq    16(%rbx,%rax,8), %r10    movq    24(%rbx,%rax,8), %r11    addq    $4, %rax    popcnt %r8, %r8    add    %r8, %rdx    popcnt %r9, %r9    add    %r9, %rcx    popcnt %r10, %r10    add    %r10, %rdi    popcnt %r11, %r11    add    %r11, %rsi    cmpq    $131072, %rax    jne .L4Same Register: 8.49272 GB/s.L9:    movq    (%rbx,%rdx,8), %r9    movq    8(%rbx,%rdx,8), %r10    movq    16(%rbx,%rdx,8), %r11    movq    24(%rbx,%rdx,8), %rbp    addq    $4, %rdx    # This time reuse ""rax"" for all the popcnts.    popcnt %r9, %rax    add    %rax, %rcx    popcnt %r10, %rax    add    %rax, %rsi    popcnt %r11, %rax    add    %rax, %r8    popcnt %rbp, %rax    add    %rax, %rdi    cmpq    $131072, %rdx    jne .L9Same Register with broken chain: 17.8869 GB/s.L14:    movq    (%rbx,%rdx,8), %r9    movq    8(%rbx,%rdx,8), %r10    movq    16(%rbx,%rdx,8), %r11    movq    24(%rbx,%rdx,8), %rbp    addq    $4, %rdx    # Reuse ""rax"" for all the popcnts.    xor    %rax, %rax    # Break the cross-iteration dependency by zeroing ""rax"".    popcnt %r9, %rax    add    %rax, %rcx    popcnt %r10, %rax    add    %rax, %rsi    popcnt %r11, %rax    add    %rax, %r8    popcnt %rbp, %rax    add    %rax, %rdi    cmpq    $131072, %rdx    jne .L14So what went wrong with the compiler?It seems that neither GCC nor Visual Studio are aware that popcnt has such a false dependency. Nevertheless, these false dependencies aren't uncommon. It's just a matter of whether the compiler is aware of it.popcnt isn't exactly the most used instruction. So it's not really a surprise that a major compiler could miss something like this. There also appears to be no documentation anywhere that mentions this problem. If Intel doesn't disclose it, then nobody outside will know until someone runs into it by chance.(Update: As of version 4.9.2, GCC is aware of this false-dependency and generates code to compensate it when optimizations are enabled. Major compilers from other vendors, including Clang, MSVC, and even Intel's own ICC are not yet aware of this microarchitectural erratum and will not emit code that compensates for it.)Why does the CPU have such a false dependency?We can speculate: it runs on the same execution unit as bsf / bsr which do have an output dependency.  (How is POPCNT implemented in hardware?).  For those instructions, Intel documents the integer result for input=0 as ""undefined"" (with ZF=1), but Intel hardware actually gives a stronger guarantee to avoid breaking old software: output unmodified.  AMD documents this behaviour.Presumably it was somehow inconvenient to make some uops for this execution unit dependent on the output but others not.AMD processors do not appear to have this false dependency.The full test code is below for reference:#include <iostream>#include <chrono>#include <x86intrin.h>int main(int argc, char* argv[]) {   using namespace std;   uint64_t size=1<<20;   uint64_t* buffer = new uint64_t[size/8];   char* charbuffer=reinterpret_cast<char*>(buffer);   for (unsigned i=0;i<size;++i) charbuffer[i]=rand()%256;   uint64_t count,duration;   chrono::time_point<chrono::system_clock> startP,endP;   {      uint64_t c0 = 0;      uint64_t c1 = 0;      uint64_t c2 = 0;      uint64_t c3 = 0;      startP = chrono::system_clock::now();      for( unsigned k = 0; k < 10000; k++){         for (uint64_t i=0;i<size/8;i+=4) {            uint64_t r0 = buffer[i + 0];            uint64_t r1 = buffer[i + 1];            uint64_t r2 = buffer[i + 2];            uint64_t r3 = buffer[i + 3];            __asm__(                ""popcnt %4, %4  \n\t""                ""add %4, %0     \n\t""                ""popcnt %5, %5  \n\t""                ""add %5, %1     \n\t""                ""popcnt %6, %6  \n\t""                ""add %6, %2     \n\t""                ""popcnt %7, %7  \n\t""                ""add %7, %3     \n\t""                : ""+r"" (c0), ""+r"" (c1), ""+r"" (c2), ""+r"" (c3)                : ""r""  (r0), ""r""  (r1), ""r""  (r2), ""r""  (r3)            );         }      }      count = c0 + c1 + c2 + c3;      endP = chrono::system_clock::now();      duration=chrono::duration_cast<std::chrono::nanoseconds>(endP-startP).count();      cout << ""No Chain\t"" << count << '\t' << (duration/1.0E9) << "" sec \t""            << (10000.0*size)/(duration) << "" GB/s"" << endl;   }   {      uint64_t c0 = 0;      uint64_t c1 = 0;      uint64_t c2 = 0;      uint64_t c3 = 0;      startP = chrono::system_clock::now();      for( unsigned k = 0; k < 10000; k++){         for (uint64_t i=0;i<size/8;i+=4) {            uint64_t r0 = buffer[i + 0];            uint64_t r1 = buffer[i + 1];            uint64_t r2 = buffer[i + 2];            uint64_t r3 = buffer[i + 3];            __asm__(                ""popcnt %4, %%rax   \n\t""                ""add %%rax, %0      \n\t""                ""popcnt %5, %%rax   \n\t""                ""add %%rax, %1      \n\t""                ""popcnt %6, %%rax   \n\t""                ""add %%rax, %2      \n\t""                ""popcnt %7, %%rax   \n\t""                ""add %%rax, %3      \n\t""                : ""+r"" (c0), ""+r"" (c1), ""+r"" (c2), ""+r"" (c3)                : ""r""  (r0), ""r""  (r1), ""r""  (r2), ""r""  (r3)                : ""rax""            );         }      }      count = c0 + c1 + c2 + c3;      endP = chrono::system_clock::now();      duration=chrono::duration_cast<std::chrono::nanoseconds>(endP-startP).count();      cout << ""Chain 4   \t""  << count << '\t' << (duration/1.0E9) << "" sec \t""            << (10000.0*size)/(duration) << "" GB/s"" << endl;   }   {      uint64_t c0 = 0;      uint64_t c1 = 0;      uint64_t c2 = 0;      uint64_t c3 = 0;      startP = chrono::system_clock::now();      for( unsigned k = 0; k < 10000; k++){         for (uint64_t i=0;i<size/8;i+=4) {            uint64_t r0 = buffer[i + 0];            uint64_t r1 = buffer[i + 1];            uint64_t r2 = buffer[i + 2];            uint64_t r3 = buffer[i + 3];            __asm__(                ""xor %%rax, %%rax   \n\t""   // <--- Break the chain.                ""popcnt %4, %%rax   \n\t""                ""add %%rax, %0      \n\t""                ""popcnt %5, %%rax   \n\t""                ""add %%rax, %1      \n\t""                ""popcnt %6, %%rax   \n\t""                ""add %%rax, %2      \n\t""                ""popcnt %7, %%rax   \n\t""                ""add %%rax, %3      \n\t""                : ""+r"" (c0), ""+r"" (c1), ""+r"" (c2), ""+r"" (c3)                : ""r""  (r0), ""r""  (r1), ""r""  (r2), ""r""  (r3)                : ""rax""            );         }      }      count = c0 + c1 + c2 + c3;      endP = chrono::system_clock::now();      duration=chrono::duration_cast<std::chrono::nanoseconds>(endP-startP).count();      cout << ""Broken Chain\t""  << count << '\t' << (duration/1.0E9) << "" sec \t""            << (10000.0*size)/(duration) << "" GB/s"" << endl;   }   free(charbuffer);}An equally interesting benchmark can be found here: http://pastebin.com/kbzgL8siThis benchmark varies the number of popcnts that are in the (false) dependency chain.False Chain 0:  41959360000 0.57748 sec     18.1578 GB/sFalse Chain 1:  41959360000 0.585398 sec    17.9122 GB/sFalse Chain 2:  41959360000 0.645483 sec    16.2448 GB/sFalse Chain 3:  41959360000 0.929718 sec    11.2784 GB/sFalse Chain 4:  41959360000 1.23572 sec     8.48557 GB/s"
"data_i","edited Apr 09 '22 at 07:20","
        How do I profile a Python script?
    ","Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs. With Python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.What is a good way to profile how long a Python program takes to run?","Python includes a profiler called cProfile. It not only gives the total running time, but also times each function separately, and tells you how many times each function was called, making it easy to determine where you should make optimizations.You can call it from within your code, or from the interpreter, like this:import cProfilecProfile.run('foo()')Even more usefully, you can invoke the cProfile when running a script:python -m cProfile myscript.pyTo make it even easier, I made a little batch file called 'profile.bat':python -m cProfile %1So all I have to do is run:profile euler048.pyAnd I get this:1007 function calls in 0.061 CPU secondsOrdered by: standard namencalls  tottime  percall  cumtime  percall filename:lineno(function)    1    0.000    0.000    0.061    0.061 <string>:1(<module>) 1000    0.051    0.000    0.051    0.000 euler048.py:2(<lambda>)    1    0.005    0.005    0.061    0.061 euler048.py:2(<module>)    1    0.000    0.000    0.061    0.061 {execfile}    1    0.002    0.002    0.053    0.053 {map}    1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler objects}    1    0.000    0.000    0.000    0.000 {range}    1    0.003    0.003    0.003    0.003 {sum}EDIT: Updated link to a good video resource from PyCon 2013 titled Python ProfilingAlso via YouTube."
"data_i","edited Dec 07 '17 at 14:40","
        How do I migrate an SVN repository with history to a new Git repository?
    ","I read the Git manual, FAQ, Git - SVN crash course, etc. and they all explain this and that, but nowhere can you find a simple instruction like:SVN repository in: svn://myserver/path/to/svn/reposGit repository in: git://myserver/path/to/git/reposgit-do-the-magic-svn-import-with-history \svn://myserver/path/to/svn/repos \git://myserver/path/to/git/reposI don't expect it to be that simple, and I don't expect it to be a single command. But I do expect it not to try to explain anything - just to say what steps to take given this example.","Create a users file (i.e. users.txt) for mapping SVN users to Git:user1 = First Last Name <email@address.com>user2 = First Last Name <email@address.com>...You can use this one-liner to build a template from your existing SVN repository:svn log -q | awk -F '|' '/^r/ {gsub(/ /, """", $2); sub("" $"", """", $2); print $2"" = ""$2"" <""$2"">""}' | sort -u > users.txtSVN will stop if it finds a missing SVN user, not in the file. But after that, you can update the file and pick up where you left off.Now pull the SVN data from the repository:git svn clone --stdlayout --no-metadata --authors-file=users.txt svn://hostname/path dest_dir-tmpThis command will create a new Git repository in dest_dir-tmp and start pulling the SVN repository. Note that the ""--stdlayout"" flag implies you have the common ""trunk/, branches/, tags/"" SVN layout. If your layout differs, become familiar with --tags, --branches, --trunk options (in general git svn help).All common protocols are allowed: svn://, http://, https://. The URL should target the base repository, something like http://svn.mycompany.com/myrepo/repository. The URL string must not include /trunk, /tag or /branches.Note that after executing this command it very often looks like the operation is ""hanging/frozen"", and it's quite normal that it can be stuck for a long time after initializing the new repository. Eventually, you will then see log messages which indicate that it's migrating.Also note that if you omit the --no-metadata flag, Git will append information about the corresponding SVN revision to the commit message (i.e. git-svn-id: svn://svn.mycompany.com/myrepo/<branchname/trunk>@<RevisionNumber> <Repository UUID>)If a user name is not found, update your users.txt file then:cd dest_dir-tmpgit svn fetchYou might have to repeat that last command several times, if you have a large project until all of the Subversion commits have been fetched:git svn fetchWhen completed, Git will checkout the SVN trunk into a new branch. Any other branches are set up as remotes. You can view the other SVN branches with:git branch -rIf you want to keep other remote branches in your repository, you want to create a local branch for each one manually.  (Skip trunk/master.)  If you don't do this, the branches won't get cloned in the final step.git checkout -b local_branch remote_branch# It's OK if local_branch and remote_branch are the same namesTags are imported as branches. You have to create a local branch, make a tag and delete the branch to have them as tags in Git. To do it with tag ""v1"":git checkout -b tag_v1 remotes/tags/v1git checkout mastergit tag v1 tag_v1git branch -D tag_v1Clone your GIT-SVN repository into a clean Git repository:git clone dest_dir-tmp dest_dirrm -rf dest_dir-tmpcd dest_dirThe local branches that you created earlier from remote branches will only have been copied as remote branches into the newly cloned repository. (Skip trunk/master.) For each branch you want to keep:git checkout -b local_branch origin/remote_branchFinally, remove the remote from your clean Git repository that points to the now-deleted temporary repository:git remote rm origin"
"data_i","edited Jul 29 '16 at 21:14","
        Get size of all tables in database
    ","I have inherited a fairly large SQL Server database. It seems to take up more space than I would expect, given the data it contains.Is there an easy way to determine how much space on disk each table is consuming?","SELECT     t.NAME AS TableName,    s.Name AS SchemaName,    p.rows,    SUM(a.total_pages) * 8 AS TotalSpaceKB,     CAST(ROUND(((SUM(a.total_pages) * 8) / 1024.00), 2) AS NUMERIC(36, 2)) AS TotalSpaceMB,    SUM(a.used_pages) * 8 AS UsedSpaceKB,     CAST(ROUND(((SUM(a.used_pages) * 8) / 1024.00), 2) AS NUMERIC(36, 2)) AS UsedSpaceMB,     (SUM(a.total_pages) - SUM(a.used_pages)) * 8 AS UnusedSpaceKB,    CAST(ROUND(((SUM(a.total_pages) - SUM(a.used_pages)) * 8) / 1024.00, 2) AS NUMERIC(36, 2)) AS UnusedSpaceMBFROM     sys.tables tINNER JOIN          sys.indexes i ON t.OBJECT_ID = i.object_idINNER JOIN     sys.partitions p ON i.object_id = p.OBJECT_ID AND i.index_id = p.index_idINNER JOIN     sys.allocation_units a ON p.partition_id = a.container_idLEFT OUTER JOIN     sys.schemas s ON t.schema_id = s.schema_idWHERE     t.NAME NOT LIKE 'dt%'     AND t.is_ms_shipped = 0    AND i.OBJECT_ID > 255 GROUP BY     t.Name, s.Name, p.RowsORDER BY     TotalSpaceMB DESC, t.Name"
"data_i","edited Oct 06 '17 at 09:18","
        Reverse a string in Python
    ","There is no built in reverse function for Python's str object. What is the best way of implementing this method?If supplying a very concise answer, please elaborate on its efficiency. For example, whether the str object is converted to a different object, etc. ","Using slicing:>>> 'hello world'[::-1]'dlrow olleh'Slice notation takes the form [start:stop:step]. In this case, we omit the start and stop positions since we want the whole string. We also use step = -1, which means, ""repeatedly step from right to left by 1 character""."
"data_i","edited Apr 25 '18 at 13:48","
        Find all tables containing column with specified name - MS SQL Server
    ","Is it possible to query for table names which contain columns beingLIKE '%myName%'?","Search Tables:SELECT      c.name  AS 'ColumnName'            ,t.name AS 'TableName'FROM        sys.columns cJOIN        sys.tables  t   ON c.object_id = t.object_idWHERE       c.name LIKE '%MyName%'ORDER BY    TableName            ,ColumnName;Search Tables and Views:SELECT      COLUMN_NAME AS 'ColumnName'            ,TABLE_NAME AS  'TableName'FROM        INFORMATION_SCHEMA.COLUMNSWHERE       COLUMN_NAME LIKE '%MyName%'ORDER BY    TableName            ,ColumnName;"
"data_i","edited Nov 24 '20 at 14:07","
        Compiling an application for use in highly radioactive environments
    ","We are compiling an embedded C++ application that is deployed in a shielded device in an environment bombarded with ionizing radiation. We are using GCC and cross-compiling for ARM. When deployed, our application generates some erroneous data and crashes more often than we would like. The hardware is designed for this environment, and our application has run on this platform for several years.Are there changes we can make to our code, or compile-time improvements that can be made to identify/correct soft errors and memory-corruption caused by single event upsets? Have any other developers had success in reducing the harmful effects of soft errors on a long-running application?","Working for about 4-5 years with software/firmware development and environment testing of miniaturized satellites*, I would like to share my experience here.*(miniaturized satellites are a lot more prone to single event upsets than bigger satellites due to its relatively small, limited sizes for its electronic components)To be very concise and direct: there is no mechanism to recover from detectable, erroneous  situation by the software/firmware itself without, at least, one  copy of minimum working version of the software/firmware somewhere for recovery purpose - and with the hardware supporting the recovery (functional).Now, this situation is normally handled both in the hardware and software level. Here, as you request, I will share what we can do in the software level....recovery purpose.... Provide ability to update/recompile/reflash your software/firmware in real environment. This is an almost must-have feature for any software/firmware in highly ionized environment. Without this, you could have redundant software/hardware as many as you want but at one point, they are all going to blow up. So, prepare this feature!...minimum working version... Have responsive, multiple copies, minimum version of the software/firmware in your code. This is like Safe mode in Windows. Instead of having only one, fully functional version of your software, have multiple copies of the minimum version of your software/firmware. The minimum copy will usually having much less size than the full copy and almost always have only the following two or three features: capable of listening to command from external system, capable of updating the current software/firmware, capable of monitoring the basic operation's housekeeping data....copy... somewhere... Have redundant software/firmware somewhere. You could, with or without redundant hardware, try to have redundant software/firmware in your ARM uC. This is normally done by having two or more identical software/firmware in separate addresses which sending heartbeat to each other - but only one will be active at a time. If one or more software/firmware is known to be unresponsive, switch to the other software/firmware. The benefit of using this approach is we can have functional replacement immediately after an error occurs - without any contact with whatever external system/party who is responsible to detect and to repair the error (in satellite case, it is usually the Mission Control Centre (MCC)). Strictly speaking, without redundant hardware, the disadvantage of doing this is you actually cannot eliminate all single point of failures. At the very least, you will still have one single point of failure, which is the switch itself (or often the beginning of the code). Nevertheless, for a device limited by size in a highly ionized environment (such as pico/femto satellites), the reduction of the single point of failures to one point without additional hardware will still be worth considering. Somemore, the piece of code for the switching would certainly be much less than the code for the whole program - significantly reducing the risk of getting Single Event in it.But if you are not doing this, you should have at least one copy in your external system which can come in contact with the device and update the software/firmware (in the satellite case, it is again the mission control centre). You could also have the copy in your permanent memory storage in your device which can be triggered to restore the running system's software/firmware...detectable erroneous situation.. The error must be detectable, usually by the hardware error correction/detection circuit or by a small piece of code for error correction/detection. It is best to put such code small, multiple, and independent from the main software/firmware. Its main task is only for checking/correcting. If the hardware circuit/firmware is reliable (such as it is more radiation hardened than the rests - or having multiple circuits/logics), then you might consider making error-correction with it. But if it is not, it is better to make it as error-detection. The correction can be by external system/device. For the error correction, you could consider making use of a basic error correction algorithm like Hamming/Golay23, because they can be implemented more easily both in the circuit/software. But it ultimately depends on your team's capability. For error detection, normally CRC is used....hardware supporting the recovery Now, comes to the most difficult aspect on this issue. Ultimately, the recovery requires the hardware which is responsible for the recovery to be at least functional. If the hardware is permanently broken (normally happen after its Total ionizing dose reaches certain level), then there is (sadly) no way for the software to help in recovery. Thus, hardware is rightly the utmost importance concern for a device exposed to high radiation level (such as satellite). In addition to the suggestion for above anticipating firmware's error due to single event upset, I would also like to suggest you to have:Error detection and/or error correction algorithm in the inter-subsystem communication protocol. This is another almost must have in order to avoid incomplete/wrong signals received from other systemFilter in your ADC reading. Do not use the ADC reading directly. Filter it by median filter, mean filter, or any other filters - never trust single reading value. Sample more, not less - reasonably."
"data_i","edited Dec 03 '20 at 10:58","
        How to specify the private SSH-key to use when executing shell command on Git?
    ","A rather unusual situation perhaps, but I want to specify a private SSH-key to use when executing a shell (git) command from the local computer.Basically like this:git clone git@github.com:TheUser/TheProject.git -key ""/home/christoffer/ssh_keys/theuser""Or even better (in Ruby):with_key(""/home/christoffer/ssh_keys/theuser"") do  sh(""git clone git@github.com:TheUser/TheProject.git"")endI have seen examples of connecting to a remote server with Net::SSH that uses a specified private key, but this is a local command. Is it possible?","None of these solutions worked for me. Instead, I elaborate on @Martin v. Löwis  's mention of setting a config file for SSH.SSH will look for the user's ~/.ssh/config file. I have mine setup as:Host gitserv    Hostname remote.server.com    IdentityFile ~/.ssh/id_rsa.github    IdentitiesOnly yes # see NOTES belowAnd I add a remote git repository:git remote add origin git@gitserv:myrepo.gitAnd then git commands work normally for me.git push -v origin masterNOTESThe IdentitiesOnly yes is required to prevent the SSH default behavior of sending the identity file matching the default filename for each protocol. If you have a file named ~/.ssh/id_rsa that will get tried BEFORE your ~/.ssh/id_rsa.github without this option.ReferencesBest way to use multiple SSH private keys on one clientHow could I stop ssh offering a wrong key"
"data_i","edited Sep 07 '19 at 19:15","
        How do I style a  dropdown with only CSS?
    ","Is there a CSS-only way to style a <select> dropdown?I need to style a <select> form as much as humanly possible, without any JavaScript. What are the properties I can use to do so in CSS?This code needs to be compatible with all major browsers:Internet Explorer 6, 7, and 8FirefoxSafariI know I can make it with JavaScript: Example.And I'm not talking about simple styling. I want to know, what the best we can do with CSS only.I found similar questions on Stack Overflow.And this one on Doctype.com.","Here are three solutions:Solution #1 - appearance: none   - with Internet Explorer 10 - 11 workaround (Demo)--To hide the default arrow set appearance: none on the select element, then add your own custom arrow with background-imageselect {   -webkit-appearance: none;   -moz-appearance: none;   appearance: none;       /* Remove default arrow */   background-image: url(...);   /* Add custom arrow */}Browser Support:appearance: none has very good browser support (caniuse) - except for Internet Explorer.We can improve this technique and add support for Internet Explorer 10 and Internet Explorer 11 by addingselect::-ms-expand {    display: none; /* Hide the default arrow in Internet Explorer 10 and Internet Explorer 11 */}If Internet Explorer 9 is a concern, we have no way of removing the default arrow (which would mean that we would now have two arrows), but, we could use a funky Internet Explorer 9 selector.To at least undo our custom arrow - leaving the default select arrow intact./* Target Internet Explorer 9 to undo the custom arrow */@media screen and (min-width:0\0) {    select {        background-image:none\9;        padding: 5px\9;    }}All together:select {  margin: 50px;  width: 150px;  padding: 5px 35px 5px 5px;  font-size: 16px;  border: 1px solid #CCC;  height: 34px;  -webkit-appearance: none;  -moz-appearance: none;  appearance: none;  background: url(https://stackoverflow.com/favicon.ico) 96% / 15% no-repeat #EEE;}/* CAUTION: Internet Explorer hackery ahead */select::-ms-expand {    display: none; /* Remove default arrow in Internet Explorer 10 and 11 */}/* Target Internet Explorer 9 to undo the custom arrow */@media screen and (min-width:0\0) {    select {        background: none\9;        padding: 5px\9;    }}<select>  <option>Apples</option>  <option selected>Pineapples</option>  <option>Chocklate</option>  <option>Pancakes</option></select>This solution is easy and has good browser support - it should generally suffice.If browser support for Internet Explorer is needed, read ahead.Solution #2 Truncate the select element to hide the default arrow (demo)--(Read more here)Wrap the select element in a div with a fixed width and overflow:hidden.Then give the select element a width of about 20 pixels greater than the div.The result is that the default drop-down arrow of the select element will be hidden (due to the overflow:hidden on the container), and you can place any background image you want on the right-hand-side of the div.The advantage of this approach is that it is cross-browser (Internet Explorer 8 and later, WebKit, and Gecko). However, the disadvantage of this approach is that the options drop-down juts out on the right-hand-side (by the 20 pixels which we hid... because the option elements take the width of the select element).[It should be noted, however, that if the custom select element is necessary only for mobile devices - then the above problem doesn't apply - because of the way each phone natively opens the select element. So for mobile, this may be the best solution.].styled select {  background: transparent;  width: 150px;  font-size: 16px;  border: 1px solid #CCC;  height: 34px;}.styled {  margin: 50px;  width: 120px;  height: 34px;  border: 1px solid #111;  border-radius: 3px;  overflow: hidden;  background: url(https://stackoverflow.com/favicon.ico) 96% / 20% no-repeat #EEE;}<div class=""styled"">  <select>    <option>Pineapples</option>    <option selected>Apples</option>    <option>Chocklate</option>    <option>Pancakes</option>  </select></div>If the custom arrow is necessary on Firefox - prior to Version 35 - but you don't need to support old versions of Internet Explorer - then keep reading...Solution #3 - Use the pointer-events property (demo)--(Read more here)The idea here is to overlay an element over the native drop down arrow (to create our custom one) and then disallow pointer events on it.Advantage: It works well in WebKit and Gecko. It looks good too (no jutting out option elements).Disadvantage: Internet Explorer (Internet Explorer 10 and down) doesn't support pointer-events, which means you can't click the custom arrow. Also, another (obvious) disadvantage with this method is that you can't target your new arrow image with a hover effect or hand cursor, because we have just disabled pointer events on them!However, with this method you can use Modernizer or conditional comments to make Internet Explorer revert to the standard built in arrow.NB: Being that Internet Explorer 10 doesn't support conditional comments anymore: If you want to use this approach, you should probably use Modernizr. However, it is still possible to exclude the pointer-events CSS from Internet Explorer 10 with a CSS hack described here..notIE {  position: relative;  display: inline-block;}select {  display: inline-block;  height: 30px;  width: 150px;  outline: none;  color: #74646E;  border: 1px solid #C8BFC4;  border-radius: 4px;  box-shadow: inset 1px 1px 2px #DDD8DC;  background: #FFF;}/* Select arrow styling */.notIE .fancyArrow {  width: 23px;  height: 28px;  position: absolute;  display: inline-block;  top: 1px;  right: 3px;  background: url(https://stackoverflow.com/favicon.ico) right / 90% no-repeat #FFF;  pointer-events: none;}/*target Internet Explorer 9 and Internet Explorer 10:*/@media screen and (min-width: 0\0) {  .notIE .fancyArrow {    display: none;  }}<!--[if !IE]> --><div class=""notIE"">  <!-- <![endif]-->  <span class=""fancyArrow""></span>  <select>    <option>Apples</option>    <option selected>Pineapples</option>    <option>Chocklate</option>    <option>Pancakes</option>  </select>  <!--[if !IE]> --></div><!-- <![endif]-->"
"data_i","edited Oct 29 '19 at 17:00","
        Fastest way to determine if an integer's square root is an integer
    ","I'm looking for the fastest way to determine if a long value is a perfect square (i.e. its square root is another integer): I've done it the easy way, by using the built-in Math.sqrt()function, but I'm wondering if there is a way to do it faster byrestricting yourself to integer-only domain.Maintaining a lookup table is impractical (since there are about231.5 integers whose square is less than 263).Here is the very simple and straightforward way I'm doing it now:public final static boolean isPerfectSquare(long n){  if (n < 0)    return false;  long tst = (long)(Math.sqrt(n) + 0.5);  return tst*tst == n;}Note: I'm using this function in many Project Euler problems.  So no one else will ever have to maintain this code.  And this kind of micro-optimization could actually make a difference, since part of the challenge is to do every algorithm in less than a minute, and this function will need to be called millions of times in some problems.I've tried the different solutions to the problem:After exhaustive testing, I found that adding 0.5 to the result of Math.sqrt() is not necessary, at least not on my machine.The fast inverse square root was faster, but it gave incorrect results for n >= 410881.  However, as suggested by BobbyShaftoe, we can use the FISR hack for n < 410881.Newton's method was a good bit slower than Math.sqrt().  This is probably because Math.sqrt() uses something similar to Newton's Method, but implemented in the hardware so it's much faster than in Java.  Also, Newton's Method still required use of doubles.A modified Newton's method, which used a few tricks so that only integer math was involved, required some hacks to avoid overflow (I want this function to work with all positive 64-bit signed integers), and it was still slower than Math.sqrt().Binary chop was even slower.  This makes sense because the binary chop will on average require 16 passes to find the square root of a 64-bit number.According to John's tests, using or statements is faster in C++ than using a switch, but in Java and C# there appears to be no difference between or and switch.I also tried making a lookup table (as a private static array of 64 boolean values).  Then instead of either switch or or statement, I would just say if(lookup[(int)(n&0x3F)]) { test } else return false;.  To my surprise, this was (just slightly) slower. This is because array bounds are checked in Java. ","I figured out a method that works ~35% faster than your 6bits+Carmack+sqrt code, at least with my CPU (x86) and programming language (C/C++).  Your results may vary, especially because I don't know how the Java factor will play out.My approach is threefold:First, filter out obvious answers.  This includes negative numbers and looking at the last 4 bits.  (I found looking at the last six didn't help.)  I also answer yes for 0.  (In reading the code below, note that my input is int64 x.)if( x < 0 || (x&2) || ((x & 7) == 5) || ((x & 11) == 8) )    return false;if( x == 0 )    return true;Next, check if it's a square modulo 255 = 3 * 5 * 17.  Because that's a product of three distinct primes, only about 1/8 of the residues mod 255 are squares.  However, in my experience, calling the modulo operator (%) costs more than the benefit one gets, so I use bit tricks involving 255 = 2^8-1 to compute the residue.  (For better or worse, I am not using the trick of reading individual bytes out of a word, only bitwise-and and shifts.)int64 y = x;y = (y & 4294967295LL) + (y >> 32); y = (y & 65535) + (y >> 16);y = (y & 255) + ((y >> 8) & 255) + (y >> 16);// At this point, y is between 0 and 511.  More code can reduce it farther.To actually check if the residue is a square, I look up the answer in a precomputed table.if( bad255[y] )    return false;// However, I just use a table of size 512Finally, try to compute the square root using a method similar to Hensel's lemma.  (I don't think it's applicable directly, but it works with some modifications.)  Before doing that, I divide out all powers of 2 with a binary search:if((x & 4294967295LL) == 0)    x >>= 32;if((x & 65535) == 0)    x >>= 16;if((x & 255) == 0)    x >>= 8;if((x & 15) == 0)    x >>= 4;if((x & 3) == 0)    x >>= 2;At this point, for our number to be a square, it must be 1 mod 8.if((x & 7) != 1)    return false;The basic structure of Hensel's lemma is the following.  (Note: untested code; if it doesn't work, try t=2 or 8.)int64 t = 4, r = 1;t <<= 1; r += ((x - r * r) & t) >> 1;t <<= 1; r += ((x - r * r) & t) >> 1;t <<= 1; r += ((x - r * r) & t) >> 1;// Repeat until t is 2^33 or so.  Use a loop if you want.The idea is that at each iteration, you add one bit onto r, the ""current"" square root of x; each square root is accurate modulo a larger and larger power of 2, namely t/2.  At the end, r and t/2-r will be square roots of x modulo t/2.  (Note that if r is a square root of x, then so is -r.  This is true even modulo numbers, but beware, modulo some numbers, things can have even more than 2 square roots; notably, this includes powers of 2.)  Because our actual square root is less than 2^32, at that point we can actually just check if r or t/2-r are real square roots.  In my actual code, I use the following modified loop:int64 r, t, z;r = start[(x >> 3) & 1023];do {    z = x - r * r;    if( z == 0 )        return true;    if( z < 0 )        return false;    t = z & (-z);    r += (z & t) >> 1;    if( r > (t >> 1) )        r = t - r;} while( t <= (1LL << 33) );The speedup here is obtained in three ways: precomputed start value (equivalent to ~10 iterations of the loop), earlier exit of the loop, and skipping some t values.  For the last part, I look at z = r - x * x, and set t to be the largest power of 2 dividing z with a bit trick.  This allows me to skip t values that wouldn't have affected the value of r anyway.  The precomputed start value in my case picks out the ""smallest positive"" square root modulo 8192.Even if this code doesn't work faster for you, I hope you enjoy some of the ideas it contains.  Complete, tested code follows, including the precomputed tables.typedef signed long long int int64;int start[1024] ={1,3,1769,5,1937,1741,7,1451,479,157,9,91,945,659,1817,11,1983,707,1321,1211,1071,13,1479,405,415,1501,1609,741,15,339,1703,203,129,1411,873,1669,17,1715,1145,1835,351,1251,887,1573,975,19,1127,395,1855,1981,425,453,1105,653,327,21,287,93,713,1691,1935,301,551,587,257,1277,23,763,1903,1075,1799,1877,223,1437,1783,859,1201,621,25,779,1727,573,471,1979,815,1293,825,363,159,1315,183,27,241,941,601,971,385,131,919,901,273,435,647,1493,95,29,1417,805,719,1261,1177,1163,1599,835,1367,315,1361,1933,1977,747,31,1373,1079,1637,1679,1581,1753,1355,513,1539,1815,1531,1647,205,505,1109,33,1379,521,1627,1457,1901,1767,1547,1471,1853,1833,1349,559,1523,967,1131,97,35,1975,795,497,1875,1191,1739,641,1149,1385,133,529,845,1657,725,161,1309,375,37,463,1555,615,1931,1343,445,937,1083,1617,883,185,1515,225,1443,1225,869,1423,1235,39,1973,769,259,489,1797,1391,1485,1287,341,289,99,1271,1701,1713,915,537,1781,1215,963,41,581,303,243,1337,1899,353,1245,329,1563,753,595,1113,1589,897,1667,407,635,785,1971,135,43,417,1507,1929,731,207,275,1689,1397,1087,1725,855,1851,1873,397,1607,1813,481,163,567,101,1167,45,1831,1205,1025,1021,1303,1029,1135,1331,1017,427,545,1181,1033,933,1969,365,1255,1013,959,317,1751,187,47,1037,455,1429,609,1571,1463,1765,1009,685,679,821,1153,387,1897,1403,1041,691,1927,811,673,227,137,1499,49,1005,103,629,831,1091,1449,1477,1967,1677,697,1045,737,1117,1737,667,911,1325,473,437,1281,1795,1001,261,879,51,775,1195,801,1635,759,165,1871,1645,1049,245,703,1597,553,955,209,1779,1849,661,865,291,841,997,1265,1965,1625,53,1409,893,105,1925,1297,589,377,1579,929,1053,1655,1829,305,1811,1895,139,575,189,343,709,1711,1139,1095,277,993,1699,55,1435,655,1491,1319,331,1537,515,791,507,623,1229,1529,1963,1057,355,1545,603,1615,1171,743,523,447,1219,1239,1723,465,499,57,107,1121,989,951,229,1521,851,167,715,1665,1923,1687,1157,1553,1869,1415,1749,1185,1763,649,1061,561,531,409,907,319,1469,1961,59,1455,141,1209,491,1249,419,1847,1893,399,211,985,1099,1793,765,1513,1275,367,1587,263,1365,1313,925,247,1371,1359,109,1561,1291,191,61,1065,1605,721,781,1735,875,1377,1827,1353,539,1777,429,1959,1483,1921,643,617,389,1809,947,889,981,1441,483,1143,293,817,749,1383,1675,63,1347,169,827,1199,1421,583,1259,1505,861,457,1125,143,1069,807,1867,2047,2045,279,2043,111,307,2041,597,1569,1891,2039,1957,1103,1389,231,2037,65,1341,727,837,977,2035,569,1643,1633,547,439,1307,2033,1709,345,1845,1919,637,1175,379,2031,333,903,213,1697,797,1161,475,1073,2029,921,1653,193,67,1623,1595,943,1395,1721,2027,1761,1955,1335,357,113,1747,1497,1461,1791,771,2025,1285,145,973,249,171,1825,611,265,1189,847,1427,2023,1269,321,1475,1577,69,1233,755,1223,1685,1889,733,1865,2021,1807,1107,1447,1077,1663,1917,1129,1147,1775,1613,1401,555,1953,2019,631,1243,1329,787,871,885,449,1213,681,1733,687,115,71,1301,2017,675,969,411,369,467,295,693,1535,509,233,517,401,1843,1543,939,2015,669,1527,421,591,147,281,501,577,195,215,699,1489,525,1081,917,1951,2013,73,1253,1551,173,857,309,1407,899,663,1915,1519,1203,391,1323,1887,739,1673,2011,1585,493,1433,117,705,1603,1111,965,431,1165,1863,533,1823,605,823,1179,625,813,2009,75,1279,1789,1559,251,657,563,761,1707,1759,1949,777,347,335,1133,1511,267,833,1085,2007,1467,1745,1805,711,149,1695,803,1719,485,1295,1453,935,459,1151,381,1641,1413,1263,77,1913,2005,1631,541,119,1317,1841,1773,359,651,961,323,1193,197,175,1651,441,235,1567,1885,1481,1947,881,2003,217,843,1023,1027,745,1019,913,717,1031,1621,1503,867,1015,1115,79,1683,793,1035,1089,1731,297,1861,2001,1011,1593,619,1439,477,585,283,1039,1363,1369,1227,895,1661,151,645,1007,1357,121,1237,1375,1821,1911,549,1999,1043,1945,1419,1217,957,599,571,81,371,1351,1003,1311,931,311,1381,1137,723,1575,1611,767,253,1047,1787,1169,1997,1273,853,1247,413,1289,1883,177,403,999,1803,1345,451,1495,1093,1839,269,199,1387,1183,1757,1207,1051,783,83,423,1995,639,1155,1943,123,751,1459,1671,469,1119,995,393,219,1743,237,153,1909,1473,1859,1705,1339,337,909,953,1771,1055,349,1993,613,1393,557,729,1717,511,1533,1257,1541,1425,819,519,85,991,1693,503,1445,433,877,1305,1525,1601,829,809,325,1583,1549,1991,1941,927,1059,1097,1819,527,1197,1881,1333,383,125,361,891,495,179,633,299,863,285,1399,987,1487,1517,1639,1141,1729,579,87,1989,593,1907,839,1557,799,1629,201,155,1649,1837,1063,949,255,1283,535,773,1681,461,1785,683,735,1123,1801,677,689,1939,487,757,1857,1987,983,443,1327,1267,313,1173,671,221,695,1509,271,1619,89,565,127,1405,1431,1659,239,1101,1159,1067,607,1565,905,1755,1231,1299,665,373,1985,701,1879,1221,849,627,1465,789,543,1187,1591,923,1905,979,1241,181};bool bad255[512] ={0,0,1,1,0,1,1,1,1,0,1,1,1,1,1,0,0,1,1,0,1,0,1,1,1,0,1,1,1,1,0,1, 1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,0,1,1,1,1,0,1,1,1, 0,1,0,1,1,0,0,1,1,1,1,1,0,1,1,1,1,0,1,1,0,0,1,1,1,1,1,1,1,1,0,1, 1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,0,1,1,1,0,1,1,1,1,0,0,1,1,1,1,1,1, 1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,0,1,1,0,1,1,1,1,1, 1,1,1,1,1,1,0,1,1,0,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1, 1,1,1,0,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1, 1,0,1,1,1,0,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1, 0,0,1,1,0,1,1,1,1,0,1,1,1,1,1,0,0,1,1,0,1,0,1,1,1,0,1,1,1,1,0,1, 1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,0,1,1,1,1,0,1,1,1, 0,1,0,1,1,0,0,1,1,1,1,1,0,1,1,1,1,0,1,1,0,0,1,1,1,1,1,1,1,1,0,1, 1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,0,1,1,1,0,1,1,1,1,0,0,1,1,1,1,1,1, 1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,0,1,1,0,1,1,1,1,1, 1,1,1,1,1,1,0,1,1,0,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1, 1,1,1,0,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1, 1,0,1,1,1,0,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1, 0,0};inline bool square( int64 x ) {    // Quickfail    if( x < 0 || (x&2) || ((x & 7) == 5) || ((x & 11) == 8) )        return false;    if( x == 0 )        return true;    // Check mod 255 = 3 * 5 * 17, for fun    int64 y = x;    y = (y & 4294967295LL) + (y >> 32);    y = (y & 65535) + (y >> 16);    y = (y & 255) + ((y >> 8) & 255) + (y >> 16);    if( bad255[y] )        return false;    // Divide out powers of 4 using binary search    if((x & 4294967295LL) == 0)        x >>= 32;    if((x & 65535) == 0)        x >>= 16;    if((x & 255) == 0)        x >>= 8;    if((x & 15) == 0)        x >>= 4;    if((x & 3) == 0)        x >>= 2;    if((x & 7) != 1)        return false;    // Compute sqrt using something like Hensel's lemma    int64 r, t, z;    r = start[(x >> 3) & 1023];    do {        z = x - r * r;        if( z == 0 )            return true;        if( z < 0 )            return false;        t = z & (-z);        r += (z & t) >> 1;        if( r > (t  >> 1) )            r = t - r;    } while( t <= (1LL << 33) );    return false;}"
"data_i","asked Aug 30 '10 at 15:02","
        What are rvalues, lvalues, xvalues, glvalues, and prvalues?
    ","In C++03, an expression is either an rvalue or an lvalue.In C++11, an expression can be an:     rvaluelvaluexvalueglvalueprvalueTwo categories have become five categories.What are these new categories of expressions?How do these new categories relate to the existing rvalue and lvalue categories?  Are the rvalue and lvalue categories in C++0x the same as they are in C++03?Why are these new categories needed?  Are the WG21 gods just trying to confuse us mere mortals?","I guess this document might serve as a not so short introduction : n3055The whole massacre began with the move semantics. Once we have expressions that can be moved and not copied, suddenly easy to grasp rules demanded distinction between expressions that can be moved, and in which direction.From what I guess based on the draft, the r/l value distinction stays the same, only in the context of moving things get messy. Are they needed? Probably not if we wish to forfeit the new features. But to allow better optimization we should probably embrace them.Quoting n3055:An lvalue (so-called, historically,because lvalues could appear on theleft-hand side  of an assignmentexpression) designates a function oran object.  [Example: If E is  anexpression of pointer type, then *Eis an lvalue expression referring tothe object  or function to which Epoints.  As another example, theresult of calling a function  whosereturn type is an lvalue reference isan lvalue.] An xvalue (an“eXpiring” value) also refers to anobject, usually near the end of its lifetime (so that its resources maybe moved, for example).  An xvalue isthe result  of certain kinds ofexpressions involving rvaluereferences.  [Example: The result of calling a function whosereturn type is an rvalue reference isan xvalue.]A glvalue   (“generalized” lvalue) is an lvalueor an xvalue. An rvalue (so-called,historically, because rvalues couldappear on the right-hand  side of anassignment expression) is an xvalue,a temporary object orsubobject thereof, or a value that isnot associated with an object. Aprvalue (“pure” rvalue) is an rvaluethat is not an xvalue.  [Example: Theresult  of calling a function whosereturn type is not a reference is aprvalue]The document in question is a great reference for this question, because it shows the exact changes in the standard that have happened as a result of the introduction of the new nomenclature."
"data_i","edited Sep 03 '21 at 16:18","
        Why do we need virtual functions in C++?
    ","I'm learning C++ and I'm just getting into virtual functions.From what I've read (in the book and online), virtual functions are functions in the base class that you can override in derived classes.But earlier in the book, when learning about basic inheritance, I was able to override base functions in derived classes without using virtual.So what am I missing here? I know there is more to virtual functions, and it seems to be important so I want to be clear on what it is exactly. I just can't find a straightforward answer online.","Here is how I understood not just what virtual functions are, but why they're required:Let's say you have these two classes:class Animal{    public:        void eat() { std::cout << ""I'm eating generic food.""; }};class Cat : public Animal{    public:        void eat() { std::cout << ""I'm eating a rat.""; }};In your main function:Animal *animal = new Animal;Cat *cat = new Cat;animal->eat(); // Outputs: ""I'm eating generic food.""cat->eat();    // Outputs: ""I'm eating a rat.""So far so good, right? Animals eat generic food, cats eat rats, all without virtual.Let's change it a little now so that eat() is called via an intermediate function (a trivial function just for this example):// This can go at the top of the main.cpp filevoid func(Animal *xyz) { xyz->eat(); }Now our main function is:Animal *animal = new Animal;Cat *cat = new Cat;func(animal); // Outputs: ""I'm eating generic food.""func(cat);    // Outputs: ""I'm eating generic food.""Uh oh... we passed a Cat into func(), but it won't eat rats. Should you overload func() so it takes a Cat*? If you have to derive more animals from Animal they would all need their own func().The solution is to make eat() from the Animal class a virtual function:class Animal{    public:        virtual void eat() { std::cout << ""I'm eating generic food.""; }};class Cat : public Animal{    public:        void eat() { std::cout << ""I'm eating a rat.""; }};Main:func(animal); // Outputs: ""I'm eating generic food.""func(cat);    // Outputs: ""I'm eating a rat.""Done."
"data_i","edited Jun 01 '20 at 14:40","
        How do I find Waldo with Mathematica?
    ","This was bugging me over the weekend: What is a good way to solve those Where's Waldo?  ['Wally' outside of North America] puzzles, using Mathematica (image-processing and other functionality)?Here is what I have so far, a function which reduces the visual complexity a little bit by dimmingsome of the non-red colors:whereIsWaldo[url_] := Module[{waldo, waldo2, waldoMask},    waldo = Import[url];    waldo2 = Image[ImageData[        waldo] /. {{r_, g_, b_} /;          Not[r > .7 && g < .3 && b < .3] :> {0, 0,          0}, {r_, g_, b_} /; (r > .7 && g < .3 && b < .3) :> {1, 1,          1}}];    waldoMask = Closing[waldo2, 4];    ImageCompose[waldo, {waldoMask, .5}]]And an example of a URL where this 'works':whereIsWaldo[""http://www.findwaldo.com/fankit/graphics/IntlManOfLiterature/Scenes/DepartmentStore.jpg""](Waldo is by the cash register):","I've found Waldo!How I've done itFirst, I'm filtering out all colours that aren't redwaldo = Import[""http://www.findwaldo.com/fankit/graphics/IntlManOfLiterature/Scenes/DepartmentStore.jpg""];red = Fold[ImageSubtract, #[[1]], Rest[#]] &@ColorSeparate[waldo];Next, I'm calculating the correlation of this image with a simple black and white pattern to find the red and white transitions in the shirt. corr = ImageCorrelate[red,    Image@Join[ConstantArray[1, {2, 4}], ConstantArray[0, {2, 4}]],    NormalizedSquaredEuclideanDistance];I use Binarize to pick out the pixels in the image with a sufficiently high correlation and draw white circle around them to emphasize them using Dilationpos = Dilation[ColorNegate[Binarize[corr, .12]], DiskMatrix[30]];I had to play around a little with the level. If the level is too high, too many false positives are picked out. Finally I'm combining this result with the original image to get the result abovefound = ImageMultiply[waldo, ImageAdd[ColorConvert[pos, ""GrayLevel""], .5]]"
"data_i","edited Jun 06 '17 at 04:10","
        Transport security has blocked a cleartext HTTP
    ","What setting do I need to put in my info.plist to enable HTTP mode as per the following error message?Transport security has blocked a cleartext HTTP (http://) resource  load since it is insecure. Temporary exceptions can be configured via  your app's Info.plist file.Assume that my domain is example.com.","Use NSAppTransportSecurity:You have to set the NSAllowsArbitraryLoads key to YES under NSAppTransportSecurity dictionary in your info.plist file."
"data_i","edited Aug 06 '18 at 09:18","
        What is the Python 3 equivalent of ""python -m SimpleHTTPServer""
    ","What is the Python 3 equivalent of python -m SimpleHTTPServer?","From the docs:The SimpleHTTPServer module has been merged into http.server in Python 3.0. The 2to3 tool will automatically adapt imports when converting your sources to 3.0.So, your command is python -m http.server, or depending on your installation, it can be:python3 -m http.server"
"data_i","edited Aug 25 '22 at 03:36","
        Save plot to image file instead of displaying it using Matplotlib
    ","This displays the figure in a GUI:import matplotlib.pyplot as pltplt.plot([1, 2, 3], [1, 4, 9])plt.show()But how do I instead save the figure to a file (e.g. foo.png)?","When using matplotlib.pyplot.savefig, the file format can be specified by the extension:from matplotlib import pyplot as pltplt.savefig('foo.png')plt.savefig('foo.pdf')That gives a rasterized or vectorized output respectively.In addition, there is sometimes undesirable whitespace around the image, which can be removed with:plt.savefig('foo.png', bbox_inches='tight')Note that if showing the plot, plt.show() should follow plt.savefig(); otherwise, the file image will be blank."
"data_i","edited Jun 16 '17 at 22:24","
        A potentially dangerous Request.Form value was detected from the client
    ","Every time a user posts something containing < or > in a page in my web application, I get this exception thrown.I don't want to go into the discussion about the smartness of throwing an exception or crashing an entire web application because somebody entered a character in a text box, but I am looking for an elegant way to handle this.Trapping the exception and showingAn error has occurred please go back and re-type your entire form again, but this time please do not use <doesn't seem professional enough to me.Disabling post validation (validateRequest=""false"") will definitely avoid this error, but it will leave the page vulnerable to a number of attacks.Ideally: When a post back occurs containing HTML restricted characters, that posted value in the Form collection will be automatically HTML encoded.So the .Text property of my text-box will be something & lt; html & gt;Is there a way I can do this from a handler?","I think you are attacking it from the wrong angle by trying to encode all posted data.Note that a ""<"" could also come from other outside sources, like a database field, a configuration, a file, a feed and so on.Furthermore, ""<"" is not inherently dangerous. It's only dangerous in a specific context: when writing strings that haven't been encoded to HTML output (because of XSS).In other contexts different sub-strings are dangerous, for example, if you write an user-provided URL into a link, the sub-string ""javascript:"" may be dangerous. The single quote character on the other hand is dangerous when interpolating strings in SQL queries, but perfectly safe if it is a part of a name submitted from a form or read from a database field.The bottom line is: you can't filter random input for dangerous characters, because any character may be dangerous under the right circumstances. You should encode at the point where some specific characters may become dangerous because they cross into a different sub-language where they have special meaning. When you write a string to HTML, you should encode characters that have special meaning in HTML, using Server.HtmlEncode. If you pass a string to a dynamic SQL statement, you should encode different characters (or better, let the framework do it for you by using prepared statements or the like)..When you are sure you HTML-encode everywhere you pass strings to HTML, then set ValidateRequest=""false"" in the <%@ Page ... %> directive in your .aspx file(s).In .NET 4 you may need to do a little more. Sometimes it's necessary to also add <httpRuntime requestValidationMode=""2.0"" /> to web.config (reference)."
"data_i","edited Nov 04 '21 at 20:01","
        How can I install packages using pip according to the requirements.txt file from a local directory?
    ","Here is the problem:I have a requirements.txt file that looks like:BeautifulSoup==3.2.0Django==1.3Fabric==1.2.0Jinja2==2.5.5PyYAML==3.09Pygments==1.4SQLAlchemy==0.7.1South==0.7.3amqplib==0.6.1anyjson==0.3...I have a local archive directory containing all the packages + others.I have created a new virtualenv withbin/virtualenv testingUpon activating it, I tried to install the packages according to requirements.txt from the local archive directory.source bin/activatepip install -r /path/to/requirements.txt -f file:///path/to/archive/I got some output that seems to indicate that the installation is fine:Downloading/unpacking Fabric==1.2.0 (from -r ../testing/requirements.txt (line 3))  Running setup.py egg_info for package Fabric    warning: no previously-included files matching '*' found under directory 'docs/_build'    warning: no files found matching 'fabfile.py'Downloading/unpacking South==0.7.3 (from -r ../testing/requirements.txt (line 8))  Running setup.py egg_info for package South....But a later check revealed that none of the packages are installed properly. I cannot import the packages, and none are found in the site-packages directory of my virtualenv. So what went wrong?","This works for everyone:pip install -r /path/to/requirements.txtExplanation:-r, --requirement < filename >Install from the given requirements file. This option can be used multiple times."
"data_i","edited Sep 09 '22 at 09:20","
        How do you convert a byte array to a hexadecimal string, and vice versa?
    ","How can you convert a byte array to a hexadecimal string and vice versa?","You can use Convert.ToHexString starting with .NET 5. There's also a method for the reverse operation: Convert.FromHexString.For older versions of .NET you can either use:public static string ByteArrayToString(byte[] ba){  StringBuilder hex = new StringBuilder(ba.Length * 2);  foreach (byte b in ba)    hex.AppendFormat(""{0:x2}"", b);  return hex.ToString();}or:public static string ByteArrayToString(byte[] ba){  return BitConverter.ToString(ba).Replace(""-"","""");}There are even more variants of doing it, for example here.The reverse conversion would go like this:public static byte[] StringToByteArray(String hex){  int NumberChars = hex.Length;  byte[] bytes = new byte[NumberChars / 2];  for (int i = 0; i < NumberChars; i += 2)    bytes[i / 2] = Convert.ToByte(hex.Substring(i, 2), 16);  return bytes;}Using Substring is the best option in combination with Convert.ToByte. See this answer for more information. If you need better performance, you must avoid Convert.ToByte before you can drop SubString."
"data_i","edited Jun 04 '20 at 09:17","
        When should I use a struct rather than a class in C#?
    ","When should you use struct and not class in C#? My conceptual model is that structs are used in times when the item is merely a collection of value types.  A way to logically hold them all together into a cohesive whole.I came across these rules here:A struct should represent a singlevalue.A struct should have a memoryfootprint less than 16 bytes.A struct should not be changed aftercreation.Do these rules work? What does a struct mean semantically? ","The source referenced by the OP has some credibility ...but what about Microsoft - what is the stance on struct usage? I sought some extra learning from Microsoft, and here is what I found:  Consider defining a structure instead of a class if instances of the  type are small and commonly short-lived or are commonly embedded in  other objects.Do not define a structure unless the type has all of the following characteristics: It logically represents a single value, similar to primitive types (integer, double, and so on).It has an instance size smaller than 16 bytes.It is immutable.It will not have to be boxed frequently.  Microsoft consistently violates those rulesOkay, #2 and #3 anyway. Our beloved dictionary has 2 internal structs:  [StructLayout(LayoutKind.Sequential)]  // default for structsprivate struct Entry  //<Tkey, TValue>{    //  View code at *Reference Source}[Serializable, StructLayout(LayoutKind.Sequential)]public struct Enumerator :     IEnumerator<KeyValuePair<TKey, TValue>>, IDisposable,     IDictionaryEnumerator, IEnumerator{    //  View code at *Reference Source}*Reference SourceThe 'JonnyCantCode.com' source got 3 out of 4 - quite forgivable since #4 probably wouldn't be an issue. If you find yourself boxing a struct, rethink your architecture.  Let's look at why Microsoft would use these structs:Each struct, Entry and Enumerator, represent single values.SpeedEntry is never passed as a parameter outside of the Dictionary class. Further investigation shows that in order to satisfy implementation of IEnumerable, Dictionary uses the Enumerator struct which it copies every time an enumerator is requested ...makes sense.Internal to the Dictionary class. Enumerator is public because Dictionary is enumerable and must have equal accessibility to the IEnumerator interface implementation - e.g. IEnumerator getter.  Update - In addition, realize that when a struct implements an interface - as Enumerator does - and is cast to that implemented type, the struct becomes a reference type and is moved to the heap. Internal to the Dictionary class, Enumerator is still a value type. However, as soon as a method calls GetEnumerator(), a reference-type IEnumerator is returned.What we don't see here is any attempt or proof of requirement to keep structs immutable or maintaining an instance size of only 16 bytes or less:  Nothing in the structs above is declared readonly - not immutableSize of these struct could be well over 16 bytesEntry has an undetermined lifetime (from Add(), to Remove(), Clear(), or garbage collection);And ... 4. Both structs store TKey and TValue, which we all know are quite capable of being reference types (added bonus info)Hashed keys notwithstanding, dictionaries are fast in part because instancing a struct is quicker than a reference type. Here, I have a Dictionary<int, int> that stores 300,000 random integers with sequentially incremented keys.Capacity: 312874  MemSize:  2660827 bytes  Completed Resize:  5ms  Total time to fill:  889msCapacity:  number of elements available before the internal array must be resized.  MemSize:  determined by serializing the dictionary into a MemoryStream and getting a byte length (accurate enough for our purposes).  Completed Resize:  the time it takes to resize the internal array from 150862 elements to 312874 elements. When you figure that each element is sequentially copied via Array.CopyTo(), that ain't too shabby.  Total time to fill: admittedly skewed due to logging and an OnResize event I added to the source; however, still impressive to fill 300k integers while resizing 15 times during the operation. Just out of curiosity, what would the total time to fill be if I already knew the capacity? 13ms So, now, what if Entry were a class? Would these times or metrics really differ that much?  Capacity:  312874  MemSize:  2660827 bytes  Completed Resize:  26ms  Total time to fill:  964msObviously, the big difference is in resizing. Any difference if Dictionary is initialized with the Capacity? Not enough to be concerned with ... 12ms.  What happens is, because Entry is a struct, it does not require initialization like a reference type. This is both the beauty and the bane of the value type. In order to use Entry as a reference type, I had to insert the following code:/* *  Added to satisfy initialization of entry elements -- *  this is where the extra time is spent resizing the Entry array * **/for (int i = 0 ; i < prime ; i++){    destinationArray[i] = new Entry( );}/*  *********************************************** */  The reason I had to initialize each array element of Entry as a reference type can be found at MSDN: Structure Design. In short:Do not provide a default constructor for a structure.If a structure defines a default constructor, when arrays of the  structure are created, the common language runtime automatically  executes the default constructor on each array element.Some compilers, such as the C# compiler, do not allow structures to  have default constructors.It is actually quite simple and we will borrow from Asimov's Three Laws of Robotics:The struct must be safe to useThe struct must perform its function efficiently, unless this would violate rule #1The struct must remain intact during its use unless its destruction is required to satisfy rule #1  ...what do we take away from this: in short, be responsible with the use of value types. They are quick and efficient, but have the ability to cause many unexpected behaviors if not properly maintained (i.e. unintentional copies).  "
"data_i","asked Aug 29 '17 at 13:48","
        Android 8: Cleartext HTTP traffic not permitted
    ","I had reports from users with Android 8 that my app (that uses back-end feed) does not show content. After investigation I found following Exception happening on Android 8:08-29 12:03:11.246 11285-11285/ E/: [12:03:11.245, main]: Exception: IOException java.io.IOException: Cleartext HTTP traffic to * not permittedat com.android.okhttp.HttpHandler$CleartextURLFilter.checkURLPermitted(HttpHandler.java:115)at com.android.okhttp.internal.huc.HttpURLConnectionImpl.execute(HttpURLConnectionImpl.java:458)at com.android.okhttp.internal.huc.HttpURLConnectionImpl.connect(HttpURLConnectionImpl.java:127)at com.deiw.android.generic.tasks.AbstractHttpAsyncTask.doConnection(AbstractHttpAsyncTask.java:207)at com.deiw.android.generic.tasks.AbstractHttpAsyncTask.extendedDoInBackground(AbstractHttpAsyncTask.java:102)at com.deiw.android.generic.tasks.AbstractAsyncTask.doInBackground(AbstractAsyncTask.java:88)at android.os.AsyncTask$2.call(AsyncTask.java:333)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at android.os.AsyncTask$SerialExecutor$1.run(AsyncTask.java:245)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1162)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:636)at java.lang.Thread.run(Thread.java:764)(I've removed package name, URL and other possible identifiers)On Android 7 and lower everything works, I do not set android:usesCleartextTraffic in Manifest (and setting it to true does not help, that is the default value anyway), neither do I use Network Security Information. If I call NetworkSecurityPolicy.getInstance().isCleartextTrafficPermitted(), it returns false for Android 8, true for older version, using the same apk file.I tried to find some mention of this on Google info about Android O, but without success.","According to Network security configuration -Starting with Android 9 (API level 28), cleartext support is disabledby default.Also have a look at Android M and the war on cleartext trafficCodelabs explanation from GoogleOption 1 -First try hitting the URL with https:// instead of http://Option 2 -Create file res/xml/network_security_config.xml -<?xml version=""1.0"" encoding=""utf-8""?><network-security-config>    <domain-config cleartextTrafficPermitted=""true"">        <domain includeSubdomains=""true"">api.example.com(to be adjusted)</domain>    </domain-config></network-security-config>AndroidManifest.xml -<?xml version=""1.0"" encoding=""utf-8""?><manifest ...>    <uses-permission android:name=""android.permission.INTERNET"" />    <application        ...        android:networkSecurityConfig=""@xml/network_security_config""        ...>        ...    </application></manifest>Option 3 -android:usesCleartextTraffic DocAndroidManifest.xml -<?xml version=""1.0"" encoding=""utf-8""?><manifest ...>    <uses-permission android:name=""android.permission.INTERNET"" />    <application        ...        android:usesCleartextTraffic=""true""        ...>        ...    </application></manifest>Also as @david.s' answer pointed out android:targetSandboxVersion can be a problem too -According to Manifest Docs -android:targetSandboxVersionThe target sandbox for this app to use. The higher the sandbox versionnumber, the higher the level of security. Its default value is 1; youcan also set it to 2. Setting this attribute to 2 switches the app toa different SELinux sandbox. The following restrictions apply to alevel 2 sandbox:The default value of usesCleartextTraffic in the Network Security    Config is false.Uid sharing is not permitted.So Option 4 -If you have android:targetSandboxVersion in <manifest> then reduce it to 1AndroidManifest.xml -<?xml version=""1.0"" encoding=""utf-8""?><manifest android:targetSandboxVersion=""1"">    <uses-permission android:name=""android.permission.INTERNET"" />    ...</manifest>"
"data_i","edited Oct 04 '21 at 09:30","
        SQL select only rows with max value on a column
    ","I have this table for documents (simplified version here):idrevcontent11...21...12...13...How do I select one row per id and only the greatest rev?With the above data, the result should contain two rows: [1, 3, ...] and [2, 1, ..]. I'm using MySQL.Currently I use checks in the while loop to detect and over-write old revs from the resultset. But is this the only method to achieve the result? Isn't there a SQL solution?","At first glance...All you need is a GROUP BY clause with the MAX aggregate function:SELECT id, MAX(rev)FROM YourTableGROUP BY idIt's never that simple, is it?I just noticed you need the content column as well.This is a very common question in SQL: find the whole data for the row with some max value in a column per some group identifier. I heard that a lot during my career. Actually, it was one the questions I answered in my current job's technical interview.It is, actually, so common that Stack Overflow community has created a single tag just to deal with questions like that: greatest-n-per-group.Basically, you have two approaches to solve that problem:Joining with simple group-identifier, max-value-in-group Sub-queryIn this approach, you first find the group-identifier, max-value-in-group (already solved above) in a sub-query. Then you join your table to the sub-query with equality on both group-identifier and max-value-in-group:SELECT a.id, a.rev, a.contentsFROM YourTable aINNER JOIN (    SELECT id, MAX(rev) rev    FROM YourTable    GROUP BY id) b ON a.id = b.id AND a.rev = b.revLeft Joining with self, tweaking join conditions and filtersIn this approach, you left join the table with itself. Equality goes in the group-identifier. Then, 2 smart moves:The second join condition is having left side value less than right valueWhen you do step 1, the row(s) that actually have the max value will have NULL in the right side (it's a LEFT JOIN, remember?). Then, we filter the joined result, showing only the rows where the right side is NULL.So you end up with:SELECT a.*FROM YourTable aLEFT OUTER JOIN YourTable b    ON a.id = b.id AND a.rev < b.revWHERE b.id IS NULL;ConclusionBoth approaches bring the exact same result.If you have two rows with max-value-in-group for group-identifier, both rows will be in the result in both approaches.Both approaches are SQL ANSI compatible, thus, will work with your favorite RDBMS, regardless of its ""flavor"".Both approaches are also performance friendly, however your mileage may vary (RDBMS, DB Structure, Indexes, etc.). So when you pick one approach over the other, benchmark. And make sure you pick the one which make most of sense to you."
"data_i","edited Sep 14 '22 at 09:59","
        How can I open a URL in Android's web browser from my application?
    ","How to open an URL from code in the built-in web browser rather than within my application?I tried this:try {    Intent myIntent = new Intent(Intent.ACTION_VIEW, Uri.parse(download_link));    startActivity(myIntent);} catch (ActivityNotFoundException e) {    Toast.makeText(this, ""No application can handle this request.""        + "" Please install a webbrowser"",  Toast.LENGTH_LONG).show();    e.printStackTrace();}but I got an Exception:No activity found to handle Intent{action=android.intent.action.VIEW data =www.google.com","Try this:Intent browserIntent = new Intent(Intent.ACTION_VIEW, Uri.parse(""http://www.google.com""));startActivity(browserIntent);That works fine for me.As for the missing ""http://"" I'd just do something like this:if (!url.startsWith(""http://"") && !url.startsWith(""https://""))   url = ""http://"" + url;I would also probably pre-populate your EditText that the user is typing a URL in with ""http://""."
"data_i","edited Jan 28 '16 at 15:25","
        What exactly is Apache Camel?
    ","I don't understand what exactly Camel does.If you could give in 101 words an introduction to Camel:What exactly is it? How does it interact with an application written in Java? Is it something that goes together with the server? Is it an independent program? Please explain what Camel is.","My take to describe this in a more accessible way...In order to understand what Apache Camel is, you need to understand what are Enterprise Integration Patterns.Let's start with what we presumably already know: The Singleton pattern, the Factory pattern, etc; They are merely ways of organizing your solution to the problem, but they are not solutions themselves. These patterns were analyzed and extracted for the rest of us by the Gang of Four, when they published their book: Design Patterns. They saved some of us tremendous effort in thinking of how to best structure our code.Much like the Gang of Four, Gregor Hohpe and Bobby Woolf authored the book Enterprise Integration Patterns (EIP) in which they propose and document a set of new patterns and blueprints for how we could best design large component-based systems, where components can be running on the same process or in a different machine.They basically propose that we structure our system to be message oriented -- where components communicate with each others using messages as inputs and outputs and absolutely nothing else. They show us a complete set of patterns that we may choose from and implement in our different components that will together form the whole system.So what is Apache Camel?Apache Camel offers you the interfaces for the EIPs, the base objects, commonly needed implementations, debugging tools, a configuration system, and many other helpers which will save you a ton of time when you want to implement your solution to follow the EIPs.Take MVC. MVC is pretty simple in theory and we could implement it without any framework help. But good MVC frameworks provide us with the structure ready-to-use and have gone the extra mile and thought out all the other ""side"" things you need when you create a large MVC project and that's why we use them most of the time.That's exactly what Apache Camel is for EIPs. It's a complete production-ready framework for people who want to implement their solution to follow the EIPs."
"data_i","edited Jul 25 '22 at 04:27","
        How do I revert a merge commit that has already been pushed to remote?
    ","git revert <commit_hash> alone won't work. Apparently, -m must be specified.","In git revert -m, the -m option specifies the parent number. This is needed because a merge commit has more than one parent, and Git does not know automatically which parent was the mainline, and which parent was the branch you want to un-merge.When you view a merge commit in the output of git log, you will see its parents listed on the line that begins with Merge:commit 8f937c683929b08379097828c8a04350b9b8e183Merge: 8989ee0 7c6b236Author: Ben James <ben@example.com>Date:   Wed Aug 17 22:49:41 2011 +0100Merge branch 'gh-pages'Conflicts:    READMEIn this situation, git revert 8f937c6 -m 1 will get you the tree as it was in 8989ee0, and git revert -m 2 will reinstate the tree as it was in 7c6b236.To better understand the parent IDs, you can run:git log 8989ee0 andgit log 7c6b236"
"data_i","edited Feb 03 '22 at 21:45","
        How to add days to Date?
    ","How to add days to current Date using JavaScript? Does JavaScript have a built in function like .NET's AddDay()?","You can create one with:-Date.prototype.addDays = function(days) {    var date = new Date(this.valueOf());    date.setDate(date.getDate() + days);    return date;}var date = new Date();console.log(date.addDays(5));This takes care of automatically incrementing the month if necessary. For example:8/31 + 1 day will become 9/1.The problem with using setDate directly is that it's a mutator and that sort of thing is best avoided. ECMA saw fit to treat Date as a mutable class rather than an immutable structure."
"data_i","asked Oct 24 '10 at 11:12","
        application/x-www-form-urlencoded or multipart/form-data?
    ","In HTTP there are two ways to POST data: application/x-www-form-urlencoded and multipart/form-data. I understand that most browsers are only able to upload files if multipart/form-data is used. Is there any additional guidance when to use one of the encoding types in an API context (no browser involved)? This might e.g. be based on:data sizeexistence of non-ASCII charactersexistence on (unencoded) binary datathe need to transfer additional data (like filename)I basically found no formal guidance on the web regarding the use of the different content-types so far.","TL;DRSummary; if you have binary (non-alphanumeric) data (or a significantly sized payload) to transmit, use multipart/form-data. Otherwise, use application/x-www-form-urlencoded.The MIME types you mention are the two Content-Type headers for HTTP POST requests that user-agents (browsers) must support.  The purpose of both of those types of requests is to send a list of name/value pairs to the server.  Depending on the type and amount of data being transmitted, one of the methods will be more efficient than the other.  To understand why, you have to look at what each is doing under the covers.For application/x-www-form-urlencoded, the body of the HTTP message sent to the server is essentially one giant query string -- name/value pairs are separated by the ampersand (&), and names are separated from values by the equals symbol (=).  An example of this would be: MyVariableOne=ValueOne&MyVariableTwo=ValueTwoAccording to the specification:[Reserved and] non-alphanumeric characters are replaced by `%HH', a percent sign and two hexadecimal digits representing the ASCII code of the characterThat means that for each non-alphanumeric byte that exists in one of our values, it's going to take three bytes to represent it.  For large binary files, tripling the payload is going to be highly inefficient.That's where multipart/form-data comes in.  With this method of transmitting name/value pairs, each pair is represented as a ""part"" in a MIME message (as described by other answers).  Parts are separated by a particular string boundary (chosen specifically so that this boundary string does not occur in any of the ""value"" payloads).  Each part has its own set of MIME headers like Content-Type, and particularly Content-Disposition, which can give each part its ""name.""  The value piece of each name/value pair is the payload of each part of the MIME message.  The MIME spec gives us more options when representing the value payload -- we can choose a more efficient encoding of binary data to save bandwidth (e.g. base 64 or even raw binary).Why not use multipart/form-data all the time?  For short alphanumeric values (like most web forms), the overhead of adding all of the MIME headers is going to significantly outweigh any savings from more efficient binary encoding."
"data_i","edited Mar 30 '22 at 05:49","
        How do I write JSON data to a file?
    ","How do I write JSON data stored in the dictionary data to a file?f = open('data.json', 'wb')f.write(data)This gives the error:TypeError: must be string or buffer, not dict","data is a Python dictionary. It needs to be encoded as JSON before writing.Use this for maximum compatibility (Python 2 and 3):import jsonwith open('data.json', 'w') as f:    json.dump(data, f)On a modern system (i.e. Python 3 and UTF-8 support), you can write a nicer file using:import jsonwith open('data.json', 'w', encoding='utf-8') as f:    json.dump(data, f, ensure_ascii=False, indent=4)See json documentation."
"data_i","edited Sep 13 '18 at 10:25","
        How do I find out which DOM element has the focus?
    ","I would like to find out, in JavaScript, which element currently has focus. I've been looking through the DOM and haven't found what I need, yet. Is there a way to do this, and how?The reason I was looking for this:I'm trying to make keys like the arrows and enter navigate through a table of input elements. Tab works now, but enter, and arrows do not by default it seems. I've got the key handling part set up but now I need to figure out how to move the focus over in the event handling functions.","Use document.activeElement, it is supported in all major browsers.Previously, if you were trying to find out what form field has focus, you could not. To emulate detection within older browsers, add a ""focus"" event handler to all fields and record the last-focused field in a variable. Add a ""blur"" handler to clear the variable upon a blur event for the last-focused field.If you need to remove the activeElement you can use blur; document.activeElement.blur(). It will change the activeElement to body.Related links:activeElement Browser CompatibilityjQuery alternative for document.activeElement"
"data_i","edited Feb 14 '22 at 23:35","
        How can I rename a database column in a Ruby on Rails migration?
    ","I wrongly named a column hased_password instead of hashed_password.How do I update the database schema, using migration to rename this column?","rename_column :table, :old_column, :new_columnYou'll probably want to create a separate migration to do this. (Rename FixColumnName as you will.):bin/rails generate migration FixColumnName# creates  db/migrate/xxxxxxxxxx_fix_column_name.rbThen edit the migration to do your will:# db/migrate/xxxxxxxxxx_fix_column_name.rbclass FixColumnName < ActiveRecord::Migration  def self.up    rename_column :table_name, :old_column, :new_column  end  def self.down    # rename back if you need or do something else or do nothing  endendFor Rails 3.1 use:While, the up and down methods still apply, Rails 3.1 receives a change method that ""knows how to migrate your database and reverse it when the migration is rolled back without the need to write a separate down method"".See ""Active Record Migrations"" for more information.rails g migration FixColumnNameclass FixColumnName < ActiveRecord::Migration  def change    rename_column :table_name, :old_column, :new_column  endendIf you happen to have a whole bunch of columns to rename, or something that would have required repeating the table name over and over again:rename_column :table_name, :old_column1, :new_column1rename_column :table_name, :old_column2, :new_column2...You could use change_table to keep things a little neater:class FixColumnNames < ActiveRecord::Migration  def change    change_table :table_name do |t|      t.rename :old_column1, :new_column1      t.rename :old_column2, :new_column2      ...    end  endendThen just db:migrate as usual or however you go about your business.For Rails 4:While creating a Migration for renaming a column, Rails 4 generates a change method instead of up and down as mentioned in the above section. The generated change method is:$ > rails g migration ChangeColumnNamewhich will create a migration file similar to:class ChangeColumnName < ActiveRecord::Migration  def change    rename_column :table_name, :old_column, :new_column  endend"
"data_i","edited Feb 28 '20 at 12:29","
        How do I update the GUI from another thread?
    ","Which is the simplest way to update a Label from another Thread?I have a Form running on thread1, and from that I'm starting another thread (thread2). While thread2 is processing some files I would like to update a Label on the Form with the current status of thread2's work.How could I do that?","The simplest way is an anonymous method passed into Label.Invoke:// Running on the worker threadstring newText = ""abc"";form.Label.Invoke((MethodInvoker)delegate {    // Running on the UI thread    form.Label.Text = newText;});// Back on the worker threadNotice that Invoke blocks execution until it completes--this is synchronous code. The question doesn't ask about asynchronous code, but there is lots of content on Stack Overflow about writing asynchronous code when you want to learn about it."
"data_i","edited Sep 06 '22 at 16:58","
        How do I remove a directory from a Git repository?
    ","How can I delete a single directory containing files from a Git repository?","Remove directory from Git and localCheckout 'master' with both directories:git rm -r one-of-the-directories // This deletes from filesystemgit commit . -m ""Remove duplicated directory""git push origin <your-git-branch> (typically 'master', but not always)Remove directory from Git but NOT localTo remove this directory from Git, but not delete it entirely from the filesystem (local):git rm -r --cached myFolder"
"data_i","edited Aug 10 '22 at 02:20","
        Convert integer to string in Python
    ","How do I convert an integer to a string?42   ⟶   ""42""For the reverse, see How do I parse a string to a float or int?. floats can be handled similarly, but handling the decimal points can be tricky because floating-point values are not precise. See Converting a float to a string without rounding it for more specific advice.",">>> str(42)'42'>>> int('42')42Links to the documentation:int()str()str(x) converts any object x to a string by calling x.__str__()."
"data_i","edited Dec 06 '19 at 10:22","
        Where to place the 'assets' folder in Android Studio?
    ","I am confused about the assets folder. It doesn't come auto-created in Android Studio, and almost all the forums in which this is discussed talk about Eclipse.How can the Assets directory be configured in Android Studio?","Since Android Studio uses the new Gradle-based build system, you should be putting assets/ inside of the source sets (e.g., src/main/assets/).In a typical Android Studio project, you will have an app/ module, with a main/ sourceset (app/src/main/ off of the project root), and so your primary assets would go in app/src/main/assets/. However:If you need assets specific to a build type, such as debug versus release, you can create sourcesets for those roles (e.g,. app/src/release/assets/)Your product flavors can also have sourcesets with assets (e.g., app/src/googleplay/assets/)Your instrumentation tests can have an androidTest sourceset with custom assets (e.g., app/src/androidTest/assets/), though be sure to ask the InstrumentationRegistry for getContext(), not getTargetContext(), to access those assetsAlso, a quick reminder: assets are read-only at runtime. Use internal storage, external storage, or the Storage Access Framework for read/write content."
"data_i","edited Apr 02 '22 at 09:44","
        How can I concatenate two arrays in Java?
    ","I need to concatenate two String arrays in Java.void f(String[] first, String[] second) {    String[] both = ???}Which is the easiest way to do this?","I found a one-line solution from the good old Apache Commons Lang library.ArrayUtils.addAll(T[], T...)Code:String[] both = ArrayUtils.addAll(first, second);"
"data_i","edited Feb 27 '22 at 07:34","
        How to Sort a List by a property in the object
    ","I have a class called Order which has properties such as OrderId, OrderDate, Quantity, and Total. I have a list of this Order class:List<Order> objListOrder = new List<Order>();GetOrderList(objListOrder); // fill list of ordersI want to sort the list based on one property of the Order object; for example, either by the order date or the order id.How can I do this in C#?","The easiest way I can think of is to use Linq:List<Order> SortedList = objListOrder.OrderBy(o=>o.OrderDate).ToList();"
"data_i","edited Jun 08 '20 at 19:42","
        How do I get time of a Python program's execution?
    ","I have a command line program in Python that takes a while to finish. I want to know the exact time it takes to finish running.I've looked at the timeit module, but it seems it's only for small snippets of code. I want to time the whole program.","The simplest way in Python:import timestart_time = time.time()main()print(""--- %s seconds ---"" % (time.time() - start_time))This assumes that your program takes at least a tenth of second to run.Prints:--- 0.764891862869 seconds ---"
"data_i","edited Apr 09 '22 at 20:40","
        What is the purpose of Node.js module.exports and how do you use it?
    ","What is the purpose of Node.js module.exports and how do you use it?I can't seem to find any information on this, but it appears to be a rather important part of Node.js as I often see it in source code.According to the Node.js documentation:moduleA reference to the currentmodule. In particular module.exportsis the same as the exports object. Seesrc/node.js for more information.But this doesn't really help.What exactly does module.exports do, and what would a simple example be?","module.exports is the object that's actually returned as the result of a require call.The exports variable is initially set to that same object (i.e. it's a shorthand ""alias""), so in the module code you would usually write something like this:let myFunc1 = function() { ... };let myFunc2 = function() { ... };exports.myFunc1 = myFunc1;exports.myFunc2 = myFunc2;to export (or ""expose"") the internally scoped functions myFunc1 and myFunc2.And in the calling code you would use:const m = require('./mymodule');m.myFunc1();where the last line shows how the result of require is (usually) just a plain object whose properties may be accessed.NB: if you overwrite exports then it will no longer refer to module.exports.  So if you wish to assign a new object (or a function reference) to exports then you should also assign that new object to module.exportsIt's worth noting that the name added to the exports object does not have to be the same as the module's internally scoped name for the value that you're adding, so you could have:let myVeryLongInternalName = function() { ... };exports.shortName = myVeryLongInternalName;// add other objects, functions, as requiredfollowed by:const m = require('./mymodule');m.shortName(); // invokes module.myVeryLongInternalName"
"data_i","edited Jun 25 '20 at 12:04","
        'Static readonly' vs. 'const'
    ","I've read around about const and static readonly fields. We have some classes which contain only constant values. They are used for various things around in our system. So I am wondering if my observation is correct:Should these kind of constant values always be static readonly for everything that is public? And only use const for internal/protected/private values?What do you recommend? Should I maybe even not use static readonly fields, but rather use properties maybe?","public static readonly fields are a little unusual; public static properties (with only a get) would be more common (perhaps backed by a private static readonly field).const values are burned directly into the call-site; this is double edged:it is useless if the value is fetched at runtime, perhaps from configif you change the value of a const, you need to rebuild all the clientsbut it can be faster, as it avoids a method call......which might sometimes have been inlined by the JIT anywayIf the value will never change, then const is fine - Zero etc make reasonable consts ;p Other than that, static properties are more common."
"data_i","edited Feb 15 '21 at 23:59","
        How to add a class to a given element?
    ","I have an element that already has a class:<div class=""someclass"">    <img ... id=""image1"" name=""image1"" /></div>Now, I want to create a JavaScript function that will add a class to the div (not replace, but add).How can I do that?","If you're only targeting modern browsers:Use element.classList.add to add a class:element.classList.add(""my-class"");And element.classList.remove to remove a class:element.classList.remove(""my-class"");If you need to support Internet Explorer 9 or lower:Add a space plus the name of your new class to the className property of the element. First, put an id on the element so you can easily get a reference.<div id=""div1"" class=""someclass"">    <img ... id=""image1"" name=""image1"" /></div>Then var d = document.getElementById(""div1"");d.className += "" otherclass"";Note the space before otherclass. It's important to include the space otherwise it compromises existing classes that come before it in the class list. See also element.className on MDN."
"data_i","edited Feb 22 '14 at 09:24","
        Is there a ""null coalescing"" operator in JavaScript?
    ","Is there a null coalescing operator in Javascript?For example, in C#, I can do this:String someString = null;var whatIWant = someString ?? ""Cookies!"";The best approximation I can figure out for Javascript is using the conditional operator:var someString = null;var whatIWant = someString ? someString : 'Cookies!';Which is sorta icky IMHO. Can I do better?","UpdateJavaScript now supports the nullish coalescing operator (??). It returns its right-hand-side operand when its left-hand-side operand is null or undefined, and otherwise returns its left-hand-side operand.Old AnswerPlease check compatibility before using it.The JavaScript equivalent of the C# null coalescing operator (??) is using a logical OR (||):var whatIWant = someString || ""Cookies!"";There are cases (clarified below) that the behaviour won't match that of C#, but this is the general, terse way of assigning default/alternative values in JavaScript.ClarificationRegardless of the type of the first operand, if casting it to a Boolean results in false, the assignment will use the second operand. Beware of all the cases below:alert(Boolean(null)); // falsealert(Boolean(undefined)); // falsealert(Boolean(0)); // falsealert(Boolean("""")); // falsealert(Boolean(""false"")); // true -- gotcha! :)This means:var whatIWant = null || new ShinyObject(); // is a new shiny objectvar whatIWant = undefined || ""well defined""; // is ""well defined""var whatIWant = 0 || 42; // is 42var whatIWant = """" || ""a million bucks""; // is ""a million bucks""var whatIWant = ""false"" || ""no way""; // is ""false"""
"data_i","edited Oct 28 '21 at 09:56","
        What are the options for storing hierarchical data in a relational database?
    ","Good OverviewsGenerally speaking, you're making a decision between fast read times (for example, nested set) or fast write times (adjacency list). Usually, you end up with a combination of the options below that best fit your needs. The following provides some in-depth reading:One more Nested Intervals vs. Adjacency List comparison: the best comparison of Adjacency List, Materialized Path, Nested Set, and Nested Interval I've found.Models for hierarchical data: slides with good explanations of tradeoffs and example usageRepresenting hierarchies in MySQL: very good overview of Nested Set in particularHierarchical data in RDBMSs: a most comprehensive and well-organized set of links I've seen, but not much in the way of explanationOptionsOnes I am aware of and general features:Adjacency List:Columns: ID, ParentIDEasy to implement.Cheap node moves, inserts, and deletes.Expensive to find the level, ancestry & descendants, pathAvoid N+1 via Common Table Expressions in databases that support themNested Set (a.k.a Modified Preorder Tree Traversal)Columns: Left, RightCheap ancestry, descendantsVery expensive O(n/2) moves, inserts, deletes due to volatile encodingBridge Table (a.k.a. Closure Table /w triggers)Uses separate join table with ancestor, descendant, depth (optional)Cheap ancestry and descendantsWrites costs O(log n) (size of the subtree) for insert, updates, deletesNormalized encoding: good for RDBMS statistics & query planner in joinsRequires multiple rows per nodeLineage Column (a.k.a. Materialized Path, Path Enumeration)Column: lineage (e.g. /parent/child/grandchild/etc...)Cheap descendants via prefix query (e.g. LEFT(lineage, #) = '/enumerated/path')Writes costs O(log n) (size of the subtree) for insert, updates, deletesNon-relational: relies on Array datatype or serialized string formatNested IntervalsLike nested set, but with real/float/decimal so that the encoding isn't volatile (inexpensive move/insert/delete)Has real/float/decimal representation/precision issuesMatrix encoding variant adds ancestor encoding (materialized path) for ""free"", but with the added trickiness of linear algebra.Flat TableA modified Adjacency List that adds a Level and Rank (e.g. ordering) column to each record.Cheap to iterate/paginate overExpensive move and deleteGood Use: threaded discussion - forums / blog commentsMultiple lineage columnsColumns: one for each lineage level, refers to all the parents up to the root, levels down from the item's level are set to NULLCheap ancestors, descendants, levelCheap insert, delete, move of the leavesExpensive insert, delete, move of the internal nodesHard limit to how deep the hierarchy can beDatabase Specific NotesMySQLUse session variables for Adjacency ListOracleUse CONNECT BY to traverse Adjacency ListsPostgreSQLltree datatype for Materialized PathSQL ServerGeneral summary2008 offers HierarchyId data type that appears to help with the Lineage Column approach and expand the depth that can be represented.","My favorite answer is as what the first sentence in this thread suggested.  Use an Adjacency List to maintain the hierarchy and use Nested Sets to query the hierarchy.The problem up until now has been that the coversion method from an Adjacecy List to Nested Sets has been frightfully slow because most people use the extreme RBAR method known as a ""Push Stack"" to do the conversion and has been considered to be way to expensive to reach the Nirvana of the simplicity of maintenance by the Adjacency List and the awesome performance of Nested Sets.  As a result, most people end up having to settle for one or the other especially if there are more than, say, a lousy 100,000 nodes or so.  Using the push stack method can take a whole day to do the conversion on what MLM'ers would consider to be a small million node hierarchy.I thought I'd give Celko a bit of competition by coming up with a method to convert an Adjacency List to Nested sets at speeds that just seem impossible. Here's the performance of the push stack method on my i5 laptop.Duration for     1,000 Nodes = 00:00:00:870 Duration for    10,000 Nodes = 00:01:01:783 (70 times slower instead of just 10)Duration for   100,000 Nodes = 00:49:59:730 (3,446 times slower instead of just 100) Duration for 1,000,000 Nodes = 'Didn't even try this'And here's the duration for the new method (with the push stack method in parenthesis).Duration for     1,000 Nodes = 00:00:00:053 (compared to 00:00:00:870)Duration for    10,000 Nodes = 00:00:00:323 (compared to 00:01:01:783)Duration for   100,000 Nodes = 00:00:03:867 (compared to 00:49:59:730)Duration for 1,000,000 Nodes = 00:00:54:283 (compared to something like 2 days!!!)Yes, that's correct.  1 million nodes converted in less than a minute and 100,000 nodes in under 4 seconds.You can read about the new method and get a copy of the code at the following URL.http://www.sqlservercentral.com/articles/Hierarchy/94040/I also developed a ""pre-aggregated"" hierarchy using similar methods.  MLM'ers and people making bills of materials will be particularly interested in this article.http://www.sqlservercentral.com/articles/T-SQL/94570/If you do stop by to take a look at either article, jump into the ""Join the discussion"" link and let me know what you think."
"data_i","edited Dec 03 '17 at 14:37","
        Is null check needed before calling instanceof?
    ","Will null instanceof SomeClass return false or throw a NullPointerException?","No, a null check is not needed before using instanceof.The expression x instanceof SomeClass is false if x is null.The Java 11 Language Specification expresses this concisely in section 15.20.2, ""Type comparison operator instanceof"". (Java 17 expresses this less concisely, after the introduction of instanceof patternmatching.)""At run time, the result of theinstanceof operator is true if thevalue of the RelationalExpression isnot null and the reference could becast to the ReferenceTypewithout raising a ClassCastException.Otherwise the result is false.""So if the operand is null, the result is false."
"data_i","edited Sep 15 '22 at 14:30","
        Interface vs Abstract Class (general OO)
    ","I have recently had two telephone interviews where I've been asked about the differences between an Interface and an Abstract class. I have explained every aspect of them I could think of, but it seems they are waiting for me to mention something specific, and I don't know what it is.From my experience I think the following is true. If I am missing a major point please let me know.Interface:Every single Method declared in an Interface will have to be implemented in the subclass.Only Events, Delegates, Properties (C#) and Methods can exist in an Interface. A class can implement multiple Interfaces.Abstract Class:Only Abstract methods have to be implemented by the subclass. An Abstract class can have normal methods with implementations. An Abstract class can also have class variables besides Events, Delegates, Properties and Methods. A class can implement one abstract class only due to the non-existence of Multi-inheritance in C#.After all that, the interviewer came up with the question ""What if you had an Abstract class with only abstract methods? How would that be different from an interface?"" I didn't know the answer but I think it's the inheritance as mentioned above right?Another interviewer asked me, ""What if you had a Public variable inside the interface, how would that be different than in a Abstract Class?"" I insisted you can't have a public variable inside an interface. I didn't know what he wanted to hear but he wasn't satisfied either.See Also:When to use an interface instead of an abstract class and vice versaInterfaces vs. Abstract ClassesHow do you decide between using an Abstract Class and an Interface?What is the difference between an interface and abstract class?","How about an analogy: when I was in the Air Force, I went to pilot training and became a USAF (US Air Force) pilot. At that point I wasn't qualified to fly anything, and had to attend aircraft type training. Once I qualified, I was a pilot (Abstract class) and a C-141 pilot (concrete class). At one of my assignments, I was given an additional duty: Safety Officer. Now I was still a pilot and a C-141 pilot, but I also performed Safety Officer duties (I implemented ISafetyOfficer, so to speak). A pilot wasn't required to be a safety officer, other people could have done it as well.All USAF pilots have to follow certain Air Force-wide regulations, and all C-141 (or F-16, or T-38) pilots 'are' USAF pilots. Anyone can be a safety officer. So, to summarize:Pilot:  abstract classC-141 Pilot:  concrete classISafety Officer:  interfaceadded note:  this was meant to be an analogy to help explain the concept, not a coding recommendation.  See the various comments below, the discussion is interesting."
"data_i","edited Mar 06 '19 at 00:56","
        Why is Dictionary preferred over Hashtable in C#?
    ","In most programming languages, dictionaries are preferred over hashtables.What are the reasons behind that?","For what it's worth, a Dictionary is (conceptually) a hash table.If you meant ""why do we use the Dictionary<TKey, TValue> class instead of the Hashtable class?"", then it's an easy answer: Dictionary<TKey, TValue> is a generic type, Hashtable is not. That means you get type safety with Dictionary<TKey, TValue>, because you can't insert any random object into it, and you don't have to cast the values you take out.Interestingly, the Dictionary<TKey, TValue> implementation in the .NET Framework is based on the Hashtable, as you can tell from this comment in its source code:The generic Dictionary was copied from Hashtable's sourceSource "
"data_i","edited Sep 11 '22 at 15:50","
        How can I change a PostgreSQL user password?
    ","How do I change the password for a PostgreSQL user?","To log in without a password:sudo -u user_name psql db_nameTo reset the password if you have forgotten:ALTER USER user_name WITH PASSWORD 'new_password';"
"data_i","edited May 25 '21 at 04:43","
        Convert a Unix timestamp to time in JavaScript
    ","I am storing time in a MySQL database as a Unix timestamp and that gets sent to some JavaScript code. How would I get just the time out of it?For example, in HH/MM/SS format.","let unix_timestamp = 1549312452// Create a new JavaScript Date object based on the timestamp// multiplied by 1000 so that the argument is in milliseconds, not seconds.var date = new Date(unix_timestamp * 1000);// Hours part from the timestampvar hours = date.getHours();// Minutes part from the timestampvar minutes = ""0"" + date.getMinutes();// Seconds part from the timestampvar seconds = ""0"" + date.getSeconds();// Will display time in 10:30:23 formatvar formattedTime = hours + ':' + minutes.substr(-2) + ':' + seconds.substr(-2);console.log(formattedTime);For more information regarding the Date object, please refer to MDN or the ECMAScript 5 specification."
"data_i","edited Aug 05 '21 at 18:28","
        How to reset AUTO_INCREMENT in MySQL
    ","How can I reset the AUTO_INCREMENT of a field?I want it to start counting from 1 again.","You can reset the counter with:ALTER TABLE tablename AUTO_INCREMENT = 1For InnoDB you cannot set the auto_increment value lower or equal to the highest current index. (quote from ViralPatel):Note that you cannot reset the counter to a value less than or equalto any that have already been used. For MyISAM, if the value is lessthan or equal to the maximum value currently in the AUTO_INCREMENTcolumn, the value is reset to the current maximum plus one. ForInnoDB, if the value is less than the current maximum value in thecolumn, no error occurs and the current sequence value is not changed.See How can I reset an MySQL AutoIncrement using a MAX value from another table? on how to dynamically get an acceptable value."
"data_i","edited Dec 04 '18 at 04:33","
        Use of *args and **kwargs
    ","So I have difficulty with the concept of *args and **kwargs.So far I have learned that:*args = list of arguments - as positional arguments**kwargs = dictionary - whose keys become separate keyword arguments and the values become values of these arguments.I don't understand what programming task this would be helpful for. Maybe:I think to enter lists and dictionaries as arguments of a function AND at the same time as a wildcard, so I can pass ANY argument?Is there a simple example to explain how *args and **kwargs are used?Also the tutorial I found used just the ""*"" and a variable name. Are *args and **kwargs just placeholders or do you use exactly *args and **kwargs in the code?","The syntax is the * and **.  The names *args and **kwargs are only by convention but there's no hard requirement to use them.You would use *args when you're not sure how many arguments might be passed to your function, i.e. it allows you pass an arbitrary number of arguments to your function.  For example:>>> def print_everything(*args):        for count, thing in enumerate(args):...         print( '{0}. {1}'.format(count, thing))...>>> print_everything('apple', 'banana', 'cabbage')0. apple1. banana2. cabbageSimilarly, **kwargs allows you to handle named arguments that you have not defined in advance:>>> def table_things(**kwargs):...     for name, value in kwargs.items():...         print( '{0} = {1}'.format(name, value))...>>> table_things(apple = 'fruit', cabbage = 'vegetable')cabbage = vegetableapple = fruitYou can use these along with named arguments too.  The explicit arguments get values first and then everything else is passed to *args and **kwargs.  The named arguments come first in the list.  For example:def table_things(titlestring, **kwargs)You can also use both in the same function definition but *args must occur before **kwargs.You can also use the * and ** syntax when calling a function.  For example:>>> def print_three_things(a, b, c):...     print( 'a = {0}, b = {1}, c = {2}'.format(a,b,c))...>>> mylist = ['aardvark', 'baboon', 'cat']>>> print_three_things(*mylist)a = aardvark, b = baboon, c = catAs you can see in this case it takes the list (or tuple) of items and unpacks it. By this it matches them to the arguments in the function.  Of course, you could have a * both in the function definition and in the function call."
"data_i","asked Feb 22 '11 at 10:30","
        What is the difference between null and undefined in JavaScript?
    ","I want to know what the difference is between null and undefined in JavaScript.","undefined means a variable has been declared but has not yet been assigned a value :var testVar;alert(testVar); //shows undefinedalert(typeof testVar); //shows undefinednull is an assignment value. It can be assigned to a variable as a representation of no value :var testVar = null;alert(testVar); //shows nullalert(typeof testVar); //shows objectFrom the preceding examples, it is clear that undefined and null are two distinct types: undefined is a type itself (undefined) while null is an object.Proof :console.log(null === undefined) // false (not the same type)console.log(null == undefined) // true (but the ""same value"")console.log(null === null) // true (both type and value are the same)andnull = 'value' // Uncaught SyntaxError: invalid assignment left-hand sideundefined = 'value' // 'value'"
"data_i","edited Jul 25 '22 at 04:17","
        Hard reset of a single file
    ","How do I discard the changes to a single file and overwrite it with a fresh HEAD copy? I want to do git reset --hard to only a single file.","To reset both the working copy of my-file.txt and its state in the Git index to that of HEAD:git checkout HEAD -- my-file.txt-- means ""treat every argument after this point as a filename"". More details in this answer. Thanks to VonC for pointing this out."
"data_i","edited Jan 29 '15 at 02:07","
        Determine Whether Two Date Ranges Overlap
    ","Given two date ranges, what is the simplest or most efficient way to determine whether the two date ranges overlap?As an example, suppose we have ranges denoted by DateTime variables StartDate1 to EndDate1 and StartDate2 to EndDate2.","(StartA <= EndB)  and  (EndA >= StartB)Proof:Let ConditionA Mean that DateRange A Completely After DateRange B_                        |---- DateRange A ------||---Date Range B -----|                          _(True if StartA > EndB)Let ConditionB Mean that DateRange A is Completely Before DateRange B|---- DateRange A -----|                        _ _                          |---Date Range B ----|(True if EndA < StartB)Then Overlap exists if Neither A Nor B is true -(If one range is neither completely after the other,nor completely before the other,then they must overlap.)Now one of De Morgan's laws says that:Not (A Or B)  <=>  Not A And Not BWhich translates to: (StartA <= EndB)  and  (EndA >= StartB)NOTE: This includes conditions where the edges overlap exactly.  If you wish to exclude that,change the >= operators to >, and <=  to <NOTE2. Thanks to @Baodad, see this blog, the actual overlap is least of:{ endA-startA, endA - startB, endB-startA, endB - startB }(StartA <= EndB)  and  (EndA >= StartB)(StartA <= EndB)  and  (StartB <= EndA)NOTE3. Thanks to @tomosius, a shorter version reads:DateRangesOverlap = max(start1, start2) < min(end1, end2)This is actually a syntactical shortcut for what is a longer implementation, which includes extra checks to verify that the start dates are on or before the endDates.  Deriving this from above:If start and end dates can be out of order, i.e., if it is possible that startA > endA or startB > endB, then you also have to check that they are in order, so that means you have to add two additional validity rules:(StartA <= EndB) and (StartB <= EndA) and (StartA <= EndA) and (StartB <= EndB)or:(StartA <= EndB) and (StartA <= EndA) and (StartB <= EndA) and (StartB <= EndB)or,(StartA <= Min(EndA, EndB) and (StartB <= Min(EndA, EndB))or:(Max(StartA, StartB) <= Min(EndA, EndB)But to implement Min() and Max(), you have to code, (using C ternary for terseness),:(StartA > StartB? Start A: StartB) <= (EndA < EndB? EndA: EndB)"
"data_i","edited Aug 24 '20 at 20:58","
        Remove empty elements from an array in Javascript
    ","How do I remove empty elements from an array in JavaScript? Is there a straightforward way, or do I need to loop through it and remove them manually?","A few simple ways:var arr = [1,2,,3,,-3,null,,0,,undefined,4,,4,,5,,6,,,,];arr.filter(n => n)// [1, 2, 3, -3, 4, 4, 5, 6]arr.filter(Number) // [1, 2, 3, -3, 4, 4, 5, 6]arr.filter(Boolean) // [1, 2, 3, -3, 4, 4, 5, 6]or - (only for single array items of type ""text"")['','1','2',3,,'4',,undefined,,,'5'].join('').split(''); // output:  [""1"",""2"",""3"",""4"",""5""]or - Classic way: simple iterationvar arr = [1,2,null, undefined,3,,3,,,0,,,[],,{},,5,,6,,,,],    len = arr.length, i;for(i = 0; i < len; i++ )    arr[i] && arr.push(arr[i]);  // copy non-empty values to the end of the arrayarr.splice(0 , len);  // cut the array and leave only the non-empty values// [1,2,3,3,[],Object{},5,6]jQuery:var arr = [1,2,,3,,3,,,0,,,4,,4,,5,,6,,,,];    arr = $.grep(arr, n => n == 0 || n);// [1, 2, 3, 3, 0, 4, 4, 5, 6]"
"data_i","asked Aug 18 '09 at 11:40","
        How can I do an UPDATE statement with JOIN in SQL Server?
    ","I need to update this table in SQL Server with data from its 'parent' table, see below:Table: saleid (int)udid (int)assid (int)Table: udid  (int)assid  (int)sale.assid contains the correct value to update ud.assid. What query will do this? I'm thinking of a join but I'm not sure if it's possible.","Syntax strictly depends on which SQL DBMS you're using. Here are some ways to do it in ANSI/ISO (aka should work on any SQL DBMS), MySQL, SQL Server, and Oracle. Be advised that my suggested ANSI/ISO method will typically be much slower than the other two methods, but if you're using a SQL DBMS other than MySQL, SQL Server, or Oracle, then it may be the only way to go (e.g. if your SQL DBMS doesn't support MERGE):ANSI/ISO:update ud      set assid = (          select sale.assid           from sale           where sale.udid = ud.id     ) where exists (      select *       from sale       where sale.udid = ud.id );MySQL:update ud uinner join sale s on    u.id = s.udidset u.assid = s.assidSQL Server:update uset u.assid = s.assidfrom ud u    inner join sale s on        u.id = s.udidPostgreSQL:update ud  set assid = s.assidfrom sale s where ud.id = s.udid;Note that the target table must not be repeated in the FROM clause for Postgres.Oracle:update    (select        u.assid as new_assid,        s.assid as old_assid    from ud u        inner join sale s on            u.id = s.udid) upset up.new_assid = up.old_assidSQLite:update ud      set assid = (          select sale.assid           from sale           where sale.udid = ud.id     ) where RowID in (      select RowID       from ud       where sale.udid = ud.id );"
"data_i","edited Jun 20 '22 at 06:28","
        How can I flush the output of the print function?
    ","How do I force Python's print function to flush the buffered output to the screen?","In Python 3, print can take an optional flush argument:print(""Hello, World!"", flush=True)In Python 2, after calling print, do:import syssys.stdout.flush()By default, print prints to sys.stdout (see the documentation for more about file objects)."
"data_i","edited Jun 22 '22 at 14:07","
        How can I generate a Git patch for a specific commit?
    ","I need to write a script that creates patches for a list of SHA-1 commit numbers.I tried using git format-patch <the SHA1>, but that generated a patch for each commit since that SHA-1 value. After a few hundred patches were generated, I had to kill the process.Is there a way to generate a patch only for the specific SHA-1 value?","Try:git format-patch -1 <sha>orgit format-patch -1 HEADAccording to the documentation link above, the -1 flag tells Git how many commits should be included in the patch;-<n>    Prepare patches from the topmost  commits.Apply the patch with the command:git am < file.patch"
"data_i","edited Oct 27 '16 at 13:51","
        How can I view a git log of just one user's commits?
    ","When using git log, how can I filter by user so that I see only commits from that user?","This works for both git log and gitk - the 2 most common ways of viewing history.You don't need to use the whole name:git log --author=""Jon""will match a commit made by ""Jonathan Smith""git log --author=Jonandgit log --author=Smithwould also work. The quotes are optional if you don't need any spaces.Add --all if you intend to search all branches and not just the current commit's ancestors in your repo.You can also easily match on multiple authors as regex is the underlying mechanism for this filter. So to list commits by Jonathan or Adam, you can do this:git log --author=""\(Adam\)\|\(Jon\)""In order to exclude commits by a particular author or set of authors using regular expressions as noted in this question, you can use a negative lookahead in combination with the --perl-regexp switch:git log --author='^(?!Adam|Jon).*$' --perl-regexpAlternatively, you can exclude commits authored by Adam by using bash and piping:git log --format='%H %an' |   grep -v Adam |   cut -d ' ' -f1 |   xargs -n1 git log -1If you want to exclude commits commited (but not necessarily authored) by Adam, replace %an with %cn. More details about this are in my blog post here: http://dymitruk.com/blog/2012/07/18/filtering-by-author-name/"
"data_i","edited Jun 20 '22 at 06:33","
        Use different Python version with virtualenv
    ","How do I create a virtual environment for a specified version of Python?","NOTE: For Python 3.3+, see The Aelfinn's answer below.Use the --python (or short -p) option when creating a virtualenv instance to specify the Python executable you want to use, e.g.:virtualenv --python=""/usr/bin/python2.6"" ""/path/to/new/virtualenv/"""
"data_i","edited Jul 01 '22 at 21:31","
        Why can't Python parse this JSON data?
    ","I have this JSON in a file:{    ""maps"": [        {            ""id"": ""blabla"",            ""iscategorical"": ""0""        },        {            ""id"": ""blabla"",            ""iscategorical"": ""0""        }    ],    ""masks"": [        ""id"": ""valore""    ],    ""om_points"": ""value"",    ""parameters"": [        ""id"": ""valore""    ]}I wrote this script to print all of the JSON data:import jsonfrom pprint import pprintwith open('data.json') as f:    data = json.load(f)pprint(data)This program raises an exception, though:Traceback (most recent call last):  File ""<pyshell#1>"", line 5, in <module>    data = json.load(f)  File ""/usr/lib/python3.5/json/__init__.py"", line 319, in loads    return _default_decoder.decode(s)  File ""/usr/lib/python3.5/json/decoder.py"", line 339, in decode    obj, end = self.raw_decode(s, idx=_w(s, 0).end())  File ""/usr/lib/python3.5/json/decoder.py"", line 355, in raw_decode    obj, end = self.scan_once(s, idx)json.decoder.JSONDecodeError: Expecting ',' delimiter: line 13 column 13 (char 213)How can I parse the JSON and extract its values?","Your data is not valid JSON format. You have [] when you should have {} for the ""masks"" and ""parameters"" elements:[] are for JSON arrays, which are called list in Python{} are for JSON objects, which are called dict in PythonHere's how your JSON file should look:{    ""maps"": [        {            ""id"": ""blabla"",            ""iscategorical"": ""0""        },        {            ""id"": ""blabla"",            ""iscategorical"": ""0""        }    ],    ""masks"": {        ""id"": ""valore""    },    ""om_points"": ""value"",    ""parameters"": {        ""id"": ""valore""    }}Then you can use your code:import jsonfrom pprint import pprintwith open('data.json') as f:    data = json.load(f)pprint(data)With data, you can now also find values like so:data[""maps""][0][""id""]data[""masks""][""id""]data[""om_points""]Try those out and see if it starts to make sense."
"data_i","edited Apr 09 '22 at 08:10","
        How do I get the filename without the extension from a path in Python?
    ","How do I get the filename without the extension from a path in Python?""/path/to/some/file.txt""  →  ""file""","Getting the name of the file without the extension:import osprint(os.path.splitext(""/path/to/some/file.txt"")[0])Prints:/path/to/some/fileDocumentation for os.path.splitext.Important Note: If the filename has multiple dots, only the extension after the last one is removed. For example:import osprint(os.path.splitext(""/path/to/some/file.txt.zip.asc"")[0])Prints:/path/to/some/file.txt.zipSee other answers below if you need to handle that case."
"data_i","edited Dec 02 '20 at 04:34","
        How can you get the build/version number of your Android application?
    ","I need to figure out how to get or make a build number for my Android application. I need the build number to display in the UI.Do I have to do something with AndroidManifest.xml?","If you're using the Gradle plugin/Android Studio, as of version 0.7.0, version code and version name are available statically in BuildConfig. Make sure you import your app's package, and not another BuildConfig:import com.yourpackage.BuildConfig;...int versionCode = BuildConfig.VERSION_CODE;String versionName = BuildConfig.VERSION_NAME;No Context object needed!Also make sure to specify them in your build.gradle file instead of the AndroidManifest.xml.defaultConfig {    versionCode 1    versionName ""1.0""}"
"data_i","edited Jul 20 '17 at 09:09","
        Create a branch in Git from another branch
    ","I have two branches: master and devI want to create a ""feature branch"" from the dev branch.Currently on the branch dev, I do:$ git checkout -b myfeature dev... (some work)$ git commit -am ""blablabla""$ git push origin myfeatureBut, after visualizing my branches, I got:--**master**------0-----0-----0-----0-----0------------------------**dev**----**myfeature**I mean that the branch seems ff merged, and I don't understand why...What I'm doing wrong?Can you explain me please how you branch off from another branch and push back to the remote repository for the feature branch?All that in a branching model like the one described here.","If you like the method in the link you've posted, have a look at Git Flow.It's a set of scripts he created for that workflow.But to answer your question:$ git checkout -b myFeature devCreates MyFeature branch off dev. Do your work and then$ git commit -am ""Your message""Now merge your changes to dev without a fast-forward$ git checkout dev$ git merge --no-ff myFeatureNow push changes to the server$ git push origin dev$ git push origin myFeatureAnd you'll see it how you want it."
"data_i","edited Jul 23 '18 at 11:38","
        How do I pass data between Activities in Android application?
    ","I have a scenario where, after logging in through a login page, there will be a sign-out button on each activity.On clicking sign-out, I will be passing the session id of the signed in user to sign-out. Can anyone guide me on how to keep session id available to all activities?Any alternative to this case ","In your current Activity, create a new Intent:String value=""Hello world"";Intent i = new Intent(CurrentActivity.this, NewActivity.class);    i.putExtra(""key"",value);startActivity(i);Then in the new Activity, retrieve those values:Bundle extras = getIntent().getExtras();if (extras != null) {    String value = extras.getString(""key"");    //The key argument here must match that used in the other activity}Use this technique to pass variables from one Activity to the other."
"data_i","edited May 14 '19 at 10:29","
        Changing image size in Markdown
    ","I just got started with Markdown. I love it, but there is one thing bugging me: How can I change the size of an image using Markdown?The documentation only gives the following suggestion for an image: ![drawing](drawing.jpg)If it is possible I would like the picture to also be centered. I am asking for general Markdown, not just how GitHub does it. ","You could just use some HTML in your Markdown:<img src=""drawing.jpg"" alt=""drawing"" width=""200""/>Or via style attribute (not supported by GitHub)<img src=""drawing.jpg"" alt=""drawing"" style=""width:200px;""/>Or you could use a custom CSS file as described in this answer on Markdown and image alignment![drawing](drawing.jpg)CSS in another file:img[alt=drawing] { width: 200px; }"
"data_i","edited Jan 22 '16 at 20:21","
        How to manage a redirect request after a jQuery Ajax call
    ","I'm using $.post() to call a servlet using Ajax and then using the resulting HTML fragment to replace a div element in the user's current page. However, if the session times out, the server sends a redirect directive to send the user to the login page. In this case, jQuery is replacing the div element with the contents of the login page, forcing the user's eyes to witness a rare scene indeed. How can I manage a redirect directive from an Ajax call with jQuery 1.2.6?","I read this question and implemented the approach that has been stated regarding setting the response HTTP status code to 278 in order to avoid the browser transparently handling the redirects. Even though this worked, I was a little dissatisfied as it is a bit of a hack.After more digging around, I ditched this approach and used JSON. In this case, all responses to AJAX requests have the status code 200 and the body of the response contains a JSON object that is constructed on the server. The JavaScript on the client can then use the JSON object to decide what it needs to do.I had a similar problem to yours. I perform an AJAX request that has 2 possible responses: one that redirects the browser to a new page and one that replaces an existing HTML form on the current page with a new one. The jQuery code to do this looks something like:$.ajax({    type: ""POST"",    url: reqUrl,    data: reqBody,    dataType: ""json"",    success: function(data, textStatus) {        if (data.redirect) {            // data.redirect contains the string URL to redirect to            window.location.href = data.redirect;        } else {            // data.form contains the HTML for the replacement form            $(""#myform"").replaceWith(data.form);        }    }});The JSON object ""data"" is constructed on the server to have 2 members: data.redirect and data.form. I found this approach to be much better."
"data_i","edited Apr 09 '22 at 07:41","
        Create a dictionary with comprehension
    ","Can I use list comprehension syntax to create a dictionary?For example, by iterating over pairs of keys and values:d = {... for k, v in zip(keys, values)}","Use a dict comprehension (Python 2.7 and later):{key: value for (key, value) in iterable}Alternatively for simpler cases or earlier version of Python, use the dict constructor, e.g.:pairs = [('a', 1), ('b', 2)]dict(pairs)                         #=> {'a': 1, 'b': 2}dict([(k, v+1) for k, v in pairs])  #=> {'a': 2, 'b': 3}Given separate arrays of keys and values, use the dict constructor with zip:keys = ['a', 'b']values = [1, 2]dict(zip(keys, values))  #=> {'a': 1, 'b': 2}2) ""zip'ped"" from two separate iterables of keys/valsdict(zip(list_of_keys, list_of_values))"
"data_i","edited Aug 29 '22 at 12:33","
        What are bitwise shift (bit-shift) operators and how do they work?
    ","I've been attempting to learn C in my spare time, and other languages (C#, Java, etc.) have the same concept (and often the same operators)...At a core level, what does bit-shifting (<<, >>, >>>) do, what problems can it help solve, and what gotchas lurk around the bend? In other words, an absolute beginner's guide to bit shifting in all its goodness.","The bit shifting operators do exactly what their name implies.  They shift bits.  Here's a brief (or not-so-brief) introduction to the different shift operators.The Operators>> is the  arithmetic (or signed) right shift operator.>>> is the logical (or unsigned) right shift operator.<< is the left shift operator, and meets the needs of both logical and arithmetic shifts.All of these operators can be applied to integer values (int, long, possibly short and byte or char).  In some languages, applying the shift operators to any datatype smaller than int automatically resizes the operand to be an int.Note that <<< is not an operator, because it would be redundant.Also note that C and C++ do not distinguish between the right shift operators.  They provide only the >> operator, and the right-shifting behavior is implementation defined for signed types.  The rest of the answer uses the C# / Java operators.(In all mainstream C and C++ implementations including GCC and Clang/LLVM, >> on signed types is arithmetic.  Some code assumes this, but it isn't something the standard guarantees.  It's not undefined, though; the standard requires implementations to define it one way or another.  However, left shifts of negative signed numbers is undefined behaviour (signed integer overflow).  So unless you need arithmetic right shift, it's usually a good idea to do your bit-shifting with unsigned types.)Left shift (<<)Integers are stored, in memory, as a series of bits.  For example, the number 6 stored as a 32-bit int would be:00000000 00000000 00000000 00000110Shifting this bit pattern to the left one position (6 << 1) would result in the number 12:00000000 00000000 00000000 00001100As you can see, the digits have shifted to the left by one position, and the last digit on the right is filled with a zero.  You might also note that shifting left is equivalent to multiplication by powers of 2.  So 6 << 1 is equivalent to 6 * 2, and 6 << 3 is equivalent to 6 * 8.  A good optimizing compiler will replace multiplications with shifts when possible.Non-circular shiftingPlease note that these are not circular shifts.  Shifting this value to the left by one position (3,758,096,384 << 1):11100000 00000000 00000000 00000000results in 3,221,225,472:11000000 00000000 00000000 00000000The digit that gets shifted ""off the end"" is lost.  It does not wrap around.Logical right shift (>>>)A logical right shift is the converse to the left shift.  Rather than moving bits to the left, they simply move to the right.  For example, shifting the number 12:00000000 00000000 00000000 00001100to the right by one position (12 >>> 1) will get back our original 6:00000000 00000000 00000000 00000110So we see that shifting to the right is equivalent to division by powers of 2.Lost bits are goneHowever, a shift cannot reclaim ""lost"" bits.  For example, if we shift this pattern:00111000 00000000 00000000 00000110to the left 4 positions (939,524,102 << 4), we get 2,147,483,744:10000000 00000000 00000000 01100000and then shifting back ((939,524,102 << 4) >>> 4) we get 134,217,734:00001000 00000000 00000000 00000110We cannot get back our original value once we have lost bits.Arithmetic right shift (>>)The arithmetic right shift is exactly like the logical right shift, except instead of padding with zero, it pads with the most significant bit.  This is because the most significant bit is the sign bit, or the bit that distinguishes positive and negative numbers.  By padding with the most significant bit, the arithmetic right shift is sign-preserving.For example, if we interpret this bit pattern as a negative number:10000000 00000000 00000000 01100000we have the number -2,147,483,552.  Shifting this to the right 4 positions with the arithmetic shift (-2,147,483,552 >> 4) would give us:11111000 00000000 00000000 00000110or the number -134,217,722.So we see that we have preserved the sign of our negative numbers by using the arithmetic right shift, rather than the logical right shift.  And once again, we see that we are performing division by powers of 2."
"data_i","edited Jan 27 '21 at 11:20","
        How do I create a file and write to it?
    ","What's the simplest way to create and write to a (text) file in Java?","Note that each of the code samples below may throw IOException. Try/catch/finally blocks have been omitted for brevity. See this tutorial for information about exception handling.Note that each of the code samples below will overwrite the file if it already existsCreating a text file:PrintWriter writer = new PrintWriter(""the-file-name.txt"", ""UTF-8"");writer.println(""The first line"");writer.println(""The second line"");writer.close();Creating a binary file:byte data[] = ...FileOutputStream out = new FileOutputStream(""the-file-name"");out.write(data);out.close();Java 7+ users can use the Files class to write to files:Creating a text file:List<String> lines = Arrays.asList(""The first line"", ""The second line"");Path file = Paths.get(""the-file-name.txt"");Files.write(file, lines, StandardCharsets.UTF_8);//Files.write(file, lines, StandardCharsets.UTF_8, StandardOpenOption.APPEND);Creating a binary file:byte data[] = ...Path file = Paths.get(""the-file-name"");Files.write(file, data);//Files.write(file, data, StandardOpenOption.APPEND);"
"data_i","edited Apr 09 '22 at 07:44","
        What does __all__ mean in Python?
    ","I see __all__ in __init__.py files. What does it do?","Linked to, but not explicitly mentioned here, is exactly when __all__ is used. It is a list of strings defining what symbols in a module will be exported when from <module> import * is used on the module.For example, the following code in a foo.py explicitly exports the symbols bar and baz:__all__ = ['bar', 'baz']waz = 5bar = 10def baz(): return 'baz'These symbols can then be imported like so:from foo import *print(bar)print(baz)# The following will trigger an exception, as ""waz"" is not exported by the moduleprint(waz)If the __all__ above is commented out, this code will then execute to completion, as the default behaviour of import * is to import all symbols that do not begin with an underscore, from the given namespace.Reference: https://docs.python.org/tutorial/modules.html#importing-from-a-packageNOTE: __all__ affects the from <module> import * behavior only. Members that are not mentioned in __all__ are still accessible from outside the module and can be imported with from <module> import <member>."
"data_i","edited Oct 08 '18 at 10:10","
        JavaScript set object key by variable
    ","I am building some objects in JavaScript and pushing those objects into an array, I am storing the key I want to use in a variable then creating my objects like so:var key = ""happyCount"";myArray.push( { key : someValueArray } );but when I try to examine my array of objects for every object the key is ""key"" instead of the value of the variable key. Is there any way to set the value of the key from a variable? Fiddle for better explanation:http://jsfiddle.net/Fr6eY/3/","You need to make the object first, then use [] to set it.var key = ""happyCount"";var obj = {};obj[key] = someValueArray;myArray.push(obj);UPDATE 2021:Computed property names feature was introduced in ECMAScript 2015 (ES6) that allows you to dynamically compute the names of the object properties in JavaScript object literal notation.const yourKeyVariable = ""happyCount"";const someValueArray= [...];const obj = {    [yourKeyVariable]: someValueArray,}"
"data_i","edited Jun 23 '18 at 16:04","
        How do I vertically align text in a div?
    ","I am trying to find the most effective way to align text with a div. I have tried a few things and none seem to work..testimonialText {  position: absolute;  left: 15px;  top: 15px;  width: 150px;  height: 309px;  vertical-align: middle;  text-align: center;  font-family: Georgia, ""Times New Roman"", Times, serif;  font-style: italic;  padding: 1em 0 1em 0;}<div class=""testimonialText"">  Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor  in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</div>","The correct way to do this in modern browsers is to use Flexbox.See this answer for details.See below for some older ways that work in older browsers.Vertical Centering in CSShttp://www.jakpsatweb.cz/css/css-vertical-center-solution.htmlArticle summary:For a CSS 2 browser, one can use display:table/display:table-cell to center content.A sample is also available at JSFiddle:div { border:1px solid green;}<div style=""display: table; height: 400px; overflow: hidden;"">  <div style=""display: table-cell; vertical-align: middle;"">    <div>      everything is vertically centered in modern IE8+ and others.    </div>  </div></div>It is possible to merge hacks for old browsers (Internet Explorer 6/7) into styles with using # to hide styles from newer browsers:div { border:1px solid green;}<div style=""display: table; height: 400px; #position: relative; overflow: hidden;"">  <div style=    ""#position: absolute; #top: 50%;display: table-cell; vertical-align: middle;"">    <div style="" #position: relative; #top: -50%"">      everything is vertically centered    </div>  </div></div>"
"data_i","edited Jun 29 '16 at 04:24","
        You have not concluded your merge (MERGE_HEAD exists)
    ","I made a branch called 'f' and did a checkout to master. When I tried the git pull command I got this message:You have not concluded your merge (MERGE_HEAD exists).Please, commit your changes before you can merge.When I try the git status, it gave me the following:On branch master# Your branch and 'origin/master' have diverged,# and have 1 and 13 different commit(s) each, respectively.## Changes to be committed:##   modified:   app/assets/images/backward.png#   modified:   app/assets/images/forward.png#   new file:   app/assets/images/index_background.jpg#   new file:   app/assets/images/loading.gif#   modified:   app/assets/images/pause.png#   modified:   app/assets/images/play.png#   new file:   app/assets/javascripts/jquery-ui-bootstrap.js#   new file:   app/assets/stylesheets/jquery-ui-bootstrap.css#   modified:   app/controllers/friends_controller.rb#   modified:   app/controllers/plays_controller.rb#   modified:   app/mailers/invite_friends_mailer.rb#   modified:   app/mailers/send_plays_mailer.rb#   modified:   app/mailers/shot_chart_mailer.rb#   modified:   app/views/friends/show_plays.html.erb#   modified:   app/views/layouts/application.html.erb#   modified:   app/views/plays/_inbox_table.html.erb#   modified:   app/views/plays/show.html.erb#   modified:   app/views/welcome/contact_form.html.erb#   modified:   app/views/welcome/index.html.erb#   modified:   log/development.log#   modified:   log/restclient.log#   new file:   tmp/cache/assets/C1A/C00/sprockets%2Fb7901e0813446f810e560158a1a97066#   modified:   tmp/cache/assets/C64/930/sprockets%2F65aa1510292214f4fd1342280d521e4c#   new file:   tmp/cache/assets/C73/C40/sprockets%2F96912377b93498914dd04bc69fa98585#   new file:   tmp/cache/assets/CA9/090/sprockets%2Fa71992733a432421e67e03ff1bd441d8#   new file:   tmp/cache/assets/CCD/7E0/sprockets%2F47125c2ebd0e8b29b6511b7b961152a1#   modified:   tmp/cache/assets/CD5/DD0/sprockets%2F59d317902de6e0f68689899259caff26#   modified:   tmp/cache/assets/CE3/080/sprockets%2F5c3b516e854760f14eda2395c4ff2581#   new file:   tmp/cache/assets/CED/B20/sprockets%2F423772fde44ab6f6f861639ee71444c4#   new file:   tmp/cache/assets/D0C/E10/sprockets%2F8d1f4b30c6be13017565fe1b697156ce#   new file:   tmp/cache/assets/D12/290/sprockets%2F93ae21f3cdd5e24444ae4651913fd875#   new file:   tmp/cache/assets/D13/FC0/sprockets%2F57aad34b9d3c9e225205237dac9b1999#   new file:   tmp/cache/assets/D1D/DE0/sprockets%2F5840ff4283f6545f472be8e10ce67bb8#   new file:   tmp/cache/assets/D23/BD0/sprockets%2F439d5dedcc8c54560881edb9f0456819#   new file:   tmp/cache/assets/D24/570/sprockets%2Fb449db428fc674796e18b7a419924afe#   new file:   tmp/cache/assets/D28/480/sprockets%2F9aeec798a04544e478806ffe57e66a51#   new file:   tmp/cache/assets/D3A/ED0/sprockets%2Fcd959cbf710b366c145747eb3c062bb4#   new file:   tmp/cache/assets/D3C/060/sprockets%2F363ac7c9208d3bb5d7047f11c159d7ce#   new file:   tmp/cache/assets/D48/D00/sprockets%2Fe23c97b8996e7b5567a3080c285aaccb#   new file:   tmp/cache/assets/D6A/900/sprockets%2Fa5cece9476b21aa4d5f46911ca96c450#   new file:   tmp/cache/assets/D6C/510/sprockets%2Fb086a020de3c258cb1c67dfc9c67d546#   new file:   tmp/cache/assets/D70/F30/sprockets%2Facf9a6348722adf1ee7abbb695603078#   new file:   tmp/cache/assets/DA3/4A0/sprockets%2F69c26d0a9ca8ce383e20897cefe05aa4#   new file:   tmp/cache/assets/DA7/2F0/sprockets%2F61da396fb86c5ecd844a2d83ac759b4b#   new file:   tmp/cache/assets/DB9/C80/sprockets%2F876fbfb9685b2b8ea476fa3c67ae498b#   new file:   tmp/cache/assets/DBD/7A0/sprockets%2F3640ea84a1dfaf6f91a01d1d6fbe223d#   new file:   tmp/cache/assets/DC1/8D0/sprockets%2Fe5ee1f1cfba2144ec00b1dcd6773e691#   new file:   tmp/cache/assets/DCC/E60/sprockets%2Fd6a95f601456c93ff9a1bb70dea3dfc0#   new file:   tmp/cache/assets/DF1/130/sprockets%2Fcda4825bb42c91e2d1f1ea7b2b958bda#   new file:   tmp/cache/assets/E23/DE0/sprockets%2Fb1acc25c28cd1fabafbec99d169163d3#   new file:   tmp/cache/assets/E23/FD0/sprockets%2Fea3dbcd1f341008ef8be67b1ccc5a9c5#   modified:   tmp/cache/assets/E4E/AD0/sprockets%2Fb930f45cfe7c6a8d0efcada3013cc4bc#   new file:   tmp/cache/assets/E63/7D0/sprockets%2F77de495a665c3ebcb47befecd07baae6#   modified:   tmp/pids/server.pid## Untracked files:#   (use ""git add <file>..."" to include in what will be committed)##   Coachbase/#   log/development.log.orig#   log/restclient.log.origWhat should I do?","The problem is your previous pull failed to merge automatically and went to conflict state. And the conflict wasn't resolved properly before the next pull.Undo the merge and pull again.To undo a merge:git merge --abort  [Since git version 1.7.4]git reset --merge  [prior git versions]Resolve the conflict.Don't forget to add and commit the merge.git pull now should work fine."
"data_i","edited Apr 02 '18 at 18:51","
        How to directly initialize a HashMap (in a literal way)?
    ","Is there some way of initializing a Java HashMap like this?:Map<String,String> test =     new HashMap<String, String>{""test"":""test"",""test"":""test""};What would be the correct syntax? I have not found anything regarding this. Is this possible? I am looking for the shortest/fastest way to put some ""final/static"" values in a map that never change and are known in advance when creating the Map.","All VersionsIn case you happen to need just a single entry: There is Collections.singletonMap(""key"", ""value"").For Java Version 9 or higher:Yes, this is possible now. In Java 9 a couple of factory methods have been added that simplify the creation of maps :// this works for up to 10 elements:Map<String, String> test1 = Map.of(    ""a"", ""b"",    ""c"", ""d"");// this works for any number of elements:import static java.util.Map.entry;    Map<String, String> test2 = Map.ofEntries(    entry(""a"", ""b""),    entry(""c"", ""d""));In the example above both test and test2 will be the same, just with different ways of expressing the Map. The Map.of method is defined for up to ten elements in the map, while the Map.ofEntries method will have no such limit.Note that in this case the resulting map will be an immutable map. If you want the map to be mutable, you could copy it again, e.g. using mutableMap = new HashMap<>(Map.of(""a"", ""b""));(See also JEP 269 and the Javadoc)For up to Java Version 8:No, you will have to add all the elements manually. You can use an initializer in an anonymous subclass to make the syntax a little bit shorter:Map<String, String> myMap = new HashMap<String, String>() {{    put(""a"", ""b"");    put(""c"", ""d"");}};However, the anonymous subclass might introduce unwanted behavior in some cases. This includes for example:It generates an additional class which increases memory consumption, disk space consumption and startup-timeIn case of a non-static method: It holds a reference to the object the creating method was called upon. That means the object of the outer class cannot be garbage collected while the created map object is still referenced, thus blocking additional memoryUsing a function for initialization will also enable you to generate a map in an initializer, but avoids nasty side-effects:Map<String, String> myMap = createMap();private static Map<String, String> createMap() {    Map<String,String> myMap = new HashMap<String,String>();    myMap.put(""a"", ""b"");    myMap.put(""c"", ""d"");    return myMap;}"
"data_i","edited Jan 21 '20 at 16:50","
        How to add local jar files to a Maven project?
    ","How do I add local jar files (not yet part of the Maven repository) directly in my project's library sources?","You can add local dependencies directly (as mentioned in build maven project with propriatery libraries included) like this:<dependency>    <groupId>com.sample</groupId>    <artifactId>sample</artifactId>    <version>1.0</version>    <scope>system</scope>    <systemPath>${project.basedir}/src/main/resources/Name_Your_JAR.jar</systemPath></dependency>UpdateIn new releases this feature is marked as deprecated but still working and not removed yet ( You just see warning in the log during maven start). An issue is raised at maven group about this https://issues.apache.org/jira/browse/MNG-6523 ( You can participate and describe why this feature is helpful in some cases). I hope this feature remains there! If you are asking me, as long as the feature is not removed, I use this to make dependency to only one naughty jar file in my project which is not fit in repository. If this feature is removed, well, there are lots of good answers here which I can chose from later!  "
"data_i","edited Jun 06 '22 at 23:56","
        if/else in a list comprehension
    ","How do I replace all the Nones with empty strings, and then call some function f?[f(x) for x in xs if x is not None else '']","You can totally do that. It's just an ordering issue:[f(x) if x is not None else '' for x in xs]In general,[f(x) if condition else g(x) for x in sequence]And, for list comprehensions with if conditions only,[f(x) for x in sequence if condition]Note that this actually uses a different language construct, a conditional expression, which itself is not part of the comprehension syntax, while the if after the for…in is part of list comprehensions and used to filter elements from the source iterable.Conditional expressions can be used in all kinds of situations where you want to choose between two expression values based on some condition. This does the same as the ternary operator ?: that exists in other languages. For example:value = 123print(value, 'is', 'even' if value % 2 == 0 else 'odd')"
"data_i","edited Dec 11 '15 at 14:17","
        When are you supposed to use escape instead of encodeURI / encodeURIComponent?
    ","When encoding a query string to be sent to a web server - when do you use escape() and when do you use encodeURI() or encodeURIComponent():Use escape:escape(""% +&="");ORuse encodeURI() / encodeURIComponent()encodeURI(""http://www.google.com?var1=value1&var2=value2"");encodeURIComponent(""var1=value1&var2=value2"");","escape()Don't use it!escape() is defined in section B.2.1.2 escape and the introduction text of Annex B says:... All of the language features and behaviours specified in this annex have one or more undesirable characteristics and in the absence of legacy usage would be removed from this specification. ...... Programmers should not use or assume the existence of these features and behaviours when writing new ECMAScript code....Behaviour:https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/escapeSpecial characters are encoded with the exception of: @*_+-./The hexadecimal form for characters, whose code unit value is 0xFF or less, is a two-digit escape sequence: %xx.For characters with a greater code unit, the four-digit format %uxxxx is used. This is not allowed within a query string (as defined in RFC3986):query       = *( pchar / ""/"" / ""?"" )pchar         = unreserved / pct-encoded / sub-delims / "":"" / ""@""unreserved    = ALPHA / DIGIT / ""-"" / ""."" / ""_"" / ""~""pct-encoded   = ""%"" HEXDIG HEXDIGsub-delims    = ""!"" / ""$"" / ""&"" / ""'"" / ""("" / "")""              / ""*"" / ""+"" / "","" / "";"" / ""=""A percent sign is only allowed if it is directly followed by two hexdigits, percent followed by u is not allowed.encodeURI()Use encodeURI when you want a working URL. Make this call:encodeURI(""http://www.example.org/a file with spaces.html"")to get:http://www.example.org/a%20file%20with%20spaces.htmlDon't call encodeURIComponent since it would destroy the URL and returnhttp%3A%2F%2Fwww.example.org%2Fa%20file%20with%20spaces.htmlNote that encodeURI, like encodeURIComponent, does not escape the ' character.encodeURIComponent()Use encodeURIComponent when you want to encode the value of a URL parameter.var p1 = encodeURIComponent(""http://example.org/?a=12&b=55"")Then you may create the URL you need:var url = ""http://example.net/?param1="" + p1 + ""&param2=99"";And you will get this complete URL:http://example.net/?param1=http%3A%2F%2Fexample.org%2F%Ffa%3D12%26b%3D55&param2=99Note that encodeURIComponent does not escape the ' character. A common bug is to use it to create html attributes such as href='MyUrl', which could suffer an injection bug. If you are constructing html from strings, either use "" instead of ' for attribute quotes, or add an extra layer of encoding (' can be encoded as %27).For more information on this type of encoding you can check: http://en.wikipedia.org/wiki/Percent-encoding"
"data_i","edited Apr 11 '22 at 21:54","
        Where can I find documentation on formatting a date in JavaScript?
    ","I noticed that JavaScript's new Date() function is very smart in accepting dates in several formats.Xmas95 = new Date(""25 Dec, 1995 23:15:00"")Xmas95 = new Date(""2009 06 12,12:52:39"")Xmas95 = new Date(""20 09 2006,12:52:39"")I could not find documentation anywhere showing all the valid string formats while calling new Date() function.This is for converting a string to a date. If we look at the opposite side, that is, converting a date object to a string, until now I was under the impression that JavaScript doesn't have a built-in API to format a date object into a string.Editor's note: The following approach is the asker's attempt that worked on a particular browser but does not work in general; see the answers on this page to see some actual solutions.Today, I played with the toString() method on the date object and surprisingly it serves the purpose of formatting date to strings.var d1 = new Date();d1.toString('yyyy-MM-dd');       //Returns ""2009-06-29"" in Internet Explorer, but not Firefox or Chromed1.toString('dddd, MMMM ,yyyy')  //Returns ""Monday, June 29,2009"" in Internet Explorer, but not Firefox or ChromeAlso here I couldn't find any documentation on all the ways we can format the date object into a string.Where is the documentation which lists the format specifiers supported by the Date() object?","I love 10 ways to format time and date using JavaScript and Working with Dates.Basically, you have three methods and you have to combine the strings for yourself:getDate() // Returns the dategetMonth() // Returns the monthgetFullYear() // Returns the yearExample:var d = new Date();var curr_date = d.getDate();var curr_month = d.getMonth() + 1; //Months are zero basedvar curr_year = d.getFullYear();console.log(curr_date + ""-"" + curr_month + ""-"" + curr_year);"
"data_i","edited Feb 11 '21 at 17:35","
        Passing data between view controllers
    ","I'm new to iOS and Objective-C and the whole MVC paradigm and I'm stuck with the following:I have a view that acts as a data entry form and I want to give the user the option to select multiple products. The products are listed on another view with a UITableViewController and I have enabled multiple selections.How do I transfer the data from one view to another? I will be holding the selections on the UITableView in an array, but how do I then pass that back to the previous data entry form view so it can be saved along with the other data to Core Data on submission of the form?I have surfed around and seen some people declare an array in the app delegate. I read something about singletons, but I don't understand what these are and I read something about creating a data model.What would be the correct way of performing this and how would I go about it?","This question seems to be very popular here on Stack Overflow so I thought I would try and give a better answer to help out people starting in the world of iOS like me.Passing Data ForwardPassing data forward to a view controller from another view controller. You would use this method if you wanted to pass an object/value from one view controller to another view controller that you may be pushing on to a navigation stack.For this example, we will have ViewControllerA and ViewControllerBTo pass a BOOL value from ViewControllerA to ViewControllerB we would do the following.in ViewControllerB.h create a property for the BOOL @property (nonatomic, assign) BOOL isSomethingEnabled;in ViewControllerA you need to tell it about ViewControllerB so use an #import ""ViewControllerB.h""Then where you want to load the view, for example, didSelectRowAtIndex or some IBAction, you need to set the property in ViewControllerB before you push it onto the navigation stack.    ViewControllerB *viewControllerB = [[ViewControllerB alloc] initWithNib:@""ViewControllerB"" bundle:nil];    viewControllerB.isSomethingEnabled = YES;    [self pushViewController:viewControllerB animated:YES];This will set isSomethingEnabled in ViewControllerB to BOOL value YES.Passing Data Forward using SeguesIf you are using Storyboards you are most likely using segues and will need this procedure to pass data forward. This is similar to the above but instead of passing the data before you push the view controller, you use a method called-(void)prepareForSegue:(UIStoryboardSegue *)segue sender:(id)senderSo to pass a BOOL from ViewControllerA to ViewControllerB we would do the following:in ViewControllerB.h create a property for the BOOL @property (nonatomic, assign) BOOL isSomethingEnabled;in ViewControllerA you need to tell it about ViewControllerB, so use an #import ""ViewControllerB.h""Create the segue from ViewControllerA to ViewControllerB on the storyboard and give it an identifier. In this example we'll call it ""showDetailSegue""Next, we need to add the method to ViewControllerA that is called when any segue is performed. Because of this we need to detect which segue was called and then do something. In our example, we will check for ""showDetailSegue"" and if that's performed, we will pass our BOOL value to ViewControllerB -(void)prepareForSegue:(UIStoryboardSegue *)segue sender:(id)sender{     if([segue.identifier isEqualToString:@""showDetailSegue""]){         ViewControllerB *controller = (ViewControllerB *)segue.destinationViewController;         controller.isSomethingEnabled = YES;     } }If you have your views embedded in a navigation controller, you need to change the method above slightly to the following    -(void)prepareForSegue:(UIStoryboardSegue *)segue sender:(id)sender{        if([segue.identifier isEqualToString:@""showDetailSegue""]){            UINavigationController *navController = (UINavigationController *)segue.destinationViewController;            ViewControllerB *controller = (ViewControllerB *)navController.topViewController;            controller.isSomethingEnabled = YES;        }    }This will set isSomethingEnabled in ViewControllerB to BOOL value YES.Passing Data BackTo pass data back from ViewControllerB to ViewControllerA you need to use Protocols and Delegates or Blocks, the latter can be used as a loosely coupled mechanism for callbacks.To do this we will make ViewControllerA a delegate of ViewControllerB. This allows ViewControllerB to send a message back to ViewControllerA enabling us to send data back.For ViewControllerA to be a delegate of ViewControllerB it must conform to ViewControllerB's protocol which we have to specify. This tells ViewControllerA which methods it must implement.In ViewControllerB.h, below the #import, but above @interface you specify the protocol. @class ViewControllerB; @protocol ViewControllerBDelegate <NSObject> - (void)addItemViewController:(ViewControllerB *)controller didFinishEnteringItem:(NSString *)item; @endNext still in the ViewControllerB.h, you need to set up a delegate property and synthesize in ViewControllerB.m @property (nonatomic, weak) id <ViewControllerBDelegate> delegate;In ViewControllerB we call a message on the delegate when we pop the view controller. NSString *itemToPassBack = @""Pass this value back to ViewControllerA""; [self.delegate addItemViewController:self didFinishEnteringItem:itemToPassBack];That's it for ViewControllerB. Now in ViewControllerA.h, tell ViewControllerA to import ViewControllerB and conform to its protocol. #import ""ViewControllerB.h"" @interface ViewControllerA : UIViewController <ViewControllerBDelegate>In ViewControllerA.m implement the following method from our protocol - (void)addItemViewController:(ViewControllerB *)controller didFinishEnteringItem:(NSString *)item {     NSLog(@""This was returned from ViewControllerB %@"", item); }Before pushing viewControllerB to navigation stack we need to tell  ViewControllerB that ViewControllerA is its delegate, otherwise we will get an error. ViewControllerB *viewControllerB = [[ViewControllerB alloc] initWithNib:@""ViewControllerB"" bundle:nil]; viewControllerB.delegate = self [[self navigationController] pushViewController:viewControllerB animated:YES];ReferencesUsing Delegation to Communicate With Other View Controllers in the View Controller Programming GuideDelegate PatternNSNotification centerIt's another way to pass data.// Add an observer in controller(s) where you want to receive data[[NSNotificationCenter defaultCenter] addObserver:self selector:@selector(handleDeepLinking:) name:@""handleDeepLinking"" object:nil];-(void) handleDeepLinking:(NSNotification *) notification {    id someObject = notification.object // Some custom object that was passed with notification fire.}// Post notificationid someObject;[NSNotificationCenter.defaultCenter postNotificationName:@""handleDeepLinking"" object:someObject];Passing Data back from one class to another (A class can be any controller, Network/session manager, UIView subclass or any other class)Blocks are anonymous functions.This example passes data from Controller B to Controller ADefine a block@property void(^selectedVoucherBlock)(NSString *); // in ContollerA.hAdd block handler (listener)Where you need a value (for example, you need your API response in ControllerA or you need ContorllerB data on A)// In ContollerA.m- (void)viewDidLoad {    [super viewDidLoad];    __unsafe_unretained typeof(self) weakSelf = self;    self.selectedVoucherBlock = ^(NSString *voucher) {        weakSelf->someLabel.text = voucher;    };}Go to Controller BUIStoryboard *storyboard = [UIStoryboard storyboardWithName:@""Main"" bundle:nil];ControllerB *vc = [storyboard instantiateViewControllerWithIdentifier:@""ControllerB""];vc.sourceVC = self;    [self.navigationController pushViewController:vc animated:NO];Fire block-(void)tableView:(UITableView *)tableView didSelectRowAtIndexPath:(NSIndexPath *)indexPath {    NSString *voucher = vouchersArray[indexPath.row];    if (sourceVC.selectVoucherBlock) {        sourceVC.selectVoucherBlock(voucher);    }    [self.navigationController popToViewController:sourceVC animated:YES];}Another Working Example for Blocks"
"data_i","edited Aug 11 '19 at 22:25","
        How do I show my global Git configuration?
    ","I'd like to show all configured Git sections.I only found git config --get core.editor, and I'd like to output everything that's configured globally, not only the configured default editor.","You can use:git config --listor look at your ~/.gitconfig file. The local configuration will be in your repository's .git/config file.Use:git config --list --show-originto see where that setting is defined (global, user, repo, etc...)"
"data_i","edited Apr 09 '19 at 03:58","
        Why don't self-closing script elements work?
    ","What is the reason browsers do not correctly recognize:<script src=""foobar.js"" /> <!-- self-closing script element -->Only this is recognized:<script src=""foobar.js""></script>Does this break the concept of XHTML support?Note: This statement is correct at least for all IE (6-8 beta 2).","The non-normative appendix ‘HTML Compatibility Guidelines’ of the XHTML 1 specification says:С.3. Element Minimization and Empty Element ContentGiven an empty instance of an element whose content model is not EMPTY (for example, an empty title or paragraph) do not use the minimized form (e.g. use <p> </p> and not <p />).XHTML DTD specifies script elements as:<!-- script statements, which may include CDATA sections --><!ELEMENT script (#PCDATA)>"
"data_i","edited Dec 20 '14 at 15:41","
        How can I undo git reset --hard HEAD~1?
    ","Is it possible to undo the changes caused by the following command? If so, how?git reset --hard HEAD~1","Pat Notz is correct.  You can get the commit back so long as it's been within a few days.  git only garbage collects after about a month or so unless you explicitly tell it to remove newer blobs.$ git initInitialized empty Git repository in .git/$ echo ""testing reset"" > file1$ git add file1$ git commit -m 'added file1'Created initial commit 1a75c1d: added file1 1 files changed, 1 insertions(+), 0 deletions(-) create mode 100644 file1$ echo ""added new file"" > file2$ git add file2$ git commit -m 'added file2'Created commit f6e5064: added file2 1 files changed, 1 insertions(+), 0 deletions(-) create mode 100644 file2$ git reset --hard HEAD^HEAD is now at 1a75c1d... added file1$ cat file2cat: file2: No such file or directory$ git reflog1a75c1d... HEAD@{0}: reset --hard HEAD^: updating HEADf6e5064... HEAD@{1}: commit: added file2$ git reset --hard f6e5064HEAD is now at f6e5064... added file2$ cat file2added new fileYou can see in the example that the file2 was removed as a result of the hard reset, but was put back in place when I reset via the reflog."
"data_i","edited Aug 02 '16 at 10:57","
        Memcached vs. Redis?
    ","We're using a Ruby web-app with Redis server for caching. Is there a point to test Memcached instead?What will give us better performance? Any pros or cons between Redis and Memcached?Points to consider:Read/write speed.Memory usage.Disk I/O dumping.Scaling.","Summary (TL;DR)Updated June 3rd, 2017Redis is more powerful, more popular, and better supported than memcached. Memcached can only do a small fraction of the things Redis can do. Redis is better even where their features overlap.For anything new, use Redis.Memcached vs Redis: Direct ComparisonBoth tools are powerful, fast, in-memory data stores that are useful as a cache. Both can help speed up your application by caching database results, HTML fragments, or anything else that might be expensive to generate.Points to ConsiderWhen used for the same thing, here is how they compare using the original question's ""Points to Consider"":Read/write speed: Both are extremely fast. Benchmarks vary by workload, versions, and many other factors but generally show redis to be as fast or almost as fast as memcached. I recommend redis, but not because memcached is slow. It's not.Memory usage: Redis is better.memcached: You specify the cache size and as you insert items the daemon quickly grows to a little more than this size. There is never really a way to reclaim any of that space, short of restarting memcached. All your keys could be expired, you could flush the database, and it would still use the full chunk of RAM you configured it with.redis: Setting a max size is up to you. Redis will never use more than it has to and will give you back memory it is no longer using.I stored 100,000 ~2KB strings (~200MB) of random sentences into both. Memcached RAM usage grew to ~225MB. Redis RAM usage grew to ~228MB. After flushing both, redis dropped to ~29MB and memcached stayed at ~225MB. They are similarly efficient in how they store data, but only one is capable of reclaiming it.Disk I/O dumping: A clear win for redis since it does this by default and has very configurable persistence. Memcached has no mechanisms for dumping to disk without 3rd party tools.Scaling: Both give you tons of headroom before you need more than a single instance as a cache. Redis includes tools to help you go beyond that while memcached does not.memcachedMemcached is a simple volatile cache server. It allows you to store key/value pairs where the value is limited to being a string up to 1MB.It's good at this, but that's all it does. You can access those values by their key at extremely high speed, often saturating available network or even memory bandwidth.When you restart memcached your data is gone. This is fine for a cache. You shouldn't store anything important there.If you need high performance or high availability there are 3rd party tools, products, and services available.redisRedis can do the same jobs as memcached can, and can do them better.Redis can act as a cache as well. It can store key/value pairs too. In redis they can even be up to 512MB.You can turn off persistence and it will happily lose your data on restart too. If you want your cache to survive restarts it lets you do that as well. In fact, that's the default.It's super fast too, often limited by network or memory bandwidth.If one instance of redis/memcached isn't enough performance for your workload, redis is the clear choice. Redis includes cluster support and comes with high availability tools (redis-sentinel) right ""in the box"". Over the past few years redis has also emerged as the clear leader in 3rd party tooling. Companies like Redis Labs, Amazon, and others offer many useful redis tools and services. The ecosystem around redis is much larger. The number of large scale deployments is now likely greater than for memcached.The Redis SupersetRedis is more than a cache. It is an in-memory data structure server. Below you will find a quick overview of things Redis can do beyond being a simple key/value cache like memcached. Most of redis' features are things memcached cannot do.DocumentationRedis is better documented than memcached. While this can be subjective, it seems to be more and more true all the time.redis.io is a fantastic easily navigated resource. It lets you try redis in the browser and even gives you live interactive examples with each command in the docs.There are now 2x as many stackoverflow results for redis as memcached. 2x as many Google results. More readily accessible examples in more languages. More active development. More active client development. These measurements might not mean much individually, but in combination they paint a clear picture that support and documentation for redis is greater and much more up-to-date.PersistenceBy default redis persists your data to disk using a mechanism called snapshotting. If you have enough RAM available it's able to write all of your data to disk with almost no performance degradation. It's almost free!In snapshot mode there is a chance that a sudden crash could result in a small amount of lost data. If you absolutely need to make sure no data is ever lost, don't worry, redis has your back there too with AOF (Append Only File) mode. In this persistence mode data can be synced to disk as it is written. This can reduce maximum write throughput to however fast your disk can write, but should still be quite fast.There are many configuration options to fine tune persistence if you need, but the defaults are very sensible. These options make it easy to setup redis as a safe, redundant place to store data. It is a real database.Many Data TypesMemcached is limited to strings, but Redis is a data structure server that can serve up many different data types. It also provides the commands you need to make the most of those data types.Strings (commands)Simple text or binary values that can be up to 512MB in size. This is the only data type redis and memcached share, though memcached strings are limited to 1MB.Redis gives you more tools for leveraging this datatype by offering commands for bitwise operations, bit-level manipulation, floating point increment/decrement support, range queries, and multi-key operations. Memcached doesn't support any of that.Strings are useful for all sorts of use cases, which is why memcached is fairly useful with this data type alone.Hashes (commands)Hashes are sort of like a key value store within a key value store. They map between string fields and string values. Field->value maps using a hash are slightly more space efficient than key->value maps using regular strings.Hashes are useful as a namespace, or when you want to logically group many keys. With a hash you can grab all the members efficiently, expire all the members together, delete all the members together, etc. Great for any use case where you have several key/value pairs that need to grouped.One example use of a hash is for storing user profiles between applications. A redis hash stored with the user ID as the key will allow you to store as many bits of data about a user as needed while keeping them stored under a single key. The advantage of using a hash instead of serializing the profile into a string is that you can have different applications read/write different fields within the user profile without having to worry about one app overriding changes made by others (which can happen if you serialize stale data).Lists (commands)Redis lists are ordered collections of strings. They are optimized for inserting, reading, or removing values from the top or bottom (aka: left or right) of the list.Redis provides many commands for leveraging lists, including commands to push/pop items, push/pop between lists, truncate lists, perform range queries, etc.Lists make great durable, atomic, queues. These work great for job queues, logs, buffers, and many other use cases.Sets (commands)Sets are unordered collections of unique values. They are optimized to let you quickly check if a value is in the set, quickly add/remove values, and to measure overlap with other sets.These are great for things like access control lists, unique visitor trackers, and many other things. Most programming languages have something similar (usually called a Set). This is like that, only distributed.Redis provides several commands to manage sets. Obvious ones like adding, removing, and checking the set are present. So are less obvious commands like popping/reading a random item and commands for performing unions and intersections with other sets.Sorted Sets (commands)Sorted Sets are also collections of unique values. These ones, as the name implies, are ordered. They are ordered by a score, then lexicographically.This data type is optimized for quick lookups by score. Getting the highest, lowest, or any range of values in between is extremely fast.If you add users to a sorted set along with their high score, you have yourself a perfect leader-board. As new high scores come in, just add them to the set again with their high score and it will re-order your leader-board. Also great for keeping track of the last time users visited and who is active in your application.Storing values with the same score causes them to be ordered lexicographically (think alphabetically). This can be useful for things like auto-complete features.Many of the sorted set commands are similar to commands for sets, sometimes with an additional score parameter. Also included are commands for managing scores and querying by score.GeoRedis has several commands for storing, retrieving, and measuring geographic data. This includes radius queries and measuring distances between points.Technically geographic data in redis is stored within sorted sets, so this isn't a truly separate data type. It is more of an extension on top of sorted sets.Bitmap and HyperLogLogLike geo, these aren't completely separate data types. These are commands that allow you to treat string data as if it's either a bitmap or a hyperloglog.Bitmaps are what the bit-level operators I referenced under Strings are for. This data type was the basic building block for reddit's recent collaborative art project: r/Place.HyperLogLog allows you to use a constant extremely small amount of space to count almost unlimited unique values with shocking accuracy. Using only ~16KB you could efficiently count the number of unique visitors to your site, even if that number is in the millions.Transactions and AtomicityCommands in redis are atomic, meaning you can be sure that as soon as you write a value to redis that value is visible to all clients connected to redis. There is no wait for that value to propagate. Technically memcached is atomic as well, but with redis adding all this functionality beyond memcached it is worth noting and somewhat impressive that all these additional data types and features are also atomic.While not quite the same as transactions in relational databases, redis also has transactions that use ""optimistic locking"" (WATCH/MULTI/EXEC).PipeliningRedis provides a feature called 'pipelining'. If you have many redis commands you want to execute you can use pipelining to send them to redis all-at-once instead of one-at-a-time.Normally when you execute a command to either redis or memcached, each command is a separate request/response cycle. With pipelining, redis can buffer several commands and execute them all at once, responding with all of the responses to all of your commands in a single reply.This can allow you to achieve even greater throughput on bulk importing or other actions that involve lots of commands.Pub/SubRedis has commands dedicated to pub/sub functionality, allowing redis to act as a high speed message broadcaster. This allows a single client to publish messages to many other clients connected to a channel.Redis does pub/sub as well as almost any tool. Dedicated message brokers like RabbitMQ may have advantages in certain areas, but the fact that the same server can also give you persistent durable queues and other data structures your pub/sub workloads likely need, Redis will often prove to be the best and most simple tool for the job.Lua ScriptingYou can kind of think of lua scripts like redis's own SQL or stored procedures. It's both more and less than that, but the analogy mostly works.Maybe you have complex calculations you want redis to perform. Maybe you can't afford to have your transactions roll back and need guarantees every step of a complex process will happen atomically. These problems and many more can be solved with lua scripting.The entire script is executed atomically, so if you can fit your logic into a lua script you can often avoid messing with optimistic locking transactions.ScalingAs mentioned above, redis includes built in support for clustering and is bundled with its own high availability tool called redis-sentinel.ConclusionWithout hesitation I would recommend redis over memcached for any new projects, or existing projects that don't already use memcached.The above may sound like I don't like memcached. On the contrary: it is a powerful, simple, stable, mature, and hardened tool. There are even some use cases where it's a little faster than redis. I love memcached. I just don't think it makes much sense for future development.Redis does everything memcached does, often better. Any performance advantage for memcached is minor and workload specific. There are also workloads for which redis will be faster, and many more workloads that redis can do which memcached simply can't. The tiny performance differences seem minor in the face of the giant gulf in functionality and the fact that both tools are so fast and efficient they may very well be the last piece of your infrastructure you'll ever have to worry about scaling.There is only one scenario where memcached makes more sense: where memcached is already in use as a cache. If you are already caching with memcached then keep using it, if it meets your needs. It is likely not worth the effort to move to redis and if you are going to use redis just for caching it may not offer enough benefit to be worth your time. If memcached isn't meeting your needs, then you should probably move to redis. This is true whether you need to scale beyond memcached or you need additional functionality."
"data_i","edited May 13 '22 at 15:41","
        Creating a singleton in Python
    ","This question is not for the discussion of whether or not the singleton design pattern is desirable, is an anti-pattern, or for any religious wars, but to discuss how this pattern is best implemented in Python in such a way that is most pythonic. In this instance I define 'most pythonic' to mean that it follows the 'principle of least astonishment'.I have multiple classes which would become singletons (my use-case is for a logger, but this is not important). I do not wish to clutter several classes with added gumph when I can simply inherit or decorate.Best methods:Method 1: A decoratordef singleton(class_):    instances = {}    def getinstance(*args, **kwargs):        if class_ not in instances:            instances[class_] = class_(*args, **kwargs)        return instances[class_]    return getinstance@singletonclass MyClass(BaseClass):    passProsDecorators are additive in a way that is often more intuitive than multiple inheritance.ConsWhile objects created using MyClass() would be true singleton objects, MyClass itself is a function, not a class, so you cannot call class methods from it. Also forx = MyClass();y = MyClass();t = type(n)();then x == y but x != t && y != tMethod 2: A base classclass Singleton(object):    _instance = None    def __new__(class_, *args, **kwargs):        if not isinstance(class_._instance, class_):            class_._instance = object.__new__(class_, *args, **kwargs)        return class_._instanceclass MyClass(Singleton, BaseClass):    passProsIt's a true classConsMultiple inheritance - eugh! __new__ could be overwritten during inheritance from a second base class? One has to think more than is necessary.Method 3: A metaclassclass Singleton(type):    _instances = {}    def __call__(cls, *args, **kwargs):        if cls not in cls._instances:            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)        return cls._instances[cls]#Python2class MyClass(BaseClass):    __metaclass__ = Singleton#Python3class MyClass(BaseClass, metaclass=Singleton):    passProsIt's a true classAuto-magically covers inheritanceUses __metaclass__ for its proper purpose (and made me aware of it)ConsAre there any?Method 4: decorator returning a class with the same namedef singleton(class_):    class class_w(class_):        _instance = None        def __new__(class_, *args, **kwargs):            if class_w._instance is None:                class_w._instance = super(class_w,                                    class_).__new__(class_,                                                    *args,                                                    **kwargs)                class_w._instance._sealed = False            return class_w._instance        def __init__(self, *args, **kwargs):            if self._sealed:                return            super(class_w, self).__init__(*args, **kwargs)            self._sealed = True    class_w.__name__ = class_.__name__    return class_w@singletonclass MyClass(BaseClass):    passProsIt's a true classAuto-magically covers inheritanceConsIs there not an overhead for creating each new class? Here we are creating two classes for each class we wish to make a singleton. While this is fine in my case, I worry that this might not scale. Of course there is a matter of debate as to whether it aught to be too easy to scale this pattern...What is the point of the _sealed attributeCan't call methods of the same name on base classes using super() because they will recurse. This means you can't customize __new__ and can't subclass a class that needs you to call up to __init__.Method 5: a modulea module file singleton.pyProsSimple is better than complexConsNot lazily instantiated","Use a MetaclassI would recommend Method #2, but you're better off using a metaclass than a base class. Here is a sample implementation:class Singleton(type):    _instances = {}    def __call__(cls, *args, **kwargs):        if cls not in cls._instances:            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)        return cls._instances[cls]        class Logger(object):    __metaclass__ = SingletonOr in Python3class Logger(metaclass=Singleton):    passIf you want to run __init__ every time the class is called, add        else:            cls._instances[cls].__init__(*args, **kwargs)to the if statement in Singleton.__call__.A few words about metaclasses. A metaclass is the class of a class; that is, a class is an instance of its metaclass. You find the metaclass of an object in Python with type(obj). Normal new-style classes are of type type. Logger in the code above will be of type class 'your_module.Singleton', just as the (only) instance of Logger will be of type class 'your_module.Logger'. When you call logger with Logger(), Python first asks the metaclass of Logger, Singleton, what to do, allowing instance creation to be pre-empted. This process is the same as Python asking a class what to do by calling __getattr__ when you reference one of it's attributes by doing myclass.attribute.A metaclass essentially decides what the definition of a class means and how to implement that definition. See for example http://code.activestate.com/recipes/498149/, which essentially recreates C-style structs in Python using metaclasses. The thread What are some (concrete) use-cases for metaclasses? also provides some examples, they generally seem to be related to declarative programming, especially as used in ORMs.In this situation, if you use your Method #2, and a subclass defines a __new__ method, it will be executed every time you call SubClassOfSingleton() -- because it is responsible for calling the method that returns the stored instance. With a metaclass, it will only be called once, when the only instance is created. You want to customize what it means to call the class, which is decided by it's type.In general, it makes sense to use a metaclass to implement a singleton. A singleton is special because is created only once, and a metaclass is the way you customize the creation of a class. Using a metaclass gives you more control in case you need to customize the singleton class definitions in other ways.Your singletons won't need multiple inheritance (because the metaclass is not a base class), but for subclasses of the created class that use multiple inheritance, you need to make sure the singleton class is the first / leftmost one with a metaclass that redefines __call__ This is very unlikely to be an issue. The instance dict is not in the instance's namespace so it won't accidentally overwrite it.You will also hear that the singleton pattern violates the ""Single Responsibility Principle"" -- each class should do only one thing. That way you don't have to worry about messing up one thing the code does if you need to change another, because they are separate and encapsulated. The metaclass implementation passes this test. The metaclass is responsible for enforcing the pattern and the created class and subclasses need not be aware that they are singletons. Method #1 fails this test, as you noted with ""MyClass itself is a a function, not a class, so you cannot call class methods from it.""Python 2 and 3 Compatible VersionWriting something that works in both Python2 and 3 requires using a slightly more complicated scheme. Since metaclasses are usually subclasses of type type, it's possible to use one to dynamically create an intermediary base class at run time with it as its metaclass and then use that as the baseclass of the public Singleton base class. It's harder to explain than to do, as illustrated next:# works in Python 2 & 3class _Singleton(type):    """""" A metaclass that creates a Singleton base class when called. """"""    _instances = {}    def __call__(cls, *args, **kwargs):        if cls not in cls._instances:            cls._instances[cls] = super(_Singleton, cls).__call__(*args, **kwargs)        return cls._instances[cls]class Singleton(_Singleton('SingletonMeta', (object,), {})): passclass Logger(Singleton):    passAn ironic aspect of this approach is that it's using subclassing to implement a metaclass. One possible advantage is that, unlike with a pure metaclass, isinstance(inst, Singleton) will return True.CorrectionsOn another topic, you've probably already noticed this, but the base class implementation in your original post is wrong. _instances needs to be referenced on the class, you need to use super() or you're recursing, and __new__ is actually a static method that you have to pass the class to, not a class method, as the actual class hasn't been created yet when it is called. All of these things will be true for a metaclass implementation as well.class Singleton(object):  _instances = {}  def __new__(class_, *args, **kwargs):    if class_ not in class_._instances:        class_._instances[class_] = super(Singleton, class_).__new__(class_, *args, **kwargs)    return class_._instances[class_]class MyClass(Singleton):  passc = MyClass()Decorator Returning A ClassI originally was writing a comment but it was too long, so I'll add this here. Method #4 is better than the other decorator version, but it's more code than needed for a singleton, and it's not as clear what it does.The main problems stem from the class being it's own base class. First, isn't it weird to have a class be a subclass of a nearly identical class with the same name that exists only in its __class__ attribute? This also means that you can't define any methods that call the method of the same name on their base class with super() because they will recurse. This means your class can't customize __new__, and can't derive from any classes that need __init__ called on them.When to use the singleton patternYour use case is one of the better examples of wanting to use a singleton. You say in one of the comments ""To me logging has always seemed a natural candidate for Singletons."" You're absolutely right.When people say singletons are bad, the most common reason is they are implicit shared state. While with global variables and top-level module imports are explicit shared state, other objects that are passed around are generally instantiated. This is a good point, with two exceptions.The first, and one that gets mentioned in various places, is when the singletons are constant. Use of global constants, especially enums, is widely accepted, and considered sane because no matter what, none of the users can mess them up for any other user. This is equally true for a constant singleton.The second exception, which get mentioned less, is the opposite -- when the singleton is only a data sink, not a data source (directly or indirectly). This is why loggers feel like a ""natural"" use for singletons. As the various users are not changing the loggers in ways other users will care about, there is not really shared state. This negates the primary argument against the singleton pattern, and makes them a reasonable choice because of their ease of use for the task.Here is a quote from http://googletesting.blogspot.com/2008/08/root-cause-of-singletons.html:Now, there is one kind of Singleton which is OK. That is a singleton where all of the reachable objects are immutable. If all objects are immutable than Singleton has no global state, as everything is constant. But it is so easy to turn this kind of singleton into mutable one, it is very slippery slope. Therefore, I am against these Singletons too, not because they are bad, but because it is very easy for them to go bad. (As a side note Java enumeration are just these kind of singletons. As long as you don't put state into your enumeration you are OK, so please don't.)The other kind of Singletons, which are semi-acceptable are those which don't effect the execution of your code, They have no ""side effects"". Logging is perfect example. It is loaded with Singletons and global state. It is acceptable (as in it will not hurt you) because your application does not behave any different whether or not a given logger is enabled. The information here flows one way: From your application into the logger. Even thought loggers are global state since no information flows from loggers into your application, loggers are acceptable. You should still inject your logger if you want your test to assert that something is getting logged, but in general Loggers are not harmful despite being full of state."
"data_i","edited Jun 24 '15 at 04:40","
        Default behavior of ""git push"" without a branch specified
    ","I use the following command to push to my remote branch:git push origin sandboxIf I saygit push origindoes that push changes in my other branches too, or does it only update my current branch? I have three branches: master, production and sandbox.The git push documentation is not very clear about this, so I'd like to clarify this for good.Which branches and remotes do the following git push commands update exactly?git push git push originorigin above is a remote.I understand that git push [remote] [branch] will push only that branch to the remote.","You can control the default behavior by setting push.default in your git config. From the git-config(1) documentation:push.defaultDefines the action git push should take if no refspec is given on the command line, no refspec is configured in the remote, and no refspec is implied by any of the options given on the command line. Possible values are:nothing: do not push anythingmatching: (default before Git 2.0) push all matching branchesAll branches having the same name in both ends are considered to be matching.upstream: push the current branch to its upstream branch (tracking is a deprecated synonym for upstream)current: push the current branch to a branch of the same namesimple: (new in Git 1.7.11, default since Git 2.0) like upstream, but refuses to push if the upstream branch's name is different from the local oneThis is the safest option and is well-suited for beginners.The simple, current and upstream modes are for those who want to push out a single branch after finishing work, even when the other branches are not yet ready to be pushed outCommand line examples:To view the current configuration:git config push.defaultTo set a new configuration:git config push.default current"
"data_i","edited Dec 29 '20 at 05:39","
        How do I make a redirect in PHP?
    ","Is it possible to redirect a user to a different page through the use of PHP?Say the user goes to www.example.com/page.php and I want to redirect them to www.example.com/index.php, how would I do so without the use of a meta refresh? Is it possible?This could even protect my pages from unauthorized users.","Summary of existing answers plus my own two cents:1. Basic answerYou can use the header() function to send a new HTTP header, but this must be sent to the browser before any HTML or text (so before the <!DOCTYPE ...> declaration, for example).header('Location: '.$newURL);2. Important detailsdie() or exit()header(""Location: https://example.com/myOtherPage.php"");die();Why you should use die() or exit(): The Daily WTFAbsolute or relative URLSince June 2014 both absolute and relative URLs can be used. See RFC 7231 which had replaced the old RFC 2616, where only absolute URLs were allowed.Status CodesPHP's ""Location""-header still uses the HTTP 302-redirect code, this is a ""temporary"" redirect and may not be the one you should use. You should consider either 301 (permanent redirect) or 303 (other).Note: W3C mentions that the 303-header is incompatible with ""many pre-HTTP/1.1 user agents. Currently used browsers are all HTTP/1.1 user agents. This is not true for many other user agents like spiders and robots.3. DocumentationHTTP Headers and the header() function in PHPWhat the PHP manual saysWhat Wikipedia saysWhat the W3C says4. AlternativesYou may use the alternative method of http_redirect($url); which needs the PECL package pecl to be installed.5. Helper FunctionsThis function doesn't incorporate the 303 status code:function Redirect($url, $permanent = false){    header('Location: ' . $url, true, $permanent ? 301 : 302);    exit();}Redirect('https://example.com/', false);This is more flexible:function redirect($url, $statusCode = 303){   header('Location: ' . $url, true, $statusCode);   die();}6. WorkaroundAs mentioned header() redirects only work before anything is written out. They usually fail if invoked inmidst HTML output. Then you might use a HTML header workaround (not very professional!) like: <meta http-equiv=""refresh"" content=""0;url=finalpage.html"">Or a JavaScript redirect even.window.location.replace(""https://example.com/"");"
"data_i","edited Oct 13 '18 at 14:44","
        How do you do block comments in YAML?
    ","How do I comment a block of lines in YAML?","YAML supports inline comments, but does not support block comments.From Wikipedia:Comments begin with the number sign ( # ), can start anywhere on a line, and continue until the end of the lineA comparison with JSON, also from Wikipedia:The syntax differences are subtle and seldom arise in practice: JSON allows extended charactersets like UTF-32, YAML requires a space after separators like comma, equals, and colon while JSON does not, and some non-standard implementations of JSON extend the grammar to include Javascript's /* ... */ comments. Handling such edge cases may require light pre-processing of the JSON before parsing as in-line YAML.# If you want to write# a block-commented Haiku# you'll need three pound signs"
"data_i","edited Oct 18 '18 at 01:16","
        Read environment variables in Node.js
    ","Is there a way to read environment variables in Node.js code?Like for example Python's os.environ['HOME'].","process.env.ENV_VARIABLEWhere ENV_VARIABLE is the name of the variable you wish to access.See Node.js docs for process.env."
"data_i","edited May 04 '15 at 12:01","
        How to get GET (query string) variables in Express.js on Node.js?
    ","Can we get the variables in the query string in Node.js just like we get them in $_GET in PHP?I know that in Node.js we can get the URL in the request. Is there a method to get the query string parameters?","Since you've mentioned Express.js in your tags, here is an Express-specific answer: use req.query. E.g.var express = require('express');var app = express();app.get('/', function(req, res){  res.send('id: ' + req.query.id);});app.listen(3000);"
"data_i","edited Oct 13 '21 at 19:44","
        How to join (merge) data frames (inner, outer, left, right)
    ","Given two data frames:df1 = data.frame(CustomerId = c(1:6), Product = c(rep(""Toaster"", 3), rep(""Radio"", 3)))df2 = data.frame(CustomerId = c(2, 4, 6), State = c(rep(""Alabama"", 2), rep(""Ohio"", 1)))df1#  CustomerId Product#           1 Toaster#           2 Toaster#           3 Toaster#           4   Radio#           5   Radio#           6   Radiodf2#  CustomerId   State#           2 Alabama#           4 Alabama#           6    OhioHow can I do database style, i.e., sql style, joins? That is, how do I get:An inner join of df1 and df2:Return only the rows in which the left table have matching keys in the right table.An outer join of df1 and df2:Returns all rows from both tables, join records from the left which have matching keys in the right table.A left outer join (or simply left join) of df1 and df2Return all rows from the left table, and any rows with matching keys from the right table.A right outer join of df1 and df2Return all rows from the right table, and any rows with matching keys from the left table.Extra credit:How can I do a SQL style select statement?","By using the merge function and its optional parameters:Inner join: merge(df1, df2) will work for these examples because R automatically joins the frames by common variable names, but you would most likely want to specify merge(df1, df2, by = ""CustomerId"") to make sure that you were matching on only the fields you desired.  You can also use the by.x and by.y parameters if the matching variables have different names in the different data frames.Outer join: merge(x = df1, y = df2, by = ""CustomerId"", all = TRUE)Left outer: merge(x = df1, y = df2, by = ""CustomerId"", all.x = TRUE)Right outer: merge(x = df1, y = df2, by = ""CustomerId"", all.y = TRUE)Cross join: merge(x = df1, y = df2, by = NULL)Just as with the inner join, you would probably want to explicitly pass ""CustomerId"" to R as the matching variable.  I think it's almost always best to explicitly state the identifiers on which you want to merge; it's safer if the input data.frames change unexpectedly and easier to read later on.You can merge on multiple columns by giving by a vector, e.g., by = c(""CustomerId"", ""OrderId""). If the column names to merge on are not the same, you can specify, e.g., by.x = ""CustomerId_in_df1"", by.y = ""CustomerId_in_df2"" where CustomerId_in_df1 is the name of the column in the first data frame and CustomerId_in_df2 is the name of the column in the second data frame. (These can also be vectors if you need to merge on multiple columns.)"
"data_i","edited Jun 20 '22 at 06:45","
        What are the differences between type() and isinstance()?
    ","What are the differences between these two code snippets?Using type:import typesif type(a) is types.DictType:    do_something()if type(b) in types.StringTypes:    do_something_else()Using isinstance:if isinstance(a, dict):    do_something()if isinstance(b, str) or isinstance(b, unicode):    do_something_else()","To summarize the contents of other (already good!) answers, isinstance caters for inheritance (an instance of a derived class is an instance of a base class, too), while checking for equality of type does not (it demands identity of types and rejects instances of subtypes, AKA subclasses).Normally, in Python, you want your code to support inheritance, of course (since inheritance is so handy, it would be bad to stop code using yours from using it!), so isinstance is less bad than checking identity of types because it seamlessly supports inheritance.It's not that isinstance is good, mind you—it's just less bad than checking equality of types.  The normal, Pythonic, preferred solution is almost invariably ""duck typing"": try using the argument as if it was of a certain desired type, do it in a try/except statement catching all exceptions that could arise if the argument was not in fact of that type (or any other type nicely duck-mimicking it;-), and in the except clause, try something else (using the argument ""as if"" it was of some other type).basestring is, however, quite a special case—a builtin type that exists only to let you use isinstance (both str and unicode subclass basestring). Strings are sequences (you could loop over them, index them, slice them, ...), but you generally want to treat them as ""scalar"" types—it's somewhat incovenient (but a reasonably frequent use case) to treat all kinds of strings (and maybe other scalar types, i.e., ones you can't loop on) one way, all containers (lists, sets, dicts, ...) in another way, and basestring plus isinstance helps you do that—the overall structure of this idiom is something like:if isinstance(x, basestring)  return treatasscalar(x)try:  return treatasiter(iter(x))except TypeError:  return treatasscalar(x)You could say that basestring is an Abstract Base Class (""ABC"")—it offers no concrete functionality to subclasses, but rather exists as a ""marker"", mainly for use with isinstance. The concept is obviously a growing one in Python, since PEP 3119, which introduces a generalization of it, was accepted and has been implemented starting with Python 2.6 and 3.0.The PEP makes it clear that, while ABCs can often substitute for duck typing, there is generally no big pressure to do that (see here). ABCs as implemented in recent Python versions do however offer extra goodies: isinstance (and issubclass) can now mean more than just ""[an instance of] a derived class"" (in particular, any class can be ""registered"" with an ABC so that it will show as a subclass, and its instances as instances of the ABC); and ABCs can also offer extra convenience to actual subclasses in a very natural way via Template Method design pattern applications (see here and here [[part II]] for more on the TM DP, in general and specifically in Python, independent of ABCs).For the underlying mechanics of ABC support as offered in Python 2.6, see here; for their 3.1 version, very similar, see here.  In both versions, standard library module collections (that's the 3.1 version—for the very similar 2.6 version, see here) offers several useful ABCs.For the purpose of this answer, the key thing to retain about ABCs (beyond an arguably more natural placement for TM DP functionality, compared to the classic Python alternative of mixin classes such as UserDict.DictMixin) is that they make isinstance (and issubclass) much more attractive and pervasive (in Python 2.6 and going forward) than they used to be (in 2.5 and before), and therefore, by contrast, make checking type equality an even worse practice in recent Python versions than it already used to be."
"data_i","edited Sep 25 '17 at 20:53","
        Hidden Features of C#?
    ","This came to my mind after I learned the following from this question:where T : structWe, C# developers, all know the basics of C#. I mean declarations, conditionals, loops, operators, etc.Some of us even mastered the stuff like Generics, anonymous types, lambdas, LINQ, ...But what are the most hidden features or tricks of C# that even C# fans, addicts, experts barely know?Here are the revealed features so far:Keywordsyield by Michael Stumvar by Michael Stumusing() statement by kokosreadonly by kokosas by Mike Stoneas / is by Ed Swangrenas / is (improved) by Rocketpantsdefault by deathofratsglobal:: by pzycomanusing() blocks by AlexCusevolatile by Jakub Šturcextern alias by Jakub ŠturcAttributesDefaultValueAttribute by Michael StumObsoleteAttribute by DannySmurfDebuggerDisplayAttribute by StuDebuggerBrowsable and DebuggerStepThrough by bdukesThreadStaticAttribute by marxidadFlagsAttribute by Martin ClarkeConditionalAttribute by AndrewBurnsSyntax?? (coalesce nulls) operator by kokosNumber flaggings by Nick Berardiwhere T:new by Lars MæhlumImplicit generics by KeithOne-parameter lambdas by KeithAuto properties by KeithNamespace aliases by KeithVerbatim string literals with @ by Patrickenum values by lfoust@variablenames by marxidadevent operators by marxidadFormat string brackets by PortmanProperty accessor accessibility modifiers by xanadontConditional (ternary) operator (?:) by JasonSchecked and unchecked operators by Binoj Antonyimplicit and explicit operators by FloryLanguage FeaturesNullable types by Brad BarkerAnonymous types by Keith__makeref __reftype __refvalue by Judah HimangoObject initializers by lomaxxFormat strings by David in DakotaExtension Methods by marxidadpartial methods by Jon EricksonPreprocessor directives by John AsbeckDEBUG pre-processor directive by Robert DurginOperator overloading by SefBknType inferrence by chakritBoolean operators taken to next level by Rob GoughPass value-type variable as interface without boxing by Roman BoikoProgrammatically determine declared variable type by Roman BoikoStatic Constructors by ChrisEasier-on-the-eyes / condensed ORM-mapping using LINQ by roosteronacid__arglist by Zac BowlingVisual Studio FeaturesSelect block of text in editor by HimadriSnippets by DannySmurf FrameworkTransactionScope by KiwiBastardDependantTransaction by KiwiBastardNullable<T> by IainMHMutex by DiagoSystem.IO.Path by ageektrappedWeakReference by Juan ManuelMethods and PropertiesString.IsNullOrEmpty() method by KiwiBastardList.ForEach() method by KiwiBastardBeginInvoke(), EndInvoke() methods by Will DeanNullable<T>.HasValue and Nullable<T>.Value properties by RismoGetValueOrDefault method by John SheehanTips & TricksNice method for event handlers by Andreas H.R. NilssonUppercase comparisons by JohnAccess anonymous types without reflection by dpA quick way to lazily instantiate collection properties by WillJavaScript-like anonymous inline-functions by roosteronacidOthernetmodules by kokos LINQBridge by Duncan Smart Parallel Extensions by Joel Coehoorn","This isn't C# per se, but I haven't seen anyone who really uses System.IO.Path.Combine() to the extent that they should. In fact, the whole Path class is really useful, but no one uses it!I'm willing to bet that every production app has the following code, even though it shouldn't:string path = dir + ""\\"" + fileName;"
"data_i","edited Mar 18 '21 at 11:19","
        How can I select an element by name with jQuery?
    ","I have a table column I’m trying to expand and hide. jQuery seems to hide the <td> elements when I select it by class but not by the element’s name.For example:$("".bold"").hide(); // Selecting by class works.$(""tcol1"").hide(); // Selecting by name does not work.Note the HTML below. The second column has the same name for all rows.  How could I create this collection using the name attribute?<tr>  <td>data1</td>  <td name=""tcol1"" class=""bold""> data2</td></tr><tr>  <td>data1</td>  <td name=""tcol1"" class=""bold""> data2</td></tr><tr>  <td>data1</td>  <td name=""tcol1"" class=""bold""> data2</td></tr>","You can use the jQuery attribute selector:$('td[name=""tcol1""]')   // Matches exactly 'tcol1'$('td[name^=""tcol""]' )  // Matches those that begin with 'tcol'$('td[name$=""tcol""]' )  // Matches those that end with 'tcol'$('td[name*=""tcol""]' )  // Matches those that contain 'tcol'"
"data_i","edited Dec 01 '19 at 18:05","
        Does JavaScript have a method like ""range()"" to generate a range within the supplied bounds?
    ","In PHP, you can do...range(1, 3); // Array(1, 2, 3)range(""A"", ""C""); // Array(""A"", ""B"", ""C"")That is, there is a function that lets you get a range of numbers or characters by passing the upper and lower bounds.Is there anything built-in to JavaScript natively for this? If not, how would I implement it?","Numbers [...Array(5).keys()]; => [0, 1, 2, 3, 4]Character iterationString.fromCharCode(...[...Array('D'.charCodeAt(0) - 'A'.charCodeAt(0) + 1).keys()].map(i => i + 'A'.charCodeAt(0))); => ""ABCD""Iterationfor (const x of Array(5).keys()) {  console.log(x, String.fromCharCode('A'.charCodeAt(0) + x));} => 0,""A"" 1,""B"" 2,""C"" 3,""D"" 4,""E""As functionsfunction range(size, startAt = 0) {    return [...Array(size).keys()].map(i => i + startAt);}function characterRange(startChar, endChar) {    return String.fromCharCode(...range(endChar.charCodeAt(0) -            startChar.charCodeAt(0), startChar.charCodeAt(0)))}As typed functionsfunction range(size:number, startAt:number = 0):ReadonlyArray<number> {    return [...Array(size).keys()].map(i => i + startAt);}function characterRange(startChar:string, endChar:string):ReadonlyArray<string> {    return String.fromCharCode(...range(endChar.charCodeAt(0) -            startChar.charCodeAt(0), startChar.charCodeAt(0)))}lodash.js _.range() function_.range(10); => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]_.range(1, 11); => [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]_.range(0, 30, 5); => [0, 5, 10, 15, 20, 25]_.range(0, -10, -1); => [0, -1, -2, -3, -4, -5, -6, -7, -8, -9]String.fromCharCode(..._.range('A'.charCodeAt(0), 'D'.charCodeAt(0) + 1)); => ""ABCD""Old non es6 browsers without a library: Array.apply(null, Array(5)).map(function (_, i) {return i;}); => [0, 1, 2, 3, 4]console.log([...Array(5).keys()]);(ES6 credit to nils petersohn and other commenters)"
"data_i","edited Aug 19 '14 at 22:36","
        echo that outputs to stderr
    ","Is there a standard Bash tool that acts like echo but outputs to stderr rather than stdout?I know I can do echo foo 1>&2 but it's kinda ugly and, I suspect, error prone (e.g. more likely to get edited wrong when things change). ","You could do this, which facilitates reading:>&2 echo ""error"">&2 copies file descriptor #2 to file descriptor #1. Therefore, after this redirection is performed, both file descriptors will refer to the same file: the one file descriptor #2 was originally referring to. For more information see the Bash Hackers Illustrated Redirection Tutorial."
"data_i","edited Feb 06 '20 at 05:16","
        How to check if a value exists in an array in Ruby
    ","I have a value 'Dog' and an array ['Cat', 'Dog', 'Bird']. How do I check if it exists in the array without looping through it? Is there a simple way of checking if the value exists, nothing more?","You're looking for include?:>> ['Cat', 'Dog', 'Bird'].include? 'Dog'=> true"
"data_i","edited Sep 05 '20 at 13:22","
        What is the best way to add options to a select from a JavaScript object with jQuery?
    ","What is the best method for adding options to a <select> from a JavaScript object using jQuery?I'm looking for something that I don't need a plugin to do, but I would also be interested in the plugins that are out there.This is what I did:selectValues = { ""1"": ""test 1"", ""2"": ""test 2"" };for (key in selectValues) {  if (typeof (selectValues[key] == 'string') {    $('#mySelect').append('<option value=""' + key + '"">' + selectValues[key] + '</option>');  }}A clean/simple solution:This is a cleaned up and simplified version of matdumsa's:$.each(selectValues, function(key, value) {     $('#mySelect')          .append($('<option>', { value : key })          .text(value));});Changes from matdumsa's: (1) removed the close tag for the option inside append() and (2) moved the properties/attributes into an map as the second parameter of append().","The same as other answers, in a jQuery fashion:$.each(selectValues, function(key, value) {        $('#mySelect')         .append($(""<option></option>"")                    .attr(""value"", key)                    .text(value)); });"
"data_i","edited Apr 09 '22 at 08:00","
        How can I check for NaN values?
    ","float('nan') represents NaN (not a number). But how do I check for it?","Use math.isnan:>>> import math>>> x = float('nan')>>> math.isnan(x)True"
"data_i","edited Dec 13 '18 at 07:55","
        Using Git with Visual Studio
    ","As a long-time Visual SourceSafe user (and hater) I was discussing switching to SVN with a colleague; he suggested using Git instead. Since, apparently, it can be used as peer-to-peer without a central server (we are a 3-developer team). I have not been able to find anything about tools that integrate Git with Visual Studio, though - does such a thing exist? What are the technologies available for using Git with Visual Studio? And what do I need to know about how they differ before I begin?","In Jan 2013, Microsoft announced that they are adding full Git support into all their ALM products. They have published a plugin for Visual Studio 2012 that adds Git source control integration.Alternatively, there is a project called Git Extensions that includes add-ins for Visual Studio 2005, 2008, 2010 and 2012, as well as Windows Explorer integration. It's regularly updated and having used it on a couple of projects, I've found it very useful.Another option is Git Source Control Provider."
"data_i","edited Sep 11 '22 at 15:33","
        How can I ""add existing frameworks"" in Xcode 4?
    ","I can't find the good old ""Add existing frameworks"" option. How do I do this?We're talking about Xcode 4 DP2 (in the context of iPhone development, as far as it matters...).","As per Apple's documentation:In the project navigator, selectyour project.  Select your target.Select the ""Build Phases"" tab.Open ""Link Binaries With Libraries""expander.Click the + button.Select your framework.(optional) Drag and drop the addedframework to the ""Frameworks"" group."
"data_i","edited Mar 12 '14 at 13:35","
        What is the difference between match_parent and fill_parent?
    ","I'm a little confused about two XML properties: match_parent and fill_parent. It seems that both are the same. Is there any difference between them?","They're the same thing (in API Level 8+). Use match_parent.FILL_PARENT (renamed MATCH_PARENT in API Level 8 and higher), which means that the view wants to be as big as its parent (minus padding)...fill_parent: The view should be as big as its parent (minus padding). This constant is deprecated starting from API Level 8 and is replaced by match_parent.http://developer.android.com/reference/android/view/ViewGroup.LayoutParams.html"
"data_i","edited Sep 21 '22 at 10:36","
        Merge/flatten an array of arrays
    ","I have a JavaScript array like:[[""$6""], [""$12""], [""$25""], [""$25""], [""$18""], [""$22""], [""$10""]]How would I go about merging the separate inner arrays into one like:[""$6"", ""$12"", ""$25"", ...]","You can use concat to merge arrays:var arrays = [  [""$6""],  [""$12""],  [""$25""],  [""$25""],  [""$18""],  [""$22""],  [""$10""]];var merged = [].concat.apply([], arrays);console.log(merged);Using the apply method of concat will just take the second parameter as an array, so the last line is identical to this:var merged2 = [].concat([""$6""], [""$12""], [""$25""], [""$25""], [""$18""], [""$22""], [""$10""]);There is also the Array.prototype.flat() method (introduced in ES2019) which you could use to flatten the arrays, although it is only available in Node.js starting with version 11, and not at all in Internet Explorer.const arrays = [      [""$6""],      [""$12""],      [""$25""],      [""$25""],      [""$18""],      [""$22""],      [""$10""]    ];const merge3 = arrays.flat(1); //The depth level specifying how deep a nested array structure should be flattened. Defaults to 1.console.log(merge3);    "
"data_i","edited Sep 18 '22 at 11:45","
        How does the 'Access-Control-Allow-Origin' header work?
    ","Apparently, I have completely misunderstood its semantics. I thought of something like this:A client downloads JavaScript code MyCode.js from http://siteA - the origin.The response header of MyCode.js contains Access-Control-Allow-Origin: http://siteB, which I thought meant that MyCode.js was allowed to make cross-origin references to the site B.The client triggers some functionality of MyCode.js, which in turn make requests to http://siteB, which should be fine, despite being cross-origin requests.Well, I am wrong. It does not work like this at all. So, I have read Cross-origin resource sharing and attempted to read Cross-Origin Resource Sharing in w3c recommendation.One thing is sure - I still do not understand how I am supposed to use this header.I have full control of both site A and site B. How do I enable the JavaScript code downloaded from the site A to access resources on the site B using this header?P.S.: I do not want to utilize JSONP.","Access-Control-Allow-Origin is a CORS (cross-origin resource sharing) header.When Site A tries to fetch content from Site B,  Site B can send an Access-Control-Allow-Origin response header to tell the browser that the content of this page is accessible to certain origins. (An origin is a domain, plus a scheme and port number.)  By default, Site B's pages are not accessible to any other origin; using the Access-Control-Allow-Origin header opens a door for cross-origin access by specific requesting origins.For each resource/page that Site B wants to make accessible to Site A, Site B should serve its pages with the response header:Access-Control-Allow-Origin: http://siteA.comModern browsers will not block cross-domain requests outright.  If Site A requests a page from Site B, the browser will actually fetch the requested page on the network level and check if the response headers list Site A as a permitted requester domain.  If Site B has not indicated that Site A is allowed to access this page, the browser will trigger the XMLHttpRequest's error event and  deny the response data to the requesting JavaScript code.Non-simple requestsWhat happens on the network level can be slightly more complex than explained above. If the request is a ""non-simple"" request, the browser first sends a data-less ""preflight"" OPTIONS request, to verify that the server will accept the request. A request is non-simple when either (or both):using an HTTP verb other than GET or POST (e.g. PUT, DELETE)using non-simple request headers; the only simple requests headers are:AcceptAccept-LanguageContent-LanguageContent-Type (this is only simple when its value is application/x-www-form-urlencoded, multipart/form-data, or text/plain)If the server responds to the OPTIONS preflight with appropriate response headers (Access-Control-Allow-Headers for non-simple headers, Access-Control-Allow-Methods for non-simple verbs) that match the non-simple verb and/or non-simple headers, then the browser sends the actual request.Supposing that Site A wants to send a PUT request for /somePage, with a non-simple Content-Type value of application/json, the browser would first send a preflight request:OPTIONS /somePage HTTP/1.1Origin: http://siteA.comAccess-Control-Request-Method: PUTAccess-Control-Request-Headers: Content-TypeNote that Access-Control-Request-Method and Access-Control-Request-Headers are added by the browser automatically; you do not need to add them. This OPTIONS preflight gets the successful response headers:Access-Control-Allow-Origin: http://siteA.comAccess-Control-Allow-Methods: GET, POST, PUTAccess-Control-Allow-Headers: Content-TypeWhen sending the actual request (after preflight is done), the behavior is identical to how a simple request is handled. In other words, a non-simple request whose preflight is successful is treated the same as a simple request (i.e., the server must still send Access-Control-Allow-Origin again for the actual response).The browsers sends the actual request:PUT /somePage HTTP/1.1Origin: http://siteA.comContent-Type: application/json{ ""myRequestContent"": ""JSON is so great"" }And the server sends back an Access-Control-Allow-Origin, just as it would for a simple request:Access-Control-Allow-Origin: http://siteA.comSee Understanding XMLHttpRequest over CORS for a little more information about non-simple requests."
"data_i","edited Apr 09 '22 at 07:49","
        How do I check if directory exists in Python?
    ","How do I check if a directory exists?","Use os.path.isdir for directories only:>>> import os>>> os.path.isdir('new_folder')TrueUse os.path.exists for both files and directories:>>> import os>>> os.path.exists(os.path.join(os.getcwd(), 'new_folder', 'file.txt'))FalseAlternatively, you can use pathlib: >>> from pathlib import Path >>> Path('new_folder').is_dir() True >>> (Path.cwd() / 'new_folder' / 'file.txt').exists() False"
"data_i","edited Dec 09 '19 at 16:42","
        How can I use threading in Python?
    ","I am trying to understand threading in Python. I've looked at the documentation and examples, but quite frankly, many examples are overly sophisticated and I'm having trouble understanding them.How do you clearly show tasks being divided for multi-threading?","Since this question was asked in 2010, there has been real simplification in how to do simple multithreading with Python with map and pool.The code below comes from an article/blog post that you should definitely check out (no affiliation) - Parallelism in one line: A Better Model for Day to Day Threading Tasks. I'll summarize below - it ends up being just a few lines of code:from multiprocessing.dummy import Pool as ThreadPoolpool = ThreadPool(4)results = pool.map(my_function, my_array)Which is the multithreaded version of:results = []for item in my_array:    results.append(my_function(item))DescriptionMap is a cool little function, and the key to easily injecting parallelism into your Python code. For those unfamiliar, map is something lifted from functional languages like Lisp. It is a function which maps another function over a sequence.Map handles the iteration over the sequence for us, applies the function, and stores all of the results in a handy list at the end.ImplementationParallel versions of the map function are provided by two libraries:multiprocessing, and also its little known, but equally fantastic step child:multiprocessing.dummy.multiprocessing.dummy is exactly the same as multiprocessing module, but uses threads instead (an important distinction - use multiple processes for CPU-intensive tasks; threads for (and during) I/O):multiprocessing.dummy replicates the API of multiprocessing, but is no more than a wrapper around the threading module.import urllib2from multiprocessing.dummy import Pool as ThreadPoolurls = [  'http://www.python.org',  'http://www.python.org/about/',  'http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html',  'http://www.python.org/doc/',  'http://www.python.org/download/',  'http://www.python.org/getit/',  'http://www.python.org/community/',  'https://wiki.python.org/moin/',]# Make the Pool of workerspool = ThreadPool(4)# Open the URLs in their own threads# and return the resultsresults = pool.map(urllib2.urlopen, urls)# Close the pool and wait for the work to finishpool.close()pool.join()And the timing results:Single thread:   14.4 seconds       4 Pool:   3.1 seconds       8 Pool:   1.4 seconds      13 Pool:   1.3 secondsPassing multiple arguments (works like this only in Python 3.3 and later):To pass multiple arrays:results = pool.starmap(function, zip(list_a, list_b))Or to pass a constant and an array:results = pool.starmap(function, zip(itertools.repeat(constant), list_a))If you are using an earlier version of Python, you can pass multiple arguments via this workaround).(Thanks to user136036 for the helpful comment.)"
"data_i","edited Sep 21 '20 at 12:15","
        Safely turning a JSON string into an object
    ","Given a string of JSON data, how can I safely turn that string into a JavaScript object?Obviously I can do this unsafely with something like:var obj = eval(""("" + json + ')');but that leaves me vulnerable to the JSON string containing other code, which it seems very dangerous to simply eval.","JSON.parse(jsonString) is a pure JavaScript approach so long as you can guarantee a reasonably modern browser."
"data_i","edited Feb 03 '17 at 14:06","
        How do you get a list of the names of all files present in a directory in Node.js?
    ","I'm trying to get a list of the names of all the files present in a directory using Node.js.  I want output that is an array of filenames. How can I do this?","You can use the fs.readdir or fs.readdirSync methods. fs is included in Node.js core, so there's no need to install anything.fs.readdirconst testFolder = './tests/';const fs = require('fs');fs.readdir(testFolder, (err, files) => {  files.forEach(file => {    console.log(file);  });});fs.readdirSyncconst testFolder = './tests/';const fs = require('fs');fs.readdirSync(testFolder).forEach(file => {  console.log(file);});The difference between the two methods, is that the first one is asynchronous, so you have to provide a callback function that will be executed when the read process ends.The second is synchronous, it will return the file name array, but it will stop any further execution of your code until the read process ends."
"data_i","edited Jun 17 '22 at 11:53","
        How does the ""this"" keyword work, and when should it be used?
    ","I am looking to find a clear explanation of what the ""this"" keyword does, and how to use it correctly.It seems to behave strangely, and I don't fully understand why.How does this work and when should it be used?","this is a keyword in JavaScript that is a property of an execution context. Its main use is in functions and constructors.The rules for this are quite simple (if you stick to best practices).Technical description of this in the specificationThe ECMAScript standard defines this via the abstract operation (abbreviated AO) ResolveThisBinding:The [AO] ResolveThisBinding […] determines the binding of the keyword this using the LexicalEnvironment of the running execution context. [Steps]:Let envRec be GetThisEnvironment().Return ? envRec.GetThisBinding().Global Environment Records, module Environment Records, and function Environment Records each have their own GetThisBinding method.The GetThisEnvironment AO finds the current running execution context’s LexicalEnvironment and finds the closest ascendant Environment Record (by iteratively accessing their [[OuterEnv]] properties) which has a this binding (i.e. HasThisBinding returns true). This process ends in one of the three Environment Record types.The value of this often depends on whether code is in strict mode.The return value of GetThisBinding reflects the value of this of the current execution context, so whenever a new execution context is established, this resolves to a distinct value. This can also happen when the current execution context is modified. The following subsections list the five cases where this can happen.You can put the code samples in the AST explorer to follow along with specification details.1. Global execution context in scriptsThis is script code evaluated at the top level, e.g. directly inside a <script>:<script>// Global contextconsole.log(this); // Logs global object.setTimeout(function(){  console.log(""Not global context"");});</script>When in the initial global execution context of a script, evaluating this causes GetThisBinding to take the following steps:The GetThisBinding concrete method of a global Environment Record envRec […] [does this]:Return envRec.[[GlobalThisValue]].The [[GlobalThisValue]] property of a global Environment Record is always set to the host-defined global object, which is reachable via globalThis (window on Web, global on Node.js; Docs on MDN). Follow the steps of InitializeHostDefinedRealm to learn how the [[GlobalThisValue]] property comes to be.2. Global execution context in modulesModules have been introduced in ECMAScript 2015.This applies to modules, e.g. when directly inside a <script type=""module"">, as opposed to a simple <script>.When in the initial global execution context of a module, evaluating this causes GetThisBinding to take the following steps:The GetThisBinding concrete method of a module Environment Record […] [does this]:Return undefined.In modules, the value of this is always undefined in the global context. Modules are implicitly in strict mode.3. Entering eval codeThere are two kinds of eval calls: direct and indirect. This distinction exists since the ECMAScript 5th edition.A direct eval call usually looks like eval(…); or (eval)(…); (or ((eval))(…);, etc.).1 It’s only direct if the call expression fits a narrow pattern.2An indirect eval call involves calling the function reference eval in any other way. It could be eval?.(…), (…, eval)(…), window.eval(…), eval.call(…,…), etc. Given const aliasEval1 = eval; window.aliasEval2 = eval;, it would also be aliasEval1(…), aliasEval2(…). Separately, given const originalEval = eval; window.eval = (x) => originalEval(x);, calling eval(…) would also be indirect.See chuckj’s answer to “(1, eval)('this') vs eval('this') in JavaScript?” and Dmitry Soshnikov’s ECMA-262-5 in detail – Chapter 2: Strict Mode (archived) for when you might use an indirect eval() call.PerformEval executes the eval code. It creates a new declarative Environment Record as its LexicalEnvironment, which is where GetThisEnvironment gets the this value from.Then, if this appears in eval code, the GetThisBinding method of the Environment Record found by GetThisEnvironment is called and its value returned.And the created declarative Environment Record depends on whether the eval call was direct or indirect:In a direct eval, it will be based on the current running execution context’s LexicalEnvironment.In an indirect eval, it will be based on the [[GlobalEnv]] property (a global Environment Record) of the Realm Record which executed the indirect eval.Which means:In a direct eval, the this value doesn’t change; it’s taken from the lexical scope that called eval.In an indirect eval, the this value is the global object (globalThis).What about new Function? — new Function is similar to eval, but it doesn’t call the code immediately; it creates a function. A this binding doesn’t apply anywhere here, except when the function is called, which works normally, as explained in the next subsection.4. Entering function codeEntering function code occurs when calling a function.There are four categories of syntax to invoke a function.The EvaluateCall AO is performed for these three:3Normal function callsOptional chaining callsTagged templatesAnd EvaluateNew is performed for this one:3Constructor invocationsThe actual function call happens at the Call AO, which is called with a thisValue determined from context; this argument is passed along in a long chain of call-related calls. Call calls the [[Call]] internal slot of the function. This calls PrepareForOrdinaryCall where a new function Environment Record is created:A function Environment Record is a declarative Environment Record that is used to represent the top-level scope of a function and, if the function is not an ArrowFunction, provides a this binding. If a function is not an ArrowFunction function and references super, its function Environment Record also contains the state that is used to perform super method invocations from within the function.In addition, there is the [[ThisValue]] field in a function Environment Record:This is the this value used for this invocation of the function.The NewFunctionEnvironment call also sets the function environment’s [[ThisBindingStatus]] property.[[Call]] also calls OrdinaryCallBindThis, where the appropriate thisArgument is determined based on:the original reference,the kind of the function, andwhether or not the code is in strict mode.Once determined, a final call to the BindThisValue method of the newly created function Environment Record actually sets the [[ThisValue]] field to the thisArgument.Finally, this very field is where a function Environment Record’s GetThisBinding AO gets the value for this from:The GetThisBinding concrete method of a function Environment Record envRec […] [does this]:[…]3. Return envRec.[[ThisValue]].Again, how exactly the this value is determined depends on many factors; this was just a general overview. With this technical background, let’s examine all the concrete examples.Arrow functionsWhen an arrow function is evaluated, the [[ThisMode]] internal slot of the function object is set to “lexical” in OrdinaryFunctionCreate.At OrdinaryCallBindThis, which takes a function F:Let thisMode be F.[[ThisMode]].If thisMode is lexical, return NormalCompletion(undefined).[…]which just means that the rest of the algorithm which binds this is skipped. An arrow function does not bind its own this value.So, what is this inside an arrow function, then? Looking back at ResolveThisBinding and GetThisEnvironment, the HasThisBinding method explicitly returns false.The HasThisBinding concrete method of a function Environment Record envRec […] [does this]:If envRec.[[ThisBindingStatus]] is lexical, return false; otherwise, return true.So the outer environment is looked up instead, iteratively. The process will end in one of the three environments that have a this binding.This just means that, in arrow function bodies, this comes from the lexical scope of the arrow function, or in other words (from Arrow function vs function declaration / expressions: Are they equivalent / exchangeable?):Arrow functions don’t have their own this […] binding. Instead, [this identifier is] resolved in the lexical scope like any other variable. That means that inside an arrow function, this [refers] to the [value of this] in the environment the arrow function is defined in (i.e. “outside” the arrow function).Function propertiesIn normal functions (function, methods), this is determined by how the function is called.This is where these “syntax variants” come in handy.Consider this object containing a function:const refObj = {    func: function(){      console.log(this);    }  };Alternatively:const refObj = {    func(){      console.log(this);    }  };In any of the following function calls, the this value inside func will be refObj.1refObj.func()refObj[""func""]()refObj?.func()refObj.func?.()refObj.func``If the called function is syntactically a property of a base object, then this base will be the “reference” of the call, which, in usual cases, will be the value of this. This is explained by the evaluation steps linked above; for example, in refObj.func() (or refObj[""func""]()), the CallMemberExpression is the entire expression refObj.func(), which consists of the MemberExpression refObj.func and the Arguments ().But also, refObj.func and refObj play three roles, each:they’re both expressions,they’re both references, andthey’re both values.refObj.func as a value is the callable function object; the corresponding reference is used to determine the this binding.The optional chaining and tagged template examples work very similarly: basically, the reference is everything before the ?.(), before the ``, or before the ().EvaluateCall uses IsPropertyReference of that reference to determine if it is a property of an object, syntactically. It’s trying to get the [[Base]] property of the reference (which is e.g. refObj, when applied to refObj.func; or foo.bar when applied to foo.bar.baz). If it is written as a property, then GetThisValue will get this [[Base]] property and use it as the this value.Note: Getters / Setters work the same way as methods, regarding this. Simple properties don’t affect the execution context, e.g. here, this is in global scope:const o = {    a: 1,    b: this.a, // Is `globalThis.a`.    [this.a]: 2 // Refers to `globalThis.a`.  };Calls without base reference, strict mode, and withA call without a base reference is usually a function that isn’t called as a property. For example:func(); // As opposed to `refObj.func();`.This also happens when passing or assigning methods, or using the comma operator. This is where the difference between Reference Record and Value is relevant.Note function j: following the specification, you will notice that j can only return the function object (Value) itself, but not a Reference Record. Therefore the base reference refObj is lost.const g = (f) => f(); // No base ref.const h = refObj.func;const j = () => refObj.func;g(refObj.func);h(); // No base ref.j()(); // No base ref.(0, refObj.func)(); // Another common pattern to remove the base ref.EvaluateCall calls Call with a thisValue of undefined here. This makes a difference in OrdinaryCallBindThis (F: the function object; thisArgument: the thisValue passed to Call):Let thisMode be F.[[ThisMode]].[…]If thisMode is strict, let thisValue be thisArgument.Else,If thisArgument is undefined or null, thenLet globalEnv be calleeRealm.[[GlobalEnv]].[…]Let thisValue be globalEnv.[[GlobalThisValue]].Else,Let thisValue be ! ToObject(thisArgument).NOTE: ToObject produces wrapper objects […].[…]Note: step 5 sets the actual value of this to the supplied thisArgument in strict mode — undefined in this case. In “sloppy mode”, an undefined or null thisArgument results in this being the global this value.If IsPropertyReference returns false, then EvaluateCall takes these steps:Let refEnv be ref.[[Base]].Assert: refEnv is an Environment Record.Let thisValue be refEnv.WithBaseObject().This is where an undefined thisValue may come from: refEnv.WithBaseObject() is always undefined, except in with statements. In this case, thisValue will be the binding object.There’s also Symbol.unscopables (Docs on MDN) to control the with binding behavior.To summarize, so far:function f1(){  console.log(this);}function f2(){  console.log(this);}function f3(){  console.log(this);}const o = {    f1,    f2,    [Symbol.unscopables]: {      f2: true    }  };f1(); // Logs `globalThis`.with(o){  f1(); // Logs `o`.  f2(); // `f2` is unscopable, so this logs `globalThis`.  f3(); // `f3` is not on `o`, so this logs `globalThis`.}and:""use strict"";function f(){  console.log(this);}f(); // Logs `undefined`.// `with` statements are not allowed in strict-mode code.Note that when evaluating this, it doesn’t matter where a normal function is defined..call, .apply, .bind, thisArg, and primitivesAnother consequence of step 5 of OrdinaryCallBindThis, in conjunction with step 6.2 (6.b in the spec), is that a primitive this value is coerced to an object only in “sloppy” mode.To examine this, let’s introduce another source for the this value: the three methods that override the this binding:4Function.prototype.apply(thisArg, argArray)Function.prototype. {call, bind} (thisArg, ...args).bind creates a bound function, whose this binding is set to thisArg and cannot change again. .call and .apply call the function immediately, with the this binding set to thisArg..call and .apply map directly to Call, using the specified thisArg. .bind creates a bound function with BoundFunctionCreate. These have their own [[Call]] method which looks up the function object’s [[BoundThis]] internal slot.Examples of setting a custom this value:function f(){  console.log(this);}const myObj = {},  g = f.bind(myObj),  h = (m) => m();// All of these log `myObj`.g();f.bind(myObj)();f.call(myObj);h(g);For objects, this is the same in strict and non-strict mode.Now, try to supply a primitive value:function f(){  console.log(this);}const myString = ""s"",  g = f.bind(myString);g();              // Logs `String { ""s"" }`.f.call(myString); // Logs `String { ""s"" }`.In non-strict mode, primitives are coerced to their object-wrapped form. It’s the same kind of object you get when calling Object(""s"") or new String(""s""). In strict mode, you can use primitives:""use strict"";function f(){  console.log(this);}const myString = ""s"",  g = f.bind(myString);g();              // Logs `""s""`.f.call(myString); // Logs `""s""`.Libraries make use of these methods, e.g. jQuery sets the this to the DOM element selected here:$(""button"").click(function(){  console.log(this); // Logs the clicked button.});Constructors, classes, and newWhen calling a function as a constructor using the new operator, EvaluateNew calls Construct, which calls the [[Construct]] method. If the function is a base constructor (i.e. not a class extends…{…}), it sets thisArgument to a new object created from the constructor’s prototype. Properties set on this in the constructor will end up on the resulting instance object. this is implicitly returned, unless you explicitly return your own non-primitive value.A class is a new way of creating constructor functions, introduced in ECMAScript 2015.function Old(a){  this.p = a;}const o = new Old(1);console.log(o);  // Logs `Old { p: 1 }`.class New{  constructor(a){    this.p = a;  }}const n = new New(1);console.log(n); // Logs `New { p: 1 }`.Class definitions are implicitly in strict mode:class A{  m1(){    return this;  }  m2(){    const m1 = this.m1;        console.log(m1());  }}new A().m2(); // Logs `undefined`.superThe exception to the behavior with new is class extends…{…}, as mentioned above. Derived classes do not immediately set their this value upon invocation; they only do so once the base class is reached through a series of super calls (happens implicitly without an own constructor). Using this before calling super is not allowed.Calling super calls the super constructor with the this value of the lexical scope (the function Environment Record) of the call. GetThisValue has a special rule for super calls. It uses BindThisValue to set this to that Environment Record.class DerivedNew extends New{  constructor(a, a2){    // Using `this` before `super` results in a ReferenceError.    super(a);    this.p2 = a2;  }}const n2 = new DerivedNew(1, 2);console.log(n2); // Logs `DerivedNew { p: 1, p2: 2 }`.5. Evaluating class fieldsInstance fields and static fields were introduced in ECMAScript 2022.When a class is evaluated, ClassDefinitionEvaluation is performed, modifying the running execution context. For each ClassElement:if a field is static, then this refers to the class itself,if a field is not static, then this refers to the instance.Private fields (e.g. #x) and methods are added to a PrivateEnvironment.Static blocks are currently a TC39 stage 3 proposal. Static blocks work the same as static fields and methods: this inside them refers to the class itself.Note that in methods and getters / setters, this works just like in normal function properties.class Demo{  a = this;  b(){    return this;  }  static c = this;  static d(){    return this;  }  // Getters, setters, private modifiers are also possible.}const demo = new Demo;console.log(demo.a, demo.b()); // Both log `demo`.console.log(Demo.c, Demo.d()); // Both log `Demo`.1: (o.f)() is equivalent to o.f(); (f)() is equivalent to f(). This is explained in this 2ality article (archived). Particularly see how a ParenthesizedExpression is evaluated.2: It must be a MemberExpression, must not be a property, must have a [[ReferencedName]] of exactly ""eval"", and must be the %eval% intrinsic object.3: Whenever the specification says “Let ref be the result of evaluating X.”, then X is some expression that you need to find the evaluation steps for. For example, evaluating a MemberExpression or CallExpression is the result of one of these algorithms. Some of them result in a Reference Record.4: There are also several other native and host methods that allow providing a this value, notably Array.prototype.map, Array.prototype.forEach, etc. that accept a thisArg as their second argument. Anyone can make their own methods to alter this like (func, thisArg) => func.bind(thisArg), (func, thisArg) => func.call(thisArg), etc. As always, MDN offers great documentation.Just for fun, test your understanding with some examplesFor each code snippet, answer the question: “What is the value of this at the marked line? Why?”.To reveal the answers, click the gray boxes.if(true){  console.log(this); // What is `this` here?} globalThis. The marked line is evaluated in the initial global execution context.const obj = {};function myFun(){  return { // What is `this` here?    ""is obj"": this === obj,    ""is globalThis"": this === globalThis  };}obj.method = myFun;console.log(obj.method());    obj. When calling a function as a property of an object, it is called with the this binding set to the base of the reference obj.method, i.e. obj.const obj = {    myMethod: function(){      return { // What is `this` here?        ""is obj"": this === obj,        ""is globalThis"": this === globalThis      };    }  },  myFun = obj.myMethod;console.log(myFun());    globalThis. Since the function value myFun / obj.myMethod is not called off of an object, as a property, the this binding will be globalThis. This is different from Python, in which accessing a method (obj.myMethod) creates a bound method object.const obj = {    myFun: () => ({ // What is `this` here?      ""is obj"": this === obj,      ""is globalThis"": this === globalThis    })  };console.log(obj.myFun());    globalThis. Arrow functions don’t create their own this binding. The lexical scope is the same as the initial global scope, so this is globalThis.function myFun(){  console.log(this); // What is `this` here?}const obj = {    myMethod: function(){      eval(""myFun()"");    }  };obj.myMethod(); globalThis. When evaluating the direct eval call, this is obj. However, in the eval code, myFun is not called off of an object, so the this binding is set to the global object.function myFun() {  // What is `this` here?  return {    ""is obj"": this === obj,    ""is globalThis"": this === globalThis  };}const obj = {};console.log(myFun.call(obj));    obj. The line myFun.call(obj); is invoking the special built-in function Function.prototype.call, which accepts thisArg as the first argument.class MyCls{  arrow = () => ({ // What is `this` here?    ""is MyCls"": this === MyCls,    ""is globalThis"": this === globalThis,    ""is instance"": this instanceof MyCls  });}console.log(new MyCls().arrow());    It’s the instance of MyCls. Arrow functions don’t change the this binding, so it comes from lexical scope. Therefore, this is exactly the same as with the class fields mentioned above, like a = this;. Try changing it to static arrow. Do you get the result you expect?"
"data_i","edited Dec 07 '21 at 17:45","
        Sort (order) data frame rows by multiple columns
    ","I want to sort a data frame by multiple columns. For example, with the data frame below I would like to sort by column 'z' (descending) then by column 'b' (ascending):dd <- data.frame(b = factor(c(""Hi"", ""Med"", ""Hi"", ""Low""),       levels = c(""Low"", ""Med"", ""Hi""), ordered = TRUE),      x = c(""A"", ""D"", ""A"", ""C""), y = c(8, 3, 9, 9),      z = c(1, 1, 1, 2))dd    b x y z1  Hi A 8 12 Med D 3 13  Hi A 9 14 Low C 9 2","You can use the order() function directly without resorting to add-on tools -- see this simpler answer which uses a trick right from the top of the example(order) code:R> dd[with(dd, order(-z, b)), ]    b x y z4 Low C 9 22 Med D 3 11  Hi A 8 13  Hi A 9 1Edit some 2+ years later:  It was just asked how to do this by column index. The answer is to simply pass the desired sorting column(s) to the order() function:R> dd[order(-dd[,4], dd[,1]), ]    b x y z4 Low C 9 22 Med D 3 11  Hi A 8 13  Hi A 9 1R> rather than using the name of the column (and with() for easier/more direct access)."
"data_i","edited Mar 22 '16 at 13:59","
        UnicodeEncodeError: 'ascii' codec can't encode character u'\xa0' in position 20: ordinal not in range(128)
    ","I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup. The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.One of the sections of code that is causing problems is shown below:agent_telno = agent.find('div', 'agent_contact_number')agent_telno = '' if agent_telno is None else agent_telno.contents[0]p.agent_info = str(agent_contact + ' ' + agent_telno).strip()Here is a stack trace produced on SOME strings when the snippet above is run:Traceback (most recent call last):  File ""foobar.py"", line 792, in <module>    p.agent_info = str(agent_contact + ' ' + agent_telno).strip()UnicodeEncodeError: 'ascii' codec can't encode character u'\xa0' in position 20: ordinal not in range(128)I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?","Read the Python Unicode HOWTO. This error is the very first example.Do not use str() to convert from unicode to encoded text / bytes.Instead, use .encode() to encode the string:p.agent_info = u' '.join((agent_contact, agent_telno)).encode('utf-8').strip()or work entirely in unicode."
"data_i","edited Nov 12 '14 at 15:01","
        Activity restart on rotation Android
    ","In my Android application, when I rotate the device (slide out the keyboard) then my Activity is restarted (onCreate is called). Now, this is probably how it's supposed to be, but I do a lot of initial setting up in the onCreate method, so I need either:Put all the initial setting up in another function so it's not all lost on device rotation orMake it so onCreate is not called again and the layout just adjusts orLimit the app to just portrait so that onCreate is not called.","Using the Application ClassDepending on what you're doing in your initialization you could consider creating a new class that extends Application and moving your initialization code into an overridden onCreate method within that class.public class MyApplicationClass extends Application {  @Override  public void onCreate() {    super.onCreate();    // TODO Put your application initialization code here.  }}The onCreate in the application class is only called when the entire application is created, so the Activity restarts on orientation or keyboard visibility changes won't trigger it.It's good practice to expose the instance of this class as a singleton and exposing the application variables you're initializing using getters and setters.NOTE: You'll need to specify the name of your new Application class in the manifest for it to be registered and used:<application    android:name=""com.you.yourapp.MyApplicationClass""Reacting to Configuration Changes [UPDATE: this is deprecated since API 13; see the recommended alternative]As a further alternative, you can have your application listen for events that would cause a restart – like orientation and keyboard visibility changes – and handle them within your Activity.Start by adding the android:configChanges node to your Activity's manifest node <activity android:name="".MyActivity""      android:configChanges=""orientation|keyboardHidden""      android:label=""@string/app_name"">or for Android 3.2 (API level 13) and newer:<activity android:name="".MyActivity""      android:configChanges=""keyboardHidden|orientation|screenSize""      android:label=""@string/app_name"">Then within the Activity override the onConfigurationChanged method and call setContentView to force the GUI layout to be re-done in the new orientation.@Overridepublic void onConfigurationChanged(Configuration newConfig) {  super.onConfigurationChanged(newConfig);  setContentView(R.layout.myLayout);}"
"data_i","edited Jan 20 '20 at 14:04","
        Check synchronously if file/directory exists in Node.js
    ","How can I synchronously check, using node.js, if a file or directory exists?","The answer to this question has changed over the years. The current answer is here at the top, followed by the various answers over the years in chronological order:Current AnswerYou can use fs.existsSync():const fs = require(""fs""); // Or `import fs from ""fs"";` with ESMif (fs.existsSync(path)) {    // Do something}It was deprecated for several years, but no longer is. From the docs:Note that fs.exists() is deprecated, but fs.existsSync() is not. (The  callback parameter to fs.exists() accepts parameters that are  inconsistent with other Node.js callbacks. fs.existsSync() does not  use a callback.)You've specifically asked for a synchronous check, but if you can use an asynchronous check instead (usually best with I/O), use fs.promises.access if you're using async functions or fs.access (since exists is deprecated) if not:In an async function:try {    await fs.promises.access(""somefile"");    // The check succeeded} catch (error) {    // The check failed}Or with a callback:fs.access(""somefile"", error => {    if (!error) {        // The check succeeded    } else {        // The check failed    }});Historical AnswersHere are the historical answers in chronological order:Original answer from 2010(stat/statSync or lstat/lstatSync)Update September 2012(exists/existsSync)Update February 2015(Noting impending deprecation of exists/existsSync, so we're probably back to stat/statSync or lstat/lstatSync)Update December 2015(There's also fs.access(path, fs.F_OK, function(){}) / fs.accessSync(path, fs.F_OK), but note that if the file/directory doesn't exist, it's an error; docs for fs.stat recommend using fs.access if you need to check for existence without opening)Update December 2016fs.exists() is still deprecated but fs.existsSync() is no longer deprecated. So you can safely use it now.Original answer from 2010:You can use statSync or lstatSync (docs link), which give you an fs.Stats object. In general, if a synchronous version of a function is available, it will have the same name as the async version with Sync at the end. So statSync is the synchronous version of stat; lstatSync is the synchronous version of lstat, etc.lstatSync tells you both whether something exists, and if so, whether it's a file or a directory (or in some file systems, a symbolic link, block device, character device, etc.), e.g. if you need to know if it exists and is a directory:var fs = require('fs');try {    // Query the entry    stats = fs.lstatSync('/the/path');    // Is it a directory?    if (stats.isDirectory()) {        // Yes it is    }}catch (e) {    // ...}...and similarly, if it's a file, there's isFile; if it's a block device, there's isBlockDevice, etc., etc. Note the try/catch; it throws an error if the entry doesn't exist at all.If you don't care what the entry is and only want to know whether it exists, you can use path.existsSync (or with latest, fs.existsSync) as noted by user618408:var path = require('path');if (path.existsSync(""/the/path"")) { // or fs.existsSync    // ...}It doesn't require a try/catch but gives you no information about what the thing is, just that it's there. path.existsSync was deprecated long ago.Side note: You've expressly asked how to check synchronously, so I've used the xyzSync versions of the functions above. But wherever possible, with I/O, it really is best to avoid synchronous calls. Calls into the I/O subsystem take significant time from a CPU's point of view. Note how easy it is to call lstat rather than lstatSync:// Is it a directory?lstat('/the/path', function(err, stats) {    if (!err && stats.isDirectory()) {        // Yes it is    }});But if you need the synchronous version, it's there.Update September 2012The below answer from a couple of years ago is now a bit out of date. The current way is to use fs.existsSync to do a synchronous check for file/directory existence (or of course  fs.exists for an asynchronous check), rather than the path versions below.Example:var fs = require('fs');if (fs.existsSync(path)) {    // Do something}// Orfs.exists(path, function(exists) {    if (exists) {        // Do something    }});Update February 2015And here we are in 2015 and the Node docs now say that fs.existsSync (and fs.exists) ""will be deprecated"". (Because the Node folks think it's dumb to check whether something exists before opening it, which it is; but that's not the only reason for checking whether something exists!)So we're probably back to the various stat methods... Until/unless this changes yet again, of course.Update December 2015Don't know how long it's been there, but there's also fs.access(path, fs.F_OK, ...) / fs.accessSync(path, fs.F_OK). And at least as of October 2016, the fs.stat documentation recommends using fs.access to do existence checks (""To check if a file exists without manipulating it afterwards, fs.access() is recommended.""). But note that the access not being available is considered an error, so this would probably be best if you're expecting the file to be accessible:var fs = require('fs');try {    fs.accessSync(path, fs.F_OK);    // Do something} catch (e) {    // It isn't accessible}// Orfs.access(path, fs.F_OK, function(err) {    if (!err) {        // Do something    } else {        // It isn't accessible    }});Update December 2016You can use fs.existsSync():if (fs.existsSync(path)) {    // Do something}It was deprecated for several years, but no longer is. From the docs:Note that fs.exists() is deprecated, but fs.existsSync() is not. (The  callback parameter to fs.exists() accepts parameters that are  inconsistent with other Node.js callbacks. fs.existsSync() does not  use a callback.)"
"data_i","edited Feb 07 '19 at 14:57","
        How can I drop all the tables in a PostgreSQL database?
    ","How can I drop all tables in PostgreSQL, working from the command line?I don't want to drop the database itself, just all tables and all the data in them.","If all of your tables are in a single schema, this approach could work (below code assumes that the name of your schema is public)DROP SCHEMA public CASCADE;CREATE SCHEMA public;If you are using PostgreSQL 9.3 or greater, you may also need to restore the default grants.GRANT ALL ON SCHEMA public TO postgres;GRANT ALL ON SCHEMA public TO public;"
"data_i","edited Jun 11 '22 at 10:01","
        How to fix npm throwing error without sudo
    ","I just installed node and npm through the package on nodejs.org, and whenever I try to search or install something with npm, it throws the following error unless I sudo the command.  I have a feeling this is a permissions issue?  I am already the admin.npm ERR! Error: EACCES, open '/Users/chietala/.npm/-/all/.cache.json'npm ERR!  { [Error: EACCES, open '/Users/chietala/.npm/-/all/.cache.json']npm ERR!   errno: 3,npm ERR!   code: 'EACCES',npm ERR!   path: '/Users/chietala/.npm/-/all/.cache.json' }npm ERR! npm ERR! Please try running this command again as root/Administrator.npm ERR! System Darwin 12.2.0npm ERR! command ""node"" ""/usr/local/bin/npm"" ""search"" ""bower""npm ERR! cwd /Users/chietalanpm ERR! node -v v0.10.4npm ERR! npm -v 1.2.18npm ERR! path /Users/chietala/.npm/-/all/.cache.jsonnpm ERR! code EACCESnpm ERR! errno 3npm ERR! stack Error: EACCES, open '/Users/chietala/.npm/-/all/.cache.json'npm ERR! npm ERR! Additional logging details can be found in:npm ERR!     /Users/chietala/npm-debug.lognpm ERR! not ok code 0","This looks like a permissions issue in your home directory. To reclaim ownership of the .npm directory execute:sudo chown -R $(whoami) ~/.npm"
"data_i","asked May 08 '09 at 15:49","
        How do function pointers in C work?
    ","I had some experience lately with function pointers in C.So going on with the tradition of answering your own questions, I decided to make a small summary of the very basics, for those who need a quick dive-in to the subject.","Function pointers in CLet's start with a basic function which we will be pointing to:int addInt(int n, int m) {    return n+m;}First thing, let's define a pointer to a function which receives 2 ints and returns an int:int (*functionPtr)(int,int);Now we can safely point to our function:functionPtr = &addInt;Now that we have a pointer to the function, let's use it:int sum = (*functionPtr)(2, 3); // sum == 5Passing the pointer to another function is basically the same:int add2to3(int (*functionPtr)(int, int)) {    return (*functionPtr)(2, 3);}We can use function pointers in return values as well (try to keep up, it gets messy):// this is a function called functionFactory which receives parameter n// and returns a pointer to another function which receives two ints// and it returns another intint (*functionFactory(int n))(int, int) {    printf(""Got parameter %d"", n);    int (*functionPtr)(int,int) = &addInt;    return functionPtr;}But it's much nicer to use a typedef:typedef int (*myFuncDef)(int, int);// note that the typedef name is indeed myFuncDefmyFuncDef functionFactory(int n) {    printf(""Got parameter %d"", n);    myFuncDef functionPtr = &addInt;    return functionPtr;}"
"data_i","edited Feb 12 '19 at 08:57","
        What is the difference between gravity and layout_gravity in Android?
    ","I know we can set the following values to the android:gravity and  android:layout_gravity properties:centercenter_verticalcenter_horizontal, etc.But I am confused regarding both of these.What is the difference between the usage of android:gravity and android:layout_gravity?","Their names should help you:android:gravity sets the gravity of the contents (i.e. its subviews) of the View it's used on.  android:layout_gravity sets the gravity of the View or Layout relative to its parent.  And an example is here."
"data_i","edited Sep 26 '11 at 15:39","
        What is the single most influential book every programmer should read?
    ","If you could go back in time and tell yourself to read a specific book at the beginning of your career as a developer, which book would it be?I expect this list to be varied and to cover a wide range of things.To search: Use the search box in the upper-right corner. To search the answers of the current question, use inquestion:this.  For example:inquestion:this ""Code Complete""","Code Complete (2nd edition) by Steve McConnellThe Pragmatic ProgrammerStructure and Interpretation of Computer ProgramsThe C Programming Language by Kernighan and RitchieIntroduction to Algorithms by Cormen, Leiserson, Rivest & SteinDesign Patterns by the Gang of FourRefactoring: Improving the Design of Existing CodeThe Mythical Man MonthThe Art of Computer Programming by Donald KnuthCompilers: Principles, Techniques and Tools by Alfred V. Aho, Ravi Sethi and Jeffrey D. UllmanGödel, Escher, Bach by Douglas HofstadterClean Code: A Handbook of Agile Software Craftsmanship by Robert C. MartinEffective C++More Effective C++CODE by Charles PetzoldProgramming Pearls by Jon BentleyWorking Effectively with Legacy Code by Michael C. FeathersPeopleware by Demarco and ListerCoders at Work by Peter SeibelSurely You're Joking, Mr. Feynman!Effective Java 2nd editionPatterns of Enterprise Application Architecture by Martin FowlerThe Little SchemerThe Seasoned SchemerWhy's (Poignant) Guide to RubyThe Inmates Are Running The Asylum: Why High Tech Products Drive Us Crazy and How to Restore the SanityThe Art of Unix ProgrammingTest-Driven Development: By Example by Kent BeckPractices of an Agile DeveloperDon't Make Me ThinkAgile Software Development, Principles, Patterns, and Practices by Robert C. MartinDomain Driven Designs by Eric EvansThe Design of Everyday Things by Donald NormanModern C++ Design by Andrei AlexandrescuBest Software Writing I by Joel SpolskyThe Practice of Programming by Kernighan and PikePragmatic Thinking and Learning: Refactor Your Wetware by Andy HuntSoftware Estimation: Demystifying the Black Art by Steve McConnelThe Passionate Programmer (My Job Went To India) by Chad FowlerHackers: Heroes of the Computer RevolutionAlgorithms + Data Structures = ProgramsWriting Solid CodeJavaScript - The Good PartsGetting Real by 37 SignalsFoundations of Programming by Karl SeguinComputer Graphics: Principles and Practice in C (2nd Edition)Thinking in Java by Bruce EckelThe Elements of Computing SystemsRefactoring to Patterns by Joshua KerievskyModern Operating Systems by Andrew S. TanenbaumThe Annotated TuringThings That Make Us Smart by Donald NormanThe Timeless Way of Building by Christopher AlexanderThe Deadline: A Novel About Project Management by Tom DeMarcoThe C++ Programming Language (3rd edition) by StroustrupPatterns of Enterprise Application ArchitectureComputer Systems - A Programmer's PerspectiveAgile Principles, Patterns, and Practices in C# by Robert C. MartinGrowing Object-Oriented Software, Guided by TestsFramework Design Guidelines by Brad AbramsObject Thinking by Dr. David WestAdvanced Programming in the UNIX Environment by W. Richard StevensHackers and Painters: Big Ideas from the Computer AgeThe Soul of a New Machine by Tracy KidderCLR via C# by Jeffrey RichterThe Timeless Way of Building by Christopher AlexanderDesign Patterns in C# by Steve MetskerAlice in Wonderland by Lewis CarolZen and the Art of Motorcycle Maintenance by Robert M. PirsigAbout Face - The Essentials of Interaction DesignHere Comes Everybody: The Power of Organizing Without Organizations by Clay ShirkyThe Tao of ProgrammingComputational Beauty of NatureWriting Solid Code by Steve MaguirePhilip and Alex's Guide to Web PublishingObject-Oriented Analysis and Design with Applications by Grady BoochEffective Java by Joshua BlochComputability by N. J. CutlandMasterminds of ProgrammingThe Tao Te ChingThe Productive ProgrammerThe Art of Deception by Kevin MitnickThe Career Programmer: Guerilla Tactics for an Imperfect World by Christopher DuncanParadigms of Artificial Intelligence Programming: Case studies in Common LispMasters of DoomPragmatic Unit Testing in C# with NUnit by Andy Hunt and Dave Thomas with Matt HargettHow To Solve It by George PolyaThe Alchemist by Paulo CoelhoSmalltalk-80: The Language and its ImplementationWriting Secure Code (2nd Edition) by Michael HowardIntroduction to Functional Programming by Philip Wadler and Richard BirdNo Bugs! by David Thielen Rework by Jason Freid and DHHJUnit in Action"
"data_i","edited Dec 02 '21 at 02:18","
        Relative imports for the billionth time
    ","I've been here:http://www.python.org/dev/peps/pep-0328/http://docs.python.org/2/tutorial/modules.html#packagesPython packages: relative importspython relative import example code does not workRelative imports in python 2.5Relative imports in PythonPython: Disabling relative importand plenty of URLs that I did not copy, some on SO, some on other sites, back when I thought I'd have the solution quickly.The forever-recurring question is this: how do I solve this ""Attempted relative import in non-package"" message?ImportError: attempted relative import with no known parent packageI built an exact replica of the package on pep-0328:package/    __init__.py    subpackage1/        __init__.py        moduleX.py        moduleY.py    subpackage2/        __init__.py        moduleZ.py    moduleA.pyThe imports were done from the console.I did make functions named spam and eggs in their appropriate modules.  Naturally, it didn't work.  The answer is apparently in the 4th URL I listed, but it's all alumni to me. There was this response on one of the URLs I visited:Relative imports use a module's name attribute to determine that module's position in the package hierarchy. If the module's name does not contain any package information (e.g. it is set to 'main') then relative imports are resolved as if the module were a top level module, regardless of where the module is actually located on the file system.The above response looks promising, but it's all hieroglyphs to me.  So my question, how do I make Python not return to me ""Attempted relative import in non-package""? has an answer that involves -m, supposedly.Can somebody please tell me why Python gives that error message, what it means by ""non-package"", why and how do you define a 'package', and the precise answer put in terms easy enough for a kindergartener to understand.","Script vs. ModuleHere's an explanation.  The short version is that there is a big difference between directly running a Python file, and importing that file from somewhere else.  Just knowing what directory a file is in does not determine what package Python thinks it is in.  That depends, additionally, on how you load the file into Python (by running or by importing).There are two ways to load a Python file: as the top-level script, or as amodule.  A file is loaded as the top-level script if you execute it directly, for instance by typing python myfile.py on the command line.  It is loaded as a module when an import statement is encountered inside some other file.  There can only be one top-level script at a time; the top-level script is the Python file you ran to start things off.NamingWhen a file is loaded, it is given a name (which is stored in its __name__ attribute).If it was loaded as the top-level script, its name is __main__.If it was loaded as a module, its name is [ the filename, preceded by the names of any packages/subpackages of which it is a part, separated by dots ], for example, package.subpackage1.moduleX.But be aware, if you load moduleX as a module from shell command line using something like python -m package.subpackage1.moduleX, the __name__ will still be __main__.So for instance in your example:package/    __init__.py    subpackage1/        __init__.py        moduleX.py    moduleA.pyif you imported moduleX (note: imported, not directly executed), its name would be package.subpackage1.moduleX.  If you imported moduleA, its name would be package.moduleA.  However, if you directly run moduleX from the command line, its name will instead be __main__, and if you directly run moduleA from the command line, its name will be __main__.  When a module is run as the top-level script, it loses its normal name and its name is instead __main__.Accessing a module NOT through its containing packageThere is an additional wrinkle: the module's name depends on whether it was imported ""directly"" from the directory it is in or imported via a package.  This only makes a difference if you run Python in a directory, and try to import a file in that same directory (or a subdirectory of it).  For instance, if you start the Python interpreter in the directory package/subpackage1 and then do import moduleX, the name of moduleX will just be moduleX, and not package.subpackage1.moduleX.  This is because Python adds the current directory to its search path when the interpreter is entered interactively; if it finds the to-be-imported module in the current directory, it will not know that that directory is part of a package, and the package information will not become part of the module's name.A special case is if you run the interpreter interactively (e.g., just type python and start entering Python code on the fly).  In this case, the name of that interactive session is __main__.Now here is the crucial thing for your error message: if a module's name has no dots, it is not considered to be part of a package.  It doesn't matter where the file actually is on disk.  All that matters is what its name is, and its name depends on how you loaded it.Now look at the quote you included in your question:Relative imports use a module's name attribute to determine that module's position in the package hierarchy. If the module's name does not contain any package information (e.g. it is set to 'main') then relative imports are resolved as if the module were a top-level module, regardless of where the module is actually located on the file system.Relative imports...Relative imports use the module's name to determine where it is in a package.  When you use a relative import like from .. import foo, the dots indicate to step up some number of levels in the package hierarchy.  For instance, if your current module's name is package.subpackage1.moduleX, then ..moduleA would mean package.moduleA.  For a from .. import to work, the module's name must have at least as many dots as there are in the import statement.... are only relative in a packageHowever, if your module's name is __main__, it is not considered to be in a package.  Its name has no dots, and therefore you cannot use from .. import statements inside it.  If you try to do so, you will get the ""relative-import in non-package"" error.Scripts can't import relativeWhat you probably did is you tried to run moduleX or the like from the command line.  When you did this, its name was set to __main__, which means that relative imports within it will fail, because its name does not reveal that it is in a package. Note that this will also happen if you run Python from the same directory where a module is, and then try to import that module, because, as described above, Python will find the module in the current directory ""too early"" without realizing it is part of a package.Also remember that when you run the interactive interpreter, the ""name"" of that interactive session is always __main__.  Thus you cannot do relative imports directly from an interactive session.  Relative imports are only for use within module files.Two solutions:If you really do want to run moduleX directly, but you still want it to be considered part of a package, you can do python -m package.subpackage1.moduleX.  The -m tells Python to load it as a module, not as the top-level script.Or perhaps you don't actually want to run moduleX, you just want to run some other script, say myfile.py, that uses functions inside moduleX.  If that is the case, put myfile.py somewhere else – not inside the package directory – and run it.  If inside myfile.py you do things like from package.moduleA import spam, it will work fine.NotesFor either of these solutions, the package directory (package in your example) must be accessible from the Python module search path (sys.path).  If it is not, you will not be able to use anything in the package reliably at all.Since Python 2.6, the module's ""name"" for package-resolution purposes is determined not just by its __name__ attributes but also by the __package__ attribute.  That's why I'm avoiding using the explicit symbol __name__ to refer to the module's ""name"".  Since Python 2.6 a module's ""name"" is effectively __package__ + '.' + __name__, or just __name__ if __package__ is None.)"
"data_i","edited Sep 08 '13 at 16:10","
        Check if element exists in jQuery
    ","How do I check if an element exists if the element is created by .append() method?$('elemId').length doesn't work for me.","$('elemId').length doesn't work for  me.You need to put # before element id:$('#elemId').length---^With vanilla JavaScript, you don't need the hash (#) e.g. document.getElementById('id_here') , however when using jQuery, you do need to put hash to target elements based on id just like CSS."
"data_i","edited Dec 25 '13 at 02:00","
        What's a quick way to comment/uncomment lines in Vim?
    ","I have a Ruby code file open in vi, there are lines commented out with #:class Search < ActiveRecord::Migration  def self.up    # create_table :searches do |t|    #   t.integer :user_id    #   t.string :name    #   t.string :all_of    #   t.string :any_of    #   t.string :none_of    #   t.string :exact_phrase    #     #   t.timestamps    # end  end  def self.down    # drop_table :searches  endendSay I want to uncomment all the lines in the first def ... end section. What's an efficient way to do that in Vim?In general, I'm looking for an easy and fluid way to comment and uncomment lines. Here I'm dealing with Ruby code, but it could be JavaScript (//) or Haml (-#).","For those tasks I use most of the time block selection.Put your cursor on the first # character, press CtrlV (or CtrlQ for gVim), and go down until the last commented line and press x, that will delete all the # characters vertically.For commenting a block of text is almost the same: First, go to the first line you want to comment, press CtrlV. This will put the editor in the VISUAL BLOCK mode.Then using the arrow key and select until the last lineNow press ShiftI, which will put the editor in INSERT mode and then press #. This will add a hash to the first line. Then press Esc (give it a second), and it will insert a # character on all other selected lines. For the stripped-down version of vim shipped with debian/ubuntu by default, type : s/^/# in the third step instead (any remaining highlighting of the first character of each line can be removed with :nohl).Here are two small screen recordings for visual reference.Comment:Uncomment:"
"data_i","edited Nov 14 '19 at 13:48","
        Ignoring directories in Git repositories on Windows
    ","How can I ignore directories or folders in Git using msysgit on Windows?","Create a file named .gitignore in your project's directory. Ignore directories by entering the directory name into the file (with a slash appended):dir_to_ignore/More information is here."
"data_i","edited May 14 '22 at 19:47","
        How can I revert multiple Git commits?
    ","I have a Git repository that looks like this:A <- B <- C <- D <- HEADI want the head of the branch to point to A, i.e., I want B, C, D, and HEAD to disappear and I want head to be synonymous with A.It sounds like I can either try to rebase (doesn't apply, since I've pushed changes in between), or revert. But how do I revert multiple commits? Do I revert one at a time? Is the order important?","Expanding what I wrote in a commentThe general rule is that you should not rewrite (change) history that you have published, because somebody might have based their work on it.  If you rewrite (change) history, you would make problems with merging their changes and with updating for them.So the solution is to create a new commit which reverts changes that you want to get rid of.  You can do this using git revert command.You have the following situation:A <-- B  <-- C <-- D                                  <-- master <-- HEAD(arrows here refers to the direction of the pointer: the ""parent"" reference in the case of commits, the top commit in the case of branch head (branch ref), and the name of branch in the case of HEAD reference).What you need to create is the following:A <-- B  <-- C <-- D <-- [(BCD)-1]                   <-- master <-- HEADwhere [(BCD)^-1] means the commit that reverts changes in commits B, C, D.  Mathematics tells us that (BCD)-1 = D-1 C-1 B-1, so you can get the required situation using the following commands:$ git revert --no-commit D$ git revert --no-commit C$ git revert --no-commit B$ git commit -m ""the commit message for all of them""Works for everything except merge commits.Alternate solution would be to checkout contents of commit A, and commit this state.  Also works with merge commits.  Added files will not be deleted, however.  If you have any local changes git stash them first:$ git checkout -f A -- . # checkout that revision over the top of local files$ git commit -aThen you would have the following situation:A <-- B  <-- C <-- D <-- A'                       <-- master <-- HEADThe commit A' has the same contents as commit A, but is a different commit (commit message, parents, commit date).Alternate solution by Jeff Ferland, modified by Charles Bailey builds upon the same idea, but uses git reset.  Here it is slightly modified, this way WORKS FOR EVERYTHING:$ git reset --hard A$ git reset --soft D # (or ORIG_HEAD or @{1} [previous location of HEAD]), all of which are D$ git commit"
"data_i","edited Mar 06 '20 at 20:02","
        Check if checkbox is checked with jQuery
    ","How can I check if a checkbox in a checkbox array is checked using the id of the checkbox array?I am using the following code, but it always returns the count of checked checkboxes regardless of id.function isCheckedById(id) {    alert(id);    var checked = $(""input[@id="" + id + ""]:checked"").length;    alert(checked);    if (checked == 0) {        return false;    } else {        return true;    }}","$('#' + id).is("":checked"")That gets if the checkbox is checked.For an array of checkboxes with the same name you can get the list of checked ones by:var $boxes = $('input[name=thename]:checked');Then to loop through them and see what's checked you can do:$boxes.each(function(){    // Do stuff here with this});To find how many are checked you can do:$boxes.length;"
"data_i","edited Apr 27 '18 at 08:52","
        Virtual member call in a constructor
    ","I'm getting a warning from ReSharper about a call to a virtual member from my objects constructor. Why would this be something not to do?","When an object written in C# is constructed, what happens is that the initializers run in order from the most derived class to the base class, and then constructors run in order from the base class to the most derived class (see Eric Lippert's blog for details as to why this is).Also in .NET objects do not change type as they are constructed, but start out as the most derived type, with the method table being for the most derived type. This means that virtual method calls always run on the most derived type.When you combine these two facts you are left with the problem that if you make a virtual method call in a constructor, and it is not the most derived type in its inheritance hierarchy, that it will be called on a class whose constructor has not been run, and therefore may not be in a suitable state to have that method called. This problem is, of course, mitigated if you mark your class as sealed to ensure that it is the most derived type in the inheritance hierarchy - in which case it is perfectly safe to call the virtual method."
"data_i","edited Aug 17 '22 at 07:09","
        String formatting: % vs. .format vs. f-string literal
    ","There are various string formatting methods:Python <2.6: ""Hello %s"" % namePython 2.6+: ""Hello {}"".format(name)   (uses str.format)Python 3.6+: f""{name}""   (uses f-strings)Which is better, and for what situations?The following methods have the same outcome, so what is the difference?name = ""Alice""""Hello %s"" % name""Hello {0}"".format(name)f""Hello {name}""# Using named arguments:""Hello %(kwarg)s"" % {'kwarg': name}""Hello {kwarg}"".format(kwarg=name)f""Hello {name}""When does string formatting run, and how do I avoid a runtime performance penalty?If you are trying to close a duplicate question that is just looking for a way to format a string, please use How do I put a variable’s value inside a string?.","To answer your first question... .format just seems more sophisticated in many ways. An annoying thing about % is also how it can either take a variable or a tuple. You'd think the following would always work:""Hello %s"" % nameyet, if name happens to be (1, 2, 3), it will throw a TypeError. To guarantee that it always prints, you'd need to do""Hello %s"" % (name,)   # supply the single argument as a single-item tuplewhich is just ugly. .format doesn't have those issues. Also in the second example you gave, the .format example is much cleaner looking.Only use it for backwards compatibility with Python 2.5.To answer your second question, string formatting happens at the same time as any other operation - when the string formatting expression is evaluated. And Python, not being a lazy language, evaluates expressions before calling functions, so the expression log.debug(""some debug info: %s"" % some_info) will first evaluate the string to, e.g. ""some debug info: roflcopters are active"", then that string will be passed to log.debug()."
"data_i","edited Jun 25 '20 at 12:07","
        Deleting array elements in JavaScript - delete vs splice
    ","What is the difference between using the delete operator on the array element as opposed to using the Array.splice method? For example:myArray = ['a', 'b', 'c', 'd'];delete myArray[1];//  ormyArray.splice (1, 1);Why even have the splice method if I can delete array elements like I can with objects?","delete will delete the object property, but will not reindex the array or update its length. This makes it appears as if it is undefined:> myArray = ['a', 'b', 'c', 'd']  [""a"", ""b"", ""c"", ""d""]> delete myArray[0]  true> myArray[0]  undefinedNote that it is not in fact set to the value undefined, rather the property is removed from the array, making it appear undefined. The Chrome dev tools make this distinction clear by printing empty when logging the array.> myArray[0]  undefined> myArray  [empty, ""b"", ""c"", ""d""]myArray.splice(start, deleteCount) actually removes the element, reindexes the array, and changes its length.> myArray = ['a', 'b', 'c', 'd']  [""a"", ""b"", ""c"", ""d""]> myArray.splice(0, 2)  [""a"", ""b""]> myArray  [""c"", ""d""]"
"data_i","edited Jun 13 '22 at 07:04","
        What is setup.py?
    ","What is setup.py and how can it be configured or used?","setup.py is a python file, the presence of which is an indication that the module/package you are about to install has likely been packaged and distributed with Distutils, which is the standard for distributing Python Modules.This allows you to easily install Python packages. Often it's enough to write:$ pip install . pip will use setup.py to install your module. Avoid calling setup.py directly.https://docs.python.org/3/installing/index.html#installing-index"
"data_i","edited Feb 03 '15 at 15:01","
        Path.Combine for URLs?
    ","Path.Combine is handy, but is there a similar function in the .NET framework for URLs?I'm looking for syntax like this:Url.Combine(""http://MyUrl.com/"", ""/Images/Image.jpg"")which would return:""http://MyUrl.com/Images/Image.jpg""","Uri has a constructor that should do this for you: new Uri(Uri baseUri, string relativeUri)Here's an example:Uri baseUri = new Uri(""http://www.contoso.com"");Uri myUri = new Uri(baseUri, ""catalog/shownew.htm"");Note from editor: Beware, this method does not work as expected. It can cut part of baseUri in some cases. See comments and other answers."
"data_i","edited Jul 20 '20 at 04:54","
        What is the difference between a field and a property?
    ","In C#, what makes a field different from a property, and when should a field be used instead of a property?","Properties expose fields.  Fields should (almost always) be kept private to a class and accessed via get and set properties.  Properties provide a level of abstraction allowing you to change the fields while not affecting the external way they are accessed by the things that use your class.public class MyClass{    // this is a field.  It is private to your class and stores the actual data.    private string _myField;    // this is a property. When accessed it uses the underlying field,    // but only exposes the contract, which will not be affected by the underlying field    public string MyProperty    {        get        {            return _myField;        }        set        {            _myField = value;        }    }    // This is an AutoProperty (C# 3.0 and higher) - which is a shorthand syntax    // used to generate a private field for you    public int AnotherProperty { get; set; } }@Kent points out that Properties are not required to encapsulate fields, they could do a calculation on other fields, or serve other purposes.@GSS points out that you can also do other logic, such as validation, when a property is accessed, another useful feature."
"data_i","edited Apr 18 '17 at 21:56","
        How do you rename a Git tag?
    ","Today I was looking through the logs for a project and realized that I fat fingered a tag name some time ago. Is there some way to rename the tag? Google hasn't turned up anything useful.I realize I could check out the tagged version and make a new tag, I even tried that. But that seems to create a tag object that isn't quite right. For one,git tag -llists it out of order relative to all of the other tags. I have no idea if that's significant, but it leads me to believe that the new tag object isn't quite what I want. I can live with that, because I really only care that the tag name matches the documentation, but I'd rather do it ""right"", assuming there is a right way to do this.","Here is how I rename a tag old to new:git tag new oldgit tag -d oldgit push origin new :oldThe colon in the push command removes the tag from the remote repository. Ifyou don't do this, Git will create the old tag on your machine when you pull.Finally, make sure that the other users remove the deleted tag. Please tellthem (co-workers) to run the following command:git pull --prune --tagsNote that if you are changing an annotated tag, you need ensure that thenew tag name is referencing the underlying commit and not the old annotated tagobject that you're about to delete. Therefore, use git tag -a new old^{}instead of git tag new old (this is because annotated tags are objects whilelightweight tags are not, more info in this answer)."
"data_i","edited Apr 19 '20 at 11:22","
        Can I concatenate multiple MySQL rows into one field?
    ","Using MySQL, I can do something like:SELECT hobbies FROM peoples_hobbies WHERE person_id = 5;My Output:shoppingfishingcodingbut instead I just want 1 row, 1 col:Expected Output:shopping, fishing, codingThe reason is that I'm selecting multiple values from multiple tables, and after all the joins I've got a lot more rows than I'd like.I've looked for a function on MySQL Doc and it doesn't look like the CONCAT or CONCAT_WS functions accept result sets.So does anyone here know how to do this?","You can use GROUP_CONCAT:SELECT person_id,   GROUP_CONCAT(hobbies SEPARATOR ', ')FROM peoples_hobbiesGROUP BY person_id;As Ludwig stated in his comment, you can add the DISTINCT operator to avoid duplicates:SELECT person_id,   GROUP_CONCAT(DISTINCT hobbies SEPARATOR ', ')FROM peoples_hobbiesGROUP BY person_id;As Jan stated in their comment, you can also sort the values before imploding it using ORDER BY:SELECT person_id,        GROUP_CONCAT(hobbies ORDER BY hobbies ASC SEPARATOR ', ')FROM peoples_hobbiesGROUP BY person_id;As Dag stated in his comment, there is a 1024 byte limit on the result. To solve this, run this query before your query:SET group_concat_max_len = 2048;Of course, you can change 2048 according to your needs. To calculate and assign the value:SET group_concat_max_len = CAST(                     (SELECT SUM(LENGTH(hobbies)) + COUNT(*) * LENGTH(', ')                           FROM peoples_hobbies                           GROUP BY person_id) AS UNSIGNED);"
"data_i","edited Aug 09 '20 at 11:41","
        What is Gradle in Android Studio?
    ","Gradle is a bit confusing to me, and also for any new Android developer. Can anyone explain what Gradle in Android Studio is and what its purpose is? Why is it included in Android Studio?","Short AnswerGradle is a build system.Long AnswerBefore Android Studio you were using Eclipse for your development purposes, and, chances are, you didn't know how to build your Android APK without Eclipse.You can do this on the command line, but you have to learn what each tool (dx and AAPT) does in the SDK.Eclipse saved us all from these low-level, but important, fundamental details by giving us their own build system.Now, have you ever wondered why the res folder is in the same directory as your src folder?This is where the build system enters the picture. The build system automatically takes all the source files (.java or .xml), then applies the appropriate tool (e.g., takes .java class files and converts them to .dex files), and groups all of them into one compressed file - our beloved APK.This build system uses some conventions: an example of one is to specify the directory containing the source files (in Eclipse it is \src folder) or resources files (in Eclipse it is \res folder).Now, in order to automate all these tasks, there has to be a script; you can write your own build system using shell scripting in Linux or batch files syntax in Windows. Got it?Gradle is another build system that takes the best features from other build systems and combines them into one. It is improved based off of their shortcomings. It is a JVM-based build system. That means you can write your own script in Java, which Android Studio makes use of.One cool thing about Gradle is that it is a plugin-based system. This means if you have your own programming language and you want to automate the task of building some package (output like a JAR file for Java) from sources, then you can write a complete plugin in Java or Groovy (or Kotlin, see here), and distribute it to the rest of the world.Why did Google use it?Google saw one of the most advanced build systems on the market and realized that you could write scripts of your own with little-to-no learning curve, and without learning Groovy or any other new language. So they wrote the Android plugin for Gradle.You must have seen build.gradle file(s) in your project. That is where you can write scripts to automate your tasks. The code you saw in these files is Groovy code. If you write System.out.println(""Hello Gradle!""); then it will print on your console.What can you do in a build script?A simple example is that you have to copy some files from one directory to another before the actual build process happens. A Gradle build script can do this."
"data_i","edited Sep 08 '20 at 07:54","
        What is the ""right"" JSON date format?
    ","I've seen so many different standards for the JSON date format:""\""\\/Date(1335205592410)\\/\""""         .NET JavaScriptSerializer""\""\\/Date(1335205592410-0500)\\/\""""    .NET DataContractJsonSerializer""2012-04-23T18:25:43.511Z""              JavaScript built-in JSON object""2012-04-21T18:25:43-05:00""             ISO 8601Which one is the right one? Or best? Is there any sort of standard on this?","JSON itself does not specify how dates should be represented, but JavaScript does.You should use the format emitted by Date's toJSON method:2012-04-23T18:25:43.511ZHere's why:It's human readable but also succinctIt sorts correctlyIt includes fractional seconds, which can help re-establish chronologyIt conforms to ISO 8601ISO 8601 has been well-established internationally for more than a decadeISO 8601 is endorsed by W3C, RFC3339, and XKCDThat being said, every date library ever written can understand ""milliseconds since 1970"". So for easy portability, ThiefMaster is right."
"data_i","edited May 03 '18 at 14:57","
        Turning off auto indent when pasting text into vim
    ","I am making the effort to learn Vim.When I paste code into my document from the clipboard, I get extra spaces at the start of each new line:line  line    lineI know you can turn off auto indent but I can't get it to work because I have some other settings conflicting or something (which look pretty obvious in my .vimrc but don't seem to matter when I take them out). How do I turn off auto indenting when I paste code but still have vim auto indent when I am writing code?  Here is my .vimrc file:set expandtab  set tabstop=2  set shiftwidth=2  set autoindent  set smartindent  set bg=dark  set nowrap  ","Update: Better answer here: https://stackoverflow.com/a/38258720/62202To turn off autoindent when you paste code, there's a special ""paste"" mode.Type :set pasteThen paste your code.  Note that the text in the tooltip now says -- INSERT (paste) --.After you pasted your code, turn off the paste-mode, so that auto-indenting when you type works correctly again.:set nopasteHowever, I always found that cumbersome.  That's why I map <F3> such that it can switch between paste and nopaste modes while editing the text!  I add this to .vimrcset pastetoggle=<F3>"
"data_i","edited Jan 20 '19 at 13:47","
        How to change the order of DataFrame columns?
    ","I have the following DataFrame (df):import numpy as npimport pandas as pddf = pd.DataFrame(np.random.rand(10, 5))I add more column(s) by assignment:df['mean'] = df.mean(1)How can I move the column mean to the front, i.e. set it as first column leaving the order of the other columns untouched?","One easy way would be to reassign the dataframe with a list of the columns, rearranged as needed. This is what you have now: In [6]: dfOut[6]:          0         1         2         3         4      mean0  0.445598  0.173835  0.343415  0.682252  0.582616  0.4455431  0.881592  0.696942  0.702232  0.696724  0.373551  0.6702082  0.662527  0.955193  0.131016  0.609548  0.804694  0.6325963  0.260919  0.783467  0.593433  0.033426  0.512019  0.4366534  0.131842  0.799367  0.182828  0.683330  0.019485  0.3633715  0.498784  0.873495  0.383811  0.699289  0.480447  0.5871656  0.388771  0.395757  0.745237  0.628406  0.784473  0.5885297  0.147986  0.459451  0.310961  0.706435  0.100914  0.3451498  0.394947  0.863494  0.585030  0.565944  0.356561  0.5531959  0.689260  0.865243  0.136481  0.386582  0.730399  0.561593In [7]: cols = df.columns.tolist()In [8]: colsOut[8]: [0L, 1L, 2L, 3L, 4L, 'mean']Rearrange cols in any way you want. This is how I moved the last element to the first position: In [12]: cols = cols[-1:] + cols[:-1]In [13]: colsOut[13]: ['mean', 0L, 1L, 2L, 3L, 4L]Then reorder the dataframe like this: In [16]: df = df[cols]  #    OR    df = df.ix[:, cols]In [17]: dfOut[17]:       mean         0         1         2         3         40  0.445543  0.445598  0.173835  0.343415  0.682252  0.5826161  0.670208  0.881592  0.696942  0.702232  0.696724  0.3735512  0.632596  0.662527  0.955193  0.131016  0.609548  0.8046943  0.436653  0.260919  0.783467  0.593433  0.033426  0.5120194  0.363371  0.131842  0.799367  0.182828  0.683330  0.0194855  0.587165  0.498784  0.873495  0.383811  0.699289  0.4804476  0.588529  0.388771  0.395757  0.745237  0.628406  0.7844737  0.345149  0.147986  0.459451  0.310961  0.706435  0.1009148  0.553195  0.394947  0.863494  0.585030  0.565944  0.3565619  0.561593  0.689260  0.865243  0.136481  0.386582  0.730399"
"data_i","edited Aug 16 '22 at 16:09","
        How to put the legend outside the plot
    ","I have a series of 20 plots (not subplots) to be made in a single figure. I want the legend to be outside of the box. At the same time, I do not want to change the axes, as the size of the figure gets reduced.I want to keep the legend box outside the plot area (I want the legend to be outside at the right side of the plot area).Is there a way that I reduce the font size of the text inside the legend box, so that the size of the legend box will be small?","There are a number of ways to do what you want.  To add to what Christian Alis and Navi already said, you can use the bbox_to_anchor keyword argument to place the legend partially outside the axes and/or decrease the font size.Before you consider decreasing the font size (which can make things awfully hard to read), try playing around with placing the legend in different places:So, let's start with a generic example:import matplotlib.pyplot as pltimport numpy as npx = np.arange(10)fig = plt.figure()ax = plt.subplot(111)for i in xrange(5):    ax.plot(x, i * x, label='$y = %ix$' % i)ax.legend()plt.show()If we do the same thing, but use the bbox_to_anchor keyword argument we can shift the legend slightly outside the axes boundaries:import matplotlib.pyplot as pltimport numpy as npx = np.arange(10)fig = plt.figure()ax = plt.subplot(111)for i in xrange(5):    ax.plot(x, i * x, label='$y = %ix$' % i)ax.legend(bbox_to_anchor=(1.1, 1.05))plt.show()Similarly, make the legend more horizontal and/or put it at the top of the figure (I'm also turning on rounded corners and a simple drop shadow):import matplotlib.pyplot as pltimport numpy as npx = np.arange(10)fig = plt.figure()ax = plt.subplot(111)for i in xrange(5):    line, = ax.plot(x, i * x, label='$y = %ix$'%i)ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.05),          ncol=3, fancybox=True, shadow=True)plt.show()Alternatively, shrink the current plot's width, and put the legend entirely outside the axis of the figure (note: if you use tight_layout(), then leave out ax.set_position():import matplotlib.pyplot as pltimport numpy as npx = np.arange(10)fig = plt.figure()ax = plt.subplot(111)for i in xrange(5):    ax.plot(x, i * x, label='$y = %ix$'%i)# Shrink current axis by 20%box = ax.get_position()ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])# Put a legend to the right of the current axisax.legend(loc='center left', bbox_to_anchor=(1, 0.5))plt.show()And in a similar manner, shrink the plot vertically, and put a horizontal legend at the bottom:import matplotlib.pyplot as pltimport numpy as npx = np.arange(10)fig = plt.figure()ax = plt.subplot(111)for i in xrange(5):    line, = ax.plot(x, i * x, label='$y = %ix$'%i)# Shrink current axis's height by 10% on the bottombox = ax.get_position()ax.set_position([box.x0, box.y0 + box.height * 0.1,                 box.width, box.height * 0.9])# Put a legend below current axisax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),          fancybox=True, shadow=True, ncol=5)plt.show()Have a look at the matplotlib legend guide. You might also take a look at plt.figlegend()."
"data_i","asked Nov 23 '08 at 06:49","
        Proper MIME media type for PDF files
    ","When working with PDFs, I've run across the MIME types application/pdf and application/x-pdf among others. Is there a difference between these two types, and if so what is it? Is one preferred over the other?I'm working on a web app which must deliver huge amounts of PDFs and I want to do it the correct way, if there is one.","The standard Media Type (formerly known as MIME types) is application/pdf. The assignment is defined in RFC 3778, The application/pdf Media Type, referenced from the Media Types registry.Media Types are controlled by a standards body, The Internet Assigned Numbers Authority (IANA). This is the same organization that manages the root name servers and the IP address space.The use of x-pdf predates the standardization of the Media Type for PDF. Media Types in the x- namespace are considered experimental, just as those in the vnd. namespace are considered vendor-specific. x-pdf might be used for compatibility with old software."
"data_i","edited Jun 22 '22 at 21:49","
        What is the difference between concurrency and parallelism?
    ","What is the difference between concurrency and parallelism?","Concurrency is when two or more tasks can start, run, and complete in overlapping time periods.  It doesn't necessarily mean they'll ever both be running at the same instant.  For example, multitasking on a single-core machine.Parallelism is when tasks literally run at the same time, e.g., on a multicore processor.Quoting Sun's Multithreaded Programming Guide:Concurrency: A condition that exists when at least two threads are making progress. A more generalized form of parallelism that can include time-slicing as a form of virtual parallelism.Parallelism: A condition that arises when at least two threads are executing simultaneously."
"data_i","edited Jul 07 '21 at 14:04","
        How to change the href attribute for a hyperlink using jQuery
    ","How can you change the href attribute (link target) for a hyperlink using jQuery?","Using$(""a"").attr(""href"", ""http://www.google.com/"")will modify the href of all hyperlinks to point to Google. You probably want a somewhat more refined selector though. For instance, if you have a mix of link source (hyperlink) and link target (a.k.a. ""anchor"") anchor tags:<a name=""MyLinks""></a><a href=""http://www.codeproject.com/"">The CodeProject</a>...Then you probably don't want to accidentally add href attributes to them. For safety then, we can specify that our selector will only match <a> tags with an existing href attribute:$(""a[href]"") //...Of course, you'll probably have something more interesting in mind. If you want to match an anchor with a specific existing href, you might use something like this:$(""a[href='http://www.google.com/']"").attr('href', 'http://www.live.com/')This will find links where the href exactly matches the string http://www.google.com/. A more involved task might be matching, then updating only part of the href:$(""a[href^='http://stackoverflow.com']"")   .each(function()   {       this.href = this.href.replace(/^http:\/\/beta\.stackoverflow\.com/,          ""http://stackoverflow.com"");   });The first part selects only links where the href starts with http://stackoverflow.com. Then, a function is defined that uses a simple regular expression to replace this part of the URL with a new one. Note the flexibility this gives you - any sort of modification to the link could be done here."
"data_i","edited Feb 24 '16 at 18:16","
        How do I convert a float number to a whole number in JavaScript?
    ","I'd like to convert a float to a whole number in JavaScript. Actually, I'd like to know how to do BOTH of the standard conversions: by truncating and by rounding. And efficiently, not via converting to a string and parsing.","var intvalue = Math.floor( floatvalue );var intvalue = Math.ceil( floatvalue ); var intvalue = Math.round( floatvalue );// `Math.trunc` was added in ECMAScript 6var intvalue = Math.trunc( floatvalue );Math object referenceExamplesPositive// value=x        //  x=5          5<x<5.5      5.5<=x<6  Math.floor(value) //  5            5            5Math.ceil(value)  //  5            6            6Math.round(value) //  5            5            6Math.trunc(value) //  5            5            5parseInt(value)   //  5            5            5~~value           //  5            5            5value | 0         //  5            5            5value >> 0        //  5            5            5value >>> 0       //  5            5            5value - value % 1 //  5            5            5Negative// value=x        // x=-5         -5>x>=-5.5   -5.5>x>-6Math.floor(value) // -5           -6           -6Math.ceil(value)  // -5           -5           -5Math.round(value) // -5           -5           -6Math.trunc(value) // -5           -5           -5parseInt(value)   // -5           -5           -5value | 0         // -5           -5           -5~~value           // -5           -5           -5value >> 0        // -5           -5           -5value >>> 0       // 4294967291   4294967291   4294967291value - value % 1 // -5           -5           -5Positive - Larger numbers// x = Number.MAX_SAFE_INTEGER/10 // =900719925474099.1// value=x            x=900719925474099    x=900719925474099.4  x=900719925474099.5           Math.floor(value) //  900719925474099      900719925474099      900719925474099Math.ceil(value)  //  900719925474099      900719925474100      900719925474100Math.round(value) //  900719925474099      900719925474099      900719925474100Math.trunc(value) //  900719925474099      900719925474099      900719925474099parseInt(value)   //  900719925474099      900719925474099      900719925474099value | 0         //  858993459            858993459            858993459~~value           //  858993459            858993459            858993459value >> 0        //  858993459            858993459            858993459value >>> 0       //  858993459            858993459            858993459value - value % 1 //  900719925474099      900719925474099      900719925474099Negative - Larger numbers// x = Number.MAX_SAFE_INTEGER/10 * -1 // -900719925474099.1// value = x      // x=-900719925474099   x=-900719925474099.5 x=-900719925474099.6Math.floor(value) // -900719925474099     -900719925474100     -900719925474100Math.ceil(value)  // -900719925474099     -900719925474099     -900719925474099Math.round(value) // -900719925474099     -900719925474099     -900719925474100Math.trunc(value) // -900719925474099     -900719925474099     -900719925474099parseInt(value)   // -900719925474099     -900719925474099     -900719925474099value | 0         // -858993459           -858993459           -858993459~~value           // -858993459           -858993459           -858993459value >> 0        // -858993459           -858993459           -858993459value >>> 0       //  3435973837           3435973837           3435973837value - value % 1 // -900719925474099     -900719925474099     -900719925474099"
"data_i","edited Aug 10 '18 at 15:14","
        Hex transparency in colors
    ","I'm working on implementing a widget transparency option for my app widget although I'm having some trouble getting the hex color values right. Being completely new to hex color transparency I searched around a bit although I couldn't find a specific answer to my question. I want to set transparency by hex color so let's say my hex color id ""#33b5e5"" and I want it to be 50% transparent. Then I'll use ""#8033b5e5"" because 80 is 50%. I found a useful chart here: http://www.dtp-aus.com/hexadeci.htm . With this data I managed to come up with this:0% = #0010% = #1620% = #3230% = #4840% = #6450% = #8060% = #9670% = #11280% = #12890% = #144Now the issues start appearing when I get higher than 100 in hex. Hex color codes can only be 8 symbols long right? For example #11233b5e5 (80%) crashes.What can I do to enable me to use the higher numbers aswell?","Here's a correct table of percentages to hex values for opacity. E.g. for 50% white you'd use #80FFFFFF. To think in terms of transparency instead, flip the order of the percentages (more opaque = less transparent).%Hex100%FF95%F290%E685%D980%CC75%BF70%B365%A660%9955%8C50%8045%7340%6635%5930%4D25%4020%3315%2610%1A5%0D0%00(source question)"
"data_i","edited Apr 04 '14 at 16:20","
        Is there a way to get the source code from an APK file?
    ","The hard drive on my laptop just crashed and I lost all the source code for an app that I have been working on for the past two months.All I have is the APK file that is stored in my email from when I sent it to a friend. Is there any way to extract my source code from this APK file?","Simple way: use online tool https://www.decompiler.com/, upload apk and get source code.Procedure for decoding .apk files, step-by-step method:Step 1:Make a new folder and copy over the .apk file that you want to decode.Now rename the extension of this .apk file to .zip (e.g. rename from filename.apk to filename.zip) and save it. Now you can access the classes.dex files, etc. At this stage you are able to see drawables but not xml and java files, so continue.Step 2:Now extract this .zip file in the same folder (or NEW FOLDER).Download dex2jar (Don't download the code, click on the releases button that's on the right then download that) and extract it to the same folder (or NEW FOLDER).Move the classes.dex file into the dex2jar folder.Now open command prompt and change directory to that folder (or NEW FOLDER). Then write d2j-dex2jar classes.dex (for mac terminal or ubuntu write ./d2j-dex2jar.sh classes.dex) and press enter. You now have the classes.dex.dex2jar file in the same folder.Download java decompiler, double click on jd-gui, click on open file, and open classes.dex.dex2jar file from that folder: now you get class files.Save all of these class files (In jd-gui, click File -> Save All Sources) by src name. At this stage you get the java source but the .xml files are still unreadable, so continue.Step 3:Now open another new folderPut in the .apk file which you want to decodeDownload the latest version of apktool AND apktool install window (both can be downloaded from the same link) and place them in the same folderOpen a command windowNow run command like apktool if framework-res.apk (if you don't have it get it here)and nextapktool d myApp.apk  (where myApp.apk denotes the filename that you want to decode)now you get a file folder in that folder and can easily read the apk's xml files.Step 4:It's not any step, just copy contents of both folders(in this case, both new folders) to the single oneand enjoy the source code..."
"data_i","edited Nov 11 '19 at 21:47","
        How to round a number to n decimal places in Java
    ","What I would like is a method to convert a double to a string which rounds using the half-up method - i.e. if the decimal to be rounded is 5, it always rounds up to the next number. This is the standard method of rounding most people expect in most situations.I also would like only significant digits to be displayed - i.e. there should not be any trailing zeroes.I know one method of doing this is to use the String.format method:String.format(""%.5g%n"", 0.912385);returns:0.91239which is great, however it always displays numbers with 5 decimal places even if they are not significant: String.format(""%.5g%n"", 0.912300);returns:0.91230Another method is to use the DecimalFormatter:DecimalFormat df = new DecimalFormat(""#.#####"");df.format(0.912385);returns:0.91238However as you can see this uses half-even rounding. That is it will round down if the previous digit is even. What I'd like is this:0.912385 -> 0.912390.912300 -> 0.9123What is the best way to achieve this in Java?","Use setRoundingMode, set the RoundingMode explicitly to handle your issue with the half-even round, then use the format pattern for your required output.Example:DecimalFormat df = new DecimalFormat(""#.####"");df.setRoundingMode(RoundingMode.CEILING);for (Number n : Arrays.asList(12, 123.12345, 0.23, 0.1, 2341234.212431324)) {    Double d = n.doubleValue();    System.out.println(df.format(d));}gives the output:12123.12350.230.12341234.2125EDIT: The original answer does not address the accuracy of the double values. That is fine if you don't care much whether it rounds up or down. But if you want accurate rounding, then you need to take the expected accuracy of the values into account. Floating point values have a binary representation internally. That means that a value like 2.7735 does not actually have that exact value internally. It can be slightly larger or slightly smaller. If the internal value is slightly smaller, then it will not round up to 2.7740. To remedy that situation, you need to be aware of the accuracy of the values that you are working with, and add or subtract that value before rounding. For example, when you know that your values are accurate up to 6 digits, then to round half-way values up, add that accuracy to the value:Double d = n.doubleValue() + 1e-6;To round down, subtract the accuracy. "
"data_i","asked Sep 20 '10 at 21:21","
        What does the exclamation mark do before the function?
    ","!function () {}();","JavaScript syntax 101: here is a function declaration:function foo() {}Note that there’s no semicolon; this is just a function declaration. You would need an invocation, foo(), to actually run the function.Now, when we add the seemingly innocuous exclamation mark: !function foo() {} it turns it into an expression. It is now a function expression.The ! alone doesn’t invoke the function, of course, but we can now put () at the end: !function foo() {}(), which has higher precedence than ! and instantly calls the function.function foo() {}() would be a syntax error because you can’t put arguments (()) right after a function declaration.So what the author is doing is saving a byte per function expression; a more readable way of writing it would be this:(function(){})();Lastly, ! makes the expression return a boolean based on the return value of the function. Usually, an immediately invoked function expression (IIFE) doesn’t explicitly return anything, so its return value will be undefined, which leaves us with !undefined which is true. This boolean isn’t used."
"data_i","edited May 23 '17 at 11:55","
        How to remove old Docker containers
    ","This question is related to Should I be concerned about excess, non-running, Docker containers?.I'm wondering how to remove old containers. The docker rm 3e552code34a lets you remove a single one, but I have lots already. docker rm --help doesn't give a selection option (like all, or by image name).Maybe there is a directory in which these containers are stored where I can delete them easily manually?","Since Docker 1.13.x you can use Docker container prune:docker container pruneThis will remove all stopped containers and should work on all platforms the same way.There is also a Docker system prune:docker system prunewhich will clean up all unused containers, networks, images (both dangling and unreferenced), and optionally, volumes, in one command.For older Docker versions, you can string Docker commands together with other Unix commands to get what you need. Here is an example on how to clean up old containers that are weeks old:$ docker ps --filter ""status=exited"" | grep 'weeks ago' | awk '{print $1}' | xargs --no-run-if-empty docker rmTo give credit, where it is due, this example is from https://twitter.com/jpetazzo/status/347431091415703552."
"data_i","edited Oct 20 '16 at 22:32","
        Difference between git stash pop and git stash apply
    ","I've been using git stash pop for quite some time. I recently found out about the git stash apply command. When I tried it out, it seemed to work the same as git stash pop. What is the difference between git stash pop and git stash apply?","git stash pop throws away the (topmost, by default) stash after applying it, whereas git stash apply leaves it in the stash list for possible later reuse (or you can then git stash drop it). This happens unless there are conflicts after git stash pop, in which case it will not remove the stash, leaving it to behave exactly like git stash apply.Another way to look at it: git stash pop is git stash apply && git stash drop."
"data_i","edited May 23 '17 at 12:26","
        Naming Classes - How to avoid calling everything a ""Manager""?
    ","A long time ago I have read an article (I believe a blog entry) which put me on the ""right"" track on naming objects: Be very very scrupulous about naming things in your program.For example if my application was (as a typical business app) handling users, companies and addresses I'd have a User, a Company and an Address domain class - and probably somewhere a UserManager, a CompanyManager and an AddressManager would pop up that handles those things.So can you tell what those UserManager, CompanyManager and AddressManager do? No, because Manager is a very very generic term that fits to anything you can do with your domain objects.The article I read recommended using very specific names. If it was a C++ application and the UserManager's job was allocating and freeing users from the heap it would not manage the users but guard their birth and death. Hmm, maybe we could call this a UserShepherd.Or maybe the UserManager's job is to examine each User object's data and sign the data cryptographically. Then we'd have a UserRecordsClerk.Now that this idea stuck with me I try to apply it. And find this simple idea amazingly hard.I can describe what the classes do and (as long as I don't slip into quick & dirty coding) the classes I write do exactly one thing. What I miss to go from that description to the names is a kind of catalogue of names, a vocabulary that maps the concepts to names.Ultimately I'd like to have something like a pattern catalogue in my mind (frequently design patterns easily provide the object names, e.g. a factory)Factory - Creates other objects (naming taken from the design pattern)Shepherd - A shepherd handles the lifetime of objects, their creation and shutdownSynchronizer - Copies data between two or more objects (or object hierarchies)Nanny - Helps objects reach ""usable"" state after creation - for example by wiring to other objectsetc etc.So, how do you handle that issue? Do you have a fixed vocabulary, do you invent new names on the fly or do you consider naming things not-so-important or wrong?P.S.: I'm also interested in links to articles and blogs discussing the issue. As a start, here is the original article that got me thinking about it: Naming Java Classes without a 'Manager'Update: Summary of answersHere's a little summary of what I learned from this question in the meantime.Try not to create new metaphors (Nanny)Have a look at what other frameworks doFurther articles/books on this topic:What names do you find yourself prepending/appending to classes regularly? What’s the best approach to naming classes?Book: Design Patterns: Elements of Reusable Object-Oriented Software (Hardcover)Book: Patterns of Enterprise Application Architecture (Hardcover)Book: Implementation Patterns (Paperback)And a current list of name prefixes/suffixes I collected (subjectively!) from the answers:CoordinatorBuilderWriterReaderHandlerContainerProtocolTargetConverterControllerViewFactoryEntityBucketAnd a good tip for the road:Don't get naming paralysis. Yes, names are very important but they're not important   enough to waste huge amounts of time on. If you can't think up a good name in 10 minutes, move on.","I asked a similar question, but where possible I try to copy the names already in the .NET framework, and I look for ideas in the Java and Android frameworks.It seems Helper, Manager, and Util are the unavoidable nouns you attach for coordinating classes that contain no state and are generally procedural and static. An alternative is Coordinator.You could get particularly purple prosey with the names and go for things like Minder, Overseer, Supervisor, Administrator, and Master, but as I said I prefer keeping it like the framework names you're used to.Some other common suffixes (if that is the correct term) you also find in the .NET framework are:BuilderA type that use some parameters to construct an instance of a special type. Builder is usually a throwaway. It may not even need to allocate a variable.If the type needs to repeatedly create objects, please use Factory.if the type responsible for create multiple different type objects, please use Factories.WriterWrite some variable into something.ReaderRead something as variable.HandlerDesigned to deal with a situation or something.ContainerCan put something into it."
"data_i","edited Jun 20 '20 at 09:12","
        Hidden features of Python
    ","What are the lesser-known but useful features of the Python programming language?Try to limit answers to Python core.One feature per answer.Give an example and short description of the feature, not just a link to documentation.Label the feature using a title as the first line.Quick links to answers:Argument UnpackingBracesChaining Comparison OperatorsDecoratorsDefault Argument Gotchas / Dangers of Mutable Default argumentsDescriptorsDictionary default .get valueDocstring TestsEllipsis Slicing SyntaxEnumerationFor/elseFunction as iter() argumentGenerator expressionsimport thisIn Place Value SwappingList stepping__missing__ itemsMulti-line RegexNamed string formattingNested list/generator comprehensionsNew types at runtime.pth filesROT13 EncodingRegex DebuggingSending to GeneratorsTab Completion in Interactive InterpreterTernary Expressiontry/except/elseUnpacking+print() functionwith statement","Chaining comparison operators:>>> x = 5>>> 1 < x < 10True>>> 10 < x < 20 False>>> x < 10 < x*10 < 100True>>> 10 > x <= 9True>>> 5 == x > 4TrueIn case you're thinking it's doing 1 < x, which comes out as True, and then comparing True < 10, which is also True, then no, that's really not what happens (see the last example.) It's really translating into 1 < x and x < 10, and x < 10 and 10 < x * 10 and x*10 < 100, but with less typing and each term is only evaluated once."
"data_i","asked Mar 20 '09 at 20:09","
        What is the difference between MVC and MVVM?
    ","Is there a difference between the standard ""Model View Controller"" pattern and Microsoft's Model/View/ViewModel pattern?","MVC/MVVM is not an either/or choice.The two patterns crop up, in different ways, in both ASP.Net and Silverlight/WPF development.For ASP.Net, MVVM is used to two-way bind data within views. This is usually a client-side implementation (e.g. using Knockout.js). MVC on the other hand is a way of separating concerns on the server-side.For Silverlight and WPF, the MVVM pattern is more encompassing and can appear to act as a replacement for MVC (or other patterns of organising software into separate responsibilities). One assumption, that frequently came out of this pattern, was that the ViewModel simply replaced the controller in MVC (as if you could just substitute VM for C in the acronym and all would be forgiven)...The ViewModel does not necessarily replace the need for separate Controllers.The problem is: that to be independently testable*, and especially reusable when needed, a view-model has no idea what view is displaying it, but more importantly no idea where its data is coming from.*Note: in practice Controllers remove most of the logic, from the ViewModel, that requires unit testing. The VM then becomes a dumb container that requires little, if any, testing. This is a good thing as the VM is just a bridge, between the designer and the coder, so should be kept simple.Even in MVVM, controllers will typically contain all processing logic and decide what data to display in which views using which view models.From what we have seen so far the main benefit of the ViewModel pattern to remove code from XAML code-behind to make XAML editing a more independent task. We still create controllers, as and when needed, to control (no pun intended) the overall logic of our applications.The basic MVCVM guidelines we follow are:Views display a certain shape of data. They have no idea where the data comes from.ViewModels hold a certain shape of data and commands, they do not know where the data, or code, comes from or how it is displayed.Models hold the actual data (various context, store or other methods)Controllers listen for, and publish, events. Controllers provide the logic that controls what data is seen and where. Controllers provide the command code to the ViewModel so that the ViewModel is actually reusable.We also noted that the Sculpture code-gen framework implements MVVM and a pattern similar to Prism AND it also makes extensive use of controllers to separate all use-case logic.Don't assume controllers are made obsolete by View-models.I have started a blog on this topic which I will add to as and when I can (archive only as hosting was lost). There are issues with combining MVCVM with the common navigation systems, as most navigation systems just use Views and VMs, but I will go into that in later articles.An additional benefit of using an MVCVM model is that only the controller objects need to exist in memory for the life of the application and the controllers contain mainly code and little state data (i.e. tiny memory overhead). This makes for much less memory-intensive apps than solutions where view-models have to be retained and it is ideal for certain types of mobile development (e.g. Windows Mobile using Silverlight/Prism/MEF). This does of course depend on the type of application as you may still need to retain the occasional cached VMs for responsiveness.Note: This post has been edited numerous times, and did not specifically target the narrow question asked, so I have updated the first part to now cover that too. Much of the discussion, in comments below, relates only to ASP.Net and not the broader picture. This post was intended to cover the broader use of MVVM in Silverlight, WPF and ASP.Net and try to discourage people from replacing controllers with ViewModels."
"data_i","edited Aug 23 '22 at 07:20","
        Null object in Python
    ","How do I refer to the null object in Python?","In Python, the 'null' object is the singleton None.To check if something is None, use the is identity operator:if foo is None:    ..."
"data_i","edited Sep 04 '22 at 19:56","
        What is the preferred Bash shebang (""#!"")?
    ","Is there any Bash shebang objectively better than the others for most uses?#!/usr/bin/env bash#!/bin/bash#!/bin/sh#!/bin/sh -etcI vaguely recall a long time ago hearing that adding a dash to the end prevents someone passing a command to your script, but can’t find any details on that.","You should use #!/usr/bin/env bash for portability: different *nixes put bash in different places, and using /usr/bin/env is a workaround to run the first bash found on the PATH. And sh is not bash."
"data_i","edited Oct 04 '15 at 22:21","
        How to compare arrays in JavaScript?
    ","I'd like to compare two arrays... ideally, efficiently. Nothing fancy, just true if they are identical, and false if not. Not surprisingly, the comparison operator doesn't seem to work.var a1 = [1,2,3];var a2 = [1,2,3];console.log(a1==a2);    // Returns falseconsole.log(JSON.stringify(a1)==JSON.stringify(a2));    // Returns trueJSON encoding each array does, but is there a faster or ""better"" way to simply compare arrays without having to iterate through each value?","To compare arrays, loop through them and compare every value:Comparing arrays:// Warn if overriding existing methodif(Array.prototype.equals)    console.warn(""Overriding existing Array.prototype.equals. Possible causes: New API defines the method, there's a framework conflict or you've got double inclusions in your code."");// attach the .equals method to Array's prototype to call it on any arrayArray.prototype.equals = function (array) {    // if the other array is a falsy value, return    if (!array)        return false;    // compare lengths - can save a lot of time     if (this.length != array.length)        return false;    for (var i = 0, l=this.length; i < l; i++) {        // Check if we have nested arrays        if (this[i] instanceof Array && array[i] instanceof Array) {            // recurse into the nested arrays            if (!this[i].equals(array[i]))                return false;               }                   else if (this[i] != array[i]) {             // Warning - two different object instances will never be equal: {x:20} != {x:20}            return false;           }               }           return true;}// Hide method from for-in loopsObject.defineProperty(Array.prototype, ""equals"", {enumerable: false});Usage:[1, 2, [3, 4]].equals([1, 2, [3, 2]]) === false;[1, ""2,3""].equals([1, 2, 3]) === false;[1, 2, [3, 4]].equals([1, 2, [3, 4]]) === true;[1, 2, 1, 2].equals([1, 2, 1, 2]) === true;You may say ""But it is much faster to compare strings - no loops..."" well, then you should note there ARE loops. First recursive loop that converts Array to string and second, that compares two strings. So this method is faster than use of string.I believe that larger amounts of data should be always stored in arrays, not in objects. However if you use objects, they can be partially compared too.Here's how:Comparing objects:I've stated above, that two object instances will never be equal, even if they contain same data at the moment:({a:1, foo:""bar"", numberOfTheBeast: 666}) == ({a:1, foo:""bar"", numberOfTheBeast: 666})  //falseThis has a reason, since there may be, for example private variables within objects.However, if you just use object structure to contain data, comparing is still possible:Object.prototype.equals = function(object2) {    //For the first loop, we only check for types    for (propName in this) {        //Check for inherited methods and properties - like .equals itself        //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/hasOwnProperty        //Return false if the return value is different        if (this.hasOwnProperty(propName) != object2.hasOwnProperty(propName)) {            return false;        }        //Check instance type        else if (typeof this[propName] != typeof object2[propName]) {            //Different types => not equal            return false;        }    }    //Now a deeper check using other objects property names    for(propName in object2) {        //We must check instances anyway, there may be a property that only exists in object2            //I wonder, if remembering the checked values from the first loop would be faster or not         if (this.hasOwnProperty(propName) != object2.hasOwnProperty(propName)) {            return false;        }        else if (typeof this[propName] != typeof object2[propName]) {            return false;        }        //If the property is inherited, do not check any more (it must be equa if both objects inherit it)        if(!this.hasOwnProperty(propName))          continue;                //Now the detail check and recursion                //This returns the script back to the array comparing        /**REQUIRES Array.equals**/        if (this[propName] instanceof Array && object2[propName] instanceof Array) {                   // recurse into the nested arrays           if (!this[propName].equals(object2[propName]))                        return false;        }        else if (this[propName] instanceof Object && object2[propName] instanceof Object) {                   // recurse into another objects                   //console.log(""Recursing to compare "", this[propName],""with"",object2[propName], "" both named \""""+propName+""\"""");           if (!this[propName].equals(object2[propName]))                        return false;        }        //Normal value comparison for strings and numbers        else if(this[propName] != object2[propName]) {           return false;        }    }    //If everything passed, let's say YES    return true;}  However, remember that this one is to serve in comparing JSON like data, not class instances and other stuff. If you want to compare more complicated objects, look at this answer and it's super long function.To make this work with Array.equals you must edit the original function a little bit:...    // Check if we have nested arrays    if (this[i] instanceof Array && array[i] instanceof Array) {        // recurse into the nested arrays        if (!this[i].equals(array[i]))            return false;    }    /**REQUIRES OBJECT COMPARE**/    else if (this[i] instanceof Object && array[i] instanceof Object) {        // recurse into another objects        //console.log(""Recursing to compare "", this[propName],""with"",object2[propName], "" both named \""""+propName+""\"""");        if (!this[i].equals(array[i]))            return false;        }    else if (this[i] != array[i]) {...I made a little test tool for both of the functions.Bonus: Nested arrays with indexOf and containsSamy Bencherif has prepared useful functions for the case you're searching for a specific object in nested arrays, which are available here: https://jsfiddle.net/SamyBencherif/8352y6yw/"
"data_i","edited Jun 20 '22 at 06:31","
        How do I check which version of Python is running my script?
    ","How do I check which version of the Python interpreter is running my script?","This information is available in the sys.version string in the sys module:>>> import sysHuman readable:>>> print(sys.version)  # parentheses necessary in python 3.       2.5.2 (r252:60911, Jul 31 2008, 17:28:52) [GCC 4.2.3 (Ubuntu 4.2.3-2ubuntu7)]For further processing, use sys.version_info or sys.hexversion:>>> sys.version_info(2, 5, 2, 'final', 0)# or>>> sys.hexversion34014192To ensure a script runs with a minimal version requirement of the Python interpreter add this to your code:assert sys.version_info >= (2, 5)This compares major and minor version information. Add micro (=0, 1, etc) and even releaselevel (='alpha','final', etc) to the tuple as you like. Note however, that it is almost always better to ""duck"" check if a certain feature is there, and if not, workaround (or bail out). Sometimes features go away in newer releases, being replaced by others."
"data_i","edited May 23 '17 at 11:55","
        Merge / convert multiple PDF files into one PDF
    ","How could I merge / convert multiple PDF files into one large PDF file?I tried the following, but the content of the target file was not as expected:convert file1.pdf file2.pdf merged.pdfI need a very simple/basic command line (CLI) solution. Best would be if I could pipe the output of the merge / convert straight into pdf2ps ( as originally attempted in my previously asked question here: Linux piping ( convert -> pdf2ps -> lp) ).","Considering that pdfunite is part of poppler it has a higher chance to be installed, usage is also simpler than pdftk:pdfunite in-1.pdf in-2.pdf in-n.pdf out.pdfJust make sure you remember to provide out.pdf, or else it will overwrite the last file in your command"
"data_i","edited Jul 22 '20 at 14:47","
        Using group by on multiple columns
    ","I understand the point of GROUP BY x.But how does GROUP BY x, y work, and what does it mean?","Group By X means put all those with the same value for X in the one group.Group By X, Y means put all those with the same values for both X and Y in the one group.To illustrate using an example, let's say we have the following table, to do with who is attending what subject at a university:Table: Subject_Selection+---------+----------+----------+| Subject | Semester | Attendee |+---------+----------+----------+| ITB001  |        1 | John     || ITB001  |        1 | Bob      || ITB001  |        1 | Mickey   || ITB001  |        2 | Jenny    || ITB001  |        2 | James    || MKB114  |        1 | John     || MKB114  |        1 | Erica    |+---------+----------+----------+When you use a group by on the subject column only; say:select Subject, Count(*)from Subject_Selectiongroup by SubjectYou will get something like:+---------+-------+| Subject | Count |+---------+-------+| ITB001  |     5 || MKB114  |     2 |+---------+-------+...because there are 5 entries for ITB001, and 2 for MKB114If we were to group by two columns:select Subject, Semester, Count(*)from Subject_Selectiongroup by Subject, Semesterwe would get this:+---------+----------+-------+| Subject | Semester | Count |+---------+----------+-------+| ITB001  |        1 |     3 || ITB001  |        2 |     2 || MKB114  |        1 |     2 |+---------+----------+-------+This is because, when we group by two columns, it is saying ""Group them so that all of those with the same Subject and Semester are in the same group, and then calculate all the aggregate functions (Count, Sum, Average, etc.) for each of those groups"". In this example, this is demonstrated by the fact that, when we count them, there are three people doing ITB001 in semester 1, and two doing it in semester 2. Both of the people doing MKB114 are in semester 1, so there is no row for semester 2 (no data fits into the group ""MKB114, Semester 2"")Hopefully that makes sense."
"data_i","edited Jul 26 '13 at 05:00","
        How do I remove the passphrase for the SSH key without having to create a new key?
    ","I set a passphrase when creating a new SSH key on my laptop. But, as I realise now, this is quite painful when you are trying to commit (Git and SVN) to a remote location over SSH many times in an hour.One way I can think of is, delete my SSH keys and create new. Is there a way to remove the passphrase, while still keeping the same keys?","Short answer:$ ssh-keygen -pThis will then prompt you to enter the keyfile location, the old passphrase, and the new passphrase (which can be left blank to have no passphrase).If you would like to do it all on one line without prompts do:$ ssh-keygen -p [-P old_passphrase] [-N new_passphrase] [-f keyfile]Important: Beware that when executing commands they will typically be logged in your ~/.bash_history file (or similar) in plain text including all arguments provided (i.e. the passphrases in this case). It is, therefore, is recommended that you use the first option unless you have a specific reason to do otherwise.   Notice though that you can still use -f keyfile without having to specify -P nor -N, and that the keyfile defaults to ~/.ssh/id_rsa, so in many cases, it's not even needed.You might want to consider using ssh-agent, which can cache the passphrase for a time. The latest versions of gpg-agent also support the protocol that is used by ssh-agent."
"data_i","edited Jun 22 '22 at 15:15","
        Trigger a button click with JavaScript on the Enter key in a text box
    ","I have one text input and one button (see below). How can I use JavaScript to trigger the button's click event when the Enter key is pressed inside the text box?There is already a different submit button on my current page, so I can't simply make the button a submit button. And, I only want the Enter key to click this specific button if it is pressed from within this one text box, nothing else.<input type=""text"" id=""txtSearch"" /><input type=""button"" id=""btnSearch"" value=""Search"" onclick=""doSomething();"" />","In jQuery, the following would work:$(""#id_of_textbox"").keyup(function(event) {    if (event.keyCode === 13) {        $(""#id_of_button"").click();    }});$(""#pw"").keyup(function(event) {    if (event.keyCode === 13) {        $(""#myButton"").click();    }});$(""#myButton"").click(function() {  alert(""Button code executed."");});<script src=""https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js""></script>Username:<input id=""username"" type=""text""><br>Password:&nbsp;<input id=""pw"" type=""password""><br><button id=""myButton"">Submit</button>Or in plain JavaScript, the following would work:document.getElementById(""id_of_textbox"")    .addEventListener(""keyup"", function(event) {    event.preventDefault();    if (event.keyCode === 13) {        document.getElementById(""id_of_button"").click();    }});document.getElementById(""pw"")    .addEventListener(""keyup"", function(event) {    event.preventDefault();    if (event.keyCode === 13) {        document.getElementById(""myButton"").click();    }});function buttonCode(){  alert(""Button code executed."");}<script src=""https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js""></script>Username:<input id=""username"" type=""text""><br>Password:&nbsp;<input id=""pw"" type=""password""><br><button id=""myButton"" onclick=""buttonCode()"">Submit</button>"
"data_i","edited Jul 11 '22 at 21:00","
        Send HTTP POST request in .NET
    ","How can I make an HTTP POST request and send data in the body?","There are several ways to perform HTTP GET and POST requests:Method A: HttpClient (Preferred)Available in: .NET Framework 4.5+, .NET Standard 1.1+, and .NET Core 1.0+.It is currently the preferred approach, and is asynchronous and high performance. Use the built-in version in most cases, but for very old platforms there is a NuGet package.using System.Net.Http;SetupIt is recommended to instantiate one HttpClient for your application's lifetime and share it unless you have a specific reason not to.private static readonly HttpClient client = new HttpClient();See HttpClientFactory for a dependency injection solution.POST  var values = new Dictionary<string, string>  {      { ""thing1"", ""hello"" },      { ""thing2"", ""world"" }  };  var content = new FormUrlEncodedContent(values);  var response = await client.PostAsync(""http://www.example.com/recepticle.aspx"", content);  var responseString = await response.Content.ReadAsStringAsync();GET  var responseString = await client.GetStringAsync(""http://www.example.com/recepticle.aspx"");Method B: Third-Party LibrariesRestSharpPOST   var client = new RestClient(""http://example.com"");   // client.Authenticator = new HttpBasicAuthenticator(username, password);   var request = new RestRequest(""resource/{id}"");   request.AddParameter(""thing1"", ""Hello"");   request.AddParameter(""thing2"", ""world"");   request.AddHeader(""header"", ""value"");   request.AddFile(""file"", path);   var response = client.Post(request);   var content = response.Content; // Raw content as string   var response2 = client.Post<Person>(request);   var name = response2.Data.Name;Flurl.HttpIt is a newer library sporting a fluent API, testing helpers, uses HttpClient under the hood, and is portable. It is available via NuGet.    using Flurl.Http;POST  var responseString = await ""http://www.example.com/recepticle.aspx""      .PostUrlEncodedAsync(new { thing1 = ""hello"", thing2 = ""world"" })      .ReceiveString();GET  var responseString = await ""http://www.example.com/recepticle.aspx""      .GetStringAsync();Method C: HttpWebRequest (not recommended for new work)Available in: .NET Framework 1.1+, .NET Standard 2.0+, .NET Core 1.0+. In .NET Core, it is mostly for compatibility -- it wraps HttpClient, is less performant, and won't get new features.using System.Net;using System.Text;  // For class Encodingusing System.IO;    // For StreamReaderPOST  var request = (HttpWebRequest)WebRequest.Create(""http://www.example.com/recepticle.aspx"");  var postData = ""thing1="" + Uri.EscapeDataString(""hello"");      postData += ""&thing2="" + Uri.EscapeDataString(""world"");  var data = Encoding.ASCII.GetBytes(postData);  request.Method = ""POST"";  request.ContentType = ""application/x-www-form-urlencoded"";  request.ContentLength = data.Length;  using (var stream = request.GetRequestStream())  {      stream.Write(data, 0, data.Length);  }  var response = (HttpWebResponse)request.GetResponse();  var responseString = new StreamReader(response.GetResponseStream()).ReadToEnd();GET  var request = (HttpWebRequest)WebRequest.Create(""http://www.example.com/recepticle.aspx"");  var response = (HttpWebResponse)request.GetResponse();  var responseString = new StreamReader(response.GetResponseStream()).ReadToEnd();Method D: WebClient (Not recommended for new work)This is a wrapper around HttpWebRequest. Compare with HttpClient.Available in: .NET Framework 1.1+, NET Standard 2.0+, and .NET Core 2.0+.In some circumstances (.NET Framework 4.5-4.8), if you need to do a HTTP request synchronously, WebClient can still be used.using System.Net;using System.Collections.Specialized;POST  using (var client = new WebClient())  {      var values = new NameValueCollection();      values[""thing1""] = ""hello"";      values[""thing2""] = ""world"";      var response = client.UploadValues(""http://www.example.com/recepticle.aspx"", values);      var responseString = Encoding.Default.GetString(response);  }GET  using (var client = new WebClient())  {      var responseString = client.DownloadString(""http://www.example.com/recepticle.aspx"");  }"
"data_i","asked Aug 24 '10 at 21:59","
        Custom HTTP headers : naming conventions
    ","Several of our users have asked us to include data relative to their account in the HTTP headers of requests we send them, or even responses they get from our API.What is the general convention to add custom HTTP headers, in terms of naming, format... etc.Also, feel free to post any smart usage of these that you stumbled upon on the web; We're trying to implement this using what's best out there as a target :)","The recommendation is was to start their name with ""X-"". E.g. X-Forwarded-For, X-Requested-With. This is also mentioned in a.o. section 5 of RFC 2047.Update 1: On June 2011, the first IETF draft was posted to deprecate the recommendation of using the ""X-"" prefix for non-standard headers. The reason is that when non-standard headers prefixed with ""X-"" become standard, removing the ""X-"" prefix breaks backwards compatibility, forcing application protocols to support both names (E.g, x-gzip & gzip are now equivalent). So, the official recommendation is to just name them sensibly without the ""X-"" prefix.Update 2: On June 2012, the deprecation of recommendation to use the ""X-"" prefix has become official as RFC 6648. Below are cites of relevance:3.  Recommendations for Creators of New Parameters...SHOULD NOT prefix their parameter names with ""X-"" or similarconstructs.4.  Recommendations for Protocol Designers...SHOULD NOT prohibit parameters with an ""X-"" prefix or similarconstructs from being registered.MUST NOT stipulate that a parameter with an ""X-"" prefix orsimilar constructs needs to be understood as unstandardized.MUST NOT stipulate that a parameter without an ""X-"" prefix orsimilar constructs needs to be understood as standardized.Note that ""SHOULD NOT"" (""discouraged"") is not the same as ""MUST NOT"" (""forbidden""), see also RFC 2119 for another spec on those keywords. In other words, you can keep using ""X-"" prefixed headers, but it's not officially recommended anymore and you may definitely not document them as if they are public standard.Summary:the official recommendation is to just name them sensibly without the ""X-"" prefixyou can keep using ""X-"" prefixed headers, but it's not officially recommended anymore and you may definitely not document them as if they are public standard"
"data_i","edited Mar 26 '17 at 15:44","
        Get the current year in JavaScript
    ","How do I get the current year in JavaScript?","Create a new Date() object and call getFullYear():new Date().getFullYear()  // returns the current yearExample usage: a page footer that always shows the current year:document.getElementById(""year"").innerHTML = new Date().getFullYear();footer {  text-align: center;  font-family: sans-serif;}<footer>    ©<span id=""year""></span> by Donald Duck</footer>See also, the Date() constructor's full list of methods."
"data_i","edited Jan 12 '16 at 23:10","
        Find when a file was deleted in Git
    ","I have a Git repository with n commits.I have a file that I need, and that used to be in the repository, and that I suddenly look for and think ""Oh! Where'd that file go?""Is there a (series of) Git command(s) that will tell me that ""file really_needed.txt was deleted at commit n-13""?In other words, without looking at every individual commit, and knowing that my Git repo has every change of every file, can I quickly find the last commit that HAS that file, so I can get it back?","To show the commits that changed a file, even if the file was deleted, run this command:git log --full-history -- [file path]If you want to see only the last commit, which deleted the file, use -1 in addition to the command above:git log --full-history -1 -- [file path]See also my article: Which commit deleted a file."
"data_i","edited Jul 11 '15 at 15:26","
        Why is executing Java code in comments with certain Unicode characters allowed?
    ","The following code produces the output ""Hello World!"" (no really, try it).public static void main(String... args) {   // The comment below is not a typo.   // \u000d System.out.println(""Hello World!"");}The reason for this is that the Java compiler parses the Unicode character \u000d as a new line and gets transformed into:public static void main(String... args) {   // The comment below is not a typo.   //   System.out.println(""Hello World!"");}Thus resulting into a comment being ""executed"".Since this can be used to ""hide"" malicious code or whatever an evil programmer can conceive, why is it allowed in comments?Why is this allowed by the Java specification?","Unicode decoding takes place before any other lexical translation. The key benefit of this is that it makes it trivial to go back and forth between ASCII and any other encoding. You don't even need to figure out where comments begin and end!As stated in JLS Section 3.3 this allows any ASCII based tool to process the source files:[...] The Java programming language specifies a standard way of transforming a program written in Unicode into ASCII that changes a program into a form that can be processed by ASCII-based tools. [...]This gives a fundamental guarantee for platform independence (independence of supported character sets) which has always been a key goal for the Java platform. Being able to write any Unicode character anywhere in the file is a neat feature, and especially important in comments, when documenting code in non-latin languages. The fact that it can interfere with the semantics in such subtle ways is just an (unfortunate) side-effect.There are many gotchas on this theme and Java Puzzlers by Joshua Bloch and Neal Gafter included the following variant:Is this a legal Java program? If so, what does it print?\u0070\u0075\u0062\u006c\u0069\u0063\u0020\u0020\u0020\u0020\u0063\u006c\u0061\u0073\u0073\u0020\u0055\u0067\u006c\u0079\u007b\u0070\u0075\u0062\u006c\u0069\u0063\u0020\u0020\u0020\u0020\u0020\u0020\u0020\u0073\u0074\u0061\u0074\u0069\u0063\u0076\u006f\u0069\u0064\u0020\u006d\u0061\u0069\u006e\u0028\u0053\u0074\u0072\u0069\u006e\u0067\u005b\u005d\u0020\u0020\u0020\u0020\u0020\u0020\u0061\u0072\u0067\u0073\u0029\u007b\u0053\u0079\u0073\u0074\u0065\u006d\u002e\u006f\u0075\u0074\u002e\u0070\u0072\u0069\u006e\u0074\u006c\u006e\u0028\u0020\u0022\u0048\u0065\u006c\u006c\u006f\u0020\u0077\u0022\u002b\u0022\u006f\u0072\u006c\u0064\u0022\u0029\u003b\u007d\u007d(This program turns out to be a plain ""Hello World"" program.)In the solution to the puzzler, they point out the following:More seriously, this puzzle serves to reinforce the lessons of the previous three: Unicode escapes are essential when you need to insert characters that can’t be represented in any other way into your program. Avoid them in all other cases.Source: Java: Executing code in comments?!"
"data_i","edited Nov 21 '17 at 13:42","
        ignoring any 'bin' directory on a git project
    ","I have a directory structure like this:.git/.gitignoremain/  ...tools/  ......Inside main and tools, and any other directory, at any level, there can be a 'bin' directory, which I want to ignore (and I want to ignore everything under it too). I've tried each of these patterns in .gitignore but none of them work:/**/bin/**/*/./**/bin/**/*./**/bin/**/***/bin/**/**/bin/**/*bin/**/*/**/bin/* #and the others with just * at the end tooCan anyone help me out? The first pattern (the one I think should be working) works just fine if I do this:/main/**/bin/**/*But I don't want to have an entry for every top-level directory and I don't want to have to modify .gitignore every time I add a new one.This is on Windows using the latest msysgit.EDIT: one more thing, there are files and directories that have the substring 'bin' in their names, I don't want those to be ignored :)","Before version 1.8.2, ** didn't have any special meaning in the .gitignore. As of 1.8.2 git supports ** to mean zero or more sub-directories (see release notes).The way to ignore all directories called bin anywhere below the current level in a directory tree is with a .gitignore file with the pattern:bin/In the man page, there an example of ignoring a directory called foo using an analogous pattern.Edit: If you already have any bin folders in your git index which you no longer wish to track then you need to remove them explicitly. Git won't stop tracking paths that are already being tracked just because they now match a new .gitignore pattern. Execute a folder remove (rm) from index only (--cached) recursivelly (-r). Command line example for root bin folder:git rm -r --cached bin"
"data_i","edited Jun 01 '20 at 21:30","
        How to convert a string to number in TypeScript?
    ","Given a string representation of a number, how can I convert it to number type in TypeScript?var numberString: string = ""1234"";var numberValue: number = /* what should I do with `numberString`? */;","Exactly like in JavaScript, you can use the parseInt or parseFloat functions, or simply use the unary + operator:var x = ""32"";var y: number = +x;All of the mentioned techniques will have correct typing and will correctly parse simple decimal integer strings like ""123"", but will behave differently for various other, possibly expected, cases (like ""123.45"") and corner cases (like null).Table taken from  this answer"
"data_i","edited Sep 22 '21 at 04:48","
        Difference between Constructor and ngOnInit
    ","Angular provides life cycle hook ngOnInit by default.Why should ngOnInit be used, if we already have a constructor?","The Constructor is a default method of the class that is executed when the class is instantiated and ensures proper initialisation of fields in the class and its subclasses. Angular, or better Dependency Injector (DI), analyses the constructor parameters and when it creates a new instance by calling new MyClass() it tries to find providers that match the types of the constructor parameters, resolves them and passes them to the constructor likenew MyClass(someArg);ngOnInit is a life cycle hook called by Angular to indicate that Angular is done creating the component.We have to import OnInit like this in order to use it (actually implementing OnInit is not mandatory but considered good practice):import { Component, OnInit } from '@angular/core';then to make use of the method OnInit, we have to implement the class like this:export class App implements OnInit {  constructor() {     // Called first time before the ngOnInit()  }  ngOnInit() {     // Called after the constructor and called  after the first ngOnChanges()   }}Implement this interface to execute custom initialization logic after your directive's data-bound properties have been initialized.ngOnInit is called right after the directive's data-bound properties have been checked for the first time,and before any of its children have been checked.It is invoked only once when the directive is instantiated.Mostly we use ngOnInit for all the initialization/declaration and avoid stuff to work in the constructor. The constructor should only be used to initialize class members but shouldn't do actual ""work"".So you should use constructor() to setup Dependency Injection and not much else. ngOnInit() is better place to ""start"" - it's where/when components' bindings are resolved.For more information refer here:https://angular.io/api/core/OnInitAngular Component Constructor Vs OnInitImportant to note that @Input values are not accessible in the constructor (Thanks to @tim for suggestion in comments)"
"data_i","edited May 10 '16 at 19:43","
        Object comparison in JavaScript
    ","What is the best way to compare objects in JavaScript?Example:var user1 = {name : ""nerd"", org: ""dev""};var user2 = {name : ""nerd"", org: ""dev""};var eq = user1 == user2;alert(eq); // gives falseI know that two objects are equal if they refer to the exact same object, but is there a way to check if they have the same attributes' values?The following way works for me, but is it the only possibility?var eq = Object.toJSON(user1) == Object.toJSON(user2);alert(eq); // gives true","Unfortunately there is no perfect way, unless you use _proto_ recursively and access all non-enumerable properties, but this works in Firefox only.So the best I can do is to guess usage scenarios.1) Fast and limited.Works when you have simple JSON-style objects without methods and DOM nodes inside: JSON.stringify(obj1) === JSON.stringify(obj2) The ORDER of the properties IS IMPORTANT, so this method will return false for following objects: x = {a: 1, b: 2}; y = {b: 2, a: 1};2) Slow and more generic.Compares objects without digging into prototypes, then compares properties' projections recursively, and also compares constructors.This is almost correct algorithm:function deepCompare () {  var i, l, leftChain, rightChain;  function compare2Objects (x, y) {    var p;    // remember that NaN === NaN returns false    // and isNaN(undefined) returns true    if (isNaN(x) && isNaN(y) && typeof x === 'number' && typeof y === 'number') {         return true;    }    // Compare primitives and functions.         // Check if both arguments link to the same object.    // Especially useful on the step where we compare prototypes    if (x === y) {        return true;    }    // Works in case when functions are created in constructor.    // Comparing dates is a common scenario. Another built-ins?    // We can even handle functions passed across iframes    if ((typeof x === 'function' && typeof y === 'function') ||       (x instanceof Date && y instanceof Date) ||       (x instanceof RegExp && y instanceof RegExp) ||       (x instanceof String && y instanceof String) ||       (x instanceof Number && y instanceof Number)) {        return x.toString() === y.toString();    }    // At last checking prototypes as good as we can    if (!(x instanceof Object && y instanceof Object)) {        return false;    }    if (x.isPrototypeOf(y) || y.isPrototypeOf(x)) {        return false;    }    if (x.constructor !== y.constructor) {        return false;    }    if (x.prototype !== y.prototype) {        return false;    }    // Check for infinitive linking loops    if (leftChain.indexOf(x) > -1 || rightChain.indexOf(y) > -1) {         return false;    }    // Quick checking of one object being a subset of another.    // todo: cache the structure of arguments[0] for performance    for (p in y) {        if (y.hasOwnProperty(p) !== x.hasOwnProperty(p)) {            return false;        }        else if (typeof y[p] !== typeof x[p]) {            return false;        }    }    for (p in x) {        if (y.hasOwnProperty(p) !== x.hasOwnProperty(p)) {            return false;        }        else if (typeof y[p] !== typeof x[p]) {            return false;        }        switch (typeof (x[p])) {            case 'object':            case 'function':                leftChain.push(x);                rightChain.push(y);                if (!compare2Objects (x[p], y[p])) {                    return false;                }                leftChain.pop();                rightChain.pop();                break;            default:                if (x[p] !== y[p]) {                    return false;                }                break;        }    }    return true;  }  if (arguments.length < 1) {    return true; //Die silently? Don't know how to handle such case, please help...    // throw ""Need two or more arguments to compare"";  }  for (i = 1, l = arguments.length; i < l; i++) {      leftChain = []; //Todo: this can be cached      rightChain = [];      if (!compare2Objects(arguments[0], arguments[i])) {          return false;      }  }  return true;}Known issues (well, they have very low priority, probably you'll never notice them):objects with different prototype structure but same projectionfunctions may have identical text but refer to different closuresTests: passes tests are from How to determine equality for two JavaScript objects?."
"data_i","edited Jun 17 '15 at 08:14","
        Changing git commit message after push (given that no one pulled from remote)
    ","I have made a git commit and subsequent push. I would like to change the commit message. If I understand correctly, this is not advisable because someone might have pulled from the remote repository before I make such changes. What if I know that no one has pulled? Is there a way to do this?","Changing historyIf it is the most recent commit, you can simply do this:git commit --amendThis brings up the editor with the last commit message and lets you edit the message.  (You can use -m if you want to wipe out the old message and use a new one.)PushingAnd then when you push, do this:git push --force-with-lease <repository> <branch>Or you can use ""+"":git push <repository> +<branch>Or you can use --force:git push --force <repository> <branch>Be careful when using these commands.If someone else pushed changes to the same branch, you probably want to avoid destroying those changes.  The --force-with-lease option is the safest, because it will abort if there are any upstream changes (If you don't specify the branch explicitly, Git will use the default push settings.  If your default push setting is ""matching"", then you may destroy changes on several branches at the same time. Pulling / fetching afterwardsAnyone who already pulled will now get an error message, and they will need to update (assuming they aren't making any changes themselves) by doing something like this:git fetch origingit reset --hard origin/master # Loses local commitsBe careful when using reset --hard.  If you have changes to the branch, those changes will be destroyed.A note about modifying historyThe destroyed data is really just the old commit message, but --force doesn't know that, and will happily delete other data too.  So think of --force as ""I want to destroy data, and I know for sure what data is being destroyed.""  But when the destroyed data is committed, you can often recover old commits from the reflog—the data is actually orphaned instead of destroyed (although orphaned commits are periodically deleted).If you don't think you're destroying data, then stay away from --force... bad things might happen.This is why --force-with-lease is somewhat safer."
"data_i","edited Jul 21 '17 at 18:20","
        Can I recover a branch after its deletion in Git?
    ","If I run git branch -d XYZ, is there a way to recover the branch? Is there a way to go back as if I didn't run the delete branch command?","Yes, you should be able to do git reflog --no-abbrev and find the SHA1 for the commit at the tip of your deleted branch, then just git checkout [sha]. And once you're at that commit, you can just git checkout -b [branchname] to recreate the branch from there.Credit to @Cascabel for this condensed/one-liner version and @Snowcrash for how to obtain the sha.If you've just deleted the branch you'll see something like this in your terminal Deleted branch <your-branch> (was <sha>). Then just use that <sha> in this one-liner:git checkout -b <your-branch> <sha>"
"data_i","edited Feb 18 '22 at 22:49","
        Convert JavaScript String to be all lower case
    ","How can I convert a JavaScript string value to be in all lower case letters?Example: ""Your Name"" to ""your name""","var lowerCaseName = ""Your Name"".toLowerCase();"
"data_i","edited Jul 01 '15 at 11:39","
        Determine whether an array contains a value
    ","I need to determine if a value exists in an array.I am using the following function:Array.prototype.contains = function(obj) {    var i = this.length;    while (i--) {        if (this[i] == obj) {            return true;        }    }    return false;}The above function always returns false.The array values and the function call is as below:arrValues = [""Sam"",""Great"", ""Sample"", ""High""]alert(arrValues.contains(""Sam""));","jQuery has a utility function for this:$.inArray(value, array)Returns index of value in array. Returns -1 if array does not contain value.See also How do I check if an array includes an object in JavaScript?"
"data_i","edited Aug 05 '21 at 20:10","
        How can I get a list of user accounts using the command line in MySQL?
    ","I'm using the MySQL command-line utility and can navigate through a database. Now I need to see a list of user accounts. How can I do this?I'm using MySQL version 5.4.1.","Use this query:SELECT User FROM mysql.user;Which will output a table like this:+-------+| User  |+-------+| root  |+-------+| user2 |+-------+As Matthew Scharley points out in the comments on this answer, you can group by the User column if you'd only like to see unique usernames."
"data_i","edited Feb 01 '15 at 15:43","
        Tab key == 4 spaces and auto-indent after curly braces in Vim
    ","How do I make vi-Vim never use tabs (converting spaces to tabs, bad!), makes the tab key == 4 spaces, and automatically indent code after curly brace blocks like Emacs does?Also, how do I save these settings so I never have to input them again?I've seen other questions related to this, but it always seems to be a little off from what I want.","As has been pointed out in a couple of other answers, the preferred method now is NOT to use smartindent, but instead use the following (in your .vimrc):filetype plugin indent on"" show existing tab with 4 spaces widthset tabstop=4"" when indenting with '>', use 4 spaces widthset shiftwidth=4"" On pressing tab, insert 4 spacesset expandtabIn your [.vimrc:][1] file:set smartindentset tabstop=4set shiftwidth=4set expandtabThe help files take a bit of time to get used to, but the more you read, the better Vim gets::help smartindentEven better, you can embed these settings in your source for portability::help auto-settingTo see your current settings::set allAs graywh points out in the comments, smartindent has been replaced by cindent which ""Works more cleverly"", although still mainly for languages with C-like syntax::help C-indenting"
"data_i","edited Aug 29 '15 at 10:19","
        offsetting an html anchor to adjust for fixed header
    ","I am trying to clean up the way my anchors work. I have a header that is fixed to the top of the page, so when you link to an anchor elsewhere in the page, the page jumps so the anchor is at the top of the page, leaving the content behind the fixed header (I hope that makes sense).  I need a way to offset the anchor by the 25px from the height of the header. I would prefer HTML or CSS, but Javascript would be acceptable as well.","You could just use CSS without any javascript.Give your anchor a class:<a class=""anchor"" id=""top""></a>You can then position the anchor an offset higher or lower than where it actually appears on the page, by making it a block element and relatively positioning it. -250px will position the anchor up 250pxa.anchor {    display: block;    position: relative;    top: -250px;    visibility: hidden;}"
"data_i","edited May 06 '20 at 08:49","
        LINQ's Distinct() on a particular property
    ","I am playing with LINQ to learn about it, but I can't figure out how to use Distinct when I do not have a simple list (a simple list of integers is pretty easy to do, this is not the question). What I if want to use Distinct on a list of an Object on one or more properties of the object?Example: If an object is Person, with Property Id. How can I get all Person and use Distinct on them with the property Id of the object?Person1: Id=1, Name=""Test1""Person2: Id=1, Name=""Test1""Person3: Id=2, Name=""Test2""How can I get just Person1 and Person3? Is that possible?If it's not possible with LINQ, what would be the best way to have a list of Person depending on some of its properties in .NET 3.5?","What if I want to obtain a distinct list based on one or more properties?Simple! You want to group them and pick a winner out of the group.List<Person> distinctPeople = allPeople  .GroupBy(p => p.PersonId)  .Select(g => g.First())  .ToList();If you want to define groups on multiple properties, here's how:List<Person> distinctPeople = allPeople  .GroupBy(p => new {p.PersonId, p.FavoriteColor} )  .Select(g => g.First())  .ToList();Note: Certain query providers are unable to resolve that each group must have at least one element, and that First is the appropriate method to call in that situation. If you find yourself working with such a query provider, FirstOrDefault may help get your query through the query provider.Note2: Consider this answer for an EF Core (prior to EF Core 6) compatible approach. https://stackoverflow.com/a/66529949/8155"
"data_i","edited Jul 25 '22 at 09:50","
        How can I center an absolutely positioned element in a div?
    ","I want to place a div (with position:absolute;) element in the center of the window. But I'm having problems doing so, because the width is unknown.I tried the following CSS code, but it needs to be adjusted because the width is responsive..center {  left: 50%;  bottom: 5px;}How can I achieve this?","This works for me:#content {  position: absolute;   left: 0;   right: 0;   margin-left: auto;   margin-right: auto;   width: 100px; /* Need a specific value to work */}<body>  <div>    <div id=""content"">      I'm the content    </div>  </div></body>"
"data_i","edited Mar 27 '18 at 11:39","
        Difference between require, include, require_once and include_once?
    ","In PHP:When should I use require vs. include?When should I use require_once vs. include_once?","There are require and include_once as well.So your question should be... When should I use require vs. include?When should I use require_once vs. requireThe answer to 1 is described here.The require() function is identical to include(), except that it handles errors differently. If an error occurs, the include() function generates a warning, but the script will continue execution. The require() generates a fatal error, and the script will stop.The answer to 2 can be found here.The require_once() statement is identical to require() except PHP will check if the file has already been included, and if so, not include (require) it again."
"data_i","edited Jun 19 '14 at 07:56","
        How to redirect output to a file and stdout
    ","In bash, calling foo would display any output from that command on the stdout.Calling foo > output would redirect any output from that command to the file specified (in this case 'output').Is there a way to redirect output to a file and have it display on stdout?","The command you want is named tee:foo | tee output.fileFor example, if you only care about stdout:ls -a | tee output.fileIf you want to include stderr, do:program [arguments...] 2>&1 | tee outfile2>&1 redirects channel 2 (stderr/standard error) into channel 1 (stdout/standard output), such that both is written as stdout. It is also directed to the given output file as of the tee command.Furthermore, if you want to append to the log file, use tee -a as:program [arguments...] 2>&1 | tee -a outfile"
"data_i","edited Jul 01 '19 at 23:19","
        How do I remove a single file from the staging area (undo git add)?
    ","Situation: I have a Git repository with files already in the index.  I make changes to several files, open Git and add these files to my staging area with ""git add .""Question: How do I remove one of those files from the staging area but not remove it from the index or undo the changes to the file itself?","If I understand the question correctly, you simply want to ""undo"" the git add that was done for that file.If you need to remove a single file from the staging area, usegit reset HEAD -- <file>If you need to remove a whole directory (folder) from the staging area, usegit reset HEAD -- <directoryName>Your modifications will be kept. When you run git status the file will once again show up as modified but not yet staged.See the git reset man page for details."
"data_i","edited Aug 31 '22 at 05:41","
        Why there are two ways to unstage a file in Git?
    ","Sometimes git suggests git rm --cached to unstage a file, sometimes git reset HEAD file. When should I use which?EDIT:D:\code\gt2>git initInitialized empty Git repository in D:/code/gt2/.git/D:\code\gt2>touch aD:\code\gt2>git status# On branch master## Initial commit## Untracked files:#   (use ""git add <file>..."" to include in what will be committed)##       anothing added to commit but untracked files present (use ""git add"" to track)D:\code\gt2>git add aD:\code\gt2>git status# On branch master## Initial commit## Changes to be committed:#   (use ""git rm --cached <file>..."" to unstage)##       new file:   a#D:\code\gt2>git commit -m a[master (root-commit) c271e05] a 0 files changed, 0 insertions(+), 0 deletions(-) create mode 100644 aD:\code\gt2>touch bD:\code\gt2>git status# On branch master# Untracked files:#   (use ""git add <file>..."" to include in what will be committed)##       bnothing added to commit but untracked files present (use ""git add"" to track)D:\code\gt2>git add bD:\code\gt2>git status# On branch master# Changes to be committed:#   (use ""git reset HEAD <file>..."" to unstage)##       new file:   b#","git rm --cached <filePath> does not unstage a file, it actually stages the removal of the file(s) from the repo (assuming it was already committed before) but leaves the file in your working tree (leaving you with an untracked file).git reset -- <filePath> will unstage any staged changes for the given file(s).That said, if you used git rm --cached on a new file that is staged, it would basically look like you had just unstaged it since it had never been committed before.Update git 2.24In this newer version of git you can use git restore --staged instead of git reset.See git docs."
"data_i","asked Jun 07 '13 at 10:26","
        Relative imports in Python 3
    ","I want to import a function from another file in the same directory.Usually, one of the following works:from .mymodule import myfunctionfrom mymodule import myfunction...but the other one gives me one of these errors:ImportError: attempted relative import with no known parent packageModuleNotFoundError: No module named 'mymodule'SystemError: Parent module '' not loaded, cannot perform relative importWhy is this?","unfortunately, this module needs to be inside the package, and it alsoneeds to be runnable as a script, sometimes. Any idea how I couldachieve that?It's quite common to have a layout like this...main.pymypackage/    __init__.py    mymodule.py    myothermodule.py...with a mymodule.py like this...#!/usr/bin/env python3# Exported functiondef as_int(a):    return int(a)# Test function for module  def _test():    assert as_int('1') == 1if __name__ == '__main__':    _test()...a myothermodule.py like this...#!/usr/bin/env python3from .mymodule import as_int# Exported functiondef add(a, b):    return as_int(a) + as_int(b)# Test function for module  def _test():    assert add('1', '1') == 2if __name__ == '__main__':    _test()...and a main.py like this...#!/usr/bin/env python3from mypackage.myothermodule import adddef main():    print(add('1', '1'))if __name__ == '__main__':    main()...which works fine when you run main.py or mypackage/mymodule.py, but fails with mypackage/myothermodule.py, due to the relative import...from .mymodule import as_intThe way you're supposed to run it is...python3 -m mypackage.myothermodule...but it's somewhat verbose, and doesn't mix well with a shebang line like #!/usr/bin/env python3.The simplest fix for this case, assuming the name mymodule is globally unique, would be to avoid using relative imports, and just use...from mymodule import as_int...although, if it's not unique, or your package structure is more complex, you'll need to include the directory containing your package directory in PYTHONPATH, and do it like this...from mypackage.mymodule import as_int...or if you want it to work ""out of the box"", you can frob the PYTHONPATH in code first with this...import sysimport osSCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))sys.path.append(os.path.dirname(SCRIPT_DIR))from mypackage.mymodule import as_intIt's kind of a pain, but there's a clue as to why in an email written by a certain Guido van Rossum...I'm -1 on this and on any other proposed twiddlings of the __main__machinery. The only use case seems to be running scripts that happento be living inside a module's directory, which I've always seen as anantipattern. To make me change my mind you'd have to convince me thatit isn't.Whether running scripts inside a package is an antipattern or not is subjective, but personally I find it really useful in a package I have which contains some custom wxPython widgets, so I can run the script for any of the source files to display a wx.Frame containing only that widget for testing purposes."
"data_i","edited Apr 11 '22 at 12:04","
        How can I check for an active Internet connection on iOS or macOS?
    ","I would like to check to see if I have an Internet connection on iOS using the Cocoa Touch libraries or on macOS using the Cocoa libraries.I came up with a way to do this using an NSURL. The way I did it seems a bit unreliable (because even Google could one day be down and relying on a third party seems bad), and while I could check to see for a response from some other websites if Google didn't respond, it does seem wasteful and an unnecessary overhead on my application.- (BOOL)connectedToInternet {    NSString *URLString = [NSString stringWithContentsOfURL:[NSURL URLWithString:@""http://www.google.com""]];    return ( URLString != NULL ) ? YES : NO;}Is what I have done bad, (not to mention stringWithContentsOfURL is deprecated in iOS 3.0 and macOS 10.4) and if so, what is a better way to accomplish this?","Important: This check should always be performed asynchronously. The majority of answers below are synchronous so be careful otherwise you'll freeze up your app.SwiftInstall via CocoaPods or Carthage: https://github.com/ashleymills/Reachability.swiftTest reachability via closureslet reachability = Reachability()!reachability.whenReachable = { reachability in    if reachability.connection == .wifi {        print(""Reachable via WiFi"")    } else {        print(""Reachable via Cellular"")    }}reachability.whenUnreachable = { _ in    print(""Not reachable"")}do {    try reachability.startNotifier()} catch {    print(""Unable to start notifier"")}Objective-CAdd SystemConfiguration framework to the project but don't worry about including it anywhereAdd Tony Million's version of Reachability.h and Reachability.m to the project (found here: https://github.com/tonymillion/Reachability)Update the interface section#import ""Reachability.h""// Add this to the interface in the .m file of your view controller@interface MyViewController (){    Reachability *internetReachableFoo;}@endThen implement this method in the .m file of your view controller which you can call// Checks if we have an internet connection or not- (void)testInternetConnection{    internetReachableFoo = [Reachability reachabilityWithHostname:@""www.google.com""];    // Internet is reachable    internetReachableFoo.reachableBlock = ^(Reachability*reach)    {        // Update the UI on the main thread        dispatch_async(dispatch_get_main_queue(), ^{            NSLog(@""Yayyy, we have the interwebs!"");        });    };    // Internet is not reachable    internetReachableFoo.unreachableBlock = ^(Reachability*reach)    {        // Update the UI on the main thread        dispatch_async(dispatch_get_main_queue(), ^{            NSLog(@""Someone broke the internet :("");        });    };    [internetReachableFoo startNotifier];}Important Note: The Reachability class is one of the most used classes in projects so you might run into naming conflicts with other projects.  If this happens, you'll have to rename one of the pairs of Reachability.h and Reachability.m files to something else to resolve the issue.Note: The domain you use doesn't matter. It's just testing for a gateway to any domain."
"data_i","edited Aug 06 '21 at 10:18","
        How can I output MySQL query results in CSV format?
    ","Is there an easy way to run a MySQL query from the Linux command line and output the results in CSV format?Here's what I'm doing now:mysql -u uid -ppwd -D dbname << EOQ | sed -e 's/        /,/g' | tee list.csvselect id, concat(""\"""",name,""\"""") as namefrom studentsEOQIt gets messy when there are a lot of columns that need to be surrounded by quotes, or if there are quotes in the results that need to be escaped.","From Save MySQL query results into a text or CSV file:SELECT order_id,product_name,qtyFROM ordersWHERE foo = 'bar'INTO OUTFILE '/var/lib/mysql-files/orders.csv'FIELDS TERMINATED BY ','ENCLOSED BY '""'LINES TERMINATED BY '\n';Note: That syntax may need to be reordered toSELECT order_id,product_name,qtyINTO OUTFILE '/var/lib/mysql-files/orders.csv'FIELDS TERMINATED BY ','ENCLOSED BY '""'LINES TERMINATED BY '\n'FROM ordersWHERE foo = 'bar';in more recent versions of MySQL.Using this command, columns names will not be exported.Also note that /var/lib/mysql-files/orders.csv will be on the server that is running MySQL. The user that the MySQL process is running under must have permissions to write to the directory chosen, or the command will fail.If you want to write output to your local machine from a remote server (especially a hosted or virtualize machine such as Heroku or Amazon RDS), this solution is not suitable."
"data_i","edited Mar 27 '18 at 01:26","
        How can I permanently enable line numbers in IntelliJ?
    ","How can I permanently enable line numbers in IntelliJ IDEA?","IntelliJ 14.X OnwardsFrom version 14.0 onwards, the path to the setting dialog is slightly different, a General submenu has been added between Editor and Appearance as shown belowIntelliJ 8.1.2 - 13.XFrom IntelliJ 8.1.2 onwards, this option is in File | Settings1. Within the IDE Settings section of that dialog, you'll find it under Editor | Appearance.On a Mac, these are named IntelliJ IDEA | Preferences..."
"data_i","edited Jul 17 '19 at 08:00","
        What is the maximum value for an int32?
    ","I can never remember the number. I need a memory rule.","It's 2,147,483,647. Easiest way to memorize it is via a tattoo."
"data_i","edited May 20 '21 at 05:19","
        Strange OutOfMemory issue while loading an image to a Bitmap object
    ","I have a ListView with a couple of image buttons on each row. When the user clicks the list row, it launches a new activity. I have had to build my own tabs because of an issue with the camera layout. The activity that gets launched for the result is a map. If I click on my button to launch the image preview (load an image off the SD card) the application returns from the activity back to the ListView activity to the result handler to relaunch my new activity which is nothing more than an image widget.The image preview on the ListView is being done with the cursor and ListAdapter. This makes it pretty simple, but I am not sure how I can put a resized image (I.e. Smaller bit size not pixel as the src for the image button on the fly. So I just resized the image that came off the phone camera.The issue is that I get an OutOfMemoryError when it tries to go back and re-launch the 2nd activity.Is there a way I can build the list adapter easily row by row, where I can resize on the fly (bitwise)?This would be preferable as I also need to make some changes to the properties of the widgets/elements in each row as I am unable to select a row with the touch screen because of the focus issue. (I can use rollerball.)I know I can do an out of band resize and save my image, but that is not really what I want to do, but some sample code for that would be nice.As soon as I disabled the image on the ListView it worked fine again.FYI: This is how I was doing it:String[] from = new String[] { DBHelper.KEY_BUSINESSNAME, DBHelper.KEY_ADDRESS,    DBHelper.KEY_CITY, DBHelper.KEY_GPSLONG, DBHelper.KEY_GPSLAT,    DBHelper.KEY_IMAGEFILENAME  + """"};int[] to = new int[] { R.id.businessname, R.id.address, R.id.city, R.id.gpslong,    R.id.gpslat, R.id.imagefilename };notes = new SimpleCursorAdapter(this, R.layout.notes_row, c, from, to);setListAdapter(notes);Where R.id.imagefilename is a ButtonImage.Here is my LogCat:01-25 05:05:49.877: ERROR/dalvikvm-heap(3896): 6291456-byte external allocation too large for this process.01-25 05:05:49.877: ERROR/(3896): VM wont let us allocate 6291456 bytes01-25 05:05:49.877: ERROR/AndroidRuntime(3896): Uncaught handler: thread main exiting due to uncaught exception01-25 05:05:49.917: ERROR/AndroidRuntime(3896): java.lang.OutOfMemoryError: bitmap size exceeds VM budget01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.graphics.BitmapFactory.nativeDecodeStream(Native Method)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.graphics.BitmapFactory.decodeStream(BitmapFactory.java:304)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.graphics.BitmapFactory.decodeFile(BitmapFactory.java:149)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.graphics.BitmapFactory.decodeFile(BitmapFactory.java:174)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.graphics.drawable.Drawable.createFromPath(Drawable.java:729)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.widget.ImageView.resolveUri(ImageView.java:484)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.widget.ImageView.setImageURI(ImageView.java:281)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.widget.SimpleCursorAdapter.setViewImage(SimpleCursorAdapter.java:183)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.widget.SimpleCursorAdapter.bindView(SimpleCursorAdapter.java:129)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.widget.CursorAdapter.getView(CursorAdapter.java:150)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.widget.AbsListView.obtainView(AbsListView.java:1057)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.widget.ListView.makeAndAddView(ListView.java:1616)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.widget.ListView.fillSpecific(ListView.java:1177)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.widget.ListView.layoutChildren(ListView.java:1454)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.widget.AbsListView.onLayout(AbsListView.java:937)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.view.View.layout(View.java:5611)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.widget.LinearLayout.setChildFrame(LinearLayout.java:1119)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.widget.LinearLayout.layoutHorizontal(LinearLayout.java:1108)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.widget.LinearLayout.onLayout(LinearLayout.java:922)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.view.View.layout(View.java:5611)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.widget.FrameLayout.onLayout(FrameLayout.java:294)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.view.View.layout(View.java:5611)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.widget.LinearLayout.setChildFrame(LinearLayout.java:1119)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.widget.LinearLayout.layoutVertical(LinearLayout.java:999)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.widget.LinearLayout.onLayout(LinearLayout.java:920)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.view.View.layout(View.java:5611)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.widget.FrameLayout.onLayout(FrameLayout.java:294)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.view.View.layout(View.java:5611)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.view.ViewRoot.performTraversals(ViewRoot.java:771)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.view.ViewRoot.handleMessage(ViewRoot.java:1103)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.os.Handler.dispatchMessage(Handler.java:88)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.os.Looper.loop(Looper.java:123)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at android.app.ActivityThread.main(ActivityThread.java:3742)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at java.lang.reflect.Method.invokeNative(Native Method)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at java.lang.reflect.Method.invoke(Method.java:515)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:739)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:497)01-25 05:05:49.917: ERROR/AndroidRuntime(3896):     at dalvik.system.NativeStart.main(Native Method)01-25 05:10:01.127: ERROR/AndroidRuntime(3943): ERROR: thread attach failed I also have a new error when displaying an image:22:13:18.594: DEBUG/skia(4204): xxxxxxxxxxx jpeg error 20 Improper call to JPEG library in state %d22:13:18.604: INFO/System.out(4204): resolveUri failed on bad bitmap uri: 22:13:18.694: ERROR/dalvikvm-heap(4204): 6291456-byte external allocation too large for this process.22:13:18.694: ERROR/(4204): VM won't let us allocate 6291456 bytes22:13:18.694: DEBUG/skia(4204): xxxxxxxxxxxxxxxxxxxx allocPixelRef failed","To fix the OutOfMemory error, you should do something like this:BitmapFactory.Options options = new BitmapFactory.Options();options.inSampleSize = 8;Bitmap preview_bitmap = BitmapFactory.decodeStream(is, null, options);This inSampleSize option reduces memory consumption.Here's a complete method. First it reads image size without decoding the content itself. Then it finds the best inSampleSize value, it should be a power of 2, and finally the image is decoded.// Decodes image and scales it to reduce memory consumptionprivate Bitmap decodeFile(File f) {    try {        // Decode image size        BitmapFactory.Options o = new BitmapFactory.Options();        o.inJustDecodeBounds = true;        BitmapFactory.decodeStream(new FileInputStream(f), null, o);        // The new size we want to scale to        final int REQUIRED_SIZE=70;        // Find the correct scale value. It should be the power of 2.        int scale = 1;        while(o.outWidth / scale / 2 >= REQUIRED_SIZE &&               o.outHeight / scale / 2 >= REQUIRED_SIZE) {            scale *= 2;        }        // Decode with inSampleSize        BitmapFactory.Options o2 = new BitmapFactory.Options();        o2.inSampleSize = scale;        return BitmapFactory.decodeStream(new FileInputStream(f), null, o2);    } catch (FileNotFoundException e) {}    return null;}"
"data_i","edited Jan 14 '17 at 17:01","
        How do I copy folder with files to another folder in Unix/Linux?
    ","I am having some issues to copy a folder with files in that folder into another folder. Command cp -r doesn't copy files in the folder.","The option you're looking for is -R.cp -R path_to_source path_to_destination/If destination doesn't exist, it will be created.-R means copy directories recursively. You can also use -r since it's case-insensitive.To copy everything inside the source folder (symlinks, hidden files) without copying the source folder itself use -a flag along with trailing /. in the source (as per @muni764's / @Anton Krug's comment):cp -a path_to_source/. path_to_destination/"
"data_i","edited Dec 21 '15 at 19:29","
        How do I reformat HTML code using Sublime Text 2?
    ","I've got some poorly-formatted HTML code that I'd like to reformat. Is there a command that will automatically reformat HTML code in Sublime Text 2 so it looks better and is easier to read?","You don't need any plugins to do this.Just select all lines (CTRL+A) and then from the menu select Edit → Line → Reindent.This will work if your file is saved with an extension that contains HTML like .html or .php.If you do this often, you may find this key mapping useful:{ ""keys"": [""ctrl+shift+r""], ""command"": ""reindent"" , ""args"": { ""single_line"": false } }If your file is not saved (e.g. you just pasted in a snippet to a new window), you can manually set the language for indentation by selecting the menu View → Syntax → language of choice before selecting the reindent option."
"data_i","asked Sep 17 '08 at 01:56","
        Create Generic method constraining T to an Enum
    ","I'm building a function to extend the Enum.Parse concept thatAllows a default value to be parsed in case that an Enum value is not foundIs case insensitiveSo I wrote the following:public static T GetEnumFromString<T>(string value, T defaultValue) where T : Enum{    if (string.IsNullOrEmpty(value)) return defaultValue;    foreach (T item in Enum.GetValues(typeof(T)))    {        if (item.ToString().ToLower().Equals(value.Trim().ToLower())) return item;    }    return defaultValue;}I am getting a Error Constraint cannot be special class System.Enum.Fair enough, but is there a workaround to allow a Generic Enum, or am I going to have to mimic the Parse function and pass a type as an attribute, which forces the ugly boxing requirement to your code.EDIT All suggestions below have been greatly appreciated, thanks.Have settled on (I've left the loop to maintain case insensitivity - I am using this when parsing XML)public static class EnumUtils{    public static T ParseEnum<T>(string value, T defaultValue) where T : struct, IConvertible    {        if (!typeof(T).IsEnum) throw new ArgumentException(""T must be an enumerated type"");        if (string.IsNullOrEmpty(value)) return defaultValue;        foreach (T item in Enum.GetValues(typeof(T)))        {            if (item.ToString().ToLower().Equals(value.Trim().ToLower())) return item;        }        return defaultValue;    }}EDIT: (16th Feb 2015) Christopher Currens has posted a compiler enforced type-safe generic solution in MSIL or F# below, which is well worth a look, and an upvote. I will remove this edit if the solution bubbles further up the page.EDIT 2: (13th Apr 2021) As this has now been addressed, and supported, since C# 7.3, I have changed the accepted answer, though full perusal of the top answers is worth it for academic, and historical, interest :)","Since Enum Type implements IConvertible interface, a better implementation should be something like this:public T GetEnumFromString<T>(string value) where T : struct, IConvertible{   if (!typeof(T).IsEnum)    {      throw new ArgumentException(""T must be an enumerated type"");   }   //...}This will still permit passing of value types implementing IConvertible. The chances are rare though."
"data_i","edited Apr 09 '22 at 08:24","
        What is the use of ""assert"" in Python?
    ","What does assert mean? How is it used?","The assert statement exists in almost every programming language. It has two main uses:It helps detect problems early in your program, where the cause is clear, rather than later when some other operation fails. A type error in Python, for example, can go through several layers of code before actually raising an Exception if not caught early on.It works as documentation for other developers reading the code, who see the assert and can confidently say that its condition holds from now on.When you do...assert condition... you're telling the program to test that condition, and immediately trigger an error if the condition is false.In Python, it's roughly equivalent to this:if not condition:    raise AssertionError()Try it in the Python shell:>>> assert True # nothing happens>>> assert FalseTraceback (most recent call last):  File ""<stdin>"", line 1, in <module>AssertionErrorAssertions can include an optional message, and you can disable them when running the interpreter.To print a message if the assertion fails:assert False, ""Oh no! This assertion failed!""Do not use parenthesis to call assert like a function. It is a statement. If you do assert(condition, message) you'll be running the assert with a (condition, message) tuple as first parameter.As for disabling them, when running python in optimized mode, where __debug__ is False, assert statements will be ignored. Just pass the -O flag:python -O script.pySee here for the relevant documentation."
"data_i","edited May 23 '17 at 12:34","
        Calculate difference between two dates (number of days)?
    ","I see that this question has been answered for Java, JavaScript, and PHP, but not C#. So, how might one calculate the number of days between two dates in C#?","Assuming StartDate and EndDate are of type DateTime:(EndDate - StartDate).TotalDays"
"data_i","edited Jan 31 '19 at 15:27","
        How can I know if a branch has been already merged into master?
    ","I have a git repository with multiple branches. How can I know which branches are already merged into the master branch?","git branch --merged master lists branches merged into mastergit branch --merged lists branches merged into HEAD (i.e. tip of current branch)git branch --no-merged lists branches that have not been mergedBy default this applies to only the local branches.  The -a flag will show both local and remote branches, and the -r flag shows only the remote branches."
"data_i","edited May 19 '18 at 14:42","
        What should be in my .gitignore for an Android Studio project?
    ","What files should be in my .gitignore for an Android Studio project?I've seen several examples that all include .iml but IntelliJ docs say that .iml must be included in your source control.","Updated to Android Studio 3.0Please share missing items in comments.A late answer but this alternative answer was not right for us ...So, here's our gitignore file:#built application files*.apk*.ap_*.aab                           # files for the dex VM*.dex                            # Java class files*.class                            # generated filesbin/gen/                            # Local configuration file (sdk path, etc)local.properties                        # Windows thumbnail dbThumbs.db                # OSX files.DS_Store                            # Android Studio*.iml.idea#.idea/workspace.xml - remove # and delete .idea if it better suit your needs..gradlebuild/.navigationcaptures/output.json     #NDKobj/.externalNativeBuildSince Android Studio 2.2 and up to 3.0, new projects are created with this gitignore file:*.iml.gradle/local.properties/.idea/workspace.xml/.idea/libraries.DS_Store/build/captures.externalNativeBuildDeprecated - for older project format, add this section to your gitignore file:/*/out/*/*/build/*/*/production*.iws*.ipr*~*.swpThis file should be located in the project's root folder and not inside the project's module folder.Edit Notes:Since version 0.3+ it seems you can commit and push *.iml and build.gradle files. If your project is based on Gradle: in the new open/import dialog, you should check the ""use auto import"" checkbox and mark the ""use default gradle wrapper (recommended)"" radio button. All paths are now relative as @George suggested.Updated answer according to @128KB attached source and @Skela suggestions"
"data_i","edited Jul 19 '21 at 20:24","
        How to manually send HTTP POST requests from Firefox or Chrome browser
    ","I want to test some URLs in a web application I'm working on. For that I would like to manually create HTTP POST requests (meaning I can add whatever parameters I like).Is there any functionality in Chrome and/or Firefox that I'm missing?","I have been making a Chrome app called Postman for this type of stuff. All the other extensions seemed a bit dated so made my own. It also has a bunch of other features which have been helpful for documenting our own API here.Postman now also has native apps (i.e. standalone) for Windows, Mac and Linux! It is more preferable now to use native apps, read more here."
"data_i","edited May 10 '22 at 19:15","
        What are these three dots in React doing?
    ","What does the ... do in this React (using JSX) code and what is it called?<Modal {...this.props} title='Modal heading' animation={false}>","That's property spread notation. It was added in ES2018 (spread for arrays/iterables was earlier, ES2015), but it's been supported in React projects for a long time via transpilation (as ""JSX spread attributes"" even though you could do it elsewhere, too, not just attributes).{...this.props} spreads out the ""own"" enumerable properties in props as discrete properties on the Modal element you're creating. For instance, if this.props contained a: 1 and b: 2, then<Modal {...this.props} title='Modal heading' animation={false}>would be the same as<Modal a={this.props.a} b={this.props.b} title='Modal heading' animation={false}>But it's dynamic, so whatever ""own"" properties are in props are included.Since children is an ""own"" property in props, spread will include it. So if the component where this appears had child elements, they'll be passed on to Modal. Putting child elements between the opening tag and closing tags is just syntactic sugar — the good kind — for putting a children property in the opening tag. Example:class Example extends React.Component {  render() {    const { className, children } = this.props;    return (      <div className={className}>      {children}      </div>    );  }}ReactDOM.render(  [    <Example className=""first"">      <span>Child in first</span>    </Example>,    <Example className=""second"" children={<span>Child in second</span>} />  ],  document.getElementById(""root""));.first {  color: green;}.second {  color: blue;}<div id=""root""></div><script src=""https://cdnjs.cloudflare.com/ajax/libs/react/16.6.3/umd/react.production.min.js""></script><script src=""https://cdnjs.cloudflare.com/ajax/libs/react-dom/16.6.3/umd/react-dom.production.min.js""></script>Spread notation is handy not only for that use case, but for creating a new object with most (or all) of the properties of an existing object — which comes up a lot when you're updating state, since you can't modify state directly:this.setState(prevState => {    return {foo: {...prevState.foo, a: ""updated""}};});That replaces this.state.foo with a new object with all the same properties as foo except the a property, which becomes ""updated"":const obj = {  foo: {    a: 1,    b: 2,    c: 3  }};console.log(""original"", obj.foo);// Creates a NEW object and assigns it to `obj.foo`obj.foo = {...obj.foo, a: ""updated""};console.log(""updated"", obj.foo);.as-console-wrapper {  max-height: 100% !important;}"
"data_i","edited Feb 25 '16 at 22:16","
        How do I combine a background-image and CSS3 gradient on the same element?
    ","How do I use CSS3 gradients for my background-color and then apply a background-image to apply some sort of light transparent texture?","Multiple backgrounds!body {  background: #eb01a5;  background-image: url(""IMAGE_URL""); /* fallback */  background-image: url(""IMAGE_URL""), linear-gradient(#eb01a5, #d13531); /* W3C */}These 2 lines are the fallback for any browser that doesn't do gradients. See notes for stacking images only IE < 9 below.Line 1 sets a flat background color.Line 2 sets the background image fallback.The final line sets a background image and gradient for browsers that can handle them.Line 3 is for all relatively modern browsers.Nearly all current browsers have support for multiple background images and css backgrounds. See http://caniuse.com/#feat=css-gradients for browser support. For a good post on why you don't need multiple browser prefixes, see http://codepen.io/thebabydino/full/pjxVWp/Layer StackIt should be noted that the first defined image will be topmost in the stack. In this case, the image is on TOP of the gradient.For more information about background layering see http://www.w3.org/TR/css3-background/#layering.Stacking images ONLY (no gradients in the declaration) For IE < 9IE9 and up can stack images this same way. You could use this to create a gradient image for ie9, though personally, I wouldn't. However to be noted when using only images, ie < 9 will ignore the fallback statement and not show any image. This does not happen when a gradient is included. To use a single fallback image in this case I suggest using Paul Irish's wonderful Conditional HTML element along with your fallback code:.lte9 #target{ background-image: url(""IMAGE_URL""); }Background position, sizing etc.Other properties that would apply to a single image may also be comma separated. If only 1 value is supplied, that will be applied to all stacked images including the gradient. background-size: 40px; will constrain both the image and the gradient to 40px height and width. However using background-size: 40px, cover; will make the image 40px and the gradient will cover the element. To only apply a setting to one image, set the default for the other: background-position: 50%, 0 0; or for browsers that support it use initial: background-position: 50%, initial;You may also use the background shorthand, however this removes the fallback color and image.body{    background: url(""IMAGE_URL"") no-repeat left top, linear-gradient(#eb01a5, #d13531);}The same applies to background-position, background-repeat, etc. "
"data_i","edited Jun 24 '15 at 06:12","
        Removing multiple files from a Git repo that have already been deleted from disk
    ","I have a Git repo that I have deleted four files from using rm (not git rm), and my Git status looks like this:#    deleted:    file1.txt#    deleted:    file2.txt#    deleted:    file3.txt#    deleted:    file4.txtHow do I remove these files from Git without having to manually go through and add each file like this:git rm file1 file2 file3 file4Ideally, I'm looking for something that works in the same way that git add . does, if that's possible.","For Git 1.x$ git add -uThis tells git to automatically stage tracked files -- including deleting the previously tracked files. For Git 2.0To stage your whole working tree:$ git add -u :/To stage just the current path:$ git add -u ."
"data_i","edited Feb 13 '19 at 15:56","
        How to get the client IP address in PHP
    ","How can I get the client IP address using PHP?I want to keep record of the user who logged into my website through his/her IP address.","Whatever you do, make sure not to trust data sent from the client. $_SERVER['REMOTE_ADDR'] contains the real IP address of the connecting party. That is the most reliable value you can find. However, they can be behind a proxy server in which case the proxy may have set the $_SERVER['HTTP_X_FORWARDED_FOR'], but this value is easily spoofed. For example, it can be set by someone without a proxy, or the IP can be an internal IP from the LAN behind the proxy.This means that if you are going to save the $_SERVER['HTTP_X_FORWARDED_FOR'], make sure you also save the $_SERVER['REMOTE_ADDR'] value. E.g. by saving both values in different fields in your database.If you are going to save the IP to a database as a string, make sure you have space for at least 45 characters. IPv6 is here to stay and those addresses are larger than the older IPv4 addresses.(Note that IPv6 usually uses 39 characters at most but there is also a special IPv6 notation for IPv4 addresses which in its full form can be up to 45 characters. So if you know what you are doing you can use 39 characters, but if you just want to set and forget it, use 45)."
"data_i","edited Jul 13 '17 at 16:52","
        How do I move to end of line in Vim?
    ","I know how to generally move around in command mode, specifically, jumping to lines, etc. But what is the command to jump to the end of the line that I am currently on?","Just the $ (dollar sign) key.  You can use A to move to the end of the line and switch to editing mode (Append).  To jump the last non-blank character, you can press g then _ keys.The opposite of A is I (Insert mode at beginning of line), as an aside.  Pressing just the ^ will place your cursor at the first non-white-space character of the line."
"data_i","edited Dec 16 '21 at 09:03","
        How to force Docker for a clean build of an image
    ","I have build a Docker image from a Docker file using the below command.$ docker build -t u12_core -f u12_core .When I am trying to rebuild it with the same command, it's using the build cache like:Step 1 : FROM ubuntu:12.04 ---> eb965dfb09d2Step 2 : MAINTAINER Pavan Gupta <pavan.gupta@gmail.com> ---> Using cache ---> 4354ccf9dcd8Step 3 : RUN apt-get update ---> Using cache ---> bcbca2fcf204Step 4 : RUN apt-get install -y openjdk-7-jdk ---> Using cache ---> 103f1a261d44Step 5 : RUN apt-get install -y openssh-server ---> Using cache ---> dde41f8d0904Step 6 : RUN apt-get install -y git-core ---> Using cache ---> 9be002f08b6aStep 7 : RUN apt-get install -y build-essential ---> Using cache ---> a752fd73a698Step 8 : RUN apt-get install -y logrotate ---> Using cache ---> 93bca09b509dStep 9 : RUN apt-get install -y lsb-release ---> Using cache ---> fd4d10cf18bcStep 10 : RUN mkdir /var/run/sshd ---> Using cache ---> 63b4ecc39ff0Step 11 : RUN echo 'root:root' | chpasswd ---> Using cache ---> 9532e31518a6Step 12 : RUN sed -i 's/PermitRootLogin without-password/PermitRootLogin yes/' /etc/ssh/sshd_config ---> Using cache ---> 47d1660bd544Step 13 : RUN sed 's@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd ---> Using cache ---> d1f97f1c52f7Step 14 : RUN wget -O aerospike.tgz 'http://aerospike.com/download/server/latest/artifact/ubuntu12' ---> Using cache ---> bd7dde7a98b9Step 15 : RUN tar -xvf aerospike.tgz ---> Using cache ---> 54adaa09921fStep 16 : RUN dpkg -i aerospike-server-community-*/*.deb ---> Using cache ---> 11aba013eea5Step 17 : EXPOSE 22 3000 3001 3002 3003 ---> Using cache ---> e33aaa78a931Step 18 : CMD /usr/sbin/sshd -D ---> Using cache ---> 25f5fe70fa84Successfully built 25f5fe70fa84The cache shows that aerospike is installed. However, I don't find it inside containers spawn from this image, so I want to rebuild this image without using the cache. How can I force Docker to rebuild a clean image without the cache?","There's a --no-cache option:docker build --no-cache -t u12_core -f u12_core .In older versions of Docker you needed to pass --no-cache=true, but this is no longer the case."
"data_i","asked Jul 07 '10 at 17:47","
        How do I delete unpushed git commits?
    ","I accidentally committed to the wrong branch.How do I delete that commit?","Delete the most recent commit, keeping the work you've done:git reset --soft HEAD~1Delete the most recent commit, destroying the work you've done:git reset --hard HEAD~1"
"data_i","edited Jul 16 '19 at 16:08","
        How to do case insensitive string comparison?
    ","How do I perform case insensitive string comparison in JavaScript?","The simplest way to do it (if you're not worried about special Unicode characters) is to call toUpperCase:var areEqual = string1.toUpperCase() === string2.toUpperCase();"
"data_i","edited Aug 25 '15 at 09:16","
        How can I disable ARC for a single file in a project?
    ","I am using ARC successfully in my project. However, I have encountered a few files (e.g., in unit tests and mock objects) where the rules of ARC are a little more fragile right now. I recall hearing that there was a way to disable ARC on a per-file basis, though I have been unable to find this option.Is this possible? How do I disable ARC on a per-file basis?","It is possible to disable ARC for individual files by adding the -fno-objc-arc compiler flag for those files. You add compiler flags in Targets -> Build Phases -> Compile Sources. You have to double click on the right column of the row under Compiler Flags. You can also add it to multiple files by holding the cmd button to select the files and then pressing enter to bring up the flag edit box. (Note that editing multiple files will overwrite any flags that it may already have.)I created a sample project that has an example: https://github.com/jaminguy/NoArcSee this answer for more info:Disable Automatic Reference Counting for Some Files"
"data_i","edited Jan 04 '21 at 05:12","
        How can I uninstall npm modules in Node.js?
    ","As commonly known, any npm module can be installed by running a simple command: npm install <module_name>.I have installed a few modules that I do not use any more and I just want to get them off. I have a few questions regarding this:Do we have any command or process to uninstall a module from the root (something like npm uninstall <module_name>)or will simply removing the module files do?How does it affect us if we keep the unused modules?","The command is simply npm uninstall <name>The Node.js documents https://npmjs.org/doc/ have all the commands that you need to know with npm.A local install will be in the node_modules/ directory of your application. This won't affect the application if a module remains there with no references to it. If you're removing a global package, however, any applications referencing it will crash.Here are different options:npm uninstall <name> removes the module from node_modules but does not update package.jsonnpm uninstall <name> --save also removes it from dependenciesin package.jsonnpm uninstall <name> --save-dev also removes it from devDependencies in package.jsonnpm uninstall -g <name> --save also removes it globally"
"data_i","edited Sep 01 '21 at 15:46","
        How to switch databases in psql?
    ","In MySQL, I used use database_name;What's the psql equivalent?","In PostgreSQL, you can use the \connect meta-command of the client tool psql:\connect DBNAMEor in short:\c DBNAME"
"data_i","edited Apr 16 '20 at 08:11","
        YYYY-MM-DD format date in shell script
    ","I tried using $(date) in my bash shell script, however, I want the date in YYYY-MM-DD format.How do I get this?","In bash (>=4.2) it is preferable to use printf's built-in date formatter (part of bash) rather than the external date (usually GNU date).As such:# put current date as yyyy-mm-dd in $date# -1 -> explicit current date, bash >=4.3 defaults to current time if not provided# -2 -> start time for shellprintf -v date '%(%Y-%m-%d)T\n' -1 # put current date as yyyy-mm-dd HH:MM:SS in $dateprintf -v date '%(%Y-%m-%d %H:%M:%S)T\n' -1 # to print directly remove -v flag, as such:printf '%(%Y-%m-%d)T\n' -1# -> current date printed to terminalIn bash (<4.2): # put current date as yyyy-mm-dd in $datedate=$(date '+%Y-%m-%d')# put current date as yyyy-mm-dd HH:MM:SS in $datedate=$(date '+%Y-%m-%d %H:%M:%S')# print current date directlyecho $(date '+%Y-%m-%d')Other available date formats can be viewed from the date man pages (for external non-bash specific command):man date"
"data_i","edited Aug 26 '15 at 03:49","
        How to find the sum of an array of numbers
    ","Given an array [1, 2, 3, 4], how can I find the sum of its elements? (In this case, the sum would be 10.)I thought $.each might be useful, but I'm not sure how to implement it.","This'd be exactly the job for reduce.If you're using ECMAScript 2015 (aka ECMAScript 6):const sum = [1, 2, 3].reduce((partialSum, a) => partialSum + a, 0);console.log(sum); // 6For older JS:const sum = [1, 2, 3].reduce(add, 0); // with initial value to avoid when the array is emptyfunction add(accumulator, a) {  return accumulator + a;}console.log(sum); // 6Isn't that pretty? :-)"
"data_i","edited Aug 16 '22 at 15:54","
        How can I remove duplicate rows?
    ","I need to remove duplicate rows from a fairly large SQL Server table (i.e. 300,000+ rows).The rows, of course, will not be perfect duplicates because of the existence of the RowID identity field.MyTableRowID int not null identity(1,1) primary key,Col1 varchar(20) not null,Col2 varchar(2048) not null,Col3 tinyint not nullHow can I do this?","Assuming no nulls, you GROUP BY the unique columns, and SELECT the MIN (or MAX) RowId as the row to keep. Then, just delete everything that didn't have a row id:DELETE FROM MyTableLEFT OUTER JOIN (   SELECT MIN(RowId) as RowId, Col1, Col2, Col3    FROM MyTable    GROUP BY Col1, Col2, Col3) as KeepRows ON   MyTable.RowId = KeepRows.RowIdWHERE   KeepRows.RowId IS NULLIn case you have a GUID instead of an integer, you can replaceMIN(RowId)withCONVERT(uniqueidentifier, MIN(CONVERT(char(36), MyGuidColumn)))"
"data_i","edited Aug 04 '19 at 17:41","
        How to create a .gitignore file
    ","I need to add some rules to my .gitignore file. However, I can't find it in my project folder. Isn't it created automatically by Xcode? If not, what command allows me to create one?","If you're using Windows, it will not let you create a file without a filename in Windows Explorer. It will give you the error ""You must type a file name"" if you try to rename a text file as .gitignoreTo get around this, I used the following steps.Create the text file gitignore.txtOpen it in a text editor and add your rules, then save and closeHold Shift, right click the folder you're in, and then select Open command window hereThen rename the file in the command line, with ren gitignore.txt .gitignoreAlternatively, HenningCash suggests in the comments:You can get around this Windows Explorer error by appending a dot tothe filename without an extension: .gitignore.. It will be automaticallychanged to .gitignore."
"data_i","edited Dec 12 '15 at 19:49","
        Where does npm install packages?
    ","Can someone tell me where can I find the Node.js modules, which I installed using npm?","Global librariesYou can run npm list -g to see which global libraries are installed and where they're located. Use npm list -g | head -1 for truncated output showing just the path. If you want to display only main packages not its sub-packages which installs along with it - you can use - npm list --depth=0 which will show all packages and for getting only globally installed packages, just add -g i.e. npm list -g --depth=0.On Unix systems they are normally placed in /usr/local/lib/node or /usr/local/lib/node_modules when installed globally. If you set the NODE_PATH environment variable to this path, the modules can be found by node.Windows XP - %USERPROFILE%\AppData\npm\node_modulesWindows 7, 8 and 10 - %USERPROFILE%\AppData\Roaming\npm\node_modulesNon-global librariesNon-global libraries are installed the node_modules sub folder in the folder you are currently in. You can run npm list to see the installed non-global libraries for your current location.      When installing use -g option to install globallynpm install -g pm2 - pm2 will be installed globally. It will then typically be found in /usr/local/lib/node_modules (Use npm root -g to check where.)npm install pm2 - pm2 will be installed locally. It will then typically be found in the local directory in /node_modules"
"data_i","edited Apr 19 '20 at 11:48","
        How do I diff the same file between two different commits on the same branch?
    ","In Git, how could I compare the same file between two different commits (not contiguous) on the same branch (master for example)?I'm searching for a compare feature like the one in Visual SourceSafe (VSS) or Team Foundation Server (TFS).Is it possible in Git?","From the git-diff manpage:git diff [--options] <commit> <commit> [--] [<path>...]For instance, to see the difference for a file ""main.c"" between now and two commits back, here are three equivalent commands:$ git diff HEAD^^ HEAD main.c$ git diff HEAD^^..HEAD -- main.c$ git diff HEAD~2 HEAD -- main.c"
"data_i","edited Apr 19 '20 at 10:51","
        How to align content of a div to the bottom
    ","Say I have the following CSS and HTML code:#header {  height: 150px;}<div id=""header"">  <h1>Header title</h1>  Header content (one or multiple lines)</div>The header section is fixed height, but the header content may change.I would like the content of the header to be vertically aligned to the bottom of the header section, so the last line of text ""sticks"" to the bottom of the header section.So if there is only one line of text, it would be like:-----------------------------| Header title|||| header content (resulting in one line)-----------------------------And if there were three lines:-----------------------------| Header title|| header content (which is so| much stuff that it perfectly| spans over three lines)-----------------------------How can this be done in CSS?","Relative+absolute positioning is your best bet:#header {  position: relative;  min-height: 150px;}#header-content {  position: absolute;  bottom: 0;  left: 0;}#header, #header * {  background: rgba(40, 40, 100, 0.25);}<div id=""header"">  <h1>Title</h1>  <div id=""header-content"">And in the last place, where this might not be the case, they would be of long standing, would have taken deep root, and would not easily be extirpated. The scheme of revising the constitution, in order to correct recent breaches of it, as well as for other purposes, has been actually tried in one of the States.</div></div>But you may run into issues with that.  When I tried it I had problems with dropdown menus appearing below the content.  It's just not pretty.Honestly, for vertical centering issues and, well, any vertical alignment issues with the items aren't fixed height, it's easier just to use tables.Example: Can you do this HTML layout without using tables?"
"data_i","edited Mar 10 '22 at 17:03","
        Local Storage vs Cookies
    ","I want to reduce load times on my websites by moving all cookies into local storage since they seem to have the same functionality. Are there any pros/cons (especially performance-wise) in using local storage to replace cookie functionality except for the obvious compatibility issues?","Cookies and local storage serve different purposes. Cookies are primarily for reading server-side, local storage can only be read by the client-side. So the question is, in your app, who needs this data — the client or the server?If it's your client (your JavaScript), then by all means switch. You're wasting bandwidth by sending all the data in each HTTP header.If it's your server, local storage isn't so useful because you'd have to forward the data along somehow (with Ajax or hidden form fields or something). This might be okay if the server only needs a small subset of the total data for each request.You'll want to leave your session cookie as a cookie either way though.As per the technical difference, and also my understanding:Apart from being an old way of saving data, Cookies give you a limit of 4096 bytes (4095, actually) — it's per cookie. Local Storage is as big as 5MB per domain — SO Question also mentions it.localStorage is an implementation of the Storage Interface. It stores data with no expiration date, and gets cleared only through JavaScript, or clearing the Browser Cache / Locally Stored Data — unlike cookie expiry."
"data_i","edited Apr 09 '22 at 08:05","
        How do I create multiline comments in Python?
    ","How do I make multi-line comments? Most languages have block comment symbols like:/**/","You can use triple-quoted strings. When they're not a docstring (the first thing in a class/function/module), they are ignored.'''This is a multilinecomment.'''(Make sure to indent the leading ''' appropriately to avoid an IndentationError.)Guido van Rossum (creator of Python) tweeted this as a ""pro tip"".However, Python's style guide, PEP8, favors using consecutive single-line comments, like this:# This is a multiline# comment....and this is also what you'll find in many projects. Text editors usually have a shortcut to do this easily."
"data_i","edited Dec 01 '19 at 18:27","
        Is there a built-in function to print all the current properties and values of an object?
    ","So what I'm looking for here is something like PHP's print_r function.This is so I can debug my scripts by seeing what's the state of the object in question.","You want vars() mixed with pprint():from pprint import pprintpprint(vars(your_object))"
"data_i","edited Jul 17 '22 at 04:19","
        How do I sort a dictionary by key?
    ","How do I sort a dictionary by its keys?Example input:{2:3, 1:89, 4:5, 3:0}Desired output:{1:89, 2:3, 3:0, 4:5}","Note: for Python 3.7+, see this answerStandard Python dictionaries are unordered (until Python 3.7). Even if you sorted the (key,value) pairs, you wouldn't be able to store them in a dict in a way that would preserve the ordering.The easiest way is to use OrderedDict, which remembers the order in which the elements have been inserted:In [1]: import collectionsIn [2]: d = {2:3, 1:89, 4:5, 3:0}In [3]: od = collections.OrderedDict(sorted(d.items()))In [4]: odOut[4]: OrderedDict([(1, 89), (2, 3), (3, 0), (4, 5)])Never mind the way od is printed out; it'll work as expected:In [11]: od[1]Out[11]: 89In [12]: od[3]Out[12]: 0In [13]: for k, v in od.iteritems(): print k, v   ....: 1 892 33 04 5Python 3For Python 3 users, one needs to use the .items() instead of .iteritems():In [13]: for k, v in od.items(): print(k, v)   ....: 1 892 33 04 5"
"data_i","edited Sep 25 '22 at 04:49","
        Asynchronous vs synchronous execution. What is the difference?
    ","What is the difference between asynchronous and synchronous execution?","When you execute something synchronously, you wait for it to finish before moving on to another task. When you execute something asynchronously, you can move on to another task before it finishes.In the context of operating systems, this corresponds to executing a process or task on a ""thread."" A thread is a series of commands (a block of code) that exist as a unit of work. The operating system runs a given thread on a processor core. However, a processor core can only execute a single thread at once. It has no concept of running multiple threads simultaneously. The operating system can provide the illusion of running multiple threads at once by running each thread for a small slice of time (such as 1ms), and continuously switching between threads.Now, if you introduce multiple processor cores into the mix, then threads CAN execute at the same time. The operating system can allocate time to one thread on the first processor core, then allocate the same block of time to another thread on a different processor core.  All of this is about allowing the operating system to manage the completion of your task while you can go on in your code and do other things.Asynchronous programming is a complicated topic because of the semantics of how things tie together when you can do them at the same time. There are numerous articles and books on the subject; have a look!"
"data_i","edited Mar 31 '21 at 16:14","
        How can I use grep to show just filenames on Linux?
    ","How can I use grep to show just file-names (no in-line matches) on Linux?I am usually using something like:find . -iname ""*php"" -exec grep -H myString {} \;How can I just get the file-names (with paths), but without the matches? Do I have to use xargs? I didn't see a way to do this on my grep man page.","The standard option grep -l (that is a lowercase L) could do this.From the Unix standard:-l    (The letter ell.) Write only the names of files containing selected    lines to standard output. Pathnames are written once per file searched.    If the standard input is searched, a pathname of (standard input) will    be written, in the POSIX locale. In other locales, standard input may be    replaced by something more appropriate in those locales.You also do not need -H in this case."
"data_i","edited Apr 11 '22 at 22:03","
        What characters can be used for up/down triangle (arrow without stem) for display in HTML?
    ","I'm looking for a HTML or ASCII character which is a triangle pointing up or down so that I can use it as a toggle switch.I found ↑ (&uarr;), and ↓ (&darr;) - but those have a narrow stem. I'm looking just for the HTML arrow ""head"".","Unicode arrows heads:▲ - U+25B2 BLACK UP-POINTING TRIANGLE▼ - U+25BC BLACK DOWN-POINTING TRIANGLE▴ - U+25B4 SMALL BLACK UP-POINTING TRIANGLE▾ - U+25BE SMALL BLACK DOWN-POINTING TRIANGLEFor ▲ and ▼ use &#x25B2; and &#x25BC; respectively if you cannot include Unicode characters directly (use UTF-8!).Note that the font support for the smaller versions is not as good. Better to use the large versions in smaller font.More Unicode arrows are at:http://en.wikipedia.org/wiki/Arrow_%28symbol%29#Arrows_in_Unicodehttp://en.wikipedia.org/wiki/Geometric_ShapesLastly, these arrows are not ASCII, including ↑ and ↓: they are Unicode."
"data_i","edited Jun 13 '22 at 01:47","
        Trim string in JavaScript
    ","How do I remove all whitespace from the start and end of the string?","All browsers since IE9+ have trim() method for strings:"" \n test \n "".trim(); // returns ""test"" hereFor those browsers who does not support trim(), you can use this polyfill from MDN:if (!String.prototype.trim) {    (function() {        // Make sure we trim BOM and NBSP        var rtrim = /^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g;        String.prototype.trim = function() {            return this.replace(rtrim, '');        };    })();}That said, if using jQuery, $.trim(str) is also available and handles undefined/null.See this:String.prototype.trim=function(){return this.replace(/^\s+|\s+$/g, '');};String.prototype.ltrim=function(){return this.replace(/^\s+/,'');};String.prototype.rtrim=function(){return this.replace(/\s+$/,'');};String.prototype.fulltrim=function(){return this.replace(/(?:(?:^|\n)\s+|\s+(?:$|\n))/g,'').replace(/\s+/g,' ');};"
"data_i","edited Aug 10 '20 at 15:14","
        How to use SSH to run a local shell script on a remote machine?
    ","I have to run a local shell script (windows/Linux) on a remote machine.I have SSH configured on both machine A and B. My script is on machine A which will run some of my code on a remote machine, machine B.The local and remote computers can be either Windows or Unix based system.Is there a way to run do this using plink/ssh?","If Machine A is a Windows box, you can use Plink (part of PuTTY) with the -m parameter, and it will execute the local script on the remote server.plink root@MachineB -m local_script.shIf Machine A is a Unix-based system, you can use:ssh root@MachineB 'bash -s' < local_script.shYou shouldn't have to copy the script to the remote server to run it."
"data_i","edited Jun 26 '20 at 08:52","
        window.onload vs $(document).ready()
    ","What are the differences between JavaScript's window.onload and jQuery's $(document).ready() method?","The ready event occurs after the HTML document has been loaded, while the onload event occurs later, when all content (e.g. images) also has been loaded.The onload event is a standard event in the DOM, while the ready event is specific to jQuery. The purpose of the ready event is that it should occur as early as possible after the document has loaded, so that code that adds functionality to the elements in the page doesn't have to wait for all content to load."
"data_i","edited Nov 14 '21 at 00:30","
        JavaScriptSerializer - JSON serialization of enum as string
    ","I have a class that contains an enum property, and upon serializing the object using JavaScriptSerializer, my json result contains the integer value of the enumeration rather than its string ""name"".  Is there a way to get the enum as a string in my json without having to create a custom JavaScriptConverter?  Perhaps there's an attribute that I could decorate the enum definition, or object property, with?As an example:enum Gender { Male, Female }class Person{    int Age { get; set; }    Gender Gender { get; set; }}Desired JSON result:{ ""Age"": 35, ""Gender"": ""Male"" }Ideally looking for answer with built-in .NET framework classes, if not possible alternatives (like Json.net) are welcome.","I have found that Json.NET provides the exact functionality I'm looking for with a StringEnumConverter attribute:using Newtonsoft.Json;using Newtonsoft.Json.Converters;[JsonConverter(typeof(StringEnumConverter))]public Gender Gender { get; set; }More details at available on StringEnumConverter documentation.There are other places to configure this converter more globally: enum itself if you want enum always be serialized/deserialized as string:[JsonConverter(typeof(StringEnumConverter))]  enum Gender { Male, Female }In case anyone wants to avoid attribute decoration, you can add the converter to your JsonSerializer (suggested by Bjørn Egil): serializer.Converters.Add(new Newtonsoft.Json.Converters.StringEnumConverter()); and it will work for every enum it sees during that serialization (suggested by Travis). or JsonConverter (suggested by banana):JsonConvert.SerializeObject(MyObject,     new Newtonsoft.Json.Converters.StringEnumConverter());Additionally you can control casing and whether numbers are still accepted by using StringEnumConverter(NamingStrategy, Boolean) constructor."
"data_i","edited May 04 '17 at 19:39","
        Which MySQL data type to use for storing boolean values
    ","Since MySQL doesn't seem to have any 'boolean' data type, which data type do you 'abuse' for storing true/false information in MySQL?Especially in the context of writing and reading from/to a PHP script.Over time I have used and seen several approaches:tinyint, varchar fields containing the values 0/1,varchar fields containing the strings '0'/'1' or 'true'/'false'and finally enum Fields containing the two options 'true'/'false'.None of the above seems optimal. I tend to prefer the tinyint 0/1 variant, since automatic type conversion in PHP gives me boolean values rather simply.So which data type do you use? Is there a type designed for boolean values which I have overlooked? Do you see any advantages/disadvantages by using one type or another?","For MySQL 5.0.3 and higher, you can use BIT. The manual says:As of MySQL 5.0.3, the BIT data type is used to store bit-fieldvalues. A type of BIT(M) enables storage of M-bit values. M can rangefrom 1 to 64.Otherwise, according to the MySQL manual you can use BOOL or BOOLEAN, which are at the moment aliases of tinyint(1):Bool, Boolean: These types are synonyms for TINYINT(1). A value ofzero is considered false. Non-zerovalues are considered true.MySQL also states that:We intend to implement full booleantype handling, in accordance withstandard SQL, in a future MySQLrelease.References: http://dev.mysql.com/doc/refman/5.5/en/numeric-type-overview.html"
"data_i","edited Jun 06 '21 at 21:45","
        How to Sort a Multi-dimensional Array by Value
    ","How can I sort this array by the value of the ""order"" key?Even though the values are currently sequential, they will not always be.Array(    [0] => Array        (            [hashtag] => a7e87329b5eab8578f4f1098a152d6f4            [title] => Flower            [order] => 3        )    [1] => Array        (            [hashtag] => b24ce0cd392a5b0b8dedc66c25213594            [title] => Free            [order] => 2        )    [2] => Array        (            [hashtag] => e7d31fc0602fb2ede144d18cdffd816b            [title] => Ready            [order] => 1        ))","Try a usort. If you are still on PHP 5.2 or earlier, you'll have to define a sorting function first:function sortByOrder($a, $b) {    return $a['order'] - $b['order'];}usort($myArray, 'sortByOrder');Starting in PHP 5.3, you can use an anonymous function:usort($myArray, function($a, $b) {    return $a['order'] - $b['order'];});With PHP 7 you can use the spaceship operator:usort($myArray, function($a, $b) {    return $a['order'] <=> $b['order'];});Finally, in PHP 7.4 you can clean up a bit with an arrow function:usort($myArray, fn($a, $b) => $a['order'] <=> $b['order']);To extend this to multi-dimensional sorting, reference the second/third sorting elements if the first is zero - best explained below. You can also use this for sorting on sub-elements.usort($myArray, function($a, $b) {    $retval = $a['order'] <=> $b['order'];    if ($retval == 0) {        $retval = $a['suborder'] <=> $b['suborder'];        if ($retval == 0) {            $retval = $a['details']['subsuborder'] <=> $b['details']['subsuborder'];        }    }    return $retval;});If you need to retain key associations, use uasort() - see comparison of array sorting functions in the manual."
"data_i","edited Aug 08 '22 at 10:56","
        Check if table exists in SQL Server
    ","I would like this to be the ultimate discussion on how to check if a table exists in SQL Server 2000/2005 using SQL Statements.Here are two possible ways of doing it. Which one is the standard/best way of doing it?First way:IF EXISTS (SELECT 1            FROM INFORMATION_SCHEMA.TABLES            WHERE TABLE_TYPE='BASE TABLE'            AND TABLE_NAME='mytablename')    SELECT 1 AS res ELSE SELECT 0 AS res;Second way:IF OBJECT_ID (N'mytablename', N'U') IS NOT NULL    SELECT 1 AS res ELSE SELECT 0 AS res;MySQL provides the simpleSHOW TABLES LIKE '%tablename%'; statement. I am looking for something similar.","For queries like this it is always best to use an INFORMATION_SCHEMA view.  These views are (mostly) standard across many different databases and rarely change from version to version.To check if a table exists use:IF (EXISTS (SELECT *                  FROM INFORMATION_SCHEMA.TABLES                  WHERE TABLE_SCHEMA = 'TheSchema'                  AND  TABLE_NAME = 'TheTable'))BEGIN    --Do StuffEND"
"data_i","edited Aug 31 '20 at 22:05","
        Get a random item from a JavaScript array
    ","var items = Array(523, 3452, 334, 31, ..., 5346);How do I get random item from items?","var item = items[Math.floor(Math.random()*items.length)];"
"data_i","edited Nov 08 '15 at 18:09","
        How to count lines in a document?
    ","I have lines like these, and I want to know how many lines I actually have...09:16:39 AM  all    2.00    0.00    4.00    0.00    0.00    0.00    0.00    0.00   94.0009:16:40 AM  all    5.00    0.00    0.00    4.00    0.00    0.00    0.00    0.00   91.0009:16:41 AM  all    0.00    0.00    4.00    0.00    0.00    0.00    0.00    0.00   96.0009:16:42 AM  all    3.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00   96.0009:16:43 AM  all    0.00    0.00    1.00    0.00    1.00    0.00    0.00    0.00   98.0009:16:44 AM  all    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.0009:16:45 AM  all    2.00    0.00    6.00    0.00    0.00    0.00    0.00    0.00   92.00Is there a way to count them all using linux commands?","Use wc:wc -l <filename>This will output the number of lines in <filename>:$ wc -l /dir/file.txt3272485 /dir/file.txtOr, to omit the <filename> from the result use wc -l < <filename>:$ wc -l < /dir/file.txt3272485You can also pipe data to wc as well:$ cat /dir/file.txt | wc -l3272485$ curl yahoo.com --silent | wc -l63"
"data_i","edited Dec 04 '18 at 02:59","
        Maintain the aspect ratio of a div with CSS
    ","I want to create a div that can change its width/height as the window's width changes.Are there any CSS3 rules that would allow the height to change according to the width, while maintaining its aspect ratio?I know I can do this via JavaScript, but I would prefer using only CSS.","Just create a wrapper <div> with a percentage value for padding-bottom, like this:.demoWrapper {  padding: 10px;  background: white;  box-sizing: border-box;  resize: horizontal;  border: 1px dashed;  overflow: auto;  max-width: 100%;  height: calc(100vh - 16px);}div {  width: 100%;  padding-bottom: 75%;  background: gold; /** <-- For the demo **/}<div class=""demoWrapper"">  <div></div></div>It will result in a <div> with height equal to 75% of the width of its container (a 4:3 aspect ratio).This relies on the fact that for padding :The percentage is calculated with respect to the width of the generated box's containing block [...]  (source: w3.org, emphasis mine)Padding-bottom values for other aspect ratios and 100% width :aspect ratio  | padding-bottom value--------------|----------------------    16:9      |       56.25%    4:3       |       75%    3:2       |       66.66%    8:5       |       62.5%Placing content in the div :In order to keep the aspect ratio of the div and prevent its content from stretching it, you need to add an absolutely positioned child and stretch it to the edges of the wrapper with:div.stretchy-wrapper {  position: relative;}div.stretchy-wrapper > div {  position: absolute;  top: 0; bottom: 0; left: 0; right: 0;}Here's a demo and another more in depth demo"
"data_i","edited Sep 10 '22 at 10:43","
        Removing duplicates in lists
    ","Pretty much I need to write a program to check if a list has any duplicates and if it does it removes them and returns a new list with the items that weren't duplicated/removed. This is what I have but to be honest I do not know what to do.def remove_duplicates():    t = ['a', 'b', 'c', 'd']    t2 = ['a', 'c', 'd']    for t in t2:        t.append(t.remove())    return t","The common approach to get a unique collection of items is to use a set. Sets are unordered collections of distinct objects. To create a set from any iterable, you can simply pass it to the built-in set() function. If you later need a real list again, you can similarly pass the set to the list() function.The following example should cover whatever you are trying to do:>>> t = [1, 2, 3, 1, 2, 3, 5, 6, 7, 8]>>> list(set(t))[1, 2, 3, 5, 6, 7, 8]>>> s = [1, 2, 3]>>> list(set(t) - set(s))[8, 5, 6, 7]As you can see from the example result, the original order is not maintained. As mentioned above, sets themselves are unordered collections, so the order is lost. When converting a set back to a list, an arbitrary order is created.Maintaining orderIf order is important to you, then you will have to use a different mechanism. A very common solution for this is to rely on OrderedDict to keep the order of keys during insertion:>>> from collections import OrderedDict>>> list(OrderedDict.fromkeys(t))[1, 2, 3, 5, 6, 7, 8]Starting with Python 3.7, the built-in dictionary is guaranteed to maintain the insertion order as well, so you can also use that directly if you are on Python 3.7 or later (or CPython 3.6):>>> list(dict.fromkeys(t))[1, 2, 3, 5, 6, 7, 8]Note that this may have some overhead of creating a dictionary first, and then creating a list from it. If you don’t actually need to preserve the order, you’re often better off using a set, especially because it gives you a lot more operations to work with. Check out this question for more details and alternative ways to preserve the order when removing duplicates.Finally note that both the set as well as the OrderedDict/dict solutions require your items to be hashable. This usually means that they have to be immutable. If you have to deal with items that are not hashable (e.g. list objects), then you will have to use a slow approach in which you will basically have to compare every item with every other item in a nested loop."
"data_i","edited Feb 15 '17 at 10:13","
        How should I ethically approach user password storage for later plaintext retrieval?
    ","As I continue to build more and more websites and web applications I am often asked to store user's passwords in a way that they can be retrieved if/when the user has an issue (either to email a forgotten password link, walk them through over the phone, etc.)  When I can I fight bitterly against this practice and I do a lot of ‘extra’ programming to make password resets and administrative assistance possible without storing their actual password.When I can’t fight it (or can’t win) then I always encode the password in some way so that it, at least, isn’t stored as plaintext in the database—though I am aware that if my DB gets hacked it wouldn't take much for the culprit to crack the passwords, so that makes me uncomfortable.In a perfect world folks would update passwords frequently and not duplicate them across many different sites—unfortunately I know MANY people that have the same work/home/email/bank password, and have even freely given it to me when they need assistance.  I don’t want to be the one responsible for their financial demise if my DB security procedures fail for some reason.Morally and ethically I feel responsible for protecting what can be, for some users, their livelihood even if they are treating it with much less respect.I am certain that there are many avenues to approach and arguments to be made for salting hashes and different encoding options, but is there a single ‘best practice’ when you have to store them?  In almost all cases I am using PHP and MySQL if that makes any difference in the way I should handle the specifics.Additional Information for BountyI want to clarify that I know this is not something you want to have to do and that in most cases refusal to do so is best.  I am, however, not looking for a lecture on the merits of taking this approach I am looking for the best steps to take if you do take this approach.In a note below I made the point that websites geared largely toward the elderly, mentally challenged, or very young can become confusing for people when they are asked to perform a secure password recovery routine.  Though we may find it simple and mundane in those cases some users need the extra assistance of either having a service tech help them into the system or having it emailed/displayed directly to them.  In such systems the attrition rate from these demographics could hobble the application if users were not given this level of access assistance, so please answer with such a setup in mind.Thanks to EveryoneThis has been a fun question with lots of debate and I have enjoyed it.  In the end I selected an answer that both retains password security (I will not have to keep plain text or recoverable passwords), but also makes it possible for the user base I specified to log into a system without the major drawbacks I have found from normal password recovery.As always there were about 5 answers that I would like to have marked as correct for different reasons, but I had to choose the best one--all the rest got a +1.  Thanks everyone!Also, thanks to everyone in the Stack community who voted for this question and/or marked it as a favorite.  I take hitting 100 up votes as a compliment and hope that this discussion has helped someone else with the same concern that I had.","How about taking another approach or angle at this problem?  Ask why the password is required to be in plaintext:  if it's so that the user can retrieve the password, then strictly speaking you don't really need to retrieve the password they set (they don't remember what it is anyway), you need to be able to give them a password they can use.Think about it:  if the user needs to retrieve the password, it's because they've forgotten it. In which case a new password is just as good as the old one. But, one of the drawbacks of common password reset mechanisms used today is that the generated passwords produced in a reset operation are generally a bunch of random characters, so they're difficult for the user to simply type in correctly unless they copy-n-paste. That can be a problem for less savvy computer users.One way around that problem is to provide auto-generated passwords that are more or less natural language text.  While natural language strings might not have the entropy that a string of random characters of the same length has, there's nothing that says your auto-generated password needs to have only 8 (or 10 or 12) characters.  Get a high-entropy auto-generated passphrase by stringing together several random words (leave a space between them, so they're still recognizable and typeable by anyone who can read). Six random words of varying length are probably easier to type correctly and with confidence than 10 random characters, and they can have a higher entropy as well.  For example, the entropy of a 10 character password drawn randomly from uppercase, lowercase, digits and 10 punctuation symbols (for a total of 72 valid symbols) would have an entropy of 61.7 bits.  Using a dictionary of 7776 words (as Diceware uses) which could be randomly selected for a six word passphrase, the passphrase would have an entropy of 77.4 bits. See the Diceware FAQ for more info.a passphrase with about 77 bits of entropy: ""admit prose flare table acute flair""a password with about 74 bits of entropy:   ""K:&$R^tt~qkD""I know I'd prefer typing the phrase, and with copy-n-paste, the phrase is no less easy to use that the password either, so no loss there. Of course if your website (or whatever the protected asset is) doesn't need 77 bits of entropy for an auto-generated passphrase, generate fewer words (which I'm sure your users would appreciate).I understand the arguments that there are password protected assets that really don't have a high level of value, so the breach of a password might not be the end of the world. For example, I probably wouldn't care if 80% of the passwords I use on various websites was breached:  all that could happen is a someone spamming or posting under my name for a while.  That wouldn't be great, but it's not like they'd be breaking into my bank account. However, given the fact that many people use the same password for their web forum sites as they do for their bank accounts (and probably national security databases), I think it would be best to handle even those 'low-value' passwords as non-recoverable."
"data_i","edited Jul 05 '21 at 05:09","
        What are the -Xms and -Xmx parameters when starting JVM?
    ","Please explain the use of the Xms and Xmx parameters in JVMs. What are the default values for them?","The flag Xmx specifies the maximum memory allocation pool for a Java Virtual Machine (JVM), while Xms specifies the initial memory allocation pool.This means that your JVM will be started with Xms amount of memory and will be able to use a maximum of Xmx amount of memory. For example, starting a JVM like below will start it with 256 MB of memory and will allow the process to use up to 2048 MB of memory:java -Xms256m -Xmx2048mThe memory flag can also be specified in different sizes, such as kilobytes, megabytes, and so on.-Xmx1024k-Xmx512m-Xmx8gThe Xms flag has no default value, and Xmx typically has a default value of 256 MB. A common use for these flags is when you encounter a java.lang.OutOfMemoryError.When using these settings, keep in mind that these settings are for the JVM's heap, and that the JVM can and will use more memory than just the size allocated to the heap. From Oracle's documentation:Note that the JVM uses more memory than just the heap. For example Java methods, thread stacks and native handles are allocated in memory separate from the heap, as well as JVM internal data structures."
"data_i","edited Oct 16 '19 at 15:42","
        Convert JS object to JSON string
    ","If I defined an object in JS with:var j={""name"":""binchen""};How can I convert the object to JSON? The output string should be:'{""name"":""binchen""}'","All current browsers have native JSON support built in. So as long as you're not dealing with prehistoric browsers like IE6/7 you can do it just as easily as that:var j = {  ""name"": ""binchen""};console.log(JSON.stringify(j));"
"data_i","edited Jun 13 '21 at 12:26","
        How to compare a local Git branch with its remote branch
    ","How can I see the diff between a local branch and a remote branch?","git diff <local branch> <remote>/<remote branch>For example, git diff main origin/main, or git diff featureA origin/nextOf course to have said remote-tracking branch you need to git fetch first; and you need it to have up-to-date information about branches in the remote repository."
"data_i","edited Aug 23 '22 at 15:31","
        Change column type in pandas
    ","I created a DataFrame from a list of lists:table = [    ['a',  '1.2',  '4.2' ],    ['b',  '70',   '0.03'],    ['x',  '5',    '0'   ],]df = pd.DataFrame(table)How do I convert the columns to specific types? In this case, I want to convert columns 2 and 3 into floats.Is there a way to specify the types while converting to DataFrame? Or is it better to create the DataFrame first and then loop through the columns to change the type for each column? Ideally I would like to do this in a dynamic way because there can be hundreds of columns, and I don't want to specify exactly which columns are of which type. All I can guarantee is that each column contains values of the same type.","You have four main options for converting types in pandas:to_numeric() - provides functionality to safely convert non-numeric types (e.g. strings) to a suitable numeric type. (See also to_datetime() and to_timedelta().)astype() - convert (almost) any type to (almost) any other type (even if it's not necessarily sensible to do so). Also allows you to convert to categorial types (very useful).infer_objects() - a utility method to convert object columns holding Python objects to a pandas type if possible.convert_dtypes() - convert DataFrame columns to the ""best possible""  dtype that supports pd.NA (pandas' object to indicate a missing value).Read on for more detailed explanations and usage of each of these methods.1. to_numeric()The best way to convert one or more columns of a DataFrame to numeric values is to use pandas.to_numeric().This function will try to change non-numeric objects (such as strings) into integers or floating-point numbers as appropriate.Basic usageThe input to to_numeric() is a Series or a single column of a DataFrame.>>> s = pd.Series([""8"", 6, ""7.5"", 3, ""0.9""]) # mixed string and numeric values>>> s0      81      62    7.53      34    0.9dtype: object>>> pd.to_numeric(s) # convert everything to float values0    8.01    6.02    7.53    3.04    0.9dtype: float64As you can see, a new Series is returned. Remember to assign this output to a variable or column name to continue using it:# convert Seriesmy_series = pd.to_numeric(my_series)# convert column ""a"" of a DataFramedf[""a""] = pd.to_numeric(df[""a""])You can also use it to convert multiple columns of a DataFrame via the apply() method:# convert all columns of DataFramedf = df.apply(pd.to_numeric) # convert all columns of DataFrame# convert just columns ""a"" and ""b""df[[""a"", ""b""]] = df[[""a"", ""b""]].apply(pd.to_numeric)As long as your values can all be converted, that's probably all you need.Error handlingBut what if some values can't be converted to a numeric type?to_numeric() also takes an errors keyword argument that allows you to force non-numeric values to be NaN, or simply ignore columns containing these values.Here's an example using a Series of strings s which has the object dtype:>>> s = pd.Series(['1', '2', '4.7', 'pandas', '10'])>>> s0         11         22       4.73    pandas4        10dtype: objectThe default behaviour is to raise if it can't convert a value. In this case, it can't cope with the string 'pandas':>>> pd.to_numeric(s) # or pd.to_numeric(s, errors='raise')ValueError: Unable to parse stringRather than fail, we might want 'pandas' to be considered a missing/bad numeric value. We can coerce invalid values to NaN as follows using the errors keyword argument:>>> pd.to_numeric(s, errors='coerce')0     1.01     2.02     4.73     NaN4    10.0dtype: float64The third option for errors is just to ignore the operation if an invalid value is encountered:>>> pd.to_numeric(s, errors='ignore')# the original Series is returned untouchedThis last option is particularly useful for converting your entire DataFrame, but don't know which of our columns can be converted reliably to a numeric type. In that case, just write:df.apply(pd.to_numeric, errors='ignore')The function will be applied to each column of the DataFrame. Columns that can be converted to a numeric type will be converted, while columns that cannot (e.g. they contain non-digit strings or dates) will be left alone.DowncastingBy default, conversion with to_numeric() will give you either an int64 or float64 dtype (or whatever integer width is native to your platform).That's usually what you want, but what if you wanted to save some memory and use a more compact dtype, like float32, or int8?to_numeric() gives you the option to downcast to either 'integer', 'signed', 'unsigned', 'float'. Here's an example for a simple series s of integer type:>>> s = pd.Series([1, 2, -7])>>> s0    11    22   -7dtype: int64Downcasting to 'integer' uses the smallest possible integer that can hold the values:>>> pd.to_numeric(s, downcast='integer')0    11    22   -7dtype: int8Downcasting to 'float' similarly picks a smaller than normal floating type:>>> pd.to_numeric(s, downcast='float')0    1.01    2.02   -7.0dtype: float322. astype()The astype() method enables you to be explicit about the dtype you want your DataFrame or Series to have. It's very versatile in that you can try and go from one type to any other.Basic usageJust pick a type: you can use a NumPy dtype (e.g. np.int16), some Python types (e.g. bool), or pandas-specific types (like the categorical dtype).Call the method on the object you want to convert and astype() will try and convert it for you:# convert all DataFrame columns to the int64 dtypedf = df.astype(int)# convert column ""a"" to int64 dtype and ""b"" to complex typedf = df.astype({""a"": int, ""b"": complex})# convert Series to float16 types = s.astype(np.float16)# convert Series to Python stringss = s.astype(str)# convert Series to categorical type - see docs for more detailss = s.astype('category')Notice I said ""try"" - if astype() does not know how to convert a value in the Series or DataFrame, it will raise an error. For example, if you have a NaN or inf value you'll get an error trying to convert it to an integer.As of pandas 0.20.0, this error can be suppressed by passing errors='ignore'. Your original object will be returned untouched.Be carefulastype() is powerful, but it will sometimes convert values ""incorrectly"". For example:>>> s = pd.Series([1, 2, -7])>>> s0    11    22   -7dtype: int64These are small integers, so how about converting to an unsigned 8-bit type to save memory?>>> s.astype(np.uint8)0      11      22    249dtype: uint8The conversion worked, but the -7 was wrapped round to become 249 (i.e. 28 - 7)!Trying to downcast using pd.to_numeric(s, downcast='unsigned') instead could help prevent this error.3. infer_objects()Version 0.21.0 of pandas introduced the method infer_objects() for converting columns of a DataFrame that have an object datatype to a more specific type (soft conversions).For example, here's a DataFrame with two columns of object type. One holds actual integers and the other holds strings representing integers:>>> df = pd.DataFrame({'a': [7, 1, 5], 'b': ['3','2','1']}, dtype='object')>>> df.dtypesa    objectb    objectdtype: objectUsing infer_objects(), you can change the type of column 'a' to int64:>>> df = df.infer_objects()>>> df.dtypesa     int64b    objectdtype: objectColumn 'b' has been left alone since its values were strings, not integers. If you wanted to force both columns to an integer type, you could use df.astype(int) instead.4. convert_dtypes()Version 1.0 and above includes a method convert_dtypes() to convert Series and DataFrame columns to the best possible dtype that supports the pd.NA missing value.Here ""best possible"" means the type most suited to hold the values. For example, this a pandas integer type, if all of the values are integers (or missing values): an object column of Python integer objects are converted to Int64, a column of NumPy int32 values, will become the pandas dtype Int32.With our object DataFrame df, we get the following result:>>> df.convert_dtypes().dtypes                                             a     Int64b    stringdtype: objectSince column 'a' held integer values, it was converted to the Int64 type (which is capable of holding missing values, unlike int64).Column 'b' contained string objects, so was changed to pandas' string dtype.By default, this method will infer the type from object values in each column. We can change this by passing infer_objects=False:>>> df.convert_dtypes(infer_objects=False).dtypes                          a    objectb    stringdtype: objectNow column 'a' remained an object column: pandas knows it can be described as an 'integer' column (internally it ran infer_dtype) but didn't infer exactly what dtype of integer it should have so did not convert it. Column 'b' was again converted to 'string' dtype as it was recognised as holding 'string' values."
"data_i","edited May 25 '12 at 16:06","
        What is the difference between visibility:hidden and display:none?
    ","The CSS rules visibility:hidden and display:none both result in the element not being visible. Are these synonyms?","display:none means that the tag in question will not appear on the page at all (although you can still interact with it through the dom).  There will be no space allocated for it between the other tags.  visibility:hidden means that unlike display:none, the tag is not visible, but space is allocated for it on the page. The tag is rendered, it just isn't seen on the page.For example:test | <span style=""[style-tag-value]"">Appropriate style in this tag</span> | testReplacing [style-tag-value] with display:none results in:test |   | testReplacing [style-tag-value] with visibility:hidden results in:test |                        | test"
"data_i","edited Apr 20 '15 at 02:52","
        How can I create a two dimensional array in JavaScript?
    ","I have been reading online and some places say it isn't possible, some say it is and then give an example and others refute the example, etc. How do I declare a 2 dimensional array in JavaScript? (assuming it's possible) How would I access its members? (myArray[0][1] or myArray[0,1]?)","let items = [  [1, 2],  [3, 4],  [5, 6]];console.log(items[0][0]); // 1console.log(items[0][1]); // 2console.log(items[1][0]); // 3console.log(items[1][1]); // 4console.log(items);"
"data_i","edited Apr 16 '20 at 08:04","
        What is the difference between the remap, noremap, nnoremap and vnoremap mapping commands in Vim?
    ","What is the difference between the remap, noremap, nnoremap and vnoremap mapping commands in Vim?","remap is an option that makes mappings work recursively. By default it is on and I'd recommend you leave it that way. The rest are mapping commands, described below::map and :noremap are recursive and non-recursive versions of the various mapping commands. For example, if we run::map j gg           (moves cursor to first line):map Q j            (moves cursor to first line):noremap W j        (moves cursor down one line)Then:j will be mapped to gg.Q will also be mapped to gg, because j will be expanded for the recursive mapping.W will be mapped to j (and not to gg) because j will not be expanded for the non-recursive mapping.Now remember that Vim is a modal editor. It has a normal mode, visual mode and other modes.For each of these sets of mappings, there is a mapping that works in normal, visual, select and operator modes (:map and :noremap), one that works in normal mode (:nmap and :nnoremap), one in visual mode (:vmap and :vnoremap) and so on.For more guidance on this, see::help :map:help :noremap:help recursive_mapping:help :map-modes"
"data_i","edited Apr 15 '21 at 07:41","
        Git merge hotfix branch into feature branch
    ","Let’s say we have the following situation in Git:A created repository:mkdir GitTest2cd GitTest2git initSome modifications in the master take place and get committed:echo ""On Master"" > filegit commit -a -m ""Initial commit""Feature1 branched off master and some work is done:git branch feature1git checkout feature1echo ""Feature1"" > featureFilegit commit -a -m ""Commit for feature1""Meanwhile, a bug is discovered in the master-code and a hotfix-branch is established:git checkout mastergit branch hotfix1git checkout hotfix1The bug is fixed in the hotfix branch and merged back into the master (perhaps after a pull request/code review):echo ""Bugfix"" > bugfixFilegit commit -a -m ""Bugfix Commit""git checkout mastergit merge --no-ff hotfix1Development on feature1 continues:git checkout feature1Say I need the hotfix in my feature branch, maybe because the bug also occurs there. How can I achieve this without duplicating the commits into my feature branch?I want to prevent to get two new commits on my feature branch which have no relation to the feature implementation. This especially seems important for me if I use pull requests: All these commits will also be included in the pull request and have to be reviewed although this has already been done (as the hotfix is already in the master).I can not do a git merge master --ff-only: ""fatal: Not possible to fast-forward, aborting."", but I am not sure if this helped me.","How do we merge the master branch into the feature branch? Easy:git checkout feature1git merge masterThere is no point in forcing a fast forward merge here, as it cannot be done. You committed both into the feature branch and the master branch. Fast forward is impossible now.Have a look at GitFlow. It is a branching model for git that can be followed, and you unconsciously already did. It also is an extension to Git which adds some commands for the new workflow steps that do things automatically which you would otherwise need to do manually.So what did you do right in your workflow? You have two branches to work with, your feature1 branch is basically the ""develop"" branch in the GitFlow model.You created a hotfix branch from master and merged it back. And now you are stuck.The GitFlow model asks you to merge the hotfix also to the development branch, which is ""feature1"" in your case.So the real answer would be:git checkout feature1git merge --no-ff hotfix1This adds all the changes that were made inside the hotfix to the feature branch, but only those changes. They might conflict with other development changes in the branch, but they will not conflict with the master branch should you merge the feature branch back to master eventually.Be very careful with rebasing. Only rebase if the changes you did stayed local to your repository, e.g. you did not push any branches to some other repository. Rebasing is a great tool for you to arrange your local commits into a useful order before pushing it out into the world, but rebasing afterwards will mess up things for the git beginners like you."
"data_i","edited Sep 28 '18 at 20:12","
        How and when to use ‘async’ and ‘await’
    ","From my understanding one of the main things that async and await do is to make code easy to write and read - but is using them equal to spawning background threads to perform long duration logic?I'm currently trying out the most basic example. I've added some comments inline. Can you clarify it for me?// I don't understand why this method must be marked as `async`.private async void button1_Click(object sender, EventArgs e){    Task<int> access = DoSomethingAsync();    // task independent stuff here    // this line is reached after the 5 seconds sleep from     // DoSomethingAsync() method. Shouldn't it be reached immediately?     int a = 1;     // from my understanding the waiting should be done here.    int x = await access; }async Task<int> DoSomethingAsync(){    // is this executed on a background thread?    System.Threading.Thread.Sleep(5000);    return 1;}","When using async and await the compiler generates a state machine in the background.Here's an example on which I hope I can explain some of the high-level details that are going on:public async Task MyMethodAsync(){    Task<int> longRunningTask = LongRunningOperationAsync();    // independent work which doesn't need the result of LongRunningOperationAsync can be done here    //and now we call await on the task     int result = await longRunningTask;    //use the result     Console.WriteLine(result);}public async Task<int> LongRunningOperationAsync() // assume we return an int from this long running operation {    await Task.Delay(1000); // 1 second delay    return 1;}OK, so what happens here:Task<int> longRunningTask = LongRunningOperationAsync(); starts executing LongRunningOperationIndependent work is done on let's assume the Main Thread (Thread ID = 1) then await longRunningTask is reached.Now, if the longRunningTask hasn't finished and it is still running, MyMethodAsync() will return to its calling method, thus the main thread doesn't get blocked. When the longRunningTask is done then a thread from the ThreadPool (can be any thread) will return to MyMethodAsync() in its previous context and continue execution (in this case printing the result to the console).A second case would be that the longRunningTask has already finished its execution and the result is available. When reaching the await longRunningTask we already have the result so the code will continue executing on the very same thread. (in this case printing result to console). Of course this is not the case for the above example, where there's a Task.Delay(1000) involved."
"data_i","edited Mar 29 '22 at 12:26","
        Best way to convert string to bytes in Python 3?
    ","TypeError: 'str' does not support the buffer interface suggests two possible methods to convert a string to bytes:b = bytes(mystring, 'utf-8')b = mystring.encode('utf-8')Which method is more Pythonic?","If you look at the docs for bytes, it points you to bytearray:bytearray([source[, encoding[, errors]]])Return a new array of bytes. The bytearray type is a mutable sequence of integers in the range 0 <= x < 256. It has most of the usual methods of mutable sequences, described in Mutable Sequence Types, as well as most methods that the bytes type has, see Bytes and Byte Array Methods.The optional source parameter can be used to initialize the array in a few different ways:If it is a string, you must also give the encoding (and optionally, errors) parameters; bytearray() then converts the string to bytes using str.encode().If it is an integer, the array will have that size and will be initialized with null bytes.If it is an object conforming to the buffer interface, a read-only buffer of the object will be used to initialize the bytes array.If it is an iterable, it must be an iterable of integers in the range 0 <= x < 256, which are used as the initial contents of the array.Without an argument, an array of size 0 is created.So bytes can do much more than just encode a string. It's Pythonic that it would allow you to call the constructor with any type of source parameter that makes sense.For  encoding a string, I think that some_string.encode(encoding) is more Pythonic than using the constructor, because it is the most self documenting -- ""take this string and encode it with this encoding"" is clearer than bytes(some_string, encoding) -- there is no explicit verb when you use the constructor.I checked the Python source. If you pass a unicode string to bytes using CPython, it calls PyUnicode_AsEncodedString, which is the implementation of encode; so you're just skipping a level of indirection if you call encode yourself.Also, see Serdalis' comment -- unicode_string.encode(encoding) is also more Pythonic because its inverse is byte_string.decode(encoding) and symmetry is nice."
"data_i","edited Jul 02 '20 at 19:59","
        How to check if element is visible after scrolling?
    ","I'm loading elements via AJAX. Some of them are only visible if you scroll down the page. Is there any way I can know if an element is now in the visible part of the page?","This should do the trick:function isScrolledIntoView(elem){    var docViewTop = $(window).scrollTop();    var docViewBottom = docViewTop + $(window).height();    var elemTop = $(elem).offset().top;    var elemBottom = elemTop + $(elem).height();    return ((elemBottom <= docViewBottom) && (elemTop >= docViewTop));}Simple Utility FunctionThis will allow you to call a utility function that accepts the element you're looking for and if you want the element to be fully in view or partially.function Utils() {}Utils.prototype = {    constructor: Utils,    isElementInView: function (element, fullyInView) {        var pageTop = $(window).scrollTop();        var pageBottom = pageTop + $(window).height();        var elementTop = $(element).offset().top;        var elementBottom = elementTop + $(element).height();        if (fullyInView === true) {            return ((pageTop < elementTop) && (pageBottom > elementBottom));        } else {            return ((elementTop <= pageBottom) && (elementBottom >= pageTop));        }    }};var Utils = new Utils();Usagevar isElementInView = Utils.isElementInView($('#flyout-left-container'), false);if (isElementInView) {    console.log('in view');} else {    console.log('out of view');}"
"data_i","edited Feb 24 '22 at 13:01","
        ""Notice: Undefined variable"", ""Notice: Undefined index"", ""Warning: Undefined array key"", and ""Notice: Undefined offset"" using PHP
    ","I'm running a PHP script and continue to receive errors like:Notice: Undefined variable: my_variable_name in C:\wamp\www\mypath\index.php on line 10Notice: Undefined index: my_index C:\wamp\www\mypath\index.php on line 11Warning: Undefined array key ""my_index"" in C:\wamp\www\mypath\index.php on line 11Line 10 and 11 looks like this:echo ""My variable value is: "" . $my_variable_name;echo ""My index value is: "" . $my_array[""my_index""];What is the meaning of these error messages?Why do they appear all of a sudden? I used to use this script for years and I've never had any problem.How do I fix them?This is a General Reference question for people to link to as duplicate, instead of having to explain the issue over and over again. I feel this is necessary because most real-world answers on this issue are very specific. Related Meta discussion:What can be done about repetitive questions?Do “reference questions” make sense?","Notice / Warning: Undefined variableFrom the vast wisdom of the PHP Manual:Relying on the default value of an uninitialized variable is problematic in the case of including one file into another which uses the same variable name. It is also a major security risk with register_globals turned on. E_NOTICE level error is issued in case of working with uninitialized variables, however not in the case of appending elements to the uninitialized array. isset() language construct can be used to detect if a variable has been already initialized. Additionally and more ideal is the solution of empty() since it does not generate a warning or error message if the variable is not initialized.From PHP documentation:No warning is generated if the variable does not exist. That meansempty() is essentially the concise equivalent to !isset($var) || $var== false.This means that you could use only empty() to determine if the variable is set, and in addition it checks the variable against the following, 0, 0.0, """", ""0"", null, false or [].Example:$o = [];@$var = ["""",0,null,1,2,3,$foo,$o['myIndex']];array_walk($var, function($v) {    echo (!isset($v) || $v == false) ? 'true ' : 'false';    echo ' ' . (empty($v) ? 'true' : 'false');    echo ""\n"";});Test the above snippet in the 3v4l.org online PHP editorAlthough PHP does not require a variable declaration, it does recommend it in order to avoid some security vulnerabilities or bugs where one would forget to give a value to a variable that will be used later in the script. What PHP does in the case of undeclared variables is issue a very low level error, E_NOTICE, one that is not even reported by default, but the Manual advises to allow during development.Ways to deal with the issue:Recommended: Declare your variables, for example when you try to append a string to an undefined variable. Or use isset() / !empty()  to check if they are declared before referencing them, as in://Initializing variable$value = """"; //Initialization value; Examples             //"""" When you want to append stuff later             //0  When you want to add numbers later//isset()$value = isset($_POST['value']) ? $_POST['value'] : '';//empty()$value = !empty($_POST['value']) ? $_POST['value'] : '';This has become much cleaner as of PHP 7.0, now you can use the null coalesce operator:    // Null coalesce operator - No need to explicitly initialize the variable.    $value = $_POST['value'] ?? '';Set a custom error handler for E_NOTICE and redirect the messages away from the standard output (maybe to a log file):set_error_handler('myHandlerForMinorErrors', E_NOTICE | E_STRICT)Disable E_NOTICE from reporting. A quick way to exclude just E_NOTICE is:error_reporting( error_reporting() & ~E_NOTICE )Suppress the error with the @ operator.Note: It's strongly recommended to implement just point 1.Notice: Undefined index / Undefined offset / Warning: Undefined array keyThis notice/warning appears when you (or PHP) try to access an undefined index of an array.Ways to deal with the issue:Check if the index exists before you access it. For this you can use isset() or array_key_exists()://isset()$value = isset($array['my_index']) ? $array['my_index'] : '';//array_key_exists()$value = array_key_exists('my_index', $array) ? $array['my_index'] : '';The language construct list() may generate this when it attempts to access an array index that does not exist:list($a, $b) = array(0 => 'a');//orlist($one, $two) = explode(',', 'test string');Two variables are used to access two array elements, however there is only one array element, index 0, so this will generate:Notice: Undefined offset: 1#$_POST / $_GET / $_SESSION variableThe notices above appear often when working with $_POST, $_GET or $_SESSION. For $_POST and $_GET you just have to check if the index exists or not before you use them. For $_SESSION you have to make sure you have the session started with session_start() and that the index also exists.Also note that all 3 variables are superglobals and are uppercase.Related:Notice: Undefined variableNotice: Undefined Index"
"data_i","edited Apr 09 '22 at 08:15","
        How do I trim whitespace from a string?
    ","How do I remove leading and trailing whitespace from a string in Python?"" Hello world "" --> ""Hello world"""" Hello world""  --> ""Hello world""""Hello world ""  --> ""Hello world""""Hello world""   --> ""Hello world""","To remove all whitespace surrounding a string, use .strip(). Examples:>>> ' Hello '.strip()'Hello'>>> ' Hello'.strip()'Hello'>>> 'Bob has a cat'.strip()'Bob has a cat'>>> '   Hello   '.strip()  # ALL consecutive spaces at both ends removed'Hello'Note that str.strip() removes all whitespace characters, including tabs and newlines. To remove only spaces, specify the specific character to remove as an argument to strip:>>> ""  Hello\n  "".strip("" "")'Hello\n'To remove only one space at most:def strip_one_space(s):    if s.endswith("" ""): s = s[:-1]    if s.startswith("" ""): s = s[1:]    return s>>> strip_one_space(""   Hello "")'  Hello'"
"data_i","edited Jan 22 '16 at 20:18","
        jQuery document.createElement equivalent?
    ","I'm refactoring some old JavaScript code and there's a lot of DOM manipulation going on.var d = document;var odv = d.createElement(""div"");odv.style.display = ""none"";this.OuterDiv = odv;var t = d.createElement(""table"");t.cellSpacing = 0;t.className = ""text"";odv.appendChild(t);I would like to know if there is a better way to do this using jQuery. I've been experimenting with:var odv = $.create(""div"");$.append(odv);// And many moreBut I'm not sure if this is any better.","Here's your example in the ""one"" line.this.$OuterDiv = $('<div></div>')    .hide()    .append($('<table></table>')        .attr({ cellSpacing : 0 })        .addClass(""text"")    );Update: I thought I'd update this post since it still gets quite a bit of traffic. In the comments below there's some discussion about $(""<div>"") vs $(""<div></div>"") vs $(document.createElement('div')) as a way of creating new elements, and which is ""best"".I put together a small benchmark, and here are roughly the results of repeating the above options 100,000 times:jQuery 1.4, 1.5, 1.6               Chrome 11  Firefox 4   IE9<div>            440ms      640ms    460ms<div></div>      420ms      650ms    480mscreateElement    100ms      180ms    300msjQuery 1.3                Chrome 11<div>             770ms<div></div>      3800mscreateElement     100msjQuery 1.2                Chrome 11<div>            3500ms<div></div>      3500mscreateElement     100msI think it's no big surprise, but document.createElement is the fastest method. Of course, before you go off and start refactoring your entire codebase, remember that the differences we're talking about here (in all but the archaic versions of jQuery) equate to about an extra 3 milliseconds per thousand elements. Update 2Updated for jQuery 1.7.2 and put the benchmark on JSBen.ch which is probably a bit more scientific than my primitive benchmarks, plus it can be crowdsourced now!http://jsben.ch/#/ARUtz"
"data_i","edited Jan 30 '19 at 10:03","
        How can I pass arguments to a batch file?
    ","I need to pass an ID and a password to a batch file at the time of running rather than hardcoding them into the file.Here's what the command line looks like:test.cmd admin P@55w0rd > test-log.txt","Another useful tip is to use %* to mean ""all"". For example:echo offset arg1=%1set arg2=%2shiftshiftfake-command /u %arg1% /p %arg2% %*When you run:test-command admin password foo barThe above batch file will run:fake-command /u admin /p password admin password foo barI may have the syntax slightly wrong, but this is the general idea."
"data_i","edited Dec 05 '19 at 17:42","
        Undo git pull, how to bring repos to old state
    ","Is there any way to revert or undo git pull so that my source/repos will come to old state that was before doing git pull ?I want to do this because it merged some files which I didn't want to do so, but only merge other remaining files. So, I want to get those files back, is that possible?EDIT: I want to undo git merge for clarification.After seeing some answers, I did this git reflogbb3139b... HEAD@{0}: pull : Fast forward01b34fa... HEAD@{1}: clone: from ...name...Now, what should I do ? Doing git reset --hard  is OK ? I don't want to screw it again, so asking for detailed steps ? ","Running git pull performs the following tasks, in order:git fetch git mergeThe merge step combines branches that have been setup to be merged in your config. You want to undo the merge step, but probably not the fetch (doesn't make a lot of sense and shouldn't be necessary).  To undo the merge, use git reset --hard to reset the local repository to a previous state; use git-reflog to find the SHA-1 of the previous state and then reset to it.WarningThe commands listed in this section remove all uncommitted changes, potentially leading to a loss of work:git reset --hardAlternatively, reset to a particular point in time, such as:git reset --hard master@{""10 minutes ago""}"
"data_i","edited Apr 19 '20 at 11:29","
        What is the purpose of the ""role"" attribute in HTML?
    ","I keep seeing role attributes in some people's work. I use it too, but I'm not sure about its effect.For example:<header id=""header"" role=""banner"">    Header stuff in here</header>Or:<section id=""facebook"" role=""contentinfo"">    Facebook stuff in here</section>Or:<section id=""main"" role=""main"">     Main content stuff in here</section>Is this role attribute necessary?Is this attribute better for semantics?Does it improve SEO?A list of roles can be found here, but I see some people make up their own. Is that allowed or a correct use of the role attribute?Any thoughts on this?","Most of the roles you see were defined as part of ARIA 1.0, and then later incorporated into HTML via supporting specs like HTML-AAM. Some of the new HTML5 elements (dialog, main, etc.) are even based on the original ARIA roles.http://www.w3.org/TR/wai-aria/While the First Rule of Aria states:If you can use a native HTML element [HTML51] or attribute with the semantics and behavior you require already built in, instead of re-purposing an element and adding an ARIA role, state or property to make it accessible, then do so.there are a few primary reasons to use roles in addition to your native semantic element.Reason #1. Overriding the role where no host language element is appropriate or, for various reasons, a less semantically appropriate element was used.In this example, a link was used, even though the resulting functionality is more button-like than a navigation link.<a href=""#"" role=""button"" aria-label=""Delete item 1"">Delete</a><!-- Note: href=""#"" is just a shorthand here, not a recommended technique. Use progressive enhancement when possible. -->Screen readers users will hear this as a button (as opposed to a link), and you can use a CSS attribute selector to avoid class-itis and div-itis.[role=""button""] {  /* style these as buttons w/o relying on a .button class */}[Update 7 years later: removed the * selector to make some commenters happy, since the old browser quirk that required universal selector on attribute selectors is unnecessary in 2020.]Reason #2. Backing up a native element's role, to support browsers that implemented the ARIA role but haven't yet implemented the native element's role.For example, the ""main"" role has been supported in browsers for many years, but it's a relatively recent addition to HTML5, so many browsers don't yet support the semantic for <main>.<main role=""main"">…</main>This is technically redundant, but helps some users and doesn't harm any. In a few years, this technique will likely become unnecessary for main.Reason #3.Update 7 years later (2020): As at least one commenter pointed out, this is now very useful for custom elements, and some spec work is underway to define the default accessibility role of a web component. Even if/once that API is standardized, there may be need to override the default role of a component.Note/ReplyYou also wrote:I see some people make up their own. Is that allowed or a correct use of the role attribute?That's an allowed use of the attribute unless a real role is not included. Browsers will apply the first recognized role in the token list.<span role=""foo link note bar"">...</a>Out of the list, only link and note are valid roles, and so the link role will be applied in the platform accessibility API because it comes first. If you use custom roles, make sure they don't conflict with any defined role in ARIA or the host language you're using (HTML, SVG, MathML, etc.)"
"data_i","edited Nov 12 '13 at 01:38","
        In Python, how do I determine if an object is iterable?
    ","Is there a method like isiterable? The only solution I have found so far is to callhasattr(myObj, '__iter__')But I am not sure how fool-proof this is.","Checking for __iter__ works on sequence types, but it would fail on e.g. strings in Python 2. I would like to know the right answer too, until then, here is one possibility (which would work on strings, too): try:     some_object_iterator = iter(some_object) except TypeError as te:     print(some_object, 'is not iterable')The iter built-in checks for the __iter__ method or in the case of strings the __getitem__ method.Another general pythonic approach is to assume an iterable, then fail gracefully if it does not work on the given object. The Python glossary:Pythonic programming style that determines an object's type by inspection of its method or attribute signature rather than by explicit relationship to some type object (""If it looks like a duck and quacks like a duck, it must be a duck."") By emphasizing interfaces rather than specific types, well-designed code improves its flexibility by allowing polymorphic substitution. Duck-typing avoids tests using type() or isinstance(). Instead, it typically employs the EAFP (Easier to Ask Forgiveness than Permission) style of programming....try:   _ = (e for e in my_object)except TypeError:   print my_object, 'is not iterable'The collections module provides some abstract base classes, which allow to ask classes or instances if they provide particular functionality, for example: from collections.abc import Iterable if isinstance(e, Iterable):     # e is iterableHowever, this does not check for classes that are iterable through __getitem__."
"data_i","edited Jan 07 '19 at 09:20","
        What are the differences between NP, NP-Complete and NP-Hard?
    ","What are the differences between NP, NP-Complete and NP-Hard?I am aware of many resources all over the web. I'd like to read your explanations, and the reason is they might be different from what's out there, or there is something that I'm not aware of.","I assume that you are looking for intuitive definitions, since the technical definitions require quite some time to understand. First of all, let's remember a preliminary needed concept to understand those definitions.Decision problem: A problem with a yes or no answer.Now, let us define those complexity classes.PP is a complexity class that represents the set of all decision problems that can be solved in polynomial time.That is, given an instance of the problem, the answer yes or no can be decided in polynomial time.ExampleGiven a connected graph G, can its vertices be coloured using two colours so that no edge is monochromatic?Algorithm: start with an arbitrary vertex, color it red and all of its neighbours blue and continue. Stop when you run out of vertices or you are forced to make an edge have both of its endpoints be the same color.NPNP is a complexity class that represents the set of all decision problems for which the instances where the answer is ""yes"" have proofs that can be verified in polynomial time.This means that if someone gives us an instance of the problem and a certificate (sometimes called a witness) to the answer being yes, we can check that it is correct in polynomial time.ExampleInteger factorisation is in NP. This is the problem that given integers n and m, is there an integer f with 1 < f < m, such that f divides n (f is a small factor of n)? This is a decision problem because the answers are yes or no. If someone hands us an instance of the problem (so they hand us integers n and m) and an integer f with 1 < f < m, and claim that f is a factor of n (the certificate), we can check the answer in polynomial time by performing the division n / f.NP-CompleteNP-Complete is a complexity class which represents the set of all problems X in NP for which it is possible to reduce any other NP problem Y to X in polynomial time.Intuitively this means that we can solve Y quickly if we know how to solve X quickly. Precisely, Y is reducible to X, if there is a polynomial time algorithm f to transform instances y of Y to instances x = f(y) of X in polynomial time, with the property that the answer to y is yes, if and only if the answer to f(y) is yes.Example 3-SAT. This is the problem wherein we are given a conjunction (ANDs) of 3-clause disjunctions (ORs), statements of the form(x_v11 OR x_v21 OR x_v31) AND (x_v12 OR x_v22 OR x_v32) AND ...                       AND (x_v1n OR x_v2n OR x_v3n)where each x_vij is a boolean variable or the negation of a variable from a finite predefined list (x_1, x_2, ... x_n). It can be shown that every NP problem can be reduced to 3-SAT. The proof of this is technical and requires use of the technical definition of NP (based on non-deterministic Turing machines). This is known as Cook's theorem.What makes NP-complete problems important is that if a deterministic polynomial time algorithm can be found to solve one of them, every NP problem is solvable in polynomial time (one problem to rule them all).NP-hardIntuitively, these are the problems that are at least as hard as the NP-complete problems. Note that NP-hard problems do not have to be in NP, and they do not have to be decision problems. The precise definition here is that a problem X is NP-hard, if there is an NP-complete problem Y, such that Y is reducible to X in polynomial time.But since any NP-complete problem can be reduced to any other NP-complete problem in polynomial time, all NP-complete problems can be reduced to any NP-hard problem in polynomial time. Then, if there is a solution to one NP-hard problem in polynomial time, there is a solution to all NP problems in polynomial time.ExampleThe halting problem is an NP-hard problem. This is the problem that given a program P and input I, will it halt? This is a decision problem but it is not in NP. It is clear that any NP-complete problem can be reduced to this one. As another example, any NP-complete problem is NP-hard.My favorite NP-complete problem is the Minesweeper problem.P = NPThis one is the most famous problem in computer science, and one of the most important outstanding questions in the mathematical sciences. In fact, the Clay Institute is offering one million dollars for a solution to the problem (Stephen Cook's writeup on the Clay website is quite good). It's clear that P is a subset of NP. The open question is whether or not NP problems have deterministic polynomial time solutions. It is largely believed that they do not. Here is an outstanding recent article on the latest (and the importance) of the P = NP problem: The Status of the P versus NP problem. The best book on the subject is Computers and Intractability by Garey and Johnson. "
"data_i","edited Dec 15 '15 at 07:23","
        Altering a column: null to not null
    ","I have a table that has several nullable integer columns.  This is undesirable for several reasons, so I am looking to update all nulls to 0 and then set these columns to NOT NULL. Aside from changing nulls to 0, data must be preserved.I am looking for the specific SQL syntax to alter a column (call it ColumnA) to ""not null"".  Assume the data has been updated to not contain nulls.Using SQL server 2000.","First, make all current NULL values disappear:UPDATE [Table] SET [Column]=0 WHERE [Column] IS NULLThen, update the table definition to disallow ""NULLs"":ALTER TABLE [Table] ALTER COLUMN [Column] INTEGER NOT NULL"
"data_i","edited Sep 03 '15 at 09:23","
        How to pass props to {this.props.children}
    ","I'm trying to find the proper way to define some components which could be used in a generic way:<Parent>  <Child value=""1"">  <Child value=""2""></Parent>There is a logic going on for rendering between parent and children components of course, you can imagine <select> and <option> as an example of this logic.This is a dummy implementation for the purpose of the question:var Parent = React.createClass({  doSomething: function(value) {  },  render: function() {    return (<div>{this.props.children}</div>);  }});var Child = React.createClass({  onClick: function() {    this.props.doSomething(this.props.value); // doSomething is undefined  },  render: function() {    return (<div onClick={this.onClick}></div>);  }});The question is whenever you use {this.props.children} to define a wrapper component, how do you pass down some property to all its children?","Cloning children with new propsYou can use React.Children to iterate over the children, and then clone each element with new props (shallow merged) using React.cloneElement.See the code comment why I don't recommend this approach.const Child = ({ childName, sayHello }) => (  <button onClick={() => sayHello(childName)}>{childName}</button>);function Parent({ children }) {  // We clone and pass this `sayHello` function  // into the child elements.  function sayHello(childName) {    console.log(`Hello from ${childName} the child`);  }  const childrenWithProps = React.Children.map(children, child => {    // Checking isValidElement is the safe way and avoids a    // typescript error too.    if (React.isValidElement(child)) {      return React.cloneElement(child, { sayHello });    }    return child;  });  return <div>{childrenWithProps}</div>}function App() {  // This approach is less type-safe and Typescript friendly since it  // looks like you're trying to render `Child` with `sayHello` missing.  // It's also confusing to readers of this code.  return (    <Parent>      <Child childName=""Billy"" />      <Child childName=""Bob"" />    </Parent>  );}ReactDOM.render(<App />, document.getElementById(""container""));<script src=""https://unpkg.com/react@17/umd/react.production.min.js""></script><script src=""https://unpkg.com/react-dom@17/umd/react-dom.production.min.js""></script><div id=""container""></div>Calling children as a functionAlternatively, you can pass props to children via render props. In this approach, the children (which can be children or any other prop name) is a function which can accept any arguments you want to pass and returns the actual children:const Child = ({ childName, sayHello }) => (  <button onClick={() => sayHello(childName)}>{childName}</button>);function Parent({ children }) {  function sayHello(childName) {    console.log(`Hello from ${childName} the child`);  }  // `children` of this component must be a function  // which returns the actual children. We can pass  // it args to then pass into them as props (in this  // case we pass `sayHello`).  return <div>{children(sayHello)}</div>}function App() {  // sayHello is the arg we passed in Parent, which  // we now pass through to Child.  return (    <Parent>      {(sayHello) => (        <React.Fragment>          <Child childName=""Billy"" sayHello={sayHello} />          <Child childName=""Bob"" sayHello={sayHello} />        </React.Fragment>      )}    </Parent>  );}ReactDOM.render(<App />, document.getElementById(""container""));<script src=""https://unpkg.com/react@17/umd/react.production.min.js""></script><script src=""https://unpkg.com/react-dom@17/umd/react-dom.production.min.js""></script><div id=""container""></div>"
"data_i","edited Oct 29 '17 at 15:42","
        What does ""static"" mean in C?
    ","I've seen the word static used in different places in C code; is this like a static function/class in C# (where the implementation is shared across objects)?  ","A static variable inside a function keeps its value between invocations.A static global variable or a function is ""seen"" only in the file it's declared in(1) is the more foreign topic if you're a newbie, so here's an example:#include <stdio.h>void foo(){    int a = 10;    static int sa = 10;    a += 5;    sa += 5;    printf(""a = %d, sa = %d\n"", a, sa);}int main(){    int i;    for (i = 0; i < 10; ++i)        foo();}This prints:a = 15, sa = 15a = 15, sa = 20a = 15, sa = 25a = 15, sa = 30a = 15, sa = 35a = 15, sa = 40a = 15, sa = 45a = 15, sa = 50a = 15, sa = 55a = 15, sa = 60This is useful for cases where a function needs to keep some state between invocations, and you don't want to use global variables. Beware, however, this feature should be used very sparingly - it makes your code not thread-safe and harder to understand.(2) Is used widely as an ""access control"" feature. If you have a .c file implementing some functionality, it usually exposes only a few ""public"" functions to users. The rest of its functions should be made static, so that the user won't be able to access them. This is encapsulation, a good practice.Quoting Wikipedia:In the C programming language, static  is used with global variables and  functions to set their scope to the  containing file. In local variables,  static is used to store the variable  in the statically allocated memory  instead of the automatically allocated  memory. While the language does not  dictate the implementation of either  type of memory, statically allocated  memory is typically reserved in data  segment of the program at compile  time, while the automatically  allocated memory is normally  implemented as a transient call stack.And to answer your second question, it's not like in C#.In C++, however, static is also used to define class attributes (shared between all objects of the same class) and methods. In C there are no classes, so this feature is irrelevant."
"data_i","edited Jun 07 '22 at 13:25","
        Vertical rulers in Visual Studio Code
    ","Rendering More than One Ruler in VS CodeVS Code's default configuration for a ruler is demonstrated below.  ""editor.ruler"": 80The issue I am having with the default VS Code configuration (as shown above) is that it only renders a single ruler. In the Sublime Text Editor I can render as many rulers as I like using the following Sublime configuration.  ""rulers"": [72, 80, 100, 120]Is it possible to render multiple rulers in V.S. Code. If it is possible, What does a multi-ruler configuration look like in VS Code?","Visual Studio Code 0.10.10 introduced this feature. To configure it, go to menu File → Preferences → Settings and add this to to your user or workspace settings:""editor.rulers"": [80,120]The color of the rulers can be customized like this:""workbench.colorCustomizations"": {    ""editorRuler.foreground"": ""#ff4081""}"
"data_i","edited Jul 01 '20 at 11:21","
        How do I set/unset a cookie with jQuery?
    ","How do I set and unset a cookie using jQuery, for example create a cookie named test and set the value to 1?","Update April 2019jQuery isn't needed for cookie reading/manipulation, so don't use the original answer below.Go to https://github.com/js-cookie/js-cookie instead, and use the library there that doesn't depend on jQuery.Basic examples:// Set a cookieCookies.set('name', 'value');// Read the cookieCookies.get('name') => // => 'value'See the docs on github for details.Before April 2019 (old)See the plugin:https://github.com/carhartl/jquery-cookieYou can then do:$.cookie(""test"", 1);To delete:$.removeCookie(""test"");Additionally, to set a timeout of a certain number of days (10 here) on the cookie:$.cookie(""test"", 1, { expires : 10 });If the expires option is omitted, then the cookie becomes a session cookie and is deleted when the browser exits.To cover all the options:$.cookie(""test"", 1, {   expires : 10,           // Expires in 10 days   path    : '/',          // The value of the path attribute of the cookie                           // (Default: path of page that created the cookie).   domain  : 'jquery.com', // The value of the domain attribute of the cookie                           // (Default: domain of page that created the cookie).   secure  : true          // If set to true the secure attribute of the cookie                           // will be set and the cookie transmission will                           // require a secure protocol (defaults to false).});To read back the value of the cookie:var cookieValue = $.cookie(""test"");UPDATE (April 2015):As stated in the comments below, the team that worked on the original plugin has removed the jQuery dependency in a new project (https://github.com/js-cookie/js-cookie) which has the same functionality and general syntax as the jQuery version. Apparently the original plugin isn't going anywhere though."
"data_i","edited Mar 05 '19 at 19:10","
        SOAP vs REST (differences)
    ","I have read articles about the differences between SOAP and REST as a web service communication protocol, but I think that the biggest advantages for REST over SOAP are: REST is more dynamic, no need to create and update UDDI(Universal Description, Discovery, and Integration).REST is not restricted to only XML format. RESTful web services can send plain text/JSON/XML.But SOAP is more standardized (E.g.: security).So, am I correct in these points?","Unfortunately, there are a lot of misinformation and misconceptions around REST. Not only your question and the answer by @cmd reflect those, but most of the questions and answers related to the subject on Stack Overflow.SOAP and REST can't be compared directly, since the first is a protocol (or at least tries to be) and the second is an architectural style. This is probably one of the sources of confusion around it, since people tend to call REST any HTTP API that isn't SOAP.Pushing things a little and trying to establish a comparison, the main difference between SOAP and REST is the degree of coupling between client and server implementations. A SOAP client works like a custom desktop application, tightly coupled to the server. There's a rigid contract between client and server, and everything is expected to break if either side changes anything. You need constant updates following any change, but it's easier to ascertain if the contract is being followed.A REST client is more like a browser. It's a generic client that knows how to use a protocol and standardized methods, and an application has to fit inside that. You don't violate the protocol standards by creating extra methods, you leverage on the standard methods and create the actions with them on your media type. If done right, there's less coupling, and changes can be dealt with more gracefully. A client is supposed to enter a REST service with zero knowledge of the API, except for the entry point and the media type. In SOAP, the client needs previous knowledge on everything it will be using, or it won't even begin the interaction. Additionally, a REST client can be extended by code-on-demand supplied by the server itself, the classical example being JavaScript code used to drive the interaction with another service on the client-side.I think these are the crucial points to understand what REST is about, and how it differs from SOAP:REST is protocol independent. It's not coupled to HTTP. Pretty much like you can follow an ftp link on a website, a REST application can use any protocol for which there is a standardized URI scheme.REST is not a mapping of CRUD to HTTP methods. Read this answer for a detailed explanation on that.REST is as standardized as the parts you're using. Security and authentication in HTTP are standardized, so that's what you use when doing REST over HTTP.REST is not REST without hypermedia and HATEOAS. This means that a client only knows the entry point URI and the resources are supposed to return links the client should follow. Those fancy documentation generators that give URI patterns for everything you can do in a REST API miss the point completely. They are not only documenting something that's supposed to be following the standard, but when you do that, you're coupling the client to one particular moment in the evolution of the API, and any changes on the API have to be documented and applied, or it will break.REST is the architectural style of the web itself. When you enter Stack Overflow, you know what a User, a Question and an Answer are, you know the media types, and the website provides you with the links to them. A REST API has to do the same. If we designed the web the way people think REST should be done, instead of having a home page with links to Questions and Answers, we'd have a static documentation explaining that in order to view a question, you have to take the URI stackoverflow.com/questions/<id>, replace id with the Question.id and paste that on your browser. That's nonsense, but that's what many people think REST is.This last point can't be emphasized enough. If your clients are building URIs from templates in documentation and not getting links in the resource representations, that's not REST. Roy Fielding, the author of REST, made it clear on this blog post: REST APIs must be hypertext-driven. With the above in mind, you'll realize that while REST might not be restricted to XML, to do it correctly with any other format you'll have to design and standardize some format for your links. Hyperlinks are standard in XML, but not in JSON. There are draft standards for JSON, like HAL.Finally, REST isn't for everyone, and a proof of that is how most people solve their problems very well with the HTTP APIs they mistakenly called REST and never venture beyond that. REST is hard to do sometimes, especially in the beginning, but it pays over time with easier evolution on the server side, and client's resilience to changes. If you need something done quickly and easily, don't bother about getting REST right. It's probably not what you're looking for. If you need something that will have to stay online for years or even decades, then REST is for you."
"data_i","edited Oct 15 '18 at 17:49","
        How to extend an existing JavaScript array with another array, without creating a new array
    ","There doesn't seem to be a way to extend an existing JavaScript array with another array, i.e. to emulate Python's extend method.I want to achieve the following:>>> a = [1, 2][1, 2]>>> b = [3, 4, 5][3, 4, 5]>>> SOMETHING HERE>>> a[1, 2, 3, 4, 5]I know there's a a.concat(b) method, but it creates a new array instead of simply extending the first one. I'd like an algorithm that works efficiently when a is significantly larger than b (i.e. one that does not copy a).Note: This is not a duplicate of How to append something to an array? -- the goal here is to add the whole contents of one array to the other, and to do it ""in place"", i.e. without copying all elements of the extended array.","The .push method can take multiple arguments. You can use the spread operator to pass all the elements of the second array as arguments to .push:>>> a.push(...b)If your browser does not support ECMAScript 6, you can use .apply instead:>>> a.push.apply(a, b)Or perhaps, if you think it's clearer:>>> Array.prototype.push.apply(a,b)Please note that all these solutions will fail with a stack overflow error if array b is too long (trouble starts at about 100,000 elements, depending on the browser).If you cannot guarantee that b is short enough, you should use a standard loop-based technique described in the other answer."
"data_i","edited Apr 13 '14 at 17:01","
        How do you use bcrypt for hashing passwords in PHP?
    ","Every now and then I hear the advice ""Use bcrypt for storing passwords in PHP, bcrypt rules"".But what is bcrypt? PHP doesn't offer any such functions, Wikipedia babbles about a file-encryption utility and Web searches just reveal a few implementations of Blowfish in different languages. Now Blowfish is also available in PHP via mcrypt, but how does that help with storing passwords? Blowfish is a general purpose cipher, it works two ways. If it could be encrypted, it can be decrypted. Passwords need a one-way hashing function.What is the explanation?","bcrypt is a hashing algorithm which is scalable with hardware (via a configurable number of rounds). Its slowness and multiple rounds ensures that an attacker must deploy massive funds and hardware to be able to crack your passwords. Add to that per-password salts (bcrypt REQUIRES salts) and you can be sure that an attack is virtually unfeasible without either ludicrous amount of funds or hardware.bcrypt uses the Eksblowfish algorithm to hash passwords. While the encryption phase of Eksblowfish and Blowfish are exactly the same, the key schedule phase of Eksblowfish ensures that any subsequent state depends on both salt and key (user password), and no state can be precomputed without the knowledge of both. Because of this key difference, bcrypt is a one-way hashing algorithm. You cannot retrieve the plain text password without already knowing the salt, rounds and key (password). [Source]How to use bcrypt:Using PHP >= 5.5-DEVPassword hashing functions have now been built directly into PHP >= 5.5. You may now use password_hash() to create a bcrypt hash of any password:<?php// Usage 1:echo password_hash('rasmuslerdorf', PASSWORD_DEFAULT).""\n"";// $2y$10$xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx// For example:// $2y$10$.vGA1O9wmRjrwAVXD98HNOgsNpDczlqm3Jq7KnEd1rVAGv3Fykk1a// Usage 2:$options = [  'cost' => 11];echo password_hash('rasmuslerdorf', PASSWORD_BCRYPT, $options).""\n"";// $2y$11$6DP.V0nO7YI3iSki4qog6OQI5eiO6Jnjsqg7vdnb.JgGIsxniOn4CTo verify a user provided password against an existing hash, you may use the password_verify() as such:<?php// See the password_hash() example to see where this came from.$hash = '$2y$07$BCryptRequires22Chrcte/VlQH0piJtjXl.0t1XkA8pw9dMXTpOq';if (password_verify('rasmuslerdorf', $hash)) {    echo 'Password is valid!';} else {    echo 'Invalid password.';}Using PHP >= 5.3.7, < 5.5-DEV (also RedHat PHP >= 5.3.3)There is a compatibility library on GitHub created based on the source code of the above functions originally written in C, which  provides the same functionality. Once the compatibility library is installed, usage is the same as above (minus the shorthand array notation if you are still on the 5.3.x branch).Using PHP < 5.3.7 (DEPRECATED)You can use crypt() function to generate bcrypt hashes of input strings. This class can automatically generate salts and verify existing hashes against an input. If you are using a version of PHP higher or equal to 5.3.7, it is highly recommended you use the built-in function or the compat library. This alternative is provided only for historical purposes.class Bcrypt{  private $rounds;  public function __construct($rounds = 12) {    if (CRYPT_BLOWFISH != 1) {      throw new Exception(""bcrypt not supported in this installation. See http://php.net/crypt"");    }    $this->rounds = $rounds;  }  public function hash($input){    $hash = crypt($input, $this->getSalt());    if (strlen($hash) > 13)      return $hash;    return false;  }  public function verify($input, $existingHash){    $hash = crypt($input, $existingHash);    return $hash === $existingHash;  }  private function getSalt(){    $salt = sprintf('$2a$%02d$', $this->rounds);    $bytes = $this->getRandomBytes(16);    $salt .= $this->encodeBytes($bytes);    return $salt;  }  private $randomState;  private function getRandomBytes($count){    $bytes = '';    if (function_exists('openssl_random_pseudo_bytes') &&        (strtoupper(substr(PHP_OS, 0, 3)) !== 'WIN')) { // OpenSSL is slow on Windows      $bytes = openssl_random_pseudo_bytes($count);    }    if ($bytes === '' && is_readable('/dev/urandom') &&       ($hRand = @fopen('/dev/urandom', 'rb')) !== FALSE) {      $bytes = fread($hRand, $count);      fclose($hRand);    }    if (strlen($bytes) < $count) {      $bytes = '';      if ($this->randomState === null) {        $this->randomState = microtime();        if (function_exists('getmypid')) {          $this->randomState .= getmypid();        }      }      for ($i = 0; $i < $count; $i += 16) {        $this->randomState = md5(microtime() . $this->randomState);        if (PHP_VERSION >= '5') {          $bytes .= md5($this->randomState, true);        } else {          $bytes .= pack('H*', md5($this->randomState));        }      }      $bytes = substr($bytes, 0, $count);    }    return $bytes;  }  private function encodeBytes($input){    // The following is code from the PHP Password Hashing Framework    $itoa64 = './ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';    $output = '';    $i = 0;    do {      $c1 = ord($input[$i++]);      $output .= $itoa64[$c1 >> 2];      $c1 = ($c1 & 0x03) << 4;      if ($i >= 16) {        $output .= $itoa64[$c1];        break;      }      $c2 = ord($input[$i++]);      $c1 |= $c2 >> 4;      $output .= $itoa64[$c1];      $c1 = ($c2 & 0x0f) << 2;      $c2 = ord($input[$i++]);      $c1 |= $c2 >> 6;      $output .= $itoa64[$c1];      $output .= $itoa64[$c2 & 0x3f];    } while (true);    return $output;  }}You can use this code like this:$bcrypt = new Bcrypt(15);$hash = $bcrypt->hash('password');$isGood = $bcrypt->verify('password', $hash);Alternatively, you may also use the Portable PHP Hashing Framework."
"data_i","edited Nov 20 '19 at 12:06","
        Multiline string literal in C#
    ","Is there an easy way to create a multiline string literal in C#?Here's what I have now:string query = ""SELECT foo, bar""+ "" FROM table""+ "" WHERE id = 42"";I know PHP has<<<BLOCKBLOCK;Does C# have something similar?","You can use the @ symbol in front of a string to form a verbatim string literal:string query = @""SELECT foo, barFROM tableWHERE id = 42"";You also do not have to escape special characters when you use this method, except for double quotes as shown in Jon Skeet's answer."
"data_i","edited May 27 '21 at 10:44","
        Passing parameters to a Bash function
    ","I am trying to search how to pass parameters in a Bash function, but what comes up is always how to pass parameter from the command line.I would like to pass parameters within my script. I tried:myBackupFunction("".."", ""..."", ""xx"")function myBackupFunction($directory, $options, $rootPassword) {     ...}But the syntax is not correct. How can I pass a parameter to my function?","There are two typical ways of declaring a function. I prefer the second approach.function function_name {   command...} orfunction_name () {   command...} To call a function with arguments:function_name ""$arg1"" ""$arg2""The function refers to passed arguments by their position (not by name), that is $1, $2, and so forth. $0 is the name of the script itself.Example:function_name () {   echo ""Parameter #1 is $1""}Also, you need to call your function after it is declared.#!/usr/bin/env shfoo 1  # this will fail because foo has not been declared yet.foo() {    echo ""Parameter #1 is $1""}foo 2 # this will work.Output:./myScript.sh: line 2: foo: command not foundParameter #1 is 2Reference: Advanced Bash-Scripting Guide."
"data_i","edited Apr 19 '20 at 17:22","
        Create a tag in a GitHub repository
    ","I have a repository in GitHub and I need to tag it.I tagged in a shell, but on GitHub, it is not showing up. Do I have to do anything else?The command I used in the shell is:git tag 2.0And now when I type git tag it shows:2.0So it seems like tags are present, correct?The repository is: https://github.com/keevitaja/myseo-pyrocms.How do I make this tag show up on GitHub? Where are my tags?","You can create tags for GitHub by either using:the Git command line, orGitHub's web interface.Creating tags from the command lineTo create a tag on your current branch, run this:git tag <tagname>If you want to include a description with your tag, add -a to create an annotated tag:git tag <tagname> -aThis will create a local tag with the current state of the branch you are on. When pushing to your remote repo, tags are NOT included by default. You will need to explicitly say that you want to push your tags to your remote repo:git push origin --tagsFrom the official Linux Kernel Git documentation for git push:--tagsAll refs under refs/tags are pushed, in addition to refspecs explicitly listed on the command line.Or if you just want to push a single tag:git push origin <tag>See also my answer to How do you push a tag to a remote repository using Git? for more details about that syntax above.Creating tags through GitHub's web interfaceYou can find GitHub's instructions for this at their Creating Releases help page. Here is a summary:Click the releases link on our repository page,Click on Create a new release or Draft a new release,Fill out the form fields, then click Publish release at the bottom,After you create your tag on GitHub, you might want to fetch it into your local repository too:git fetchNow next time, you may want to create one more tag within the same release from website. For that follow these steps:Go to release tabClick on edit button for the releaseProvide name of the new tag ABC_DEF_V_5_3_T_2 and hit tabAfter hitting tab, UI will show this message: Excellent! This tag will be created from the target when you publish this release. Also UI will provide an option to select the branch/commitSelect branch or commitCheck ""This is a pre-release"" checkbox for qa tag and uncheck it if the tag is created for Prod tag.After that click on ""Update Release""This will create a new Tag within the existing Release."
"data_i","asked May 18 '13 at 07:18","
        \d less efficient than [0-9]
    ","I made a comment yesterday on an answer where someone had used [0123456789] in a regex rather than [0-9] or \d. I said it was probably more efficient to use a range or digit specifier than a character set.I decided to test that out today and found out to my surprise that (in the c# regex engine at least) \d appears to be less efficient than either of the other two which don't seem to differ much. Here is my test output over 10000 random strings of 1000 random characters with 5077 actually containing a digit:Regex \d           took 00:00:00.2141226 result: 5077/10000Regex [0-9]        took 00:00:00.1357972 result: 5077/10000  63.42 % of firstRegex [0123456789] took 00:00:00.1388997 result: 5077/10000  64.87 % of firstIt's a surprise to me for two reasons, that I would be interested if anyone can shed some light on:I would have thought the range would be implemented much more efficiently than the set.I can't understand why \d is worse than [0-9]. Is there more to \d than simply shorthand for [0-9]?Here is the test code:using System;using System.Collections.Generic;using System.Linq;using System.Text;using System.Diagnostics;using System.Text.RegularExpressions;namespace SO_RegexPerformance{    class Program    {        static void Main(string[] args)        {            var rand = new Random(1234);            var strings = new List<string>();            //10K random strings            for (var i = 0; i < 10000; i++)            {                //generate random string                var sb = new StringBuilder();                for (var c = 0; c < 1000; c++)                {                    //add a-z randomly                    sb.Append((char)('a' + rand.Next(26)));                }                //in roughly 50% of them, put a digit                if (rand.Next(2) == 0)                {                    //replace 1 char with a digit 0-9                    sb[rand.Next(sb.Length)] = (char)('0' + rand.Next(10));                }                strings.Add(sb.ToString());            }            var baseTime = testPerfomance(strings, @""\d"");            Console.WriteLine();            var testTime = testPerfomance(strings, ""[0-9]"");            Console.WriteLine(""  {0:P2} of first"", testTime.TotalMilliseconds / baseTime.TotalMilliseconds);            testTime = testPerfomance(strings, ""[0123456789]"");            Console.WriteLine(""  {0:P2} of first"", testTime.TotalMilliseconds / baseTime.TotalMilliseconds);        }        private static TimeSpan testPerfomance(List<string> strings, string regex)        {            var sw = new Stopwatch();            int successes = 0;            var rex = new Regex(regex);            sw.Start();            foreach (var str in strings)            {                if (rex.Match(str).Success)                {                    successes++;                }            }            sw.Stop();            Console.Write(""Regex {0,-12} took {1} result: {2}/{3}"", regex, sw.Elapsed, successes, strings.Count);            return sw.Elapsed;        }    }}","\d checks all Unicode digits, while [0-9] is limited to these 10 characters. For example, Persian digits, ۱۲۳۴۵۶۷۸۹, are an example of Unicode digits which are matched with \d, but not [0-9].You can generate a list of all such characters using the following code:var sb = new StringBuilder();for(UInt16 i = 0; i < UInt16.MaxValue; i++){    string str = Convert.ToChar(i).ToString();    if (Regex.IsMatch(str, @""\d""))        sb.Append(str);}Console.WriteLine(sb.ToString());Which generates:0123456789٠١٢٣٤٥٦٧٨٩۰۱۲۳۴۵۶۷۸۹߀߁߂߃߄߅߆߇߈߉०१२३४५६७८९০১২৩৪৫৬৭৮৯੦੧੨੩੪੫੬੭੮੯૦૧૨૩૪૫૬૭૮૯୦୧୨୩୪୫୬୭୮୯௦௧௨௩௪௫௬௭௮௯౦౧౨౩౪౫౬౭౮౯೦೧೨೩೪೫೬೭೮೯൦൧൨൩൪൫൬൭൮൯๐๑๒๓๔๕๖๗๘๙໐໑໒໓໔໕໖໗໘໙༠༡༢༣༤༥༦༧༨༩၀၁၂၃၄၅၆၇၈၉႐႑႒႓႔႕႖႗႘႙០១២៣៤៥៦៧៨៩᠐᠑᠒᠓᠔᠕᠖᠗᠘᠙᥆᥇᥈᥉᥊᥋᥌᥍᥎᥏᧐᧑᧒᧓᧔᧕᧖᧗᧘᧙᭐᭑᭒᭓᭔᭕᭖᭗᭘᭙᮰᮱᮲᮳᮴᮵᮶᮷᮸᮹᱀᱁᱂᱃᱄᱅᱆᱇᱈᱉᱐᱑᱒᱓᱔᱕᱖᱗᱘᱙꘠꘡꘢꘣꘤꘥꘦꘧꘨꘩꣐꣑꣒꣓꣔꣕꣖꣗꣘꣙꤀꤁꤂꤃꤄꤅꤆꤇꤈꤉꩐꩑꩒꩓꩔꩕꩖꩗꩘꩙０１２３４５６７８９"
"data_i","edited Aug 06 '21 at 15:57","
        How can I list the tables in a SQLite database file that was opened with ATTACH?
    ","What SQL can be used to list the tables, and the rows within those tables in an SQLite database file - once I have attached it with the ATTACH command on the SQLite 3 command line tool?","There are a few steps to see the tables in an SQLite database:List the tables in your database:.tablesList how the table looks:.schema tablenamePrint the entire table:SELECT * FROM tablename;List all of the available SQLite prompt commands:.help"
"data_i","edited Apr 13 '22 at 19:31","
        .gitignore exclude folder but include specific subfolder
    ","I have the folder application/ which I add to the .gitignore. Inside the  application/ folder is the folder application/language/gr. How can I include this folder?I've tried thisapplication/!application/language/gr/","If you exclude application/, then everything under it will always be excluded (even if some later negative exclusion pattern (“unignore”) might match something under application/).To do what you want, you have to “unignore” every parent directory of anything that you want to “unignore”. Usually you end up writing rules for this situation in pairs: ignore everything in a directory, but not some certain subdirectory.# you can skip this first one if it is not already excluded by prior patterns!application/application/*!application/language/application/language/*!application/language/gr/NoteThe trailing /* is significant:  The pattern dir/ excludes a directory named dir and (implicitly) everything under it.With dir/, Git will never look at anything under dir, and thus will never apply any of the “un-exclude” patterns to anything under dir.The pattern dir/* says nothing about dir itself; it just excludes everything under dir.With dir/*, Git will process the direct contents of dir, giving other patterns a chance to “un-exclude” some bit of the content (!dir/sub/). "
"data_i","edited Oct 06 '12 at 12:28","
        Recommended way to embed PDF in HTML?
    ","What is the recommended way to embed PDF in HTML?iFrame? Object? Embed?What does Adobe say itself about it?In my case, the PDF is generated on the fly, so it can't be uploaded to a third-party solution prior to flushing it.","This is quick, easy, to the point and doesn't require any third-party script:<embed src=""http://example.com/the.pdf"" width=""500"" height=""375""  type=""application/pdf"">UPDATE (2/3/2021)Adobe now offers it's own PDF Embed API.https://www.adobe.io/apis/documentcloud/dcsdk/pdf-embed.htmlUPDATE (1/2018):The Chrome browser on Android no longer supports PDF embeds. You can get around this by using the Google Drive PDF viewer<embed src=""https://drive.google.com/viewerng/viewer?embedded=true&url=http://example.com/the.pdf"" width=""500"" height=""375"">"
"data_i","edited Oct 23 '19 at 12:16","
        How can I declare and use Boolean variables in a shell script?
    ","I tried to declare a Boolean variable in a shell script using the following syntax:variable=$falsevariable=$trueIs this correct? Also, if I wanted to update that variable would I use the same syntax? Finally, is the following syntax for using Boolean variables as expressions correct?if [ $variable ]if [ !$variable ]","Revised Answer (Feb 12, 2014)the_world_is_flat=true# ...do something interesting...if [ ""$the_world_is_flat"" = true ] ; then    echo 'Be careful not to fall off!'fiOriginal AnswerCaveats: https://stackoverflow.com/a/21210966/89391the_world_is_flat=true# ...do something interesting...if $the_world_is_flat ; then    echo 'Be careful not to fall off!'fiFrom: Using boolean variables in BashThe reason the original answer is included here is because the comments before the revision on Feb 12, 2014 pertain only to the original answer, and many of the comments are wrong when associated with the revised answer. For example, Dennis Williamson's comment about bash builtin true on Jun 2, 2010 only applies to the original answer, not the revised."
"data_i","edited Jan 09 '19 at 20:48","
        UTF-8 all the way through
    ","I'm setting up a new server and want to support UTF-8 fully in my web application. I have tried this in the past on existing servers and always seem to end up having to fall back to ISO-8859-1.Where exactly do I need to set the encoding/charsets? I'm aware that I need to configure Apache, MySQL, and PHP to do this — is there some standard checklist I can follow, or perhaps troubleshoot where the mismatches occur?This is for a new Linux server, running MySQL 5, PHP, 5 and Apache 2.","Data Storage:Specify the utf8mb4 character set on all tables and text columns in your database.  This makes MySQL physically store and retrieve values encoded natively in UTF-8.  Note that MySQL will implicitly use utf8mb4 encoding if a utf8mb4_* collation is specified (without any explicit character set).In older versions of MySQL (< 5.5.3), you'll unfortunately be forced to use simply utf8, which only supports a subset of Unicode characters.  I wish I were kidding.Data Access:In your application code (e.g. PHP), in whatever DB access method you use, you'll need to set the connection charset to utf8mb4.  This way, MySQL does no conversion from its native UTF-8 when it hands data off to your application and vice versa.Some drivers provide their own mechanism for configuring the connection character set, which both updates its own internal state and informs MySQL of the encoding to be used on the connection—this is usually the preferred approach.   In PHP:If you're using the PDO abstraction layer with PHP ≥ 5.3.6, you can specify charset in the DSN: $dbh = new PDO('mysql:charset=utf8mb4');If you're using mysqli, you can call set_charset():  $mysqli->set_charset('utf8mb4');       // object oriented style  mysqli_set_charset($link, 'utf8mb4');  // procedural styleIf you're stuck with plain mysql but happen to be running PHP ≥ 5.2.3, you can call mysql_set_charset.If the driver does not provide its own mechanism for setting the connection character set, you may have to issue a query to tell MySQL how your application expects data on the connection to be encoded: SET NAMES 'utf8mb4'.The same consideration regarding utf8mb4/utf8 applies as above.Output:UTF-8 should be set in the HTTP header, such as Content-Type: text/html; charset=utf-8. You can achieve that either by setting default_charset in php.ini (preferred), or manually using header() function.If your application transmits text to other systems, they will also need to be informed of the character encoding.  With web applications, the browser must be informed of the encoding in which data is sent (through HTTP response headers or HTML metadata).When encoding the output using json_encode(), add JSON_UNESCAPED_UNICODE as a second parameter.Input:Browsers will submit data in the character set specified for the document, hence nothing particular has to be done on the input.In case you have doubts about request encoding (in case it could be tampered with), you may verify every received string as being valid UTF-8 before you try to store it or use it anywhere.  PHP's mb_check_encoding() does the trick, but you have to use it religiously.  There's really no way around this, as malicious clients can submit data in whatever encoding they want, and I haven't found a trick to get PHP to do this for you reliably.Other Code Considerations:Obviously enough, all files you'll be serving (PHP, HTML, JavaScript, etc.) should be encoded in valid UTF-8.You need to make sure that every time you process a UTF-8 string, you do so safely.  This is, unfortunately, the hard part.  You'll probably want to make extensive use of PHP's mbstring extension.PHP's built-in string operations are not by default UTF-8 safe.  There are some things you can safely do with normal PHP string operations (like concatenation), but for most things you should use the equivalent mbstring function.To know what you're doing (read: not mess it up), you really need to know UTF-8 and how it works on the lowest possible level.  Check out any of the links from utf8.com for some good resources to learn everything you need to know."
"data_i","edited Sep 16 '22 at 10:56","
        Difference between ""wait()"" vs ""sleep()"" in Java
    ","What is the difference between a wait() and sleep() in Threads?Is my understanding that a wait()-ing Thread is still in running mode and uses CPU cycles but a sleep()-ing does not consume any CPU cycles correct?Why do we have both wait() and sleep()?How does their implementation vary at a lower level?","A wait can be ""woken up"" by another thread calling notify on the monitor which is being waited on whereas a sleep cannot. Also a wait (and notify) must happen in a block synchronized on the monitor object whereas sleep does not:Object mon = ...;synchronized (mon) {    mon.wait();} At this point the currently executing thread waits and releases the monitor. Another thread may dosynchronized (mon) { mon.notify(); }(on the same mon object) and the first thread (assuming it is the only thread waiting on the monitor) will wake up. You can also call notifyAll if more than one thread is waiting on the monitor – this will wake all of them up. However, only one of the threads will be able to grab the monitor (remember that the wait is in a synchronized block) and carry on – the others will then be blocked until they can acquire the monitor's lock.Another point is that you call wait on Object itself (i.e. you wait on an object's monitor) whereas you call sleep on Thread.Yet another point is that you can get spurious wakeups from wait (i.e. the thread which is waiting resumes for no apparent reason). You should always wait whilst spinning on some condition as follows:  synchronized {    while (!condition) { mon.wait(); }}"
"data_i","edited Jul 13 '22 at 12:54","
        jQuery Get Selected Option From Dropdown
    ","Usually I use $(""#id"").val() to return the value of the selected option, but this time it doesn't work.The selected tag has the id aioConceptNamehtml code<label for=""name"">Name</label><input type=""text"" name=""name"" id=""name"" /><label for=""aioConceptName"">AIO Concept Name</label><select id=""aioConceptName"">    <option>choose io</option>    <option>roma</option>    <option>totti</option></select>","For dropdown options you probably want something like this:For selected textvar conceptName = $('#aioConceptName').find("":selected"").text();For selected valuevar conceptName = $('#aioConceptName').find("":selected"").val();The reason val() doesn't do the trick is because clicking an option doesn't change the value of the dropdown--it just adds the :selected property to the selected option which is a child of the dropdown."
"data_i","edited Apr 10 '22 at 10:31","
        How to move a file in Python?
    ","How would I do the equivalent of mv src/* dest/ in Python?>>> source_files = '/PATH/TO/FOLDER/*'>>> destination_folder = 'PATH/TO/FOLDER'>>> # equivalent of $ mv source_files destination_folder","os.rename(), os.replace(), or shutil.move()All employ the same syntax:import osimport shutilos.rename(""path/to/current/file.foo"", ""path/to/new/destination/for/file.foo"")os.replace(""path/to/current/file.foo"", ""path/to/new/destination/for/file.foo"")shutil.move(""path/to/current/file.foo"", ""path/to/new/destination/for/file.foo"")Note that you must include the file name (file.foo) in both the source and destination arguments. If it is changed, the file will be renamed as well as moved.Note also that in the first two cases the directory in which the new file is being created must already exist. On Windows, a file with that name must not exist or an exception will be raised, but os.replace() will silently replace a file even in that occurrence.As has been noted in comments on other answers, shutil.move simply calls os.rename in most cases. However, if the destination is on a different disk than the source, it will instead copy and then delete the source file."
"data_i","edited Sep 28 '12 at 19:02","
        How to cherry-pick multiple commits
    ","I have two branches. Commit a is the head of one, while the other has b, c, d, e and f on top of a. I want to move c, d, e and f to first branch without commit b. Using cherry pick it is easy: checkout first branch cherry-pick one by one c to f and rebase second branch onto first. But is there any way to cherry-pick all c-f in one command?Here is a visual description of the scenario (thanks JJD):","Git 1.7.2 introduced the ability to cherry pick a range of commits. From the release notes:git cherry-pick learned to pick a range of commits(e.g. cherry-pick A..B and cherry-pick --stdin), so did git revert; these do not support the nicer sequencing control rebase [-i] has, though.To cherry-pick all the commits from commit A to commit B (where A is older than B), run:git cherry-pick A^..BIf you want to ignore A itself, run:git cherry-pick A..BNotes from comments:A should be older than B, or A should be from another branch.On Windows, it should be A^^..B as the caret needs to be escaped, or it should be ""A^..B"" (double quotes).In zsh shell, it should be 'A^..B' (single quotes) as the caret is a special character.For an exposition, see the answer by Gabriel Staples.(Credits to damian, J. B. Rainsberger, sschaef, Neptilo, Pete and TMin in the comments.)"
"data_i","edited Nov 28 '17 at 13:57","
        How do I sort an NSMutableArray with custom objects in it?
    ","What I want to do seems pretty simple, but I can't find any answers on the web. I have an NSMutableArray of objects, and let's say they are 'Person' objects. I want to sort the NSMutableArray by Person.birthDate which is an NSDate.I think it has something to do with this method:NSArray *sortedArray = [drinkDetails sortedArrayUsingSelector:@selector(???)];In Java I would make my object implement Comparable, or use Collections.sort with an inline custom comparator...how on earth do you do this in Objective-C?","Compare methodEither you implement a compare-method for your object:- (NSComparisonResult)compare:(Person *)otherObject {    return [self.birthDate compare:otherObject.birthDate];}NSArray *sortedArray = [drinkDetails sortedArrayUsingSelector:@selector(compare:)];NSSortDescriptor (better)or usually even better:NSSortDescriptor *sortDescriptor;sortDescriptor = [[NSSortDescriptor alloc] initWithKey:@""birthDate""                                           ascending:YES];NSArray *sortedArray = [drinkDetails sortedArrayUsingDescriptors:@[sortDescriptor]];You can easily sort by multiple keys by adding more than one to the array. Using custom comparator-methods is possible as well. Have a look at the documentation.Blocks (shiny!)There's also the possibility of sorting with a block since Mac OS X 10.6 and iOS 4:NSArray *sortedArray;sortedArray = [drinkDetails sortedArrayUsingComparator:^NSComparisonResult(Person *a, Person *b) {    return [a.birthDate compare:b.birthDate];}];PerformanceThe -compare: and block-based methods will be quite a bit faster, in general, than using NSSortDescriptor as the latter relies on KVC.  The primary advantage of the NSSortDescriptor method is that it provides a way to define your sort order using data, rather than code, which makes it easy to e.g. set things up so users can sort an NSTableView by clicking on the header row."
"data_i","edited Jun 25 '21 at 08:40","
        SQL Server - Best way to get identity of inserted row?
    ","What is the best way to get IDENTITY of inserted row?I know about @@IDENTITY and IDENT_CURRENT and SCOPE_IDENTITY but don't understand the pros and cons attached to each.Can someone please explain the differences and when I should be using each?","@@IDENTITY returns the last identity value generated for any table in the current session, across all scopes.  You need to be careful here, since it's across scopes.  You could get a value from a trigger, instead of your current statement.SCOPE_IDENTITY() returns the last identity value generated for any table in the current session and the current scope.  Generally what you want to use.IDENT_CURRENT('tableName') returns the last identity value generated for a specific table in any session and any scope.  This lets you specify which table you want the value from, in case the two above aren't quite what you need (very rare).  Also, as @Guy Starbuck mentioned, ""You could use this if you want to get the current IDENTITY value for a table that you have not inserted a record into.""The OUTPUT clause of the INSERT statement will let you access every row that was inserted via that statement.  Since it's scoped to the specific statement, it's more straightforward than the other functions above.  However, it's a little more verbose (you'll need to insert into a table variable/temp table and then query that) and it gives results even in an error scenario where the statement is rolled back.  That said, if your query uses a parallel execution plan, this is the only guaranteed method for getting the identity (short of turning off parallelism). However, it is executed before triggers and cannot be used to return trigger-generated values."
"data_i","edited Jun 05 '22 at 19:47","
        How do I get the full path of the current file's directory?
    ","How do I get the current file's directory path?I tried:>>> os.path.abspath(__file__)'C:\\python27\\test.py'But I want:'C:\\python27\\'","The special variable __file__ contains the path to the current file. From that we can get the directory using either pathlib or the os.path module.Python 3For the directory of the script being run:import pathlibpathlib.Path(__file__).parent.resolve()For the current working directory:import pathlibpathlib.Path().resolve()Python 2 and 3For the directory of the script being run:import osos.path.dirname(os.path.abspath(__file__))If you mean the current working directory:import osos.path.abspath(os.getcwd())Note that before and after file is two underscores, not just one.Also note that if you are running interactively or have loaded code from something other than a file (eg: a database or online resource), __file__ may not be set since there is no notion of ""current file"". The above answer assumes the most common scenario of running a python script that is in a file.Referencespathlib in the python documentation.os.path - Python 2.7, os.path - Python 3os.getcwd - Python 2.7, os.getcwd - Python 3what does the __file__ variable mean/do?"
"data_i","edited Jun 20 '22 at 06:47","
        How do I terminate a script?
    ","How do I exit a script early, like the die() command in PHP?","import syssys.exit()details from the sys module documentation:sys.exit([arg])Exit from Python. This is implemented by raising theSystemExit exception, so cleanup actions specified by finally clausesof try statements are honored, and it is possible to intercept theexit attempt at an outer level.The optional argument arg can be an integer giving the exit status(defaulting to zero), or another type of object. If it is an integer,zero is considered “successful termination” and any nonzero value isconsidered “abnormal termination” by shells and the like. Most systemsrequire it to be in the range 0-127, and produce undefined resultsotherwise. Some systems have a convention for assigning specificmeanings to specific exit codes, but these are generallyunderdeveloped; Unix programs generally use 2 for command line syntaxerrors and 1 for all other kind of errors. If another type of objectis passed, None is equivalent to passing zero, and any other object isprinted to stderr and results in an exit code of 1. In particular,sys.exit(""some error message"") is a quick way to exit a program whenan error occurs.Since exit() ultimately “only” raises an exception, it will only exitthe process when called from the main thread, and the exception is notintercepted.Note that this is the 'nice' way to exit.  @glyphtwistedmatrix below points out that if you want a 'hard exit', you can use os._exit(*errorcode*), though it's likely os-specific to some extent (it might not take an errorcode under windows, for example), and it definitely is less friendly since it doesn't let the interpreter do any cleanup before the process dies.  On the other hand, it does kill the entire process, including all running threads, while sys.exit() (as it says in the docs) only exits if called from the main thread, with no other threads running."
"data_i","edited Feb 28 '13 at 14:16","
        How do I determine the size of my array in C?
    ","How do I determine the size of my array in C? That is, the number of elements the array can hold?","Executive summary:int a[17];size_t n = sizeof(a)/sizeof(a[0]);Full answer:To determine the size of your array in bytes, you can use the sizeofoperator:int a[17];size_t n = sizeof(a);On my computer, ints are 4 bytes long, so n is 68.To determine the number of elements in the array, we can dividethe total size of the array by the size of the array element.You could do this with the type, like this:int a[17];size_t n = sizeof(a) / sizeof(int);and get the proper answer (68 / 4 = 17), but if the type ofa changed you would have a nasty bug if you forgot to changethe sizeof(int) as well.So the preferred divisor is sizeof(a[0]) or the equivalent sizeof(*a), the size of the first element of the array.int a[17];size_t n = sizeof(a) / sizeof(a[0]);Another advantage is that you can now easily parameterizethe array name in a macro and get:#define NELEMS(x)  (sizeof(x) / sizeof((x)[0]))int a[17];size_t n = NELEMS(a);"
"data_i","edited Dec 18 '18 at 00:58","
        What are some examples of commonly used practices for naming git branches?
    ","I've been using a local git repository interacting with my group's CVS repository for several months, now.  I've made an almost neurotic number of branches, most of which have thankfully merged back into my trunk.  But naming is starting to become an issue.  If I have a task easily named with a simple label, but I accomplish it in three stages which each include their own branch and merge situation, then I can repeat the branch name each time, but that makes the history a little confusing.  If I get more specific in the names, with a separate description for each stage, then the branch names start to get long and unwieldy.I did learn looking through old threads here that I could start naming branches with a / in the name, i.e., topic/task, or something like that.  I may start doing that and seeing if it helps keep things better organized.What are some best practices for naming git branches?Edit:Nobody has actually suggested any naming conventions.I do delete branches when I'm done with them.  I just happen to have several around due to management constantly adjusting my priorities. :)As an example of why I might need more than one branch on a task, suppose I need to commit the first discrete milestone in the task to the group's CVS repository.  At that point, due to my imperfect interaction with CVS, I would perform that commit and then kill that branch.  (I've seen too much weirdness interacting with CVS if I try to continue to use the same branch at that point.)","Here are some branch naming conventions that I use and the reasons for themBranch naming conventionsUse grouping tokens (words) at the beginning of your branch names.Define and use short lead tokens to differentiate branches in a way that is meaningful to your workflow.Use slashes to separate parts of your branch names.Do not use bare numbers as leading parts.Avoid long descriptive names for long-lived branches.Group tokensUse ""grouping"" tokens in front of your branch names. group1/foogroup2/foogroup1/bargroup2/bargroup3/bargroup1/bazThe groups can be named whatever you like to match your workflow.  I like to use short nouns for mine.  Read on for more clarity.Short well-defined tokensChoose short tokens so they do not add too much noise to every one of your branch names.  I use these:wip       Works in progress; stuff I know won't be finished soonfeat      Feature I'm adding or expandingbug       Bug fix or experimentjunk      Throwaway branch created to experimentEach of these tokens can be used to tell you to which part of your workflow each branch belongs.It sounds like you have multiple branches for different cycles of a change. I do not know what your cycles are, but let's assume they are 'new', 'testing' and 'verified'.  You can name your branches with abbreviated versions of these tags, always spelled the same way, to both group them and to remind you which stage you're in.new/frabnotznew/foonew/bartest/footest/frabnotzver/fooYou can quickly tell which branches have reached each different stage, and you can group them together easily using Git's pattern matching options.$ git branch --list ""test/*""test/footest/frabnotz$ git branch --list ""*/foo""new/footest/foover/foo$ gitk --branches=""*/foo""Use slashes to separate partsYou may use most any delimiter you like in branch names, but I find slashes to be the most flexible. You might prefer to use dashes or dots.  But slashes let you do some branch renaming when pushing or fetching to/from a remote.$ git push origin 'refs/heads/feature/*:refs/heads/phord/feat/*'$ git push origin 'refs/heads/bug/*:refs/heads/review/bugfix/*'For me, slashes also work better for tab expansion (command completion) in my shell.  The way I have it configured I can search for branches with different sub-parts by typing the first characters of the part and pressing the TAB key.  Zsh then gives me a list of branches which match the part of the token I have typed.  This works for preceding tokens as well as embedded ones.$ git checkout new<TAB>Menu:  new/frabnotz   new/foo   new/bar$ git checkout foo<TAB>Menu:  new/foo   test/foo   ver/foo(Zshell is very configurable about command completion and I could also configure it to handle dashes, underscores or dots the same way. But I choose not to.)It also lets you search for branches in many git commands, like this:git branch --list ""feature/*""git log --graph --oneline --decorate --branches=""feature/*"" gitk --branches=""feature/*"" Caveat: As Slipp points out in the comments, slashes can cause problems.  Because branches are implemented as paths, you cannot have a branch named ""foo"" and another branch named ""foo/bar"".  This can be confusing for new users.Do not use bare numbersDo not use use bare numbers (or hex numbers) as part of your branch naming scheme. Inside tab-expansion of a reference name, git may decide that a number is part of a sha-1 instead of a branch name.  For example, my issue tracker names bugs with decimal numbers.  I name my related branches CRnnnnn rather than just nnnnn to avoid confusion.  $ git checkout CR15032<TAB>Menu:   fix/CR15032    test/CR15032If I tried to expand just 15032, git would be unsure whether I wanted to search SHA-1's or branch names, and my choices would be somewhat limited.Avoid long descriptive namesLong branch names can be very helpful when you are looking at a list of branches.  But it can get in the way when looking at decorated one-line logs as the branch names can eat up most of the single line and abbreviate the visible part of the log.On the other hand long branch names can be more helpful in ""merge commits"" if you do not habitually rewrite them by hand.  The default merge commit message is Merge branch 'branch-name'.  You may find it more helpful to have merge messages show up as Merge branch 'fix/CR15032/crash-when-unformatted-disk-inserted' instead of just Merge branch 'fix/CR15032'."
"data_i","edited Apr 09 '22 at 22:45","
        How can I get the full object in Node.js's console.log(), rather than '[Object]'?
    ","I have this object:const myObject = {   ""a"":""a"",   ""b"":{      ""c"":""c"",      ""d"":{         ""e"":""e"",         ""f"":{            ""g"":""g"",            ""h"":{               ""i"":""i""            }         }      }   }};But when I try to show it using console.log(myObject), I receive this output:{ a: 'a', b: { c: 'c', d: { e: 'e', f: [Object] } } }How can I get the full object, including the content of property f?","You need to use util.inspect():const util = require('util')console.log(util.inspect(myObject, {showHidden: false, depth: null, colors: true}))// alternative shortcutconsole.log(util.inspect(myObject, false, null, true /* enable colors */))Outputs{ a: 'a',  b: { c: 'c', d: { e: 'e', f: { g: 'g', h: { i: 'i' } } } } }"
"data_i","edited Apr 16 '20 at 08:06","
        Where and why do I have to put the ""template"" and ""typename"" keywords?
    ","In templates, where and why do I have to put typename and template on dependent names?What exactly are dependent names anyway?  I have the following code:template <typename T, typename Tail> // Tail will be a UnionNode too.struct UnionNode : public Tail {    // ...    template<typename U> struct inUnion {        // Q: where to add typename/template here?        typedef Tail::inUnion<U> dummy;     };    template< > struct inUnion<T> {    };};template <typename T> // For the last node Tn.struct UnionNode<T, void> {    // ...    template<typename U> struct inUnion {        char fail[ -2 + (sizeof(U)%2) ]; // Cannot be instantiated for any U    };    template< > struct inUnion<T> {    };};The problem I have is in the typedef Tail::inUnion<U> dummy line. I'm fairly certain that inUnion is a dependent name, and VC++ is quite right in choking on it.I also know that I should be able to add template somewhere to tell the compiler that inUnion is a template-id. But where exactly? And should it then assume that inUnion is a class template, i.e. inUnion<U> names a type and not a function?","(See here also for my C++11 answer)In order to parse a C++ program, the compiler needs to know whether certain names are types or not. The following example demonstrates that:t * f;How should this be parsed? For many languages a compiler doesn't need to know the meaning of a name in order to parse and basically know what action a line of code does. In C++, the above however can yield vastly different interpretations depending on what t means. If it's a type, then it will be a declaration of a pointer f. However if it's not a type, it will be a multiplication. So the C++ Standard says at paragraph (3/7):Some names denote types or templates. In general, whenever a name is encountered it is necessary to determine whether that name denotes one of these entities before continuing to parse the program that contains it. The process that determines this is called name lookup.How will the compiler find out what a name t::x refers to, if t refers to a template type parameter? x could be a static int data member that could be multiplied or could equally well be a nested class or typedef that could yield to a declaration. If a name has this property - that it can't be looked up until the actual template arguments are known - then it's called a dependent name (it ""depends"" on the template parameters). You might recommend to just wait till the user instantiates the template: Let's wait until the user instantiates the template, and then later find out the real meaning of t::x * f;. This will work and actually is allowed by the Standard as a possible implementation approach. These compilers basically copy the template's text into an internal buffer, and only when an instantiation is needed, they parse the template and possibly detect errors in the definition. But instead of bothering the template's users (poor colleagues!) with errors made by a template's author, other implementations choose to check templates early on and give errors in the definition as soon as possible, before an instantiation even takes place. So there has to be a way to tell the compiler that certain names are types and that certain names aren't. The ""typename"" keywordThe answer is: We decide how the compiler should parse this. If t::x is a dependent name, then we need to prefix it by typename to tell the compiler to parse it in a certain way. The Standard says at (14.6/2):A name used in a template declaration or definition and that is dependent on a template-parameter is  assumed not to name a type unless the applicable name lookup finds a type name or the name is qualified  by the keyword typename. There are many names for which typename is not necessary, because the compiler can, with the applicable name lookup in the template definition, figure out how to parse a construct itself - for example with T *f;, when T is a type template parameter. But for t::x * f; to be a declaration, it must be written as typename t::x *f;. If you omit the keyword and the name is taken to be a non-type, but when instantiation finds it denotes a type, the usual error messages are emitted by the compiler. Sometimes, the error consequently is given at definition time:// t::x is taken as non-type, but as an expression the following misses an// operator between the two names or a semicolon separating them.t::x f;The syntax allows typename only before qualified names - it is therefor taken as granted that unqualified names are always known to refer to types if they do so.A similar gotcha exists for names that denote templates, as hinted at by the introductory text.The ""template"" keywordRemember the initial quote above and how the Standard requires special handling for templates as well? Let's take the following innocent-looking example: boost::function< int() > f;It might look obvious to a human reader. Not so for the compiler. Imagine the following arbitrary definition of boost::function and f:namespace boost { int function = 0; }int main() {   int f = 0;  boost::function< int() > f; }That's actually a valid expression! It uses the less-than operator to compare boost::function against zero (int()), and then uses the greater-than operator to compare the resulting bool against f. However as you might well know, boost::function in real life is a template, so the compiler knows (14.2/3):After name lookup (3.4) finds that a name is a template-name, if this name is followed by a <, the < is  always taken as the beginning of a template-argument-list and never as a name followed by the less-than  operator.Now we are back to the same problem as with typename. What if we can't know yet whether the name is a template when parsing the code? We will need to insert template immediately before the template name, as specified by 14.2/4. This looks like:t::template f<int>(); // call a function templateTemplate names can not only occur after a :: but also after a -> or . in a class member access. You need to insert the keyword there too:this->template f<int>(); // call a function templateDependenciesFor the people that have thick Standardese books on their shelf and that want to know what exactly I was talking about, I'll talk a bit about how this is specified in the Standard.In template declarations some constructs have different meanings depending on what template arguments you use to instantiate the template: Expressions may have different types or values, variables may have different types or function calls might end up calling different functions. Such constructs are generally said to depend on template parameters.The Standard defines precisely the rules by whether a construct is dependent or not. It separates them into logically different groups: One catches types, another catches expressions. Expressions may depend by their value and/or their type. So we have, with typical examples appended:Dependent types (e.g: a type template parameter T)Value-dependent expressions (e.g: a non-type template parameter N)Type-dependent expressions (e.g: a cast to a type template parameter (T)0)Most of the rules are intuitive and are built up recursively: For example, a type constructed as T[N] is a dependent type if N is a value-dependent expression or T is a dependent type. The details of this can be read in section (14.6.2/1) for dependent types, (14.6.2.2) for type-dependent expressions and (14.6.2.3) for value-dependent expressions. Dependent namesThe Standard is a bit unclear about what exactly is a dependent name. On a simple read (you know, the principle of least surprise), all it defines as a dependent name is the special case for function names below. But since clearly T::x also needs to be looked up in the instantiation context, it also needs to be a dependent name (fortunately, as of mid C++14 the committee has started to look into how to fix this confusing definition). To avoid this problem, I have resorted to a simple interpretation of the Standard text. Of all the constructs that denote dependent types or expressions, a subset of them represent names. Those names are therefore ""dependent names"". A name can take different forms - the Standard says:A name is a use of an identifier (2.11), operator-function-id (13.5), conversion-function-id (12.3.2), or template-id (14.2) that denotes an entity or label (6.6.4, 6.1)An identifier is just a plain sequence of characters / digits, while the next two are the operator + and operator type form. The last form is template-name <argument list>. All these are names, and by conventional use in the Standard, a name can also include qualifiers that say what namespace or class a name should be looked up in.A value dependent expression 1 + N is not a name, but N is. The subset of all dependent constructs that are names is called dependent name. Function names, however, may have different meaning in different instantiations of a template, but unfortunately are not caught by this general rule. Dependent function namesNot primarily a concern of this article, but still worth mentioning: Function names are an exception that are handled separately. An identifier function name is dependent not by itself, but by the type dependent argument expressions used in a call. In the example f((T)0), f is a dependent name. In the Standard, this is specified at (14.6.2/1).Additional notes and examplesIn enough cases we need both of typename and template. Your code should look like the followingtemplate <typename T, typename Tail>struct UnionNode : public Tail {    // ...    template<typename U> struct inUnion {        typedef typename Tail::template inUnion<U> dummy;    };    // ...};The keyword template doesn't always have to appear in the last part of a name. It can appear in the middle before a class name that's used as a scope, like in the following exampletypename t::template iterator<int>::value_type v;In some cases, the keywords are forbidden, as detailed belowOn the name of a dependent base class you are not allowed to write typename. It's assumed that the name given is a class type name. This is true for both names in the base-class list and the constructor initializer list: template <typename T> struct derive_from_Has_type : /* typename */ SomeBase<T>::type  { };In using-declarations it's not possible to use template after the last ::, and the C++ committee said not to work on a solution.  template <typename T> struct derive_from_Has_type : SomeBase<T> {    using SomeBase<T>::template type; // error    using typename SomeBase<T>::type; // typename *is* allowed };"
"data_i","edited Apr 19 '20 at 11:17","
        Which characters are valid in CSS class names/selectors?
    ","What characters/symbols are allowed within the CSS class selectors?I know that the following characters are invalid, but what characters are valid?~ ! @ $ % ^ & * ( ) + = , . / ' ; : "" ? > < [ ] \ { } | ` #","You can check directly at the CSS grammar.Basically1, a name must begin with an underscore (_), a hyphen (-), or a letter(a–z), followed by any number of hyphens, underscores, letters, or numbers. There is a catch: if the first character is a hyphen, the second character must2 be a  letter or underscore, and the name must be at least 2 characters long.-?[_a-zA-Z]+[_a-zA-Z0-9-]*In short, the previous rule translates to the following, extracted from the W3C spec.:In CSS, identifiers (including element names, classes, and IDs inselectors) can contain only the characters [a-z0-9] and ISO 10646characters U+00A0 and higher, plus the hyphen (-) and the underscore(_); they cannot start with a digit, or a hyphen followed by a digit.Identifiers can also contain escaped characters and any ISO 10646character as a numeric code (see next item). For instance, theidentifier ""B&W?"" may be written as ""B&W?"" or ""B\26 W\3F"".Identifiers beginning with a hyphen or underscore are typically reserved for browser-specific extensions, as in -moz-opacity.1 It's all made a bit more complicated by the inclusion of escaped unicode characters (that no one really uses).2 Note that, according to the grammar I linked, a rule starting with TWO hyphens, e.g. --indent1, is invalid.  However, I'm pretty sure I've seen this in practice."
"data_i","asked Sep 25 '08 at 13:26","
        How can I get jQuery to perform a synchronous, rather than asynchronous, Ajax request?
    ","I have a JavaScript widget which provides standard extension points. One of them is the beforecreate function. It should return false to prevent an item from being created. I've added an Ajax call into this function using jQuery:beforecreate: function (node, targetNode, type, to) {  jQuery.get('http://example.com/catalog/create/' + targetNode.id + '?name=' + encode(to.inp[0].value),  function (result) {    if (result.isOk == false)         alert(result.message);  });}But I want to prevent my widget from creating the item, so I should return false in the mother-function, not in the callback. Is there a way to perform a synchronous AJAX request using jQuery or any other in-browser API?","From the jQuery documentation: you specify the asynchronous option to be false to get a synchronous Ajax request. Then your callback can set some data before your mother function proceeds.Here's what your code would look like if changed as suggested:beforecreate: function (node, targetNode, type, to) {    jQuery.ajax({        url: 'http://example.com/catalog/create/' + targetNode.id + '?name=' + encode(to.inp[0].value),        success: function (result) {            if (result.isOk == false) alert(result.message);        },        async: false    });}"
"data_i","edited Apr 09 '22 at 08:53","
        How can I do a line break (line continuation) in Python?
    ","Given:e = 'a' + 'b' + 'c' + 'd'How do I write the above in two lines?e = 'a' + 'b' +    'c' + 'd'","What is the line?  You can just have arguments on the next line without any problems:a = dostuff(blahblah1, blahblah2, blahblah3, blahblah4, blahblah5,             blahblah6, blahblah7)Otherwise you can do something like this:if (a == True and    b == False):or with explicit line break:if a == True and \   b == False:Check the style guide for more information.Using parentheses, your example can be written over multiple lines:a = ('1' + '2' + '3' +    '4' + '5')The same effect can be obtained using explicit line break:a = '1' + '2' + '3' + \    '4' + '5'Note that the style guide says that using the implicit continuation with parentheses is preferred, but in this particular case just adding parentheses around your expression is probably the wrong way to go."
"data_i","edited Apr 10 '22 at 10:46","
        How to copy a dictionary and only edit the copy
    ","I set dict2 = dict1. When I edit dict2, the original dict1 also changes. Why?>>> dict1 = {""key1"": ""value1"", ""key2"": ""value2""}>>> dict2 = dict1>>> dict2[""key2""] = ""WHY?!"">>> dict1{'key2': 'WHY?!', 'key1': 'value1'}","Python never implicitly copies objects. When you set dict2 = dict1, you are making them refer to the same exact dict object, so when you mutate it, all references to it keep referring to the object in its current state.If you want to copy the dict (which is rare), you have to do so explicitly withdict2 = dict(dict1)ordict2 = dict1.copy()"
"data_i","edited May 02 '22 at 09:11","
        How do I access the $scope variable in browser's console using AngularJS?
    ","I would like to access my $scope variable in Chrome's JavaScript console. How do I do that?I can neither see $scope nor the name of my module myapp in the console as variables.","Pick an element in the HTML panel of the developer tools and type this in the console:angular.element($0).scope()In WebKit and Firefox, $0 is a reference to the selected DOM node in the elements tab, so by doing this you get the selected DOM node scope printed out in the console.You can also target the scope by element ID, like so:angular.element(document.getElementById('yourElementId')).scope()Addons/ExtensionsThere are some very useful Chrome extensions that you might want to check out:Batarang. This has been around for a while.ng-inspector. This is the newest one, and as the name suggests, it allows you to inspect your application's scopes.Playing with jsFiddleWhen working with jsfiddle you can open the fiddle in show mode by adding /show at the end of the URL. When running like this you have access to the angular global. You can try it here:http://jsfiddle.net/jaimem/Yatbt/showjQuery LiteIf you load jQuery before AngularJS, angular.element can be passed a jQuery selector. So you could inspect the scope of a controller withangular.element('[ng-controller=ctrl]').scope()Of a button angular.element('button:eq(1)').scope()... and so on.You might actually want to use a global function to make it easier:window.SC = function(selector){    return angular.element(selector).scope();};Now you could do thisSC('button:eq(10)')SC('button:eq(10)').row   // -> value of scope.rowCheck here: http://jsfiddle.net/jaimem/DvRaR/1/show/"
"data_i","edited Apr 19 '20 at 11:13","
        'Must Override a Superclass Method' Errors after importing a project into Eclipse
    ","Anytime I have to re-import my projects into Eclipse (if I reinstalled Eclipse, or changed the location of the projects), almost all of my overridden methods are not formatted correctly, causing the error:The method must override a superclass methodIt may be noteworthy to mention this is with Android projects for whatever reason, the method argument values are not always populated, so I have to manually populate them myself. For instance:list.setOnCreateContextMenuListener(new OnCreateContextMenuListener() {    //These arguments have their correct names    public void onCreateContextMenu(ContextMenu menu, View v,                                     ContextMenuInfo menuInfo) {                     }});will be initially populated like this:list.setOnCreateContextMenuListener(new OnCreateContextMenuListener() {    //This methods arguments were not automatically provided        public void onCreateContextMenu(ContextMenu arg1, View arg2,                                    ContextMenuInfo arg3) {    }});The odd thing is, if I remove my code, and have Eclipse automatically recreate the method, it uses the same argument names I already had, so I don't really know where the problem is, other then it auto-formatting the method for me.This becomes quite a pain having to manually recreate ALL my overridden methods by hand. If anyone can explain why this happens or how to fix it. I would be very happy.Maybe it is due to the way I am formatting the methods, which are inside an argument of another method?","Eclipse is defaulting to Java 1.5 and you have classes implementing interface methods (which in Java 1.6 can be annotated with @Override, but in Java 1.5 can only be applied to methods overriding a superclass method).Go to your project/IDE preferences and set the Java compiler level to 1.6 and also make sure you select JRE 1.6 to execute your program from Eclipse."
"data_i","edited Aug 27 '19 at 13:34","
        How to escape single quotes within single quoted strings
    ","Let's say, you have a Bash alias like:alias rxvt='urxvt'which works fine.However:alias rxvt='urxvt -fg '#111111' -bg '#111111''won't work, and neither will:alias rxvt='urxvt -fg \'#111111\' -bg \'#111111\''So how do you end up matching up opening and closing quotes inside a string once you have escaped quotes?alias rxvt='urxvt -fg'\''#111111'\'' -bg '\''#111111'\''seems ungainly although it would represent the same string if you're allowed to concatenate them like that.","If you really want to use single quotes in the outermost layer, remember that you can glue both kinds of quotation. Example: alias rxvt='urxvt -fg '""'""'#111111'""'""' -bg '""'""'#111111'""'"" #                     ^^^^^       ^^^^^     ^^^^^       ^^^^ #                     12345       12345     12345       1234Explanation of how '""'""' is interpreted as just ':' End first quotation which uses single quotes."" Start second quotation, using double-quotes.' Quoted character."" End second quotation, using double-quotes.' Start third quotation, using single quotes.If you do not place any whitespaces between (1) and (2), or between (4) and (5), the shell will interpret that string as a one long word."
"data_i","edited Aug 28 '19 at 09:16","
        How can you speed up Eclipse?
    ","How can you make the experience with Eclipse faster? For instance: I disable all the plugins I don't need (Mylyn, Subclipse, …).Instead of using a plugin for Mercurial, I configure TortoiseHG as an external tool.","The three most influential factors for Eclipse speed are:Using the latest version of Eclipse (2020-06 as on 26 June 2020)Note that David Balažic's comment (July 2014) contradicts that criteria which was working six years ago:The ""same"" workspace in Indigo (3.7.2) SR2 loads in 4 seconds, in Kepler SR2 (4.3.2) in 7 seconds and in Luna (4.4.0) in 10 seconds. All are Java EE bundles. Newer versions have more bundled plugins, but still the trend is obvious. (by ""same"" workspace I mean: same (additionally installed) plugins used, same projects checked out from version control).Launching it with the latest JDK (Java 14 at the time of writing, which does not prevent you to compile in your Eclipse project with any other JDK you want: 1.4.2, 1.5, 1.6 older...)  -vm jdk1.6.0_10\jre\bin\client\jvm.dllConfiguring the eclipse.ini (see this question for a complete eclipse.ini)  -Xms512m  -Xmx4096m  [...]The Xmx argument is the amount of memory Eclipse will get (in simple terms). With -Xmx4g, it gets 4 GB of RAM, etc.Note:Referring to the jvm.dll has advantages:Splash screen coming up sooner.Eclipse.exe in the process list instead of java.exe.Firewalls: Eclipse wants access to the Internet instead of Java.Window management branding issues, especially on Windows and Mac.Dec. 2020, Udo conforms in the commentsFrom version 4.8 (Photon) an up there was a steady speed gain after each version.The main platform was optimized every release to load faster, enable more features for the dark theme and to add more features for newer Java versions for the Java development tools.Especially with-in the last 3 versions the startup time was increased a lot.  There should be a significant increase in start-up time with the newest version of Eclipse 2020-12.In my experience it started a lot faster with each new version.But: There are still plug-ins which do not follow the new way of using the Eclipse API and are therefore still slow to start.Since the change to Java 11 as the minimum runtime version starting from Eclipse version 2020-09 at least the core system uses the newer features of the JVM. It is up to the providers of the other plug-ins to upgrade to newer APIs and to use the full power of modern CPUs (e.g. concurrent programming model)."
"data_i","edited Apr 19 '20 at 11:23","
        Get the name of an object's type
    ","Is there a JavaScript equivalent of Java's class.getName()?","Is there a JavaScript equivalent of Java's class.getName()?No.ES2015 Update: the name of class Foo {} is Foo.name.  The name of thing's class, regardless of thing's type, is thing.constructor.name. Builtin constructors in an ES2015 environment have the correct name property; for instance (2).constructor.name is ""Number"".But here are various hacks that all fall down in one way or another:Here is a hack that will do what you need - be aware that it modifies the Object's prototype, something people frown upon (usually for good reason)Object.prototype.getName = function() {    var funcNameRegex = /function (.{1,})\(/;   var results = (funcNameRegex).exec((this).constructor.toString());   return (results && results.length > 1) ? results[1] : """";};Now, all of your objects will have the function, getName(), that will return the name of the constructor as a string. I have tested this in FF3 and IE7, I can't speak for other implementations.If you don't want to do that, here is a discussion on the various ways of determining types in JavaScript...I recently updated this to be a bit more exhaustive, though it is hardly that. Corrections welcome...Using the constructor property...Every object has a value for its constructor property, but depending on how that object was constructed as well as what you want to do with that value, it may or may not be useful.Generally speaking, you can use the constructor property to test the type of the object like so:var myArray = [1,2,3];(myArray.constructor == Array); // trueSo, that works well enough for most needs. That said...CaveatsWill not work AT ALL in many casesThis pattern, though broken, is quite common:function Thingy() {}Thingy.prototype = {    method1: function() {    },    method2: function() {    }};Objects constructed via new Thingy will have a constructor property that points to Object, not Thingy. So we fall right at the outset; you simply cannot trust constructor in a codebase that you don't control.Multiple InheritanceAn example where it isn't as obvious is using multiple inheritance:function a() { this.foo = 1;}function b() { this.bar = 2; }b.prototype = new a(); // b inherits from aThings now don't work as you might expect them to:var f = new b(); // instantiate a new object with the b constructor(f.constructor == b); // false(f.constructor == a); // trueSo, you might get unexpected results if the object your testing has a different object set as its prototype. There are ways around this outside the scope of this discussion.There are other uses for the constructor property, some of them interesting, others not so much; for now we will not delve into those uses since it isn't relevant to this discussion.Will not work cross-frame and cross-windowUsing .constructor for type checking will break when you want to check the type of objects coming from different window objects, say that of an iframe or a popup window. This is because there's a different version of each core type constructor in each `window', i.e.iframe.contentWindow.Array === Array // falseUsing the instanceof operator...The instanceof operator is a clean way of testing object type as well, but has its own potential issues, just like the constructor property.var myArray = [1,2,3];(myArray instanceof Array); // true(myArray instanceof Object); // trueBut instanceof fails to work for literal values (because literals are not Objects)3 instanceof Number // false'abc' instanceof String // falsetrue instanceof Boolean // falseThe literals need to be wrapped in an Object in order for instanceof to work, for examplenew Number(3) instanceof Number // trueThe .constructor check works fine for literals because the . method invocation implicitly wraps the literals in their respective object type3..constructor === Number // true'abc'.constructor === String // truetrue.constructor === Boolean // trueWhy two dots for the 3? Because Javascript interprets the first dot as a decimal point ;)Will not work cross-frame and cross-windowinstanceof also will not work across different windows, for the same reason as the constructor property check.Using the name property of the constructor property...Does not work AT ALL in many casesAgain, see above; it's quite common for constructor to be utterly and completely wrong and useless.Does NOT work in <IE9Using myObjectInstance.constructor.name will give you a string containing the name of the constructor function used, but is subject to the caveats about the constructor property that were mentioned earlier.For IE9 and above, you can monkey-patch in support:if (Function.prototype.name === undefined && Object.defineProperty !== undefined) {    Object.defineProperty(Function.prototype, 'name', {        get: function() {            var funcNameRegex = /function\s+([^\s(]+)\s*\(/;            var results = (funcNameRegex).exec((this).toString());            return (results && results.length > 1) ? results[1] : """";        },        set: function(value) {}    });}Updated version from the article in question. This was added 3 months after the article was published, this is the recommended version to use by the article's author Matthew Scharley. This change was inspired by comments pointing out potential pitfalls in the previous code.if (Function.prototype.name === undefined && Object.defineProperty !== undefined) {    Object.defineProperty(Function.prototype, 'name', {        get: function() {            var funcNameRegex = /function\s([^(]{1,})\(/;            var results = (funcNameRegex).exec((this).toString());            return (results && results.length > 1) ? results[1].trim() : """";        },        set: function(value) {}    });}Using Object.prototype.toStringIt turns out, as this post details, you can use Object.prototype.toString - the low level and generic implementation of toString - to get the type for all built-in typesObject.prototype.toString.call('abc') // [object String]Object.prototype.toString.call(/abc/) // [object RegExp]Object.prototype.toString.call([1,2,3]) // [object Array]One could write a short helper function such asfunction type(obj){    return Object.prototype.toString.call(obj).slice(8, -1);}to remove the cruft and get at just the type nametype('abc') // StringHowever, it will return Object for all user-defined types.Caveats for all...All of these are subject to one potential problem, and that is the question of how the object in question was constructed. Here are various ways of building objects and the values that the different methods of type checking will return:// using a named function:function Foo() { this.a = 1; }var obj = new Foo();(obj instanceof Object);          // true(obj instanceof Foo);             // true(obj.constructor == Foo);         // true(obj.constructor.name == ""Foo"");  // true// let's add some prototypical inheritancefunction Bar() { this.b = 2; }Foo.prototype = new Bar();obj = new Foo();(obj instanceof Object);          // true(obj instanceof Foo);             // true(obj.constructor == Foo);         // false(obj.constructor.name == ""Foo"");  // false// using an anonymous function:obj = new (function() { this.a = 1; })();(obj instanceof Object);              // true(obj.constructor == obj.constructor); // true(obj.constructor.name == """");         // true// using an anonymous function assigned to a variablevar Foo = function() { this.a = 1; };obj = new Foo();(obj instanceof Object);      // true(obj instanceof Foo);         // true(obj.constructor == Foo);     // true(obj.constructor.name == """"); // true// using object literal syntaxobj = { foo : 1 };(obj instanceof Object);            // true(obj.constructor == Object);        // true(obj.constructor.name == ""Object""); // trueWhile not all permutations are present in this set of examples, hopefully there are enough to provide you with an idea about how messy things might get depending on your needs. Don't assume anything, if you don't understand exactly what you are after, you may end up with code breaking where you don't expect it to because of a lack of grokking the subtleties.NOTE:Discussion of the typeof operator may appear to be a glaring omission, but it really isn't useful in helping to identify whether an object is a given type, since it is very simplistic. Understanding where typeof is useful is important, but I don't currently feel that it is terribly relevant to this discussion. My mind is open to change though. :)"
"data_i","edited Apr 09 '22 at 08:55","
        How do I create a constant in Python?
    ","How do I declare a constant in Python?In Java, we do:public static final String CONST_NAME = ""Name"";","You cannot declare a variable or value as constant in Python.To indicate to programmers that a variable is a constant, one usually writes it in upper case:CONST_NAME = ""Name""To raise exceptions when constants are changed, see Constants in Python by Alex Martelli. Note that this is not commonly used in practice.As of Python 3.8, there's a typing.Final variable annotation that will tell static type checkers (like mypy) that your variable shouldn't be reassigned. This is the closest equivalent to Java's final. However, it does not actually prevent reassignment:from typing import Finala: Final[int] = 1# Executes fine, but mypy will report an error if you run mypy on this:a = 2"
"data_i","edited Apr 19 '20 at 11:31","
        How can I merge two commits into one if I already started rebase?
    ","I am trying to merge 2 commits into 1, so I followed “squashing commits with rebase” from git ready.I rangit rebase --interactive HEAD~2In the resulting editor, I change pick to squash and then save-quit, but the rebase fails with the errorCannot 'squash' without a previous commitNow that my work tree has reached this state, I’m having trouble recovering.   The command git rebase --interactive HEAD~2 fails with:Interactive rebase already startedand git rebase --continue fails withCannot 'squash' without a previous commit","SummaryThe error messageCannot 'squash' without a previous commitmeans you likely attempted to “squash downward.” Git always squashes a newer commit into an older commit or “upward” as viewed on the interactive rebase todo list, that is into a commit on a previous line. Changing the command on your todo list’s very first line to squash will always produce this error as there is nothing for the first commit to squash into.The FixFirst get back to where you started with$ git rebase --abortSay your history is$ git log --pretty=onelinea931ac7c808e2471b22b5bd20f0cad046b1c5d0d cb76d157d507e819d7511132bdb5a80dd421d854f bdf239176e1a2ffac927d8b496ea00d5488481db5 aThat is, a was the first commit, then b, and finally c. After committing c we decide to squash b and c together:(Note: Running git log pipes its output into a pager, less by default on most platforms. To quit the pager and return to your command prompt, press the q key.)Running git rebase --interactive HEAD~2 gives you an editor withpick b76d157 bpick a931ac7 c# Rebase df23917..a931ac7 onto df23917## Commands:#  p, pick = use commit#  r, reword = use commit, but edit the commit message#  e, edit = use commit, but stop for amending#  s, squash = use commit, but meld into previous commit#  f, fixup = like ""squash"", but discard this commit's log message## If you remove a line here THAT COMMIT WILL BE LOST.# However, if you remove everything, the rebase will be aborted.#(Notice that this todo list is in the reverse order as compared with the output of git log.)Changing b’s pick to squash will result in the error you saw, but if instead you squash c into b (newer commit into the older or “squashing upward”) by changing the todo list topick   b76d157 bsquash a931ac7 cand save-quitting your editor, you'll get another editor whose contents are# This is a combination of 2 commits.# The first commit's message is:b# This is the 2nd commit message:cWhen you save and quit, the contents of the edited file become commit message of the new combined commit:$ git log --pretty=oneline18fd73d3ce748f2a58d1b566c03dd9dafe0b6b4f b and cdf239176e1a2ffac927d8b496ea00d5488481db5 aNote About Rewriting HistoryInteractive rebase rewrites history. Attempting to push to a remote that contains the old history will fail because it is not a fast-forward.If the branch you rebased is a topic or feature branch in which you are working by yourself, no big deal. Pushing to another repository will require the --force option, or alternatively you may be able, depending on the remote repository’s permissions, to first delete the old branch and then push the rebased version. Examples of those commands that will potentially destroy work is outside the scope of this answer.Rewriting already-published history on a branch in which you are working with other people without very good reason such as leaking a password or other sensitive details forces work onto your collaborators and is antisocial and will annoy other developers. The “Recovering From an Upstream Rebase” section in the git rebase documentation explains, with added emphasis.Rebasing (or any other form of rewriting) a branch that others have based work on is a bad idea: anyone downstream of it is forced to manually fix their history. This section explains how to do the fix from the downstream’s point of view. The real fix, however, would be to avoid rebasing the upstream in the first place. …"
"data_i","edited Aug 07 '15 at 13:40","
        performSelector may cause a leak because its selector is unknown
    ","I'm getting the following warning by the ARC compiler:""performSelector may cause a leak because its selector is unknown"".Here's what I'm doing:[_controller performSelector:NSSelectorFromString(@""someMethod"")];Why do I get this warning? I understand the compiler can't check if the selector exists or not, but why would that cause a leak?  And how can I change my code so that I don't get this warning anymore?","SolutionThe compiler is warning about this for a reason. It's very rare that this warning should simply be ignored, and it's easy to work around. Here's how:if (!_controller) { return; }SEL selector = NSSelectorFromString(@""someMethod"");IMP imp = [_controller methodForSelector:selector];void (*func)(id, SEL) = (void *)imp;func(_controller, selector);Or more tersely (though hard to read & without the guard):SEL selector = NSSelectorFromString(@""someMethod"");((void (*)(id, SEL))[_controller methodForSelector:selector])(_controller, selector);ExplanationWhat's going on here is you're asking the controller for the C function pointer for the method corresponding to the controller. All NSObjects respond to methodForSelector:, but you can also use class_getMethodImplementation in the Objective-C runtime (useful if you only have a protocol reference, like id<SomeProto>). These function pointers are called IMPs, and are simple typedefed function pointers (id (*IMP)(id, SEL, ...))1.  This may be close to the actual method signature of the method, but will not always match exactly.Once you have the IMP, you need to cast it to a function pointer that includes all of the details that ARC needs (including the two implicit hidden arguments self and _cmd of every Objective-C method call). This is handled in the third line (the (void *) on the right hand side simply tells the compiler that you know what you're doing and not to generate a warning since the pointer types don't match).Finally, you call the function pointer2.Complex ExampleWhen the selector takes arguments or returns a value, you'll have to change things a bit:SEL selector = NSSelectorFromString(@""processRegion:ofView:"");IMP imp = [_controller methodForSelector:selector];CGRect (*func)(id, SEL, CGRect, UIView *) = (void *)imp;CGRect result = _controller ?  func(_controller, selector, someRect, someView) : CGRectZero;Reasoning for WarningThe reason for this warning is that with ARC, the runtime needs to know what to do with the result of the method you're calling. The result could be anything: void, int, char, NSString *, id, etc. ARC normally gets this information from the header of the object type you're working with.3There are really only 4 things that ARC would consider for the return value:4Ignore non-object types (void, int, etc)Retain object value, then release when it is no longer used (standard assumption)Release new object values when no longer used (methods in the init/ copy family or attributed with ns_returns_retained)Do nothing & assume returned object value will be valid in local scope (until inner most release pool is drained, attributed with ns_returns_autoreleased)The call to methodForSelector: assumes that the return value of the method it's calling is an object, but does not retain/release it. So you could end up creating a leak if your object is supposed to be released as in #3 above (that is, the method you're calling returns a new object).For selectors you're trying to call that return void or other non-objects, you could enable compiler features to ignore the warning, but it may be dangerous. I've seen Clang go through a few iterations of how it handles return values that aren't assigned to local variables. There's no reason that with ARC enabled that it can't retain and release the object value that's returned from methodForSelector: even though you don't want to use it. From the compiler's perspective, it is an object after all. That means that if the method you're calling, someMethod, is returning a non object (including void), you could end up with a garbage pointer value being retained/released and crash.Additional ArgumentsOne consideration is that this is the same warning will occur with performSelector:withObject: and you could run into similar problems with not declaring how that method consumes parameters. ARC allows for declaring consumed parameters, and if the method consumes the parameter, you'll probably eventually send a message to a zombie and crash. There are ways to work around this with bridged casting, but really it'd be better to simply use the IMP and function pointer methodology above. Since consumed parameters are rarely an issue, this isn't likely to come up.Static SelectorsInterestingly, the compiler will not complain about selectors declared statically:[_controller performSelector:@selector(someMethod)];The reason for this is because the compiler actually is able to record all of the information about the selector and the object during compilation. It doesn't need to make any assumptions about anything. (I checked this a year a so ago by looking at the source, but don't have a reference right now.)SuppressionIn trying to think of a situation where suppression of this warning would be necessary and good code design, I'm coming up blank. Someone please share if they have had an experience where silencing this warning was necessary (and the above doesn't handle things properly).MoreIt's possible to build up an NSMethodInvocation to handle this as well, but doing so requires a lot more typing and is also slower, so there's little reason to do it.HistoryWhen the performSelector: family of methods was first added to Objective-C, ARC did not exist. While creating ARC, Apple decided that a warning should be generated for these methods as a way of guiding developers toward using other means to explicitly define how memory should be handled when sending arbitrary messages via a named selector. In Objective-C, developers are able to do this by using C style casts on raw function pointers.With the introduction of Swift, Apple has documented the performSelector: family of methods as ""inherently unsafe"" and they are not available to Swift.Over time, we have seen this progression:Early versions of Objective-C allow performSelector: (manual memory management)Objective-C with ARC warns for use of performSelector:Swift does not have access to performSelector: and documents these methods as ""inherently unsafe""The idea of sending messages based on a named selector is not, however, an ""inherently unsafe"" feature. This idea has been used successfully for a long time in Objective-C as well as many other programming languages.1 All Objective-C methods have two hidden arguments, self and _cmd that are implicitly added when you call a method.2 Calling a NULL function is not safe in C. The guard used to check for the presence of the controller ensures that we have an object. We therefore know we'll get an IMP from methodForSelector: (though it may be _objc_msgForward, entry into the message forwarding system). Basically, with the guard in place, we know we have a function to call.3 Actually, it's possible for it to get the wrong info if declare you objects as id and you're not importing all headers. You could end up with crashes in code that the compiler thinks is fine. This is very rare, but could happen. Usually you'll just get a warning that it doesn't know which of two method signatures to choose from.4 See the ARC reference on retained return values and unretained return values for more details."
"data_i","edited Jul 07 '09 at 04:09","
        git: undo all working dir changes including new files
    ","How to delete all changes from working directory including new untracked files. I know that git checkout -f does that, but it doesn't delete new untracked files created since last commit.Does anybody have an idea how to do that?","git reset --hard # removes staged and working directory changes## !! be very careful with these !!## you may end up deleting what you don't want to## read comments and manual.git clean -f -d # remove untrackedgit clean -f -x -d # CAUTION: as above but removes ignored files like config.git clean -fxd :/ # CAUTION: as above, but cleans untracked and ignored files through the entire repo (without :/, the operation affects only the current directory)To see what will be deleted before-hand, without actually deleting it, use the -n flag (this is basically a test-run). When you are ready to actually delete, then remove the -n flag:git clean -nfd"
"data_i","edited Mar 29 '22 at 12:39","
        Correct way to write line to file?
    ","How do I write a line to a file in modern Python? I heard that this is deprecated:print >>f, ""hi there""Also, does ""\n"" work on all platforms, or should I use ""\r\n"" on Windows?","This should be as simple as:with open('somefile.txt', 'a') as the_file:    the_file.write('Hello\n')From The Documentation:Do not use os.linesep as a line terminator when writing files opened in text mode (the default); use a single '\n' instead, on all platforms.Some useful reading:The with statementopen()'a' is for append, or use'w' to write with truncationos (particularly os.linesep)"
"data_i","edited Jun 20 '22 at 09:29","
        How can I grep recursively, but only in files with certain extensions?
    ","I'm working on a script to grep certain directories:{ grep -r -i CP_Image ~/path1/;grep -r -i CP_Image ~/path2/;grep -r -i CP_Image ~/path3/;grep -r -i CP_Image ~/path4/;grep -r -i CP_Image ~/path5/; }| mailx -s GREP email@domain.exampleHow can I limit results only to extensions .h and .cpp?","Just use the --include parameter, like this:grep -inr --include \*.h --include \*.cpp CP_Image ~/path[12345] | mailx -s GREP email@domain.exampleThat should do what you want.To take the explanation from HoldOffHunger's answer below:grep: command-r: recursively-i: ignore-case-n: each output line is preceded by its relative line number in the file--include \*.cpp: all *.cpp: C++ files (escape with \ just in case you have a directory with asterisks in the filenames)./: Start at current directory."
"data_i","edited Sep 29 '17 at 12:45","
        How to remove item from array by value?
    ","Is there a method to remove an item from a JavaScript array?Given an array:var ary = ['three', 'seven', 'eleven'];I would like to do something like:removeItem('seven', ary);I've looked into splice() but that only removes by the position number, whereas I need something to remove an item by its value.","You can use the indexOf method like this:var index = array.indexOf(item);if (index !== -1) {  array.splice(index, 1);}Note: You'll need to shim it for IE8 and belowvar array = [1,2,3,4]var item = 3var index = array.indexOf(item);array.splice(index, 1);console.log(array)"
"data_i","edited Oct 13 '19 at 03:06","
        Xcode - How to fix 'NSUnknownKeyException', reason: … this class is not key value coding-compliant for the key X"" error?
    ","I'm trying to link a UILabel with an IBOutlet created in my class.My application is crashing with the following error. What does this mean? How can I fix it?*** Terminating app due to uncaught exception 'NSUnknownKeyException', reason: '[<UIViewController 0x6e36ae0> setValue:forUndefinedKey:]: this class is not key value coding-compliant for the key XXX.'","You may have a bad connection in your xib.I've had this error many times. While TechZen's answer is absolutely right in this case, another common cause is when you change the name of a IBOutlet property in your .h/.m which you've already connected up to File's Owner in the nib.From your nib:Select the object in IB and go to the 'Connections Inspector'.Under 'Referencing Outlets' make sure that your object isn't still connected to the old property name... if it is, click the small 'x' to delete the reference and build again. Another common cause if you are using Storyboard, your UIButton might have more then one assignings (Solution is almost the same as for nib):Open your storyboard and right click the UIButtonYou will see that there is more than one assign/ref to this button.Remove one of the ""Main..."" greyed windows with the small ""x"":"
"data_i","edited Feb 16 '21 at 07:17","
        Enumerations on PHP
    ","I know that PHP doesn't yet have native Enumerations. But I have become accustomed to them from the Java world. I would love to use enums as a way to give predefined values which IDEs' auto-completion features could understand.Constants do the trick, but there's the namespace collision problem and (or actually because) they're global. Arrays don't have the namespace problem, but they're too vague, they can be overwritten at runtime and IDEs rarely know how to autofill their keys without additional static analysis annotations or attributes.Are there any solutions/workarounds you commonly use? Does anyone recall whether the PHP guys have had any thoughts or decisions around enumerations?","Depending upon use case, I would normally use something simple like the following:abstract class DaysOfWeek{    const Sunday = 0;    const Monday = 1;    // etc.}$today = DaysOfWeek::Sunday;However, other use cases may require more validation of constants and values. Based on the comments below about reflection, and a few other notes, here's an expanded example which may better serve a much wider range of cases:abstract class BasicEnum {    private static $constCacheArray = NULL;    private static function getConstants() {        if (self::$constCacheArray == NULL) {            self::$constCacheArray = [];        }        $calledClass = get_called_class();        if (!array_key_exists($calledClass, self::$constCacheArray)) {            $reflect = new ReflectionClass($calledClass);            self::$constCacheArray[$calledClass] = $reflect->getConstants();        }        return self::$constCacheArray[$calledClass];    }    public static function isValidName($name, $strict = false) {        $constants = self::getConstants();        if ($strict) {            return array_key_exists($name, $constants);        }        $keys = array_map('strtolower', array_keys($constants));        return in_array(strtolower($name), $keys);    }    public static function isValidValue($value, $strict = true) {        $values = array_values(self::getConstants());        return in_array($value, $values, $strict);    }}By creating a simple enum class that extends BasicEnum, you now have the ability to use methods thusly for simple input validation:abstract class DaysOfWeek extends BasicEnum {    const Sunday = 0;    const Monday = 1;    const Tuesday = 2;    const Wednesday = 3;    const Thursday = 4;    const Friday = 5;    const Saturday = 6;}DaysOfWeek::isValidName('Humpday');                  // falseDaysOfWeek::isValidName('Monday');                   // trueDaysOfWeek::isValidName('monday');                   // trueDaysOfWeek::isValidName('monday', $strict = true);   // falseDaysOfWeek::isValidName(0);                          // falseDaysOfWeek::isValidValue(0);                         // trueDaysOfWeek::isValidValue(5);                         // trueDaysOfWeek::isValidValue(7);                         // falseDaysOfWeek::isValidValue('Friday');                  // falseAs a side note, any time I use reflection at least once on a static/const class where the data won't change (such as in an enum), I cache the results of those reflection calls, since using fresh reflection objects each time will eventually have a noticeable performance impact (Stored in an assocciative array for multiple enums).Now that most people have finally upgraded to at least 5.3, and SplEnum is available, that is certainly a viable option as well--as long as you don't mind the traditionally unintuitive notion of having actual enum instantiations throughout your codebase. In the above example, BasicEnum and DaysOfWeek cannot be instantiated at all, nor should they be."
"data_i","edited Apr 19 '20 at 13:43","
        Difference between JOIN and INNER JOIN
    ","Both these joins will give me the same results:SELECT * FROM table JOIN otherTable ON table.ID = otherTable.FKvsSELECT * FROM table INNER JOIN otherTable ON table.ID = otherTable.FKIs there any difference between the statements in performance or otherwise? Does it differ between different SQL implementations? ","They are functionally equivalent, but INNER JOIN can be a bit clearer to read, especially if the query has other join types (i.e. LEFT or RIGHT or CROSS) included in it."
"data_i","edited Jul 05 '21 at 06:52","
        How to get the current working directory in Java?
    ","I want to access my current working directory using Java.My code: String currentPath = new java.io.File(""."").getCanonicalPath(); System.out.println(""Current dir:"" + currentPath); String currentDir = System.getProperty(""user.dir""); System.out.println(""Current dir using System:"" + currentDir);Output:Current dir: C:\WINDOWS\system32Current dir using System: C:\WINDOWS\system32My output is not correct because the C drive is not my current directory.How to get the current directory?","Code :public class JavaApplication {  public static void main(String[] args) {    System.out.println(""Working Directory = "" + System.getProperty(""user.dir""));  }}This will print the absolute path of the current directory from where your application was initialized.Explanation:From the documentation:java.io package resolve relative pathnames using current user directory. The current directory is represented as system property, that is, user.dir and is the directory from where the JVM was invoked."
"data_i","edited Oct 22 '21 at 12:15","
        Get a list from Pandas DataFrame column headers
    ","I want to get a list of the column headers from a Pandas DataFrame.  The DataFrame will come from user input, so I won't know how many columns there will be or what they will be called.For example, if I'm given a DataFrame like this:>>> my_dataframe    y  gdp  cap0   1    2    51   2    3    92   8    7    23   3    4    74   6    7    75   4    8    36   8    2    87   9    9   108   6    6    49  10   10    7I would get a list like this:>>> header_list['y', 'gdp', 'cap']","You can get the values as a list by doing:list(my_dataframe.columns.values)Also you can simply use (as shown in Ed Chum's answer):list(my_dataframe)"
"data_i","edited Feb 02 '19 at 04:22","
        Access-Control-Allow-Origin Multiple Origin Domains?
    ","Is there a way to allow multiple cross-domains using the Access-Control-Allow-Origin header?I'm aware of the *, but it is too open. I really want to allow just a couple domains.As an example, something like this:Access-Control-Allow-Origin: http://domain1.example, http://domain2.exampleI have tried the above code but it does not seem to work in Firefox.Is it possible to specify multiple domains or am I stuck with just one?","Sounds like the recommended way to do it is to have your server read the Origin header from the client, compare that to the list of domains you would like to allow, and if it matches, echo the value of the Origin header back to the client as the Access-Control-Allow-Origin header in the response.With .htaccess you can do it like this:# ----------------------------------------------------------------------# Allow loading of external fonts# ----------------------------------------------------------------------<FilesMatch ""\.(ttf|otf|eot|woff|woff2)$"">    <IfModule mod_headers.c>        SetEnvIf Origin ""http(s)?://(www\.)?(google.com|staging.google.com|development.google.com|otherdomain.example|dev02.otherdomain.example)$"" AccessControlAllowOrigin=$0        Header add Access-Control-Allow-Origin %{AccessControlAllowOrigin}e env=AccessControlAllowOrigin        Header merge Vary Origin    </IfModule></FilesMatch>"
"data_i","edited Apr 09 '22 at 09:21","
        Why does comparing strings using either '==' or 'is' sometimes produce a different result?
    ","Two string variables are set to the same value. s1 == s2 always returns True, but s1 is s2 sometimes returns False.If I open my Python interpreter and do the same is comparison, it succeeds:>>> s1 = 'text'>>> s2 = 'text'>>> s1 is s2TrueWhy is this?","is is identity testing, == is equality testing. what happens in your code would be emulated in the interpreter like this:>>> a = 'pub'>>> b = ''.join(['p', 'u', 'b'])>>> a == bTrue>>> a is bFalseso, no wonder they're not the same, right?In other words: a is b is the equivalent of id(a) == id(b)"
"data_i","edited Nov 24 '14 at 23:47","
        Difference Between Select and SelectMany
    ","I've been searching the difference between Select and SelectMany but I haven't been able to find a suitable answer. I need to learn the difference when using LINQ To SQL but all I've found are standard array examples. Can someone provide a LINQ To SQL example?","SelectMany flattens queries that return lists of lists. For examplepublic class PhoneNumber{    public string Number { get; set; }}public class Person{    public IEnumerable<PhoneNumber> PhoneNumbers { get; set; }    public string Name { get; set; }}IEnumerable<Person> people = new List<Person>();// Select gets a list of lists of phone numbersIEnumerable<IEnumerable<PhoneNumber>> phoneLists = people.Select(p => p.PhoneNumbers);// SelectMany flattens it to just a list of phone numbers.IEnumerable<PhoneNumber> phoneNumbers = people.SelectMany(p => p.PhoneNumbers);// And to include data from the parent in the result: // pass an expression to the second parameter (resultSelector) in the overload:var directory = people   .SelectMany(p => p.PhoneNumbers,               (parent, child) => new { parent.Name, child.Number });Live Demo on .NET Fiddle"
"data_i","edited Jun 12 '20 at 10:05","
        Remove element by id
    ","When removing an element with standard JavaScript, you must go to its parent first:var element = document.getElementById(""element-id"");element.parentNode.removeChild(element);Having to go to the parent node first seems a bit odd to me, is there a reason JavaScript works like this?","I know that augmenting native DOM functions isn't always the best or most popular solution, but this works fine for modern browsers.Element.prototype.remove = function() {    this.parentElement.removeChild(this);}NodeList.prototype.remove = HTMLCollection.prototype.remove = function() {    for(var i = this.length - 1; i >= 0; i--) {        if(this[i] && this[i].parentElement) {            this[i].parentElement.removeChild(this[i]);        }    }}And then you can remove elements like this  document.getElementById(""my-element"").remove();ordocument.getElementsByClassName(""my-elements"").remove();Note: this solution doesn't work for IE 7 and below. For more info about extending the DOM read this article.EDIT: Reviewing my answer in 2019, node.remove() has come to the rescue and can be used as follows (without the polyfill above):document.getElementById(""my-element"").remove();or[...document.getElementsByClassName(""my-elements"")].map(n => n && n.remove());These functions are available in all modern browsers (not IE). Read more on MDN."
"data_i","edited Sep 05 '22 at 11:10","
        How do I reverse a list or loop over it backwards?
    ","How do I iterate over a list in reverse in Python?See also: How can I get a reversed copy of a list (avoid a separate statement when chaining a method after .reverse)?","To get a new reversed list, apply the reversed function and collect the items into a list:>>> xs = [0, 10, 20, 40]>>> list(reversed(xs))[40, 20, 10, 0]To iterate backwards through a list:>>> xs = [0, 10, 20, 40]>>> for x in reversed(xs):...     print(x)4020100"
"data_i","edited Jul 29 '21 at 15:36","
        How to rebase local branch onto remote master
    ","I have a cloned project from a master branch from remote repository remote_repo. I create a new branch and I commit to that branch. Other programmers pushed to remote_repo to the master branch.I now need to rebase my local branch RB onto remote_repo's master branch.How to do this? What commands to type to a terminal?","First fetch the new master from the upstream repository, then rebase your work branch on that:git fetch origin            # Updates origin/mastergit rebase origin/master    # Rebases current branch onto origin/masterUpdate: Please see Paul Draper's answer for a more concise way to do the same - recent Git versions provide a simpler way to do the equivalent of the above two commands."
"data_i","edited Oct 20 '19 at 13:04","
        Iterating through a Collection, avoiding ConcurrentModificationException when removing objects in a loop
    ","We all know you can't do the following because of ConcurrentModificationException:for (Object i : l) {    if (condition(i)) {        l.remove(i);    }}But this apparently works sometimes, but not always. Here's some specific code:public static void main(String[] args) {    Collection<Integer> l = new ArrayList<>();    for (int i = 0; i < 10; ++i) {        l.add(4);        l.add(5);        l.add(6);    }    for (int i : l) {        if (i == 5) {            l.remove(i);        }    }    System.out.println(l);}This, of course, results in:Exception in thread ""main"" java.util.ConcurrentModificationExceptionEven though multiple threads aren't doing it. Anyway.What's the best solution to this problem? How can I remove an item from the collection in a loop without throwing this exception?I'm also using an arbitrary Collection here, not necessarily an ArrayList, so you can't rely on get.","Iterator.remove() is safe, you can use it like this:List<String> list = new ArrayList<>();// This is a clever way to create the iterator and call iterator.hasNext() like// you would do in a while-loop. It would be the same as doing://     Iterator<String> iterator = list.iterator();//     while (iterator.hasNext()) {for (Iterator<String> iterator = list.iterator(); iterator.hasNext();) {    String string = iterator.next();    if (string.isEmpty()) {        // Remove the current element from the iterator and the list.        iterator.remove();    }}Note that Iterator.remove() is the only safe way to modify a collection during iteration; the behavior is unspecified if the underlying collection is modified in any other way while the iteration is in progress.Source: docs.oracle > The Collection InterfaceAnd similarly, if you have a ListIterator and want to add items, you can use ListIterator#add, for the same reason you can use Iterator#remove — it's designed to allow it.In your case you tried to remove from a list, but the same restriction applies if trying to put into a Map while iterating its content. "
"data_i","edited Apr 18 '18 at 11:50","
        Can't execute jar- file: ""no main manifest attribute""
    ","I have installed an application, when I try to run it (it's an executable jar) nothing happens. When I run it from the commandline with: java -jar ""app.jar""I get the following message:no main manifest attribute, in ""app.jar""Normally, if I had created the program myself, I would have added a main class attribute to the manifest file. But in this case, since the file is from an application, i cannot do that. I also tried extracting the jar to see if I could find the main class, but there are to many classes and none of them has the word ""main"" in it's name. There must be a way to fix this because the program runs fine on other systems.","First, it's kind of weird, to see you run java -jar ""app"" and not java -jar app.jarSecond, to make a jar executable... you need to jar a file called META-INF/MANIFEST.MFthe file itself should have (at least) this one liner:Main-Class: com.mypackage.MyClassWhere com.mypackage.MyClass is the class holding the public static void main(String[] args) entry point.Note that there are several ways to get this done either with the CLI, Maven, Ant or Gradle:For CLI, the following command will do: (tks @dvvrt)jar cmvf META-INF/MANIFEST.MF <new-jar-filename>.jar  <files to include>For Maven, something like the following snippet should do the trick. Note that this is only the plugin definition, not the full pom.xml:Latest doc on this plugin: see https://maven.apache.org/plugins/maven-jar-plugin/<build>  <plugins>    <plugin>      <!-- Build an executable JAR -->      <groupId>org.apache.maven.plugins</groupId>      <artifactId>maven-jar-plugin</artifactId>      <version>3.1.0</version>      <configuration>        <archive>          <manifest>            <addClasspath>true</addClasspath>            <classpathPrefix>lib/</classpathPrefix>            <mainClass>com.mypackage.MyClass</mainClass>          </manifest>        </archive>      </configuration>    </plugin>  </plugins></build>(Pick a <version> appropriate to your project.)For Ant, the snippet below should help:<jar destfile=""build/main/checksites.jar"">  <fileset dir=""build/main/classes""/>  <zipfileset includes=""**/*.class"" src=""lib/main/some.jar""/>  <manifest>    <attribute name=""Main-Class"" value=""com.acme.checksites.Main""/>  </manifest></jar>Credits Michael Niemand -For Gradle:plugins {    id 'java'}jar {    manifest {        attributes(                'Main-Class': 'com.mypackage.MyClass'        )    }}"
"data_i","edited Apr 09 '22 at 09:44","
        Display number with leading zeros
    ","How do I display a leading zero for all numbers with less than two digits?1    →  0110   →  10100  →  100","In Python 2 (and Python 3) you can do:number = 1print(""%02d"" % (number,))Basically % is like printf or sprintf (see docs).For Python 3.+, the same behavior can also be achieved with format:number = 1print(""{:02d}"".format(number))For Python 3.6+ the same behavior can be achieved with f-strings:number = 1print(f""{number:02d}"")"
"data_i","edited Apr 09 '22 at 09:53","
        Getting key with maximum value in dictionary?
    ","I have a dictionary where keys are strings, and values are integers.stats = {'a': 1, 'b': 3000, 'c': 0}How do I get the key with the maximum value? In this case, it is 'b'.Is there a nicer approach than using an intermediate list with reversed key-value tuples?inverse = [(value, key) for key, value in stats.items()]print(max(inverse)[1])","max(stats, key=stats.get)"
"data_i","edited Aug 20 '20 at 14:25","
        jQuery get specific option tag text
    ","All right, say I have this:<select id='list'>    <option value='1'>Option A</option>    <option value='2'>Option B</option>    <option value='3'>Option C</option></select>What would the selector look like if I wanted to get ""Option B"" when I have the value '2'?Please note that this is not asking how to get the selected text value, but just any one of them, whether selected or not, depending on the value attribute. I tried:$(""#list[value='2']"").text();But it is not working.","If you'd like to get the option with a value of 2, use$(""#list option[value='2']"").text();If you'd like to get whichever option is currently selected, use$(""#list option:selected"").text();"
"data_i","edited Oct 25 '18 at 17:30","
        Running shell command and capturing the output
    ","I want to write a function that will execute a shell command and return its output as a string, no matter, is it an error or success message. I just want to get the same result that I would have gotten with the command line.What would be a code example that would do such a thing?For example:def run_command(cmd):    # ??????print run_command('mysqladmin create test -uroot -pmysqladmin12')# Should output something like:# mysqladmin: CREATE DATABASE failed; error: 'Can't create database 'test'; database exists'","In all officially maintained versions of Python, the simplest approach is to use the subprocess.check_output function:>>> subprocess.check_output(['ls', '-l'])b'total 0\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\n'check_output runs a single program that takes only arguments as input.1 It returns the result exactly as printed to stdout. If you need to write input to stdin, skip ahead to the run or Popen sections. If you want to execute complex shell commands, see the note on shell=True at the end of this answer.The check_output function works in all officially maintained versions of Python. But for more recent versions, a more flexible approach is available.Modern versions of Python (3.5 or higher): runIf you're using Python 3.5+, and do not need backwards compatibility, the new run function is recommended by the official documentation for most tasks. It provides a very general, high-level API for the subprocess module. To capture the output of a program, pass the subprocess.PIPE flag to the stdout keyword argument. Then access the stdout attribute of the returned CompletedProcess object:>>> import subprocess>>> result = subprocess.run(['ls', '-l'], stdout=subprocess.PIPE)>>> result.stdoutb'total 0\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\n'The return value is a bytes object, so if you want a proper string, you'll need to decode it. Assuming the called process returns a UTF-8-encoded string:>>> result.stdout.decode('utf-8')'total 0\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\n'This can all be compressed to a one-liner if desired:>>> subprocess.run(['ls', '-l'], stdout=subprocess.PIPE).stdout.decode('utf-8')'total 0\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\n'If you want to pass input to the process's stdin, you can pass a bytes object to the input keyword argument:>>> cmd = ['awk', 'length($0) > 5']>>> ip = 'foo\nfoofoo\n'.encode('utf-8')>>> result = subprocess.run(cmd, stdout=subprocess.PIPE, input=ip)>>> result.stdout.decode('utf-8')'foofoo\n'You can capture errors by passing stderr=subprocess.PIPE (capture to result.stderr) or stderr=subprocess.STDOUT (capture to result.stdout along with regular output). If you want run to throw an exception when the process returns a nonzero exit code, you can pass check=True. (Or you can check the returncode attribute of result above.) When security is not a concern, you can also run more complex shell commands by passing shell=True as described at the end of this answer.Later versions of Python streamline the above further. In Python 3.7+, the above one-liner can be spelled like this:>>> subprocess.run(['ls', '-l'], capture_output=True, text=True).stdout'total 0\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\n'Using run this way adds just a bit of complexity, compared to the old way of doing things. But now you can do almost anything you need to do with the run function alone.Older versions of Python (3-3.4): more about check_outputIf you are using an older version of Python, or need modest backwards compatibility, you can use the check_output function as briefly described above. It has been available since Python 2.7.subprocess.check_output(*popenargs, **kwargs)  It takes takes the same arguments as Popen (see below), and returns a string containing the program's output. The beginning of this answer has a more detailed usage example. In Python 3.5+, check_output is equivalent to executing run with check=True and stdout=PIPE, and returning just the stdout attribute.You can pass stderr=subprocess.STDOUT to ensure that error messages are included in the returned output. When security is not a concern, you can also run more complex shell commands by passing shell=True as described at the end of this answer.If you need to pipe from stderr or pass input to the process, check_output won't be up to the task. See the Popen examples below in that case.Complex applications and legacy versions of Python (2.6 and below): PopenIf you need deep backwards compatibility, or if you need more sophisticated functionality than check_output or run provide, you'll have to work directly with Popen objects, which encapsulate the low-level API for subprocesses.The Popen constructor accepts either a single command without arguments, or a list containing a command as its first item, followed by any number of arguments, each as a separate item in the list. shlex.split can help parse strings into appropriately formatted lists. Popen objects also accept a host of different arguments for process IO management and low-level configuration.To send input and capture output, communicate is almost always the preferred method. As in:output = subprocess.Popen([""mycmd"", ""myarg""],                           stdout=subprocess.PIPE).communicate()[0]Or>>> import subprocess>>> p = subprocess.Popen(['ls', '-a'], stdout=subprocess.PIPE, ...                                    stderr=subprocess.PIPE)>>> out, err = p.communicate()>>> print out...fooIf you set stdin=PIPE, communicate also allows you to pass data to the process via stdin:>>> cmd = ['awk', 'length($0) > 5']>>> p = subprocess.Popen(cmd, stdout=subprocess.PIPE,...                           stderr=subprocess.PIPE,...                           stdin=subprocess.PIPE)>>> out, err = p.communicate('foo\nfoofoo\n')>>> print outfoofooNote Aaron Hall's answer, which indicates that on some systems, you may need to set stdout, stderr, and stdin all to PIPE (or DEVNULL) to get communicate to work at all.In some rare cases, you may need complex, real-time output capturing. Vartec's answer suggests a way forward, but methods other than communicate are prone to deadlocks if not used carefully.As with all the above functions, when security is not a concern, you can run more complex shell commands by passing shell=True.Notes1. Running shell commands: the shell=True argumentNormally, each call to run, check_output, or the Popen constructor executes a single program. That means no fancy bash-style pipes. If you want to run complex shell commands, you can pass shell=True, which all three functions support. For example:>>> subprocess.check_output('cat books/* | wc', shell=True, text=True)' 1299377 17005208 101299376\n'However, doing this raises security concerns. If you're doing anything more than light scripting, you might be better off calling each process separately, and passing the output from each as an input to the next, viarun(cmd, [stdout=etc...], input=other_output)OrPopen(cmd, [stdout=etc...]).communicate(other_output)The temptation to directly connect pipes is strong; resist it. Otherwise, you'll likely see deadlocks or have to do hacky things like this."
"data_i","edited Aug 08 '22 at 11:50","
        How do I find the location of my Python site-packages directory?
    ","How do I find the location of my site-packages directory?","There are two types of site-packages directories, global and per user.Global site-packages (""dist-packages"") directories are listed in sys.path when you run: python -m siteFor a more concise list run getsitepackages from the site module in Python code: python -c 'import site; print(site.getsitepackages())'Caution: In virtual environments getsitepackages is not available with older versions of virtualenv, sys.path from above will list the virtualenv's site-packages directory correctly, though. In Python 3, you may use the sysconfig module instead: python3 -c 'import sysconfig; print(sysconfig.get_paths()[""purelib""])'The per user site-packages directory (PEP 370) is where Python installs your local packages: python -m site --user-siteIf this points to a non-existing directory check the exit status of Python and see python -m site --help for explanations.Hint: Running pip list --user or pip freeze --user gives you a list of all installed per user site-packages.Practical Tips<package>.__path__ lets you identify the location(s) of a specific package: (details)  $ python -c ""import setuptools as _; print(_.__path__)""  ['/usr/lib/python2.7/dist-packages/setuptools']<module>.__file__ lets you identify the location of a specific module: (difference)  $ python3 -c ""import os as _; print(_.__file__)""  /usr/lib/python3.6/os.pyRun pip show <package> to show Debian-style package information:  $ pip show pytest  Name: pytest  Version: 3.8.2  Summary: pytest: simple powerful testing with Python  Home-page: https://docs.pytest.org/en/latest/  Author: Holger Krekel, Bruno Oliveira, Ronny Pfannschmidt, Floris Bruynooghe, Brianna Laugher, Florian Bruhin and others  Author-email: None  License: MIT license  Location: /home/peter/.local/lib/python3.4/site-packages  Requires: more-itertools, atomicwrites, setuptools, attrs, pathlib2, six, py, pluggy"
"data_i","edited Apr 10 '22 at 10:56","
        Create a Pandas Dataframe by appending one row at a time
    ","How do I create an empty DataFrame, then add rows, one by one?I created an empty DataFrame:df = pd.DataFrame(columns=('lib', 'qty1', 'qty2'))Then I can add a new row at the end and fill a single field with:df = df._set_value(index=len(df), col='qty1', value=10.0)It works for only one field at a time. What is a better way to add new row to df?","You can use df.loc[i], where the row with index i will be what you specify it to be in the dataframe.>>> import pandas as pd>>> from numpy.random import randint>>> df = pd.DataFrame(columns=['lib', 'qty1', 'qty2'])>>> for i in range(5):>>>     df.loc[i] = ['name' + str(i)] + list(randint(10, size=2))>>> df     lib qty1 qty20  name0    3    31  name1    2    42  name2    2    83  name3    2    14  name4    9    6"
"data_i","edited Sep 15 '16 at 11:14","
        Open link in new tab or window
    ","Is it possible to open an a href link in a new tab instead of the same tab?<a href=""http://your_url_here.html"">Link</a>","You should add the target=""_blank"" and rel=""noopener noreferrer"" in the anchor tag.For example:<a target=""_blank"" rel=""noopener noreferrer"" href=""http://your_url_here.html"">Link</a>Adding rel=""noopener noreferrer"" is not mandatory, but it's a recommended security measure. More information can be found in the links below. Source: MDN | HTML element <a> | attribute targetAbout rel=noopenerOpens External Anchors Using rel=""noopener"""
"data_i","edited Sep 05 '22 at 09:33","
        What is the purpose of the `self` parameter? Why is it needed?
    ","Consider this example:class MyClass:    def func(self, name):        self.name = nameI know that self refers to the specific instance of MyClass. But why must func explicitly include self as a parameter? Why do we need to use self in the method's code? Some other languages make this implicit, or use special syntax instead.For a language-agnostic consideration of the design decision, see What is the advantage of having this/self pointer mandatory explicit?.To close debugging questions where OP omitted a self parameter for a method and got a TypeError, use TypeError: method() takes 1 positional argument but 2 were given instead. If OP omitted self. in the body of the method and got a NameError, consider How can I call a function within a class?.","The reason you need to use self. is because Python does not use special syntax to refer to instance attributes. Python decided to do methods in a way that makes the instance to which the method belongs be passed automatically, but not received automatically: the first parameter of methods is the instance the method is called on. That makes methods entirely the same as functions, and leaves the actual name to use up to you (although self is the convention, and people will generally frown at you when you use something else.) self is not special to the code, it's just another object.Python could have done something else to distinguish normal names from attributes -- special syntax like Ruby has, or requiring declarations like C++ and Java do, or perhaps something  yet more different -- but it didn't. Python's all for making things explicit, making it obvious what's what, and although it doesn't do it entirely everywhere, it does do it for instance attributes. That's why assigning to an instance attribute needs to know what instance to assign to, and that's why it needs self.."
"data_i","edited Jun 05 '22 at 19:45","
        Why do people write #!/usr/bin/env python on the first line of a Python script?
    ","I see these at the top of Python files:#!/usr/bin/env python#!/usr/bin/env python3It seems to me like the files run the same without that line.","If you have several versions of Python installed, /usr/bin/env will ensure the interpreter used is the first one on your environment's $PATH. The alternative would be to hardcode something like #!/usr/bin/python; that's ok, but less flexible.In Unix, an executable file that's meant to be interpreted can indicate what interpreter to use by having a #! at the start of the first line, followed by the interpreter (and any flags it may need).If you're talking about other platforms, of course, this rule does not apply (but that ""shebang line"" does no harm, and will help if you ever copy that script to a platform with a Unix base, such as Linux, Mac, etc)."
"data_i","edited Aug 18 '21 at 17:55","
        How to reload a page using JavaScript
    ","How can I reload the page using JavaScript?I need a method that works in all browsers.","JavaScript 1.2 and newerwindow.location.reload();// If we needed to force the document to be fetched from the// web server again (such as where the document contents// change dynamically but cache control headers are not// configured properly), Firefox supports a non-standard// parameter that can be set to true to bypass the cache://window.location.reload(true);JavaScript 1.1window.location.replace(window.location.pathname + window.location.search + window.location.hash);// does not create a history entryJavaScript 1.0window.location.href = window.location.pathname + window.location.search + window.location.hash;// creates a history entry"
"data_i","edited Aug 20 '14 at 15:00","
        Redefine tab as 4 spaces
    ","My current setting assumes 8 spaces; how could I redefine it?","It depends on what you mean. Do you want actual tab characters in your file to appear 4 spaces wide, or by ""tab"" do you actually mean an indent, generated by pressing the tab key, which would result in the file literally containing (up to) 4 space characters for each ""tab"" you type?Depending on your answer, one of the following sets ofsettings should work for you:For tab characters that appear 4-spaces-wide:set tabstop=4If you're using actual tab character in your source code you probably also want these settings (these are actually the defaults, but you may want to set them defensively):set softtabstop=0 noexpandtabFinally, if you want an indent to correspond to a single tab, you should also use:set shiftwidth=4For indents that consist of 4 space characters but are entered with the tab key:set tabstop=8 softtabstop=0 expandtab shiftwidth=4 smarttabTo make the above settings permanent addthese lines to your vimrc.In case you need to make adjustments, or would simply like to understand what these options all mean, here's a breakdown of what each option means:tabstopThe width of a hard tabstop measured in ""spaces"" -- effectively the (maximum) width of an actual tab character.shiftwidthThe size of an ""indent"". It's also measured in spaces, so if your code base indents with tab characters then you want shiftwidth to equal the number of tab characters times tabstop. This is also used by things like the =, > and < commands.softtabstopSetting this to a non-zero value other than tabstop will make the tab key (in insert mode)   insert a combination of spaces (and possibly tabs) to simulate tab stops at this width.expandtabEnabling this will make the tab key (in insert mode) insert spaces instead of   tab characters. This also affects the behavior of the retab command.smarttabEnabling this will make the tab key (in insert mode) insert spaces or tabs to  go to the next indent  of the next tabstop when the cursor is at the beginning of a line (i.e. the  only preceding characters are whitespace).For more details on any of these see :help 'optionname' in vim (e.g. :help 'tabstop') "
"data_i","edited Jul 21 '21 at 08:15","
        How to remove remote origin from a Git repository
    ","I just did git init to initialize my folder as Git repository and then added a remote repository using git remote add origin URL. Now I want to remove this git remote add origin and add a new repository git remote add origin new-URL. How can I do it?","Instead of removing and re-adding, you can do this:git remote set-url origin git://new.url.hereSee this question: How to change the URI (URL) for a remote Git repository?To remove remote use this:git remote remove origin"
"data_i","edited Sep 17 '15 at 16:38","
        Activity has leaked window that was originally added
    ","What is this error, and why does it happen?05-17 18:24:57.069: ERROR/WindowManager(18850): Activity com.mypkg.myP has leaked window com.android.internal.policy.impl.PhoneWindow$DecorView@44c46ff0 that was originally added here05-17 18:24:57.069: ERROR/WindowManager(18850): android.view.WindowLeaked: Activity ccom.mypkg.myP has leaked window com.android.internal.policy.impl.PhoneWindow$DecorView@44c46ff0 that was originally added here05-17 18:24:57.069: ERROR/WindowManager(18850):     at android.view.ViewRoot.<init>(ViewRoot.java:231)05-17 18:24:57.069: ERROR/WindowManager(18850):     at android.view.WindowManagerImpl.addView(WindowManagerImpl.java:148)05-17 18:24:57.069: ERROR/WindowManager(18850):     at android.view.WindowManagerImpl.addView(WindowManagerImpl.java:91)05-17 18:24:57.069: ERROR/WindowManager(18850):     at android.view.Window$LocalWindowManager.addView(Window.java:424)05-17 18:24:57.069: ERROR/WindowManager(18850):     at android.app.Dialog.show(Dialog.java:239)05-17 18:24:57.069: ERROR/WindowManager(18850):     at com.mypkg.myP$PreparePairingLinkageData.onPreExecute(viewP.java:183)05-17 18:24:57.069: ERROR/WindowManager(18850):     at android.os.AsyncTask.execute(AsyncTask.java:391)05-17 18:24:57.069: ERROR/WindowManager(18850):     at com.mypkg.myP.onCreate(viewP.java:94)05-17 18:24:57.069: ERROR/WindowManager(18850):     at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1047)05-17 18:24:57.069: ERROR/WindowManager(18850):     at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2544)05-17 18:24:57.069: ERROR/WindowManager(18850):     at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2621)05-17 18:24:57.069: ERROR/WindowManager(18850):     at android.app.ActivityThread.access$2200(ActivityThread.java:126)05-17 18:24:57.069: ERROR/WindowManager(18850):     at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1932)05-17 18:24:57.069: ERROR/WindowManager(18850):     at android.os.Handler.dispatchMessage(Handler.java:99)05-17 18:24:57.069: ERROR/WindowManager(18850):     at android.os.Looper.loop(Looper.java:123)05-17 18:24:57.069: ERROR/WindowManager(18850):     at android.app.ActivityThread.main(ActivityThread.java:4595)05-17 18:24:57.069: ERROR/WindowManager(18850):     at java.lang.reflect.Method.invokeNative(Native Method)05-17 18:24:57.069: ERROR/WindowManager(18850):     at java.lang.reflect.Method.invoke(Method.java:521)05-17 18:24:57.069: ERROR/WindowManager(18850):     at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:860)05-17 18:24:57.069: ERROR/WindowManager(18850):     at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:618)05-17 18:24:57.069: ERROR/WindowManager(18850):     at dalvik.system.NativeStart.main(Native Method)","You're trying to show a Dialog after you've exited an Activity.[EDIT]This question is one of the top search on google for android developer,therefore Adding few important points from comments, which might be more helpful for future investigator without going in depth of comment conversation.Answer 1 : You're trying to show a Dialog after you've exited an Activity.Answer 2 This error can be a little misleading in some circumstances (although  the answer is still completely accurate) - i.e. in my case an  unhandled Exception was thrown in an AsyncTask, which caused the  Activity to shutdown, then an open progressdialog caused this  Exception.. so the 'real' exception was a little earlier in the logAnswer 3 Call dismiss() on the Dialog instance you created before exiting your  Activity, e.g. in onPause() or onDestroy()"
"data_i","edited Nov 14 '19 at 11:32","
        How do I check if a string contains another string in Objective-C?
    ","How can I check if a string (NSString) contains another smaller string?I was hoping for something like:NSString *string = @""hello bla bla"";NSLog(@""%d"",[string containsSubstring:@""hello""]);But the closest I could find was:if ([string rangeOfString:@""hello""] == 0) {    NSLog(@""sub string doesnt exist"");} else {    NSLog(@""exists"");}Anyway, is that the best way to find if a string contains another string?","NSString *string = @""hello bla bla"";if ([string rangeOfString:@""bla""].location == NSNotFound) {  NSLog(@""string does not contain bla"");} else {  NSLog(@""string contains bla!"");}The key is noticing that rangeOfString: returns an NSRange struct, and the documentation says that it returns the struct {NSNotFound, 0} if the ""haystack"" does not contain the ""needle"".And if you're on iOS 8 or OS X Yosemite, you can now do: (*NOTE: This WILL crash your app if this code is called on an iOS7 device).NSString *string = @""hello bla blah"";if ([string containsString:@""bla""]) {  NSLog(@""string contains bla!"");} else {  NSLog(@""string does not contain bla"");}(This is also how it would work in Swift) "
"data_i","edited Aug 09 '22 at 02:24","
        How to read a text file into a string variable and strip newlines?
    ","I have a text file that looks like:ABCDEFHow can I read the file into a single-line string without newlines, in this case creating a string 'ABCDEF'?For reading the file into a list of lines, but removing the trailing newline character from each line, see How to read a file without newlines?.","You could use:with open('data.txt', 'r') as file:    data = file.read().replace('\n', '')Or if the file content is guaranteed to be one-linewith open('data.txt', 'r') as file:    data = file.read().rstrip()"
"data_i","edited Jul 13 '19 at 01:04","
        How to drop rows of Pandas DataFrame whose value in a certain column is NaN
    ","I have this DataFrame and want only the records whose EPS column is not NaN:>>> df                 STK_ID  EPS  cashSTK_ID RPT_Date                   601166 20111231  601166  NaN   NaN600036 20111231  600036  NaN    12600016 20111231  600016  4.3   NaN601009 20111231  601009  NaN   NaN601939 20111231  601939  2.5   NaN000001 20111231  000001  NaN   NaN...i.e. something like df.drop(....) to get this resulting dataframe:                  STK_ID  EPS  cashSTK_ID RPT_Date                   600016 20111231  600016  4.3   NaN601939 20111231  601939  2.5   NaNHow do I do that?","Don't drop, just take the rows where EPS is not NA:df = df[df['EPS'].notna()]"
"data_i","asked Jun 22 '10 at 18:17","
        Difference between Build Solution, Rebuild Solution, and Clean Solution in Visual Studio?
    ","What is the difference between Build Solution, Rebuild Solution, and Clean Solution in Visual Studio?When is the appropriate time to use each one of these?","Build solution will perform an incremental build: if it doesn't think it needs to rebuild a project, it won't. It may also use partially-built bits of the project if they haven't changed (I don't know how far it takes this)Rebuild solution will clean and then build the solution from scratch, ignoring anything it's done before. The difference between this and ""Clean, followed by Build"" is that Rebuild will clean-then-build each project, one at a time, rather than cleaning all and then building all.Clean solution will remove the build artifacts from the previous build. If there are any other files in the build target directories (bin and obj) they may not be removed, but actual build artifacts are. I've seen behaviour for this vary - sometimes deleting fairly thoroughly and sometimes not - but I'll give VS the benefit of the doubt for the moment :)(The links are to the devenv.exe command line switches, but they do the same as the menu items.)"
"data_i","edited Dec 11 '13 at 15:27","
        pg_config executable not found
    ","I am having trouble installing psycopg2. I get the following error when I try to pip install psycopg2:Error: pg_config executable not found.Please add the directory containing pg_config to the PATHor specify the full executable path with the option:    python setup.py build_ext --pg-config /path/to/pg_config build ...or with the pg_config option in 'setup.cfg'.----------------------------------------Command python setup.py egg_info failed with error code 1 in /tmp/pip-build/psycopg2But the problem is pg_config is actually in my PATH; it runs without any problem:$ which pg_config/usr/pgsql-9.1/bin/pg_configI tried adding the pg_config path to the setup.cfg file and building it using the source files I downloaded from their website (http://initd.org/psycopg/) and I get the following error message!Error: Unable to find 'pg_config' file in '/usr/pgsql-9.1/bin/'But it is actually THERE!!!I am baffled by these errors. Can anyone help please?By the way, I sudo all the commands. Also I am on RHEL 5.5.","pg_config is in postgresql-devel (libpq-dev in Debian/Ubuntu, libpq-devel on Centos/Fedora/Cygwin/Babun.)"
"data_i","edited Aug 18 '22 at 13:31","
        How to parse JSON in Java
    ","I have the following JSON text. How can I parse it to get the values of pageName, pagePic, post_id, etc.?{  ""pageInfo"": {    ""pageName"": ""abc"",    ""pagePic"": ""http://example.com/content.jpg""  },  ""posts"": [    {      ""post_id"": ""123456789012_123456789012"",      ""actor_id"": ""1234567890"",      ""picOfPersonWhoPosted"": ""http://example.com/photo.jpg"",      ""nameOfPersonWhoPosted"": ""Jane Doe"",      ""message"": ""Sounds cool. Can't wait to see it!"",      ""likesCount"": ""2"",      ""comments"": [],      ""timeOfPost"": ""1234567890""    }  ]}","The org.json library is easy to use.Just remember (while casting or using methods like getJSONObject and getJSONArray) that in JSON notation[ … ] represents an array, so library will parse it to JSONArray{ … } represents an object, so library will parse it to JSONObjectExample code below:import org.json.*;String jsonString = ... ; //assign your JSON String hereJSONObject obj = new JSONObject(jsonString);String pageName = obj.getJSONObject(""pageInfo"").getString(""pageName"");JSONArray arr = obj.getJSONArray(""posts""); // notice that `""posts"": [...]`for (int i = 0; i < arr.length(); i++){    String post_id = arr.getJSONObject(i).getString(""post_id"");    ......}You may find more examples from: Parse JSON in JavaDownloadable jar:  http://mvnrepository.com/artifact/org.json/json"
"data_i","edited Apr 16 '20 at 08:21","
        What is the  in a .vimrc file?
    ","I see <leader> in many .vimrc files, and I am wondering what does it mean? What is it used for? Just a general overview of the purpose and usage would be great.","The <Leader> key is mapped to \ by default.  So if you have a map of <Leader>t, you can execute it by default with \+t.  For more detail or re-assigning it using the mapleader variable, see:help leaderTo define a mapping which uses the ""mapleader"" variable, the special string""<Leader>"" can be used.  It is replaced with the string value of ""mapleader"".If ""mapleader"" is not set or empty, a backslash is used instead.  Example:    :map <Leader>A  oanother line <Esc>Works like:    :map \A  oanother line <Esc>But after:    :let mapleader = "",""It works like:    :map ,A  oanother line <Esc>Note that the value of ""mapleader"" is used at the moment the mapping isdefined.  Changing ""mapleader"" after that has no effect for already definedmappings."
"data_i","edited Jan 10 '22 at 14:49","
        Better way to set distance between flexbox items
    ","To set the minimal distance between flexbox items I'm using margin: 0 5px on .item and margin: 0 -5px on container. For me it seems like a hack, but I can't find any better way to do this.#box {  display: flex;  width: 100px;  margin: 0 -5px;}.item {  background: gray;  width: 50px;  height: 50px;  margin: 0 5px;}<div id='box'>  <div class='item'></div>  <div class='item'></div>  <div class='item'></div>  <div class='item'></div></div>","Flexbox doesn't have collapsing margins.Flexbox doesn't have anything akin to border-spacing for tables (edit: CSS property gap fulfills this role in newer browsers, Can I use)Therefore achieving what you are asking for is a bit more difficult.In my experience, the ""cleanest"" way that doesn't use :first-child/:last-child and works without any modification on flex-wrap:wrap is to set padding:5px on the container and margin:5px on the children. That will produce a 10px gap between each child and between each child and their parent.Demo.upper {  margin: 30px;  display: flex;  flex-direction: row;  width: 300px;  height: 80px;  border: 1px red solid;  padding: 5px; /* this */}.upper > div {  flex: 1 1 auto;  border: 1px red solid;  text-align: center;  margin: 5px;  /* and that, will result in a 10px gap */}.upper.mc /* multicol test */ {  flex-direction: column;  flex-wrap: wrap;  width: 200px;  height: 200px;}<div class=""upper"">  <div>aaa<br/>aaa</div>  <div>aaa</div>  <div>aaa<br/>aaa</div>  <div>aaa<br/>aaa<br/>aaa</div>  <div>aaa</div>  <div>aaa</div></div><div class=""upper mc"">  <div>aaa<br/>aaa</div>  <div>aaa</div>  <div>aaa<br/>aaa</div>  <div>aaa<br/>aaa<br/>aaa</div>  <div>aaa</div>  <div>aaa</div></div>"
"data_i","edited Apr 12 '14 at 08:11","
        Get the first element of an array
    ","I have an array:  array( 4 => 'apple', 7 => 'orange', 13 => 'plum' )I would like to get the first element of this array. Expected result: string apple One requirement: it cannot be done with passing by reference, so array_shift is not a good solution.How can I do this?","Original answer, but costly (O(n)):array_shift(array_values($array));In O(1):array_pop(array_reverse($array));Other use cases, etc...If modifying (in the sense of resetting array pointers) of $array is not a problem, you might use:reset($array);This should be theoretically more efficient, if a array ""copy"" is needed:array_shift(array_slice($array, 0, 1));With PHP 5.4+ (but might cause an index error if empty):array_values($array)[0];"
"data_i","edited Jan 13 '13 at 16:05","
        How do I get started with Node.js
    ","Are there any good resources to get started with Node.JS? Any good tutorials, blogs or books?Of course, I have visited its official website http://nodejs.org/, but I didn't think the documentation they have is a good starting point.","You can follow these tutorials to get started:TutorialsNodeSchool.io interactive lessonsThe Art of Node (an introduction to Node.js)Hello WorldHello World Web Server (paid)Node.js guideBuild a blog with Node.js, express and MongoDBNode.js for BeginnersLearn Node.js Completely and with ConfidenceNode JS Processing Model – Single Threaded Model with Event Loop ArchitectureRisingStack's Node Hero SeriesGreat Node.js tutorials voted by the programming communityNode.js Tutorial30 days of NodeDeveloper SitesJoyent's developer site for nodeTutorials TeacherVideosNode Tuts (Node.js video tutorials)Einführung in Node.js (in German)Introduction to Node.js with Ryan DahlNode.js: Asynchronous Purity Leads to Faster DevelopmentParallel Programming with Node.jsServer-side JavaScript with Node, Connect & ExpressNode.js First LookNode.js with MongoDBRyan Dahl's Google Tech TalkReal Time Web with Node.jsNode.js Tutorials for BeginnersPluralsight courses (paid)Udemy Learn and understand Nodejs (paid)The New BostonScreencastsLearn All The NodesNode TutsEinführung in Node.js (in German)NodeCastsBooksThe Node Beginner BookMastering Node.jsUp and Running with Node.jsNode.js in ActionSmashing Node.js: JavaScript EverywhereNode.js & Co. (in German)Sam's Teach Yourself Node.js in 24 HoursMost detailed list of free JavaScript BooksMixu's Node BookNode.js the Right Way: Practical, Server-Side JavaScript That ScaleBeginning Web Development with Node.jsNode Web DevelopmentNodeJS for Righteous Universal Domination!CoursesReal Time Web with Node.jsEssential Node.js from DevelopMentorFreecodecamp - Learn to code for freeUdemy - The Complete Node.js Developer Course (3rd Edition) (paid)BlogsThe Node.js blogHow To NodeDailyJSNodejitsu blogRyan Wilcox's WhitepaperdevthoughtPodcastsNodeUpJavaScript resourcesCrockford's videos (must see!)Essential JavaScript Design Patterns For BeginnersJavaScript gardenJavaScript Patterns bookJavaScript: The Good Parts bookEloquent javascript  bookNode.js ModulesSearch for registered Node.js modulesA curated list of awesome Node.js librariesWiki List on GitHub/Joyent/Node.js (start here last!)OtherJSApp.US - like jsfiddle, but for Node.jsNode with VJET JS (for Eclipse IDE)Production sites with published source:Node Knockout Hackathon (source)Freecodecamp - Learn to code for free (source)Useful Node.js Tools, Tutorials and ResourcesRunnable.com - like jsfiddle, but for server side as wellGetting Started with Node.js on HerokuGetting Started with Node.js on Open-ShiftAuthentication using Passport"
"data_i","edited Feb 15 '22 at 16:03","
        What effect does the `--no-ff` flag have for `git merge`?
    ","Using gitk log, I could not spot a difference between the effect of git merge and git merge --no-ff. How can I observe the difference (with a git command or some tool)?","The --no-ff flag prevents git merge from executing a ""fast-forward"" if it detects that your current HEAD is an ancestor of the commit you're trying to merge. A fast-forward is when, instead of constructing a merge commit, git just moves your branch pointer to point at the incoming commit. This commonly occurs when doing a git pull without any local changes.However, occasionally you want to prevent this behavior from happening, typically because you want to maintain a specific branch topology (e.g. you're merging in a topic branch and you want to ensure it looks that way when reading history). In order to do that, you can pass the --no-ff flag and git merge will always construct a merge instead of fast-forwarding.Similarly, if you want to execute a git pull or use git merge in order to explicitly fast-forward, and you want to bail out if it can't fast-forward, then you can use the --ff-only flag. This way you can regularly do something like git pull --ff-only without thinking, and then if it errors out you can go back and decide if you want to merge or rebase."
"data_i","edited Jun 05 '18 at 18:20","
        Run/install/debug Android applications over Wi-Fi?
    ","I thought there was a way to test your applications in development over Wi-Fi. Is this possible?I'd love to be able to untether my phone and develop wirelessly.","See forum post Any way to view Android screen remotely without root? - Post #9.Connect the device via USB and make sure debugging is working;adb tcpip 5555. This makes the device to start listening for connections on port 5555;Look up the device IP address with adb shell netcfg or adb shell ifconfig with 6.0 and higher;You can disconnect the USB now;adb connect <DEVICE_IP_ADDRESS>:5555. This connects to the server we set up on the device on step 2;Now you have a device over the network with which you can debug as usual.To switch the server back to the USB mode, run adb usb, which will put the server on your phone back to the USB mode. If you have more than one device, you can specify the device with the -s option: adb -s <DEVICE_IP_ADDRESS>:5555 usb.No root required!To find the IP address of the device: run adb shell and then netcfg. You'll see it there.To find the IP address while using OSX run the command adb shell ip route.WARNING: leaving the option enabled is dangerous, anyone in your network can connect to your device in debug, even if you are in data network. Do it only when connected to a trusted Wi-Fi and remember to disconnect it when done!@Sergei suggested that line 2 should be modified, commenting: ""-d option needed to connect to the USB device when the other connection persists (for example, emulator connected or other Wi-Fi device)"".This information may prove valuable to future readers, but I rolled-back to the original version that had received 178 upvotes.On some device you can do the same thing even if you do not have an USB cable:Enable ADB over network in developer settingIt should show the IP addressadb connect <DEVICE_IP_ADDRESS>:5555Disable the setting when doneUsing Android Studio there is a plugin allowing you to connect USB Debugging without the need of using any ADB command from a terminal."
"data_i","edited Nov 18 '21 at 20:20","
        How to add a new column to an existing DataFrame?
    ","I have the following indexed DataFrame with named columns and rows not- continuous numbers:          a         b         c         d2  0.671399  0.101208 -0.181532  0.2412733  0.446172 -0.243316  0.051767  1.5773185  0.614758  0.075793 -0.451460 -0.012493I would like to add a new column, 'e', to the existing data frame and do not want to change anything in the data frame (i.e., the new column always has the same length as the DataFrame). 0   -0.3354851   -1.1666582   -0.385571dtype: float64How can I add column e to the above example? ","Edit 2017As indicated in the comments and by @Alexander, currently the best method to add the values of a Series as a new column of a DataFrame could be using assign:df1 = df1.assign(e=pd.Series(np.random.randn(sLength)).values)Edit 2015Some reported getting the SettingWithCopyWarning with this code.However, the code still runs perfectly with the current pandas version 0.16.1.>>> sLength = len(df1['a'])>>> df1          a         b         c         d6 -0.269221 -0.026476  0.997517  1.2943858  0.917438  0.847941  0.034235 -0.448948>>> df1['e'] = pd.Series(np.random.randn(sLength), index=df1.index)>>> df1          a         b         c         d         e6 -0.269221 -0.026476  0.997517  1.294385  1.7571678  0.917438  0.847941  0.034235 -0.448948  2.228131>>> pd.version.short_version'0.16.1'The SettingWithCopyWarning aims to inform of a possibly invalid assignment on a copy of the Dataframe. It doesn't necessarily say you did it wrong (it can trigger false positives) but from 0.13.0 it let you know there are more adequate methods for the same purpose. Then, if you get the warning, just follow its advise: Try using .loc[row_index,col_indexer] = value instead>>> df1.loc[:,'f'] = pd.Series(np.random.randn(sLength), index=df1.index)>>> df1          a         b         c         d         e         f6 -0.269221 -0.026476  0.997517  1.294385  1.757167 -0.0509278  0.917438  0.847941  0.034235 -0.448948  2.228131  0.006109>>> In fact, this is currently the more efficient method as described in pandas docsOriginal answer:Use the original df1 indexes to create the series:df1['e'] = pd.Series(np.random.randn(sLength), index=df1.index)"
"data_i","edited Apr 10 '22 at 10:28","
        If Python is interpreted, what are .pyc files?
    ","Python is an interpreted language. But why does my source directory contain .pyc files, which are identified by Windows as ""Compiled Python Files""?","I've been given to understand that  Python is an interpreted language...This popular meme is incorrect, or, rather, constructed upon a misunderstanding of (natural) language levels: a similar mistake would be to say ""the Bible is a hardcover book"".  Let me explain that simile...""The Bible"" is ""a book"" in the sense of being a class of (actual, physical objects identified as) books; the books identified as ""copies of the Bible"" are supposed to have something fundamental in common (the contents, although even those can be in different languages, with different acceptable translations, levels of footnotes and other annotations) -- however, those books are perfectly well allowed to differ in a myriad of aspects that are not considered fundamental -- kind of binding, color of binding, font(s) used in the printing, illustrations if any, wide writable margins or not, numbers and kinds of builtin bookmarks, and so on, and so forth.It's quite possible that a typical printing of the Bible would indeed be in hardcover binding -- after all, it's a book that's typically meant to be read over and over, bookmarked at several places, thumbed through looking for given chapter-and-verse pointers, etc, etc, and a good hardcover binding can make a given copy last longer under such use.  However, these are mundane (practical) issues that cannot be used to determine whether a given actual book object is a copy of the Bible or not: paperback printings are perfectly possible!Similarly, Python is ""a language"" in the sense of defining a class of language implementations which must all be similar in some fundamental respects (syntax, most semantics except those parts of those where they're explicitly allowed to differ) but are fully allowed to differ in just about every ""implementation"" detail -- including how they deal with the source files they're given, whether they compile the sources to some lower level forms (and, if so, which form -- and whether they save such compiled forms, to disk or elsewhere), how they execute said forms, and so forth.The classical implementation, CPython, is often called just ""Python"" for short -- but it's just one of several production-quality implementations, side by side with Microsoft's IronPython (which compiles to CLR codes, i.e., "".NET""), Jython (which compiles to JVM codes), PyPy (which is written in Python itself and can compile to a huge variety of ""back-end"" forms including ""just-in-time"" generated machine language).  They're all Python (==""implementations of the Python language"") just like many superficially different book objects can all be Bibles (==""copies of The Bible"").If you're interested in CPython specifically: it compiles the source files into a Python-specific lower-level form (known as ""bytecode""), does so automatically when needed (when there is no bytecode file corresponding to a source file, or the bytecode file is older than the source or compiled by a different Python version), usually saves the bytecode files to disk (to avoid recompiling them in the future).  OTOH IronPython will typically compile to CLR codes (saving them to disk or not, depending) and Jython to JVM codes (saving them to disk or not -- it will use the .class extension if it does save them).These lower level forms are then executed by appropriate ""virtual machines"" also known as ""interpreters"" -- the CPython VM, the .Net runtime, the Java VM (aka JVM), as appropriate.So, in this sense (what do typical implementations do), Python is an ""interpreted language"" if and only if C# and Java are: all of them have a typical implementation strategy of producing bytecode first, then executing it via a VM/interpreter.More likely the focus is on how ""heavy"", slow, and high-ceremony the compilation process is.  CPython is designed to compile as fast as possible, as lightweight as possible, with as little ceremony as feasible -- the compiler does very little error checking and optimization, so it can run fast and in small amounts of memory, which in turns lets it be run automatically and transparently whenever needed, without the user even needing to be aware that there is a compilation going on, most of the time.  Java and C# typically accept more work during compilation (and therefore don't perform automatic compilation) in order to check errors more thoroughly and perform more optimizations.  It's a continuum of gray scales, not a black or white situation, and it would be utterly arbitrary to put a threshold at some given level and say that only above that level you call it ""compilation""!-)"
"data_i","edited Aug 29 '22 at 17:35","
        What is the difference between null=True and blank=True in Django?
    ","When we add a model field in Django we generally write:models.CharField(max_length=100, null=True, blank=True)The same is done with ForeignKey, DecimalField etc. What is the basic difference between:null=True onlyblank=True onlynull=True and blank=Truein respect to different (CharField, ForeignKey, ManyToManyField, DateTimeField) fields? What are the advantages/disadvantages of using option 1, 2, or 3?","null=True sets NULL (versus NOT NULL) on the column in your DB. Blank values for Django field types such as DateTimeField or ForeignKey will be stored as NULL in the DB.blank determines whether the field will be required in forms. This includes the admin and your custom forms. If blank=True then the field will not be required, whereas if it's False the field cannot be blank.The combo of the two is so frequent because typically if you're going to allow a field to be blank in your form, you're going to also need your database to allow NULL values for that field. The exception is CharFields and TextFields, which in Django are never saved as NULL. Blank values are stored in the DB as an empty string ('').A few examples:models.DateTimeField(blank=True) # raises IntegrityError if blankmodels.DateTimeField(null=True) # NULL allowed, but must be filled out in a formObviously, Those two options don't make logical sense to use (though there might be a use case for null=True, blank=False if you want a field to always be required in forms, optional when dealing with an object through something like the shell.)models.CharField(blank=True) # No problem, blank is stored as ''models.CharField(null=True) # NULL allowed, but will never be set as NULLCHAR and TEXT types are never saved as NULL by Django, so null=True is unnecessary. However, you can manually set one of these fields to None to force set it as NULL. If you have a scenario where that might be necessary, you should still include null=True."
"data_i","edited Apr 09 '22 at 09:48","
        How do I check if a variable exists?
    ","I want to check if a variable exists. Now I'm doing something like this:try:    myVarexcept NameError:    # Do something.Are there other ways without exceptions?","To check the existence of a local variable:if 'myVar' in locals():  # myVar exists.To check the existence of a global variable:if 'myVar' in globals():  # myVar exists.To check if an object has an attribute:if hasattr(obj, 'attr_name'):  # obj.attr_name exists."
"data_i","edited Jan 17 '20 at 22:43","
        How to get current time and date in Android
    ","How can I get the current time and date in an Android app?","You could use:import java.util.CalendarDate currentTime = Calendar.getInstance().getTime();There are plenty of constants in Calendar for everything you need.Check the Calendar class documentation."
"data_i","edited Jun 12 '21 at 10:19","
        Easy interview question got harder: given numbers 1..100, find the missing number(s) given exactly k are missing
    ","I had an interesting job interview experience a while back. The question started really easy:Q1: We have a bag containing numbers 1, 2, 3, …, 100. Each number appears exactly once, so there are 100 numbers. Now one number is randomly picked out of the bag. Find the missing number.I've heard this interview question before, of course, so I very quickly answered along the lines of:A1: Well, the sum of the numbers 1 + 2 + 3 + … + N is (N+1)(N/2) (see Wikipedia: sum of arithmetic series). For N = 100, the sum is 5050.Thus, if all numbers are present in the bag, the sum will be exactly 5050. Since one number is missing, the sum will be less than this, and the difference is that number. So we can find that missing number in O(N) time and O(1) space.At this point I thought I had done well, but all of a sudden the question took an unexpected turn:Q2: That is correct, but now how would you do this if TWO numbers are missing?I had never seen/heard/considered this variation before, so I panicked and couldn't answer the question. The interviewer insisted on knowing my thought process, so I mentioned that perhaps we can get more information by comparing against the expected product, or perhaps doing a second pass after having gathered some information from the first pass, etc, but I really was just shooting in the dark rather than actually having a clear path to the solution.The interviewer did try to encourage me by saying that having a second equation is indeed one way to solve the problem. At this point I was kind of upset (for not knowing the answer before hand), and asked if this is a general (read: ""useful"") programming technique, or if it's just a trick/gotcha answer.The interviewer's answer surprised me: you can generalize the technique to find 3 missing numbers. In fact, you can generalize it to find k missing numbers.Qk: If exactly k numbers are missing from the bag, how would you find it efficiently?This was a few months ago, and I still couldn't figure out what this technique is.  Obviously there's a Ω(N) time lower bound since we must scan all the numbers at least once, but the interviewer insisted that the TIME and SPACE complexity of the solving technique (minus the O(N) time input scan) is defined in k not N.So the question here is simple:How would you solve Q2?How would you solve Q3?How would you solve Qk?ClarificationsGenerally there are N numbers from 1..N, not just 1..100.I'm not looking for the obvious set-based solution, e.g. using a bit set, encoding the presence/absence each number by the value of a designated bit, therefore using O(N) bits in additional space. We can't afford any additional space proportional to N.I'm also not looking for the obvious sort-first approach. This and the set-based approach are worth mentioning in an interview (they are easy to implement, and depending on N, can be very practical). I'm looking for the Holy Grail solution (which may or may not be practical to implement, but has the desired asymptotic characteristics nevertheless).So again, of course you must scan the input in O(N), but you can only capture small amount of information (defined in terms of k not N), and must then find the k missing numbers somehow.","Here's a summary of Dimitris Andreou's link.Remember sum of i-th powers, where i=1,2,..,k. This reduces the problem to solving the system of equationsa1 + a2 + ... + ak = b1a12 + a22 + ... + ak2 = b2...a1k + a2k + ... + akk = bkUsing Newton's identities, knowing bi allows to computec1 = a1 + a2 + ... akc2 = a1a2 + a1a3 + ... + ak-1ak...ck = a1a2 ... akIf you expand the polynomial (x-a1)...(x-ak) the coefficients will be exactly c1, ..., ck - see Viète's formulas. Since every polynomial factors uniquely (ring of polynomials is an Euclidean domain), this means ai are uniquely determined, up to permutation.This ends a proof that remembering powers is enough to recover the numbers. For constant k, this is a good approach.However, when k is varying, the direct approach of computing c1,...,ck is prohibitely expensive, since e.g. ck is the product of all missing numbers, magnitude n!/(n-k)!. To overcome this, perform computations in Zq field, where q is a prime such that n <= q < 2n - it exists by Bertrand's postulate. The proof doesn't need to be changed, since the formulas still hold, and factorization of polynomials is still unique. You also need an algorithm for factorization over finite fields, for example the one by Berlekamp or Cantor-Zassenhaus.High level pseudocode for constant k:Compute i-th powers of given numbersSubtract to get sums of i-th powers of unknown numbers. Call the sums bi.Use Newton's identities to compute coefficients from bi; call them ci. Basically, c1 = b1; c2 = (c1b1 - b2)/2; see Wikipedia for exact formulasFactor the polynomial xk-c1xk-1 + ... + ck.The roots of the polynomial are the needed numbers a1, ..., ak.For varying k, find a prime n <= q < 2n using e.g. Miller-Rabin, and perform the steps with all numbers reduced modulo q.EDIT: The previous version of this answer stated that instead of Zq, where q is prime, it is possible to use a finite field of characteristic 2 (q=2^(log n)). This is not the case, since Newton's formulas require division by numbers up to k."
"data_i","edited Jan 27 '16 at 17:18","
        Sort ArrayList of custom Objects by property
    ","I read about sorting ArrayLists using a Comparator but in all of the examples people used compareTo which according to some research is a method for Strings.I wanted to sort an ArrayList of custom objects by one of their properties: a Date object(getStartDay()). Normally I compare them by item1.getStartDate().before(item2.getStartDate()) so I was wondering whether I could write something like:public class CustomComparator {    public boolean compare(Object object1, Object object2) {        return object1.getStartDate().before(object2.getStartDate());    }}public class RandomName {    ...    Collections.sort(Database.arrayList, new CustomComparator);    ...}","Since Date implements Comparable, it has a compareTo method just like String does.So your custom Comparator could look like this:public class CustomComparator implements Comparator<MyObject> {    @Override    public int compare(MyObject o1, MyObject o2) {        return o1.getStartDate().compareTo(o2.getStartDate());    }}The compare() method must return an int, so you couldn't directly return a boolean like you were planning to anyway.Your sorting code would be just about like you wrote:Collections.sort(Database.arrayList, new CustomComparator());A slightly shorter way to write all this, if you don't need to reuse your comparator, is to write it as an inline anonymous class:Collections.sort(Database.arrayList, new Comparator<MyObject>() {    @Override    public int compare(MyObject o1, MyObject o2) {        return o1.getStartDate().compareTo(o2.getStartDate());    }});Since java-8You can now write the last example in a shorter form by using a lambda expression for the Comparator:Collections.sort(Database.arrayList,                         (o1, o2) -> o1.getStartDate().compareTo(o2.getStartDate()));And List has a sort(Comparator) method, so you can shorten this even further:Database.arrayList.sort((o1, o2) -> o1.getStartDate().compareTo(o2.getStartDate()));This is such a common idiom that there's a built-in method to generate a Comparator for a class with a Comparable key:Database.arrayList.sort(Comparator.comparing(MyObject::getStartDate));All of these are equivalent forms."
"data_i","edited Jan 28 '18 at 21:41","
        How to uncommit my last commit in Git
    ","How can I uncommit my last commit in git?Is itgit reset --hard HEADorgit reset --hard HEAD^?","If you aren't totally sure what you mean by ""uncommit"" and don't know if you want to use git reset, please see ""Revert to a previous Git commit"".If you're trying to understand git reset better, please see ""Can you explain what ""git reset"" does in plain English?"".If you know you want to use git reset, it still depends what you mean by ""uncommit"". If all you want to do is undo the act of committing, leaving everything else intact, use:git reset --soft HEAD^If you want to undo the act of committing and everything you'd staged, but leave the work tree (your files) intact:git reset HEAD^And if you actually want to completely undo it, throwing away all uncommitted changes, resetting everything to the previous commit (as the original question asked):git reset --hard HEAD^The original question also asked it's HEAD^ not HEAD. HEAD refers to the current commit - generally, the tip of the currently checked-out branch. The ^ is a notation which can be attached to any commit specifier, and means ""the commit before"". So, HEAD^ is the commit before the current one, just as master^ is the commit before the tip of the master branch.Here's the portion of the git-rev-parse documentation describing all of the ways to specify commits (^ is just a basic one among many)."
"data_i","edited Jan 13 '21 at 23:00","
        How does the @property decorator work in Python?
    ","I would like to understand how the built-in function property works. What confuses me is that property can also be used as a decorator, but it only takes arguments when used as a built-in function and not when used as a decorator.This example is from the documentation:class C:    def __init__(self):        self._x = None    def getx(self):        return self._x    def setx(self, value):        self._x = value    def delx(self):        del self._x    x = property(getx, setx, delx, ""I'm the 'x' property."")property's arguments are getx, setx, delx and a doc string.In the code below property is used as a decorator. The object of it is the x function, but in the code above there is no place for an object function in the arguments.class C:    def __init__(self):        self._x = None    @property    def x(self):        """"""I'm the 'x' property.""""""        return self._x    @x.setter    def x(self, value):        self._x = value    @x.deleter    def x(self):        del self._xHow are the x.setter and x.deleter decorators created in this case?","The property() function returns a special descriptor object:>>> property()<property object at 0x10ff07940>It is this object that has extra methods:>>> property().getter<built-in method getter of property object at 0x10ff07998>>>> property().setter<built-in method setter of property object at 0x10ff07940>>>> property().deleter<built-in method deleter of property object at 0x10ff07998>These act as decorators too. They return a new property object:>>> property().getter(None)<property object at 0x10ff079f0>that is a copy of the old object, but with one of the functions replaced.Remember, that the @decorator syntax is just syntactic sugar; the syntax:@propertydef foo(self): return self._fooreally means the same thing asdef foo(self): return self._foofoo = property(foo)so foo the function is replaced by property(foo), which we saw above is a special object. Then when you use @foo.setter(), what you are doing is call that property().setter method I showed you above, which returns a new copy of the property, but this time with the setter function replaced with the decorated method.The following sequence also creates a full-on property, by using those decorator methods.First we create some functions and a property object with just a getter:>>> def getter(self): print('Get!')... >>> def setter(self, value): print('Set to {!r}!'.format(value))... >>> def deleter(self): print('Delete!')... >>> prop = property(getter)>>> prop.fget is getterTrue>>> prop.fset is NoneTrue>>> prop.fdel is NoneTrueNext we use the .setter() method to add a setter:>>> prop = prop.setter(setter)>>> prop.fget is getterTrue>>> prop.fset is setterTrue>>> prop.fdel is NoneTrueLast we add a deleter with the .deleter() method:>>> prop = prop.deleter(deleter)>>> prop.fget is getterTrue>>> prop.fset is setterTrue>>> prop.fdel is deleterTrueLast but not least, the property object acts as a descriptor object, so it has .__get__(), .__set__() and .__delete__() methods to hook into instance attribute getting, setting and deleting:>>> class Foo: pass... >>> prop.__get__(Foo(), Foo)Get!>>> prop.__set__(Foo(), 'bar')Set to 'bar'!>>> prop.__delete__(Foo())Delete!The Descriptor Howto includes a pure Python sample implementation of the property() type:class Property:    ""Emulate PyProperty_Type() in Objects/descrobject.c""    def __init__(self, fget=None, fset=None, fdel=None, doc=None):        self.fget = fget        self.fset = fset        self.fdel = fdel        if doc is None and fget is not None:            doc = fget.__doc__        self.__doc__ = doc    def __get__(self, obj, objtype=None):        if obj is None:            return self        if self.fget is None:            raise AttributeError(""unreadable attribute"")        return self.fget(obj)    def __set__(self, obj, value):        if self.fset is None:            raise AttributeError(""can't set attribute"")        self.fset(obj, value)    def __delete__(self, obj):        if self.fdel is None:            raise AttributeError(""can't delete attribute"")        self.fdel(obj)    def getter(self, fget):        return type(self)(fget, self.fset, self.fdel, self.__doc__)    def setter(self, fset):        return type(self)(self.fget, fset, self.fdel, self.__doc__)    def deleter(self, fdel):        return type(self)(self.fget, self.fset, fdel, self.__doc__)"
"data_i","edited Feb 05 '17 at 01:57","
        How to write a:hover in inline CSS?
    ","I have a case where I must write inline CSS code, and I want to apply a hover style on an anchor.How can I use a:hover in inline CSS inside the HTML style attribute?E.g. you can't reliably use CSS classes in HTML emails.","Short answer: you can't.Long answer: you shouldn't. Give it a class name or an id and use stylesheets to apply the style.:hover is a pseudo-selector and, for CSS, only has meaning within the style sheet. There isn't any inline-style equivalent (as it isn't defining the selection criteria). Response to the OP's comments:See Totally Pwn CSS with Javascript for a good script on adding CSS rules dynamically. Also see Change style sheet for some of the theory on the subject.Also, don't forget, you can add links to external stylesheets if that's an option. For example,<script type=""text/javascript"">  var link = document.createElement(""link"");  link.setAttribute(""rel"",""stylesheet"");  link.setAttribute(""href"",""http://wherever.com/yourstylesheet.css"");  var head = document.getElementsByTagName(""head"")[0];  head.appendChild(link);</script>Caution: the above assumes there is a head section. "
"data_i","edited Jan 21 '21 at 10:35","
        How do I limit the number of rows returned by an Oracle query after ordering?
    ","Is there a way to make an Oracle query behave like it contains a MySQL limit clause?In MySQL, I can do this:select * from sometableorder by namelimit 20,10to get the 21st to the 30th rows (skip the first 20, give the next 10). The rows are selected after the order by, so it really starts on the 20th name alphabetically.In Oracle, the only thing people mention is the rownum pseudo-column, but it is evaluated before order by, which means this:select * from sometablewhere rownum <= 10order by namewill return a random set of ten rows ordered by name, which is not usually what I want. It also doesn't allow for specifying an offset.","You can use a subquery for this likeselect *from  ( select *   from emp   order by sal desc ) where ROWNUM <= 5;Have also a look at the topic On ROWNUM and limiting results at Oracle/AskTom for more information.Update:To limit the result with both lower and upper bounds things get a bit more bloated withselect * from ( select a.*, ROWNUM rnum from   ( <your_query_goes_here, with order by> ) a   where ROWNUM <= :MAX_ROW_TO_FETCH )where rnum  >= :MIN_ROW_TO_FETCH;(Copied from specified AskTom-article)Update 2:Starting with Oracle 12c (12.1) there is a syntax available to limit rows or start at offsets.SELECT * FROM   sometableORDER BY nameOFFSET 20 ROWS FETCH NEXT 10 ROWS ONLY;See this answer for more examples. Thanks to Krumia for the hint."
"data_i","edited Oct 15 '21 at 15:42","
        What is a race condition?
    ","When writing multithreaded applications, one of the most common problems experienced is race conditions.My questions to the community are:What is the race condition?How do you detect them?How do you handle them?Finally, how do you prevent them from occurring?","A race condition occurs when two or more threads can access shared data and they try to change it at the same time. Because the thread scheduling algorithm can swap between threads at any time, you don't know the order in which the threads will attempt to access the shared data. Therefore, the result of the change in data is dependent on the thread scheduling algorithm, i.e. both threads are ""racing"" to access/change the data. Problems often occur when one thread does a ""check-then-act"" (e.g. ""check"" if the value is X, then ""act"" to do something that depends on the value being X) and another thread does something to the value in between the ""check"" and the ""act"". E.g:if (x == 5) // The ""Check""{   y = x * 2; // The ""Act""   // If another thread changed x in between ""if (x == 5)"" and ""y = x * 2"" above,   // y will not be equal to 10.}The point being, y could be 10, or it could be anything, depending on whether another thread changed x in between the check and act. You have no real way of knowing.In order to prevent race conditions from occurring, you would typically put a lock around the shared data to ensure only one thread can access the data at a time. This would mean something like this:// Obtain lock for xif (x == 5){   y = x * 2; // Now, nothing can change x until the lock is released.               // Therefore y = 10}// release lock for x"
"data_i","edited Sep 21 '18 at 06:42","
        How can I disable the UITableView selection?
    ","When you tap a row in a UITableView, the row is highlighted and selected. Is it possible to disable this so tapping a row does nothing?","All you have to do is set the selection style on the UITableViewCell instance using either:Objective-C:cell.selectionStyle = UITableViewCellSelectionStyleNone;or[cell setSelectionStyle:UITableViewCellSelectionStyleNone];Swift 2:cell.selectionStyle = UITableViewCellSelectionStyle.NoneSwift 3 and 4.x:cell.selectionStyle = .noneFurther, make sure you either don't implement -tableView:didSelectRowAtIndexPath: in your table view delegate or explicitly exclude the cells you want to have no action if you do implement it.More info here and here"
"data_i","edited Sep 18 '18 at 18:30","
        How to merge a specific commit in Git
    ","I have forked a branch from a repository in GitHub and committed something specific to me. Now I found the original repository had a good feature which was at HEAD.I want to merge it only without previous commits. What should I do? I know how to merge all commits:git branch -b a-good-featuregit pull repository mastergit checkout mastergit merge a-good-featuregit commit -agit push","'git cherry-pick' should be your answer here.Apply the change introduced by an existing commit. Do not forget to read bdonlan's answer about the consequence of cherry-picking in this post:""Pull all commits from a branch, push specified commits to another"", where:A-----B------C \  \   Dbecomes:A-----B------C \  \   D-----C'The problem with this commit is that git considers commits to include all history before themWhere C' has a different SHA-1 ID.  Likewise, cherry picking a commit from one branch to another basically involves generating a patch, then applying it, thus losing history that way as well.This changing of commit IDs breaks git's merging functionality among other things (though if used sparingly there are heuristics that will paper over this).  More importantly though, it ignores functional dependencies - if C actually used a function defined in B, you'll never know."
"data_i","edited Mar 24 '16 at 17:25","
        What's the difference between a mock & stub?
    ","I've read various articles about mocking vs stubbing in testing, including Martin Fowler's Mocks Aren't Stubs, but still don't understand the difference.","ForewordThere are several definitions of objects, that are not real. The general term is test double. This term encompasses: dummy, fake, stub, mock.ReferenceAccording to Martin Fowler's article:Dummy objects are passed around but never actually used. Usually they are just used to fill parameter lists.Fake objects actually have working implementations, but usually take some shortcut which makes them not suitable for production (an in memory database is a good example).Stubs provide canned answers to calls made during the test, usually not responding at all to anything outside what's programmed in for the test. Stubs may also record information about calls, such as an email gateway stub that remembers the messages it 'sent', or maybe only how many messages it 'sent'.Mocks are what we are talking about here: objects pre-programmed with expectations which form a specification of the calls they are expected to receive.StyleMocks vs Stubs = Behavioral testing vs State testingPrincipleAccording to the principle of Test only one thing per test, there may be several stubs in one test, but generally there is only one mock.LifecycleTest lifecycle with stubs:Setup - Prepare object that is being tested and its stubs collaborators.Exercise - Test the functionality.Verify state - Use asserts to check object's state.Teardown - Clean up resources.Test lifecycle with mocks:Setup data - Prepare object that is being tested.Setup expectations - Prepare expectations in mock that is being used by primary object.Exercise - Test the functionality.Verify expectations - Verify that correct methods has been invoked in mock.Verify state - Use asserts to check object's state.Teardown - Clean up resources.SummaryBoth mocks and stubs testing give an answer for the question: What is the result?Testing with mocks are also interested in: How the result has been achieved?"
"data_i","edited Jul 22 '22 at 15:21","
        Reference - What does this error mean in PHP?
    ","What is this?This is a number of answers about warnings, errors, and notices you might encounter while programming PHP and have no clue how to fix them. This is also a Community Wiki, so everyone is invited to participate adding to and maintaining this list.Why is this?Questions like ""Headers already sent"" or ""Calling a member of a non-object"" pop up frequently on Stack Overflow. The root cause of those questions is always the same. So the answers to those questions typically repeat them and then show the OP which line to change in their particular case. These answers do not add any value to the site because they only apply to the OP's particular code. Other users having the same error cannot easily read the solution out of it because they are too localized. That is sad because once you understood the root cause, fixing the error is trivial. Hence, this list tries to explain the solution in a general way to apply.What should I do here?If your question has been marked as a duplicate of this one, please find your error message below and apply the fix to your code. The answers usually contain further links to investigate in case it shouldn't be clear from the general answer alone.If you want to contribute, please add your ""favorite"" error message, warning or notice, one per answer, a short description what it means (even if it is only highlighting terms to their manual page), a possible solution or debugging approach and a listing of existing Q&A that are of value. Also, feel free to improve any existing answers.The ListNothing is seen. The page is empty and white. (also known as White Page/Screen Of Death)Code doesn't run/what looks like parts of my PHP code are outputWarning: Cannot modify header information - headers already sentWarning: mysql_fetch_array() expects parameter 1 to be resource, boolean given a.k.a.Warning: mysql_fetch_array(): supplied argument is not a valid MySQL result resourceWarning: [function] expects parameter 1 to be resource, boolean givenWarning: [function]: failed to open stream: [reason]Warning: open_basedir restriction in effectWarning: Division by zeroWarning: Illegal string offset 'XXX'Warning: count(): Parameter must be an array or an object that implements CountableParse error: syntax error, unexpected '['Parse error: syntax error, unexpected T_XXXParse error:  syntax error, unexpected T_ENCAPSED_AND_WHITESPACEParse error: syntax error, unexpected T_PAAMAYIM_NEKUDOTAYIMParse error: syntax error, unexpected 'require_once' (T_REQUIRE_ONCE), expecting function (T_FUNCTION)Parse error: syntax error, unexpected T_VARIABLEFatal error: Allowed memory size of XXX bytes exhausted (tried to allocate XXX bytes)Fatal error: Maximum execution time of XX seconds exceededFatal error: Call to a member function ... on a non-object or nullFatal Error: Call to Undefined function XXXFatal Error: Cannot redeclare XXXFatal error: Can't use function return value in write contextFatal error: Declaration of AAA::BBB() must be compatible with that of CCC::BBB()'Return type of AAA::BBB() should either be compatible with CCC::BBB(), or the #[\ReturnTypeWillChange] attribute should be usedFatal error: Using $this when not in object contextFatal error: Object of class Closure could not be converted to stringFatal error: Undefined class constantFatal error: Uncaught TypeError: Argument #n must be of type x, y givenNotice: Array to string conversionNotice: Trying to get property of non-object errorNotice: Undefined variable or property""Notice: Undefined Index"", or ""Warning: Undefined array key""Notice: Undefined offset XXX [Reference]Notice: Uninitialized string offset: XXXNotice: Use of undefined constant XXX - assumed 'XXX' / Error: Undefined constant XXXMySQL: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ... at line ...Strict Standards: Non-static method [<class>::<method>] should not be called staticallyWarning: function expects parameter X to be boolean/string/integerHTTP Error 500 - Internal server errorDeprecated: Arrays and strings offset access syntax with curly braces is deprecatedAlso, see:Reference - What does this symbol mean in PHP?","Warning: Cannot modify header information - headers already sentHappens when your script tries to send an HTTP header to the client but there already was output before, which resulted in headers to be already sent to the client.This is an E_WARNING and it will not stop the script.A typical example would be a template file like this:<html>    <?php session_start(); ?>    <head><title>My Page</title></html>...The session_start() function will try to send headers with the session cookie to the client. But PHP already sent headers when it wrote the <html> element to the output stream. You'd have to move the session_start() to the top.You can solve this by going through the lines before the code triggering the Warning and check where it outputs. Move any header sending code before that code. An often overlooked output is new lines after PHP's closing ?>. It is considered a standard practice to omit ?> when it is the last thing in the file. Likewise, another common cause for this warning is when the opening <?php has an empty space, line, or invisible character before it, causing the web server to send the headers and the whitespace/newline thus when PHP starts parsing won't be able to submit any header.If your file has more than one <?php ... ?> code block in it, you should not have any spaces in between them. (Note: You might have multiple blocks if you had code that was automatically constructed)Also make sure you don't have any Byte Order Marks in your code, for example when the encoding of the script is UTF-8 with BOM.Related Questions:Headers already sent by PHPAll PHP ""Headers already sent"" Questions on StackoverflowByte Order MarkWhat PHP Functions Create Output?"
"data_i","edited Jun 13 '21 at 12:26","
        What do Clustered and Non-Clustered index actually mean?
    ","I have a limited exposure to DB and have only used DB as an application programmer. I want to know about Clustered and Non clustered indexes.I googled and what I found was :A clustered index is a special type of index that reorders  the way  records in the table are physically  stored.  Therefore table can have only  one clustered index. The leaf  nodes  of a clustered index contain the data  pages. A nonclustered index is a  special type of index in which  the  logical order of the index does not  match the physical  stored order of  the rows on disk. The leaf node of a   nonclustered index does not consist of  the data pages.  Instead, the leaf  nodes contain index rows.What I found in SO was What are the differences between a clustered and a non-clustered index?.Can someone explain this in plain English?","With a clustered index the rows are stored physically on the disk in the same order as the index. Therefore, there can be only one clustered index.With a non clustered index there is a second list that has pointers to the physical rows. You can have many non clustered indices, although each new index will increase the time it takes to write new records. It is generally faster to read from a clustered index if you want to get back all the columns. You do not have to go first to the index and then to the table.Writing to a table with a clustered index can be slower, if there is a need to rearrange the data."
"data_i","edited Jul 07 '21 at 04:50","
        How do I escape a single quote in SQL Server?
    ","I am trying to insert some text data into a table in SQL Server 9.The text includes a single quote '.How do I escape that?I tried using two single quotes, but it threw me some errors.eg. insert into my_table values('hi, my name''s tim.');","Single quotes are escaped by doubling them up, just as you've shown us in your example. The following SQL illustrates this functionality. I tested it on SQL Server 2008:DECLARE @my_table TABLE (    [value] VARCHAR(200))INSERT INTO @my_table VALUES ('hi, my name''s tim.')SELECT * FROM @my_tableResultsvalue==================hi, my name's tim."
"data_i","edited Jul 28 '11 at 17:48","
        How do I connect to a MySQL Database in Python?
    ","How do I connect to a MySQL database using a python program?","Connecting to MYSQL with Python 2 in three steps1 - SettingYou must install a MySQL driver before doing anything. Unlike PHP, Only the SQLite driver is installed by default with Python. The most used package to do so is MySQLdb but it's hard to install it using easy_install. Please note MySQLdb only supports Python 2.For Windows user, you can get an exe of MySQLdb. For Linux, this is a casual package (python-mysqldb). (You can use sudo apt-get install python-mysqldb (for debian based distros), yum install MySQL-python (for rpm-based), or dnf install python-mysql (for modern fedora distro) in command line to download.)For Mac, you can install MySQLdb using Macport.2 - UsageAfter installing, Reboot. This is not mandatory, But it will prevent me from answering 3 or 4 other questions in this post if something goes wrong. So please reboot.Then it is just like using any other package :#!/usr/bin/pythonimport MySQLdbdb = MySQLdb.connect(host=""localhost"",    # your host, usually localhost                     user=""john"",         # your username                     passwd=""megajonhy"",  # your password                     db=""jonhydb"")        # name of the data base# you must create a Cursor object. It will let#  you execute all the queries you needcur = db.cursor()# Use all the SQL you likecur.execute(""SELECT * FROM YOUR_TABLE_NAME"")# print all the first cell of all the rowsfor row in cur.fetchall():    print row[0]db.close()Of course, there are thousand of possibilities and options; this is a very basic example. You will have to look at the documentation. A good starting point.3 - More advanced usageOnce you know how it works, You may want to use an ORM to avoid writing SQL manually and manipulate your tables as they were Python objects. The most famous ORM in the Python community is SQLAlchemy. I strongly advise you to use it: your life is going to be much easier.I recently discovered another jewel in the Python world: peewee. It's a very lite ORM, really easy and fast to setup then use. It makes my day for small projects or stand alone apps, Where using big tools like SQLAlchemy or Django is overkill :import peeweefrom peewee import *db = MySQLDatabase('jonhydb', user='john', passwd='megajonhy')class Book(peewee.Model):    author = peewee.CharField()    title = peewee.TextField()    class Meta:        database = dbBook.create_table()book = Book(author=""me"", title='Peewee is cool')book.save()for book in Book.filter(author=""me""):    print book.titleThis example works out of the box. Nothing other than having peewee (pip install peewee) is required."
"data_i","edited Apr 19 '20 at 11:48","
        .gitignore for Visual Studio Projects and Solutions
    ","Which files should I include in .gitignore when using Git in conjunction with Visual Studio Solutions (.sln) and Projects?","See the official GitHub's ""Collection of useful .gitignore templates"".The .gitignore for Visual Studio can be found here:https://github.com/github/gitignore/blob/main/VisualStudio.gitignore"
"data_i","edited Nov 10 '20 at 15:55","
        What is ""Linting""?
    ","PHPLint, JSLint, and I recently came across ""you can lint your JS code on the fly"" while reading something about some IDE.So, what is ""linting""?","Linting is the process of running a program that will analyse code for potential errors.See lint on wikipedia:lint was the name originally given to a particular program that flagged some suspicious and non-portable constructs (likely to be bugs) in C language source code. The term is now applied generically to tools that flag suspicious usage in software written in any computer language."
"data_i","edited Jan 02 '20 at 18:13","
        What's the difference between utf8_general_ci and utf8_unicode_ci?
    ","Between utf8_general_ci and utf8_unicode_ci, are there any differences in terms of performance?","For those people still arriving at this question in 2020 or later, there are newer options that may be better than both of these.  For example, utf8_unicode_520_ci.All these collations are for the UTF-8 character encoding.  The differences are in how text is sorted and compared._unicode_ci and _general_ci are two different sets of rules for sorting and comparing text according to the way we expect.  Newer versions of MySQL introduce new sets of rules, too, such as _unicode_520_ci for equivalent rules based on Unicode 5.2, or the MySQL 8.x specific _0900_ai_ci for equivalent rules based on Unicode 9.0 (and with no equivalent _general_ci variant). People reading this now should probably use one of these newer collations instead of either _unicode_ci or _general_ci. The description of those older collations below is provided for interest only.MySQL is currently transitioning away from an older, flawed UTF-8 implementation.  For now, you need to use utf8mb4 instead of utf8 for the character encoding part, to ensure you are getting the fixed version.  The flawed version remains for backward compatibility, though it is being deprecated.Key differencesutf8mb4_unicode_ci is based on the official Unicode rules for universal sorting and comparison, which sorts accurately in a wide range of languages.utf8mb4_general_ci is a simplified set of sorting rules which aims to do as well as it can while taking many short-cuts designed to improve speed.  It does not follow the Unicode rules and will result in undesirable sorting or comparison in some situations, such as when using particular languages or characters.On modern servers, this performance boost will be all but negligible.  It was devised in a time when servers had a tiny fraction of the CPU performance of today's computers.Benefits of utf8mb4_unicode_ci over utf8mb4_general_ciutf8mb4_unicode_ci, which uses the Unicode rules for sorting and comparison, employs a fairly complex algorithm for correct sorting in a wide range of languages and when using a wide range of special characters. These rules need to take into account language-specific conventions; not everybody sorts their characters in what we would call 'alphabetical order'.As far as Latin (ie ""European"") languages go, there is not much difference between the Unicode sorting and the simplified utf8mb4_general_ci sorting in MySQL, but there are still a few differences:For examples, the Unicode collation sorts ""ß"" like ""ss"", and ""Œ"" like ""OE"" as people using those characters would normally want, whereas utf8mb4_general_ci sorts them as single characters (presumably like ""s"" and ""e"" respectively).Some Unicode characters are defined as ignorable, which means they shouldn't count toward the sort order and the comparison should move on to the next character instead.  utf8mb4_unicode_ci handles these properly.In non-latin languages, such as Asian languages or languages with different alphabets, there may be a lot more differences between Unicode sorting and the simplified utf8mb4_general_ci sorting.  The suitability of utf8mb4_general_ci will depend heavily on the language used.  For some languages, it'll be quite inadequate.What should you use?There is almost certainly no reason to use utf8mb4_general_ci anymore, as we have left behind the point where CPU speed is low enough that the performance difference would be important.  Your database will almost certainly be limited by other bottlenecks than this.In the past, some people recommended to use utf8mb4_general_ci except when accurate sorting was going to be important enough to justify the performance cost.  Today, that performance cost has all but disappeared, and developers are treating internationalization more seriously.There's an argument to be made that if speed is more important to you than accuracy, you may as well not do any sorting at all.  It's trivial to make an algorithm faster if you do not need it to be accurate.  So, utf8mb4_general_ci is a compromise that's probably not needed for speed reasons and probably also not suitable for accuracy reasons.One other thing I'll add is that even if you know your application only supports the English language, it may still need to deal with people's names, which can often contain characters used in other languages in which it is just as important to sort correctly.  Using the Unicode rules for everything helps add peace of mind that the very smart Unicode people have worked very hard to make sorting work properly.What the parts meanFirstly, ci is for case-insensitive sorting and comparison.  This means it's suitable for textual data, and case is not important.  The other types of collation are cs (case-sensitive) for textual data where case is important, and bin, for where the encoding needs to match, bit for bit, which is suitable for fields which are really encoded binary data (including, for example, Base64).  Case-sensitive sorting leads to some weird results and case-sensitive comparison can result in duplicate values differing only in letter case, so case-sensitive collations are falling out of favor for textual data - if case is significant to you, then otherwise ignorable punctuation and so on is probably also significant, and a binary collation might be more appropriate.Next, unicode or general refers to the specific sorting and comparison rules - in particular, the way text is normalized or compared.  There are many different sets of rules for the utf8mb4 character encoding, with unicode and general being two that attempt to work well in all possible languages rather than one specific one.  The differences between these two sets of rules are the subject of this answer.  Note that unicode uses rules from Unicode 4.0.  Recent versions of MySQL and MariaDB add the rulesets unicode_520 using rules from Unicode 5.2, and MySQL 8.x adds 0900 (dropping the ""unicode_"" part) using rules from Unicode 9.0.And lastly, utf8mb4 is of course the character encoding used internally.  In this answer I'm talking only about Unicode based encodings."
"data_i","edited Feb 05 '19 at 08:55","
        How can I develop for iPhone using a Windows development machine?
    ","Is there any way to tinker with the iPhone SDK on a Windows machine? Are there plans for an iPhone SDK version for Windows?The only other way I can think of doing this is to run a Mac VM image on a VMWare server running on Windows, although I'm not too sure how legal this is.","It's certainly possible to develop on a Windows machine, in fact, my first application was exclusively developed on the old Dell Precision I had at the time :)There are three routes;Install OSx86 (aka iATKOS / Kalyway) on a second partition/disk and dual boot.Run Mac OS X Server under VMWare (Mac OS X 10.7 (Lion) onwards, read the update below).Use a framework and/or toolset, which allows developing on Windows, like Delphi XE4 with the mac-in-cloud service, which can build without MacOS device need. This is a commercial toolset, but the component and lib support is growing.Other honorable mentions are Flutter, Xamarin and similar; which may at end need actual MacOS device for final build (but you can test on Android till then, as they're cross-platform).The first route requires modifying (or using a pre-modified) image of Leopard that can be installed on a regular PC. This is not as hard as you would think, although your success/effort ratio will depend upon how closely the hardware in your PC matches that in Mac hardware - e.g. if you're running a Core 2 Duo on an Intel Motherboard, with an NVidia graphics card you are laughing. If you're running an AMD machine or something without SSE3 it gets a little more involved.If you purchase (or already own) a version of Leopard then this is a gray area since the Leopard EULA states you may only run it on an ""Apple Labeled"" machine. As many point out if you stick an Apple sticker on your PC you're probably covered.The second option is more costly. The EULA for the workstation version of Leopard prevents it from being run under emulation and as a result, there's no support in VMWare for this. Leopard server, however, CAN be run under emulation and can be used for desktop purposes. Leopard server and VMWare are expensive, however.If you're interested in option 1) I would suggest starting at Insanelymac and reading the OSx86 sections.I do think you should consider whether the time you will invest is going to be worth the money you will save though. It was for me because I enjoy tinkering with this type of stuff and I started during the early iPhone betas, months before their App Store became available.Alternatively, you could pick up a low-spec Mac Mini from eBay. You don't need much horsepower to run the SDK and you can always sell it on later if you decide to stop development or buy a better Mac.Update: You cannot create a Mac OS X Client virtual machine for OS X 10.6 and earlier. Apple does not allow these Client OSes to be virtualized. With Mac OS X 10.7 (Lion) onwards, Apple has changed its licensing agreement in regards to virtualization. Source: VMWare KnowledgeBase"
"data_i","edited Apr 09 '16 at 14:27","
        GitHub relative link in Markdown file
    ","Is there a way to create a URL anchor, <a>, link from within a Markdown file, to another file within the same repository and branch (aka a link relative to the current branch)?For example, in the master branch I have a README.md file, which I would like do something like:# My Projectis really really cool. My Project has a subdir named myLib, see below.## myLib documentationsee documentation [here](myLib/README.md)This would allow me to link from one .md to another within the same branch and not have to worry about which branch I'm in (avoid having to do an absolute URL that includes the github.com branch name).Here is a working example of what I mean:GOTO http://github.com/rynop/testRel, link does not work.GOTO http://github.com/rynop/testRel/blob/master/README.md, link works.This is expected because at this point the starting URL is in the branch. Now how do I get it to pick up the current branch in the README.md at the root of the repository?Update: I opened an issue against GitHub for this feature request.","Update 30th, January 2013, 16 months later:GitHub Blog Post Relative links in markup files:Starting today, GitHub supports relative links in markup files.Now you can link directly between different documentation files, whether you view the documentation on GitHub itself, or locally, using a different markup renderer.You want examples of link definitions and how they work? Here's some Markdown for you.Instead of an absolute link:[a link](https://github.com/user/repo/blob/branch/other_file.md)…you can use a relative link:[a relative link](other_file.md)[a relative link](path%20with%20spaces/other_file.md)and we'll make sure it gets linked to user/repo/blob/branch/other_file.md.If you were using a workaround like [a workaround link](repo/blob/master/other_file.md), you'll have to update your documentation to use the new syntax.This also means your documentation can now easily stand on its own, without always pointing to GitHub.Marcono1234 adds in the commentsAlso useful: When the link starts with a /, it is relative to the root of the repository (regardless of whether the markdown file is nested in subdirectories)Update December 20th, 2011:The GitHub markup issue 84 is currently closed by technoweenie, with the comment:We tried adding a <base> tag for this, but it causes problems with other relative links on the site.October 12th, 2011:If you look at the raw source of the README.md of Markdown itself(!), relative paths don't seem to be supported.You will find references like:[r2h]: http://github.com/github/markup/tree/master/lib/github/commands/rest2html[r2hc]: http://github.com/github/markup/tree/master/lib/github/markups.rb#L13As noted in InvisibleWolf's answer, if the target link is a directory and it has space, then you need to use %20 for each space."
"data_i","edited Jun 26 '19 at 18:34","
        How can I sanitize user input with PHP?
    ","Is there a catchall function somewhere that works well for sanitizing user input for SQL injection and XSS attacks, while still allowing certain types of HTML tags?","It's a common misconception that user input can be filtered. PHP even has a (now deprecated) ""feature"", called magic-quotes, that builds on this idea. It's nonsense. Forget about filtering (or cleaning, or whatever people call it).What you should do, to avoid problems, is quite simple: whenever you embed a a piece of data within a foreign code, you must treat it according to the formatting rules of that code. But you must understand that such rules could be too complicated to try to follow them all manually. For example, in SQL, rules for strings, numbers and identifiers are all different. For your convenience, in most cases there is a dedicated tool for such an embedding. For example, when you need to use a PHP variable in the SQL query, you have to use a prepared statement, that will take care of all the proper formatting/treatment.Another example is HTML: If you embed strings within HTML markup, you must escape it with htmlspecialchars. This means that every single echo or print statement should use htmlspecialchars.A third example could be shell commands: If you are going to embed strings (such as arguments) to external commands, and call them with exec, then you must use escapeshellcmd and escapeshellarg.Also, a very compelling example is JSON. The rules are so numerous and complicated that you would never be able to follow them all manually. That's why you should never ever create a JSON string manually, but always use a dedicated function, json_encode() that will correctly format every bit of data.And so on and so forth ...The only case where you need to actively filter data, is if you're accepting preformatted input. For example, if you let your users post HTML markup, that you plan to display on the site. However, you should be wise to avoid this at all cost, since no matter how well you filter it, it will always be a potential security hole."
"data_i","edited Jun 23 '21 at 09:14","
        Using Node.js as a simple web server
    ","I want to run a very simple HTTP server. Every GET request to example.com should get index.html served to it but as a regular HTML page (i.e., same experience as when you read normal web pages).Using the code below, I can read the content of index.html. How do I serve index.html as a regular web page?var http = require('http');var fs = require('fs');var index = fs.readFileSync('index.html');http.createServer(function (req, res) {  res.writeHead(200, {'Content-Type': 'text/plain'});  res.end(index);}).listen(9615);One suggestion below is complicated and requires me to write a get line for each resource (CSS, JavaScript, images) file I want to use. How can I serve a single HTML page with some images, CSS and JavaScript?","Simplest Node.js server is just:$ npm install http-server -gNow you can run a server via the following commands:$ cd MyApp$ http-serverIf you're using NPM 5.2.0 or newer, you can use http-server without installing it with npx. This isn't recommended for use in production but is a great way to quickly get a server running on localhost.$ npx http-serverOr, you can try this, which opens your web browser and enables CORS requests:$ http-server -o --corsFor more options, check out the documentation for http-server on GitHub, or run:$ http-server --helpLots of other nice features and brain-dead-simple deployment to NodeJitsu.Feature ForksOf course, you can easily top up the features with your own fork.  You might find it's already been done in one of the existing 800+ forks of this project:https://github.com/nodeapps/http-server/networkLight Server: An Auto Refreshing AlternativeA nice alternative to http-server is light-server. It supports file watching and auto-refreshing and many other features.$ npm install -g light-server $ light-serverAdd to your directory context menu in Windows Explorer reg.exe add HKCR\Directory\shell\LightServer\command /ve /t REG_EXPAND_SZ /f /d ""\""C:\nodejs\light-server.cmd\"" \""-o\"" \""-s\"" \""%V\""""Simple JSON REST serverIf you need to create a simple REST server for a prototype project then json-server might be what you're looking for.Auto Refreshing EditorsMost web page editors and IDE tools now include a web server that will watch your source files and auto refresh your web page when they change.I use Live Server with Visual Studio Code.The open source text editor Brackets also includes a NodeJS static web server. Just open any HTML file in Brackets, press ""Live Preview"" and it starts a static server and opens your browser at the page. The browser will auto refresh whenever you edit and save the HTML file. This especially useful when testing adaptive web sites. Open your HTML page on multiple browsers/window sizes/devices. Save your HTML page and instantly see if your adaptive stuff is working as they all auto refresh.Web / SPA / PWA / Mobile / Desktop / Browser Ext Web DevelopersSome SPA frameworks include a built in version of the Webpack DevServer that can detect source file changes and trigger an incremental rebuild and patch (called hot reloading) of your SPA or PWA web app. Here's a few popular SPA frameworks that can do this.VueJS DevelopersFor VueJS developers, a favorite is Quasar Framework that includes the Webpack DevServer out of the box with switches to support server-side rendering (SSR) and proxy rules to cure your CORS issues. It includes a large number of optimized components designed to adapt for both Mobile and Desktop. These allows you to build one app for ALL platforms (SPA, SPA+SSR, PWA, PWA+SSR, Cordova and Capacitor Mobile AppStore apps, Electron Desktop Node+VueJS apps and even Browser extensions).Another popular one is NuxtJS that also supports static HTML/CSS code generation as well as SSR or no-SSR build modes with plugins for other UI component suites.React Framework DevelopersReactJS developers can also setup hot reloading.Cordova/Capacitor + Ionic Framework DevelopersIconic is a mobile only hybrid component framework that now supports VueJS, React and Angular development.  A local server with auto refresh features is baked into the ionic tool. Just run ionic serve from your app folder. Even better ... ionic serve --lab to view auto-refreshing side by side views of both iOS and Android."
"data_i","asked Jun 12 '17 at 07:13","
        What's the difference between implementation, api and compile in Gradle?
    ","After updating to Android Studio 3.0 and creating a new project, I noticed that in build.gradle there is a new way to add new dependencies instead of compile there is implementation and instead of testCompile there is testImplementation.Example: implementation 'com.android.support:appcompat-v7:25.0.0' testImplementation 'junit:junit:4.12'instead of compile 'com.android.support:appcompat-v7:25.0.0' testCompile 'junit:junit:4.12'What's the difference between them and what should I be using?","tl;drJust replace:compile with implementation (if you don't need transitivity) or api (if you need transitivity)testCompile with testImplementationdebugCompile with debugImplementationandroidTestCompile with androidTestImplementationcompileOnly is still valid. It was added in 3.0 to replace provided and not compile. (provided introduced when Gradle didn't have a configuration name for that use-case and named it after Maven's provided scope.)It is one of the breaking changes coming with Android Gradle plugin 3.0 that Google announced at IO17.The compile configuration is now deprecated and should be replaced by implementation or apiFrom the Gradle documentation:dependencies {    api 'commons-httpclient:commons-httpclient:3.1'    implementation 'org.apache.commons:commons-lang3:3.5'}Dependencies appearing in the api configurations will betransitively exposed to consumers of the library, and as such willappear on the compile classpath of consumers.Dependencies found in the implementation configuration will, on theother hand, not be exposed to consumers, and therefore not leak intothe consumers' compile classpath. This comes with several benefits:dependencies do not leak into the compile classpath of consumers anymore, so you will never accidentally depend on a transitivedependencyfaster compilation thanks to reduced classpath sizeless recompilations when implementation dependencies change: consumers would not need to be recompiledcleaner publishing: when used in conjunction with the new maven-publish plugin, Java libraries produce POM files thatdistinguish exactly between what is required to compile against thelibrary and what is required to use the library at runtime (in otherwords, don't mix what is needed to compile the library itself and whatis needed to compile against the library).The compile configuration still exists, but should not be used as it will not offer the guarantees that the api and implementation configurations provide.Note: if you are only using a library in your app module -the common case- you won't notice any difference.you will only see the difference if you have a complex project with modules depending on each other, or you are creating a library."
"data_i","edited Mar 27 '22 at 21:04","
        What is a mixin and why is it useful?
    ","In Programming Python, Mark Lutz mentions the term mixin. I am from a C/C++/C# background and I have not heard the term before. What is a mixin?Reading between the lines of this example (which I have linked to because it is quite long), I am presuming it is a case of using multiple inheritance to extend a class as opposed to proper subclassing. Is this right?Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition?What separates a mixin from multiple inheritance? Is it just a matter of semantics?","A mixin is a special kind of multiple inheritance.  There are two main situations where mixins are used:You want to provide a lot of optional features for a class.You want to use one particular feature in a lot of different classes.For an example of number one, consider werkzeug's request and response system.  I can make a plain old request object by saying:from werkzeug import BaseRequestclass Request(BaseRequest):    passIf I want to add accept header support, I would make thatfrom werkzeug import BaseRequest, AcceptMixinclass Request(AcceptMixin, BaseRequest):    passIf I wanted to make a request object that supports accept headers, etags, authentication, and user agent support, I could do this:from werkzeug import BaseRequest, AcceptMixin, ETagRequestMixin, UserAgentMixin, AuthenticationMixinclass Request(AcceptMixin, ETagRequestMixin, UserAgentMixin, AuthenticationMixin, BaseRequest):    passThe difference is subtle, but in the above examples, the mixin classes weren't made to stand on their own.  In more traditional multiple inheritance, the AuthenticationMixin (for example) would probably be something more like Authenticator.  That is, the class would probably be designed to stand on its own."
"data_i","edited Feb 28 '21 at 16:26","
        How to install Java 8 on Mac
    ","Editors note:  This question was asked in 2014, and the answers may be outdated.I want to do some programming with the latest JavaFX, which requires Java 8. I'm using IntelliJ 13 CE and Mac OS X 9 Mavericks. I ran Oracle's Java 8 installer, and the files look like they ended up at/Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdkbut previous versions are at/System/Library/Java/JavaFrameworks/jdk1.6....Not sure why the latest installer puts this in /Library instead of /System/Library (nor what the difference is). But /usr/libexec/java_home doesn't find 1.8, so all the posts I've found on how to set your current java version don't work. I've tried adding a symbolic link to make it look like 1.8 is in the /System/Library... path, but it doesn't help. /usr/libexec/java_home -V still only lists the old Java 1.6.Ironically, the ""Java"" control panel under System Preferences shows only Java 1.8!Why doesn't Oracle's installer put it where it really goes? And how can I work around this problem?","Oracle has a poor record for making it easy to install and configure Java, but using Homebrew, the latest OpenJDK (Java 14) can be installed with:brew install --cask adoptopenjdk8For the many use cases depending on an older version (commonly Java 8), the AdoptOpenJDK project makes it possible with an extra step.brew tap adoptopenjdk/openjdkbrew install --cask adoptopenjdk8Existing users of Homebrew may encounter Error: Cask adoptopenjdk8 exists in multiple taps due to prior workarounds with different instructions. This can be solved by fully specifying the location with brew install --cask adoptopenjdk/openjdk/adoptopenjdk8."
"data_i","edited Aug 15 '20 at 17:17","
        How to sort an array of integers correctly
    ","Trying to get the highest and lowest value from an array that I know will contain only integers seems to be harder than I thought.var numArray = [140000, 104, 99];numArray = numArray.sort();console.log(numArray)I'd expect this to show 99, 104, 140000. Instead it shows 104, 140000, 99. So it seems the sort is handling the values as strings.Is there a way to get the sort function to actually sort on integer value?","By default, the sort method sorts elements alphabetically. To sort numerically just add a new method which handles numeric sorts (sortNumber, shown below) -var numArray = [140000, 104, 99];numArray.sort(function(a, b) {  return a - b;});console.log(numArray);Documentation:Mozilla Array.prototype.sort() recommends this compare function for arrays that don't contain Infinity or NaN.  (Because Infinity - Infinity is NaN, not 0).Also examples of sorting objects by key."
"data_i","edited Feb 22 '22 at 15:13","
        Retrieving the last record in each group - MySQL
    ","There is a table messages that contains data as shown below:Id   Name   Other_Columns-------------------------1    A       A_data_12    A       A_data_23    A       A_data_34    B       B_data_15    B       B_data_26    C       C_data_1If I run a query select * from messages group by name, I will get the result as:1    A       A_data_14    B       B_data_16    C       C_data_1What query will return the following result?3    A       A_data_35    B       B_data_26    C       C_data_1That is, the last record in each group should be returned.At present, this is the query that I use:SELECT  *FROM (SELECT  *FROM messagesORDER BY id DESC) AS xGROUP BY nameBut this looks highly inefficient. Any other ways to achieve the same result?","MySQL 8.0 now supports windowing functions, like almost all popular SQL implementations. With this standard syntax, we can write greatest-n-per-group queries:WITH ranked_messages AS (  SELECT m.*, ROW_NUMBER() OVER (PARTITION BY name ORDER BY id DESC) AS rn  FROM messages AS m)SELECT * FROM ranked_messages WHERE rn = 1;This and other approaches to finding groupwise maximal rows are illustrated in the MySQL manual.Below is the original answer I wrote for this question in 2009:I write the solution this way:SELECT m1.*FROM messages m1 LEFT JOIN messages m2 ON (m1.name = m2.name AND m1.id < m2.id)WHERE m2.id IS NULL;Regarding performance, one solution or the other can be better, depending on the nature of your data. So you should test both queries and use the one that is better at performance given your database.For example, I have a copy of the StackOverflow August data dump.  I'll use that for benchmarking.  There are 1,114,357 rows in the Posts table.  This is running on MySQL 5.0.75 on my Macbook Pro 2.40GHz.I'll write a query to find the most recent post for a given user ID (mine).First using the technique shown by @Eric with the GROUP BY in a subquery:SELECT p1.postidFROM Posts p1INNER JOIN (SELECT pi.owneruserid, MAX(pi.postid) AS maxpostid            FROM Posts pi GROUP BY pi.owneruserid) p2  ON (p1.postid = p2.maxpostid)WHERE p1.owneruserid = 20860;1 row in set (1 min 17.89 sec)Even the EXPLAIN analysis takes over 16 seconds:+----+-------------+------------+--------+----------------------------+-------------+---------+--------------+---------+-------------+| id | select_type | table      | type   | possible_keys              | key         | key_len | ref          | rows    | Extra       |+----+-------------+------------+--------+----------------------------+-------------+---------+--------------+---------+-------------+|  1 | PRIMARY     | <derived2> | ALL    | NULL                       | NULL        | NULL    | NULL         |   76756 |             | |  1 | PRIMARY     | p1         | eq_ref | PRIMARY,PostId,OwnerUserId | PRIMARY     | 8       | p2.maxpostid |       1 | Using where | |  2 | DERIVED     | pi         | index  | NULL                       | OwnerUserId | 8       | NULL         | 1151268 | Using index | +----+-------------+------------+--------+----------------------------+-------------+---------+--------------+---------+-------------+3 rows in set (16.09 sec)Now produce the same query result using my technique with LEFT JOIN:SELECT p1.postidFROM Posts p1 LEFT JOIN posts p2  ON (p1.owneruserid = p2.owneruserid AND p1.postid < p2.postid)WHERE p2.postid IS NULL AND p1.owneruserid = 20860;1 row in set (0.28 sec)The EXPLAIN analysis shows that both tables are able to use their indexes:+----+-------------+-------+------+----------------------------+-------------+---------+-------+------+--------------------------------------+| id | select_type | table | type | possible_keys              | key         | key_len | ref   | rows | Extra                                |+----+-------------+-------+------+----------------------------+-------------+---------+-------+------+--------------------------------------+|  1 | SIMPLE      | p1    | ref  | OwnerUserId                | OwnerUserId | 8       | const | 1384 | Using index                          | |  1 | SIMPLE      | p2    | ref  | PRIMARY,PostId,OwnerUserId | OwnerUserId | 8       | const | 1384 | Using where; Using index; Not exists | +----+-------------+-------+------+----------------------------+-------------+---------+-------+------+--------------------------------------+2 rows in set (0.00 sec)Here's the DDL for my Posts table:CREATE TABLE `posts` (  `PostId` bigint(20) unsigned NOT NULL auto_increment,  `PostTypeId` bigint(20) unsigned NOT NULL,  `AcceptedAnswerId` bigint(20) unsigned default NULL,  `ParentId` bigint(20) unsigned default NULL,  `CreationDate` datetime NOT NULL,  `Score` int(11) NOT NULL default '0',  `ViewCount` int(11) NOT NULL default '0',  `Body` text NOT NULL,  `OwnerUserId` bigint(20) unsigned NOT NULL,  `OwnerDisplayName` varchar(40) default NULL,  `LastEditorUserId` bigint(20) unsigned default NULL,  `LastEditDate` datetime default NULL,  `LastActivityDate` datetime default NULL,  `Title` varchar(250) NOT NULL default '',  `Tags` varchar(150) NOT NULL default '',  `AnswerCount` int(11) NOT NULL default '0',  `CommentCount` int(11) NOT NULL default '0',  `FavoriteCount` int(11) NOT NULL default '0',  `ClosedDate` datetime default NULL,  PRIMARY KEY  (`PostId`),  UNIQUE KEY `PostId` (`PostId`),  KEY `PostTypeId` (`PostTypeId`),  KEY `AcceptedAnswerId` (`AcceptedAnswerId`),  KEY `OwnerUserId` (`OwnerUserId`),  KEY `LastEditorUserId` (`LastEditorUserId`),  KEY `ParentId` (`ParentId`),  CONSTRAINT `posts_ibfk_1` FOREIGN KEY (`PostTypeId`) REFERENCES `posttypes` (`PostTypeId`)) ENGINE=InnoDB;Note to commenters: If you want another benchmark with a different version of MySQL, a different dataset, or different table design, feel free to do it yourself. I have shown the technique above. Stack Overflow is here to show you how to do software development work, not to do all the work for you."
"data_i","edited Jul 29 '17 at 18:17","
        How to make Twitter Bootstrap menu dropdown on hover rather than click
    ","I'd like to have my Bootstrap menu automatically drop down on hover, rather than having to click the menu title. I'd also like to lose the little arrows next to the menu titles.","To get the menu to automatically drop on hover then this can achieved using basic CSS. You need to work out the selector to the hidden menu option and then set it to display as block when the appropriate li tag is hovered over. Taking the example from the twitter bootstrap page, the selector would be as follows:ul.nav li.dropdown:hover > ul.dropdown-menu {    display: block;    }However, if you are using Bootstrap's responsive features, you will not want this functionality on a collapsed navbar (on smaller screens). To avoid this, wrap the code above in a media query:@media (min-width: 979px) {  ul.nav li.dropdown:hover > ul.dropdown-menu {    display: block;  }}To hide the arrow (caret) this is done in different ways depending on whether you are using Twitter Bootstrap version 2 and lower or version 3:Bootstrap 3To remove the caret in version 3 you just need to remove the HTML <b class=""caret""></b> from the .dropdown-toggle anchor element:<a class=""dropdown-toggle"" data-toggle=""dropdown"" href=""#"">    Dropdown    <b class=""caret""></b>    <-- remove this line</a>Bootstrap 2 & lowerTo remove the caret in version 2 you need a little more insight into CSS and I suggest looking at how the :after pseudo element works in more detail. To get you started on your way to understanding, to target and remove the arrows in the twitter bootstrap example, you would use the following CSS selector and code:a.menu:after, .dropdown-toggle:after {    content: none;}It will work in your favour if you look further into how these work and not just use the answers that I have given you.Thanks to @CocaAkat for pointing out that we were missing the "">"" child combinator to prevent sub menus being shown on the parent hover"
"data_i","edited May 22 '22 at 05:40","
        How to remove the space between inline/inline-block elements?
    ","There will be a 4 pixel wide space between these span elements:span {  display: inline-block;  width: 100px;  background-color: palevioletred;}<p>  <span> Foo </span>  <span> Bar </span></p>Fiddle DemoI understand that I could get rid of that space by removing the white-space between the span elements in the HTML:<p>  <span> Foo </span><span> Bar </span></p>I'm Looking for a CSS solution that doesn't involve:Altering the HTML.JavaScript.","Alternatively, you should now use flexbox to achieve many of the layouts that you may previously have used inline-block for: https://css-tricks.com/snippets/css/a-guide-to-flexbox/Since this answer has become rather popular, I'm rewriting it significantly.Let's not forget the actual question that was asked:How to remove the space between inline-block elements? I was hopingfor a CSS solution that doesn't require the HTML source code to betampered with. Can this issue be solved with CSS alone?It is possible to solve this problem with CSS alone, but there are no completely robust CSS fixes.The solution I had in my initial answer was to add font-size: 0 to the parent element, and then declare a sensible font-size on the children.http://jsfiddle.net/thirtydot/dGHFV/1361/This works in recent versions of all modern browsers. It works in IE8. It does not work in Safari 5, but it does work in Safari 6. Safari 5 is nearly a dead browser (0.33%, August 2015).Most of the possible issues with relative font sizes are not complicated to fix.However, while this is a reasonable solution if you specifically need a CSS only fix, it's not what I recommend if you're free to change your HTML (as most of us are).This is what I, as a reasonably experienced web developer, actually do to solve this problem:<p>    <span>Foo</span><span>Bar</span></p>Yes, that's right. I remove the whitespace in the HTML between the inline-block elements.It's easy. It's simple. It works everywhere. It's the pragmatic solution.You do sometimes have to carefully consider where whitespace will come from. Will appending another element with JavaScript add whitespace? No, not if you do it properly.Let's go on a magical journey of different ways to remove the whitespace, with some new HTML:<ul>    <li>Item 1</li>    <li>Item 2</li>    <li>Item 3</li></ul>You can do this, as I usually do: <ul>     <li>Item 1</li><li>Item 2</li><li>Item 3</li> </ul>http://jsfiddle.net/thirtydot/dGHFV/1362/Or, this: <ul>     <li>Item 1</li     ><li>Item 2</li     ><li>Item 3</li> </ul>Or, use comments: <ul>     <li>Item 1</li><!--     --><li>Item 2</li><!--     --><li>Item 3</li> </ul>Or, if you are using using PHP or similar: <ul>     <li>Item 1</li><?     ?><li>Item 2</li><?     ?><li>Item 3</li> </ul>Or, you can even skip certain closing tags entirely (all browsers are fine with this): <ul>     <li>Item 1     <li>Item 2     <li>Item 3 </ul>Now that I've gone and bored you to death with ""one thousand different ways to remove whitespace, by thirtydot"", hopefully you've forgotten all about font-size: 0."
"data_i","edited Dec 29 '21 at 13:16","
        Which version of PostgreSQL am I running?
    ","I'm in a corporate environment (running Debian Linux) and didn't install it myself. I access the databases using Navicat or phpPgAdmin (if that helps). I also don't have shell access to the server running the database.","Run this query from PostgreSQL:SELECT version();"
"data_i","edited Mar 22 '18 at 06:44","
        Dealing with ""java.lang.OutOfMemoryError: PermGen space"" error
    ","Recently I ran into this error in my web application:java.lang.OutOfMemoryError: PermGen spaceIt's a typical Hibernate/JPA + IceFaces/JSF application running on Tomcat 6 and JDK 1.6.Apparently this can occur after redeploying an application a few times.What causes it and what can be done to avoid it?How do I fix the problem?","The solution was to add these flags to JVM command line when Tomcat is started:-XX:+CMSClassUnloadingEnabled -XX:+CMSPermGenSweepingEnabledYou can do that by shutting down the tomcat service, then going into the Tomcat/bin directory and running tomcat6w.exe. Under the ""Java"" tab, add the arguments to the ""Java Options"" box. Click ""OK"" and then restart the service.If you get an error the specified service does not exist as an installed service you should run:tomcat6w //ES//servicenamewhere servicename is the name of the server as viewed in services.mscSource: orx's comment on Eric's Agile Answers."
"data_i","edited Jun 11 '20 at 08:49","
        Group by in LINQ
    ","Let's suppose if we have a class like:class Person {     internal int PersonID;     internal string car; }I have a list of this class: List<Person> persons;And this list can have multiple instances with same PersonIDs, for example: persons[0] = new Person { PersonID = 1, car = ""Ferrari"" }; persons[1] = new Person { PersonID = 1, car = ""BMW""     }; persons[2] = new Person { PersonID = 2, car = ""Audi""    }; Is there a way I can group by PersonID and get the list of all the cars he has? For example, the expected result would be class Result {    int PersonID;   List<string> cars; }So after grouping, I would get: results[0].PersonID = 1; List<string> cars = results[0].cars; result[1].PersonID = 2; List<string> cars = result[1].cars;From what I have done so far: var results = from p in persons              group p by p.PersonID into g              select new { PersonID = g.Key, // this is where I am not sure what to doCould someone please point me in the right direction? ","Absolutely - you basically want:var results = from p in persons              group p.car by p.PersonId into g              select new { PersonId = g.Key, Cars = g.ToList() };Or as a non-query expression:var results = persons.GroupBy(    p => p.PersonId,     p => p.car,    (key, g) => new { PersonId = key, Cars = g.ToList() });Basically the contents of the group (when viewed as an IEnumerable<T>) is a sequence of whatever values were in the projection (p.car in this case) present for the given key.For more on how GroupBy works, see my Edulinq post on the topic.(I've renamed PersonID to PersonId in the above, to follow .NET naming conventions.)Alternatively, you could use a Lookup:var carsByPersonId = persons.ToLookup(p => p.PersonId, p => p.car);You can then get the cars for each person very easily:// This will be an empty sequence for any personId not in the lookupvar carsForPerson = carsByPersonId[personId];"
"data_i","edited May 24 '22 at 15:16","
        Secure hash and salt for PHP passwords
    ","It is currently said that MD5 is partially unsafe. Taking this into consideration, I'd like to know which mechanism to use for password protection.This question, Is “double hashing” a password less secure than just hashing it once? suggests that hashing multiple times may be a good idea, whereas How to implement password protection for individual files? suggests using salt.I'm using PHP. I want a safe and fast password encryption system. Hashing a password a million times may be safer, but also slower. How to achieve a good balance between speed and safety? Also, I'd prefer the result to have a constant number of characters.The hashing mechanism must be available in PHPIt must be safeIt can use salt (in this case, are all salts equally good? Is there any way to generate good salts?)Also, should I store two fields in the database (one using MD5 and another one using SHA, for example)? Would it make it safer or unsafer?In case I wasn't clear enough, I want to know which hashing function(s) to use and how to pick a good salt in order to have a safe and fast password protection mechanism.Related questions that don't quite cover my question:What's the difference between SHA and MD5 in PHPSimple Password EncryptionSecure methods of storing keys, passwords for asp.netHow would you implement salted passwords in Tomcat 5.5","DISCLAIMER: This answer was written in 2008.Since then, PHP has given us password_hash and password_verify and, since their introduction, they are the recommended password hashing & checking method.The theory of the answer is still a good read though.TL;DRDon'tsDon't limit what characters users can enter for passwords. Only idiots do this.Don't limit the length of a password. If your users want a sentence with supercalifragilisticexpialidocious in it, don't prevent them from using it.Don't strip or escape HTML and special characters in the password.Never store your user's password in plain-text.Never email a password to your user except when they have lost theirs, and you sent a temporary one.Never, ever log passwords in any manner.Never hash passwords with SHA1 or MD5 or even SHA256! Modern crackers can exceed 60 and 180 billion hashes/second (respectively).Don't mix bcrypt and with the raw output of hash(), either use hex output or base64_encode it. (This applies to any input that may have a rogue \0 in it, which can seriously weaken security.)DosUse scrypt when you can; bcrypt if you cannot.Use PBKDF2 if you cannot use either bcrypt or scrypt, with SHA2 hashes.Reset everyone's passwords when the database is compromised.Implement a reasonable 8-10 character minimum length, plus require at least 1 upper case letter, 1 lower case letter, a number, and a symbol. This will improve the entropy of the password, in turn making it harder to crack. (See the ""What makes a good password?"" section for some debate.)Why hash passwords anyway?The objective behind hashing passwords is simple: preventing malicious access to user accounts by compromising the database. So the goal of password hashing is to deter a hacker or cracker by costing them too much time or money to calculate the plain-text passwords. And time/cost are the best deterrents in your arsenal.Another reason that you want a good, robust hash on a user accounts is to give you enough time to change all the passwords in the system. If your database is compromised you will need enough time to at least lock the system down, if not change every password in the database.Jeremiah Grossman, CTO of Whitehat Security, stated on White Hat Security blog after a recent password recovery that required brute-force breaking of his password protection:Interestingly, in living out this nightmare, I learned A LOT I didn’t know about password cracking, storage, and complexity. I’ve come to appreciate why password storage is ever so much more important than password complexity. If you don’t know how your password is stored, then all you really can depend upon is complexity. This might be common knowledge to password and crypto pros, but for the average InfoSec or Web Security expert, I highly doubt it.(Emphasis mine.)What makes a good password anyway?Entropy. (Not that I fully subscribe to Randall's viewpoint.)In short, entropy is how much variation is within the password. When a password is only lowercase roman letters, that's only 26 characters. That isn't much variation. Alpha-numeric passwords are better, with 36 characters. But allowing upper and lower case, with symbols, is roughly 96 characters. That's a lot better than just letters. One problem is, to make our passwords memorable we insert patterns—which reduces entropy. Oops!Password entropy is approximated easily. Using the full range of ascii characters (roughly 96 typeable characters) yields an entropy of 6.6 per character, which at 8 characters for a password is still too low (52.679 bits of entropy) for future security. But the good news is: longer passwords, and passwords with unicode characters, really increase the entropy of a password and make it harder to crack.There's a longer discussion of password entropy on the Crypto StackExchange site. A good Google search will also turn up a lot of results.In the comments I talked with @popnoodles, who pointed out that enforcing a password policy of X length with X many letters, numbers, symbols, etc, can actually reduce entropy by making the password scheme more predictable. I do agree. Randomess, as truly random as possible, is always the safest but least memorable solution.So far as I've been able to tell, making the world's best password is a Catch-22. Either its not memorable, too predictable, too short, too many unicode characters (hard to type on a Windows/Mobile device), too long, etc. No password is truly good enough for our purposes, so we must protect them as though they were in Fort Knox.Best practicesBcrypt and scrypt are the current best practices. Scrypt will be better than bcrypt in time, but it hasn't seen adoption as a standard by Linux/Unix or by webservers, and hasn't had in-depth reviews of its algorithm posted yet. But still, the future of the algorithm does look promising. If you are working with Ruby there is an scrypt gem that will help you out, and Node.js now has its own scrypt package. You can use Scrypt in PHP either via the Scrypt extension or the Libsodium extension (both are available in PECL).I highly suggest reading the documentation for the crypt function if you want to understand how to use bcrypt, or finding yourself a good wrapper or use something like PHPASS for a more legacy implementation. I recommend a minimum of 12 rounds of bcrypt, if not 15 to 18.I changed my mind about using bcrypt when I learned that bcrypt only uses blowfish's key schedule, with a variable cost mechanism. The latter lets you increase the cost to brute-force a password by increasing blowfish's already expensive key schedule.Average practicesI almost can't imagine this situation anymore. PHPASS supports PHP 3.0.18 through 5.3, so it is usable on almost every installation imaginable—and should be used if you don't know for certain that your environment supports bcrypt.But suppose that you cannot use bcrypt or PHPASS at all. What then?Try an implementation of PDKBF2 with the maximum number of rounds that your environment/application/user-perception can tolerate. The lowest number I'd recommend is 2500 rounds. Also, make sure to use hash_hmac() if it is available to make the operation harder to reproduce.Future PracticesComing in PHP 5.5 is a full password protection library that abstracts away any pains of working with bcrypt. While most of us are stuck with PHP 5.2 and 5.3 in most common environments, especially shared hosts, @ircmaxell has built a compatibility layer for the coming API that is backward compatible to PHP 5.3.7.Cryptography Recap & DisclaimerThe computational power required to actually crack a hashed password doesn't exist. The only way for computers to ""crack"" a password is to recreate it and simulate the hashing algorithm used to secure it. The speed of the hash is linearly related to its ability to be brute-forced. Worse still, most hash algorithms can be easily parallelized to perform even faster. This is why costly schemes like bcrypt and scrypt are so important.You cannot possibly foresee all threats or avenues of attack, and so you must make your best effort to protect your users up front. If you do not, then you might even miss the fact that you were attacked until it's too late... and you're liable. To avoid that situation, act paranoid to begin with. Attack your own software (internally) and attempt to steal user credentials, or modify other user's accounts or access their data. If you don't test the security of your system, then you cannot blame anyone but yourself.Lastly: I am not a cryptographer. Whatever I've said is my opinion, but I happen to think it's based on good ol' common sense ... and lots of reading. Remember, be as paranoid as possible, make things as hard to intrude as possible, and then, if you are still worried, contact a white-hat hacker or cryptographer to see what they say about your code/system."
"data_i","edited Dec 11 '19 at 12:22","
        How do I use reflection to call a generic method?
    ","What's the best way to call a generic method when the type parameter isn't known at compile time, but instead is obtained dynamically at runtime?Consider the following sample code - inside the Example() method, what's the most concise way to invoke GenericMethod<T>() using the Type stored in the myType variable?public class Sample{    public void Example(string typeName)    {        Type myType = FindType(typeName);        // What goes here to call GenericMethod<T>()?        GenericMethod<myType>(); // This doesn't work        // What changes to call StaticMethod<T>()?        Sample.StaticMethod<myType>(); // This also doesn't work    }    public void GenericMethod<T>()    {        // ...    }    public static void StaticMethod<T>()    {        //...    }}","You need to use reflection to get the method to start with, then ""construct"" it by supplying type arguments with MakeGenericMethod:MethodInfo method = typeof(Sample).GetMethod(nameof(Sample.GenericMethod));MethodInfo generic = method.MakeGenericMethod(myType);generic.Invoke(this, null);For a static method, pass null as the first argument to Invoke. That's nothing to do with generic methods - it's just normal reflection.As noted, a lot of this is simpler as of C# 4 using dynamic - if you can use type inference, of course. It doesn't help in cases where type inference isn't available, such as the exact example in the question."
"data_i","edited Apr 09 '22 at 09:46","
        How to get line count of a large file cheaply in Python?
    ","How do I get a line count of a large file in the most memory- and time-efficient manner?def file_len(filename):    with open(filename) as f:        for i, _ in enumerate(f):            pass    return i + 1","One line, probably pretty fast:num_lines = sum(1 for line in open('myfile.txt'))"
"data_i","edited May 29 '18 at 23:45","
        How do I run two commands in one line in Windows CMD?
    ","I want to run two commands in a Windows CMD console.In Linux I would do it like thistouch thisfile ; ls -lstrhHow is it done on Windows?","Like this on all Microsoft OSes since 2000, and still good today:dir & echo fooIf you want the second command to execute only if the first exited successfully:dir && echo fooThe single ampersand (&) syntax to execute multiple commands on one line goes back to Windows XP, Windows 2000, and some earlier NT versions. (4.0 at least, according to one commenter here.)There are quite a few other points about this that you'll find scrolling down this page.Historical data follows, for those who may find it educational.Prior to that, the && syntax was only a feature of the shell replacement 4DOS before that feature was added to the Microsoft command interpreter.In Windows 95, 98 and ME, you'd use the pipe character instead:dir | echo fooIn MS-DOS 5.0 and later, through some earlier Windows and NT versions of the command interpreter, the (undocumented) command separator was character 20 (Ctrl+T) which I'll represent with ^T here.dir ^T echo foo"
"data_i","edited Apr 09 '22 at 10:16","
        What does the 'b' character do in front of a string literal?
    ","Apparently, the following is the valid syntax:b'The string'I would like to know:What does this b character in front of the string mean?What are the effects of using it?What are appropriate situations to use it?I found a related question right here on SO, but that question is about PHP though, and it states the b is used to indicate the string is binary, as opposed to Unicode, which was needed for code to be compatible from version of PHP < 6, when migrating to PHP 6. I don't think this applies to Python.I did find this documentation on the Python site about using a u character in the same syntax to specify a string as Unicode. Unfortunately, it doesn't mention the b character anywhere in that document.Also, just out of curiosity, are there more symbols than the b and u that do other things?","Python 3.x makes a clear distinction between the types:str = '...' literals = a sequence of Unicode characters (Latin-1, UCS-2 or UCS-4, depending on the widest character in the string)bytes = b'...' literals = a sequence of octets (integers between 0 and 255)If you're familiar with:Java or C#, think of str as String and bytes as byte[];SQL, think of str as NVARCHAR and bytes as BINARY or BLOB;Windows registry, think of str as REG_SZ and bytes as REG_BINARY.If you're familiar with C(++), then forget everything you've learned about char and strings, because a character is not a byte.  That idea is long obsolete.You use str when you want to represent text.print('שלום עולם')You use bytes when you want to represent low-level binary data like structs.NaN = struct.unpack('>d', b'\xff\xf8\x00\x00\x00\x00\x00\x00')[0]You can encode a str to a bytes object.>>> '\uFEFF'.encode('UTF-8')b'\xef\xbb\xbf'And you can decode a bytes into a str.>>> b'\xE2\x82\xAC'.decode('UTF-8')'€'But you can't freely mix the two types.>>> b'\xEF\xBB\xBF' + 'Text with a UTF-8 BOM'Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>TypeError: can't concat bytes to strThe b'...' notation is somewhat confusing in that it allows the bytes 0x01-0x7F to be specified with ASCII characters instead of hex numbers.>>> b'A' == b'\x41'TrueBut I must emphasize, a character is not a byte.>>> 'A' == b'A'FalseIn Python 2.xPre-3.0 versions of Python lacked this kind of distinction between text and binary data.  Instead, there was:unicode = u'...' literals = sequence of Unicode characters = 3.x strstr = '...' literals = sequences of confounded bytes/charactersUsually text, encoded in some unspecified encoding.But also used to represent binary data like struct.pack output.In order to ease the 2.x-to-3.x transition, the b'...' literal syntax was backported to Python 2.6, in order to allow distinguishing binary strings (which should be bytes in 3.x) from text strings (which should be str in 3.x).  The b prefix does nothing in 2.x, but tells the 2to3 script not to convert it to a Unicode string in 3.x.So yes, b'...' literals in Python have the same purpose that they do in PHP.Also, just out of curiosity, are theremore symbols than the b and u that doother things?The r prefix creates a raw string (e.g., r'\t' is a backslash + t instead of a tab), and triple quotes '''...''' or """"""..."""""" allow multi-line string literals."
"data_i","edited Jan 26 '22 at 00:48","
        Using Node.js require vs. ES6 import/export
    ","In a project I am collaborating on, we have two choices on which module system we can use:Importing modules using require, and exporting using module.exports and exports.foo.Importing modules using ES6 import, and exporting using ES6 exportAre there any performance benefits to using one over the other? Is there anything else that we should know if we were to use ES6 modules over Node ones?","UpdateSince Node v12 (April 2019), support for ES modules is enabled by default, and since Node v15 (October 2020) it's stable (see here). Files including node modules must either end in .mjs or the nearest package.json file must contain ""type"": ""module"". The Node documentation has a ton more information, also about interop between CommonJS and ES modules.Performance-wise there is always the chance that newer features are not as well optimized as existing features. However, since module files are only evaluated once, the performance aspect can probably be ignored. In the end you have to run benchmarks to get a definite answer anyway.ES modules can be loaded dynamically via the import() function. Unlike require, this returns a promise.Previous answerAre there any performance benefits to using one over the other?Keep in mind that there is no JavaScript engine yet that natively supports ES6 modules. You said yourself that you are using Babel. Babel converts import and export declaration to CommonJS (require/module.exports) by default anyway. So even if you use ES6 module syntax, you will be using CommonJS under the hood if you run the code in Node.There are technical differences between CommonJS and ES6 modules, e.g. CommonJS allows you to load modules dynamically. ES6 doesn't allow this, but there is an API in development for that.Since ES6 modules are part of the standard, I would use them."
"data_i","edited Apr 09 '21 at 16:27","
        How do I copy a version of a single file from one Git branch to another?
    ","I've got two branches that are fully merged together.However, after the merge is done, I realise that one file has been messed up by the merge (someone else did an auto-format, gah), and it would just be easier to change to the new version in the other branch, and then reinsert my one line change after bringing it over into my branch.So what's the easiest way in Git to do this?","Run this from the branch where you want the file to end up:git checkout otherbranch myfile.txtGeneral formulas:git checkout <commit_hash> <relative_path_to_file_or_dir>git checkout <remote_name>/<branch_name> <file_or_dir>Some notes (from comments):Using the commit hash, you can pull files from any commitThis works for files and directoriesOverwrites the file myfile.txt and mydirWildcards don't work, but relative paths doMultiple paths can be specifiedAn alternative:git show commit_id:path/to/file > path/to/file"
"data_i","edited Sep 05 '19 at 19:44","
        Putting a simple if-then-else statement on one line
    ","I'm just getting into Python and I really like the terseness of the syntax. However, is there an easier way of writing an if-then-else statement so it fits on one line?For example:if count == N:    count = 0else:    count = N + 1Is there a simpler way of writing this? I mean, in Objective-C I would write this as:count = count == N ? 0 : count + 1;Is there something similar for Python?UpdateI know that in this instance I can use count == (count + 1) % N. I'm asking about the general syntax.","That's more specifically a ternary operator expression than an if-then, here's the python syntaxvalue_when_true if condition else value_when_falseBetter Example: (thanks Mr. Burns)'Yes' if fruit == 'Apple' else 'No'Now with assignment and contrast with if syntaxfruit = 'Apple'isApple = True if fruit == 'Apple' else Falsevsfruit = 'Apple'isApple = Falseif fruit == 'Apple' : isApple = True"
"data_i","edited Jul 01 '15 at 01:14","
        What is HEAD in Git?
    ","You see the Git documentation saying things likeThe branch must be fully merged in HEAD.But what is Git HEAD exactly?","You can think of the HEAD as the ""current branch"". When you switch branches with git checkout, the HEAD revision changes to point to the tip of the new branch.You can see what HEAD points to by doing:cat .git/HEADIn my case, the output is:$ cat .git/HEADref: refs/heads/masterIt is possible for HEAD to refer to a specific revision that is not associated with a branch name. This situation is called a detached HEAD."
"data_i","edited Jan 06 '20 at 06:40","
        How to reformat JSON in Notepad++?
    ","I need Notepad++ to take a json string from this{""menu"": {""id"": ""file"",""value"": ""File"",""popup"": {""menuitem"": [{""value"": ""New"", ""onclick"": ""CreateNewDoc()""},{""value"": ""Open"", ""onclick"": ""OpenDoc()""},{""value"": ""Close"", ""onclick"": ""CloseDoc()""}]}}}to this...{""menu"": {  ""id"": ""file"",  ""value"": ""File"",  ""popup"": {    ""menuitem"": [      {""value"": ""New"", ""onclick"": ""CreateNewDoc()""},      {""value"": ""Open"", ""onclick"": ""OpenDoc()""},      {""value"": ""Close"", ""onclick"": ""CloseDoc()""}    ]  }}}I looked around at all the TextFX options but couldn't find anything that worked.","Update:As of Notepad++ v7.6, use Plugin Admin to install JSTool per this answer INSTALLDownload it from http://sourceforge.net/projects/jsminnpp/ and copy JSMinNpp.dll to plugin directory of Notepad++. Or you can just install ""JSTool"" from Plugin Manager in Notepad++.New Notepad++ install and where did PluginManager go? See How to view Plugin Manager in Notepad++ {  ""menu"" : {    ""id"" : ""file"",    ""value"" : ""File"",    ""popup"" : {      ""menuitem"" : [{      ""value"" : ""New"",          ""onclick"" : ""CreateNewDoc()""        }, {          ""value"" : ""Open"",          ""onclick"" : ""OpenDoc()""        }, {          ""value"" : ""Close"",          ""onclick"" : ""CloseDoc()""        }      ]    }  }}Tip: Select the code you want to reformat, then Plugins | JSTool | JSFormat."
"data_i","edited Aug 20 '19 at 18:13","
        Call one constructor from another
    ","I have two constructors which feed values to readonly fields.public class Sample{    public Sample(string theIntAsString)    {        int i = int.Parse(theIntAsString);        _intField = i;    }    public Sample(int theInt) => _intField = theInt;    public int IntProperty    => _intField;    private readonly int _intField;}One constructor receives the values directly, and the other does some calculation and obtains the values, then sets the fields.Now here's the catch:I don't want to duplicate thesetting code. In this case, just onefield is set but of course there maywell be more than one.To make the fields readonly, I needto set them from the constructor, soI can't ""extract"" the shared code toa utility function.I don't know how to call oneconstructor from another.Any ideas?","Like this:public Sample(string str) : this(int.Parse(str)) { }"
"data_i","edited Apr 29 '19 at 18:00","
        Are HTTPS URLs encrypted?
    ","Are all URLs encrypted when using TLS/SSL (HTTPS) encryption? I would like to know because I want all URL data to be hidden when using TLS/SSL (HTTPS).If TLS/SSL gives you total URL encryption then I don't have to worry about hiding confidential information from URLs.","Yes, the SSL connection is between the TCP layer and the HTTP layer.  The client and server first establish a secure encrypted TCP connection (via the SSL/TLS protocol) and then the client will send the HTTP request (GET, POST, DELETE...) over that encrypted TCP connection.Note however (as also noted in the comments) that the domain name part of the URL is sent in clear text during the first part of the TLS negotiation. So, the domain name of the server can be sniffed. But not the rest of the URL."
"data_i","edited Apr 19 '20 at 11:32","
        How do servlets work? Instantiation, sessions, shared variables and multithreading
    ","Suppose, I have a webserver which holds numerous servlets. For information passing among those servlets I am setting session and instance variables.Now, if 2 or more users send request to this server then what happens to the session variables?Will they all be common for all the users or they will be different for each user?If they are different, then how was the server able to differentiate between different users?One more similar question, if there are n users accessing a particular servlet, then this servlet gets instantiated only the first time the first user accessed it or does it get instantiated for all the users separately?In other words, what happens to the instance variables?","ServletContextWhen the servlet container (like Apache Tomcat) starts up, it will deploy and load all its web applications. When a web application is loaded, the servlet container creates the ServletContext once and keeps it in the server's memory. The web app's web.xml and all of included web-fragment.xml files is parsed, and each <servlet>, <filter> and <listener> found (or each class annotated with @WebServlet, @WebFilter and @WebListener respectively) will be instantiated once and be kept in the server's memory as well, registred via the ServletContext. For each instantiated filter, its init() method is invoked with a new FilterConfig argument which in turn contains the involved ServletContext.When a Servlet has a <servlet><load-on-startup> or @WebServlet(loadOnStartup) value greater than 0, then its init() method is also invoked during startup with a new ServletConfig argument which in turn contains the involved ServletContext. Those servlets are initialized in the same order specified by that value (1 is 1st, 2 is 2nd, etc). If the same value is specified for more than one servlet, then each of those servlets is loaded in the same order as they appear in the web.xml, web-fragment.xml, or @WebServlet classloading. In the event the ""load-on-startup"" value is absent, the init() method will be invoked whenever the HTTP request hits that servlet for the very first time.When the servlet container is finished with all of the above described initialization steps, then the ServletContextListener#contextInitialized() will be invoked with a ServletContextEvent argument which in turn contains the involved ServletContext. This will allow the developer the opportunity to programmatically register yet another Servlet, Filter or Listener.When the servlet container shuts down, it unloads all web applications, invokes the destroy() method of all its initialized servlets and filters, and all Servlet, Filter and Listener instances registered via the ServletContext are trashed. Finally the ServletContextListener#contextDestroyed() will be invoked and the ServletContext itself will be trashed.HttpServletRequest and HttpServletResponseThe servlet container is attached to a web server that listens for HTTP requests on a certain port number (port 8080 is usually used during development and port 80 in production). When a client (e.g. user with a web browser, or programmatically using URLConnection) sends an HTTP request, the servlet container creates new HttpServletRequest and HttpServletResponse objects and passes them through any defined Filter in the chain and, eventually, the Servlet instance.In the case of filters, the doFilter() method is invoked. When the servlet container's code calls chain.doFilter(request, response), the request and response continue on to the next filter, or hit the servlet if there are no remaining filters.In the case of servlets, the service() method is invoked. By default, this method determines which one of the doXxx() methods to invoke based off of  request.getMethod(). If the determined method is absent from the servlet, then an HTTP 405 error is returned in the response.The request object provides access to all of the information about the HTTP request, such as its URL, headers, query string and body. The response object provides the ability to control and send the HTTP response the way you want by, for instance, allowing you to set the headers and the body (usually with generated HTML content from a JSP file). When the HTTP response is committed and finished, both the request and response objects are recycled and made available for reuse.HttpSessionWhen a client visits the webapp for the first time and/or the HttpSession is obtained for the first time via request.getSession(), the servlet container creates a new HttpSession object, generates a long and unique ID (which you can get by session.getId()), and stores it in the server's memory. The servlet container also sets a Cookie in the Set-Cookie header of the HTTP response with JSESSIONID as its name and the unique session ID as its value.As per the HTTP cookie specification (a contract any decent web browser and web server must adhere to), the client (the web browser) is required to send this cookie back in subsequent requests in the Cookie header for as long as the cookie is valid (i.e. the unique ID must refer to an unexpired session and the domain and path are correct). Using your browser's built-in HTTP traffic monitor, you can verify that the cookie is valid (press F12 in Chrome / Firefox 23+ / IE9+, and check the Net/Network tab). The servlet container will check the Cookie header of every incoming HTTP request for the presence of the cookie with the name JSESSIONID and use its value (the session ID) to get the associated HttpSession from server's memory.The HttpSession stays alive until it has been idle (i.e. not used in a request) for more than the timeout value specified in <session-timeout>, a setting in web.xml. The timeout value defaults to 30 minutes. So, when the client doesn't visit the web app for longer than the time specified, the servlet container trashes the session. Every subsequent request, even with the cookie specified, will not have access to the same session anymore; the servlet container will create a new session.On the client side, the session cookie stays alive for as long as the browser instance is running. So, if the client closes the browser instance (all tabs/windows), then the session is trashed on the client's side. In a new browser instance, the cookie associated with the session wouldn't exist, so it would no longer be sent. This causes an entirely new HttpSession to be created, with an entirely new session cookie being used.In a nutshellThe ServletContext lives for as long as the web app lives. It is shared among all requests in all sessions.The HttpSession lives for as long as the client is interacting with the web app with the same browser instance, and the session hasn't timed out at the server side. It is shared among all requests in the same session.The HttpServletRequest and HttpServletResponse live from the time the servlet receives an HTTP request from the client, until the complete response (the web page) has arrived. It is not shared elsewhere.All Servlet, Filter and Listener instances live as long as the web app lives. They are shared among all requests in all sessions.Any attribute that is defined in ServletContext, HttpServletRequest and HttpSession will live as long as the object in question lives. The object itself represents the ""scope"" in bean management frameworks such as JSF, CDI, Spring, etc. Those frameworks store their scoped beans as an attribute of its closest matching scope.Thread SafetyThat said, your major concern is possibly thread safety. You should now know that servlets and filters are shared among all requests. That's the nice thing about Java, it's multithreaded and different threads (read: HTTP requests) can make use of the same instance. It would otherwise be too expensive to recreate, init() and destroy() them for every single request.You should also realize that you should never assign any request or session scoped data as an instance variable of a servlet or filter. It will be shared among all other requests in other sessions. That's not thread-safe! The below example illustrates this:public class ExampleServlet extends HttpServlet {    private Object thisIsNOTThreadSafe;    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {        Object thisIsThreadSafe;        thisIsNOTThreadSafe = request.getParameter(""foo""); // BAD!! Shared among all requests!        thisIsThreadSafe = request.getParameter(""foo""); // OK, this is thread safe.    } }See also:What is the difference between JSF, Servlet and JSP?Best option for Session management in JavaDifference between / and /* in servlet mapping url patterndoGet and doPost in ServletsServlet seems to handle multiple concurrent browser requests synchronouslyWhy Servlets are not thread Safe?"
"data_i","edited Apr 09 '22 at 09:49","
        How to get the ASCII value of a character
    ","How do I get the ASCII value of a character as an int in Python?","From here:The function ord() gets the int valueof the char. And in case you want toconvert back after playing with thenumber, function chr() does the trick.>>> ord('a')97>>> chr(97)'a'>>> chr(ord('a') + 3)'d'>>>In Python 2, there was also the unichr function, returning the Unicode character whose ordinal is the unichr argument:>>> unichr(97)u'a'>>> unichr(1234)u'\u04d2'In Python 3 you can use chr instead of unichr.ord() - Python 3.6.5rc1 documentationord() - Python 2.7.14 documentation"
"data_i","edited Jun 28 '21 at 12:11","
        Which @NotNull Java annotation should I use?
    ","I'm looking to make my code more readable as well as use tooling like IDE code inspection and/or static code analysis (FindBugs and Sonar) to avoid NullPointerExceptions.  Many of the tools seem incompatible with each others' @NotNull/@NonNull/@Nonnull annotation and listing all of them in my code would be terrible to read.  Any suggestions of which one is the 'best'?  Here is the list of equivalent annotations I've found:javax.validation.constraints.NotNullCreated for runtime validation, not static analysis.documentationedu.umd.cs.findbugs.annotations.NonNullUsed by FindBugs (dead project) and its successor SpotBugs static analysis and therefore Sonar (now Sonarqube)FindBugs documentation, SpotBugs documentationjavax.annotation.NonnullThis might work with FindBugs too, but JSR-305 is inactive. (See also: What is the status of JSR 305?)sourceorg.jetbrains.annotations.NotNullUsed by IntelliJ IDEA IDE for static analysis.documentationlombok.NonNullUsed to control code generation in Project Lombok.Placeholder annotation since there is no standard.source,documentationandroidx.annotation.NonNullMarker annotation available in Android, provided by annotation packagedocumentationorg.eclipse.jdt.annotation.NonNullUsed by Eclipse for static code analysisdocumentation","Since JSR 305 (whose goal was to standardize @NonNull and @Nullable) has been dormant for several years, I'm afraid there is no good answer. All we can do is to find a pragmatic solution and mine is as follows:SyntaxFrom a purely stylistic standpoint I would like to avoid any reference to IDE, framework or any toolkit except Java itself.This rules out:android.support.annotationedu.umd.cs.findbugs.annotationsorg.eclipse.jdt.annotationorg.jetbrains.annotationsorg.checkerframework.checker.nullness.quallombok.NonNullWhich leaves us with either javax.validation.constraints or javax.annotation.The former comes with JEE. If this is better than javax.annotation, which  might come eventually with JSE or never at all, is a matter of debate.I personally prefer javax.annotation because I wouldn't like the JEE dependency.This leaves us withjavax.annotationwhich is also the shortest one.There is only one syntax which would even be better: java.annotation.Nullable. As other packages graduatedfrom javax to java in the past, the javax.annotation wouldbe a step in the right direction.ImplementationI was hoping that they all have basically the same trivial implementation,but a detailed analysis showed that this is not true.First for the similarities:The @NonNull annotations all have the linepublic @interface NonNull {}except fororg.jetbrains.annotations which calls it @NotNull and has a trivial implementationjavax.annotation which has a longer implementationjavax.validation.constraints which also calls it @NotNull and has an implementationThe @Nullable annotations all have the linepublic @interface Nullable {}except for (again) the org.jetbrains.annotations with their trivial implementation.For the differences:A striking one is thatjavax.annotationjavax.validation.constraintsorg.checkerframework.checker.nullness.qualall have runtime annotations (@Retention(RUNTIME)), whileandroid.support.annotationedu.umd.cs.findbugs.annotationsorg.eclipse.jdt.annotationorg.jetbrains.annotationsare only compile time (@Retention(CLASS)).As described in this SO answer the impact of runtime annotationsis smaller than one might think, but they have the benefitof enabling tools to do runtime checks in addition to thecompile time ones.Another important difference is where in the code the annotations can be used.There are two different approaches. Some packages use JLS 9.6.4.1 style contexts. The following table gives an overview:PackageFIELDMETHODPARAMETERLOCAL_VARIABLEandroid.support.annotation✔️✔️✔️edu.umd.cs.findbugs.annotations✔️✔️✔️✔️org.jetbrains.annotation✔️✔️✔️✔️lombok✔️✔️✔️✔️javax.validation.constraints✔️✔️✔️org.eclipse.jdt.annotation, javax.annotation and org.checkerframework.checker.nullness.qual use the contexts defined inJLS 4.11, which is in my opinion the right way to do it.This leaves us withjavax.annotationorg.checkerframework.checker.nullness.qualin this round.CodeTo help you to compare further details yourself I list the code of every annotation below.To make comparison easier I removed comments, imports and the @Documented annotation.(they all had @Documented except for the classes from the Android package).I reordered the lines and @Target fields and normalized the qualifications.package android.support.annotation;@Retention(CLASS)@Target({FIELD, METHOD, PARAMETER})public @interface NonNull {}package edu.umd.cs.findbugs.annotations;@Retention(CLASS)@Target({FIELD, METHOD, PARAMETER, LOCAL_VARIABLE})public @interface NonNull {}package org.eclipse.jdt.annotation;@Retention(CLASS)@Target({ TYPE_USE })public @interface NonNull {}package org.jetbrains.annotations;@Retention(CLASS)@Target({FIELD, METHOD, PARAMETER, LOCAL_VARIABLE})public @interface NotNull {String value() default """";}package javax.annotation;@TypeQualifier@Retention(RUNTIME)public @interface Nonnull {    When when() default When.ALWAYS;    static class Checker implements TypeQualifierValidator<Nonnull> {        public When forConstantValue(Nonnull qualifierqualifierArgument,                Object value) {            if (value == null)                return When.NEVER;            return When.ALWAYS;        }    }}package org.checkerframework.checker.nullness.qual;@Retention(RUNTIME)@Target({TYPE_USE, TYPE_PARAMETER})@SubtypeOf(MonotonicNonNull.class)@ImplicitFor(    types = {        TypeKind.PACKAGE,        TypeKind.INT,        TypeKind.BOOLEAN,        TypeKind.CHAR,        TypeKind.DOUBLE,        TypeKind.FLOAT,        TypeKind.LONG,        TypeKind.SHORT,        TypeKind.BYTE    },    literals = {LiteralKind.STRING})@DefaultQualifierInHierarchy@DefaultFor({TypeUseLocation.EXCEPTION_PARAMETER})@DefaultInUncheckedCodeFor({TypeUseLocation.PARAMETER, TypeUseLocation.LOWER_BOUND})public @interface NonNull {}For completeness, here are the @Nullable implementations:package android.support.annotation;@Retention(CLASS)@Target({METHOD, PARAMETER, FIELD})public @interface Nullable {}package edu.umd.cs.findbugs.annotations;@Target({FIELD, METHOD, PARAMETER, LOCAL_VARIABLE})@Retention(CLASS)public @interface Nullable {}package org.eclipse.jdt.annotation;@Retention(CLASS)@Target({ TYPE_USE })public @interface Nullable {}package org.jetbrains.annotations;@Retention(CLASS)@Target({FIELD, METHOD, PARAMETER, LOCAL_VARIABLE})public @interface Nullable {String value() default """";}package javax.annotation;@TypeQualifierNickname@Nonnull(when = When.UNKNOWN)@Retention(RUNTIME)public @interface Nullable {}package org.checkerframework.checker.nullness.qual;@Retention(RUNTIME)@Target({TYPE_USE, TYPE_PARAMETER})@SubtypeOf({})@ImplicitFor(    literals = {LiteralKind.NULL},    typeNames = {java.lang.Void.class})@DefaultInUncheckedCodeFor({TypeUseLocation.RETURN, TypeUseLocation.UPPER_BOUND})public @interface Nullable {}The following two packages have no @Nullable, so I list them separately; Lombok has a pretty boring @NonNull.In javax.validation.constraints the @NonNull is actually a @NotNulland it has a longish implementation.package lombok;@Retention(CLASS)@Target({FIELD, METHOD, PARAMETER, LOCAL_VARIABLE})public @interface NonNull {}package javax.validation.constraints;@Retention(RUNTIME)@Target({ FIELD, METHOD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER })@Constraint(validatedBy = {})public @interface NotNull {    String message() default ""{javax.validation.constraints.NotNull.message}"";    Class<?>[] groups() default { };    Class<? extends Payload>[] payload() default {};    @Target({ METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER })    @Retention(RUNTIME)    @Documented    @interface List {        NotNull[] value();    }}SupportFrom my experience, javax.annotation is at least supported by Eclipse and the Checker Framework out of the box.SummaryMy ideal annotation would be the java.annotation syntax with the Checker Framework implementation.If you don't intend to use the Checker Framework the javax.annotation (JSR-305) is still your best bet for the time being.If you are willing to buy into the Checker Framework just usetheir org.checkerframework.checker.nullness.qual.Sourcesandroid.support.annotation from android-5.1.1_r1.jaredu.umd.cs.findbugs.annotations from findbugs-annotations-1.0.0.jarorg.eclipse.jdt.annotation from org.eclipse.jdt.annotation_2.1.0.v20160418-1457.jarorg.jetbrains.annotations from jetbrains-annotations-13.0.jarjavax.annotation from gwt-dev-2.5.1-sources.jarorg.checkerframework.checker.nullness.qual from checker-framework-2.1.9.ziplombok from lombok commit f6da35e4c4f3305ecd1b415e2ab1b9ef8a9120b4javax.validation.constraints from validation-api-1.0.0.GA-sources.jar"
"data_i","edited Oct 30 '19 at 08:46","
        How to list branches that contain a given commit?
    ","How can I query git to find out which branches contain a given commit? gitk will usually list the branches, unless there are too many, in which case it just says ""many (38)"" or something like that. I need to know the full list, or at least whether certain branches contain the commit.","From the git-branch manual page: git branch --contains <commit>Only list branches which contain the specified commit (HEAD if not specified). Implies --list. git branch -r --contains <commit>Lists remote tracking branches as well (as mentioned in user3941992's answer below) that is ""local branches that have a direct relationship to a remote branch"".As noted by Carl Walsh, this applies only to the default refspecfetch = +refs/heads/*:refs/remotes/origin/*If you need to include other ref namespace (pull request, Gerrit, ...), you need to add that new refspec, and fetch again:git config --add remote.origin.fetch ""+refs/pull/*/head:refs/remotes/origin/pr/*""git fetchgit branch -r --contains <commit>See also this git ready article.The --contains tag will figure out if a certain commit has been brought in yet into your branch. Perhaps you’ve got a commit SHA from a patch you thought you had applied, or you just want to check if commit for your favorite open source project that reduces memory usage by 75% is in yet.$ git log -1 testscommit d590f2ac0635ec0053c4a7377bd929943d475297Author: Nick Quaranto <nick@quaran.to>Date:   Wed Apr 1 20:38:59 2009 -0400    Green all around, finally.$ git branch --contains d590f2  tests* masterNote: if the commit is on a remote tracking branch, add the -a option.(as MichielB comments below)git branch -a --contains <commit>MatrixFrog comments that it only shows which branches contain that exact commit.If you want to know which branches contain an ""equivalent"" commit (i.e. which branches have cherry-picked that commit) that's git cherry:Because git cherry compares the changeset rather than the commit id (sha1), you can use git cherry to find out if a commit you made locally has been applied <upstream> under a different commit id.For example, this will happen if you’re feeding patches <upstream> via email rather than pushing or pulling commits directly.           __*__*__*__*__> <upstream>          /fork-point          \__+__+__-__+__+__-__+__> <head>(Here, the commits marked '-' wouldn't show up with git cherry, meaning they are already present in <upstream>.)"
"data_i","edited Jan 21 '17 at 21:15","
        Is quitting an application frowned upon?
    ","Moving on in my attempt to learn Android, I just read the following:Question: Does the user have a choice to kill the application   unless we put a menu option in to kill it? If no such option exists,   how does the user terminate the application? Answer: (Romain Guy): The user doesn't, the system handles this automatically. That's what the activity lifecycle (especially onPause/onStop/onDestroy) is for. No matter what you do, do not put a ""quit"" or ""exit"" application button. It is useless with Android's application model. This is also contrary to how core applications work. Hehe, for every step I take in the Android world I run into some sort of problem =(Apparently, you cannot quit an application in Android (but the Android system can very well totally destroy your app whenever it feels like it). What's up with that? I am starting to think that it's impossible to write an app that functions as a ""normal app"" - that the user can quit the app when he/she decides to do so. That is not something that should be relied upon the OS to do.The application I am trying to create is not an application for the Android Market. It is not an application for ""wide use"" by the general public, it is a business app that is going to be used in a very narrow business field.I was actually really looking forward to developing for the Android platform, since it addresses a lot of issues that exist in Windows Mobile and .NET. However, the last week has been somewhat of a turnoff for me... I hope I don't have to abandon Android, but it doesn't look very good right now =(Is there a way for me to really quit the application?","This will eventually get to your question, but I first want to address a number of issues you raise in your various comments to the various answers already given at the time of this writing. I have no intention of changing your mind -- rather, these are here for others who come to read this post in the future.The point is that I cannot allow forAndroid to determine when my app isgoing to be terminated. that must bethe choice of the user.Millions of people are perfectly happy with the model where the environment closes up the application as needed. Those users simply don't think about ""terminating"" the Android app, any more than they think about ""terminating"" a Web page or ""terminating"" a thermostat.iPhone users are much the same way, in that pressing the iPhone button does not necessarily ""feel"" like the app was terminated since many iPhone apps pick up where the user left off, even if the app really was shut down (since iPhone only allows one third-party app at a time, at present).As I said above, there is a lot ofthings going on in my app (data beingPUSHed to the device, lists with tasksthat always should be there, etc.).I don't know what ""lists with tasks that always should be there"" means, but the ""data being PUSHed to the device"" is a pleasant fiction and should not be done by activity in any case. Use a scheduled task (via AlarmManager) to update your data for maximum reliability.Our users log in and can't be doingthat every time they get a phone calland Android decides to kill the app.There are many iPhone and Android applications that deal with this. Usually, it is because they hold onto login credentials, rather than forcing users to log in every time manually.For example, we want to check updateswhen exiting the applicationThat is a mistake on any operating system. For all you know, the reason your application is being ""exited"" is because the OS is shutting down, and then your update process will fail mid-stream. Generally, that's not a good thing. Either check updates on start or check updates totally asynchronously (e.g., via a scheduled task), never on exit.Some comments suggest that hitting theback button does not kill the app atall (see link in my question above).Pressing the BACK button does not ""kill the app"". It finishes the activity that was on-screen when the user pressed the BACK button.It should only terminate when theusers want to terminate it - neverever any other way. If you can't writeapps that behave like that in Android,then I think that Android can't be usedfor writing real apps =(Then neither can Web applications. Or WebOS, if I understand their model correctly (haven't had a chance to play with one yet). In all of those, users don't ""terminate"" anything -- they just leave. iPhone is a bit different, in that it only presently allows one thing to run at a time (with a few exceptions), and so the act of leaving implies a fairly immediate termination of the app.Is there a way for me to really quitthe application?As everybody else told you, users (via BACK) or your code (via finish()) can close up your currently-running activity. Users generally don't need anything else, for properly-written applications, any more than they need a ""quit"" option for using Web applications.No two application environments are the same, by definition. This means that you can see trends in environments as new ones arise and others get buried.For example, there is a growing movement to try to eliminate the notion of the ""file"". Most Web applications don't force users to think of files. iPhone apps typically don't force users to think of files. Android apps generally don't force users to think of files. And so on.Similarly, there is a growing movement to try to eliminate the notion of ""terminating"" an app. Most Web applications don't force the user to log out, but rather implicitly log the user out after a period of inactivity. Same thing with Android, and to a lesser extent, iPhone (and possibly WebOS).This requires more emphasis on application design, focusing on business goals, and not sticking with an implementation model tied to a previous application environment. Developers who lack the time or inclination to do this will get frustrated with newer environments that break their existing mental model. This is not the fault of either environment, any more than it is the fault of a mountain for storms flowing around it rather than through it.For example, some development environments, like Hypercard and Smalltalk, had the application and the development tools co-mingled in one setup. This concept did not catch on much, outside of language extensions to apps (e.g., VBA in Excel, Lisp in AutoCAD). Developers who came up with mental models that presumed the existence of development tools in the app itself, therefore, either had to change their model or limit themselves to environments where their model would hold true.So, when you write:Along with other messy things Idiscovered, I think that developingour app for Android is not going tohappen.That would appear to be for the best, for you, for right now. Similarly, I would counsel you against attempting to port your application to the Web, since some of the same problems you have reported with Android you will find in Web applications as well (e.g., no ""termination""). Or, conversely, someday if you do port your app to the Web, you may find that the Web application's flow may be a better match for Android, and you can revisit an Android port at that time."
"data_i","edited Jul 15 '19 at 23:35","
        How to overlay one div over another div
    ","I need assistance with overlaying one individual div over another individual div.My code looks like this:<div class=""navi""></div><div id=""infoi"">    <img src=""info_icon2.png"" height=""20"" width=""32""/></div>Unfortunately I cannot nest the div#infoi or the img, inside the first div.navi.It has to be two separate divs as shown, but I need to know how I could place the div#infoi over the div.navi and to the right most side and centered on top of the div.navi.","#container {  width: 100px;  height: 100px;  position: relative;}#navi,#infoi {  width: 100%;  height: 100%;  position: absolute;  top: 0;  left: 0;}#infoi {  z-index: 10;}<div id=""container"">  <div id=""navi"">a</div>  <div id=""infoi"">    <img src=""https://appharbor.com/assets/images/stackoverflow-logo.png"" height=""20"" width=""32"" />b  </div></div>I would suggest learning about position: relative and child elements with position: absolute."
"data_i","edited Mar 30 '21 at 14:20","
        How to perform an integer division, and separately get the remainder, in JavaScript?
    ","In JavaScript, how do I get:The whole number of times a given integer goes into another?The remainder?","For some number y and some divisor x compute the quotient (quotient)[1] and remainder (remainder) as:const quotient = Math.floor(y/x);const remainder = y % x;Example:const quotient = Math.floor(13/3); // => 4 => the times 3 fits into 13  const remainder = 13 % 3;          // => 1[1] The integer number resulting from the division of one number by another"
"data_i","edited Dec 23 '19 at 13:32","
        How can I customize the tab-to-space conversion factor?
    ","How do I customize the tab-to-space conversion factor when using Visual Studio Code?For instance, right now in HTML it appears to produce two spaces per press of TAB, but in TypeScript it produces 4.","By default, Visual Studio Code will try to guess your indentation options depending on the file you open.You can turn off indentation guessing via ""editor.detectIndentation"": false.You can customize this easily via these three settings for Windows in menu File → Preferences → User Settings and for Mac in menu Code → Preferences → Settings or ⌘,:// The number of spaces a tab is equal to. This setting is overridden// based on the file contents when `editor.detectIndentation` is true.""editor.tabSize"": 4,// Insert spaces when pressing Tab. This setting is overriden// based on the file contents when `editor.detectIndentation` is true.""editor.insertSpaces"": true,// When opening a file, `editor.tabSize` and `editor.insertSpaces`// will be detected based on the file contents. Set to false to keep// the values you've explicitly set, above.""editor.detectIndentation"": false"
"data_i","edited Jul 03 '19 at 04:50","
        Serializing to JSON in jQuery
    ","I need to serialize an object to JSON. I'm using jQuery. Is there a ""standard"" way to do this?My specific situation: I have an array defined as shown below:var countries = new Array();countries[0] = 'ga';countries[1] = 'cd';...and I need to turn this into a string to pass to $.ajax() like this:$.ajax({    type: ""POST"",    url: ""Concessions.aspx/GetConcessions"",    data: ""{'countries':['ga','cd']}"",...","JSON-js - JSON in JavaScript.To convert an object to a string, use JSON.stringify:var json_text = JSON.stringify(your_object, null, 2);To convert a JSON string to object, use JSON.parse:var your_object = JSON.parse(json_text);It was recently recommended by John Resig:...PLEASE start migrating  your JSON-using applications over to  Crockford's json2.js. It is fully  compatible with the ECMAScript 5  specification and gracefully degrades  if a native (faster!) implementation  exists.In fact, I just landed a change in jQuery yesterday that utilizes the  JSON.parse method if it exists, now  that it has been completely specified.I tend to trust what he says on JavaScript matters :)All modern browsers (and many older ones which aren't ancient) support the JSON object natively. The current version of Crockford's JSON library will only define JSON.stringify and JSON.parse if they're not already defined, leaving any browser native implementation intact."
"data_i","edited Apr 19 '20 at 11:18","
        Android SDK installation doesn't find JDK
    ","I'm trying to install the Android SDK on my Windows 7 x64 System.  jdk-6u23-windows-x64.exe is installed, but the Android SDK setup refuses to proceed because it doesn't find the JDK installation.Is this a known issue? And is there a solution?","Press Back when you get the notification and then Next. This time it will find the JDK. "
"data_i","edited Jan 10 '20 at 01:45","
        How to call shell commands from Ruby
    ","How do I call shell commands from inside of a Ruby program? How do I then get output from these commands back into Ruby?","This explanation is based on a commented Ruby script from a friend of mine. If you want to improve the script, feel free to update it at the link.First, note that when Ruby calls out to a shell, it typically calls /bin/sh, not Bash. Some Bash syntax is not supported by /bin/sh on all systems.Here are ways to execute a shell script:cmd = ""echo 'hi'"" # Sample string that can be usedKernel#` , commonly called backticks – `cmd`This is like many other languages, including Bash, PHP, and Perl.Returns the result (i.e. standard output) of the shell command.Docs: http://ruby-doc.org/core/Kernel.html#method-i-60value = `echo 'hi'`value = `#{cmd}`Built-in syntax, %x( cmd )Following the x character is a delimiter, which can be any character.If the delimiter is one of the characters (, [, {, or <,the literal consists of the characters up to the matching closing delimiter,taking account of nested delimiter pairs. For all other delimiters, theliteral comprises the characters up to the next occurrence of thedelimiter character.  String interpolation #{ ... } is allowed.Returns the result (i.e. standard output) of the shell command, just like the backticks.Docs: https://docs.ruby-lang.org/en/master/syntax/literals_rdoc.html#label-Percent+Stringsvalue = %x( echo 'hi' )value = %x[ #{cmd} ]Kernel#systemExecutes the given command in a subshell. Returns true if the command was found and run successfully, false otherwise.Docs: http://ruby-doc.org/core/Kernel.html#method-i-systemwasGood = system( ""echo 'hi'"" )wasGood = system( cmd )Kernel#execReplaces the current process by running the given external command.Returns none, the current process is replaced and never continues.Docs: http://ruby-doc.org/core/Kernel.html#method-i-execexec( ""echo 'hi'"" )exec( cmd ) # Note: this will never be reached because of the line aboveHere's some extra advice:$?, which is the same as $CHILD_STATUS, accesses the status of the last system executed command if you use the backticks, system() or %x{}.You can then access the exitstatus and pid properties:$?.exitstatusFor more reading see:http://www.elctech.com/blog/i-m-in-ur-commandline-executin-ma-commandshttp://blog.jayfields.com/2006/06/ruby-kernel-system-exec-and-x.htmlhttp://tech.natemurray.com/2007/03/ruby-shell-commands.html"
"data_i","edited Mar 13 '21 at 14:02","
        CSS selector for first element with class
    ","I have a bunch of elements with a class name red, but I can't seem to select the first element with the class=""red"" using the following CSS rule:.home .red:first-child {    border: 1px solid red;}<div class=""home"">    <span>blah</span>    <p class=""red"">first</p>    <p class=""red"">second</p>    <p class=""red"">third</p>    <p class=""red"">fourth</p></div>What is wrong in this selector and how do I correct it to target the first child with class red?","This is one of the most well-known examples of authors misunderstanding how :first-child works. Introduced in CSS2, the :first-child pseudo-class represents the very first child of its parent. That's it. There's a very common misconception that it picks up whichever child element is the first to match the conditions specified by the rest of the compound selector. Due to the way selectors work (see here for an explanation), that is simply not true.Selectors level 3 introduces a :first-of-type pseudo-class, which represents the first element among siblings of its element type. This answer explains, with illustrations, the difference between :first-child and :first-of-type. However, as with :first-child, it does not look at any other conditions or attributes. In HTML, the element type is represented by the tag name. In the question, that type is p.Unfortunately, there is no similar :first-of-class pseudo-class for matching the first child element of a given class. At the time this answer was first posted, the newly published FPWD of Selectors level 4 introduced an :nth-match() pseudo-class, designed around existing selector mechanics as I mentioned in the first paragraph by adding a selector-list argument, through which you can supply the rest of the compound selector to get the desired filtering behavior. In recent years this functionality was subsumed into :nth-child() itself, with the selector list appearing as an optional second argument, to simplify things as well as averting the false impression that :nth-match() matched across the entire document (see the final note below).While we await cross-browser support (seriously, it's been nearly 10 years, and there has only been a single implementation for the last 5 of those years), one workaround that Lea Verou and I developed independently (she did it first!) is to first apply your desired styles to all your elements with that class:/*  * Select all .red children of .home, including the first one, * and give them a border. */.home > .red {    border: 1px solid red;}... then ""undo"" the styles for elements with the class that come after the first one, using the general sibling combinator ~ in an overriding rule:/*  * Select all but the first .red child of .home, * and remove the border from the previous rule. */.home > .red ~ .red {    border: none;}Now only the first element with class=""red"" will have a border.Here's an illustration of how the rules are applied:.home > .red {    border: 1px solid red;}.home > .red ~ .red {    border: none;}<div class=""home"">  <span>blah</span>         <!-- [1] -->  <p class=""red"">first</p>  <!-- [2] -->  <p class=""red"">second</p> <!-- [3] -->  <p class=""red"">third</p>  <!-- [3] -->  <p class=""red"">fourth</p> <!-- [3] --></div>No rules are applied; no border is rendered.This element does not have the class red, so it's skipped.Only the first rule is applied; a red border is rendered.This element has the class red, but it's not preceded by any elements with the class red in its parent. Thus the second rule is not applied, only the first, and the element keeps its border.Both rules are applied; no border is rendered.This element has the class red. It is also preceded by at least one other element with the class red. Thus both rules are applied, and the second border declaration overrides the first, thereby ""undoing"" it, so to speak.As a bonus, although it was introduced in Selectors 3, the general sibling combinator is actually pretty well-supported by IE7 and newer, unlike :first-of-type and :nth-of-type() which are only supported by IE9 onward. If you need good browser support, you're in luck.In fact, the fact that the sibling combinator is the only important component in this technique, and it has such amazing browser support, makes this technique very versatile — you can adapt it for filtering elements by other things, besides class selectors:You can use this to work around :first-of-type in IE7 and IE8, by simply supplying a type selector instead of a class selector (again, more on its incorrect usage in the question in a later section): article > p {     /* Apply styles to article > p:first-of-type, which may or may not be :first-child */ } article > p ~ p {     /* Undo the above styles for every subsequent article > p */ }You can filter by attribute selectors or any other simple selectors instead of classes.You can also combine this overriding technique with pseudo-elements even though pseudo-elements technically aren't simple selectors.Note that in order for this to work, you will need to know in advance what the default styles will be for your other sibling elements so you can override the first rule. Additionally, since this involves overriding rules in CSS, you can't achieve the same thing with a single selector for use with the Selectors API, or Selenium's CSS locators.On a final note, keep in mind that this answer assumes that the question is looking for any number of first child elements having a given class. There is neither a pseudo-class nor even a generic CSS solution for the nth match of a complex selector across the entire document — whether a solution exists depends heavily on the document structure. jQuery provides :eq(), :first, :last and more for this purpose, but note again that they function very differently from :nth-child() et al. Using the Selectors API, you can either use document.querySelector() to obtain the very first match:var first = document.querySelector('.home > .red');Or use document.querySelectorAll() with an indexer to pick any specific match:var redElements = document.querySelectorAll('.home > .red');var first = redElements[0];var second = redElements[1];// etcAlthough the .red:nth-of-type(1) solution in the original accepted answer by Philip Daubmeier works (which was originally written by Martyn but deleted since), it does not behave the way you'd expect it to.For example, if you only wanted to select the p here:<p class=""red""></p><div class=""red""></div>... then you can't use .red:first-of-type (equivalent to .red:nth-of-type(1)), because each element is the first (and only) one of its type (p and div respectively), so both will be matched by the selector.When the first element of a certain class is also the first of its type, the pseudo-class will work, but this happens only by coincidence. This behavior is demonstrated in Philip's answer. The moment you stick in an element of the same type before this element, the selector will fail. Taking the markup from the question:<div class=""home"">  <span>blah</span>  <p class=""red"">first</p>  <p class=""red"">second</p>  <p class=""red"">third</p>  <p class=""red"">fourth</p></div>Applying a rule with .red:first-of-type will work, but once you add another p without the class:<div class=""home"">  <span>blah</span>  <p>dummy</p>  <p class=""red"">first</p>  <p class=""red"">second</p>  <p class=""red"">third</p>  <p class=""red"">fourth</p></div>... the selector will immediately fail, because the first .red element is now the second p element."
"data_i","edited Aug 16 '21 at 09:39","
        Where is the global git config data stored?
    ","When using git config --global to set things up, to which file will it write?Example:git config --global core.editor ""blah""I can't find it at these places:C:\Program Files\Git\etc\gitconfigC:\myapp\.git\configI have not set an ENV?My Git version: 1.6.5.1.1367.gcd48 –on Windows 7","Update 2016: with git 2.8 (March 2016), you can simply use:git config --list --show-originAnd with Git 2.26 (Q1 2020), you can add a --show-scope optiongit config --list --show-origin --show-scopeYou will see which config is set where.See ""Where do the settings in my Git configuration come from?""As Stevoisiak points out in the comments,it will work with non-standard install locations. (i.e. Git Portable)(like the latest PortableGit-2.14.2-64-bit.7z.exe, which can be uncompressed anywhere you want)Original answer (2010)From the docs:--globalFor writing options: write to global ~/.gitconfig file rather than the repository .git/config.Since you're using Git for Windows, it may not be clear what location this corresponds to. But if you look at etc/profile (in C:\Program Files\Git), you'll see:HOME=""$HOMEDRIVE$HOMEPATH""Meaning:C:\Users\MyLogin(on Windows 7)That means the file is in C:\Users\MyLogin\.gitconfig for Git in Windows 7."
"data_i","edited Dec 30 '17 at 11:21","
        Convert tabs to spaces in Notepad++
    ","How do I convert tabs to spaces in Notepad++? I found a webpage that suggests it's possible, but I couldn't find any information about how to do it. I would like to be able to do that, because some web forms don't respect code with tabs in them.","To convert existing tabs to spaces, press Edit->Blank Operations->TAB to Space.If in the future you want to enter spaces instead of tab when you press tab key:Go to Settings->Preferences...->Language (since version 7.1) or Settings->Preferences...->Tab Settings (previous versions)Check Replace by space(Optional) You can set the number of spaces to use in place of a Tab by changing the Tab size field."
"data_i","edited May 14 '21 at 07:31","
        How to call asynchronous method from synchronous method in C#?
    ","I have a public async void Foo() method that I want to call from synchronous method. So far all I have seen from MSDN documentation is calling async methods via async methods, but my whole program is not built with async methods.Is this even possible?Here's one example of calling these methods from an asynchronous method:Walkthrough: Accessing the Web by Using Async and Await (C# and Visual Basic)Now I'm looking into calling these async methods from sync methods.","Asynchronous programming does ""grow"" through the code base. It has been compared to a zombie virus. The best solution is to allow it to grow, but sometimes that's not possible.I have written a few types in my Nito.AsyncEx library for dealing with a partially-asynchronous code base. There's no solution that works in every situation, though.Solution AIf you have a simple asynchronous method that doesn't need to synchronize back to its context, then you can use Task.WaitAndUnwrapException:var task = MyAsyncMethod();var result = task.WaitAndUnwrapException();You do not want to use Task.Wait or Task.Result because they wrap exceptions in AggregateException.This solution is only appropriate if MyAsyncMethod does not synchronize back to its context. In other words, every await in MyAsyncMethod should end with ConfigureAwait(false). This means it can't update any UI elements or access the ASP.NET request context.Solution BIf MyAsyncMethod does need to synchronize back to its context, then you may be able to use AsyncContext.RunTask to provide a nested context:var result = AsyncContext.RunTask(MyAsyncMethod).Result;*Update 4/14/2014: In more recent versions of the library the API is as follows:var result = AsyncContext.Run(MyAsyncMethod);(It's OK to use Task.Result in this example because RunTask will propagate Task exceptions).The reason you may need AsyncContext.RunTask instead of Task.WaitAndUnwrapException is because of a rather subtle deadlock possibility that happens on WinForms/WPF/SL/ASP.NET:A synchronous method calls an async method, obtaining a Task.The synchronous method does a blocking wait on the Task.The async method uses await without ConfigureAwait.The Task cannot complete in this situation because it only completes when the async method is finished; the async method cannot complete because it is attempting to schedule its continuation to the SynchronizationContext, and WinForms/WPF/SL/ASP.NET will not allow the continuation to run because the synchronous method is already running in that context.This is one reason why it's a good idea to use ConfigureAwait(false) within every async method as much as possible.Solution CAsyncContext.RunTask won't work in every scenario. For example, if the async method awaits something that requires a UI event to complete, then you'll deadlock even with the nested context. In that case, you could start the async method on the thread pool:var task = Task.Run(async () => await MyAsyncMethod());var result = task.WaitAndUnwrapException();However, this solution requires a MyAsyncMethod that will work in the thread pool context. So it can't update UI elements or access the ASP.NET request context. And in that case, you may as well add ConfigureAwait(false) to its await statements, and use solution A.Update, 2019-05-01: The current ""least-worst practices"" are in an MSDN article here."
"data_i","edited Jul 26 '18 at 19:10","
        Converting 'ArrayList to 'String[]' in Java
    ","How might I convert an ArrayList<String> object to a String[] array in Java?","List<String> list = ..;String[] array = list.toArray(new String[0]);For example:List<String> list = new ArrayList<String>();//add some stufflist.add(""android"");list.add(""apple"");String[] stringArray = list.toArray(new String[0]);The toArray() method without passing any argument returns Object[]. So you have to pass an array as an argument, which will be filled with the data from the list, and returned. You can pass an empty array as well, but you can also pass an array with the desired size.Important update: Originally the code above used new String[list.size()]. However, this blogpost reveals that due to JVM optimizations, using new String[0] is better now."
"data_i","edited Apr 22 '19 at 22:44","
        How can I generate random alphanumeric strings?
    ","How can I generate a random 8 character alphanumeric string in C#?","I heard LINQ is the new black, so here's my attempt using LINQ:private static Random random = new Random();public static string RandomString(int length){    const string chars = ""ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"";    return new string(Enumerable.Repeat(chars, length)        .Select(s => s[random.Next(s.Length)]).ToArray());}(Note: The use of the Random class makes this unsuitable for anything security related, such as creating passwords or tokens. Use the RNGCryptoServiceProvider class if you need a strong random number generator.)"
"data_i","edited Dec 10 '18 at 13:08","
        Git push rejected after feature branch rebase
    ","OK, I thought this was a simple git scenario, what am I missing?I have a master branch and a feature branch. I do some work on master, some on feature, and then some more on master. I end up with something like this (lexicographic order implies the order of commits):A--B--C------F--G  (master)       \            D--E  (feature)I have no problem to git push origin master to keep the remote master updated, nor with git push origin feature (when on feature) to maintain a remote backup for my feature work. Up until now, we're good.But now I want to rebase feature on top of the F--G commits on master, so I git checkout feature and git rebase master. Still good. Now we have:A--B--C------F--G  (master)                 \                  D'--E'  (feature)Problem: the moment I want to backup the new rebased feature branched with git push origin feature, the push is rejected since the tree has changed due to the rebasing. This can only be solved with git push --force origin feature.I hate using --force without being sure I need it. So, do I need it? Does the rebasing necessarily imply that the next push should be --forceful?This feature branch is not shared with any other devs, so I have no problem de facto with the force push, I'm not going to lose any data, the question is more conceptual.","The problem is that git push assumes that remote branch can be fast-forwarded to your local branch, that is that all the difference between local and remote branches is in local having some new commits at the end like that:Z--X--R         <- origin/some-branch (can be fast-forwarded to Y commit)       \                T--Y    <- some-branchWhen you perform git rebase commits D and E are applied to new base and new commits are created. That means after rebase you have something like that:A--B--C------F--G--D'--E'   <- feature-branch       \          D--E                <- origin/feature-branchIn that situation remote branch can't be fast-forwarded to local. Though, theoretically local branch can be merged into remote (obviously you don't need it in that case), but as git push performs only fast-forward merges it throws and error.And what --force option does is just ignoring state of remote branch and setting it to the commit you're pushing into it. So git push --force origin feature-branch simply overrides origin/feature-branch with local feature-branch.In my opinion, rebasing feature branches on master and force-pushing them back to remote repository is OK as long as you're the only one who works on that branch."
"data_i","edited Apr 09 '22 at 09:57","
        How do I get file creation and modification date/times?
    ","What's the best cross-platform way to get file creation and modification dates/times, that works on both Linux and Windows?","Getting some sort of modification date in a cross-platform way is easy - just call os.path.getmtime(path) and you'll get the Unix timestamp of when the file at path was last modified.Getting file creation dates, on the other hand, is fiddly and platform-dependent, differing even between the three big OSes:On Windows, a file's ctime (documented at https://msdn.microsoft.com/en-us/library/14h5k7ff.aspx) stores its creation date. You can access this in Python through os.path.getctime() or the .st_ctime attribute of the result of a call to os.stat(). This won't work on Unix, where the ctime is the last time that the file's attributes or content were changed.On Mac, as well as some other Unix-based OSes, you can use the .st_birthtime attribute of the result of a call to os.stat().On Linux, this is currently impossible, at least without writing a C extension for Python. Although some file systems commonly used with Linux do store creation dates (for example, ext4 stores them in st_crtime) , the Linux kernel offers no way of accessing them; in particular, the structs it returns from stat() calls in C, as of the latest kernel version, don't contain any creation date fields. You can also see that the identifier st_crtime doesn't currently feature anywhere in the Python source. At least if you're on ext4, the data is attached to the inodes in the file system, but there's no convenient way of accessing it.The next-best thing on Linux is to access the file's mtime, through either os.path.getmtime() or the .st_mtime attribute of an os.stat() result. This will give you the last time the file's content was modified, which may be adequate for some use cases.Putting this all together, cross-platform code should look something like this...import osimport platformdef creation_date(path_to_file):    """"""    Try to get the date that a file was created, falling back to when it was    last modified if that isn't possible.    See http://stackoverflow.com/a/39501288/1709587 for explanation.    """"""    if platform.system() == 'Windows':        return os.path.getctime(path_to_file)    else:        stat = os.stat(path_to_file)        try:            return stat.st_birthtime        except AttributeError:            # We're probably on Linux. No easy way to get creation dates here,            # so we'll settle for when its content was last modified.            return stat.st_mtime"
"data_i","edited Apr 09 '22 at 10:56","
        How to catch and print the full exception traceback without halting/exiting the program?
    ","I want to catch and log exceptions without exiting, e.g.,try:    do_stuff()except Exception as err:    print(Exception, err)    # I want to print the entire traceback here,    # not just the exception name and detailsI want to print the exact same output that is printed when the exception is raised without the try/except intercepting the exception, and I do not want it to exit my program.","traceback.format_exc() or sys.exc_info() will yield more info if that's what you want.import tracebackimport systry:    do_stuff()except Exception:    print(traceback.format_exc())    # or    print(sys.exc_info()[2])"
"data_i","edited Jun 29 '14 at 16:47","
        How to execute a JavaScript function when I have its name as a string
    ","I have the name of a function in JavaScript as a string. How do I convert that into a function pointer so I can call it later?Depending on the circumstances, I may need to pass various arguments into the method too.Some of the functions may take the form of namespace.namespace.function(args[...]).","Don't use eval unless you absolutely, positively have no other choice.As has been mentioned, using something like this would be the best way to do it:window[""functionName""](arguments);That, however, will not work with a namespace'd function:window[""My.Namespace.functionName""](arguments); // failThis is how you would do that:window[""My""][""Namespace""][""functionName""](arguments); // succeedsIn order to make that easier and provide some flexibility, here is a convenience function:function executeFunctionByName(functionName, context /*, args */) {  var args = Array.prototype.slice.call(arguments, 2);  var namespaces = functionName.split(""."");  var func = namespaces.pop();  for(var i = 0; i < namespaces.length; i++) {    context = context[namespaces[i]];  }  return context[func].apply(context, args);}You would call it like so:executeFunctionByName(""My.Namespace.functionName"", window, arguments);Note, you can pass in whatever context you want, so this would do the same as above:executeFunctionByName(""Namespace.functionName"", My, arguments);"
"data_i","edited Aug 14 '22 at 23:56","
        Negative matching using grep (match lines that do not contain foo)
    ","How do I match all lines not matching a particular pattern using grep? I tried this:grep '[^foo]'","grep -v is your friend:grep --help | grep invert  -v, --invert-match        select non-matching linesAlso check out the related -L (the complement of -l).-L, --files-without-match only print FILE names containing no match"
"data_i","edited Sep 30 '15 at 08:17","
        How do I get ASP.NET Web API to return JSON instead of XML using Chrome?
    ","Using the newer ASP.NET Web API, in Chrome I am seeing XML - how can I change it to request JSON so I can view it in the browser? I do believe it is just part of the request headers, am I correct in that?","Note: Read the comments of this answer, it can produce a XSS Vulnerability if you are using the default error handing of WebAPII just add the following in App_Start / WebApiConfig.cs class in my MVC Web API project.config.Formatters.JsonFormatter.SupportedMediaTypes    .Add(new MediaTypeHeaderValue(""text/html"") );That makes sure you get JSON on most queries, but you can get XML when you send text/xml.If you need to have the response Content-Type as application/json please check Todd's answer below.NameSpace is using System.Net.Http.Headers."
"data_i","edited Apr 17 '22 at 02:00","
        How does Python's super() work with multiple inheritance?
    ","How does super() work with multiple inheritance? For example, given:class First(object):    def __init__(self):        print ""first""class Second(object):    def __init__(self):        print ""second""class Third(First, Second):    def __init__(self):        super(Third, self).__init__()        print ""that's it""Which parent method of Third does super().__init__ refer to? Can I choose which runs?I know it has something to do with method resolution order (MRO).","This is detailed with a reasonable amount of detail by Guido himself in his blog post Method Resolution Order (including two earlier attempts).In your example, Third() will call First.__init__. Python looks for each attribute in the class's parents as they are listed left to right. In this case, we are looking for __init__. So, if you defineclass Third(First, Second):    ...Python will start by looking at First, and, if First doesn't have the attribute, then it will look at Second.This situation becomes more complex when inheritance starts crossing paths (for example if First inherited from Second). Read the link above for more details, but, in a nutshell, Python will try to maintain the order in which each class appears on the inheritance list, starting with the child class itself.So, for instance, if you had:class First(object):    def __init__(self):        print ""first""class Second(First):    def __init__(self):        print ""second""class Third(First):    def __init__(self):        print ""third""class Fourth(Second, Third):    def __init__(self):        super(Fourth, self).__init__()        print ""that's it""the MRO would be [Fourth, Second, Third, First].By the way: if Python cannot find a coherent method resolution order, it'll raise an exception, instead of falling back to behavior which might surprise the user.Example of an ambiguous MRO:class First(object):    def __init__(self):        print ""first""        class Second(First):    def __init__(self):        print ""second""class Third(First, Second):    def __init__(self):        print ""third""Should Third's MRO be [First, Second] or [Second, First]? There's no obvious expectation, and Python will raise an error:TypeError: Error when calling the metaclass bases    Cannot create a consistent method resolution order (MRO) for bases Second, FirstWhy do the examples above lack super() calls? The point of the examples is to show how the MRO is constructed. They are not intended to print ""first\nsecond\third"" or whatever. You can – and should, of course, play around with the example, add super() calls, see what happens, and gain a deeper understanding of Python's inheritance model. But my goal here is to keep it simple and show how the MRO is built. And it is built as I explained:>>> Fourth.__mro__(<class '__main__.Fourth'>, <class '__main__.Second'>, <class '__main__.Third'>, <class '__main__.First'>, <type 'object'>)"
"data_i","edited Sep 21 '22 at 15:27","
        How to deal with SettingWithCopyWarning in Pandas
    ","BackgroundI just upgraded my Pandas from 0.11 to 0.13.0rc1. Now, the application is popping out many new warnings. One of them like this:E:\FinReporter\FM_EXT.py:449: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.Try using .loc[row_index,col_indexer] = value instead  quote_df['TVol']   = quote_df['TVol']/TVOL_SCALEI want to know what exactly it means?  Do I need to change something?How should I suspend the warning if I insist to use quote_df['TVol']   = quote_df['TVol']/TVOL_SCALE?The function that gives errorsdef _decode_stock_quote(list_of_150_stk_str):    """"""decode the webpage and return dataframe""""""    from cStringIO import StringIO    str_of_all = """".join(list_of_150_stk_str)    quote_df = pd.read_csv(StringIO(str_of_all), sep=',', names=list('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefg')) #dtype={'A': object, 'B': object, 'C': np.float64}    quote_df.rename(columns={'A':'STK', 'B':'TOpen', 'C':'TPCLOSE', 'D':'TPrice', 'E':'THigh', 'F':'TLow', 'I':'TVol', 'J':'TAmt', 'e':'TDate', 'f':'TTime'}, inplace=True)    quote_df = quote_df.ix[:,[0,3,2,1,4,5,8,9,30,31]]    quote_df['TClose'] = quote_df['TPrice']    quote_df['RT']     = 100 * (quote_df['TPrice']/quote_df['TPCLOSE'] - 1)    quote_df['TVol']   = quote_df['TVol']/TVOL_SCALE    quote_df['TAmt']   = quote_df['TAmt']/TAMT_SCALE    quote_df['STK_ID'] = quote_df['STK'].str.slice(13,19)    quote_df['STK_Name'] = quote_df['STK'].str.slice(21,30)#.decode('gb2312')    quote_df['TDate']  = quote_df.TDate.map(lambda x: x[0:4]+x[5:7]+x[8:10])        return quote_dfMore error messagesE:\FinReporter\FM_EXT.py:449: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.Try using .loc[row_index,col_indexer] = value instead  quote_df['TVol']   = quote_df['TVol']/TVOL_SCALEE:\FinReporter\FM_EXT.py:450: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.Try using .loc[row_index,col_indexer] = value instead  quote_df['TAmt']   = quote_df['TAmt']/TAMT_SCALEE:\FinReporter\FM_EXT.py:453: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.Try using .loc[row_index,col_indexer] = value instead  quote_df['TDate']  = quote_df.TDate.map(lambda x: x[0:4]+x[5:7]+x[8:10])","The SettingWithCopyWarning was created to flag potentially confusing ""chained"" assignments, such as the following, which does not always work as expected, particularly when the first selection returns a copy.  [see GH5390 and GH5597 for background discussion.]df[df['A'] > 2]['B'] = new_val  # new_val not set in dfThe warning offers a suggestion to rewrite as follows:df.loc[df['A'] > 2, 'B'] = new_valHowever, this doesn't fit your usage, which is equivalent to:df = df[df['A'] > 2]df['B'] = new_valWhile it's clear that you don't care about writes making it back to the original frame (since you are overwriting the reference to it), unfortunately this pattern cannot be differentiated from the first chained assignment example. Hence the (false positive) warning. The potential for false positives is addressed in the docs on indexing, if you'd like to read further.  You can safely disable this new warning with the following assignment.import pandas as pdpd.options.mode.chained_assignment = None  # default='warn'Other Resourcespandas User Guide: Indexing and selecting dataPython Data Science Handbook: Data Indexing and SelectionReal Python: SettingWithCopyWarning in Pandas: Views vs CopiesDataquest: SettingwithCopyWarning: How to Fix This Warning in PandasTowards Data Science: Explaining the SettingWithCopyWarning in pandas"
"data_i","edited Apr 09 '22 at 10:18","
        How to make a class JSON serializable
    ","How to make a Python class serializable?class FileItem:    def __init__(self, fname):        self.fname = fnameAttempt to serialize to JSON:>>> import json>>> x = FileItem('/foo/bar')>>> json.dumps(x)TypeError: Object of type 'FileItem' is not JSON serializable","Here is a simple solution for a simple feature:.toJSON() MethodInstead of a JSON serializable class, implement a serializer method:import jsonclass Object:    def toJSON(self):        return json.dumps(self, default=lambda o: o.__dict__,             sort_keys=True, indent=4)So you just call it to serialize:me = Object()me.name = ""Onur""me.age = 35me.dog = Object()me.dog.name = ""Apollo""print(me.toJSON())will output:{    ""age"": 35,    ""dog"": {        ""name"": ""Apollo""    },    ""name"": ""Onur""}"
"data_i","asked Jul 20 '12 at 14:02","
        Sending command line arguments to npm script
    ","The scripts portion of my package.json currently looks like this:""scripts"": {    ""start"": ""node ./script.js server""}...which means I can run npm start to start the server. So far so good.However, I would like to be able to run something like npm start 8080 and have the argument(s) passed to script.js (e.g. npm start 8080 => node ./script.js server 8080). Is this possible?","npm 2 and newerIt's possible to pass args to npm run since npm 2 (2014). The syntax is as follows:npm run <command> [-- <args>]Note the -- separator, used to separate the params passed to npm command itself, and the params passed to your script.With the example package.json:  ""scripts"": {    ""grunt"": ""grunt"",    ""server"": ""node server.js""  }here's how to pass the params to those scripts:npm run grunt -- task:target  // invokes `grunt task:target`npm run server -- --port=1337 // invokes `node server.js --port=1337`Note: If your param does not start with - or --, then having an explicit -- separator is not needed; but it's better to do it anyway for clarity.npm run grunt task:target     // invokes `grunt task:target`Note below the difference in behavior (test.js has console.log(process.argv)): the params which start with - or -- are passed to npm and not to the script, and are silently swallowed there.$ npm run test foobar['C:\\Program Files\\nodejs\\node.exe', 'C:\\git\\myrepo\\test.js',  'foobar']$ npm run test -foobar['C:\\Program Files\\nodejs\\node.exe', 'C:\\git\\myrepo\\test.js']$ npm run test --foobar['C:\\Program Files\\nodejs\\node.exe', 'C:\\git\\myrepo\\test.js']$ npm run test -- foobar['C:\\Program Files\\nodejs\\node.exe', 'C:\\git\\myrepo\\test.js', 'foobar']$ npm run test -- -foobar['C:\\Program Files\\nodejs\\node.exe', 'C:\\git\\myrepo\\test.js', '-foobar']$ npm run test -- --foobar['C:\\Program Files\\nodejs\\node.exe', 'C:\\git\\myrepo\\test.js', '--foobar']The difference is clearer when you use a param actually used by npm:$ npm test --help      // this is disguised `npm --help test`npm test [-- <args>]aliases: tst, tTo get the parameter value, see this question. For reading named parameters, it's probably best to use a parsing library like yargs or minimist; nodejs exposes process.argv globally, containing command line parameter values, but this is a low-level API (whitespace-separated array of strings, as provided by the operating system to the node executable).Edit 2013.10.03: It's not currently possible directly. But there's a related GitHub issue opened on npm to implement the behavior you're asking for. Seems the consensus is to have this implemented, but it depends on another issue being solved before.Original answer (2013.01): As a some kind of workaround (though not very handy), you can do as follows:Say your package name from package.json is myPackage and you have also""scripts"": {    ""start"": ""node ./script.js server""}Then add in package.json:""config"": {    ""myPort"": ""8080""}And in your script.js:// defaulting to 8080 in case if script invoked not via ""npm run-script"" but directlyvar port = process.env.npm_package_config_myPort || 8080That way, by default npm start will use 8080. You can however configure it (the value will be stored by npm in its internal storage):npm config set myPackage:myPort 9090Then, when invoking npm start, 9090 will be used (the default from package.json gets overridden)."
"data_i","edited Feb 11 '21 at 20:43","
        What is a correct MIME type for .docx, .pptx, etc.?
    ","For older *.doc documents, this was enough:header(""Content-Type: application/msword"");What MIME type should I use for new .docx documents? Also, for pptx and xlsx documents?","Here are the correct Microsoft Office MIME types for HTTP content streaming:Extension MIME Type.doc      application/msword.dot      application/msword.docx     application/vnd.openxmlformats-officedocument.wordprocessingml.document.dotx     application/vnd.openxmlformats-officedocument.wordprocessingml.template.docm     application/vnd.ms-word.document.macroEnabled.12.dotm     application/vnd.ms-word.template.macroEnabled.12.xls      application/vnd.ms-excel.xlt      application/vnd.ms-excel.xla      application/vnd.ms-excel.xlsx     application/vnd.openxmlformats-officedocument.spreadsheetml.sheet.xltx     application/vnd.openxmlformats-officedocument.spreadsheetml.template.xlsm     application/vnd.ms-excel.sheet.macroEnabled.12.xltm     application/vnd.ms-excel.template.macroEnabled.12.xlam     application/vnd.ms-excel.addin.macroEnabled.12.xlsb     application/vnd.ms-excel.sheet.binary.macroEnabled.12.ppt      application/vnd.ms-powerpoint.pot      application/vnd.ms-powerpoint.pps      application/vnd.ms-powerpoint.ppa      application/vnd.ms-powerpoint.pptx     application/vnd.openxmlformats-officedocument.presentationml.presentation.potx     application/vnd.openxmlformats-officedocument.presentationml.template.ppsx     application/vnd.openxmlformats-officedocument.presentationml.slideshow.ppam     application/vnd.ms-powerpoint.addin.macroEnabled.12.pptm     application/vnd.ms-powerpoint.presentation.macroEnabled.12.potm     application/vnd.ms-powerpoint.template.macroEnabled.12.ppsm     application/vnd.ms-powerpoint.slideshow.macroEnabled.12.mdb      application/vnd.ms-accessFor further details check out this TechNet article and this blog post."
"data_i","edited Jun 20 '18 at 05:55","
        How to trim whitespace from a Bash variable?
    ","I have a shell script with this code:var=`hg st -R ""$path""`if [ -n ""$var"" ]; then    echo $varfiBut the conditional code always executes, because hg st always prints at least one newline character.Is there a simple way to strip whitespace from $var (like trim() in PHP)?orIs there a standard way of dealing with this issue?I could use sed or AWK, but I'd like to think there is a more elegant solution to this problem.","A simple answer is:echo ""   lol  "" | xargsXargs will do the trimming for you. It's one command/program, no parameters, returns the trimmed string, easy as that!Note: this doesn't remove all internal spaces so ""foo bar"" stays the same; it does NOT become ""foobar"". However, multiple spaces will be condensed to single spaces, so ""foo    bar"" will become ""foo bar"". In addition it doesn't remove end of lines characters."
"data_i","edited Aug 10 '17 at 10:55","
        How to kill a process running on particular port in Linux?
    ","I tried to close the tomcat using ./shutdown.sh from tomcat /bin directory. But found that the server was not closed properly. And thus I was unable to restartMy tomcat is running on port 8080.I want to kill the tomcat process running on 8080. I first want to have the list of processes running on a specific port (8080) in order to select which process to kill.","This fuser 8080/tcp will print you PID of process bound on that port.And this fuser -k 8080/tcp will kill that process.Works on Linux only. More universal is use of lsof -i4 (or 6 for IPv6). "
"data_i","edited Jul 15 '15 at 18:29","
        Remove all child elements of a DOM node in JavaScript
    ","How would I go about removing all of the child elements of a DOM node in JavaScript?Say I have the following (ugly) HTML:<p id=""foo"">    <span>hello</span>    <div>world</div></p>And I grab the node I want like so:var myNode = document.getElementById(""foo"");How could I remove the children of foo so that just <p id=""foo""></p> is left?Could I just do:myNode.childNodes = new Array();or should I be using some combination of removeElement?I'd like the answer to be straight up DOM; though extra points if you also provide an answer in jQuery along with the DOM-only answer.","Option 1 A: Clearing innerHTML.This approach is simple, but might not be suitable for high-performance applications because it invokes the browser's HTML parser (though browsers may optimize for the case where the value is an empty string).doFoo.onclick = () => {  const myNode = document.getElementById(""foo"");  myNode.innerHTML = '';}<div id='foo' style=""height: 100px; width: 100px; border: 1px solid black;"">  <span>Hello</span></div><button id='doFoo'>Remove via innerHTML</button>Option 1 B: Clearing textContentAs above, but use .textContent. According to MDN this will be faster than innerHTML as browsers won't invoke their HTML parsers and will instead immediately replace all children of the element with a single #text node.doFoo.onclick = () => {  const myNode = document.getElementById(""foo"");  myNode.textContent = '';}<div id='foo' style=""height: 100px; width: 100px; border: 1px solid black;"">  <span>Hello</span></div><button id='doFoo'>Remove via textContent</button>Option 2 A: Looping to remove every lastChild:An earlier edit to this answer used firstChild, but this is updated to use lastChild as in computer-science, in general, it's significantly faster to remove the last element of a collection than it is to remove the first element (depending on how the collection is implemented).The loop continues to check for firstChild just in case it's faster to check for firstChild than lastChild (e.g. if the element list is implemented as a directed linked-list by the UA).doFoo.onclick = () => {  const myNode = document.getElementById(""foo"");  while (myNode.firstChild) {    myNode.removeChild(myNode.lastChild);  }}<div id='foo' style=""height: 100px; width: 100px; border: 1px solid black;"">  <span>Hello</span></div><button id='doFoo'>Remove via lastChild-loop</button>Option 2 B: Looping to remove every lastElementChild:This approach preserves all non-Element (namely #text nodes and <!-- comments --> ) children of the parent (but not their descendants) - and this may be desirable in your application (e.g. some templating systems that use inline HTML comments to store template instructions).This approach wasn't used until recent years as Internet Explorer only added support for lastElementChild in IE9.doFoo.onclick = () => {  const myNode = document.getElementById(""foo"");  while (myNode.lastElementChild) {    myNode.removeChild(myNode.lastElementChild);  }}<div id='foo' style=""height: 100px; width: 100px; border: 1px solid black;"">  <!-- This comment won't be removed -->  <span>Hello <!-- This comment WILL be removed --></span>  <!-- But this one won't. --></div><button id='doFoo'>Remove via lastElementChild-loop</button>Bonus: Element.clearChildren monkey-patch:We can add a new method-property to the Element prototype in JavaScript to simplify invoking it to just el.clearChildren() (where el is any HTML element object).(Strictly speaking this is a monkey-patch, not a polyfill, as this is not a standard DOM feature or missing feature. Note that monkey-patching is rightfully discouraged in many situations.)if( typeof Element.prototype.clearChildren === 'undefined' ) {    Object.defineProperty(Element.prototype, 'clearChildren', {      configurable: true,      enumerable: false,      value: function() {        while(this.firstChild) this.removeChild(this.lastChild);      }    });}<div id='foo' style=""height: 100px; width: 100px; border: 1px solid black;"">  <span>Hello <!-- This comment WILL be removed --></span></div><button onclick=""this.previousElementSibling.clearChildren()"">Remove via monkey-patch</button>"
"data_i","edited Jul 10 '22 at 22:40","
        Replace one substring for another string in shell script
    ","I have ""I love Suzi and Marry"" and I want to change ""Suzi"" to ""Sara"".firstString=""I love Suzi and Marry""secondString=""Sara""Desired result:firstString=""I love Sara and Marry""","To replace the first occurrence of a pattern with a given string, use ${parameter/pattern/string}:#!/bin/bashfirstString=""I love Suzi and Marry""secondString=""Sara""echo ""${firstString/Suzi/""$secondString""}""    # prints 'I love Sara and Marry'To replace all occurrences, use ${parameter//pattern/string}:message='The secret code is 12345'echo ""${message//[0-9]/X}""           # prints 'The secret code is XXXXX'(This is documented in the Bash Reference Manual, §3.5.3 ""Shell Parameter Expansion"".)Note that this feature is not specified by POSIX — it's a Bash extension — so not all Unix shells implement it. For the relevant POSIX documentation, see The Open Group Technical Standard Base Specifications, Issue 7, the Shell & Utilities volume, §2.6.2 ""Parameter Expansion""."
"data_i","asked Jul 31 '12 at 15:06","
        How do I encode and decode a base64 string?
    ","How do I return a base64 encoded string given a string?How do I decode a base64 encoded string into a string?","Encodepublic static string Base64Encode(string plainText) {  var plainTextBytes = System.Text.Encoding.UTF8.GetBytes(plainText);  return System.Convert.ToBase64String(plainTextBytes);}Decodepublic static string Base64Decode(string base64EncodedData) {  var base64EncodedBytes = System.Convert.FromBase64String(base64EncodedData);  return System.Text.Encoding.UTF8.GetString(base64EncodedBytes);}"
"data_i","edited Mar 18 '20 at 14:07","
        How can I initialise a static Map?
    ","How would you initialise a static Map in Java?Method one: static initialiser Method two: instance initialiser (anonymous subclass)orsome other method?What are the pros and cons of each?Here is an example illustrating the two methods:import java.util.HashMap;import java.util.Map;public class Test {    private static final Map<Integer, String> myMap = new HashMap<>();    static {        myMap.put(1, ""one"");        myMap.put(2, ""two"");    }    private static final Map<Integer, String> myMap2 = new HashMap<>(){        {            put(1, ""one"");            put(2, ""two"");        }    };}","The instance initialiser is just syntactic sugar in this case, right? I don't see why you need an extra anonymous class just to initialize. And it won't work if the class being created is final.You can create an immutable map using a static initialiser too:public class Test {    private static final Map<Integer, String> myMap;    static {        Map<Integer, String> aMap = ....;        aMap.put(1, ""one"");        aMap.put(2, ""two"");        myMap = Collections.unmodifiableMap(aMap);    }}"
"data_i","edited Aug 28 '21 at 22:10","
        Pipe to/from the clipboard in a Bash script
    ","Is it possible to pipe to/from the clipboard in Bash?Whether it is piping to/from a device handle or using an auxiliary application, I can't find anything.For example, if /dev/clip was a device linking to the clipboard we could do:cat /dev/clip        # Dump the contents of the clipboardcat foo > /dev/clip  # Dump the contents of ""foo"" into the clipboard","There are a wealth of clipboards you could be dealing with.  I expect you're probably a Linux user who wants to put stuff in the X Windows primary clipboard.  Usually, the clipboard you want to talk to has a utility that lets you talk to it.In the case of X, there's xclip (and others). xclip -selection c will send data to the clipboard that works with Ctrl + C, Ctrl + V  in most applications.If you're on Mac OS X, there's pbcopy. E.g., cat example.txt | pbcopyIf you're in Linux terminal mode (no X) then look into gpm or Screen which has a clipboard.  Try the Screen command readreg.Under Windows 10+ or Cygwin, use /dev/clipboard or clip."
"data_i","edited Nov 20 '16 at 16:07","
        Can I hide the HTML5 number input’s spin box?
    ","Is there a consistent way across browsers to hide the new spin boxes that some browsers (such as Chrome) render for HTML input of type number?  I am looking for a CSS or JavaScript method to prevent the up/down arrows from appearing.<input id=""test"" type=""number"">","This CSS effectively hides the spin-button for webkit browsers (have tested it in Chrome 7.0.517.44 and Safari Version 5.0.2 (6533.18.5)):input::-webkit-outer-spin-button,input::-webkit-inner-spin-button {    /* display: none; <- Crashes Chrome on hover */    -webkit-appearance: none;    margin: 0; /* <-- Apparently some margin are still there even though it's hidden */}input[type=number] {    -moz-appearance:textfield; /* Firefox */}<input type=""number"" step=""0.01"" />You can always use the inspector (webkit, possibly Firebug for Firefox) to look for matched CSS properties for the elements you are interested in, look for Pseudo elements. This image shows results for an input element type=""number"":"
"data_i","edited Feb 25 '21 at 13:24","
        Center a column using Twitter Bootstrap 3
    ","How do I center a div of one column size within the container (12 columns) in Twitter Bootstrap 3?.centered {  background-color: red;}<!-- Latest compiled and minified CSS --><link rel=""stylesheet"" href=""https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css"" integrity=""sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u"" crossorigin=""anonymous""><body class=""container"">  <div class=""col-lg-1 col-offset-6 centered"">    <img data-src=""holder.js/100x100"" alt="""" />  </div></body>I want a div, with a class .centered to be centered within the container. I may use a row if there are multiple divs, but for now I just want a div with the size of one column centered within the container (12 columns).I am also not sure the above approach is good enough as the intention is not to offset the div by half. I do not need free spaces outside the div and the contents of the div shrink in proportion. I want to empty space outside the div to be evenly distributed (shrink till the container width is equal to one column).","There are two approaches to centering a column <div> in Bootstrap 3:Approach 1 (offsets):The first approach uses Bootstrap's own offset classes so it requires no change in markup and no extra CSS. The key is to set an offset equal to half of the remaining size of the row. So for example, a column of size 2 would be centered by adding an offset of 5, that's (12-2)/2.In markup this would look like:<div class=""row"">    <div class=""col-md-2 col-md-offset-5""></div></div>Now, there's an obvious drawback for this method. It only works for even column sizes, so only .col-X-2, .col-X-4, col-X-6, col-X-8, and col-X-10 are supported.Approach 2 (the old margin:auto)You can center any column size by using the proven margin: 0 auto; technique. You just need to take care of the floating that is added by Bootstrap's grid system. I recommend defining a custom CSS class like the following:.col-centered{    float: none;    margin: 0 auto;}Now you can add it to any column size at any screen size, and it will work seamlessly with Bootstrap's responsive layout:<div class=""row"">    <div class=""col-lg-1 col-centered""></div></div>Note: With both techniques you could skip the .row element and have the column centered inside a .container, but you would notice a minimal difference in the actual column size because of the padding in the container class.Update:Since v3.0.1 Bootstrap has a built-in class named center-block that uses margin: 0 auto, but is missing float:none, you can add that to your CSS to make it work with the grid system."
"data_i","edited Apr 20 '17 at 02:54","
        How to tag an older commit in Git?
    ","We are new to git, and I want to set a tag at the beginning of our repository. Our production code is the same as the beginning repository, but we've made commits since then.A tag at the beginning would allow us to ""roll back"" production to a known, stable state.So how to add a tag to an arbitrary, older commit?","Example:git tag -a v1.2 9fceb02 -m ""Message here""Where 9fceb02 is the beginning part of the commit id.You can then push the tag using git push origin v1.2.You can do git log to show all the commit id's in your current branch.There is also a good chapter on tagging in the Pro Git book.Warning: This creates tags with the current date (and that value is what will show on a GitHub releases page, for example).  If you want the tag to be dated with the commit date, please look at another answer."
"data_i","edited May 09 '22 at 12:17","
        Converting array to list in Java
    ","How do I convert an array to a list in Java?I used the Arrays.asList() but the behavior (and signature) somehow changed from Java SE 1.4.2 (docs now in archive) to 8 and most snippets I found on the web use the 1.4.2 behaviour.For example:int[] numbers = new int[] { 1, 2, 3 };Arrays.asList(numbers)on 1.4.2 returns a list containing the elements 1, 2, 3on 1.5.0+ returns a list containing the array 'numbers'In many cases it should be easy to detect, but sometimes it can slip unnoticed:Assert.assertTrue(Arrays.asList(numbers).indexOf(4) == -1);","In your example, it is because you can't have a List of a primitive type. In other words, List<int> is not possible.You can, however, have a List<Integer> using the Integer class that wraps the int primitive. Convert your array to a List with the Arrays.asList utility method.Integer[] numbers = new Integer[] { 1, 2, 3 };List<Integer> list = Arrays.asList(numbers);See this code run live at IdeOne.com."
"data_i","edited Apr 01 '21 at 10:52","
        How to set or change the default Java (JDK) version on macOS?
    ","How can you change the default version of Java on a mac?","First run /usr/libexec/java_home -V which will output something like the following:Matching Java Virtual Machines (3):1.8.0_05, x86_64:   ""Java SE 8"" /Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdk/Contents/Home1.6.0_65-b14-462, x86_64:   ""Java SE 6"" /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home1.6.0_65-b14-462, i386: ""Java SE 6"" /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home/Library/Java/JavaVirtualMachines/jdk1.8.0_05.jdk/Contents/HomePick the version you want to be the default (1.6.0_65-b14-462 for arguments sake) then:export JAVA_HOME=`/usr/libexec/java_home -v 1.6.0_65-b14-462`or you can specify just the major version, like:export JAVA_HOME=`/usr/libexec/java_home -v 1.8`Now when you run java -version you will see:java version ""1.6.0_65""Java(TM) SE Runtime Environment (build 1.6.0_65-b14-462-11M4609)Java HotSpot(TM) 64-Bit Server VM (build 20.65-b04-462, mixed mode)Add the export JAVA_HOME… line to your shell’s init file.For Bash (as stated by antonyh):export JAVA_HOME=$(/usr/libexec/java_home -v 1.8)For Fish (as stated by ormurin)set -x JAVA_HOME (/usr/libexec/java_home -d64 -v1.8)Updating the .zshrc file should work:nano ~/.zshrcexport JAVA_HOME=$(/usr/libexec/java_home -v 1.8.0)Press CTRL+X to exit the editorPress Y to save your changessource ~/.zshrcecho $JAVA_HOMEjava -version"
"data_i","edited Sep 17 '16 at 01:35","
        How to clear the canvas for redrawing
    ","After experimenting with composite operations and drawing images on the canvas I'm now trying to remove images and compositing. How do I do this?I need to clear the canvas for redrawing other images; this can go on for a while so I don't think drawing a new rectangle every time will be the most efficient option.","Given that canvas is a canvas element or an OffscreenCanvas object,const context = canvas.getContext('2d');context.clearRect(0, 0, canvas.width, canvas.height);"
"data_i","edited Jul 28 '20 at 09:16","
        master branch and 'origin/master' have diverged, how to 'undiverge' branches'?
    ","Somehow my master and my origin/master branch have diverged.I actually don't want them to diverge.How can I view these differences and merge them?","You can review the differences with a:git log HEAD..origin/main# old repositoriesgit log HEAD..origin/masterbefore pulling it (fetch + merge) (see also ""How do you get git to always pull from a specific branch?"")Note: since Git 2.28 (Q3 2020), the default branch is configurable, and now (2021+) set to main, no longer master.The rest of the answer reflects that more recent convention.When you have a message like:""Your branch and 'origin/main' have diverged, # and have 1 and 1 different commit(s) each, respectively.""Check if you need to update origin.If origin is up-to-date, then some commits have been pushed to origin from another repo while you made your own commits locally.... o ---- o ---- A ---- B  origin/main (upstream work)                   \                    C  main(your work)You based commit C on commit A because that was the latest work you had fetched from upstream at the time.However, before you tried to push back to origin, someone else pushed the commit B.Development history has diverged into separate paths.You can then merge or rebase. See Pro Git: Git Branching - Rebasing for details.MergeUse the git merge command:$ git merge origin/main# old repositories$ git merge origin/masterThis tells Git to integrate the changes from origin/main into your work and create a merge commit.The graph of history now looks like this:... o ---- o ---- A ---- B  origin/main (upstream work)                   \      \                    C ---- M  main (your work)The new merge, commit M, has two parents, each representing one path of development that led to the content stored in that commit.Note that the history behind M is now non-linear.RebaseUse the git rebase command:$ git rebase origin/main# old repositories$ git rebase origin/masterThis tells Git to replay commit C (your work) as if you had based it on commit B instead of A.CVS and Subversion users routinely rebase their local changes on top of upstream work when they update before commit.Git just adds explicit separation between the commit and rebase steps.The graph of history now looks like this:... o ---- o ---- A ---- B  origin/main (upstream work)                          \                           C'  main (your work)Commit C' is a new commit created by the git rebase command.It is different from C in two ways:It has a different history: B instead of A.Its content accounts for changes in both B and C; it is the same as M from the merge example.Note that the history behind C' is still linear.We have chosen (for now) to allow only linear history in cmake.org/cmake.git.This approach preserves the CVS-based workflow used previously and may ease the transition.An attempt to push C' into our repository will work (assuming you have permissions and no one has pushed while you were rebasing).The git pull command provides a shorthand way to fetch from origin and rebase local work on it:$ git pull --rebaseThis combines the above fetch and rebase steps into one command."
"data_i","edited Mar 21 '19 at 00:52","
        Does Django scale?
    ","I'm building a web application with Django. The reasons I chose Django were:I wanted to work with free/open-source tools.I like Python and feel it's a long-term language, whereas regarding Ruby I wasn't sure, and PHP seemed like a huge hassle to learn.I'm building a prototype for an idea and wasn't thinking too much about the future. Development speed was the main factor, and I already knew Python.I knew the migration to Google App Engine would be easier should I choose to do so in the future.I heard Django was ""nice"".Now that I'm getting closer to thinking about publishing my work, I start being concerned about scale. The only information I found about the scaling capabilities of Django is provided by the Django team (I'm not saying anything to disregard them, but this is clearly not objective information...).My questions:What's the ""largest"" site that's built on Django today? (I measure size mostly by user traffic)Can Django deal with 100,000 users daily, each visiting the site for a couple of hours?Could a site like Stack Overflow run on Django?","""What are the largest sites built on Django today?""There isn't any single place that collects information about traffic on Django built sites, so I'll have to take a stab at it using data from various locations.  First, we have a list of Django sites on the front page of the main Django project page and then a list of Django built sites at djangosites.org.  Going through the lists and picking some that I know have decent traffic we see:Instagram: What Powers Instagram: Hundreds of Instances, Dozens of Technologies.Pinterest: Alexa rank 37 (21.4.2015) and 70 Million users in 2013Bitbucket: 200TB of Code and 2.500.000 UsersDisqus: Serving 400 million people with Python.curse.com: 600k daily visits.tabblo.com: 44k daily visits, see Ned Batchelder's posts Infrastructure for modern web sites.chesspark.com: Alexa rank about 179k.pownce.com (no longer active): alexa rank about 65k.Mike Malone of Pownce, in his EuroDjangoCon presentation on Scaling Django Web Apps says ""hundreds of hits per second"".  This is a very good presentation on how to scale Django, and makes some good points including (current) shortcomings in Django scalability.HP had a site built with Django 1.5: ePrint center. However, as for novemer/2015 the entire website was migrated and this link is just a redirect. This website was a world-wide service attending subscription to Instant Ink and related services HP offered (*).""Can Django deal with 100,000 users daily, each visiting the site for a couple of hours?""Yes, see above.""Could a site like Stack Overflow run on Django?""My gut feeling is yes but, as others answered and Mike Malone mentions in his presentation, database design is critical. Strong proof might also be found at www.cnprog.com if we can find any reliable traffic stats. Anyway, it's not just something that will happen by throwing together a bunch of Django models :)There are, of course, many more sites and bloggers of interest, but I have got to stop somewhere!Blog post about Using Django to build high-traffic site michaelmoore.com described as a top 10,000 website.  Quantcast stats and compete.com stats.(*) The author of the edit, including such reference, used to work as outsourced developer in that project."
"data_i","edited Jul 30 '18 at 18:32","
        Convert ArrayList to String[] array
    ","I'm working in the android environment and have tried the following code, but it doesn't seem to be working.String [] stockArr = (String[]) stock_list.toArray();If I define as follows:String [] stockArr = {""hello"", ""world""};it works. Is there something that I'm missing?","Use like this.List<String> stockList = new ArrayList<String>();stockList.add(""stock1"");stockList.add(""stock2"");String[] stockArr = new String[stockList.size()];stockArr = stockList.toArray(stockArr);for(String s : stockArr)    System.out.println(s);"
"data_i","edited Feb 19 '17 at 11:11","
        How to create a generic array in Java?
    ","Due to the implementation of Java generics, you can't have code like this: public class GenSet<E> {    private E a[];    public GenSet() {        a = new E[INITIAL_ARRAY_LENGTH]; // error: generic array creation    }}How can I implement this while maintaining type safety?I saw a solution on the Java forums that goes like this:import java.lang.reflect.Array;class Stack<T> {    public Stack(Class<T> clazz, int capacity) {        array = (T[])Array.newInstance(clazz, capacity);    }    private final T[] array;}But I really don't get what's going on.","I have to ask a question in return: is your GenSet ""checked"" or ""unchecked""?What does that mean?Checked: strong typing. GenSet knows explicitly what type of objects it contains (i.e. its constructor was explicitly called with a Class<E> argument, and methods will throw an exception when they are passed arguments that are not of type E. See Collections.checkedCollection.-> in that case, you should write:public class GenSet<E> {    private E[] a;    public GenSet(Class<E> c, int s) {        // Use Array native method to create array        // of a type only known at run time        @SuppressWarnings(""unchecked"")        final E[] a = (E[]) Array.newInstance(c, s);        this.a = a;    }    E get(int i) {        return a[i];    }}Unchecked: weak typing. No type checking is actually done on any of the objects passed as argument.-> in that case, you should writepublic class GenSet<E> {    private Object[] a;    public GenSet(int s) {        a = new Object[s];    }    E get(int i) {        @SuppressWarnings(""unchecked"")        final E e = (E) a[i];        return e;    }}Note that the component type of the array should be the erasure of the type parameter:public class GenSet<E extends Foo> { // E has an upper bound of Foo    private Foo[] a; // E erases to Foo, so use Foo[]    public GenSet(int s) {        a = new Foo[s];    }    ...}All of this results from a known, and deliberate, weakness of generics in Java: it was implemented using erasure, so ""generic"" classes don't know what type argument they were created with at run time, and therefore can not provide type-safety unless some explicit mechanism (type-checking) is implemented."
"data_i","edited Jan 06 '21 at 08:26","
        What do ""branch"", ""tag"" and ""trunk"" mean in Subversion repositories?
    ","I've seen these words a lot around Subversion (and I guess general repository) discussions.I have been using SVN for my projects for the last few years, but I've never grasped the complete concept of these directories.What do they mean?","Hmm, not sure I agree with Nick re tag being similar to a branch. A tag is just a markerTrunk would be the main body of development, originating from the start of the project until the present.Branch will be a copy of code derived from a certain point in the trunk that is used for applying major changes to the code while preserving the integrity of the code in the trunk. If the major changes work according to plan, they are usually merged back into the trunk. Tag will be a point in time on the trunk or a branch that you wish to preserve. The two main reasons for preservation would be that either this is a major release of the software, whether alpha, beta, RC or RTM, or this is the most stable point of the software before major revisions on the trunk were applied.In open source projects, major branches that are not accepted into the trunk by the project stakeholders can become the bases for forks -- e.g., totally separate projects that share a common origin with other source code.The branch and tag subtrees are distinguished from the trunk in the following ways:Subversion allows sysadmins to create hook scripts which are triggered for execution when certain events occur; for instance, committing a change to the repository. It is very common for a typical Subversion repository implementation to treat any path containing ""/tag/"" to be write-protected after creation; the net result is that tags, once created, are immutable (at least to ""ordinary"" users). This is done via the hook scripts, which enforce the immutability by preventing further changes if tag is a parent node of the changed object.Subversion also has added features, since version 1.5, relating to ""branch merge tracking"" so that changes committed to a branch can be merged back into the trunk with support for incremental, ""smart"" merging."
"data_i","edited Aug 10 '22 at 18:56","
        Alternatives for returning multiple values from a Python function
    ","The canonical way to return multiple values in languages that support it is often tupling.Option: Using a tupleConsider this trivial example:def f(x):  y0 = x + 1  y1 = x * 3  y2 = y0 ** y3  return (y0, y1, y2)However, this quickly gets problematic as the number of values returned increases. What if you want to return four or five values? Sure, you could keep tupling them, but it gets easy to forget which value is where. It's also rather ugly to unpack them wherever you want to receive them.Option: Using a dictionaryThe next logical step seems to be to introduce some sort of 'record notation'. In Python, the obvious way to do this is by means of a dict.Consider the following:def g(x):  y0 = x + 1  y1 = x * 3  y2 = y0 ** y3  return {'y0': y0, 'y1': y1 ,'y2': y2}(Just to be clear, y0, y1, and y2 are just meant as abstract identifiers. As pointed out, in practice you'd use meaningful identifiers.)Now, we have a mechanism whereby we can project out a particular member of the returned object. For example,result['y0']Option: Using a classHowever, there is another option. We could instead return a specialized structure. I've framed this in the context of Python, but I'm sure it applies to other languages as well. Indeed, if you were working in C this might very well be your only option. Here goes:class ReturnValue:  def __init__(self, y0, y1, y2):     self.y0 = y0     self.y1 = y1     self.y2 = y2def g(x):  y0 = x + 1  y1 = x * 3  y2 = y0 ** y3  return ReturnValue(y0, y1, y2)In Python the previous two are perhaps very similar in terms of plumbing - after all { y0, y1, y2 } just end up being entries in the internal __dict__ of the ReturnValue.There is one additional feature provided by Python though for tiny objects, the __slots__ attribute. The class could be expressed as:class ReturnValue(object):  __slots__ = [""y0"", ""y1"", ""y2""]  def __init__(self, y0, y1, y2):     self.y0 = y0     self.y1 = y1     self.y2 = y2From the Python Reference Manual:The __slots__ declaration takes a sequence of instance variables and reserves just enough space in each instance to hold a value for each variable. Space is saved because __dict__ is not created for each instance.Option: Using a dataclass (Python 3.7+)Using Python 3.7's new dataclasses, return a class with automatically added special methods, typing and other useful tools:@dataclassclass Returnvalue:    y0: int    y1: float    y3: intdef total_cost(x):    y0 = x + 1    y1 = x * 3    y2 = y0 ** y3    return ReturnValue(y0, y1, y2)Option: Using a listAnother suggestion which I'd overlooked comes from Bill the Lizard:def h(x):  result = [x + 1]  result.append(x * 3)  result.append(y0 ** y3)  return resultThis is my least favorite method though. I suppose I'm tainted by exposure to Haskell, but the idea of mixed-type lists has always felt uncomfortable to me. In this particular example the list is -not- mixed type, but it conceivably could be.A list used in this way really doesn't gain anything with respect to the tuple as far as I can tell. The only real difference between lists and tuples in Python is that lists are mutable, whereas tuples are not.I personally tend to carry over the conventions from functional programming: use lists for any number of elements of the same type, and tuples for a fixed number of elements of predetermined types.QuestionAfter the lengthy preamble, comes the inevitable question. Which method (do you think) is best?","Named tuples were added in 2.6 for this purpose.  Also see os.stat for a similar builtin example.>>> import collections>>> Point = collections.namedtuple('Point', ['x', 'y'])>>> p = Point(1, y=2)>>> p.x, p.y1 2>>> p[0], p[1]1 2In recent versions of Python 3 (3.6+, I think), the new typing library got the NamedTuple class to make named tuples easier to create and more powerful. Inheriting from typing.NamedTuple lets you use docstrings, default values, and type annotations.Example (From the docs):class Employee(NamedTuple):  # inherit from typing.NamedTuple    name: str    id: int = 3  # default valueemployee = Employee('Guido')assert employee.id == 3"
"data_i","edited Sep 05 '22 at 19:30","
        Message ""Support for password authentication was removed. Please use a personal access token instead.""
    ","I got this error on my console when I tried to use git pull:remote: Support for password authentication was removed on August 13, 2021. Please use a personal access token instead.remote: Please see https://github.blog/2020-12-15-token-authentication-requirements-for-git-operations/ for more information.fatal: unable to access ""..."" : The requested URL returned error: 403It's very weird, because I just followed the documentation and created a token two weeks ago on GitHub. The token expires on Tue, Oct 26, 2021. Why has this been removed today?","From August 13, 2021, GitHub is no longer accepting account passwords when authenticating Git operations. You need to add a PAT (Personal Access Token) instead, and you can follow the below method to add a PAT on your system.Create Personal Access Token on GitHubFrom your GitHub account, go to Settings => Developer Settings => Personal Access Token =>  Generate New Token (Give your password) => Fillup the form => click Generate token => Copy the generated Token, it will be something like ghp_sFhFsSHhTzMDreGRLjmks4TzuzgthdvfsrtaNow follow below method based on your machine:For Windows OS ⤴Go to Credential Manager from Control Panel => Windows Credentials => find git:https://github.com => Edit => On Password replace with with your GitHub Personal Access Token => You are DoneIf you don’t find git:https://github.com => Click on Add a generic credential => Internet address will be git:https://github.com and you need to type in your username and password will be your GitHub Personal Access Token => Click Ok and you are doneFor macOS ⤴Click on the Spotlight icon (magnifying glass) on the right side of the menu bar. Type Keychain access then press the Enter key to launch the app => In Keychain Access, search for github.com => Find the internet password entry for github.com => Edit or delete the entry accordingly => You are doneFor a Linux-based OS ⤴For Linux, you need to configure the local GIT client with a usernameand email address,$ git config --global user.name ""your_github_username""$ git config --global user.email ""your_github_email""$ git config -lOnce GIT is configured, we can begin using it to access GitHub.Example:$ git clone https://github.com/YOUR-USERNAME/YOUR-REPOSITORY> Cloning into `YOUR-REPOSITORY`...Username: <type your username>Password: <type your password or personal access token (GitHub)Now cache the given record in your computer to remembers the token:$ git config --global credential.helper cacheIf needed, anytime you can delete the cache record by:$ git config --global --unset credential.helper$ git config --system --unset credential.helperNow try to pull with -v to verify$ git pull -vLinux/Debian(Clone as follows):git clone https://<tokenhere>@github.com/<user>/<repo>.gitFor PhpStormIf you are using PhpStorm, go to menu Git => pull and select authentication via Personal Access Token. Enter your PAT it will allow you to pull/push the changes."
"data_i","edited Apr 17 '20 at 17:57","
        How to exit git log or git diff
    ","I'm trying to learn Git with the help of Git Immersion.There's one thing that frustrates me whenever I use git log or git diff:I can't figure out what to do next when I encounter this (END) word.I can't type any commands, and I end up closing the current Bash window and open another. How do I type in the next command that I want to use?","You're in the less program, which makes the output of git log scrollable.Type q to exit this screen. Type h to get help.If you don't want to read the output in a pager and want it to be just printed to the terminal define the environment variable GIT_PAGER to cat or set core.pager to cat (execute git config --global core.pager cat)."
"data_i","edited Apr 15 '19 at 15:24","
        What are the possible values of the Hibernate hbm2ddl.auto configuration and what do they do
    ","I really want to know more about the update, export and the values that could be given to hibernate.hbm2ddl.autoI need to know when to use the update and when not? And what is the alternative?These are changes that could happen over DB:new tablesnew columns in old tablescolumns deleteddata type of a column changeda type of a column changed its attributestables droppedvalues of a column changed In each case what is the best solution?","From the community documentation:hibernate.hbm2ddl.auto    Automatically validates or exports schema DDL to the database when the SessionFactory is created. With create-drop, the database schema will be dropped when the SessionFactory is closed explicitly.e.g. validate | update | create | create-dropSo the list of possible options are,validate: validate the schema, makes no changes to the database.update: update the schema.create: creates the schema, destroying previous data.create-drop: drop the schema when the SessionFactory is closed explicitly, typically when the application is stopped.none: does nothing with the schema, makes no changes to the databaseThese options seem intended to be developers tools and not to facilitate any production level databases, you may want to have a look at the following question; Hibernate: hbm2ddl.auto=update in production?"
"data_i","edited Jul 28 '15 at 10:01","
        What is the best way to conditionally apply a class?
    ","Lets say you have an array that is rendered in a ul with an li for each element and a property on the controller called selectedIndex. What would be the best way to add a class to the li with the index selectedIndex in AngularJS?I am currently duplicating (by hand) the li code and adding the class to one of the li tags and using ng-show and ng-hide to show only one li per index.","If you don't want to put CSS class names into Controller like I do, here is an old trick that I use since pre-v1 days. We can write an expression that evaluates directly to a class name selected, no custom directives are necessary:ng:class=""{true:'selected', false:''}[$index==selectedIndex]""Please note the old syntax with colon. There is also a new better way of applying classes conditionally, like:ng-class=""{selected: $index==selectedIndex}""Angular now supports expressions that return an object. Each property (name) of this object is now considered as a class name and is applied depending on its value.However these ways are not functionally equal. Here is an example:ng-class=""{admin:'enabled', moderator:'disabled', '':'hidden'}[user.role]""We could therefore reuse existing CSS classes by basically mapping a model property to a class name and at the same time keep CSS classes out of Controller code."
"data_i","edited Aug 28 '16 at 15:34","
        When should you use a class vs a struct in C++?
    ","In what scenarios is it better to use a struct vs a class in C++?","The differences between a class and a struct in C++ is:struct members and base classes/structs are public by default.class  members and base classes/struts are private by default.Both classes and structs can have a mixture of public, protected and private members, can use inheritance and can have member functions.I would recommend you:use struct for plain-old-data structures without any class-like features;use class when you make use of features such as private or protected members, non-default constructors and operators, etc."
"data_i","edited Aug 21 '19 at 21:48","
        What is event bubbling and capturing?
    ","What is the difference between event bubbling and capturing? When should one use bubbling vs capturing?","Event bubbling and capturing are two ways of event propagation in the HTML DOM API, when an event occurs in an element inside another element, and both elements have registered a handle for that event. The event propagation mode determines in which order the elements receive the event.With bubbling, the event is first captured and handled by the innermost element and then propagated to outer elements.With capturing, the event is first captured by the outermost element and propagated to the inner elements.Capturing is also called ""trickling"", which helps remember the propagation order:trickle down, bubble upBack in the old days, Netscape advocated event capturing, while Microsoft promoted event bubbling. Both are part of the W3C Document Object Model Events standard (2000).IE < 9 uses only event bubbling, whereas IE9+ and all major browsers support both. On the other hand, the performance of event bubbling may be slightly lower for complex DOMs.We can use the addEventListener(type, listener, useCapture) to register event handlers for in either bubbling (default) or capturing mode. To use the capturing model pass the third argument as true.Example<div>    <ul>        <li></li>    </ul></div>In the structure above, assume that a click event occurred in the li element.In capturing model, the event will be handled by the div first (click event handlers in the div will fire first), then in the ul, then at the last in the target element, li.In the bubbling model, the opposite will happen: the event will be first handled by the li, then by the ul, and at last by the div element.For more information, seeEvent Order on QuirksModeaddEventListener on MDNEvents Advanced on QuirksModeIn the example below, if you click on any of the highlighted elements, you can see that the capturing phase of the event propagation flow occurs first, followed by the bubbling phase.var logElement = document.getElementById('log');function log(msg) {    logElement.innerHTML += ('<p>' + msg + '</p>');}function capture() {    log('capture: ' + this.firstChild.nodeValue.trim());}function bubble() {    log('bubble: ' + this.firstChild.nodeValue.trim());}function clearOutput() {    logElement.innerHTML = """";}var divs = document.getElementsByTagName('div');for (var i = 0; i < divs.length; i++) {    divs[i].addEventListener('click', capture, true);    divs[i].addEventListener('click', bubble, false);}var clearButton = document.getElementById('clear');clearButton.addEventListener('click', clearOutput);p {    line-height: 0;}div {    display:inline-block;    padding: 5px;    background: #fff;    border: 1px solid #aaa;    cursor: pointer;}div:hover {    border: 1px solid #faa;    background: #fdd;}<div>1    <div>2        <div>3            <div>4                <div>5</div>            </div>        </div>    </div></div><button id=""clear"">clear output</button><section id=""log""></section>Another example at JSFiddle."
"data_i","edited Jul 19 '19 at 10:37","
        How do I ""select Android SDK"" in Android Studio?
    ","After a successful import of an Eclipse-Android-Project into ""Android Studio 1.4"", I get the error ""Please select Android SDK""when I click on the button to run the application in simulator, but I can't find any way of doing that.This dialog opens when I click on ""run"":This is the ""project structure"" dialog:What should I do now?","I go to build.gradle and click sync now. Then it worked.Update :  File -> Sync Project with Gradle Files (Android Studio 3.1.1)Tools -> Android -> Sync Project with Gradle Files (Android Studio 3.0.1)Or You can click on the icon from the toolbar.This answer may not help works for later version as Android studio Team work on making the tool more better, the way to sync may be different in the next version of Android Studio.COMMON WAY that may helps is try to sync project and then Invalidate Caches and Restart Android Studio.Solution for Android Studio 3.1.2 [See below answer]See Latest Android Studio version"
"data_i","edited Oct 21 '21 at 13:24","
        Can't bind to 'formGroup' since it isn't a known property of 'form'
    ","The situationI am trying to make what should be a very simple form in my Angular application, but no matter what, it never works.The Angular versionAngular 2.0.0 RC5The errorCan't bind to 'formGroup' since it isn't a known property of 'form'The codeThe view<form [formGroup]=""newTaskForm"" (submit)=""createNewTask()"">   <div class=""form-group"">      <label for=""name"">Name</label>      <input type=""text"" name=""name"" required>   </div>   <button type=""submit"" class=""btn btn-default"">Submit</button></form>The controllerimport { Component } from '@angular/core';import { FormGroup, FormControl, Validators, FormBuilder }  from '@angular/forms';import {FormsModule,ReactiveFormsModule} from '@angular/forms';import { Task } from './task';@Component({    selector: 'task-add',    templateUrl: 'app/task-add.component.html'})export class TaskAddComponent {    newTaskForm: FormGroup;    constructor(fb: FormBuilder)    {        this.newTaskForm = fb.group({            name: ["""", Validators.required]        });    }    createNewTask()    {        console.log(this.newTaskForm.value)    }}The ngModuleimport { NgModule }      from '@angular/core';import { BrowserModule } from '@angular/platform-browser';import { FormsModule }   from '@angular/forms';import { routing }        from './app.routing';import { AppComponent }  from './app.component';import { TaskService } from './task.service'@NgModule({    imports: [        BrowserModule,        routing,        FormsModule    ],    declarations: [ AppComponent ],    providers: [        TaskService    ],    bootstrap: [ AppComponent ]})export class AppModule { }The questionWhy am I getting that error? Am I missing something?","RC6/RC7/Final release FIXTo fix this error, you just need to import ReactiveFormsModule from @angular/forms in your module. Here's the example of a basic module with ReactiveFormsModule import:import { NgModule } from '@angular/core';import { BrowserModule } from '@angular/platform-browser';import { FormsModule, ReactiveFormsModule } from '@angular/forms';import { AppComponent }  from './app.component';@NgModule({    imports: [        BrowserModule,        FormsModule,        ReactiveFormsModule    ],    declarations: [        AppComponent    ],    bootstrap: [AppComponent]})export class AppModule { }To explain further, formGroup is a selector for directive named FormGroupDirective that is a part of ReactiveFormsModule, hence the need to import it. It is used to bind an existing FormGroup to a DOM element. You can read more about it on Angular's official docs page.RC5 FIXYou need to import { REACTIVE_FORM_DIRECTIVES } from '@angular/forms' in your controller and add it to directives in @Component. That will fix the problem.After you fix that, you will probably get another error because you didn't add formControlName=""name"" to your input in form."
"data_i","edited Apr 01 '19 at 21:38","
        How to check if a map contains a key in Go?
    ","I know I can iterate over a map m by,for k, v := range m { ... }and look for a key but is there a more efficient way of testing a key's existence in a map? I couldn't find the answer in the language spec.","One line answer:if val, ok := dict[""foo""]; ok {    //do something here}Explanation:if statements in Go can include both a condition and an initialization statement. The example above uses both:initializes two variables - val will receive either the value of ""foo"" from the map or a ""zero value"" (in this case the empty string) and ok will receive a bool that will be set to true if ""foo"" was actually present in the mapevaluates ok, which will be true if ""foo"" was in the mapIf ""foo"" is indeed present in the map, the body of the if statement will be executed and val will be local to that scope."
"data_i","edited Dec 17 '16 at 12:03","
        How do I get the path to the current script with Node.js?
    ","How would I get the path to the script in Node.js?I know there's process.cwd, but that only refers to the directory where the script was called, not of the script itself. For instance, say I'm in /home/kyle/ and I run the following command:node /home/kyle/some/dir/file.jsIf I call process.cwd(), I get /home/kyle/, not /home/kyle/some/dir/.  Is there a way to get that directory?","I found it after looking through the documentation again. What I was looking for were the __filename and __dirname module-level variables.__filename is the file name of the current module. This is the resolved absolute path of the current module file. (ex:/home/kyle/some/dir/file.js)__dirname is the directory name of the current module. (ex:/home/kyle/some/dir)"
"data_i","edited Jun 20 '22 at 06:52","
        How do I print an exception in Python?
    ","How do I print the error/exception in the except: block?try:    ...except:    print(exception)","For Python 2.6 and later and Python 3.x:except Exception as e: print(e)For Python 2.5 and earlier, use:except Exception,e: print str(e)"
"data_i","edited May 14 '22 at 21:54","
        How can I revert uncommitted changes including files and folders?
    ","Is there a Git command to revert all uncommitted changes in a working tree and index and to also remove newly created files and folders?","You can run these two commands:# Revert changes to modified files.git reset --hard# Remove all untracked files and directories.# '-f' is force, '-d' is remove directories.git clean -fd"
"data_i","edited Jan 12 '22 at 21:05","
        How do you remove all the options of a select box and then add one option and select it with jQuery?
    ","Using core jQuery, how do you remove all the options of a select box, then add one option and select it?My select box is the following.<Select id=""mySelect"" size=""9""> </Select>EDIT: The following code was helpful with chaining. However, (in Internet Explorer) .val('whatever') did not select the option that was added. (I did use the same 'value' in both .append and .val.)$('#mySelect').find('option').remove().end().append('<option value=""whatever"">text</option>').val('whatever');EDIT: Trying to get it to mimic this code, I use the following code whenever the page/form is reset. This select box is populated by a set of radio buttons. .focus() was closer, but the option did not appear selected like it does with .selected= ""true"". Nothing is wrong with my existing code - I am just trying to learn jQuery.var mySelect = document.getElementById('mySelect');mySelect.options.length = 0;mySelect.options[0] = new Option (""Foo (only choice)"", ""Foo"");mySelect.options[0].selected=""true"";EDIT: selected answer was close to what I needed. This worked for me:$('#mySelect').children().remove().end().append('<option selected value=""whatever"">text</option>') ;But both answers led me to my final solution..","$('#mySelect')    .find('option')    .remove()    .end()    .append('<option value=""whatever"">text</option>')    .val('whatever');"
"data_i","edited Aug 22 '16 at 17:47","
        How to convert a string to lower or upper case in Ruby
    ","How do I take a string and convert it to lower or upper case in Ruby?","Ruby has a few methods for changing the case of strings. To convert to lowercase, use downcase:""hello James!"".downcase    #=> ""hello james!""Similarly, upcase capitalizes every letter and capitalize capitalizes the first letter of the string but lowercases the rest:""hello James!"".upcase      #=> ""HELLO JAMES!""""hello James!"".capitalize  #=> ""Hello james!""""hello James!"".titleize    #=> ""Hello James!"" (Rails/ActiveSupport only)If you want to modify a string in place, you can add an exclamation point to any of those methods:string = ""hello James!""string.downcase!string   #=> ""hello james!""Refer to the documentation for String for more information."
"data_i","edited Jul 01 '22 at 14:15","
        Could not find a part of the path ... bin\roslyn\csc.exe
    ","I am trying to run an ASP.NET MVC (model-view-controller) project retrieved from TFS (Team Foundation Server) source control. I have added all assembly references and I am able to build and compile successfully without any error or warning.But I get the following error in the browser:Could not find a part of the path'C:\B8akWorkspace\B8akProject\B8akSolution\B8AK.Portal\bin\roslyn\csc.exe'.Here is a full screenshot of the error page.After few days of research, I understood that Roslyn is a .NET compiler platform that offers advanced compiling features. However, I do not understand why my build is trying to find \bin\roslyn\csc.exe because I did not configure anything related to Roslyn. Nor did I intend to use Roslyn in my project.","TL; DRrun this in the Package Manager Console:Update-Package Microsoft.CodeDom.Providers.DotNetCompilerPlatform -rMore informationThis problem is not related to Visual Studio itself, so answers suggesting adding build steps to copy files over are rather a workaround. Same with adding compiler binaries manually to the project.The Roslyn compiler comes from a NuGet package and there is/was a bug in some versions of that package (I don't know exactly which ones). The solution is to reinstall/upgrade that package to a bug-free version. Originally before I wrote the answer back in 2015 I fixed it by installing following packages at specific versions:Microsoft.Net.Compilers 1.1.1Microsoft.CodeDom.Providers.DotNetCompilerPlatform 1.0.1Then I looked into .csproj and made sure that the paths to packages are correct (in my case ..\..\packages\*.*) inside tags <ImportProject> on top and in <Target> with name ""EnsureNuGetPackageBuildImports"" on the bottom. This is on MVC 5 and .NET Framework 4.5.2."
"data_i","edited Feb 10 '21 at 14:59","
        Returning IEnumerable vs. IQueryable
    ","What is the difference between returning IQueryable<T> vs. IEnumerable<T>, when should one be preferred over the other?IQueryable<Customer> custs = from c in db.Customerswhere c.City == ""<City>""select c;IEnumerable<Customer> custs = from c in db.Customerswhere c.City == ""<City>""select c;Will both be deferred execution and when should one be preferred over the other?","Yes, both will give you deferred execution.The difference is that IQueryable<T> is the interface that allows LINQ-to-SQL (LINQ.-to-anything really) to work. So if you further refine your query on an IQueryable<T>, that query will be executed in the database, if possible. For the IEnumerable<T> case, it will be LINQ-to-object, meaning that all objects matching the original query will have to be loaded into memory from the database.In code:IQueryable<Customer> custs = ...;// Later on...var goldCustomers = custs.Where(c => c.IsGold);That code will execute SQL to only select gold customers. The following code, on the other hand, will execute the original query in the database, then filtering out the non-gold customers in the memory:IEnumerable<Customer> custs = ...;// Later on...var goldCustomers = custs.Where(c => c.IsGold);This is quite an important difference, and working on IQueryable<T> can in many cases save you from returning too many rows from the database. Another prime example is doing paging: If you use Take and Skip on IQueryable, you will only get the number of rows requested; doing that on an IEnumerable<T> will cause all of your rows to be loaded in memory."
"data_i","edited Apr 09 '22 at 10:03","
        Count the number of occurrences of a character in a string
    ","How do I count the number of occurrences of a character in a string?e.g. 'a' appears in 'Mary had a little lamb' 4 times.","str.count(sub[, start[, end]])Return the number of non-overlapping occurrences of substring sub in the range [start, end]. Optional arguments start and end are interpreted as in slice notation.>>> sentence = 'Mary had a little lamb'>>> sentence.count('a')4"
"data_i","edited Jan 27 '19 at 23:42","
        What does %~dp0 mean, and how does it work?
    ","I find %~dp0 very useful, and I use it a lot to make my batch files more portable.But the label itself seems very cryptic to me... What is the ~ doing? Does dp mean drive and path? Does the 0 refer to %0, the path to the batch file that includes the file name?Or it is just a weird label?I'd also like to know if it is a documented feature, or something prone to be deprecated.","Callingfor /?in the command-line gives help about this syntax (which can be used outside FOR, too, this is just the place where help can be found).In addition, substitution of FOR  variable references has been enhanced.  You can now use the following optional  syntax:%~I         - expands %I removing any surrounding quotes ("")%~fI        - expands %I to a fully qualified path name%~dI        - expands %I to a drive letter only%~pI        - expands %I to a path only%~nI        - expands %I to a file name only%~xI        - expands %I to a file extension only%~sI        - expanded path contains short names only%~aI        - expands %I to file attributes of file%~tI        - expands %I to date/time of file%~zI        - expands %I to size of file%~$PATH:I   - searches the directories listed in the PATH               environment variable and expands %I to the               fully qualified name of the first one found.               If the environment variable name is not               defined or the file is not found by the               search, then this modifier expands to the               empty stringThe modifiers can be combined to get  compound results:%~dpI       - expands %I to a drive letter and path only%~nxI       - expands %I to a file name and extension only%~fsI       - expands %I to a full path name with short names only%~dp$PATH:I - searches the directories listed in the PATH               environment variable for %I and expands to the               drive letter and path of the first one found.%~ftzaI     - expands %I to a DIR like output lineIn the above examples %I and PATH can  be replaced by other valid values.   The %~ syntax is terminated by a valid  FOR variable name. Picking upper case  variable names like %I makes it more  readable and avoids confusion with the  modifiers, which are not case  sensitive.There are different letters you can use like f for ""full path name"", d for drive letter, p for path, and they can be combined. %~ is the beginning for each of those sequences and a number I denotes it works on the parameter %I (where %0 is the complete name of the batch file, just like you assumed)."
"data_i","edited Jul 29 '20 at 05:17","
        Ukkonen's suffix tree algorithm in plain English
    ","I feel a bit thick at this point. I've spent days trying to fully wrap my head around suffix tree construction, but because I don't have a mathematical background, many of the explanations elude me as they start to make excessive use of mathematical symbology. The closest to a good explanation that I've found is Fast String Searching With Suffix Trees, but he glosses over various points and some aspects of the algorithm remain unclear.A step-by-step explanation of this algorithm here on Stack Overflow would be invaluable for many others besides me, I'm sure.For reference, here's Ukkonen's paper on the algorithm: http://www.cs.helsinki.fi/u/ukkonen/SuffixT1withFigs.pdfMy basic understanding, so far:I need to iterate through each prefix P of a given string TI need to iterate through each suffix S in prefix P and add that to treeTo add suffix S to the tree, I need to iterate through each character in S, with the iterations consisting of either walking down an existing branch that starts with the same set of characters C in S and potentially splitting an edge into descendent nodes when I reach a differing character in the suffix, OR if there was no matching edge to walk down. When no matching edge is found to walk down for C, a new leaf edge is created for C.The basic algorithm appears to be O(n2), as is pointed out in most explanations, as we need to step through all of the prefixes, then we need to step through each of the suffixes for each prefix. Ukkonen's algorithm is apparently unique because of the suffix pointer technique he uses, though I think that is what I'm having trouble understanding.I'm also having trouble understanding:exactly when and how the ""active point"" is assigned, used and changedwhat is going on with the canonization aspect of the algorithmWhy the implementations I've seen need to ""fix"" bounding variables that they are usingHere is the completed C# source code. It not only works correctly, but supports automatic canonization and renders a nicer looking text graph of the output. Source code and sample output is at:https://gist.github.com/2373868Update 2017-11-04After many years I've found a new use for suffix trees, and have implemented the algorithm in JavaScript. Gist is below. It should be bug-free. Dump it into a js file, npm install chalk from the same location, and then run with node.js to see some colourful output. There's a stripped down version in the same Gist, without any of the debugging code.https://gist.github.com/axefrog/c347bf0f5e0723cbd09b1aaed6ec6fc6","The following is an attempt to describe the Ukkonen algorithm by first showing what it does when the string is simple (i.e. does not contain any repeated characters), and then extending it to the full algorithm.First, a few preliminary statements.What we are building, is basically like a search trie. So thereis a root node, edges going out of it leading to new nodes, andfurther edges going out of those, and so forthBut: Unlike in a search trie, the edge labels are not singlecharacters. Instead, each edge is labeled using a pair of integers[from,to]. These are pointers into the text. In this sense, eachedge carries a string label of arbitrary length, but takes only O(1)space (two pointers).Basic principleI would like to first demonstrate how to create the suffix tree of aparticularly simple string, a string with no repeated characters:abcThe algorithm works in steps, from left to right. There is one step for every character of the string. Each step might involve more than one individual operation, but we will see (see the final observations at the end) that the total number of operations is O(n).So, we start from the left, and first insert only the single charactera by creating an edge from the root node (on the left) to a leaf,and labeling it as [0,#], which means the edge represents thesubstring starting at position 0 and ending at the current end. Iuse the symbol # to mean the current end, which is at position 1(right after a).So we have an initial tree, which looks like this:And what it means is this:Now we progress to position 2 (right after b). Our goal at each stepis to insert all suffixes up to the current position. We do thisbyexpanding the existing a-edge to abinserting one new edge for bIn our representation this looks likeAnd what it means is:We observe two things:The edge representation for ab is the same as it used to bein the initial tree: [0,#]. Its meaning has automatically changedbecause we updated the current position # from 1 to 2.Each edge consumes O(1) space, because it consists of only twopointers into the text, regardless of how many characters itrepresents.Next we increment the position again and update the tree by appendinga c to every existing edge and inserting one new edge for the newsuffix c.In our representation this looks likeAnd what it means is:We observe:The tree is the correct suffix tree up to the current positionafter each stepThere are as many steps as there are characters in the textThe amount of work in each step is O(1), because all existing edgesare updated automatically by incrementing #, and inserting theone new edge for the final character can be done in O(1)time. Hence for a string of length n, only O(n) time is required.First extension: Simple repetitionsOf course this works so nicely only because our string does notcontain any repetitions. We now look at a more realistic string:abcabxabcdIt starts with abc as in the previous example, then ab is repeatedand followed by x, and then abc is repeated followed by d.Steps 1 through 3: After the first 3 steps we have the tree from the previous example:Step 4: We move # to position 4. This implicitly updates all existingedges to this:and we need to insert the final suffix of the current step, a, atthe root.Before we do this, we introduce two more variables (in addition to#), which of course have been there all the time but we haven't usedthem so far:The active point, which is a triple(active_node,active_edge,active_length)The remainder, which is an integer indicating how many new suffixeswe need to insertThe exact meaning of these two will become clear soon, but for nowlet's just say:In the simple abc example, the active point was always(root,'\0x',0), i.e. active_node was the root node, active_edge was specified as the null character '\0x', and active_length was zero. The effect of this was that the one new edge thatwe inserted in every step was inserted at the root node as afreshly created edge. We will see soon why a triple is necessary torepresent this information.The remainder was always set to 1 at the beginning of eachstep. The meaning of this was that the number of suffixes we had toactively insert at the end of each step was 1 (always just thefinal character).Now this is going to change. When we insert the current finalcharacter a at the root, we notice that there is already an outgoingedge starting with a, specifically: abca. Here is what we do insuch a case:We do not insert a fresh edge [4,#] at the root node. Instead wesimply notice that the suffix a is already in ourtree. It ends in the middle of a longer edge, but we are notbothered by that. We just leave things the way they are.We set the active point to (root,'a',1). That means the activepoint is now somewhere in the middle of outgoing edge of the root node that starts with a, specifically, after position 1 on that edge. Wenotice that the edge is specified simply by its firstcharacter a. That suffices because there can be only one edgestarting with any particular character (confirm that this is true after reading through the entire description).We also increment remainder, so at the beginning of the next stepit will be 2.Observation: When the final suffix we need to insert is found toexist in the tree already, the tree itself is not changed at all (we only update the active point and remainder). The treeis then not an accurate representation of the suffix tree up to thecurrent position any more, but it contains all suffixes (because the finalsuffix a is contained implicitly). Hence, apart from updating thevariables (which are all of fixed length, so this is O(1)), there wasno work done in this step.Step 5: We update the current position # to 5. Thisautomatically updates the tree to this:And because remainder is 2, we need to insert two finalsuffixes of the current position: ab and b. This is basically because:The a suffix from the previous step has never been properlyinserted. So it has remained, and since we have progressed onestep, it has now grown from a to ab.And we need to insert the new final edge b.In practice this means that we go to the active point (which points tobehind the a on what is now the abcab edge), and insert thecurrent final character b. But: Again, it turns out that b isalso already present on that same edge.So, again, we do not change the tree. We simply:Update the active point to (root,'a',2) (same node and edgeas before, but now we point to behind the b)Increment the remainder to 3 because we still have not properlyinserted the final edge from the previous step, and we don't insertthe current final edge either.To be clear: We had to insert ab and b in the current step, butbecause ab was already found, we updated the active point and didnot even attempt to insert b. Why? Because if ab is in the tree,every suffix of it (including b) must be in the tree,too. Perhaps only implicitly, but it must be there, because of theway we have built the tree so far.We proceed to step 6 by incrementing #. The tree isautomatically updated to:Because remainder is 3, we have to insert abx, bx andx. The active point tells us where ab ends, so we only need tojump there and insert the x. Indeed, x is not there yet, so wesplit the abcabx edge and insert an internal node:The edge representations are still pointers into the text, sosplitting and inserting an internal node can be done in O(1) time.So we have dealt with abx and decrement remainder to 2. Now weneed to insert the next remaining suffix, bx. But before we do thatwe need to update the active point. The rule for this, after splittingand inserting an edge, will be called Rule 1 below, and it applies whenever theactive_node is root (we will learn rule 3 for other cases furtherbelow). Here is rule 1:After an insertion from root,active_node remains rootactive_edge is set to the first character of the new suffix we  need to insert, i.e. bactive_length is reduced by 1Hence, the new active-point triple (root,'b',1) indicates that thenext insert has to be made at the bcabx edge, behind 1 character,i.e. behind b. We can identify the insertion point in O(1) time andcheck whether x is already present or not. If it was present, wewould end the current step and leave everything the way it is. But xis not present, so we insert it by splitting the edge:Again, this took O(1) time and we update remainder to 1 and theactive point to (root,'x',0) as rule 1 states.But there is one more thing we need to do. We'll call this Rule 2:If we split an edge and insert a new node, and if that is not the  first node created during the current step, we connect the previously  inserted node and the new node through a special pointer, a suffix  link. We will later see why that is useful. Here is what we get, the  suffix link is represented as a dotted edge:We still need to insert the final suffix of the current step,x. Since the active_length component of the active node has fallento 0, the final insert is made at the root directly. Since there is nooutgoing edge at the root node starting with x, we insert a newedge:As we can see, in the current step all remaining inserts were made.We proceed to step 7 by setting #=7, which automatically appends the next character,a, to all leaf edges, as always. Then we attempt to insert the new finalcharacter to the active point (the root), and find that it is therealready. So we end the current step without inserting anything andupdate the active point to (root,'a',1).In step 8, #=8, we append b, and as seen before, this onlymeans we update the active point to (root,'a',2) and increment remainder without doinganything else, because b is already present. However, we notice (in O(1) time) that the active pointis now at the end of an edge. We reflect this by re-setting it to(node1,'\0x',0). Here, I use node1 to refer to theinternal node the ab edge ends at.Then, in step #=9, we need to insert 'c' and this will help us tounderstand the final trick:Second extension: Using suffix linksAs always, the # update appends c automatically to the leaf edgesand we go to the active point to see if we can insert 'c'. It turnsout 'c' exists already at that edge, so we set the active point to(node1,'c',1), increment remainder and do nothing else.Now in step #=10, remainder is 4, and so we first need to insertabcd (which remains from 3 steps ago) by inserting d at the activepoint.Attempting to insert d at the active point causes an edge split inO(1) time:The active_node, from which the split was initiated, is marked inred above. Here is the final rule, Rule 3:After splitting an edge from an active_node that is not the root  node, we follow the suffix link going out of that node, if there is  any, and reset the active_node to the node it points to. If there is  no suffix link, we set the active_node to the root. active_edge  and active_length remain unchanged.So the active point is now (node2,'c',1), and node2 is marked inred below:Since the insertion of abcd is complete, we decrement remainder to3 and consider the next remaining suffix of the current step,bcd. Rule 3 has set the active point to just the right node and edgeso inserting bcd can be done by simply inserting its final characterd at the active point.Doing this causes another edge split, and because of rule 2, wemust create a suffix link from the previously inserted node to the newone:We observe: Suffix links enable us to reset the active point so we  can make the next remaining insert at O(1) effort. Look at the  graph above to confirm that indeed node at label ab is linked to  the node at b (its suffix), and the node at abc is linked to  bc.The current step is not finished yet. remainder is now 2, and weneed to follow rule 3 to reset the active point again. Since thecurrent active_node (red above) has no suffix link, we reset toroot. The active point is now (root,'c',1).Hence the next insert occurs at the one outgoing edge of the root nodewhose label starts with c: cabxabcd, behind the first character,i.e. behind c. This causes another split:And since this involves the creation of a new internal node,we followrule 2 and set a new suffix link from the previously created internalnode:(I am using Graphviz Dot for these littlegraphs. The new suffix link caused dot to re-arrange the existingedges, so check carefully to confirm that the only thing that wasinserted above is a new suffix link.)With this, remainder can be set to 1 and since the active_node isroot, we use rule 1 to update the active point to (root,'d',0). Thismeans the final insert of the current step is to insert a single dat root:That was the final step and we are done. There are number of finalobservations, though:In each step we move # forward by 1 position. This automaticallyupdates all leaf nodes in O(1) time.But it does not deal with a) any suffixes remaining from previoussteps, and b) with the one final character of the current step.remainder tells us how many additional inserts we need tomake. These inserts correspond one-to-one to the final suffixes ofthe string that ends at the current position #. We consider oneafter the other and make the insert. Important: Each insert isdone in O(1) time since the active point tells us exactly where togo, and we need to add only one single character at the activepoint. Why? Because the other characters are contained implicitly(otherwise the active point would not be where it is).After each such insert, we decrement remainder and follow thesuffix link if there is any. If not we go to root (rule 3). If weare at root already, we modify the active point using rule 1. Inany case, it takes only O(1) time.If, during one of these inserts, we find that the character we wantto insert is already there, we don't do anything and end thecurrent step, even if remainder>0. The reason is that anyinserts that remain will be suffixes of the one we just tried tomake. Hence they are all implicit in the current tree. The factthat remainder>0 makes sure we deal with the remaining suffixeslater.What if at the end of the algorithm remainder>0? This will be thecase whenever the end of the text is a substring that occurredsomewhere before. In that case we must append one extra characterat the end of the string that has not occurred before. In theliterature, usually the dollar sign $ is used as a symbol forthat. Why does that matter? --> If later we use the completed suffix tree to search for suffixes, we must accept matches only if they end at a leaf. Otherwise we would get a lot of spurious matches, because there are many strings implicitly contained in the tree that are not actual suffixes of the main string. Forcing remainder to be 0 at the end is essentially a way to ensure that all suffixes end at a leaf node. However, if we want to use the tree to search for general substrings, not only suffixes of the main string, this final step is indeed not required, as suggested by the OP's comment below.So what is the complexity of the entire algorithm? If the text is ncharacters in length, there are obviously n steps (or n+1 if we addthe dollar sign). In each step we either do nothing (other thanupdating the variables), or we make remainder inserts, each taking O(1)time. Since remainder indicates how many times we have done nothingin previous steps, and is decremented for every insert that we makenow, the total number of times we do something is exactly n (orn+1). Hence, the total complexity is O(n).However, there is one small thing that I did not properly explain:It can happen that we follow a suffix link, update the activepoint, and then find that its active_length component does notwork well with the new active_node. For example, consider a situationlike this:(The dashed lines indicate the rest of the tree. The dotted line is asuffix link.)Now let the active point be (red,'d',3), so it points to the placebehind the f on the defg edge. Now assume we made the necessaryupdates and now follow the suffix link to update the active pointaccording to rule 3. The new active point is (green,'d',3). However,the d-edge going out of the green node is de, so it has only 2characters. In order to find the correct active point, we obviouslyneed to follow that edge to the blue node and reset to (blue,'f',1).In a particularly bad case, the active_length could be as large asremainder, which can be as large as n. And it might very well happenthat to find the correct active point, we need not only jump over oneinternal node, but perhaps many, up to n in the worst case. Does thatmean the algorithm has a hidden O(n2) complexity, becausein each step remainder is generally O(n), and the post-adjustmentsto the active node after following a suffix link could be O(n), too?No. The reason is that if indeed we have to adjust the active point(e.g. from green to blue as above), that brings us to a new node thathas its own suffix link, and active_length will be reduced. Aswe follow down the chain of suffix links we make the remaining inserts, active_length can onlydecrease, and the number of active-point adjustments we can make onthe way can't be larger than active_length at any given time. Sinceactive_length can never be larger than remainder, and remainderis O(n) not only in every single step, but the total sum of incrementsever made to remainder over the course of the entire process isO(n) too, the number of active point adjustments is also bounded byO(n)."
"data_i","edited May 30 '20 at 00:15","
        How to understand nil vs. empty vs. blank in Ruby
    ","I find myself repeatedly looking for a clear definition of the differences of nil?, blank?, and empty? in Ruby on Rails.  Here's the closest I've come:blank? objects are false, empty, or a whitespace string. For example, """", "" "", nil, [], and {} are blank.nil? objects are instances of NilClass.empty? objects are class-specific, and the definition varies from class to class. A string is empty if it has no characters, and an array is empty if it contains no items.Is there anything missing, or a tighter comparison that can be made?",".nil? can be used on any object and is true if the object is nil..empty? can be used on strings, arrays and hashes and returns true if:String length == 0Array length == 0Hash length == 0Running .empty? on something that is nil will throw a NoMethodError.That is where .blank? comes in. It is implemented by Rails and will operate on any object as well as work like .empty? on strings, arrays and hashes.nil.blank? == truefalse.blank? == true[].blank? == true{}.blank? == true"""".blank? == true5.blank? == false0.blank? == false.blank? also evaluates true on strings which are non-empty but contain only whitespace:""  "".blank? == true""  "".empty? == falseRails also provides .present?, which returns the negation of .blank?.Array gotcha: blank? will return false even if all elements of an array are blank. To determine blankness in this case, use all? with blank?, for example:[ nil, '' ].blank? == false[ nil, '' ].all? &:blank? == true "
"data_i","edited Dec 13 '19 at 05:53","
        How to effectively work with multiple files in Vim
    ","I've started using Vim to develop Perl scripts and am starting to find it very powerful. One thing I like is to be able to open multiple files at once with:vi main.pl maintenance.pland then hop between them with::n:prevand see which file are open with::argsAnd to add a file, I can say: :n test.plwhich I expect would then be added to my list of files, but instead it wipes out my current file list and when I type :args I only have test.pl open.So how can I add and remove files in my args list?","Why not use tabs (introduced in Vim 7)?You can switch between tabs with :tabn and :tabp,With :tabe <filepath> you can add a new tab; and with a regular :q or :wq you close a tab.If you map :tabn and :tabp to your F7/F8 keys you can easily switch between files.If there are not that many files or you don't have Vim 7 you can also split your screen in multiple files: :sp <filepath>. Then you can switch between splitscreens with Ctrl+W and then an arrow key in the direction you want to move (or instead of arrow keys, w for next and W for previous splitscreen)"
"data_i","edited Dec 15 '18 at 17:59","
        How do I collapse sections of code in Visual Studio Code for Windows?
    ","How do I fold or collapse sections of code in Visual Studio Code?Is this feature supported?","Folding has been rolled out and is now implemented since Visual Studio Code version 0.10.11. There are these keyboard shortcuts available:Fold folds the innermost uncollapsed region at the cursor:Ctrl + Shift + [ on Windows and Linux⌥ + ⌘ + [ on macOSUnfold unfolds the collapsed region at the cursor:Ctrl + Shift + ] on Windows and Linux⌥ + ⌘ + ] on macOSFold All folds all regions in the editor:Ctrl + K, Ctrl + 0 (zero) on Windows and Linux⌘ + K, ⌘ +0 (zero) on macOSUnfold All unfolds all regions in the editor:Ctrl + K, Ctrl + J on Windows and Linux⌘ + K, ⌘ + J on macOSReferences: https://code.visualstudio.com/docs/getstarted/keybindings"
"data_i","edited Dec 15 '19 at 04:44","
        How can I tell if a DOM element is visible in the current viewport?
    ","Is there an efficient way to tell if a DOM element (in an HTML document) is currently visible (appears in the viewport)?(The question refers to Firefox.)","Now most browsers support getBoundingClientRect method, which has become the best practice. Using an old answer is very slow, not accurate and has several bugs.The solution selected as correct is almost never precise.This solution was tested on Internet Explorer 7 (and later), iOS 5 (and later) Safari, Android 2.0 (Eclair) and later, BlackBerry, Opera Mobile, and Internet Explorer Mobile 9.function isElementInViewport (el) {    // Special bonus for those using jQuery    if (typeof jQuery === ""function"" && el instanceof jQuery) {        el = el[0];    }    var rect = el.getBoundingClientRect();    return (        rect.top >= 0 &&        rect.left >= 0 &&        rect.bottom <= (window.innerHeight || document.documentElement.clientHeight) && /* or $(window).height() */        rect.right <= (window.innerWidth || document.documentElement.clientWidth) /* or $(window).width() */    );}How to use:You can be sure that the function given above returns correct answer at the moment of time when it is called, but what about tracking element's visibility as an event?Place the following code at the bottom of your <body> tag:function onVisibilityChange(el, callback) {    var old_visible;    return function () {        var visible = isElementInViewport(el);        if (visible != old_visible) {            old_visible = visible;            if (typeof callback == 'function') {                callback();            }        }    }}var handler = onVisibilityChange(el, function() {    /* Your code go here */});// jQuery$(window).on('DOMContentLoaded load resize scroll', handler);/* // Non-jQueryif (window.addEventListener) {    addEventListener('DOMContentLoaded', handler, false);    addEventListener('load', handler, false);    addEventListener('scroll', handler, false);    addEventListener('resize', handler, false);} else if (window.attachEvent)  {    attachEvent('onDOMContentLoaded', handler); // Internet Explorer 9+ :(    attachEvent('onload', handler);    attachEvent('onscroll', handler);    attachEvent('onresize', handler);}*/If you do any DOM modifications, they can change your element's visibility of course.Guidelines and common pitfalls:Maybe you need to track page zoom / mobile device pinch? jQuery should handle zoom/pinch cross browser, otherwise first or second link should help you.If you modify DOM, it can affect the element's visibility. You should take control over that and call handler() manually. Unfortunately, we don't have any cross browser onrepaint event. On the other hand that allows us to make optimizations and perform re-check only on DOM modifications that can change an element's visibility.Never Ever use it inside jQuery $(document).ready() only, because there is no warranty CSS has been applied in this moment. Your code can work locally with your CSS on a hard drive, but once put on a remote server it will fail.After DOMContentLoaded is fired, styles are applied, but the images are not loaded yet. So, we should add window.onload event listener.We can't catch zoom/pinch event yet.The last resort could be the following code:/* TODO: this looks like a very bad code */setInterval(handler, 600);You can use the awesome feature pageVisibiliy of the HTML5 API if you care if the tab with your web page is active and visible.TODO: this method does not handle two situations:Overlapping using z-index.Using overflow-scroll in element's container.Try something new - The Intersection Observer API explained."
"data_i","edited Jul 16 '20 at 22:38","
        How to mark a method as obsolete or deprecated?
    ","How do I mark a method as obsolete or deprecated using C#?","The shortest way is by adding the ObsoleteAttribute as an attribute to the method. Make sure to include an appropriate explanation:[Obsolete(""Method1 is deprecated, please use Method2 instead."")]public void Method1(){ … }You can also cause the compilation to fail, treating the usage of the method as an error instead of warning, if the method is called from somewhere in code like this:[Obsolete(""Method1 is deprecated, please use Method2 instead."", true)]"
"data_i","edited Sep 01 '22 at 14:33","
        Listing only directories using ls in Bash?
    ","This command lists directories in the current path:ls -d */What exactly does the pattern */ do?And how can we give the absolute path in the above command (e.g. ls -d /home/alice/Documents) for listing only directories in that path?","*/ is a pattern that matches all of the subdirectories in the current directory (* would match all files and subdirectories; the / restricts it to directories). Similarly, to list all subdirectories under /home/alice/Documents, use ls -d /home/alice/Documents/*/"
"data_i","edited Mar 15 '18 at 00:00","
        Get JavaScript object from array of objects by value of property
    ","Let's say I have an array of four objects:var jsObjects = [   {a: 1, b: 2},    {a: 3, b: 4},    {a: 5, b: 6},    {a: 7, b: 8}];Is there a way that I can get the third object ({a: 5, b: 6}) by the value of the property b for example without a for...in loop?","Filter array of objects, which property matches value, returns array:var result = jsObjects.filter(obj => {  return obj.b === 6})See the MDN Docs on Array.prototype.filter()const jsObjects = [  {a: 1, b: 2},   {a: 3, b: 4},   {a: 5, b: 6},   {a: 7, b: 8}]let result = jsObjects.filter(obj => {  return obj.b === 6})console.log(result)Find the value of the first element/object in the array, otherwise undefined is returned.var result = jsObjects.find(obj => {  return obj.b === 6})See the MDN Docs on Array.prototype.find()const jsObjects = [  {a: 1, b: 2},   {a: 3, b: 4},   {a: 5, b: 6},   {a: 7, b: 8}]let result = jsObjects.find(obj => {  return obj.b === 6})console.log(result)"
"data_i","edited Mar 24 '20 at 17:47","
        HTTP response code for POST when resource already exists
    ","I'm building a server that allows clients to store objects.  Those objects are fully constructed at client side, complete with object IDs that are permanent for the whole lifetime of the object.I have defined the API so that clients can create or modify objects using PUT:PUT /objects/{id} HTTP/1.1...{json representation of the object}The {id} is the object ID, so it is part of the Request-URI.Now, I'm also considering allowing clients to create the object using POST:POST /objects/ HTTP/1.1...{json representation of the object, including ID}Since POST is meant as ""append"" operation, I'm not sure what to do in case the object is already there.  Should I treat the request as modification request or should I return some error code (which)?","My feeling is 409 Conflict is the most appropriate, however, seldom seen in the wild of course:The request could not be completed due to a conflict with the current state of the resource. This code is only allowed in situations where it is expected that the user might be able to resolve the conflict and resubmit the request. The response body SHOULD include enough information for the user to recognize the source of the conflict. Ideally, the response entity would include enough information for the user or user agent to fix the problem; however, that might not be possible and is not required.Conflicts are most likely to occur in response to a PUT request. For example, if versioning were being used and the entity being PUT included changes to a resource which conflict with those made by an earlier (third-party) request, the server might use the 409 response to indicate that it can't complete the request. In this case, the response entity would likely contain a list of the differences between the two versions in a format defined by the response Content-Type."
"data_i","edited Nov 10 '20 at 12:19","
        How can I pipe stderr, and not stdout?
    ","I have a program that writes information to stdout and stderr, and I need to process the stderr with grep, leaving stdout aside.Using a temporary file, one could do it in two steps:command > /dev/null 2> temp.filegrep 'something' temp.fileBut how can this be achieved without temp files, using one command and pipes?","First redirect stderr to stdout — the pipe; then redirect stdout to /dev/null (without changing where stderr is going):command 2>&1 >/dev/null | grep 'something'For the details of I/O redirection in all its variety, see the chapter on Redirections in the Bash reference manual.Note that the sequence of I/O redirections is interpreted left-to-right, but pipes are set up before the I/O redirections are interpreted.  File descriptors such as 1 and 2 are references to open file descriptions.  The operation 2>&1 makes file descriptor 2 aka stderr refer to the same open file description as file descriptor 1 aka stdout is currently referring to (see dup2() and open()).  The operation >/dev/null then changes file descriptor 1 so that it refers to an open file description for /dev/null, but that doesn't change the fact that file descriptor 2 refers to the open file description which file descriptor 1 was originally pointing to — namely, the pipe."
"data_i","edited Aug 22 '20 at 09:32","
        Create a git patch from the uncommitted changes in the current working directory
    ","Say I have uncommitted changes in my working directory. How can I make a patch from those without having to create a commit?","If you haven't yet commited the changes, then:git diff > mypatch.patchBut sometimes it happens that part of the stuff you're doing are new files that are untracked and won't be in your git diff output. So, one way to do a patch is to stage everything for a new commit (git add each file, or just git add .) but don't do the commit, and then:git diff --cached > mypatch.patchAdd the 'binary' option if you want to add binary files to the patch (e.g. mp3 files):git diff --cached --binary > mypatch.patchYou can later apply the patch:git apply mypatch.patch"
"data_i","edited Aug 28 '17 at 00:43","
        What does  in XML mean?
    ","I often find this strange CDATA tag in XML files:<![CDATA[some stuff]]>I have observed that this CDATA tag always comes at the beginning, and then followed by some stuff.But sometimes it is used, sometimes it is not. I assume it is to mark that some stuff is the ""data"" that will be inserted after that. But what kind of data is some stuff? Isn't anything I write in XML tags some sort of data?","CDATA stands for Character Data and it means that the data in between these strings includes data that could be interpreted as XML markup, but should not be.The key differences between CDATA and comments are:As Richard points out, CDATA is still part of the document, while a comment is not.In CDATA you cannot include the string ]]> (CDEnd), while in a comment -- is invalid.Parameter Entity references are not recognized inside of comments.This means given these four snippets of XML from one well-formed document:<!ENTITY MyParamEntity ""Has been expanded""><!--Within this comment I can use ]]>and other reserved characters like <&, ', and "", but %MyParamEntity; will not be expanded(if I retrieve the text of this node it will contain%MyParamEntity; and not ""Has been expanded"")and I can't place two dashes next to each other.--><![CDATA[Within this Character Data block I canuse double dashes as much as I want (along with <, &, ', and "")*and* %MyParamEntity; will be expanded to the text""Has been expanded"" ... however, I can't usethe CEND sequence. If I need to use CEND I must escape one of thebrackets or the greater-than sign using concatenated CDATA sections.]]><description>An example of escaped CENDs</description><!-- This text contains a CEND ]]> --><!-- In this first case we put the ]] at the end of the first CDATA block     and the > in the second CDATA block --><data><![CDATA[This text contains a CEND ]]]]><![CDATA[>]]></data><!-- In this second case we put a ] at the end of the first CDATA block     and the ]> in the second CDATA block --><alternative><![CDATA[This text contains a CEND ]]]><![CDATA[]>]]></alternative>"
"data_i","edited May 23 '20 at 07:15","
        How to overcome ""datetime.datetime not JSON serializable""?
    ","I have a basic dict as follows:sample = {}sample['title'] = ""String""sample['somedate'] = somedatetimehereWhen I try to do jsonify(sample) I get:TypeError: datetime.datetime(2012, 8, 8, 21, 46, 24, 862000) is not JSON serializableWhat can I do such that my dictionary sample can overcome the error above?Note: Though it may not be relevant, the dictionaries are generated from the retrieval of records out of mongodb where when I print out str(sample['somedate']), the output is 2012-08-08 21:46:24.862000.","My quick & dirty JSON dump that eats dates and everything:json.dumps(my_dictionary, indent=4, sort_keys=True, default=str)default is a function applied to objects that aren't serializable.In this case it's str, so it just converts everything it doesn't know to strings. Which is great for serialization but not so great when deserializing (hence the ""quick & dirty"") as anything might have been string-ified without warning, e.g. a function or numpy array."
"data_i","edited Mar 23 '19 at 08:51","
        How do you get the index of the current iteration of a foreach loop?
    ","Is there some rare language construct I haven't encountered (like the few I've learned recently, some on Stack Overflow) in C# to get a value representing the current iteration of a foreach loop?For instance, I currently do something like this depending on the circumstances:int i = 0;foreach (Object o in collection){    // ...    i++;}","Ian Mercer posted a similar solution as this on Phil Haack's blog:foreach (var item in Model.Select((value, i) => new { i, value })){    var value = item.value;    var index = item.i;}This gets you the item (item.value) and its index (item.i) by using this overload of LINQ's Select:the second parameter of the function [inside Select] represents the index of the source element.The new { i, value } is creating a new anonymous object.Heap allocations can be avoided by using ValueTuple if you're using C# 7.0 or later:foreach (var item in Model.Select((value, i) => ( value, i ))){    var value = item.value;    var index = item.i;}You can also eliminate the item. by using automatic destructuring:foreach (var (value, i) in Model.Select((value, i) => ( value, i ))){    // Access `value` and `i` directly here.}"
"data_i","edited Mar 21 '17 at 21:26","
        How does the SQL injection from the ""Bobby Tables"" XKCD comic work?
    ","Just looking at:(Source: https://xkcd.com/327/)What does this SQL do:Robert'); DROP TABLE STUDENTS; --I know both ' and -- are for comments, but doesn't the word DROP get commented as well since it is part of the same line?","It drops the students table.The original code in the school's program probably looks something likeq = ""INSERT INTO Students VALUES ('"" + FNMName.Text + ""', '"" + LName.Text + ""')"";This is the naive way to add text input into a query, and is very bad, as you will see.After the values from the first name, middle name textbox FNMName.Text (which is Robert'); DROP TABLE STUDENTS; --) and the last name textbox LName.Text (let's call it Derper) are concatenated with the rest of the query, the result is now actually two queries separated by the statement terminator (semicolon).  The second query has been injected into the first.  When the code executes this query against the database, it will look like thisINSERT INTO Students VALUES ('Robert'); DROP TABLE Students; --', 'Derper')which, in plain English, roughly translates to the two queries:Add a new record to the Students table with a Name value of 'Robert'andDelete the Students tableEverything past the second query is marked as a comment:  --', 'Derper')The ' in the student's name is not a comment, it's the closing string delimiter.  Since the student's name is a string, it's needed syntactically to complete the hypothetical query.  Injection attacks only work when the SQL query they inject results in valid SQL.Edited again as per dan04's astute comment"
"data_i","edited Apr 03 '21 at 19:22","
        How do I display an alert dialog on Android?
    ","I want to display a dialog/popup window with a message to the user that shows ""Are you sure you want to delete this entry?"" with one button that says 'Delete'. When Delete is touched, it should delete that entry, otherwise nothing.I have written a click listener for those buttons, but how do I invoke a dialog or popup and its functionality?","You could use an AlertDialog for this and construct one using its Builder class. The example below uses the default constructor that only takes in a Context since the dialog will inherit the proper theme from the Context you pass in, but there's also a constructor that allows you to specify a specific theme resource as the second parameter if you desire to do so.new AlertDialog.Builder(context)    .setTitle(""Delete entry"")    .setMessage(""Are you sure you want to delete this entry?"")    // Specifying a listener allows you to take an action before dismissing the dialog.    // The dialog is automatically dismissed when a dialog button is clicked.    .setPositiveButton(android.R.string.yes, new DialogInterface.OnClickListener() {        public void onClick(DialogInterface dialog, int which) {             // Continue with delete operation        }     })    // A null listener allows the button to dismiss the dialog and take no further action.    .setNegativeButton(android.R.string.no, null)    .setIcon(android.R.drawable.ic_dialog_alert)    .show();"
"data_i","edited May 21 '22 at 08:59","
        How do I trim whitespace?
    ","Is there a Python function that will trim whitespace (spaces and tabs) from a string?So that given input ""  \t example string\t  "" becomes ""example string"".","For whitespace on both sides, use str.strip:s = ""  \t a string example\t  ""s = s.strip()For whitespace on the right side, use str.rstrip:s = s.rstrip()For whitespace on the left side, use str.lstrip:s = s.lstrip()You can provide an argument to strip arbitrary characters to any of these functions, like this:s = s.strip(' \t\n\r')This will strip any space, \t, \n, or \r characters from both sides of the string.The examples above only remove strings from the left-hand and right-hand sides of strings. If you want to also remove characters from the middle of a string, try re.sub:import reprint(re.sub('[\s+]', '', s))That should print out:astringexample"
"data_i","edited Jan 27 '22 at 11:00","
        How can I undo pushed commits using git?
    ","I have a project in a remote repository, synchronized with a local repository (development) and the server one (prod). I've been making some commited changes already pushed to remote and pulled from the server. Now, I want to undo those changes. So I could just git checkout to the commit before the changes and commit the new changes, but I'm guessing that there will be problems to push them again to remote. Any suggestion on how should I proceed?  ","You can revert individual commits with:git revert <commit_hash>This will create a new commit which reverts the changes of the commit you specified. Note that it only reverts that specific commit, and not commits that come after that. If you want to revert a range of commits, you can do it like this:git revert <oldest_commit_hash>..<latest_commit_hash>It reverts all the commits after <oldest_commit_hash> up to and including <latest_commit_hash>. On some versions of git it also reverts the <oldest_commit_hash>, so double check if that commit gets reverted or not. You can always drop the latest revert commit (which reverts the oldest commit) with g reset --hard HEAD~.To know the hash of the commit(s) you can use git log.Look at the git-revert man page for more information about the git revert command. Also, look at this answer for more information about reverting commits."
"data_i","edited Jun 05 '22 at 19:16","
        How to return dictionary keys as a list in Python?
    ","With Python 2.7, I can get dictionary keys, values, or items as a list:>>> newdict = {1:0, 2:0, 3:0}>>> newdict.keys()[1, 2, 3]With Python >= 3.3, I get:>>> newdict.keys()dict_keys([1, 2, 3])How do I get a plain list of keys with Python 3?","This will convert the dict_keys object to a list:list(newdict.keys())On the other hand, you should ask yourself whether or not it matters. It is Pythonic to assume duck typing -- if it looks like a duck and it quacks like a duck, it is a duck. The dict_keys object can be iterated over just like a list. For instance:for key in newdict.keys():    print(key)Note that dict_keys doesn't support insertion newdict[k] = v, though you may not need it."
"data_i","edited Sep 19 '22 at 13:25","
        Detecting a mobile browser
    ","I'm looking for a function that returns a boolean value if the user is using a mobile browser or not.I know that I can use navigator.userAgent and write that function by using regex, but user-agents are too various for different platforms. I doubt that matching all possible devices would be easy, and I think this problem has been solved many times so there should be some kind of complete solution for such a task.I was looking at this site, but sadly the script is so cryptic that I have no idea how to use it for my purpose, which is to create a function that returns true/false.","Using Regex (from detectmobilebrowsers.com):Here's a function that uses an insanely long and comprehensive regex which returns a true or false value depending on whether or not the user is browsing with a mobile.window.mobileCheck = function() {  let check = false;  (function(a){if(/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(a)||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0,4))) check = true;})(navigator.userAgent||navigator.vendor||window.opera);  return check;};For those wishing to include tablets in this test (though arguably, you shouldn't), you can use the following function:window.mobileAndTabletCheck = function() {  let check = false;  (function(a){if(/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino|android|ipad|playbook|silk/i.test(a)||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0,4))) check = true;})(navigator.userAgent||navigator.vendor||window.opera);  return check;};Using navigator.userAgentDataYou may also use navigator.userAgentData.mobile, but userAgentData is still experimental, so it is not recommended for use in production.const isMobile = navigator.userAgentData.mobile; //resolves true/falseCompatibility chart for userAgentDataThe Original AnswerYou can do this by simply running through a list of devices and checking if the useragent matches anything like so:  function detectMob() {    const toMatch = [        /Android/i,        /webOS/i,        /iPhone/i,        /iPad/i,        /iPod/i,        /BlackBerry/i,        /Windows Phone/i    ];        return toMatch.some((toMatchItem) => {        return navigator.userAgent.match(toMatchItem);    });}However since you believe that this method is unreliable, You could assume that any device that had a resolution of 800x600 or less was a mobile device too, narrowing your target even more (although these days many mobile devices have much greater resolutions than this)i.e  function detectMob() {    return ( ( window.innerWidth <= 800 ) && ( window.innerHeight <= 600 ) );  }Reference:Detecting Browser and Devices with javascript"
"data_i","edited Aug 15 '19 at 18:57","
        How to get the difference between two arrays in JavaScript?
    ","Is there a way to return the difference between two arrays in JavaScript?For example:var a1 = ['a', 'b'];var a2 = ['a', 'b', 'c', 'd'];// need [""c"", ""d""]","There is a better way using ES7:Intersection let intersection = arr1.filter(x => arr2.includes(x));For [1,2,3] [2,3] it will yield [2,3]. On the other hand, for [1,2,3] [2,3,5] will return the same thing.Differencelet difference = arr1.filter(x => !arr2.includes(x));For [1,2,3] [2,3] it will yield [1]. On the other hand, for [1,2,3] [2,3,5] will return the same thing.For a symmetric difference, you can do:let difference = arr1                 .filter(x => !arr2.includes(x))                 .concat(arr2.filter(x => !arr1.includes(x)));This way, you will get an array containing all the elements of arr1 that are not in arr2 and vice-versaAs @Joshaven Potter pointed out on his answer, you can add this to Array.prototype so it can be used like this:Array.prototype.diff = function(arr2) { return this.filter(x => !arr2.includes(x)); }[1, 2, 3].diff([2, 3])"
"data_i","edited Oct 09 '17 at 05:04","
        Git: Create a branch from unstaged/uncommitted changes on master
    ","Context: I'm working on master adding a simple feature. After a few minutes I realize it was not so simple and it should have been better to work into a new branch.This always happens to me and I have no idea how to switch to another branch and take all these uncommited changes with me leaving the master branch clean. I supposed git stash && git stash branch new_branch would simply accomplish that but this is what I get:~/test $ git status# On branch masternothing to commit (working directory clean)~/test $ echo ""hello!"" > testing ~/test $ git status# On branch master# Changed but not updated:#   (use ""git add <file>..."" to update what will be committed)#   (use ""git checkout -- <file>..."" to discard changes in working directory)##   modified:   testing#no changes added to commit (use ""git add"" and/or ""git commit -a"")~/test $ git stashSaved working directory and index state WIP on master: 4402b8c testingHEAD is now at 4402b8c testing~/test $ git status# On branch masternothing to commit (working directory clean)~/test $ git stash branch new_branchSwitched to a new branch 'new_branch'# On branch new_branch# Changed but not updated:#   (use ""git add <file>..."" to update what will be committed)#   (use ""git checkout -- <file>..."" to discard changes in working directory)##   modified:   testing#no changes added to commit (use ""git add"" and/or ""git commit -a"")Dropped refs/stash@{0} (db1b9a3391a82d86c9fdd26dab095ba9b820e35b)~/test $ git s# On branch new_branch# Changed but not updated:#   (use ""git add <file>..."" to update what will be committed)#   (use ""git checkout -- <file>..."" to discard changes in working directory)##   modified:   testing#no changes added to commit (use ""git add"" and/or ""git commit -a"")~/test $ git checkout masterM   testingSwitched to branch 'master'~/test $ git status# On branch master# Changed but not updated:#   (use ""git add <file>..."" to update what will be committed)#   (use ""git checkout -- <file>..."" to discard changes in working directory)##   modified:   testing#no changes added to commit (use ""git add"" and/or ""git commit -a"")Do you know if there is any way of accomplishing this?","No need to stash.Update 2020 / Git 2.23Git 2.23 adds the new switch subcommand, in an attempt to clear some of the confusion caused by the overloaded usage of checkout (switching branches, restoring files, detaching HEAD, etc.)Starting with this version of Git, replace the git checkout command below with:git switch -c <new-branch>The behavior remains unchanged.Before Update 2020 / Git 2.23git checkout -b new_branch_namedoes not touch your local changes. It just creates the branch from the current HEAD and sets the HEAD there.So I guess that's what you want.--- Edit to explain the result of checkout master ---Are you confused because checkout master does not discard your changes?Since the changes are only local, git does not want you to lose them too easily. Upon changing branch, git does not overwrite your local changes. The result of your checkout master is:M   testing, which means that your working files are not clean. git did change the HEAD, but did not overwrite your local files. That is why your last status still show your local changes, although you are on master.If you really want to discard the local changes, you have to force the checkout with -f.git checkout master -fSince your changes were never committed, you'd lose them.Try to get back to your branch, commit your changes, then checkout the master again.git checkout new_branchgit commit -a -m""edited""git checkout mastergit statusYou should get a M message after the first checkout, but then not anymore after the checkout master, and git status should show no modified files.--- Edit to clear up confusion about working directory (local files)---In answer to your first comment, local changes are just... well, local. Git does not save them automatically, you must tell it to save them for later.If you make changes and do not explicitly commit or stash them, git will not version them. If you change HEAD (checkout master), the local changes are not overwritten since unsaved."
"data_i","edited Nov 11 '19 at 14:17","
        What is the difference between a Docker image and a container?
    ","When using Docker, we start with a base image. We boot it up, create changes and those changes are saved in layers forming another image.So eventually I have an image for my PostgreSQL instance and an image for my web application, changes to which keep on being persisted.What is a container?","An instance of an image is called a container. You have an image, which is a set of layers as you describe. If you start this image, you have a running container of this image. You can have many running containers of the same image.You can see all your images with docker images whereas you can see your running containers with docker ps (and you can see all containers with docker ps -a).So a running instance of an image is a container."
"data_i","asked Apr 26 '11 at 23:56","
        In Node.js, how do I ""include"" functions from my other files?
    ","Let's say I have a file called app.js. Pretty simple:var express = require('express');var app = express.createServer();app.set('views', __dirname + '/views');app.set('view engine', 'ejs');app.get('/', function(req, res){  res.render('index', {locals: {    title: 'NowJS + Express Example'  }});});app.listen(8080);What if I have a functions inside ""tools.js"".  How would I import them to use in apps.js?Or...am I supposed to turn ""tools"" into a module, and then require it? << seems hard, I rather do the basic import of the tools.js file.","You can require any js file, you just need to declare what you want to expose.// tools.js// ========module.exports = {  foo: function () {    // whatever  },  bar: function () {    // whatever  }};var zemba = function () {}And in your app file:// app.js// ======var tools = require('./tools');console.log(typeof tools.foo); // => 'function'console.log(typeof tools.bar); // => 'function'console.log(typeof tools.zemba); // => undefined"
"data_i","edited Apr 16 '22 at 10:26","
        What is the difference between public, private, and protected inheritance in C++?
    ","What is the difference between public, private, and protected inheritance in C++?All of the questions I've found on SO deal with specific cases.","class A {    public:       int x;    protected:       int y;    private:       int z;};class B : public A{    // x is public    // y is protected    // z is not accessible from B};class C : protected A{    // x is protected    // y is protected    // z is not accessible from C};class D : private A    // 'private' is default for classes{    // x is private    // y is private    // z is not accessible from D};IMPORTANT NOTE: Classes B, C and D all contain the variables x, y and z. It is just question of access.About usage of protected and private inheritance you could read here."
"data_i","edited Aug 22 '16 at 17:46","
        How to pass command line arguments to a rake task
    ","I have a rake task that needs to insert a value into multiple databases.  I'd like to pass this value into the rake task from the command line, or from another rake task.How can I do this?","You can specify formal arguments in rake by adding symbol arguments to the task call.  For example:require 'rake'task :my_task, [:arg1, :arg2] do |t, args|  puts ""Args were: #{args} of class #{args.class}""  puts ""arg1 was: '#{args[:arg1]}' of class #{args[:arg1].class}""  puts ""arg2 was: '#{args[:arg2]}' of class #{args[:arg2].class}""endtask :invoke_my_task do  Rake.application.invoke_task(""my_task[1, 2]"")end# or if you prefer this syntax...task :invoke_my_task_2 do  Rake::Task[:my_task].invoke(3, 4)end# a task with prerequisites passes its # arguments to it prerequisitestask :with_prerequisite, [:arg1, :arg2] => :my_task #<- name of prerequisite task# to specify default values, # we take advantage of args being a Rake::TaskArguments objecttask :with_defaults, :arg1, :arg2 do |t, args|  args.with_defaults(:arg1 => :default_1, :arg2 => :default_2)  puts ""Args with defaults were: #{args}""endThen, from the command line:> rake my_task[1,false]Args were: {:arg1=>""1"", :arg2=>""false""} of class Rake::TaskArgumentsarg1 was: '1' of class Stringarg2 was: 'false' of class String> rake ""my_task[1, 2]""Args were: {:arg1=>""1"", :arg2=>""2""}> rake invoke_my_taskArgs were: {:arg1=>""1"", :arg2=>""2""}> rake invoke_my_task_2Args were: {:arg1=>3, :arg2=>4}> rake with_prerequisite[5,6]Args were: {:arg1=>""5"", :arg2=>""6""}> rake with_defaultsArgs with defaults were: {:arg1=>:default_1, :arg2=>:default_2}> rake with_defaults['x','y']Args with defaults were: {:arg1=>""x"", :arg2=>""y""}As demonstrated in the second example, if you want to use spaces, the quotes around the target name are necessary to keep the shell from splitting up the arguments at the space.Looking at the code in rake.rb, it appears that rake does not parse task strings to extract arguments for prerequisites, so you can't do task :t1 => ""dep[1,2]"".  The only way to specify different arguments for a prerequisite would be to invoke it explicitly within the dependent task action, as in :invoke_my_task and :invoke_my_task_2.Note that some shells (like zsh) require you to escape the brackets: rake my_task\['arg1'\]"
"data_i","edited Aug 02 '22 at 22:07","
        How do I use 'git reset --hard HEAD' to revert to a previous commit?
    ","I know that Git tracks changes I make to my application, and holds on to them until I commit the changes.To revert to a previous commit, I used:$ git reset --hard HEADHEAD is now at 820f417 microHow do I then revert the files on my hard drive back to that previous commit?My next steps were:git add .git commit -m ""revert""But none of the files have changed on my hard drive...","First, it's always worth noting that git reset --hard is a potentially dangerous command, since it throws away all your uncommitted changes. For safety, you should always check that the output of git status is clean (that is, empty) before using it.Initially you say the following:So I know that Git tracks changes I make to my application, and it holds on to them until I commit the changes, but here's where I'm hung up:That's incorrect. Git only records the state of the files when you stage them (with git add) or when you create a commit. Once you've created a commit which has your project files in a particular state, they're very safe, but until then Git's not really ""tracking changes"" to your files. (for example, even if you do git add to stage a new version of the file, that overwrites the previously staged version of that file in the staging area.)In your question you then go on to ask the following:When I want to revert to a previous commit I use: git reset --hard HEAD And git returns: HEAD is now at 820f417 microHow do I then revert the files on my hard drive back to that previous commit?If you do git reset --hard <SOME-COMMIT> then Git will:Make your current branch (typically master) back to point at <SOME-COMMIT>.Then make the files in your working tree and the index (""staging area"") the same as the versions committed in <SOME-COMMIT>.HEAD points to your current branch (or current commit), so all that git reset --hard HEAD will do is to throw away any uncommitted changes you have.So, suppose the good commit that you want to go back to is f414f31. (You can find that via git log or any history browser.) You then have a few different options depending on exactly what you want to do:Change your current branch to point to the older commit instead. You could do that with git reset --hard f414f31. However, this is rewriting the history of your branch, so you should avoid it if you've shared this branch with anyone. Also, the commits you did after f414f31 will no longer be in the history of your master branch.Create a new commit that represents exactly the same state of the project as f414f31, but just adds that on to the history, so you don't lose any history. You can do that using the steps suggested in this answer - something like:git reset --hard f414f31git reset --soft HEAD@{1}git commit -m ""Reverting to the state of the project at f414f31"""
"data_i","edited Feb 03 '19 at 13:50","
        How do I provide a username and password when running ""git clone git@remote.git""?
    ","I know how to provide a username and password to an HTTPS request like this:git clone https://username:password@remoteBut I'd like to know how to provide a username and password to the remote like this:git clone git@remote.gitI've tried like this:git clone username:password@git@remote.gitgit clone git@username:password@remote.gitgit clone git@remote.git@username:passwordBut they haven't worked.","Based on Michael Scharf's comment:You can leave out the password so that it won't be logged in your Bash history file:git clone https://username@github.com/username/repository.gitIt will prompt you for your password.Alternatively, you may use:git clone https://username:password@github.com/username/repository.gitThis way worked for me from a GitHub repository."
"data_i","edited Nov 27 '15 at 07:57","
        Get list of all tables in Oracle?
    ","How do I query an Oracle database to display the names of all tables in it?","SELECT owner, table_name  FROM dba_tablesThis is assuming that you have access to the DBA_TABLES data dictionary view.  If you do not have those privileges but need them, you can request that the DBA explicitly grants you privileges on that table, or, that the DBA grants you the SELECT ANY DICTIONARY privilege or the SELECT_CATALOG_ROLE role (either of which would allow you to query any data dictionary table).  Of course, you may want to exclude certain schemas like SYS and SYSTEM which have large numbers of Oracle tables that you probably don't care about.Alternatively, if you do not have access to DBA_TABLES, you can see all the tables that your account has access to through the ALL_TABLES view:SELECT owner, table_name  FROM all_tablesAlthough, that may be a subset of the tables available in the database (ALL_TABLES shows you the information for all the tables that your user has been granted access to).  If you are only concerned with the tables that you own, not those that you have access to, you could use USER_TABLES:SELECT table_name  FROM user_tablesSince USER_TABLES only has information about the tables that you own, it does not have an OWNER column – the owner, by definition, is you.Oracle also has a number of legacy data dictionary views-- TAB, DICT, TABS, and CAT for example-- that could be used.  In general, I would not suggest using these legacy views unless you absolutely need to backport your scripts to Oracle 6.  Oracle has not changed these views in a long time so they often have problems with newer types of objects.  For example, the TAB and CAT views both show information about tables that are in the user's recycle bin while the [DBA|ALL|USER]_TABLES views all filter those out.  CAT also shows information about materialized view logs with a TABLE_TYPE of ""TABLE"" which is unlikely to be what you really want.  DICT combines tables and synonyms and doesn't tell you who owns the object."
"data_i","edited Aug 30 '18 at 05:49","
        Parsing JSON with Unix tools
    ","I'm trying to parse JSON returned from a curl request, like so:curl 'http://twitter.com/users/username.json' |    sed -e 's/[{}]/''/g' |     awk -v k=""text"" '{n=split($0,a,"",""); for (i=1; i<=n; i++) print a[i]}'The above splits the JSON into fields, for example:% ...""geo_enabled"":false""friends_count"":245""profile_text_color"":""000000""""status"":""in_reply_to_screen_name"":null""source"":""web""""truncated"":false""text"":""My status""""favorited"":false% ...How do I print a specific field (denoted by the -v k=text)?","There are a number of tools specifically designed for the purpose of manipulating JSON from the command line, and will be a lot easier and more reliable than doing it with Awk, such as jq:curl -s 'https://api.github.com/users/lambda' | jq -r '.name'You can also do this with tools that are likely already installed on your system, like Python using the json module, and so avoid any extra dependencies, while still having the benefit of a proper JSON parser. The following assume you want to use UTF-8, which the original JSON should be encoded in and is what most modern terminals use as well:Python 3:curl -s 'https://api.github.com/users/lambda' | \    python3 -c ""import sys, json; print(json.load(sys.stdin)['name'])""Python 2:export PYTHONIOENCODING=utf8curl -s 'https://api.github.com/users/lambda' | \    python2 -c ""import sys, json; print json.load(sys.stdin)['name']""Frequently Asked QuestionsWhy not a pure shell solution?The standard POSIX/Single Unix Specification shell is a very limited language which doesn't contain facilities for representing sequences (list or arrays) or associative arrays (also known as hash tables, maps, dicts, or objects in some other languages). This makes representing the result of parsing JSON somewhat tricky in portable shell scripts. There are somewhat hacky ways to do it, but many of them can break if keys or values contain certain special characters.Bash 4 and later, zsh, and ksh have support for arrays and associative arrays, but these shells are not universally available (macOS stopped updating Bash at Bash 3, due to a change from GPLv2 to GPLv3, while many Linux systems don't have zsh installed out of the box). It's possible that you could write a script that would work in either Bash 4 or zsh, one of which is available on most macOS, Linux, and BSD systems these days, but it would be tough to write a shebang line that worked for such a polyglot script.Finally, writing a full fledged JSON parser in shell would be a significant enough dependency that you might as well just use an existing dependency like jq or Python instead. It's not going to be a one-liner, or even small five-line snippet, to do a good implementation.Why not use awk, sed, or grep?It is possible to use these tools to do some quick extraction from JSON with a known shape and formatted in a known way, such as one key per line. There are several examples of suggestions for this in other answers.However, these tools are designed for line based or record based formats; they are not designed for recursive parsing of matched delimiters with possible escape characters.So these quick and dirty solutions using awk/sed/grep are likely to be fragile, and break if some aspect of the input format changes, such as collapsing whitespace, or adding additional levels of nesting to the JSON objects, or an escaped quote within a string. A solution that is robust enough to handle all JSON input without breaking will also be fairly large and complex, and so not too much different than adding another dependency on jq or Python.I have had to deal with large amounts of customer data being deleted due to poor input parsing in a shell script before, so I never recommend quick and dirty methods that may be fragile in this way. If you're doing some one-off processing, see the other answers for suggestions, but I still highly recommend just using an existing tested JSON parser.Historical notesThis answer originally recommended jsawk, which should still work, but is a little more cumbersome to use than jq, and depends on a standalone JavaScript interpreter being installed which is less common than a Python interpreter, so the above answers are probably preferable:curl -s 'https://api.github.com/users/lambda' | jsawk -a 'return this.name'This answer also originally used the Twitter API from the question, but that API no longer works, making it hard to copy the examples to test out, and the new Twitter API requires API keys, so I've switched to using the GitHub API which can be used easily without API keys.  The first answer for the original question would be:curl 'http://twitter.com/users/username.json' | jq -r '.text'"
"data_i","edited Mar 08 '22 at 18:54","
        Remove a git commit which has not been pushed
    ","I did a git commit but I have not pushed it to the repository yet.So when I do git status, I get '# Your branch is ahead of 'master' by 1 commit.So if I want to roll back my top commit, can I just do:git reset --hard eb27bf26dd18c5a34e0e82b929e0d74cfcaab316given that when I do git log I get:commit eb27bf26dd18c5a34e0e82b929e0d74cfcaab316Date:   Tue Sep 29 11:21:41 2009 -0700commit db0c078d5286b837532ff5e276dcf91885df2296Date:   Tue Sep 22 10:31:37 2009 -0700","IF you have NOT pushed your changes to remotegit reset HEAD~1Check if the working copy is clean by git status.ELSE you have pushed your changes to remotegit revert HEADThis command will revert/remove the local commits/change and then you can push"
"data_i","edited May 22 '17 at 07:01","
        How do I use extern to share variables between source files?
    ","I know that global variables in C sometimes have the extern keyword. What is an extern variable? What is the declaration like? What is its scope?This is related to sharing variables across source files, but how does that work precisely? Where do I use extern?","Using extern is only of relevance when the program you're buildingconsists of multiple source files linked together, where some of thevariables defined, for example, in source file file1.c need to bereferenced in other source files, such as file2.c.It is important to understand the difference between defining avariable and declaring avariable:A variable is declared when the compiler is informed that avariable exists (and this is its type); it does not allocate thestorage for the variable at that point.A variable is defined when the compiler allocates the storage forthe variable.You may declare a variable multiple times (though once is sufficient);you may only define it once within a given scope.A variable definition is also a declaration, but not all variabledeclarations are definitions.Best way to declare and define global variablesThe clean, reliable way to declare and define global variables is to usea header file to contain an extern declaration of the variable.The header is included by the one source file that defines the variableand by all the source files that reference the variable.For each program, one source file (and only one source file) defines thevariable.Similarly, one header file (and only one header file) should declare thevariable.The header file is crucial; it enables cross-checking betweenindependent TUs (translation units — think source files) and ensuresconsistency.Although there are other ways of doing it, this method is simple andreliable.It is demonstrated by file3.h, file1.c and file2.c:file3.hextern int global_variable;  /* Declaration of the variable */file1.c#include ""file3.h""  /* Declaration made available here */#include ""prog1.h""  /* Function declarations *//* Variable defined here */int global_variable = 37;    /* Definition checked against declaration */int increment(void) { return global_variable++; }file2.c#include ""file3.h""#include ""prog1.h""#include <stdio.h>void use_it(void){    printf(""Global variable: %d\n"", global_variable++);}That's the best way to declare and define global variables.The next two files complete the source for prog1:The complete programs shown use functions, so function declarations havecrept in.Both C99 and C11 require functions to be declared or defined before theyare used (whereas C90 did not, for good reasons).I use the keyword extern in front of function declarations in headersfor consistency — to match the extern in front of variabledeclarations in headers.Many people prefer not to use extern in front of functiondeclarations; the compiler doesn't care — and ultimately, neither do Ias long as you're consistent, at least within a source file.prog1.hextern void use_it(void);extern int increment(void);prog1.c#include ""file3.h""#include ""prog1.h""#include <stdio.h>int main(void){    use_it();    global_variable += 19;    use_it();    printf(""Increment: %d\n"", increment());    return 0;}prog1 uses prog1.c, file1.c, file2.c, file3.h and prog1.h.The file prog1.mk is a makefile for prog1 only.It will work with most versions of make produced since about the turnof the millennium.It is not tied specifically to GNU Make.prog1.mk# Minimal makefile for prog1PROGRAM = prog1FILES.c = prog1.c file1.c file2.cFILES.h = prog1.h file3.hFILES.o = ${FILES.c:.c=.o}CC      = gccSFLAGS  = -std=c11GFLAGS  = -gOFLAGS  = -O3WFLAG1  = -WallWFLAG2  = -WextraWFLAG3  = -WerrorWFLAG4  = -Wstrict-prototypesWFLAG5  = -Wmissing-prototypesWFLAGS  = ${WFLAG1} ${WFLAG2} ${WFLAG3} ${WFLAG4} ${WFLAG5}UFLAGS  = # Set on command line onlyCFLAGS  = ${SFLAGS} ${GFLAGS} ${OFLAGS} ${WFLAGS} ${UFLAGS}LDFLAGS =LDLIBS  =all:    ${PROGRAM}${PROGRAM}: ${FILES.o}    ${CC} -o $@ ${CFLAGS} ${FILES.o} ${LDFLAGS} ${LDLIBS}prog1.o: ${FILES.h}file1.o: ${FILES.h}file2.o: ${FILES.h}# If it exists, prog1.dSYM is a directory on macOSDEBRIS = a.out core *~ *.dSYMRM_FR  = rm -frclean:    ${RM_FR} ${FILES.o} ${PROGRAM} ${DEBRIS}GuidelinesRules to be broken by experts only, and only with good reason:A header file only contains extern declarations of variables — neverstatic or unqualified variable definitions.For any given variable, only one header file declares it (SPOT —Single Point of Truth).A source file never contains extern declarations of variables —source files always include the (sole) header that declares them.For any given variable, exactly one source file defines the variable,preferably initializing it too.  (Although there is no need toinitialize explicitly to zero, it does no harm and can do some good,because there can be only one initialized definition of a particularglobal variable in a program).The source file that defines the variable also includes the header toensure that the definition and the declaration are consistent.A function should never need to declare a variable using extern.Avoid global variables whenever possible — use functions instead.The source code and text of this answer are available in mySOQ (Stack Overflow Questions)repository on GitHub in thesrc/so-0143-3204sub-directory.If you're not an experienced C programmer, you could (and perhapsshould) stop reading here.Not so good way to define global variablesWith some (indeed, many) C compilers, you can get away with what'scalled a 'common' definition of a variable too.'Common', here, refers to a technique used in Fortran for sharingvariables between source files, using a (possibly named) COMMON block.What happens here is that each of a number of files provides a tentativedefinition of the variable.As long as no more than one file provides an initialized definition,then the various files end up sharing a common single definition of thevariable:file10.c#include ""prog2.h""long l;   /* Do not do this in portable code */void inc(void) { l++; }file11.c#include ""prog2.h""long l;   /* Do not do this in portable code */void dec(void) { l--; }file12.c#include ""prog2.h""#include <stdio.h>long l = 9;   /* Do not do this in portable code */void put(void) { printf(""l = %ld\n"", l); }This technique does not conform to the letter of the C standard and the'one definition rule' — it is officially undefined behaviour:J.2 Undefined behaviorAn identifier with external linkage is used, but in the program theredoes not exist exactly one external definition for the identifier, orthe identifier is not used and there exist multiple externaldefinitions for the identifier (6.9).§6.9 External definitions ¶5An external definition is an external declaration that is also adefinition of a function (other than an inline definition) or anobject.If an identifier declared with external linkage is used in anexpression (other than as part of the operand of a sizeof or_Alignof operator whose result is an integer constant), somewhere inthe entire program there shall be exactly one external definition forthe identifier; otherwise, there shall be no more thanone.161)161) Thus, if an identifier declared with external linkageis not used in an expression, there need be no external definition forit.However, the C standard also lists it in informative Annex J as one ofthe Common extensions.J.5.11 Multiple external definitionsThere may be more than one external definition for the identifier ofan object, with or without the explicit use of the keyword extern; ifthe definitions disagree, or more than one is initialized, thebehavior is undefined (6.9.2).Because this technique is not always supported, it is best to avoidusing it, especially if your code needs to be portable.Using this technique, you can also end up with unintentional typepunning.If one of the files above declared l as a double instead of as along, C's type-unsafe linkers probably would not spot the mismatch.If you're on a machine with 64-bit long and double, you'd not evenget a warning; on a machine with 32-bit long and 64-bit double,you'd probably get a warning about the different sizes — the linkerwould use the largest size, exactly as a Fortran program would take thelargest size of any common blocks.Note that GCC 10.1.0, which was released on 2020-05-07, changes thedefault compilation options to use-fno-common, which meansthat by default, the code above no longer links unless you override thedefault with -fcommon (or use attributes, etc — see the link).The next two files complete the source for prog2:prog2.hextern void dec(void);extern void put(void);extern void inc(void);prog2.c#include ""prog2.h""#include <stdio.h>int main(void){    inc();    put();    dec();    put();    dec();    put();}prog2 uses prog2.c, file10.c, file11.c, file12.c, prog2.h.WarningAs noted in comments here, and as stated in my answer to a similarquestion, using multipledefinitions for a global variable leads to undefined behaviour (J.2;§6.9), which is the standard's way of saying ""anything could happen"".One of the things that can happen is that the program behaves as youexpect; and J.5.11 says, approximately, ""you might be lucky more oftenthan you deserve"".But a program that relies on multiple definitions of an extern variable— with or without the explicit 'extern' keyword — is not a strictlyconforming program and not guaranteed to work everywhere.Equivalently: it contains a bug which may or may not show itself.Violating the guidelinesThere are, of course, many ways in which these guidelines can be broken.Occasionally, there may be a good reason to break the guidelines, butsuch occasions are extremely unusual.faulty_header.hint some_var;    /* Do not do this in a header!!! */Note 1: if the header defines the variable without the extern keyword,then each file that includes the header creates a tentative definitionof the variable.As noted previously, this will often work, but the C standard does notguarantee that it will work.broken_header.hint some_var = 13;    /* Only one source file in a program can use this */Note 2: if the header defines and initializes the variable, then onlyone source file in a given program can use the header.Since headers are primarily for sharing information, it is a bit sillyto create one that can only be used once.seldom_correct.hstatic int hidden_global = 3;   /* Each source file gets its own copy  */Note 3: if the header defines a static variable (with or withoutinitialization), then each source file ends up with its own privateversion of the 'global' variable.If the variable is actually a complex array, for example, this can leadto extreme duplication of code.  It can, very occasionally, be asensible way to achieve some effect, but that is very unusual.SummaryUse the header technique I showed first.It works reliably and everywhere.Note, in particular, that the header declaring the global_variable isincluded in every file that uses it — including the one that defines it.This ensures that everything is self-consistent.Similar concerns arise with declaring and defining functions —analogous rules apply.But the question was about variables specifically, so I've kept theanswer to variables only.End of Original AnswerIf you're not an experienced C programmer, you probably should stop reading here.Late Major AdditionAvoiding Code DuplicationOne concern that is sometimes (and legitimately) raised about the'declarations in headers, definitions in source' mechanism describedhere is that there are two files to be kept synchronized — the headerand the source.  This is usually followed up with an observation that amacro can be used so that the header serves double duty — normallydeclaring the variables, but when a specific macro is set before theheader is included, it defines the variables instead.Another concern can be that the variables need to be defined in each ofa number of 'main programs'.  This is normally a spurious concern; youcan simply introduce a C source file to define the variables and linkthe object file produced with each of the programs.A typical scheme works like this, using the original global variableillustrated in file3.h:file3a.h#ifdef DEFINE_VARIABLES#define EXTERN /* nothing */#else#define EXTERN extern#endif /* DEFINE_VARIABLES */EXTERN int global_variable;file1a.c#define DEFINE_VARIABLES#include ""file3a.h""  /* Variable defined - but not initialized */#include ""prog3.h""int increment(void) { return global_variable++; }file2a.c#include ""file3a.h""#include ""prog3.h""#include <stdio.h>void use_it(void){    printf(""Global variable: %d\n"", global_variable++);}The next two files complete the source for prog3:prog3.hextern void use_it(void);extern int increment(void);prog3.c#include ""file3a.h""#include ""prog3.h""#include <stdio.h>int main(void){    use_it();    global_variable += 19;    use_it();    printf(""Increment: %d\n"", increment());    return 0;}prog3 uses prog3.c, file1a.c, file2a.c, file3a.h, prog3.h.Variable initializationThe problem with this scheme as shown is that it does not provide forinitialization of the global variable.  With C99 or C11 and variable argumentlists for macros, you could define a macro to support initialization too.(With C89 and no support for variable argument lists in macros, there is noeasy way to handle arbitrarily long initializers.)file3b.h#ifdef DEFINE_VARIABLES#define EXTERN                  /* nothing */#define INITIALIZER(...)        = __VA_ARGS__#else#define EXTERN                  extern#define INITIALIZER(...)        /* nothing */#endif /* DEFINE_VARIABLES */EXTERN int global_variable INITIALIZER(37);EXTERN struct { int a; int b; } oddball_struct INITIALIZER({ 41, 43 });Reverse contents of #if and #else blocks, fixing bug identified byDenis Kniazhevfile1b.c#define DEFINE_VARIABLES#include ""file3b.h""  /* Variables now defined and initialized */#include ""prog4.h""int increment(void) { return global_variable++; }int oddball_value(void) { return oddball_struct.a + oddball_struct.b; }file2b.c#include ""file3b.h""#include ""prog4.h""#include <stdio.h>void use_them(void){    printf(""Global variable: %d\n"", global_variable++);    oddball_struct.a += global_variable;    oddball_struct.b -= global_variable / 2;}Clearly, the code for the oddball structure is not what you'd normallywrite, but it illustrates the point.  The first argument to the secondinvocation of INITIALIZER is { 41 and the remaining argument(singular in this example) is 43 }.  Without C99 or similar supportfor variable argument lists for macros, initializers that need tocontain commas are very problematic.Correct header file3b.h included (instead of fileba.h) perDenis KniazhevThe next two files complete the source for prog4:prog4.hextern int increment(void);extern int oddball_value(void);extern void use_them(void);prog4.c#include ""file3b.h""#include ""prog4.h""#include <stdio.h>int main(void){    use_them();    global_variable += 19;    use_them();    printf(""Increment: %d\n"", increment());    printf(""Oddball:   %d\n"", oddball_value());    return 0;}prog4 uses prog4.c, file1b.c, file2b.c, prog4.h, file3b.h.Header GuardsAny header should be protected against reinclusion, so that typedefinitions (enum, struct or union types, or typedefs generally) do notcause problems.  The standard technique is to wrap the body of theheader in a header guard such as:#ifndef FILE3B_H_INCLUDED#define FILE3B_H_INCLUDED...contents of header...#endif /* FILE3B_H_INCLUDED */The header might be included twice indirectly.  For example, iffile4b.h includes file3b.h for a type definition that isn't shown,and file1b.c needs to use both header file4b.h and file3b.h, thenyou have some more tricky issues to resolve.  Clearly, you might revisethe header list to include just file4b.h.  However, you might not beaware of the internal dependencies — and the code should, ideally,continue to work.Further, it starts to get tricky because you might include file4b.hbefore including file3b.h to generate the definitions, but the normalheader guards on file3b.h would prevent the header being reincluded.So, you need to include the body of file3b.h at most once fordeclarations, and at most once for definitions, but you might need bothin a single translation unit (TU — a combination of a source file andthe headers it uses).Multiple inclusion with variable definitionsHowever, it can be done subject to a not too unreasonable constraint.Let's introduce a new set of file names:external.h for the EXTERN macro definitions, etc.file1c.h to define types (notably, struct oddball, the type of oddball_struct).file2c.h to define or declare the global variables.file3c.c which defines the global variables.file4c.c which simply uses the global variables.file5c.c which shows that you can declare and then define the global variables.file6c.c which shows that you can define and then (attempt to) declare the global variables.In these examples, file5c.c and file6c.c directly include the headerfile2c.h several times, but that is the simplest way to show that themechanism works.  It means that if the header was indirectly includedtwice, it would also be safe.The restrictions for this to work are:The header defining or declaring the global variables may not itselfdefine any types.Immediately before you include a header that should define variables,you define the macro DEFINE_VARIABLES.The header defining or declaring the variables has stylized contents.external.h/*** This header must not contain header guards (like <assert.h> must not).** Each time it is invoked, it redefines the macros EXTERN, INITIALIZE** based on whether macro DEFINE_VARIABLES is currently defined.*/#undef EXTERN#undef INITIALIZE#ifdef DEFINE_VARIABLES#define EXTERN              /* nothing */#define INITIALIZE(...)     = __VA_ARGS__#else#define EXTERN              extern#define INITIALIZE(...)     /* nothing */#endif /* DEFINE_VARIABLES */file1c.h#ifndef FILE1C_H_INCLUDED#define FILE1C_H_INCLUDEDstruct oddball{    int a;    int b;};extern void use_them(void);extern int increment(void);extern int oddball_value(void);#endif /* FILE1C_H_INCLUDED */file2c.h/* Standard prologue */#if defined(DEFINE_VARIABLES) && !defined(FILE2C_H_DEFINITIONS)#undef FILE2C_H_INCLUDED#endif#ifndef FILE2C_H_INCLUDED#define FILE2C_H_INCLUDED#include ""external.h""   /* Support macros EXTERN, INITIALIZE */#include ""file1c.h""     /* Type definition for struct oddball */#if !defined(DEFINE_VARIABLES) || !defined(FILE2C_H_DEFINITIONS)/* Global variable declarations / definitions */EXTERN int global_variable INITIALIZE(37);EXTERN struct oddball oddball_struct INITIALIZE({ 41, 43 });#endif /* !DEFINE_VARIABLES || !FILE2C_H_DEFINITIONS *//* Standard epilogue */#ifdef DEFINE_VARIABLES#define FILE2C_H_DEFINITIONS#endif /* DEFINE_VARIABLES */#endif /* FILE2C_H_INCLUDED */file3c.c#define DEFINE_VARIABLES#include ""file2c.h""  /* Variables now defined and initialized */int increment(void) { return global_variable++; }int oddball_value(void) { return oddball_struct.a + oddball_struct.b; }file4c.c#include ""file2c.h""#include <stdio.h>void use_them(void){    printf(""Global variable: %d\n"", global_variable++);    oddball_struct.a += global_variable;    oddball_struct.b -= global_variable / 2;}file5c.c#include ""file2c.h""     /* Declare variables */#define DEFINE_VARIABLES#include ""file2c.h""  /* Variables now defined and initialized */int increment(void) { return global_variable++; }int oddball_value(void) { return oddball_struct.a + oddball_struct.b; }file6c.c#define DEFINE_VARIABLES#include ""file2c.h""     /* Variables now defined and initialized */#include ""file2c.h""     /* Declare variables */int increment(void) { return global_variable++; }int oddball_value(void) { return oddball_struct.a + oddball_struct.b; }The next source file completes the source (provides a main program) for prog5, prog6 and prog7:prog5.c#include ""file2c.h""#include <stdio.h>int main(void){    use_them();    global_variable += 19;    use_them();    printf(""Increment: %d\n"", increment());    printf(""Oddball:   %d\n"", oddball_value());    return 0;}prog5 uses prog5.c, file3c.c, file4c.c, file1c.h, file2c.h, external.h.prog6 uses prog5.c, file5c.c, file4c.c, file1c.h, file2c.h, external.h.prog7 uses prog5.c, file6c.c, file4c.c, file1c.h, file2c.h, external.h.This scheme avoids most problems.  You only run into a problem if aheader that defines variables (such as file2c.h) is included byanother header (say file7c.h) that defines variables.  There isn't aneasy way around that other than ""don't do it"".You can partially work around the problem by revising file2c.h intofile2d.h:file2d.h/* Standard prologue */#if defined(DEFINE_VARIABLES) && !defined(FILE2D_H_DEFINITIONS)#undef FILE2D_H_INCLUDED#endif#ifndef FILE2D_H_INCLUDED#define FILE2D_H_INCLUDED#include ""external.h""   /* Support macros EXTERN, INITIALIZE */#include ""file1c.h""     /* Type definition for struct oddball */#if !defined(DEFINE_VARIABLES) || !defined(FILE2D_H_DEFINITIONS)/* Global variable declarations / definitions */EXTERN int global_variable INITIALIZE(37);EXTERN struct oddball oddball_struct INITIALIZE({ 41, 43 });#endif /* !DEFINE_VARIABLES || !FILE2D_H_DEFINITIONS *//* Standard epilogue */#ifdef DEFINE_VARIABLES#define FILE2D_H_DEFINITIONS#undef DEFINE_VARIABLES#endif /* DEFINE_VARIABLES */#endif /* FILE2D_H_INCLUDED */The issue becomes 'should the header include #undef DEFINE_VARIABLES?'If you omit that from the header and wrap any defining invocation with#define and #undef:#define DEFINE_VARIABLES#include ""file2c.h""#undef DEFINE_VARIABLESin the source code (so the headers never alter the value ofDEFINE_VARIABLES), then you should be clean.  It is just a nuisance tohave to remember to write the the extra line.  An alternative might be:#define HEADER_DEFINING_VARIABLES ""file2c.h""#include ""externdef.h""externdef.h/*** This header must not contain header guards (like <assert.h> must not).** Each time it is included, the macro HEADER_DEFINING_VARIABLES should** be defined with the name (in quotes - or possibly angle brackets) of** the header to be included that defines variables when the macro** DEFINE_VARIABLES is defined.  See also: external.h (which uses** DEFINE_VARIABLES and defines macros EXTERN and INITIALIZE** appropriately).**** #define HEADER_DEFINING_VARIABLES ""file2c.h""** #include ""externdef.h""*/#if defined(HEADER_DEFINING_VARIABLES)#define DEFINE_VARIABLES#include HEADER_DEFINING_VARIABLES#undef DEFINE_VARIABLES#undef HEADER_DEFINING_VARIABLES#endif /* HEADER_DEFINING_VARIABLES */This is getting a tad convoluted, but seems to be secure (using thefile2d.h, with no #undef DEFINE_VARIABLES in the file2d.h).file7c.c/* Declare variables */#include ""file2d.h""/* Define variables */#define HEADER_DEFINING_VARIABLES ""file2d.h""#include ""externdef.h""/* Declare variables - again */#include ""file2d.h""/* Define variables - again */#define HEADER_DEFINING_VARIABLES ""file2d.h""#include ""externdef.h""int increment(void) { return global_variable++; }int oddball_value(void) { return oddball_struct.a + oddball_struct.b; }file8c.h/* Standard prologue */#if defined(DEFINE_VARIABLES) && !defined(FILE8C_H_DEFINITIONS)#undef FILE8C_H_INCLUDED#endif#ifndef FILE8C_H_INCLUDED#define FILE8C_H_INCLUDED#include ""external.h""   /* Support macros EXTERN, INITIALIZE */#include ""file2d.h""     /* struct oddball */#if !defined(DEFINE_VARIABLES) || !defined(FILE8C_H_DEFINITIONS)/* Global variable declarations / definitions */EXTERN struct oddball another INITIALIZE({ 14, 34 });#endif /* !DEFINE_VARIABLES || !FILE8C_H_DEFINITIONS *//* Standard epilogue */#ifdef DEFINE_VARIABLES#define FILE8C_H_DEFINITIONS#endif /* DEFINE_VARIABLES */#endif /* FILE8C_H_INCLUDED */file8c.c/* Define variables */#define HEADER_DEFINING_VARIABLES ""file2d.h""#include ""externdef.h""/* Define variables */#define HEADER_DEFINING_VARIABLES ""file8c.h""#include ""externdef.h""int increment(void) { return global_variable++; }int oddball_value(void) { return oddball_struct.a + oddball_struct.b; }The next two files complete the source for prog8 and prog9:prog8.c#include ""file2d.h""#include <stdio.h>int main(void){    use_them();    global_variable += 19;    use_them();    printf(""Increment: %d\n"", increment());    printf(""Oddball:   %d\n"", oddball_value());    return 0;}file9c.c#include ""file2d.h""#include <stdio.h>void use_them(void){    printf(""Global variable: %d\n"", global_variable++);    oddball_struct.a += global_variable;    oddball_struct.b -= global_variable / 2;}prog8 uses prog8.c, file7c.c, file9c.c.prog9 uses prog8.c, file8c.c, file9c.c.However, the problems are relatively unlikely to occur in practice,especially if you take the standard advice toAvoid global variablesDoes this exposition miss anything?_Confession_: The 'avoiding duplicated code' scheme outlined here wasdeveloped because the issue affects some code I work on (but don't own),and is a niggling concern with the scheme outlined in the first part ofthe answer.  However, the original scheme leaves you with just twoplaces to modify to keep variable definitions and declarationssynchronized, which is a big step forward over having exernal variabledeclarations scattered throughout the code base (which really matterswhen there are thousands of files in total).  However, the code in thefiles with the names `fileNc.[ch]` (plus `external.h` and `externdef.h`)shows that it can be made to work.  Clearly, it would not be hard tocreate a header generator script to give you the standardized templatefor a variable defining and declaring header file.NB These are toy programs with just barely enough code to make themmarginally interesting.  There is repetition within the examples thatcould be removed, but isn't to simplify the pedagogical explanation.(For example: the difference between prog5.c and prog8.c is the nameof one of the headers that are included.  It would be possible toreorganize the code so that the main() function was not repeated, butit would conceal more than it revealed.)"
"data_i","edited Nov 28 '16 at 13:46","
        Extract file name from path, no matter what the os/path format
    ","Which Python library can I use to extract filenames from paths, no matter what the operating system or path format could be?For example, I'd like all of these paths to return me c:a/b/c/a/b/c\a\b\c\a\b\c\a\b\ca/b/../../a/b/c/a/b/../../a/b/c","There's a function that returns exactly what you wantimport osprint(os.path.basename(your_path))WARNING: When os.path.basename() is used on a POSIX system to get the base name from a Windows-styled path (e.g. ""C:\\my\\file.txt""), the entire path will be returned.Example below from interactive python shell running on a Linux host:Python 3.8.2 (default, Mar 13 2020, 10:14:16)[GCC 9.3.0] on LinuxType ""help"", ""copyright"", ""credits"" or ""license"" for more information.>>> import os>>> filepath = ""C:\\my\\path\\to\\file.txt"" # A Windows style file path.>>> os.path.basename(filepath)'C:\\my\\path\\to\\file.txt'"
"data_i","edited Mar 23 '19 at 11:19","
        How do I rename both a Git local and remote branch name?
    ","I have four branches like master -> origin/regacy, FeatureA -> origin/FeatureA. As you can see, I typed the wrong name.So I want to rename a remote branch name (origin/regacy → origin/legacy or origin/master)I try the command below:git remote rename regacy legacyBut Git console returned an error message to me. error : Could not rename config section 'remote.regacy' to 'remote.legacy'How can I solve this problem?","There are a few ways to accomplish that:Change your local branch and then push your changesPush the branch to remote with the new name while keeping the original name locallyRenaming local and remote# Rename the local branch to the new namegit branch -m <old_name> <new_name># Delete the old branch on remote - where <remote> is, for example, origingit push <remote> --delete <old_name># Or shorter way to delete remote branch [:]git push <remote> :<old_name># Prevent git from using the old name when pushing in the next step.# Otherwise, git will use the old upstream name instead of <new_name>.git branch --unset-upstream <new_name># Push the new branch to remotegit push <remote> <new_name># Reset the upstream branch for the new_name local branchgit push <remote> -u <new_name>Renaming Only remote branchCredit: ptim# In this option, we will push the branch to the remote with the new name# While keeping the local name as isgit push <remote> <remote>/<old_name>:refs/heads/<new_name> :<old_name>Important note:When you use the git branch -m (move), Git is also updating your tracking branch with the new name.git remote rename legacy legacygit remote rename is trying to update your remote section in your configuration file. It will rename the remote with the given name to the new name, but in your case, it did not find any, so the renaming failed.But it will not do what you think; it will rename your local configuration remote name and not the remote branch. NoteGit servers might allow you to rename Git branches using the web interface or external programs (like Sourcetree, etc.), but you have to keep in mind that in Git all the work is done locally, so it's recommended to use the above commands to the work."
"data_i","edited May 10 '21 at 17:22","
        How do I turn a C# object into a JSON string in .NET?
    ","I have classes like these:class MyDate{    int year, month, day;}class Lad{    string firstName;    string lastName;    MyDate dateOfBirth;}And I would like to turn a Lad object into a JSON string like this:{    ""firstName"":""Markoff"",    ""lastName"":""Chaney"",    ""dateOfBirth"":    {        ""year"":""1901"",        ""month"":""4"",        ""day"":""30""    }}(Without the formatting). I found this link, but it uses a namespace that's not in .NET 4. I also heard about JSON.NET, but their site seems to be down at the moment, and I'm not keen on using external DLL files.Are there other options besides manually creating a JSON string writer?","Since we all love one-liners... this one depends on the Newtonsoft NuGet package, which is popular and better than the default serializer.Newtonsoft.Json.JsonConvert.SerializeObject(new {foo = ""bar""})Documentation: Serializing and Deserializing JSON"
"data_i","edited Jun 14 '21 at 12:42","
        How to have 'git log' show filenames like 'svn log -v'
    ","SVN's log has a ""-v"" mode that outputs filenames of files changed in each commit, like so:jes5199$ svn log -v------------------------------------------------------------------------r1 |   jes5199 | 2007-01-03 14:39:41 -0800 (Wed, 03 Jan 2007) | 1 lineChanged paths:   A /AUTHORS   A /COPYING   A /ChangeLog   A /EVOLUTION   A /INSTALL   A /MacOSXIs there a quick way to get a list of changed files in each commit in Git?","For full path names of changed files:git log --name-onlyFor full path names and status of changed files:git log --name-statusFor abbreviated pathnames and a diffstat of changed files:git log --statThere are a lot more options. Check out the documentation."
"data_i","edited Apr 26 '19 at 13:47","
        How to echo shell commands as they are executed
    ","In a shell script, how do I echo all shell commands called and expand any variable names?For example, given the following line:ls $DIRNAMEI would like the script to run the command and display the followingls /full/path/to/some/dirThe purpose is to save a log of all shell commands called and their arguments. Is there perhaps a better way of generating such a log?","set -x or set -o xtrace expands variables and prints a little + sign before the line.set -v or set -o verbose does not expand the variables before printing.Use set +x and set +v to turn off the above settings.On the first line of the script, one can put #!/bin/sh -x (or -v) to have the same effect as set -x (or -v) later in the script.The above also works with /bin/sh.See the bash-hackers' wiki on set attributes, and on debugging.$ cat shl#!/bin/bash                                                                     DIR=/tmp/sols $DIR$ bash -x shl + DIR=/tmp/so+ ls /tmp/so$"
"data_i","edited Dec 01 '17 at 09:41","
        findViewById in Fragment
    ","I am trying to create an ImageView in a Fragment which will refer to the ImageView element which I have created in the XML for the Fragment. However, the findViewById method only works if I extend an Activity class. Is there anyway of which I can use it in Fragment as well?public class TestClass extends Fragment {    public View onCreateView(LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState) {        ImageView imageView = (ImageView)findViewById(R.id.my_image);        return inflater.inflate(R.layout.testclassfragment, container, false);    }}The findViewById method has an error on it which states that the method is undefined.","Use getView() or the View parameter from implementing the  onViewCreated method. It returns the root view for the fragment (the one returned by onCreateView() method). With this you can call findViewById().@Overridepublic void onViewCreated(View view, @Nullable Bundle savedInstanceState) {    ImageView imageView = (ImageView) getView().findViewById(R.id.foo);    // or  (ImageView) view.findViewById(R.id.foo); As getView() works only after onCreateView(), you can't use it inside onCreate() or onCreateView() methods of the fragment ."
"data_i","edited Jan 20 '20 at 06:42","
        You need to use a Theme.AppCompat theme (or descendant) with this activity
    ","Android Studio 0.4.5Android documentation for creating custom dialog boxes: http://developer.android.com/guide/topics/ui/dialogs.htmlIf you want a custom dialog, you can instead display an Activity as a dialog instead of using the Dialog APIs. Simply create an activity and set its theme to Theme.Holo.Dialog in the <activity> manifest element:<activity android:theme=""@android:style/Theme.Holo.Dialog"" >However, when I tried this I get the following exception:java.lang.IllegalStateException: You need to use a Theme.AppCompat theme (or descendant) with this activityI am supporting the following, and I can't using something greater than 10 for the min:minSdkVersion 10targetSdkVersion 19In my styles I have the following:<!-- Base application theme. -->    <style name=""AppTheme"" parent=""Theme.AppCompat.Light.DarkActionBar"">And in my manifest I have this for the activity: <application        android:allowBackup=""true""        android:icon=""@drawable/ic_launcher""        android:label=""@string/app_name""        android:theme=""@style/AppTheme"" >        <activity            android:theme=""@android:style/Theme.Holo.Light.Dialog""            android:name=""com.ssd.register.Dialog_update""            android:label=""@string/title_activity_dialog_update"" >        </activity>Creating the dialog box like this was something I was hopping to do, as I have already completed the layout.Can anyone tell me how I can get around this problem?","The reason you are having this problem is because the activity you are trying to apply the dialog theme to is extending ActionBarActivity which requires the AppCompat theme to be applied. Update: Extending  AppCompatActivity would also  have this problem In this case, change the Java inheritance from ActionBarActivity to Activity and leave the dialog theme in the manifest as it is, a non Theme.AppCompat value The general rule is that if you want your code to support older versions of Android,  it should have the AppCompat theme and the java code should extend AppCompatActivity. If you have *an activity that doesn't need this support, such as you only care about the latest versions and features of Android, you can apply any theme to it but the java code must extend plain old Activity.NOTE: When change from AppCompatActivity (or a subclass, ActionBarActivity), to Activity, must also change the various calls with ""support"" to the corresponding call without ""support"".  So, instead of getSupportFragmentManager, call getFragmentManager."
"data_i","edited Apr 19 '20 at 13:44","
        What are POD types in C++?
    ","I've come across this term POD-type a few times.What does it mean? ","POD stands for Plain Old Data - that is, a class (whether defined with the keyword struct or the keyword class) without constructors, destructors and virtual members functions. Wikipedia's article on POD goes into a bit more detail and defines it as:A Plain Old Data Structure in C++ is an aggregate class that contains only PODS as members, has no user-defined destructor, no user-defined copy assignment operator, and no nonstatic members of pointer-to-member type.Greater detail can be found in this answer for C++98/03. C++11 changed the rules surrounding POD, relaxing them greatly, thus necessitating a follow-up answer here."
"data_i","edited Apr 19 '20 at 11:33","
        Are there constants in JavaScript?
    ","Is there a way to use constants in JavaScript?If not, what's the common practice for specifying variables that are used as constants?","Since ES2015, JavaScript has a notion of const:const MY_CONSTANT = ""some-value"";This will work in pretty much all browsers except IE 8, 9 and 10. Some may also need strict mode enabled.You can use var with conventions like ALL_CAPS to show that certain values should not be modified if you need to support older browsers or are working with legacy code:var MY_CONSTANT = ""some-value"";"
"data_i","edited Jun 24 '18 at 14:53","
        How can I pad an integer with zeros on the left?
    ","How do you left pad an int with zeros when converting to a String in java?I'm basically looking to pad out integers up to 9999 with leading zeros (e.g. 1 = 0001).","Use java.lang.String.format(String,Object...) like this:String.format(""%05d"", yournumber);for zero-padding with a length of 5. For hexadecimal output replace the d with an x as in ""%05x"".The full formatting options are documented as part of java.util.Formatter."
"data_i","edited Sep 18 '22 at 15:40","
        Set select option 'selected', by value
    ","I have a select field with some options in it. Now I need to select one of those options with jQuery. But how can I do that when I only know the value of the option that must be selected?I have the following HTML:<div class=""id_100"">  <select>    <option value=""val1"">Val 1</option>    <option value=""val2"">Val 2</option>    <option value=""val3"">Val 3</option>  </select></div>I need to select the option with value val2. How can this be done?Here's a demo page:http://jsfiddle.net/9Stxb/","There's an easier way that doesn't require you to go into the options tag:$(""div.id_100 select"").val(""val2"");Check out this jQuery method.Note: The above code does not trigger the change event.You need to call it like this for full compatibility:$(""div.id_100 select"").val(""val2"").change();"
"data_i","edited Mar 30 '22 at 05:11","
        Difference between del, remove, and pop on lists
    ","Is there any difference between these three methods to remove an element from a list?>>> a = [1, 2, 3]>>> a.remove(2)>>> a[1, 3]>>> a = [1, 2, 3]>>> del a[1]>>> a[1, 3]>>> a = [1, 2, 3]>>> a.pop(1)2>>> a[1, 3]","The effects of the three different methods to remove an element from a list:remove removes the first matching value, not a specific index:>>> a = [0, 2, 3, 2]>>> a.remove(2)>>> a[0, 3, 2]del removes the item at a specific index:>>> a = [9, 8, 7, 6]>>> del a[1]>>> a[9, 7, 6]and pop removes the item at a specific index and returns it.>>> a = [4, 3, 5]>>> a.pop(1)3>>> a[4, 5]Their error modes are different too:>>> a = [4, 5, 6]>>> a.remove(7)Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>ValueError: list.remove(x): x not in list>>> del a[7]Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>IndexError: list assignment index out of range>>> a.pop(7)Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>IndexError: pop index out of range"
"data_i","edited Oct 21 '20 at 11:54","
        How to determine if Javascript array contains an object with an attribute that equals a given value?
    ","I have an array likevendors = [{    Name: 'Magenic',    ID: 'ABC'  },  {    Name: 'Microsoft',    ID: 'DEF'  } // and so on... ];How do I check this array to see if ""Magenic"" exists? I don't want to loop, unless I have to. I'm working with potentially a couple thousand records.","No need to reinvent the wheel loop, at least not explicitly (using arrow functions, modern browsers only):if (vendors.filter(e => e.Name === 'Magenic').length > 0) {  /* vendors contains the element we're looking for */}or, better yet, use some as it allows the browser to stop as soon as one element is found that matches, so it's going to be faster:if (vendors.some(e => e.Name === 'Magenic')) {  /* vendors contains the element we're looking for */}or the equivalent (in this case) find:if (vendors.find(e => e.Name === 'Magenic')) {  /* same result as above, but a different function return type */}And you can even get the position of that element by using findIndex:const i = vendors.findIndex(e => e.Name === 'Magenic');if (i > -1) {  /* vendors contains the element we're looking for, at index ""i"" */}And if you need compatibility with lousy browsers then your best bet is:if (vendors.filter(function(e) { return e.Name === 'Magenic'; }).length > 0) {  /* vendors contains the element we're looking for */}"
"data_i","edited Apr 09 '22 at 10:22","
        How do I get a list of locally installed Python modules?
    ","How do I get a list of Python modules installed on my computer?","help('modules')in a Python shell/prompt."
"data_i","edited Feb 04 '14 at 03:00","
        Remove a symlink to a directory
    ","I have a symlink to an important directory. I want to get rid of that symlink, while keeping the directory behind it.  I tried rm and get back rm: cannot remove 'foo'.I tried rmdir and got back rmdir: failed to remove 'foo': Directory not emptyI then progressed through rm -f, rm -rf and sudo rm -rfThen I went to find my back-ups.Is there a way to get rid of the symlink with out throwing away the baby with the bathwater?   ","# this works:rm foo# versus this, which doesn't:rm foo/Basically, you need to tell it to delete a file, not delete a directory. I believe the difference between rm and rmdir exists because of differences in the way the C library treats each.At any rate, the first should work, while the second should complain about foo being a directory.If it doesn't work as above, then check your permissions. You need write permission to the containing directory to remove files."
"data_i","edited Feb 19 '17 at 02:34","
        Why do people use Heroku when AWS is present? What distinguishes Heroku from AWS?
    ","I'm a beginner RoR programmer who's planning to deploy my app using Heroku. Word from my other advisor friends says that Heroku is really easy, good to use. The only problem is that I still have no idea what Heroku does...I've looked at their website and in a nutshell, what Heroku does is help with scaling but... why does that even matter? How does Heroku help with:Speed - My research implied that deploying AWS on the US East Coast would be the fastest if I am targeting a US/Asia-based audience.Security - How secure are they?Scaling - How does it actually work?Cost efficiency - There's something like a dyno that makes it easy to scale.How do they fare against their competitors? For example, Engine Yard and bluebox?Please use layman English terms to explain... I'm a beginner programmer.","First things first, AWS and Heroku are different things. AWS offer Infrastructure as a Service (IaaS) whereas Heroku offer a Platform as a Service (PaaS).What's the difference? Very approximately, IaaS gives you components you need in order to build things on top of it; PaaS gives you an environment where you just push code and some basic configuration and get a running application. IaaS can give you more power and flexibility, at the cost of having to build and maintain more yourself.To get your code running on AWS and looking a bit like a Heroku deployment, you'll want some EC2 instances - you'll want a load balancer / caching layer installed on them (e.g. Varnish), you'll want instances running something like Passenger and nginx to serve your code, you'll want to deploy and configure a clustered database instance of something like PostgreSQL. You'll want a deployment system with something like Capistrano, and something doing log aggregation.That's not an insignificant amount of work to set up and maintain. With Heroku, the effort required to get to that sort of stage is maybe a few lines of application code and a git push.So you're this far, and you want to scale up. Great. You're using Puppet for your EC2 deployment, right? So now you configure your Capistrano files to spin up/down instances as needed; you re-jig your Puppet config so Varnish is aware of web-worker instances and will automatically pool between them. Or you heroku scale web:+5.Hopefully that gives you an idea of the comparison between the two. Now to address your specific points:SpeedCurrently Heroku only runs on AWS instances in us-east and eu-west. For you, this sounds like what you want anyway. For others, it's potentially more of a consideration.SecurityI've seen a lot of internally-maintained production servers that are way behind on security updates, or just generally poorly put together. With Heroku, you have someone else managing that sort of thing, which is either a blessing or a curse depending on how you look at it!When you deploy, you're effectively handing your code straight over to Heroku. This may be an issue for you. Their article on Dyno Isolation details their isolation technologies (it seems as though multiple dynos are run on individual EC2 instances). Several colleagues have expressed issues with these technologies and the strength of their isolation; I am alas not in a position of enough knowledge / experience to really comment, but my current Heroku deployments consider that ""good enough"". It may be an issue for you, I don't know.ScalingI touched on how one might implement this in my IaaS vs PaaS comparison above. Approximately, your application has a Procfile, which has lines of the form dyno_type: command_to_run, so for example (cribbed from http://devcenter.heroku.com/articles/process-model):web:    bundle exec rails serverworker: bundle exec rake jobs:workThis, with a:heroku scale web:2 worker:10will result in you having 2 web dynos and 10 worker dynos running. Nice, simple, easy. Note that web is a special dyno type, which has access to the outside world, and is behind their nice web traffic multiplexer (probably some sort of Varnish / nginx combination) that will route traffic accordingly. Your workers probably interact with a message queue for similar routing, from which they'll get the location via a URL in the environment.Cost EfficiencyLots of people have lots of different opinions about this. Currently it's $0.05/hr for a dyno hour, compared to $0.025/hr for an AWS micro instance or $0.09/hr for an AWS small instance.Heroku's dyno documentation says you have about 512MB of RAM, so it's probably not too unreasonable to consider a dyno as a bit like an EC2 micro instance. Is it worth double the price? How much do you value your time? The amount of time and effort required to build on top of an IaaS offering to get it to this standard is definitely not cheap. I can't really answer this question for you, but don't underestimate the 'hidden costs' of setup and maintenance.(A bit of an aside, but if I connect to a dyno from here (heroku run bash), a cursory look shows 4 cores in /proc/cpuinfo and 36GB of RAM - this leads me to believe that I'm on a ""High-Memory Double Extra Large Instance"". The Heroku dyno documentation says each dyno receives 512MB of RAM, so I'm potentially sharing with up to 71 other dynos. (I don't have enough data about the homogeny of Heroku's AWS instances, so your milage may vary))How do they fare against their competitors?This, I'm afraid I can't really help you with. The only competitor I've ever really looked at was Google App Engine - at the time I was looking to deploy Java applications, and the amount of restrictions on usable frameworks and technologies was incredibly off-putting. This is more than ""just a Java thing"" - the amount of general restrictions and necessary considerations (the FAQ hints at several) seemed less than convenient. In contrast, deploying to Heroku has been a dream.ConclusionPlease comment if there are gaps / other areas you'd like addressed. I feel I should offer my personal position. I love Heroku for ""quick deployments"". When I'm starting an application, and I want some cheap hosting (the Heroku free tier is awesome - essentially if you only need one web dyno and 5MB of PostgreSQL, it's free to host an application), Heroku is my go-to position. For ""Serious Production Deployment"" with several paying customers, with a service-level-agreement, with dedicated time to spend on ops, et cetera, I can't quite bring myself to offload that much control to Heroku, and then either AWS or our own servers have been the hosting platform of choice.Ultimately, it's about what works best for you. You say you're ""a beginner programmer"" - it might just be that using Heroku will let you focus on writing Ruby, and not have to spend time getting all the other infrastructure around your code built up. I'd definitely give it a try.Note, AWS does actually have a PaaS offering, Elastic Beanstalk, that supports Ruby, Node.js, PHP, Python, .NET and Java. I think generally most people, when they see ""AWS"", jump to things like EC2 and S3 and EBS, which are definitely IaaS offerings"
"data_i","edited Jun 06 '22 at 04:40","
        Fastest way to check if a value exists in a list
    ","What is the fastest way to check if a value exists in a very large list?","7 in aClearest and fastest way to do it.You can also consider using a set, but constructing that set from your list may take more time than faster membership testing will save. The only way to be certain is to benchmark well. (this also depends on what operations you require)"
"data_i","edited Dec 07 '20 at 19:53","
        ""Large data"" workflows using pandas
    ","I have tried to puzzle out an answer to this question for many months while learning pandas.  I use SAS for my day-to-day work and it is great for it's out-of-core support.  However, SAS is horrible as a piece of software for numerous other reasons.One day I hope to replace my use of SAS with python and pandas, but I currently lack an out-of-core workflow for large datasets.  I'm not talking about ""big data"" that requires a distributed network, but rather files too large to fit in memory but small enough to fit on a hard-drive.My first thought is to use HDFStore to hold large datasets on disk and pull only the pieces I need into dataframes for analysis.  Others have mentioned MongoDB as an easier to use alternative.  My question is this:What are some best-practice workflows for accomplishing the following:Loading flat files into a permanent, on-disk database structureQuerying that database to retrieve data to feed into a pandas data structureUpdating the database after manipulating pieces in pandasReal-world examples would be much appreciated, especially from anyone who uses pandas on ""large data"".Edit -- an example of how I would like this to work:Iteratively import a large flat-file and store it in a permanent, on-disk database structure.  These files are typically too large to fit in memory.In order to use Pandas, I would like to read subsets of this data (usually just a few columns at a time) that can fit in memory.I would create new columns by performing various operations on the selected columns.I would then have to append these new columns into the database structure.I am trying to find a best-practice way of performing these steps. Reading links about pandas and pytables it seems that appending a new column could be a problem.Edit -- Responding to Jeff's questions specifically:I am building consumer credit risk models. The kinds of data include phone, SSN and address characteristics; property values; derogatory information like criminal records, bankruptcies, etc... The datasets I use every day have nearly 1,000 to 2,000 fields on average of mixed data types: continuous, nominal and ordinal variables of both numeric and character data.  I rarely append rows, but I do perform many operations that create new columns.Typical operations involve combining several columns using conditional logic into a new, compound column. For example, if var1 > 2 then newvar = 'A' elif var2 = 4 then newvar = 'B'.  The result of these operations is a new column for every record in my dataset.Finally, I would like to append these new columns into the on-disk data structure.  I would repeat step 2, exploring the data with crosstabs and descriptive statistics trying to find interesting, intuitive relationships to model.A typical project file is usually about 1GB.  Files are organized into such a manner where a row consists of a record of consumer data.  Each row has the same number of columns for every record.  This will always be the case.It's pretty rare that I would subset by rows when creating a new column.  However, it's pretty common for me to subset on rows when creating reports or generating descriptive statistics.  For example, I might want to create a simple frequency for a specific line of business, say Retail credit cards.  To do this, I would select only those records where the line of business = retail in addition to whichever columns I want to report on.  When creating new columns, however, I would pull all rows of data and only the columns I need for the operations.The modeling process requires that I analyze every column, look for interesting relationships with some outcome variable, and create new compound columns that describe those relationships.  The columns that I explore are usually done in small sets.  For example, I will focus on a set of say 20 columns just dealing with property values and observe how they relate to defaulting on a loan.  Once those are explored and new columns are created, I then move on to another group of columns, say college education, and repeat the process.  What I'm doing is creating candidate variables that explain the relationship between my data and some outcome.  At the very end of this process, I apply some learning techniques that create an equation out of those compound columns.It is rare that I would ever add rows to the dataset.  I will nearly always be creating new columns (variables or features in statistics/machine learning parlance).","I routinely use tens of gigabytes of data in just this fashione.g. I have tables on disk that I read via queries, create data and append back.It's worth reading the docs and late in this thread for several suggestions for how to store your data.Details which will affect how you store your data, like:Give as much detail as you can; and I can help you develop a structure.Size of data, # of rows, columns, types of columns; are you appendingrows, or just columns? What will typical operations look like. E.g. do a query on columns to select a bunch of rows and specific columns, then do an operation (in-memory), create new columns, save these.(Giving a toy example could enable us to offer more specific recommendations.)After that processing, then what do you do? Is step 2 ad hoc, or repeatable?Input flat files: how many, rough total size in Gb. How are these organized e.g. by records? Does each one contains different fields, or do they have some records per file with all of the fields in each file?Do you ever select subsets of rows (records) based on criteria (e.g. select the rows with field A > 5)? and then do something, or do you just select fields A, B, C with all of the records (and then do something)?Do you 'work on' all of your columns (in groups), or are there a good proportion that you may only use for reports (e.g. you want to keep the data around, but don't need to pull in that column explicity until final results time)?SolutionEnsure you have pandas at least 0.10.1 installed.Read iterating files chunk-by-chunk and multiple table queries.Since pytables is optimized to operate on row-wise (which is what you query on), we will create a table for each group of fields. This way it's easy to select a small group of fields (which will work with a big table, but it's more efficient to do it this way... I think I may be able to fix this limitation in the future... this is more intuitive anyhow):(The following is pseudocode.)import numpy as npimport pandas as pd# create a storestore = pd.HDFStore('mystore.h5')# this is the key to your storage:#    this maps your fields to a specific group, and defines #    what you want to have as data_columns.#    you might want to create a nice class wrapping this#    (as you will want to have this map and its inversion)  group_map = dict(    A = dict(fields = ['field_1','field_2',.....], dc = ['field_1',....,'field_5']),    B = dict(fields = ['field_10',......        ], dc = ['field_10']),    .....    REPORTING_ONLY = dict(fields = ['field_1000','field_1001',...], dc = []),)group_map_inverted = dict()for g, v in group_map.items():    group_map_inverted.update(dict([ (f,g) for f in v['fields'] ]))Reading in the files and creating the storage (essentially doing what append_to_multiple does):for f in files:   # read in the file, additional options may be necessary here   # the chunksize is not strictly necessary, you may be able to slurp each    # file into memory in which case just eliminate this part of the loop    # (you can also change chunksize if necessary)   for chunk in pd.read_table(f, chunksize=50000):       # we are going to append to each table by group       # we are not going to create indexes at this time       # but we *ARE* going to create (some) data_columns       # figure out the field groupings       for g, v in group_map.items():             # create the frame for this group             frame = chunk.reindex(columns = v['fields'], copy = False)                 # append it             store.append(g, frame, index=False, data_columns = v['dc'])Now you have all of the tables in the file (actually you could store them in separate files if you wish, you would prob have to add the filename to the group_map, but probably this isn't necessary).This is how you get columns and create new ones:frame = store.select(group_that_I_want)# you can optionally specify:# columns = a list of the columns IN THAT GROUP (if you wanted to#     select only say 3 out of the 20 columns in this sub-table)# and a where clause if you want a subset of the rows# do calculations on this framenew_frame = cool_function_on_frame(frame)# to 'add columns', create a new group (you probably want to# limit the columns in this new_group to be only NEW ones# (e.g. so you don't overlap from the other tables)# add this info to the group_mapstore.append(new_group, new_frame.reindex(columns = new_columns_created, copy = False), data_columns = new_columns_created)When you are ready for post_processing:# This may be a bit tricky; and depends what you are actually doing.# I may need to modify this function to be a bit more general:report_data = store.select_as_multiple([groups_1,groups_2,.....], where =['field_1>0', 'field_1000=foo'], selector = group_1)About data_columns, you don't actually need to define ANY data_columns; they allow you to sub-select rows based on the column. E.g. something like:store.select(group, where = ['field_1000=foo', 'field_1001>0'])They may be most interesting to you in the final report generation stage (essentially a data column is segregated from other columns, which might impact efficiency somewhat if you define a lot).You also might want to:create a function which takes a list of fields, looks up the groups in the groups_map, then selects these and concatenates the results so you get the resulting frame (this is essentially what select_as_multiple does). This way the structure would be pretty transparent to you.indexes on certain data columns (makes row-subsetting much faster).enable compression.Let me know when you have questions!"
"data_i","edited Jan 07 '17 at 09:03","
        Shortcuts in Objective-C to concatenate NSStrings
    ","Are there any shortcuts to (stringByAppendingString:) string concatenation in Objective-C, or shortcuts for working with NSString in general?For example, I'd like to make:NSString *myString = @""This"";NSString *test = [myString stringByAppendingString:@"" is just a test""];something more like:string myString = ""This"";string test = myString + "" is just a test"";","An option:[NSString stringWithFormat:@""%@/%@/%@"", one, two, three];Another option:I'm guessing you're not happy with multiple appends (a+b+c+d), in which case you could do:NSLog(@""%@"", [Util append:one, @"" "", two, nil]); // ""one two""NSLog(@""%@"", [Util append:three, @""/"", two, @""/"", one, nil]); // three/two/oneusing something like+ (NSString *) append:(id) first, ...{    NSString * result = @"""";    id eachArg;    va_list alist;    if(first)    {        result = [result stringByAppendingString:first];        va_start(alist, first);        while (eachArg = va_arg(alist, id))         result = [result stringByAppendingString:eachArg];        va_end(alist);    }    return result;}"
"data_i","edited Sep 12 '22 at 05:23","
        How do I iterate through two lists in parallel?
    ","I have two iterables, and I want to go over them in pairs:foo = [1, 2, 3]bar = [4, 5, 6]for (f, b) in iterate_together(foo, bar):    print(""f:"", f, "" |  b:"", b)That should result in:f: 1  |  b: 4f: 2  |  b: 5f: 3  |  b: 6One way to do it is to iterate over the indices:for i in range(len(foo)):    print(""f:"", foo[i], "" |  b:"", bar[i])But that seems somewhat unpythonic to me. Is there a better way to do it?","Python 3for f, b in zip(foo, bar):    print(f, b)zip stops when the shorter of foo or bar stops.In Python 3, zipreturns an iterator of tuples, like itertools.izip in Python2.  To get a listof tuples, use list(zip(foo, bar)). And to zip until both iterators areexhausted, you would useitertools.zip_longest.Python 2In Python 2, zipreturns a list of tuples. This is fine when foo and bar are not massive. If they are both massive then forming zip(foo,bar) is an unnecessarily massivetemporary variable, and should be replaced by itertools.izip oritertools.izip_longest, which returns an iterator instead of a list.import itertoolsfor f,b in itertools.izip(foo,bar):    print(f,b)for f,b in itertools.izip_longest(foo,bar):    print(f,b)izip stops when either foo or bar is exhausted.izip_longest stops when both foo and bar are exhausted.When the shorter iterator(s) are exhausted, izip_longest yields a tuple with None in the position corresponding to that iterator. You can also set a different fillvalue besides None if you wish. See here for the full story.Note also that zip and its zip-like brethen can accept an arbitrary number of iterables as arguments. For example,for num, cheese, color in zip([1,2,3], ['manchego', 'stilton', 'brie'],                               ['red', 'blue', 'green']):    print('{} {} {}'.format(num, color, cheese))prints1 red manchego2 blue stilton3 green brie"
"data_i","edited Jan 30 '19 at 21:04","
        Check if a variable is of function type
    ","Suppose I have any variable, which is defined as follows:var a = function() {/* Statements */};I want a function which checks if the type of the variable is function-like. i.e. :function foo(v) {if (v is function type?) {/* do something */}};foo(a);How can I check if the variable a is of type Function in the way defined above?","if (typeof v === 'function') {    // do something}"
"data_i","edited Jul 22 '20 at 15:54","
        Convert a string to an enum in C#
    ","What's the best way to convert a string to an enumeration value in C#?I have an HTML select tag containing the values of an enumeration. When the page is posted, I want to pick up the value (which will be in the form of a string) and convert it to the corresponding enumeration value.In an ideal world, I could do something like this:StatusEnum MyStatus = StatusEnum.Parse(""Active"");but that isn't a valid code.","In .NET Core and .NET Framework ≥4.0 there is a generic parse method:Enum.TryParse(""Active"", out StatusEnum myStatus);This also includes C#7's new inline out variables, so this does the try-parse, conversion to the explicit enum type and initialises+populates the myStatus variable.If you have access to C#7 and the latest .NET this is the best way.Original AnswerIn .NET it's rather ugly (until 4 or above):StatusEnum MyStatus = (StatusEnum) Enum.Parse(typeof(StatusEnum), ""Active"", true);I tend to simplify this with:public static T ParseEnum<T>(string value){    return (T) Enum.Parse(typeof(T), value, true);}Then I can do:StatusEnum MyStatus = EnumUtil.ParseEnum<StatusEnum>(""Active"");One option suggested in the comments is to add an extension, which is simple enough:public static T ToEnum<T>(this string value){    return (T) Enum.Parse(typeof(T), value, true);}StatusEnum MyStatus = ""Active"".ToEnum<StatusEnum>();Finally, you may want to have a default enum to use if the string cannot be parsed:public static T ToEnum<T>(this string value, T defaultValue) {    if (string.IsNullOrEmpty(value))    {        return defaultValue;    }    T result;    return Enum.TryParse<T>(value, true, out result) ? result : defaultValue;}Which makes this the call:StatusEnum MyStatus = ""Active"".ToEnum(StatusEnum.None);However, I would be careful adding an extension method like this to string as (without namespace control) it will appear on all instances of string whether they hold an enum or not (so 1234.ToString().ToEnum(StatusEnum.None) would be valid but nonsensical) . It's often be best to avoid cluttering Microsoft's core classes with extra methods that only apply in very specific contexts unless your entire development team has a very good understanding of what those extensions do."
"data_i","edited Jul 11 '22 at 05:49","
        What is the difference between statically typed and dynamically typed languages?
    ","What does it mean when we say a language is dynamically typed versus statically typed?","Statically typed languagesA language is statically typed if the type of a variable is known at compile time. For some languages this means that you as the programmer must specify what type each variable is; other languages (e.g.: Java, C, C++) offer some form of type inference, the capability of the type system to deduce the type of a variable (e.g.: OCaml, Haskell, Scala, Kotlin).The main advantage here is that all kinds of checking can be done by the compiler, and therefore a lot of trivial bugs are caught at a very early stage.Examples: C, C++, Java, Rust, Go, ScalaDynamically typed languagesA language is dynamically typed if the type is associated with run-time values, and not named variables/fields/etc. This means that you as a programmer can write a little quicker because you do not have to specify types every time (unless using a statically-typed language with type inference).Examples: Perl, Ruby, Python, PHP, JavaScript, ErlangMost scripting languages have this feature as there is no compiler to do static type-checking anyway, but you may find yourself searching for a bug that is due to the interpreter misinterpreting the type of a variable. Luckily, scripts tend to be small so bugs have not so many places to hide.Most dynamically typed languages do allow you to provide type information, but do not require it. One language that is currently being developed, Rascal, takes a hybrid approach allowing dynamic typing within functions but enforcing static typing for the function signature."
"data_i","edited Sep 09 '20 at 04:29","
        Convert character to ASCII code in JavaScript
    ","How can I convert a character to its ASCII code using JavaScript?For example:get 10 from ""\n"".","""\n"".charCodeAt(0);"
"data_i","edited Jun 18 '22 at 18:45","
        How to reload .bash_profile from the command line
    ","How can I reload file .bash_profile from the command line?I can get the shell to recognize changes to .bash_profile by exiting and logging back in, but I would like to be able to do it on demand.","Simply type source ~/.bash_profile.Alternatively, if you like saving keystrokes, you can type . ~/.bash_profile."
"data_i","edited Jan 07 '14 at 14:17","
        What is the maximum length of a valid email address?
    ","What is the maximum length of a valid email address? Is it defined by any standard?","An email address must not exceed 254 characters.This was accepted by the IETF following submitted erratum. A full diagnosis of any given address is available online. The original version of RFC 3696 described 320 as the maximum length, but John Klensin subsequently accepted an incorrect value, since a Path is defined asPath = ""<"" [ A-d-l "":"" ] Mailbox "">""So the Mailbox element (i.e., the email address) has angle brackets around it to form a Path, which a maximum length of 254 characters to restrict the Path length to 256 characters or fewer.The maximum length specified in RFC 5321 states:The maximum total length of a reverse-path or forward-path is 256 characters.RFC 3696 was corrected here.People should be aware of the errata against RFC 3696 in particular. Three of the canonical examples are in fact invalid addresses.I've collated a couple hundred test addresses, which you can find at http://www.dominicsayers.com/isemail"
"data_i","edited Jun 10 '21 at 17:21","
        Use a list of values to select rows from a Pandas dataframe
    ","Let’s say I have the following Pandas dataframe:df = DataFrame({'A' : [5,6,3,4], 'B' : [1,2,3, 5]})df     A   B0    5   11    6   22    3   33    4   5I can subset based on a specific value:x = df[df['A'] == 3]x     A   B2    3   3But how can I subset based on a list of values? - something like this:list_of_values = [3,6]y = df[df['A'] in list_of_values]To get:     A    B1    6    22    3    3","You can use the isin method:In [1]: df = pd.DataFrame({'A': [5,6,3,4], 'B': [1,2,3,5]})In [2]: dfOut[2]:   A  B0  5  11  6  22  3  33  4  5In [3]: df[df['A'].isin([3, 6])]Out[3]:   A  B1  6  22  3  3And to get the opposite use ~:In [4]: df[~df['A'].isin([3, 6])]Out[4]:   A  B0  5  13  4  5"
"data_i","edited Sep 01 '17 at 15:57","
        What is an example of the Liskov Substitution Principle?
    ","I have heard that the Liskov Substitution  Principle (LSP) is a fundamental principle of object oriented design. What is it and what are some examples of its use?","A great example illustrating LSP (given by Uncle Bob in a podcast I heard recently) was how sometimes something that sounds right in natural language doesn't quite work in code.In mathematics, a Square is a Rectangle. Indeed it is a specialization of a rectangle. The ""is a"" makes you want to model this with inheritance. However if in code you made Square derive from Rectangle, then a Square should be usable anywhere you expect a Rectangle. This makes for some strange behavior.Imagine you had SetWidth and SetHeight methods on your Rectangle base class; this seems perfectly logical. However if your Rectangle reference pointed to a Square, then SetWidth and SetHeight doesn't make sense because setting one would change the other to match it. In this case Square fails the Liskov Substitution Test with Rectangle and the abstraction of having Square inherit from Rectangle is a bad one.Y'all should check out the other priceless SOLID Principles Explained With Motivational Posters."
"data_i","edited May 21 '18 at 19:47","
        How to prune local tracking branches that do not exist on remote anymore
    ","With git remote prune origin I can remove the local branches that are not  on the remote any more.But I also want to remove local branches that were created from those remote branches (a check if they are unmerged would be nice).How can I do this?","After pruning, you can get the list of remote branches with git branch -r.  The list of branches with their remote tracking branch can be retrieved with git branch -vv.  So using these two lists you can find the remote tracking branches that are not in the list of remotes.This line should do the trick (requires bash or zsh, won't work with standard Bourne shell):git fetch -p ; git branch -r | awk '{print $1}' | egrep -v -f /dev/fd/0 <(git branch -vv | grep origin) | awk '{print $1}' | xargs git branch -dThis string gets the list of remote branches and passes it into egrep through the standard input.  And filters the branches that have a remote tracking branch (using git branch -vv and filtering for those that have origin) then getting the first column of that output which will be the branch name.  Finally passing all the branch names into the delete branch command.Since it is using the -d option, it will not delete branches that have not been merged into the branch that you are on when you run this command."
"data_i","edited Mar 01 '21 at 12:45","
        How to resolve java.lang.NoClassDefFoundError: javax/xml/bind/JAXBException
    ","I have some code that uses JAXB API classes which have been provided as a part of the JDK in Java 6/7/8.  When I run the same code with Java 9, at runtime I get errors indicating that JAXB classes can not be found.The JAXB classes have been provided as a part of the JDK since Java 6, so why can Java 9 no longer find these classes?","The JAXB APIs are considered to be Java EE APIs and therefore are no longer contained on the default classpath in Java SE 9. In Java 11, they are completely removed from the JDK.Java 9 introduces the concepts of modules, and by default, the java.se aggregate module is available on the classpath (or rather, module-path). As the name implies, the java.se aggregate module does not include the Java EE APIs that have been traditionally bundled with Java 6/7/8.Fortunately, these Java EE APIs that were provided in JDK 6/7/8 are still in the JDK, but they just aren't on the classpath by default. The extra Java EE APIs are provided in the following modules:java.activationjava.corbajava.transactionjava.xml.bind  << This one contains the JAXB APIsjava.xml.wsjava.xml.ws.annotationQuick and dirty solution: (JDK 9/10 only)To make the JAXB APIs available at runtime, specify the following command-line option:--add-modules java.xml.bindBut I still need this to work with Java 8!!!If you try specifying --add-modules with an older JDK, it will blow up because it's an unrecognized option. I suggest one of two options:You can set any Java 9+ only options using the JDK_JAVA_OPTIONS environment variable. This environment variable is automatically read by the java launcher for Java 9+.You can add the -XX:+IgnoreUnrecognizedVMOptions to make the JVM silently ignore unrecognized options, instead of blowing up. But beware! Any other command-line arguments you use will no longer be validated for you by the JVM. This option works with Oracle/OpenJDK as well as IBM JDK (as of JDK 8sr4).Alternate quick solution: (JDK 9/10 only)Note that you can make all of the above Java EE modules available at run time by specifying the --add-modules java.se.ee option. The java.se.ee module is an aggregate module that includes java.se.ee as well as the above Java EE API modules. Note, this doesn't work on Java 11 because java.se.ee was removed in Java 11.Proper long-term solution: (JDK 9 and beyond)The Java EE API modules listed above are all marked @Deprecated(forRemoval=true) because they are scheduled for removal in Java 11. So the --add-module approach will no longer work in Java 11 out-of-the-box.What you will need to do in Java 11 and forward is include your own copy of the Java EE APIs on the classpath or module path. For example, you can add the JAX-B APIs as a Maven dependency like this:<!-- API, java.xml.bind module --><dependency>    <groupId>jakarta.xml.bind</groupId>    <artifactId>jakarta.xml.bind-api</artifactId>    <version>2.3.2</version></dependency><!-- Runtime, com.sun.xml.bind module --><dependency>    <groupId>org.glassfish.jaxb</groupId>    <artifactId>jaxb-runtime</artifactId>    <version>2.3.2</version></dependency>See the JAXB Reference Implementation page for more details on JAXB.For full details on Java modularity, see JEP 261: Module SystemAs of July 2022, the latest version of the bind-api and jaxb-runtime is 4.0.0.  So you can also use    <version>4.0.0</version>...within those dependency clauses. But if you do so, the package names have changed from javax.xml.bind... to jakarta.xml.bind....  You will need to modify your source code to use these later versions of the JARs.For Gradle or Android Studio developer: (JDK 9 and beyond)Add the following dependencies to your build.gradle file:dependencies {    // JAX-B dependencies for JDK 9+    implementation ""jakarta.xml.bind:jakarta.xml.bind-api:2.3.2""    implementation ""org.glassfish.jaxb:jaxb-runtime:2.3.2""}"
"data_i","edited Jun 29 '18 at 15:37","
        Can't create handler inside thread that has not called Looper.prepare()
    ","What does the following exception mean; how can I fix it?This is the code:Toast toast = Toast.makeText(mContext, ""Something"", Toast.LENGTH_SHORT);This is the exception:java.lang.RuntimeException: Can't create handler inside thread that has not called Looper.prepare()     at android.os.Handler.<init>(Handler.java:121)     at android.widget.Toast.<init>(Toast.java:68)     at android.widget.Toast.makeText(Toast.java:231)","You need to call Toast.makeText(...) from the UI thread:activity.runOnUiThread(new Runnable() {  public void run() {    Toast.makeText(activity, ""Hello"", Toast.LENGTH_SHORT).show();  }});This is copy-pasted from another (duplicate) SO answer."
"data_i","edited Apr 08 '22 at 07:22","
        Filename too long in Git for Windows
    ","I'm using Git-1.9.0-preview20140217 for Windows. As I know, this release should fix the issue with too long filenames. But not for me.Surely I'm doing something wrong: I did git config core.longpaths true and git add . and then git commit. Everything went well. But when I now do a git status, I get a list of files with Filename too long, for example:node_modules/grunt-contrib-imagemin/node_modules/pngquant-bin/node_modules/bin-wrapper/node_modules/download/node_modules/request/node_modules/form-data/node_modules/combined-stream/node_modules/delayed-stream/test/integration/test-handle-source-errors.js: Filename too longIt is quite simple to reproduce for me: just create a Yeoman web application with the Angular generator (""yo angular"") and remove node_modules from the .gitignore file. Then repeat the aforementioned Git commands.What am I missing here?","Git has a limit of 4096 characters for a filename, except on Windows when Git is compiled with msys. It uses an older version of the Windows API and there's a limit of 260 characters for a filename.So as far as I understand this, it's a limitation of msys and not of Git. You can read the details here:https://github.com/msysgit/git/pull/110You can circumvent this by using another Git client on Windows or set core.longpaths to true as explained in other answers.git config --system core.longpaths trueGit is build as a combination of scripts and compiled code. With the above change some of the scripts might fail. That's the reason for core.longpaths not to be enabled by default.The windows documentation at https://docs.microsoft.com/en-us/windows/win32/fileio/maximum-file-path-limitation?tabs=cmd#enable-long-paths-in-windows-10-version-1607-and-later has some more information:Starting in Windows 10, version 1607, MAX_PATH limitations have beenremoved from common Win32 file and directory functions. However, youmust opt-in to the new behavior.A registry key allows you to enable or disable the new long pathbehavior. To enable long path behavior set the registry key atHKLM\SYSTEM\CurrentControlSet\Control\FileSystem\LongPathsEnabled(Type: REG_DWORD)"
"data_i","edited Dec 16 '19 at 04:55","
        How to apply CSS to iframe?
    ","I have a simple page that has some iframe sections (to display RSS links). How can I apply the same CSS format from the main page to the page displayed in the iframe?","Edit: This does not work cross domain unless the appropriate CORS header is set.There are two different things here: the style of the iframe block and the style of the page embedded in the iframe. You can set the style of the iframe block the usual way:<iframe name=""iframe1"" id=""iframe1"" src=""empty.htm""         frameborder=""0"" border=""0"" cellspacing=""0""        style=""border-style: none;width: 100%; height: 120px;""></iframe>The style of the page embedded in the iframe must be either set by including it in the child page:<link type=""text/css"" rel=""Stylesheet"" href=""Style/simple.css"" />Or it can be loaded from the parent page with Javascript:var cssLink = document.createElement(""link"");cssLink.href = ""style.css""; cssLink.rel = ""stylesheet""; cssLink.type = ""text/css""; frames['iframe1'].document.head.appendChild(cssLink);"
"data_i","edited Aug 17 '19 at 01:29","
        Why not use Double or Float to represent currency?
    ","I've always been told never to represent money with double or float types, and this time I pose the question to you: why? I'm sure there is a very good reason, I simply do not know what it is.","Because floats and doubles cannot accurately represent the base 10 multiples that we use for money. This issue isn't just for Java, it's for any programming language that uses base 2 floating-point types.In base 10, you can write 10.25 as 1025 * 10-2 (an integer times a power of 10). IEEE-754 floating-point numbers are different, but a very simple way to think about them is to multiply by a power of two instead. For instance, you could be looking at 164 * 2-4 (an integer times a power of two), which is also equal to 10.25. That's not how the numbers are represented in memory, but the math implications are the same.Even in base 10, this notation cannot accurately represent most simple fractions. For instance, you can't represent 1/3: the decimal representation is repeating (0.3333...), so there is no finite integer that you can multiply by a power of 10 to get 1/3. You could settle on a long sequence of 3's and a small exponent, like 333333333 * 10-10, but it is not accurate: if you multiply that by 3, you won't get 1.However, for the purpose of counting money, at least for countries whose money is valued within an order of magnitude of the US dollar, usually all you need is to be able to store multiples of 10-2, so it doesn't really matter that 1/3 can't be represented.The problem with floats and doubles is that the vast majority of money-like numbers don't have an exact representation as an integer times a power of 2. In fact, the only multiples of 0.01 between 0 and 1 (which are significant when dealing with money because they're integer cents) that can be represented exactly as an IEEE-754 binary floating-point number are 0, 0.25, 0.5, 0.75 and 1. All the others are off by a small amount. As an analogy to the 0.333333 example, if you take the floating-point value for 0.01 and you multiply it by 10, you won't get 0.1. Instead you will get something like 0.099999999786...Representing money as a double or float will probably look good at first as the software rounds off the tiny errors, but as you perform more additions, subtractions, multiplications and divisions on inexact numbers, errors will compound and you'll end up with values that are visibly not accurate. This makes floats and doubles inadequate for dealing with money, where perfect accuracy for multiples of base 10 powers is required.A solution that works in just about any language is to use integers instead, and count cents. For instance, 1025 would be $10.25. Several languages also have built-in types to deal with money. Among others, Java  has the BigDecimal class, and Rust has the rust_decimal crate, and C# has the decimal type."
"data_i","edited Nov 18 '18 at 07:28","
        How to compare strings in Bash
    ","How do I compare a variable to a string (and do something if they match)?","Using variables in if statementsif [ ""$x"" = ""valid"" ]; then  echo ""x has the value 'valid'""fiIf you want to do something when they don't match, replace = with !=. You can read more about string operations and arithmetic operations in their respective documentation.Why do we use quotes around $x?You want the quotes around $x, because if it is empty, your Bash script encounters a syntax error as seen below:if [ = ""valid"" ]; thenNon-standard use of == operatorNote that Bash allows == to be used for equality with [, but this is not standard.Use either the first case wherein the quotes around $x are optional:if [[ ""$x"" == ""valid"" ]]; thenor use the second case:if [ ""$x"" = ""valid"" ]; then"
"data_i","edited Nov 20 '17 at 17:29","
        Maximum request length exceeded.
    ","I am getting the error Maximum request length exceeded when I am trying to upload a video in my site.  How do I fix this?","If you are using IIS for hosting your application, then the default upload file size is 4MB. To increase it, please use this below section in your web.config -<configuration>    <system.web>        <httpRuntime maxRequestLength=""1048576"" />    </system.web></configuration>For IIS7 and above, you also need to add the lines below: <system.webServer>   <security>      <requestFiltering>         <requestLimits maxAllowedContentLength=""1073741824"" />      </requestFiltering>   </security> </system.webServer>Note: maxRequestLength is measured in kilobytesmaxAllowedContentLength is measured in bytes which is why the values differ in this config example. (Both are equivalent to 1 GB.)"
"data_i","edited Nov 12 '16 at 21:27","
        What are Long-Polling, Websockets, Server-Sent Events (SSE) and Comet?
    ","I have tried reading some articles, but I am not very clear on the concepts yet.Would someone like to take a shot at explaining to me what these technologies are:Long PollingServer-Sent EventsWebsocketsCometOne thing that I came across every time was, the server keeps a connection open and pushes data to the client. How is the connection kept open, and how does the client get the pushed data? (How does the client use the data, maybe some code might help?)Now, which one of them should I use for a real-time app. I have been hearing a lot about websockets (with socket.io [a node.js library]) but why not PHP?","In the examples below the client is the browser and the server is the webserver hosting the website.Before you can understand these technologies, you have to understand classic HTTP web traffic first.Regular HTTP:A client requests a webpage from a server.The server calculates the responseThe server sends the response to the client. Ajax Polling:A client requests a webpage from a server using regular HTTP (see HTTP above).The client receives the requested webpage and executes the JavaScript on the page which requests a file from the server at regular intervals (e.g. 0.5 seconds).The server calculates each response and sends it back, just like normal HTTP traffic.Ajax Long-Polling:A client requests a webpage from a server using regular HTTP (see HTTP above).The client receives the requested webpage and executes the JavaScript on the page which requests a file from the server.The server does not immediately respond with the requested information but waits until there's new information available.When there's new information available, the server responds with the new information.The client receives the new information and immediately sends another request to the server, re-starting the process. HTML5 Server Sent Events (SSE) / EventSource:A client requests a webpage from a server using regular HTTP (see HTTP above).The client receives the requested webpage and executes the JavaScript on the page which opens a connection to the server.The server sends an event to the client when there's new information available. Real-time traffic from server to client, mostly that's what you'll needYou'll want to use a server that has an event loopConnections with servers from other domains are only possible with correct CORS settingsIf you want to read more, I found these very useful: (article), (article), (article), (tutorial).HTML5 Websockets:A client requests a webpage from a server using regular http (see HTTP above).The client receives the requested webpage and executes the JavaScript on the page which opens a connection with the server.The server and the client can now send each other messages when new data (on either side) is available.Real-time traffic from the server to the client and from the client to the serverYou'll want to use a server that has an event loopWith WebSockets it is possible to connect with a server from another domain.It is also possible to use a third party hosted websocket server, for example Pusher or others. This way you'll only have to implement the client side, which is very easy!If you want to read more, I found these very useful: (article), (article) (tutorial).Comet:Comet is a collection of techniques prior to HTML5 which use streaming and long-polling to achieve real time applications. Read more on wikipedia or this article.Now, which one of them should I use for a realtime app (that I need to  code). I have been hearing a lot about websockets (with socket.io [a  node.js library]) but why not PHP ?You can use PHP with WebSockets, check out Ratchet. "
"data_i","edited Dec 28 '15 at 08:49","
        Fling gesture detection on grid layout
    ","I want to get fling gesture detection working in my Android application.What I have is a GridLayout that contains 9 ImageViews. The source can be found here: Romain Guys's Grid Layout.That file I take is from Romain Guy's Photostream application and has only been slightly adapted.For the simple click situation I need only set the onClickListener for each ImageView I add to be the main activity which implements View.OnClickListener. It seems infinitely more complicated to implement something that recognizes a fling. I presume this is because it may span views?If my activity implementsOnGestureListener I don't know how toset that as the gesture listener forthe Grid or the Image views that Iadd.public class SelectFilterActivity extends Activity implements   View.OnClickListener, OnGestureListener { ...If my activity implementsOnTouchListener then I have noonFling method to override (it hastwo events as parameters allowing meto determine if the fling wasnoteworthy).public class SelectFilterActivity extends Activity implements    View.OnClickListener, OnTouchListener { ...If I make a custom View, like GestureImageView that extends ImageView I don't know how to tell the activity that a fling has occurred from the view. In any case, I tried this and the methods weren't called when I touched the screen.I really just need a concrete example of this working across views. What, when and how should I attach this listener? I need to be able to detect single clicks also.// Gesture detectionmGestureDetector = new GestureDetector(this, new GestureDetector.SimpleOnGestureListener() {    public boolean onFling(MotionEvent e1, MotionEvent e2, float velocityX, float velocityY) {        int dx = (int) (e2.getX() - e1.getX());        // don't accept the fling if it's too short        // as it may conflict with a button push        if (Math.abs(dx) > MAJOR_MOVE && Math.abs(velocityX) > Math.absvelocityY)) {            if (velocityX > 0) {                moveRight();            } else {                moveLeft();            }            return true;        } else {            return false;        }    }});Is it possible to lay a transparent view over the top of my screen to capture flings?If I choose not to inflate my child image views from XML can I pass the GestureDetector as a constructor parameter to a new subclass of ImageView that I create?This is the very simple activity that I'm trying to get the fling detection to work for: SelectFilterActivity (Adapted from photostream).I've been looking at these sources:Detect Gestures - TutorialSDK docsCalculator CodeNothing has worked for me so far and I was hoping for some pointers.","Thanks to Code Shogun, whose code I adapted to my situation.Let your activity implementOnClickListener as usual:public class SelectFilterActivity extends Activity implements OnClickListener {  private static final int SWIPE_MIN_DISTANCE = 120;  private static final int SWIPE_MAX_OFF_PATH = 250;  private static final int SWIPE_THRESHOLD_VELOCITY = 200;  private GestureDetector gestureDetector;  View.OnTouchListener gestureListener;  @Override  protected void onCreate(Bundle savedInstanceState) {    super.onCreate(savedInstanceState);    /* ... */    // Gesture detection    gestureDetector = new GestureDetector(this, new MyGestureDetector());    gestureListener = new View.OnTouchListener() {      public boolean onTouch(View v, MotionEvent event) {        return gestureDetector.onTouchEvent(event);      }    };  }  class MyGestureDetector extends SimpleOnGestureListener {    @Override    public boolean onFling(MotionEvent e1, MotionEvent e2, float velocityX, float velocityY) {      try {        if (Math.abs(e1.getY() - e2.getY()) > SWIPE_MAX_OFF_PATH)          return false;        // right to left swipe        if(e1.getX() - e2.getX() > SWIPE_MIN_DISTANCE && Math.abs(velocityX) > SWIPE_THRESHOLD_VELOCITY) {          Toast.makeText(SelectFilterActivity.this, ""Left Swipe"", Toast.LENGTH_SHORT).show();        } else if (e2.getX() - e1.getX() > SWIPE_MIN_DISTANCE && Math.abs(velocityX) > SWIPE_THRESHOLD_VELOCITY) {          Toast.makeText(SelectFilterActivity.this, ""Right Swipe"", Toast.LENGTH_SHORT).show();        }      } catch (Exception e) {         // nothing      }      return false;    }    @Override    public boolean onDown(MotionEvent e) {      return true;    }  }}Attach your gesture listener to all the views you add to the main layout;// Do this for each view added to the gridimageView.setOnClickListener(SelectFilterActivity.this); imageView.setOnTouchListener(gestureListener);Watch in awe as your overridden methods are hit, both the onClick(View v) of the activity and the onFling of the gesture listener.public void onClick(View v) {  Filter f = (Filter) v.getTag();  FilterFullscreenActivity.show(this, input, f);}The post 'fling' dance is optional but encouraged. "
"data_i","edited Feb 10 '21 at 14:36","
        Selecting element by data attribute with jQuery
    ","Is there an easy and straight-forward method to select elements based on their data attribute?  For example, select all anchors that has data attribute named customerID which has value of 22.  I am kind of hesitant to use rel or other attributes to store such information, but I find it much harder to select an element based on what data is stored in it.","$('*[data-customerID=""22""]');You should be able to omit the *, but if I recall correctly, depending on which jQuery version you’re using, this might give faulty results.Note that for compatibility with the Selectors API (document.querySelector{,all}), the quotes around the attribute value (22) may not be omitted in this case.Also, if you work with data attributes a lot in your jQuery scripts, you might want to consider using the HTML5 custom data attributes plugin. This allows you to write even more readable code by using .dataAttr('foo'), and results in a smaller file size after minification (compared to using .attr('data-foo'))."
"data_i","edited Nov 05 '13 at 16:15","
        Defining a variable with or without export
    ","What is export for?What is the difference between:export name=valueandname=value","export makes the variable available to sub-processes.That is,export name=valuemeans that the variable name is available to any process you run from that shell process. If you want a process to make use of this variable, use export, and run the process from that shell.name=valuemeans the variable scope is restricted to the shell, and is not available to any other process. You would use this for (say) loop variables, temporary variables etc.It's important to note that exporting a variable doesn't make it available to parent processes. That is, specifying and exporting a variable in a spawned process doesn't make it available in the process that launched it."
"data_i","edited Jun 11 '19 at 14:25","
        How to create a checkbox with a clickable label?
    ","How can I create an HTML checkbox with a label that is clickable (this means that clicking on the label turns the checkbox on/off)?","Method 1: Wrap Label TagWrap the checkbox within a label tag:<label><input type=""checkbox"" name=""checkbox"" value=""value"">Text</label>Method 2: Use the for AttributeUse the for attribute (match the checkbox id):<input type=""checkbox"" name=""checkbox"" id=""checkbox_id"" value=""value""><label for=""checkbox_id"">Text</label>NOTE: ID must be unique on the page!ExplanationSince the other answers don't mention it, a label can include up to 1 input and omit the for attribute, and it will be assumed that it is for the input within it.Excerpt from w3.org (with my emphasis):[The for attribute] explicitly associates the label being defined with another control. When present, the value of this attribute must be the same as the value of the id attribute of some other control in the same document. When absent, the label being defined is associated with the element's contents.To associate a label with another control implicitly, the control element must be within the contents of the LABEL element. In this case, the LABEL may only contain one control element. The label itself may be positioned before or after the associated control.Using this method has some advantages over for:No need to assign an id to every checkbox (great!).No need to use the extra attribute in the <label>.The input's clickable area is also the label's clickable area, so there aren't two separate places to click that can control the checkbox - only one, no matter how far apart the <input> and actual label text are, and no matter what kind of CSS you apply to it.Demo with some CSS:label { border:1px solid #ccc; padding:10px; margin:0 0 10px; display:block; }label:hover { background:#eee; cursor:pointer;}<label><input type=""checkbox"" />Option 1</label><label><input type=""checkbox"" />Option 2</label><label><input type=""checkbox"" />Option 3</label>"
"data_i","edited Sep 11 '17 at 14:40","
        git undo all uncommitted or unsaved changes
    ","I'm trying to undo all changes since my last commit. I tried git reset --hard and git reset --hard HEAD after viewing this post. I responds with head is now at 18c3773... but when I look at my local source all the files are still there. What am I missing?","This will unstage all files you might have staged with git add:git resetThis will revert all local uncommitted changes (should be executed in repo root):git checkout .You can also revert uncommitted changes only to particular file or directory:git checkout [some_dir|file.txt]Yet another way to revert all uncommitted changes (longer to type, but works from any subdirectory):git reset --hard HEADThis will remove all local untracked files, so only git tracked files remain:git clean -fdxWARNING: -x  will also remove all ignored files, including ones specified by .gitignore! You may want to use -n for preview of files to be deleted.To sum it up: executing commands below is basically equivalent to fresh git clone from original source (but it does not re-download anything, so is much faster):git resetgit checkout .git clean -fdxTypical usage for this would be in build scripts, when you must make sure that your tree is absolutely clean - does not have any modifications or locally created object files or build artefacts, and you want to make it work very fast and to not re-clone whole repository every single time."
"data_i","edited Dec 16 '20 at 21:19","
        What is the difference between 'typedef' and 'using' in C++11?
    ","I know that in C++11 we can now use using to write type alias, like typedefs:typedef int MyInt;Is, from what I understand, equivalent to:using MyInt = int;And that new syntax emerged from the effort to have a way to express ""template typedef"":template< class T > using MyType = AnotherType< T, MyAllocatorType >;But, with the first two non-template examples, are there any other subtle differences in the standard? For example, typedefs do aliasing in a ""weak"" way. That is it does not create a new type but only a new name (conversions are implicit between those names).Is it the same with using or does it generate a new type? Are there any differences?","They are equivalent, from the standard (emphasis mine) (7.1.3.2):A typedef-name can also be introduced by an alias-declaration. The  identifier following the using keyword becomes a typedef-name and the  optional attribute-specifier-seq following the identifier appertains  to that typedef-name. It has the same semantics as if it were  introduced by the typedef specifier. In particular, it  does not define a new type and it shall not appear in the type-id."
"data_i","edited Oct 13 '11 at 07:38","
        How do I expire a PHP session after 30 minutes?
    ","I need to keep a session alive for 30 minutes and then destroy it. ","You should implement a session timeout of your own. Both options mentioned by others (session.gc_maxlifetime and session.cookie_lifetime) are not reliable. I'll explain the reasons for that.First:session.gc_maxlifetimesession.gc_maxlifetime specifies the number of seconds after which data will be seen as 'garbage' and cleaned up. Garbage collection occurs during session start.But the garbage collector is only started with a probability of session.gc_probability divided by session.gc_divisor. And using the default values for those options (1 and 100 respectively), the chance is only at 1%.Well, you could simply adjust these values so that the garbage collector is started more often. But when the garbage collector is started, it will check the validity for every registered session. And that is cost-intensive.Furthermore, when using PHP's default session.save_handler files, the session data is stored in files in a path specified in session.save_path. With that session handler, the age of the session data is calculated on the file's last modification date and not the last access date:Note: If you are using the default file-based session handler, your filesystem must keep track of access times (atime). Windows FAT does not so you will have to come up with another way to handle garbage collecting your session if you are stuck with a FAT filesystem or any other filesystem where atime tracking is not available. Since PHP 4.2.3 it has used mtime (modified date) instead of atime. So, you won't have problems with filesystems where atime tracking is not available.So it additionally might occur that a session data file is deleted while the session itself is still considered as valid because the session data was not updated recently.And second:session.cookie_lifetimesession.cookie_lifetime specifies the lifetime of the cookie in seconds which is sent to the browser. […]Yes, that's right. This only affects the cookie lifetime and the session itself may still be valid. But it's the server's task to invalidate a session, not the client. So this doesn't help anything. In fact, having session.cookie_lifetime set to 0 would make the session’s cookie a real session cookie that is only valid until the browser is closed.Conclusion / best solution:The best solution is to implement a session timeout of your own. Use a simple time stamp that denotes the time of the last activity (i.e. request) and update it with every request:if (isset($_SESSION['LAST_ACTIVITY']) && (time() - $_SESSION['LAST_ACTIVITY'] > 1800)) {    // last request was more than 30 minutes ago    session_unset();     // unset $_SESSION variable for the run-time     session_destroy();   // destroy session data in storage}$_SESSION['LAST_ACTIVITY'] = time(); // update last activity time stampUpdating the session data with every request also changes the session file's modification date so that the session is not removed by the garbage collector prematurely.You can also use an additional time stamp to regenerate the session ID periodically to avoid attacks on sessions like session fixation:if (!isset($_SESSION['CREATED'])) {    $_SESSION['CREATED'] = time();} else if (time() - $_SESSION['CREATED'] > 1800) {    // session started more than 30 minutes ago    session_regenerate_id(true);    // change session ID for the current session and invalidate old session ID    $_SESSION['CREATED'] = time();  // update creation time}Notes:session.gc_maxlifetime should be at least equal to the lifetime of this custom expiration handler (1800 in this example);if you want to expire the session after 30 minutes of activity instead of after 30 minutes since start, you'll also need to use setcookie with an expire of time()+60*30 to keep the session cookie active."
"data_i","edited Sep 19 '22 at 19:39","
        How do I get the value of text input field using JavaScript?
    ","I am working on a search with JavaScript. I would use a form, but it messes up something else on my page. I have this input text field:<input name=""searchTxt"" type=""text"" maxlength=""512"" id=""searchTxt"" class=""searchField""/>And this is my JavaScript code:<script type=""text/javascript"">  function searchURL(){    window.location = ""http://www.myurl.com/search/"" + (input text value);  }</script>How do I get the value from the text field into JavaScript?","There are various methods to get an input textbox value directly (without wrapping the input element inside a form element):Method 1document.getElementById('textbox_id').value to get the value ofdesired boxFor exampledocument.getElementById(""searchTxt"").value; Note: Method 2,3,4 and 6 returns a collection of elements, so use [whole_number] to get the desired occurrence. For the first element, use [0],for the second one use [1], and so on...Method 2Usedocument.getElementsByClassName('class_name')[whole_number].value which returns a Live HTMLCollectionFor exampledocument.getElementsByClassName(""searchField"")[0].value; if this is the first textbox in your page.Method 3Use document.getElementsByTagName('tag_name')[whole_number].value which also returns a live HTMLCollectionFor exampledocument.getElementsByTagName(""input"")[0].value;, if this is the first textbox in your page.Method 4document.getElementsByName('name')[whole_number].value which also >returns a live NodeListFor exampledocument.getElementsByName(""searchTxt"")[0].value; if this is the first textbox with name 'searchtext' in your page.Method 5Use the powerful document.querySelector('selector').value which uses a CSS selector to select the elementFor exampledocument.querySelector('#searchTxt').value; selected by iddocument.querySelector('.searchField').value; selected by classdocument.querySelector('input').value; selected by tagnamedocument.querySelector('[name=""searchTxt""]').value; selected by nameMethod 6document.querySelectorAll('selector')[whole_number].value which also uses a CSS selector to select elements, but it returns all elements with that selector as a static Nodelist.For exampledocument.querySelectorAll('#searchTxt')[0].value;  selected by iddocument.querySelectorAll('.searchField')[0].value; selected by classdocument.querySelectorAll('input')[0].value;        selected by tagnamedocument.querySelectorAll('[name=""searchTxt""]')[0].value; selected by nameSupportBrowserMethod1Method2Method3Method4Method5/6IE6Y(Buggy)NYY(Buggy)NIE7Y(Buggy)NYY(Buggy)NIE8YNYY(Buggy)YIE9YYYY(Buggy)YIE10YYYYYFF3.0YYYYN    IE=Internet ExplorerFF3.5/FF3.6YYYYY    FF=Mozilla FirefoxFF4b1YYYYY    GC=Google ChromeGC4/GC5YYYYY    Y=YES,N=NOSafari4/Safari5YYYYYOpera10.10/Opera10.53/YYYY(Buggy)YOpera10.60Opera 12YYYYYUseful linksTo see the support of these methods with all the bugs including more details click hereDifference Between Static collections and Live collections click HereDifference Between NodeList and HTMLCollection click Here"
"data_i","edited Apr 10 '22 at 13:02","
        Get difference between two lists
    ","I have two lists in Python:temp1 = ['One', 'Two', 'Three', 'Four']temp2 = ['One', 'Two']I want to create a third list with items from the first list which aren't  in the second list:temp3 = ['Three', 'Four']Are there any fast ways without cycles and checking?","To get elements which are in temp1 but not in temp2 :In [5]: list(set(temp1) - set(temp2))Out[5]: ['Four', 'Three']Beware that it is asymmetric :In [5]: set([1, 2]) - set([2, 3])Out[5]: set([1]) where you might expect/want it to equal set([1, 3]). If you do want set([1, 3]) as your answer, you can use set([1, 2]).symmetric_difference(set([2, 3]))."
"data_i","edited Apr 07 '20 at 22:44","
        Get the data received in a Flask request
    ","I want to be able to get the data sent to my Flask app. I've tried accessing request.data but it is an empty string. How do you access request data?from flask import request@app.route('/', methods=['GET', 'POST'])def parse_request():    data = request.data  # data is empty    # need posted data hereThe answer to this question led me to ask Get raw POST body in Python Flask regardless of Content-Type header next, which is about getting the raw data rather than the parsed data.","The docs describe the attributes available on the request object (from flask import request) during a request. In most common cases request.data will be empty because it's used as a fallback:request.data Contains the incoming request data as string in case it came with a mimetype Flask does not handle.request.args: the key/value pairs in the URL query stringrequest.form: the key/value pairs in the body, from a HTML post form, or JavaScript request that isn't JSON encodedrequest.files: the files in the body, which Flask keeps separate from form. HTML forms must use enctype=multipart/form-data or files will not be uploaded.request.values: combined args and form, preferring args if keys overlaprequest.json: parsed JSON data. The request must have the application/json content type, or use request.get_json(force=True) to ignore the content type.All of these are MultiDict instances (except for json). You can access values using:request.form['name']: use indexing if you know the key existsrequest.form.get('name'): use get if the key might not existrequest.form.getlist('name'): use getlist if the key is sent multiple times and you want a list of values. get only returns the first value."
"data_i","edited Jul 20 '20 at 18:12","
        How to replace innerHTML of a div using jQuery?
    ","How could I achieve the following:document.all.regTitle.innerHTML = 'Hello World';Using jQuery where regTitle is my div id?","$(""#regTitle"").html(""Hello World"");"
"data_i","edited Mar 09 '17 at 17:37","
        What is (functional) reactive programming?
    ","I've read the Wikipedia article on reactive programming. I've also read the small article on functional reactive programming. The descriptions are quite abstract.What does functional reactive programming (FRP) mean in practice? What does reactive programming (as opposed to non-reactive programming?) consist of? My background is in imperative/OO languages, so an explanation that relates to this paradigm would be appreciated.","If you want to get a feel for FRP, you could start with the old Fran tutorial from 1998, which has animated illustrations.  For papers, start with Functional Reactive Animation and then follow up on links on the publications link on my home page and the FRP link on the Haskell wiki.Personally, I like to think about what FRP means before addressing how it might be implemented.(Code without a specification is an answer without a question and thus ""not even wrong"".)So I don't describe FRP in representation/implementation terms as Thomas K does in another answer (graphs, nodes, edges, firing, execution, etc).There are many possible implementation styles, but no implementation says what FRP is.I do resonate with Laurence G's simple description that FRP is about ""datatypes that represent a value 'over time' "".Conventional imperative programming captures these dynamic values only indirectly, through state and mutations.The complete history (past, present, future) has no first class representation.Moreover, only discretely evolving values can be (indirectly) captured, since the imperative paradigm is temporally discrete.In contrast, FRP captures these evolving values directly and has no difficulty with continuously evolving values.FRP is also unusual in that it is concurrent without running afoul of the theoretical & pragmatic rats' nest that plagues imperative concurrency.Semantically, FRP's concurrency is fine-grained, determinate, and continuous.(I'm talking about meaning, not implementation.  An implementation may or may not involve concurrency or parallelism.)Semantic determinacy is very important for reasoning, both rigorous and informal.While concurrency adds enormous complexity to imperative programming (due to nondeterministic interleaving), it is effortless in FRP.So, what is FRP?You could have invented it yourself.Start with these ideas:Dynamic/evolving values (i.e., values ""over time"") are first class values in themselves.  You can define them and combine them, pass them into & out of functions.  I called these things ""behaviors"".Behaviors are built up out of a few primitives, like constant (static) behaviors and time (like a clock), and then with sequential and parallel combination.  n behaviors are combined by applying an n-ary function (on static values), ""point-wise"", i.e., continuously over time.To account for discrete phenomena, have another type (family) of ""events"", each of which has a stream (finite or infinite) of occurrences.  Each occurrence has an associated time and value.To come up with the compositional vocabulary out of which all behaviors and events can be built, play with some examples.  Keep deconstructing into pieces that are more general/simple.So that you know you're on solid ground, give the whole model a compositional foundation, using the technique of denotational semantics, which just means that (a) each type has a corresponding simple & precise mathematical type of ""meanings"", and (b) each primitive and operator has a simple & precise meaning as a function of the meanings of the constituents.Never, ever mix implementation considerations into your exploration process.  If this description is gibberish to you, consult (a) Denotational design with type class morphisms, (b) Push-pull functional reactive programming (ignoring the implementation bits), and (c) the Denotational Semantics Haskell wikibooks page.  Beware that denotational semantics has two parts, from its two founders Christopher Strachey and Dana Scott: the easier & more useful Strachey part and the harder and less useful (for software design) Scott part.If you stick with these principles, I expect you'll get something more-or-less in the spirit of FRP.Where did I get these principles?  In software design, I always ask the same question: ""what does it mean?"".Denotational semantics gave me a precise framework for this question, and one that fits my aesthetics (unlike operational or axiomatic semantics, both of which leave me unsatisfied).So I asked myself what is behavior?I soon realized that the temporally discrete nature of imperative computation is an accommodation to a particular style of machine, rather than a natural description of behavior itself.The simplest precise description of behavior I can think of is simply ""function of (continuous) time"", so that's my model.Delightfully, this model handles continuous, deterministic concurrency with ease and grace.It's been quite a challenge to implement this model correctly and efficiently, but that's another story."
"data_i","edited Dec 10 '17 at 17:10","
        Android ""Only the original thread that created a view hierarchy can touch its views.""
    ","I've built a simple music player in Android. The view for each song contains a SeekBar, implemented like this: public class Song extends Activity implements OnClickListener,Runnable {    private SeekBar progress;    private MediaPlayer mp;    // ...    private ServiceConnection onService = new ServiceConnection() {          public void onServiceConnected(ComponentName className,            IBinder rawBinder) {              appService = ((MPService.LocalBinder)rawBinder).getService(); // service that handles the MediaPlayer              progress.setVisibility(SeekBar.VISIBLE);              progress.setProgress(0);              mp = appService.getMP();              appService.playSong(title);              progress.setMax(mp.getDuration());              new Thread(Song.this).start();          }          public void onServiceDisconnected(ComponentName classname) {              appService = null;          }    };    public void onCreate(Bundle savedInstanceState) {        super.onCreate(savedInstanceState);        setContentView(R.layout.song);        // ...        progress = (SeekBar) findViewById(R.id.progress);        // ...    }    public void run() {    int pos = 0;    int total = mp.getDuration();    while (mp != null && pos<total) {        try {            Thread.sleep(1000);            pos = appService.getSongPosition();        } catch (InterruptedException e) {            return;        } catch (Exception e) {            return;        }        progress.setProgress(pos);    }}This works fine. Now I want a timer counting the seconds/minutes of the progress of the song. So I put a TextView in the layout, get it with findViewById() in onCreate(), and put this in run() after progress.setProgress(pos):String time = String.format(""%d:%d"",            TimeUnit.MILLISECONDS.toMinutes(pos),            TimeUnit.MILLISECONDS.toSeconds(pos),            TimeUnit.MINUTES.toSeconds(TimeUnit.MILLISECONDS.toMinutes(                    pos))            );currentTime.setText(time);  // currentTime = (TextView) findViewById(R.id.current_time);But that last line gives me the exception:android.view.ViewRoot$CalledFromWrongThreadException: Only the original thread that created a view hierarchy can touch its views.Yet I'm doing basically the same thing here as I'm doing with the SeekBar - creating the view in onCreate, then touching it in run() - and it doesn't give me this complaint.","You have to move the portion of the background task that updates the UI onto the main thread. There is a simple piece of code for this:runOnUiThread(new Runnable() {    @Override    public void run() {        // Stuff that updates the UI    }});Documentation for Activity.runOnUiThread.Just nest this inside the method that is running in the background, and then copy paste the code that implements any updates in the middle of the block. Include only the smallest amount of code possible, otherwise you start to defeat the purpose of the background thread."
"data_i","edited Feb 14 '15 at 02:42","
        What is stdClass in PHP?
    ","Please define what stdClass is.","stdClass is just a generic 'empty' class that's used when casting other types to objects. Despite what the other two answers say, stdClass is not the base class for objects in PHP.  This can be demonstrated fairly easily:class Foo{}$foo = new Foo();echo ($foo instanceof stdClass)?'Y':'N';// outputs 'N'I don't believe there's a concept of a base object in PHP"
"data_i","edited Jul 24 '20 at 20:58","
        How to prevent buttons from submitting forms
    ","In the following page, with Firefox the remove button submits the form, but the add button does not.How do I prevent the remove button from submitting the form?function addItem() {  var v = $('form :hidden:last').attr('name');  var n = /(.*)input/.exec(v);  var newPrefix;  if (n[1].length == 0) {    newPrefix = '1';  } else {    newPrefix = parseInt(n[1]) + 1;  }  var oldElem = $('form tr:last');  var newElem = oldElem.clone(true);  var lastHidden = $('form :hidden:last');  lastHidden.val(newPrefix);  var pat = '=\""' + n[1] + 'input';  newElem.html(newElem.html().replace(new RegExp(pat, 'g'), '=\""' + newPrefix + 'input'));  newElem.appendTo('table');  $('form :hidden:last').val('');}function removeItem() {  var rows = $('form tr');  if (rows.length > 2) {    rows[rows.length - 1].html('');    $('form :hidden:last').val('');  } else {    alert('Cannot remove any more rows');  }}<script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/1.3.2/jquery.min.js""></script><html><body>    <form autocomplete=""off"" method=""post"" action="""">        <p>Title:<input type=""text"" /></p>        <button onclick=""addItem(); return false;"">Add Item</button>        <button onclick=""removeItem(); return false;"">Remove Last Item</button>        <table>            <th>Name</th>            <tr>                <td><input type=""text"" id=""input1"" name=""input1"" /></td>                <td><input type=""hidden"" id=""input2"" name=""input2"" /></td>            </tr>        </table>        <input id=""submit"" type=""submit"" name=""submit"" value=""Submit"">    </form></body></html>","You're using an HTML5 button element. Remember the reason is this button has a default behavior of submit, as stated in the W3 specification as seen here:W3C HTML5 ButtonSo you need to specify its type explicitly:<button type=""button"">Button</button>in order to override the default submit type. I just want to point out the reason why this happens."
"data_i","edited Aug 27 '20 at 13:25","
        How can I start PostgreSQL server on Mac OS X?
    ","Final update:I had forgotten to run the initdb command.By running this commandps auxwww | grep postgresI see that postgres is not running> ps auxwww | grep postgresremcat          1789   0.0  0.0  2434892    480 s000  R+   11:28PM   0:00.00 grep postgresThis raises the question:How do I start the PostgreSQL server?Update:> pg_ctl -D /usr/local/var/postgres -l /usr/local/var/postgres/server.log startserver startingsh: /usr/local/var/postgres/server.log: No such file or directoryUpdate 2:The touch was not successful, so I did this instead:> mkdir /usr/local/var/postgres> vi /usr/local/var/postgres/server.log> ls /usr/local/var/postgres/server.logBut when I try to start the Ruby on Rails server, I still see this:Is the server running on host ""localhost"" and acceptingTCP/IP connections on port 5432?Update 3:> pg_ctl -D /usr/local/var/postgres statuspg_ctl: no server runningUpdate 4:I found that there wasn't any pg_hba.conf file (only file pg_hba.conf.sample), so I modified the sample and renamed it (to remover the .sample). Here are the contents: # IPv4 local connections: host    all             all             127.0.0.1/32           trust # IPv6 local connections: host    all             all             ::1/128                trustBut I don't understand this:> pg_ctl -D /usr/local/var/postgres -l /usr/local/var/postgres/server.log startserver starting> pg_ctl -D /usr/local/var/postgres statuspg_ctl: no server runningAlso:sudo find / -name postgresql.conffind: /dev/fd/3: Not a directoryfind: /dev/fd/4: Not a directoryUpdate 5:sudo pg_ctl -D /usr/local/var/postgres -l /usr/local/var/postgres/server.log startPassword:pg_ctl: cannot be run as rootPlease log in (using, e.g., ""su"") as the (unprivileged) user that will own the server process.Update 6:This seems odd:> egrep 'listen|port' /usr/local/var/postgres/postgresql.confegrep: /usr/local/var/postgres/postgresql.conf: No such file or directoryThough, I did do this:>sudo find / -name ""*postgresql.conf*""find: /dev/fd/3: Not a directoryfind: /dev/fd/4: Not a directory/usr/local/Cellar/postgresql/9.0.4/share/postgresql/postgresql.conf.sample/usr/share/postgresql/postgresql.conf.sampleSo I did this:egrep 'listen|port' /usr/local/Cellar/postgresql/9.0.4/share/postgresql/postgresql.conf.sample#listen_addresses = 'localhost'        # what IP address(es) to listen on;#port = 5432                # (change requires restart)                # supported by the operating system:                #   %r = remote host and portSo I tried this:> cp /usr/local/Cellar/postgresql/9.0.4/share/postgresql/postgresql.conf.sample /usr/local/Cellar/postgresql/9.0.4/share/postgresql/postgresql.conf> cp /usr/share/postgresql/postgresql.conf.sample /usr/share/postgresql/postgresql.confI am still getting the same ""Is the server running?"" message.","The Homebrew package manager includes launchctl plists to start automatically. For more information, run brew info postgres.Start manuallypg_ctl -D /usr/local/var/postgres startStop manuallypg_ctl -D /usr/local/var/postgres stopStart automatically""To have launchd start postgresql now and restart at login:""brew services start postgresqlWhat is the result of pg_ctl -D /usr/local/var/postgres -l /usr/local/var/postgres/server.log start?What is the result of pg_ctl -D /usr/local/var/postgres status?Are there any error messages in the server.log?Make sure tcp localhost connections are enabled in pg_hba.conf:# IPv4 local connections:host    all    all    127.0.0.1/32    trustCheck the listen_addresses and port in postgresql.conf:egrep 'listen|port' /usr/local/var/postgres/postgresql.conf#listen_addresses = 'localhost'        # What IP address(es) to listen on;#port = 5432                # (change requires restart)Cleaning upPostgreSQL was most likely installed via Homebrew, Fink, MacPorts or the EnterpriseDB installer.Check the output of the following commands to determine which package manager it was installed with:brew && brew list|grep postgresfink && fink list|grep postgresport && port installed|grep postgres"
"data_i","edited Aug 03 '19 at 17:08","
        Global Git ignore
    ","I want to set up Git to globally ignore certain files.I have added a .gitignore file to my home directory (/Users/me/) and I have added the following line to it:*.tmprojBut it is not ignoring this type of files, any idea what I am doing wrong?","You need to set up your global core.excludesfile configuration file to point to this global ignore file e.g:*nix or Windows git bash:git config --global core.excludesFile '~/.gitignore'Windows cmd:git config --global core.excludesFile ""%USERPROFILE%\.gitignore""Windows PowerShell:git config --global core.excludesFile ""$Env:USERPROFILE\.gitignore""For Windows it is set to the location C:\Users\%username%\.gitignore. You can verify that the config value is correct by doing:git config --global core.excludesFileThe result should be the expanded path to your user profile's .gitignore. Ensure that the value does not contain the unexpanded %USERPROFILE% string.Important: The above commands will only set the location of the ignore file that git will use. The file has to still be manually created in that location and populated with the ignore list. (from muruge's comment)You can read about the command at https://docs.github.com/en/get-started/getting-started-with-git/ignoring-files#configuring-ignored-files-for-all-repositories-on-your-computer"
"data_i","edited Sep 22 '14 at 16:03","
        How can I represent an 'Enum' in Python?
    ","I'm mainly a C# developer, but I'm currently working on a project in Python.How can I represent the equivalent of an Enum in Python?  ","Enums have been added to Python 3.4 as described in PEP 435.  It has also been backported to 3.3, 3.2, 3.1, 2.7, 2.6, 2.5, and 2.4 on pypi.For more advanced Enum techniques try the aenum library (2.7, 3.3+, same author as enum34. Code is not perfectly compatible between py2 and py3, e.g. you'll need __order__ in python 2).To use enum34, do $ pip install enum34To use aenum, do $ pip install aenumInstalling enum (no numbers) will install a completely different and incompatible version.from enum import Enum     # for enum34, or the stdlib version# from aenum import Enum  # for the aenum versionAnimal = Enum('Animal', 'ant bee cat dog')Animal.ant  # returns <Animal.ant: 1>Animal['ant']  # returns <Animal.ant: 1> (string lookup)Animal.ant.name  # returns 'ant' (inverse lookup)or equivalently:class Animal(Enum):    ant = 1    bee = 2    cat = 3    dog = 4In earlier versions, one way of accomplishing enums is:def enum(**enums):    return type('Enum', (), enums)which is used like so:>>> Numbers = enum(ONE=1, TWO=2, THREE='three')>>> Numbers.ONE1>>> Numbers.TWO2>>> Numbers.THREE'three'You can also easily support automatic enumeration with something like this:def enum(*sequential, **named):    enums = dict(zip(sequential, range(len(sequential))), **named)    return type('Enum', (), enums)and used like so:>>> Numbers = enum('ZERO', 'ONE', 'TWO')>>> Numbers.ZERO0>>> Numbers.ONE1Support for converting the values back to names can be added this way:def enum(*sequential, **named):    enums = dict(zip(sequential, range(len(sequential))), **named)    reverse = dict((value, key) for key, value in enums.iteritems())    enums['reverse_mapping'] = reverse    return type('Enum', (), enums)This overwrites anything with that name, but it is useful for rendering your enums in output. It will throw a KeyError if the reverse mapping doesn't exist. With the first example:>>> Numbers.reverse_mapping['three']'THREE'If you are using MyPy another way to express ""enums"" is with typing.Literal.For example:from typing import Literal #python >=3.8from typing_extensions import Literal #python 2.7, 3.4-3.7Animal = Literal['ant', 'bee', 'cat', 'dog']def hello_animal(animal: Animal):    print(f""hello {animal}"")hello_animal('rock') # errorhello_animal('bee') # passes"
"data_i","edited Jun 13 '19 at 09:59","
        How do I pass environment variables to Docker containers?
    ","I'm new to Docker, and it's unclear how to access an external database from a container. Is the best way to hard-code in the connection string?# DockerfileENV DATABASE_URL amazon:rds/connection?string","You can pass environment variables to your containers with the -e flag.An example from a startup script:sudo docker run -d -t -i -e REDIS_NAMESPACE='staging' \ -e POSTGRES_ENV_POSTGRES_PASSWORD='foo' \-e POSTGRES_ENV_POSTGRES_USER='bar' \-e POSTGRES_ENV_DB_NAME='mysite_staging' \-e POSTGRES_PORT_5432_TCP_ADDR='docker-db-1.hidden.us-east-1.rds.amazonaws.com' \-e SITE_URL='staging.mysite.com' \-p 80:80 \--link redis:redis \  --name container_name dockerhub_id/image_nameOr, if you don't want to have the value on the command-line where it will be displayed by ps, etc., -e can pull in the value from the current environment if you just give it without the =:sudo PASSWORD='foo' docker run  [...] -e PASSWORD [...]If you have many environment variables and especially if they're meant to be secret, you can use an env-file:$ docker run --env-file ./env.list ubuntu bashThe --env-file flag takes a filename as an argument and expects each line to be in the VAR=VAL format, mimicking the argument passed to --env. Comment lines need only be prefixed with #"
"data_i","edited Jun 08 '17 at 08:47","
        Including all the jars in a directory within the Java classpath
    ","Is there a way to include all the jar files within a directory in the classpath?I'm trying java -classpath lib/*.jar:. my.package.Program and it is not able to find class files that are certainly in those jars.  Do I need to add each jar file to the classpath separately? ","Using Java 6 or later, the classpath option supports wildcards. Note the following:Use straight quotes ("")Use *, not *.jarWindowsjava -cp ""Test.jar;lib/*"" my.package.MainClassUnixjava -cp ""Test.jar:lib/*"" my.package.MainClassThis is similar to Windows, but uses : instead of ;. If you cannot use wildcards, bash allows the following syntax (where lib is the directory containing all the Java archive files):java -cp ""$(printf %s: lib/*.jar)""(Note that using a classpath is incompatible with the -jar option. See also: Execute jar file with multiple classpath libraries from command prompt)Understanding WildcardsFrom the Classpath document:Class path entries can contain the basename wildcard character *, which is considered equivalent to specifying a list of all the filesin the directory with the extension .jar or .JAR. For example, theclass path entry foo/* specifies all JAR files in the directory namedfoo. A classpath entry consisting simply of * expands to a list of allthe jar files in the current directory.A class path entry that contains * will not match class files. Tomatch both classes and JAR files in a single directory foo, use eitherfoo;foo/* or foo/*;foo. The order chosen determines whether theclasses and resources in foo are loaded before JAR files in foo, orvice versa.Subdirectories are not searched recursively. For example, foo/* looksfor JAR files only in foo, not in foo/bar, foo/baz, etc.The order in which the JAR files in a directory are enumerated in theexpanded class path is not specified and may vary from platform toplatform and even from moment to moment on the same machine. Awell-constructed application should not depend upon any particularorder. If a specific order is required then the JAR files can beenumerated explicitly in the class path.Expansion of wildcards is done early, prior to the invocation of aprogram's main method, rather than late, during the class-loadingprocess itself. Each element of the input class path containing awildcard is replaced by the (possibly empty) sequence of elementsgenerated by enumerating the JAR files in the named directory. Forexample, if the directory foo contains a.jar, b.jar, and c.jar, thenthe class path foo/* is expanded into foo/a.jar;foo/b.jar;foo/c.jar,and that string would be the value of the system propertyjava.class.path.The CLASSPATH environment variable is not treated any differently fromthe -classpath (or -cp) command-line option. That is, wildcards arehonored in all these cases. However, class path wildcards are nothonored in the Class-Path jar-manifest header.Note: due to a known bug in java 8, the windows examples must use a backslash preceding entries with a trailing asterisk: https://bugs.openjdk.java.net/browse/JDK-8131329"
"data_i","edited Sep 17 '22 at 12:33","
        Propagate all arguments in a Bash shell script
    ","I am writing a very simple script that calls another script, and I need to propagate the parameters from my current script to the script I am executing.For instance, my script name is foo.sh and calls bar.sh.foo.sh:bar $1 $2 $3 $4How can I do this without explicitly specifying each parameter?","Use ""$@"" instead of plain $@ if you actually wish your parameters to be passed the same.Observe:$ cat no_quotes.sh#!/bin/bashecho_args.sh $@$ cat quotes.sh#!/bin/bashecho_args.sh ""$@""$ cat echo_args.sh#!/bin/bashecho Received: $1echo Received: $2echo Received: $3echo Received: $4$ ./no_quotes.sh first secondReceived: firstReceived: secondReceived:Received:$ ./no_quotes.sh ""one quoted arg""Received: oneReceived: quotedReceived: argReceived:$ ./quotes.sh first secondReceived: firstReceived: secondReceived:Received:$ ./quotes.sh ""one quoted arg""Received: one quoted argReceived:Received:Received:"
"data_i","edited Sep 20 '20 at 06:45","
        What is the difference between --save and --save-dev?
    ","What is the difference between:npm install [package_name]and:npm install [package_name] --saveand:npm install [package_name] --save-devWhat does this mean? And what is really the effect of --save and -dev keywords?","The difference between --save and --save-dev may not be immediately noticeable if you have tried them both on your own projects. So here are a few examples...Let's say you were building an app that used the moment package to parse and display dates. Your app is a scheduler so it really needs this package to run, as in: cannot run without it. In this case you would usenpm install moment --saveThis would create a new value in your package.json""dependencies"": {   ...   ""moment"": ""^2.17.1""}When you are developing, it really helps to use tools such as test suites and may need jasmine-core and karma. In this case you would usenpm install jasmine-core --save-devnpm install karma --save-devThis would also create a new value in your package.json""devDependencies"": {    ...    ""jasmine-core"": ""^2.5.2"",    ""karma"": ""^1.4.1"",}You do not need the test suite to run the app in its normal state, so it is a --save-dev type dependency, nothing more. You can see how if you do not understand what is really happening, it is a bit hard to imagine.Taken directly from NPM docs docs#dependenciesDependenciesDependencies are specified in a simple object that maps a package nameto a version range. The version range is a string that has one ormore space-separated descriptors. Dependencies can also be identifiedwith a tarball or git URL.Please do not put test harnesses or transpilers in your dependenciesobject. See devDependencies, below.Even in the docs, it asks you to use --save-dev for modules such as test harnesses."
"data_i","edited Sep 10 '16 at 03:36","
        How are zlib, gzip and zip related? What do they have in common and how are they different?
    ","The compression algorithm used in zlib is essentially the same as that in gzip and zip. What are gzip and zip? How are they different and how are they same?","Short form:.zip is an archive format using, usually, the Deflate compression method.  The .gz gzip format is for single files, also using the Deflate compression method.  Often gzip is used in combination with tar to make a compressed archive format, .tar.gz.  The zlib library provides Deflate compression and decompression code for use by zip, gzip, png (which uses the zlib wrapper on deflate data), and many other applications.Long form:The ZIP format was developed by Phil Katz as an open format with an open specification, where his implementation, PKZIP, was shareware.  It is an archive format that stores files and their directory structure, where each file is individually compressed.  The file type is .zip.  The files, as well as the directory structure, can optionally be encrypted.The ZIP format supports several compression methods:    0 - The file is stored (no compression)    1 - The file is Shrunk    2 - The file is Reduced with compression factor 1    3 - The file is Reduced with compression factor 2    4 - The file is Reduced with compression factor 3    5 - The file is Reduced with compression factor 4    6 - The file is Imploded    7 - Reserved for Tokenizing compression algorithm    8 - The file is Deflated    9 - Enhanced Deflating using Deflate64(tm)   10 - PKWARE Data Compression Library Imploding (old IBM TERSE)   11 - Reserved by PKWARE   12 - File is compressed using BZIP2 algorithm   13 - Reserved by PKWARE   14 - LZMA   15 - Reserved by PKWARE   16 - IBM z/OS CMPSC Compression   17 - Reserved by PKWARE   18 - File is compressed using IBM TERSE (new)   19 - IBM LZ77 z Architecture    20 - deprecated (use method 93 for zstd)   93 - Zstandard (zstd) Compression    94 - MP3 Compression    95 - XZ Compression    96 - JPEG variant   97 - WavPack compressed data   98 - PPMd version I, Rev 1   99 - AE-x encryption marker (see APPENDIX E)Methods 1 to 7 are historical and are not in use.  Methods 9 through 98 are relatively recent additions and are in varying, small amounts of use.  The only method in truly widespread use in the ZIP format is method 8, Deflate, and to some smaller extent method 0, which is no compression at all.  Virtually every .zip file that you will come across in the wild will use exclusively methods 8 and 0, likely just method 8.  (Method 8 also has a means to effectively store the data with no compression and relatively little expansion, and Method 0 cannot be streamed whereas Method 8 can be.)The ISO/IEC 21320-1:2015 standard for file containers is a restricted zip format, such as used in Java archive files (.jar), Office Open XML files (Microsoft Office .docx, .xlsx, .pptx), Office Document Format files (.odt, .ods, .odp), and EPUB files (.epub). That standard limits the compression methods to 0 and 8, as well as other constraints such as no encryption or signatures.Around 1990, the Info-ZIP group wrote portable, free, open-source implementations of zip and unzip utilities, supporting compression with the Deflate format, and decompression of that and the earlier formats.  This greatly expanded the use of the .zip format.In the early '90s, the gzip format was developed as a replacement for the Unix compress utility, derived from the Deflate code in the Info-ZIP utilities.  Unix compress was designed to compress a single file or stream, appending a .Z to the file name.  compress uses the LZW compression algorithm, which at the time was under patent and its free use was in dispute by the patent holders.  Though some specific implementations of Deflate were patented by Phil Katz, the format was not, and so it was possible to write a Deflate implementation that did not infringe on any patents.  That implementation has not been so challenged in the last 20+ years.  The Unix gzip utility was intended as a drop-in replacement for compress, and in fact is able to decompress compress-compressed data (assuming that you were able to parse that sentence).  gzip appends a .gz to the file name.  gzip uses the Deflate compressed data format, which compresses quite a bit better than Unix compress, has very fast decompression, and adds a CRC-32 as an integrity check for the data.  The header format also permits the storage of more information than the compress format allowed, such as the original file name and the file modification time.Though compress only compresses a single file, it was common to use the tar utility to create an archive of files, their attributes, and their directory structure into a single .tar file, and to then compress it with compress to make a .tar.Z file.  In fact, the tar utility had and still has an option to do the compression at the same time, instead of having to pipe the output of tar to compress.  This all carried forward to the gzip format, and tar has an option to compress directly to the .tar.gz format.  The tar.gz format compresses better than the .zip approach, since the compression of a .tar can take advantage of redundancy across files, especially many small files.  .tar.gz is the most common archive format in use on Unix due to its very high portability, but there are more effective compression methods in use as well, so you will often see .tar.bz2 and .tar.xz archives.Unlike .tar, .zip has a central directory at the end, which provides a list of the contents. That and the separate compression provides random access to the individual entries in a .zip file. A .tar file would have to be decompressed and scanned from start to end in order to build a directory, which is how a .tar file is listed.Shortly after the introduction of gzip, around the mid-1990s, the same patent dispute called into question the free use of the .gif image format, very widely used on bulletin boards and the World Wide Web (a new thing at the time).  So a small group created the PNG losslessly compressed image format, with file type .png, to replace .gif.  That format also uses the Deflate format for compression, which is applied after filters on the image data expose more of the redundancy.  In order to promote widespread usage of the PNG format, two free code libraries were created.  libpng and zlib.  libpng handled all of the features of the PNG format, and zlib provided the compression and decompression code for use by libpng, as well as for other applications.  zlib was adapted from the gzip code.All of the mentioned patents have since expired.The zlib library supports Deflate compression and decompression, and three kinds of wrapping around the deflate streams.  Those are: no wrapping at all (""raw"" deflate), zlib wrapping, which is used in the PNG format data blocks, and gzip wrapping, to provide gzip routines for the programmer.  The main difference between zlib and gzip wrapping is that the zlib wrapping is more compact, six bytes vs. a minimum of 18 bytes for gzip, and the integrity check, Adler-32, runs faster than the CRC-32 that gzip uses.  Raw deflate is used by programs that read and write the .zip format, which is another format that wraps around deflate compressed data.zlib is now in wide use for data transmission and storage.  For example, most HTTP transactions by servers and browsers compress and decompress the data using zlib, specifically HTTP header Content-Encoding: deflate means deflate compression method wrapped inside the zlib data format.Different implementations of deflate can result in different compressed output for the same input data, as evidenced by the existence of selectable compression levels that allow trading off compression effectiveness for CPU time. zlib and PKZIP are not the only implementations of deflate compression and decompression. Both the 7-Zip archiving utility and Google's zopfli library have the ability to use much more CPU time than zlib in order to squeeze out the last few bits possible when using the deflate format, reducing compressed sizes by a few percent as compared to zlib's highest compression level. The pigz utility, a parallel implementation of gzip, includes the option to use zlib (compression levels 1-9) or zopfli (compression level 11), and somewhat mitigates the time impact of using zopfli by splitting the compression of large files over multiple processors and cores."
"data_i","edited Jul 21 '18 at 05:32","
        Can a local variable's memory be accessed outside its scope?
    ","I have the following code.#include <iostream>int * foo(){    int a = 5;    return &a;}int main(){    int* p = foo();    std::cout << *p;    *p = 8;    std::cout << *p;}And the code is just running with no runtime exceptions!The output was 58How can it be? Isn't the memory of a local variable inaccessible outside its function?","How can it be? Isn't the memory of a local variable inaccessible outside its function?You rent a hotel room. You put a book in the top drawer of the bedside table and go to sleep.  You check out the next morning, but ""forget"" to give back your key. You steal the key!A week later, you return to the hotel, do not check in, sneak into your old room with your stolen key, and look in the drawer. Your book is still there. Astonishing!How can that be? Aren't the contents of a hotel room drawer inaccessible if you haven't rented the room?Well, obviously that scenario can happen in the real world no problem. There is no mysterious force that causes your book to disappear when you are no longer authorized to be in the room. Nor is there a mysterious force that prevents you from entering a room with a stolen key.The hotel management is not required to remove your book. You didn't make a contract with them that said that if you leave stuff behind, they'll shred it for you. If you illegally re-enter your room with a stolen key to get it back, the hotel security staff is not required to catch you sneaking in. You didn't make a contract with them that said ""if I try to sneak back into my room later, you are required to stop me."" Rather, you signed a contract with them that said ""I promise not to sneak back into my room later"", a contract which you broke.In this situation anything can happen. The book can be there -- you got lucky. Someone else's book can be there and yours could be in the hotel's furnace. Someone could be there right when you come in, tearing your book to pieces. The hotel could have removed the table and book entirely and replaced it with a wardrobe. The entire hotel could be just about to be torn down and replaced with a football stadium, and you are going to die in an explosion while you are sneaking around. You don't know what is going to happen; when you checked out of the hotel and stole a key to illegally use later, you gave up the right to live in a predictable, safe world because you chose to break the rules of the system.C++ is not a safe language. It will cheerfully allow you to break the rules of the system. If you try to do something illegal and foolish like going back into a room you're not authorized to be in and rummaging through a desk that might not even be there anymore, C++ is not going to stop you. Safer languages than C++ solve this problem by restricting your power -- by having much stricter control over keys, for example.UPDATEHoly goodness, this answer is getting a lot of attention. (I'm not sure why -- I considered it to be just a ""fun"" little analogy, but whatever.)I thought it might be germane to update this a bit with a few more technical thoughts.Compilers are in the business of generating code which manages the storage of the data manipulated by that program. There are lots of different ways of generating code to manage memory, but over time two basic techniques have become entrenched. The first is to have some sort of ""long lived"" storage area where the ""lifetime"" of each byte in the storage -- that is, the period of time when it is validly associated with some program variable -- cannot be easily predicted ahead of time. The compiler generates calls into a ""heap manager"" that knows how to dynamically allocate storage when it is needed and reclaim it when it is no longer needed.The second method is to have a “short-lived” storage area where the lifetime of each byte is well known. Here, the lifetimes follow a “nesting” pattern. The longest-lived of these short-lived variables will be allocated before any other short-lived variables, and will be freed last. Shorter-lived variables will be allocated after the longest-lived ones, and will be freed before them. The lifetime of these shorter-lived variables is “nested” within the lifetime of longer-lived ones.Local variables follow the latter pattern; when a method is entered, its local variables come alive. When that method calls another method, the new method's local variables come alive. They'll be dead before the first method's local variables are dead.  The relative order of the beginnings and endings of lifetimes of storages associated with local variables can be worked out ahead of time.For this reason, local variables are usually generated as storage on a ""stack"" data structure, because a stack has the property that the first thing pushed on it is going to be the last thing popped off. It's like the hotel decides to only rent out rooms sequentially, and you can't check out until everyone with a room number higher than you has checked out. So let's think about the stack. In many operating systems you get one stack per thread and the stack is allocated to be a certain fixed size. When you call a method, stuff is pushed onto the stack. If you then pass a pointer to the stack back out of your method, as the original poster does here, that's just a pointer to the middle of some entirely valid million-byte memory block. In our analogy, you check out of the hotel; when you do, you just checked out of the highest-numbered occupied room.  If no one else checks in after you, and you go back to your room illegally, all your stuff is guaranteed to still be there in this particular hotel.We use stacks for temporary stores because they are really cheap and easy. An implementation of C++ is not required to use a stack for storage of locals; it could use the heap. It doesn't, because that would make the program slower. An implementation of C++ is not required to leave the garbage you left on the stack untouched so that you can come back for it later illegally; it is perfectly legal for the compiler to generate code that turns back to zero everything in the ""room"" that you just vacated. It doesn't because again, that would be expensive.An implementation of C++ is not required to ensure that when the stack logically shrinks, the addresses that used to be valid are still mapped into memory. The implementation is allowed to tell the operating system ""we're done using this page of stack now. Until I say otherwise, issue an exception that destroys the process if anyone touches the previously-valid stack page"".  Again, implementations do not actually do that because it is slow and unnecessary.Instead, implementations let you make mistakes and get away with it. Most of the time. Until one day something truly awful goes wrong and the process explodes.This is problematic. There are a lot of rules and it is very easy to break them accidentally. I certainly have many times. And worse, the problem often only surfaces when memory is detected to be corrupt billions of nanoseconds after the corruption happened, when it is very hard to figure out who messed it up.More memory-safe languages solve this problem by restricting your power. In ""normal"" C# there simply is no way to take the address of a local and return it or store it for later. You can take the address of a local, but the language is cleverly designed so that it is impossible to use it after the lifetime of the local ends. In order to take the address of a local and pass it back, you have to put the compiler in a special ""unsafe"" mode, and put the word ""unsafe"" in your program, to call attention to the fact that you are probably doing something dangerous that could be breaking the rules. For further reading:What if C# did allow returning references? Coincidentally that is the subject of today's blog post:https://ericlippert.com/2011/06/23/ref-returns-and-ref-locals/Why do we use stacks to manage memory? Are value types in C# always stored on the stack? How does virtual memory work? And many more topics in how the C# memory manager works. Many of these articles are also germane to C++ programmers:https://ericlippert.com/tag/memory-management/"
"data_i","edited Apr 10 '22 at 11:02","
        Is there a simple way to delete a list element by value?
    ","I want to remove a value from a list if it exists in the list (which it may not).a = [1, 2, 3, 4]b = a.index(6)del a[b]print(a)The above gives the error:ValueError: list.index(x): x not in listSo I have to do this:a = [1, 2, 3, 4]try:    b = a.index(6)    del a[b]except:    passprint(a)But is there not a simpler way to do this?","To remove the first occurrence of an element, use list.remove:>>> xs = ['a', 'b', 'c', 'd']>>> xs.remove('b')>>> print(xs)['a', 'c', 'd']To remove all occurrences of an element, use a list comprehension:>>> xs = ['a', 'b', 'c', 'd', 'b', 'b', 'b', 'b']>>> xs = [x for x in xs if x != 'b']>>> print(xs)['a', 'c', 'd']"
"data_i","edited May 14 '20 at 13:09","
        Converting an object to a string
    ","How can I convert a JavaScript object into a string?Example:var o = {a:1, b:2}console.log(o)console.log('Item: ' + o)Output:Object { a=1, b=2} // very nice readable output :)  Item: [object Object] // no idea what's inside :(","I would recommend using JSON.stringify, which converts the set of the variables in the object to a JSON string.var obj = {  name: 'myObj'};JSON.stringify(obj);Most modern browsers support this method natively, but for those that don't, you can include a JS version."
"data_i","edited Jan 24 '16 at 19:34","
        endsWith in JavaScript
    ","How can I check if a string ends with a particular character in JavaScript?Example: I have a string var str = ""mystring#"";I want to know if that string is ending with #. How can I check it?Is there a endsWith() method in JavaScript?One solution I have is take the length of the string and get the last character and check it.Is this the best way or there is any other way?","UPDATE (Nov 24th, 2015):This answer is originally posted in the year 2010 (SIX years back.) so please take note of these insightful comments:Shauna -Update for Googlers - Looks like ECMA6 adds this function. The MDN article also shows a polyfill. https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/endsWithT.J. Crowder -Creating substrings isn't expensive on modern browsers; it may well have been in 2010 when this answer was posted. These days, the simple this.substr(-suffix.length) === suffix approach is fastest on Chrome, the same on IE11 as indexOf, and only 4% slower (fergetaboutit territory) on Firefox: https://jsben.ch/OJzlM And faster across the board when the result is false: jsperf.com/endswith-stackoverflow-when-false Of course, with ES6 adding endsWith, the point is moot. :-)ORIGINAL ANSWER:I know this is a year old question... but I need this too and I need it to work cross-browser so... combining everyone's answer and comments and simplifying it a bit:String.prototype.endsWith = function(suffix) {    return this.indexOf(suffix, this.length - suffix.length) !== -1;};Doesn't create a substringUses native indexOf function for fastest resultsSkip unnecessary comparisons using the second parameter of indexOf to skip aheadWorks in Internet ExplorerNO Regex complicationsAlso, if you don't like stuffing things in native data structure's prototypes, here's a standalone version:function endsWith(str, suffix) {    return str.indexOf(suffix, str.length - suffix.length) !== -1;}EDIT: As noted by @hamish in the comments, if you want to err on the safe side and check if an implementation has already been provided, you can just adds a typeof check like so:if (typeof String.prototype.endsWith !== 'function') {    String.prototype.endsWith = function(suffix) {        return this.indexOf(suffix, this.length - suffix.length) !== -1;    };}"
"data_i","edited Jun 16 '20 at 04:35","
        Getting a random value from a JavaScript array
    ","Consider:var myArray = ['January', 'February', 'March'];    How can I select a random value from this array using JavaScript?","It's a simple one-liner:const randomElement = array[Math.floor(Math.random() * array.length)];For example:const months = [""January"", ""February"", ""March"", ""April"", ""May"", ""June"", ""July""];const random = Math.floor(Math.random() * months.length);console.log(random, months[random]);"
"data_i","edited Oct 21 '19 at 10:41","
        How to mock void methods with Mockito
    ","How to mock methods with void return type? I implemented an observer pattern but I can't mock it with Mockito because I don't know how.And I tried to find an example on the Internet but didn't succeed.My class looks like this:public class World {    List<Listener> listeners;    void addListener(Listener item) {        listeners.add(item);    }    void doAction(Action goal,Object obj) {        setState(""i received"");        goal.doAction(obj);        setState(""i finished"");    }    private string state;    //setter getter state} public class WorldTest implements Listener {    @Test public void word{    World  w= mock(World.class);    w.addListener(this);    ...    ...    }}interface Listener {    void doAction();}The system is not triggered with mock.I want to show the above-mentioned system state. And make assertions according to them.","Take a look at the Mockito API docs. As the linked document mentions (Point # 12) you can use any of the doThrow(),doAnswer(),doNothing(),doReturn() family of methods from Mockito framework to mock void methods.For example,Mockito.doThrow(new Exception()).when(instance).methodName();or if you want to combine it with follow-up behavior,Mockito.doThrow(new Exception()).doNothing().when(instance).methodName();Presuming that you are looking at mocking the setter setState(String s) in the class World below is the code uses doAnswer method to mock the setState.World mockWorld = mock(World.class); doAnswer(new Answer<Void>() {    public Void answer(InvocationOnMock invocation) {      Object[] args = invocation.getArguments();      System.out.println(""called with arguments: "" + Arrays.toString(args));      return null;    }}).when(mockWorld).setState(anyString());"
"data_i","edited Oct 08 '20 at 18:40","
        How to use Git and Dropbox together?
    ","Is it possible to use Git and Dropbox together?","I think that Git on Dropbox is great. I use it all the time. I have multiple computers (two at home and one at work) on which I use Dropbox as a central bare repository. Since I don’t want to host it on a public service, and I don’t have access to a server that I can always SSH to, Dropbox takes care of this by syncing in the background (very doing so quickly).Setup is something like this:~/project $ git init~/project $ git add .~/project $ git commit -m ""first commit""~/project $ cd ~/Dropbox/git~/Dropbox/git $ git init --bare project.git~/Dropbox/git $ cd ~/project~/project $ git remote add origin ~/Dropbox/git/project.git~/project $ git push -u origin masterFrom there, you can just clone that ~/Dropbox/git/project.git directory (regardless of whether it belongs to your Dropbox account or is shared across multiple accounts) and do all the normal Git operations—they will be synchronized to all your other machines automatically.I wrote a blog post “On Version Control” in which I cover the reasoning behind my environment setup. It’s based on my Ruby on Rails development experience, but it can be applied to anything, really."
"data_i","edited Sep 04 '18 at 02:54","
        Colors in JavaScript console
    ","Can Chrome's built-in JavaScript console display colors?I want errors in red, warnings in orange and console.log's in green. Is that possible?","In Chrome & Firefox (+31) you can add CSS in console.log messages:console.log('%c Oh my heavens! ', 'background: #222; color: #bada55');The same can be applied for adding multiple CSS to same command.ReferencesMDN: Styling console outputChrome: Console API Reference"
"data_i","edited Nov 27 '21 at 23:49","
        What are the most common Python docstring formats?
    ","I have seen a few different styles of writing docstrings in Python, what are the most popular styles?","FormatsPython docstrings can be written following several formats as the other posts showed. However the default Sphinx docstring format was not mentioned and is based on reStructuredText (reST). You can get some information about the main formats in this blog post.Note that the reST is recommended by the PEP 287There follows the main used formats for docstrings.- EpytextHistorically a javadoc like style was prevalent, so it was taken as a base for Epydoc (with the called Epytext format) to generate documentation.Example:""""""This is a javadoc style.@param param1: this is a first param@param param2: this is a second param@return: this is a description of what is returned@raise keyError: raises an exception""""""- reSTNowadays, the probably more prevalent format is the reStructuredText (reST) format that is used by Sphinx to generate documentation.Note: it is used by default in JetBrains PyCharm (type triple quotes after defining a method and hit enter). It is also used by default as output format in Pyment.Example:""""""This is a reST style.:param param1: this is a first param:param param2: this is a second param:returns: this is a description of what is returned:raises keyError: raises an exception""""""- GoogleGoogle has their own format that is often used. It also can be interpreted by Sphinx (ie. using Napoleon plugin). Example:""""""This is an example of Google style.Args:    param1: This is the first param.    param2: This is a second param.Returns:    This is a description of what is returned.Raises:    KeyError: Raises an exception.""""""Even more examples- NumpydocNote that Numpy recommend to follow their own numpydoc based on Google format and usable by Sphinx.""""""My numpydoc description of a kindof very exhautive numpydoc format docstring.Parameters----------first : array_like    the 1st param name `first`second :    the 2nd paramthird : {'value', 'other'}, optional    the 3rd param, by default 'value'Returns-------string    a value in a stringRaises------KeyError    when a key errorOtherError    when an other error""""""Converting/GeneratingIt is possible to use a tool like Pyment to automatically generate docstrings to a Python project not yet documented, or to convert existing docstrings (can be mixing several formats) from a format to an other one.Note: The examples are taken from the Pyment documentation"
"data_i","edited Aug 13 '21 at 19:42","
        Deserialize JSON into C# dynamic object?
    ","Is there a way to deserialize JSON content into a C# dynamic type? It would be nice to skip creating a bunch of classes in order to use the DataContractJsonSerializer.","If you are happy to have a dependency upon the System.Web.Helpers assembly, then you can use the Json class:dynamic data = Json.Decode(json);It is included with the MVC framework as an additional download to the .NET 4 framework. Be sure to give Vlad an upvote if that's helpful! However if you cannot assume the client environment includes this DLL, then read on.An alternative deserialisation approach is suggested here.  I modified the code slightly to fix a bug and suit my coding style.  All you need is this code and a reference to System.Web.Extensions from your project:using System;using System.Collections;using System.Collections.Generic;using System.Collections.ObjectModel;using System.Dynamic;using System.Linq;using System.Text;using System.Web.Script.Serialization;public sealed class DynamicJsonConverter : JavaScriptConverter{    public override object Deserialize(IDictionary<string, object> dictionary, Type type, JavaScriptSerializer serializer)    {        if (dictionary == null)            throw new ArgumentNullException(""dictionary"");        return type == typeof(object) ? new DynamicJsonObject(dictionary) : null;    }    public override IDictionary<string, object> Serialize(object obj, JavaScriptSerializer serializer)    {        throw new NotImplementedException();    }    public override IEnumerable<Type> SupportedTypes    {        get { return new ReadOnlyCollection<Type>(new List<Type>(new[] { typeof(object) })); }    }    #region Nested type: DynamicJsonObject    private sealed class DynamicJsonObject : DynamicObject    {        private readonly IDictionary<string, object> _dictionary;        public DynamicJsonObject(IDictionary<string, object> dictionary)        {            if (dictionary == null)                throw new ArgumentNullException(""dictionary"");            _dictionary = dictionary;        }        public override string ToString()        {            var sb = new StringBuilder(""{"");            ToString(sb);            return sb.ToString();        }        private void ToString(StringBuilder sb)        {            var firstInDictionary = true;            foreach (var pair in _dictionary)            {                if (!firstInDictionary)                    sb.Append("","");                firstInDictionary = false;                var value = pair.Value;                var name = pair.Key;                if (value is string)                {                    sb.AppendFormat(""{0}:\""{1}\"""", name, value);                }                else if (value is IDictionary<string, object>)                {                    new DynamicJsonObject((IDictionary<string, object>)value).ToString(sb);                }                else if (value is ArrayList)                {                    sb.Append(name + "":["");                    var firstInArray = true;                    foreach (var arrayValue in (ArrayList)value)                    {                        if (!firstInArray)                            sb.Append("","");                        firstInArray = false;                        if (arrayValue is IDictionary<string, object>)                            new DynamicJsonObject((IDictionary<string, object>)arrayValue).ToString(sb);                        else if (arrayValue is string)                            sb.AppendFormat(""\""{0}\"""", arrayValue);                        else                            sb.AppendFormat(""{0}"", arrayValue);                    }                    sb.Append(""]"");                }                else                {                    sb.AppendFormat(""{0}:{1}"", name, value);                }            }            sb.Append(""}"");        }        public override bool TryGetMember(GetMemberBinder binder, out object result)        {            if (!_dictionary.TryGetValue(binder.Name, out result))            {                // return null to avoid exception.  caller can check for null this way...                result = null;                return true;            }            result = WrapResultObject(result);            return true;        }        public override bool TryGetIndex(GetIndexBinder binder, object[] indexes, out object result)        {            if (indexes.Length == 1 && indexes[0] != null)            {                if (!_dictionary.TryGetValue(indexes[0].ToString(), out result))                {                    // return null to avoid exception.  caller can check for null this way...                    result = null;                    return true;                }                result = WrapResultObject(result);                return true;            }            return base.TryGetIndex(binder, indexes, out result);        }        private static object WrapResultObject(object result)        {            var dictionary = result as IDictionary<string, object>;            if (dictionary != null)                return new DynamicJsonObject(dictionary);            var arrayList = result as ArrayList;            if (arrayList != null && arrayList.Count > 0)            {                return arrayList[0] is IDictionary<string, object>                     ? new List<object>(arrayList.Cast<IDictionary<string, object>>().Select(x => new DynamicJsonObject(x)))                     : new List<object>(arrayList.Cast<object>());            }            return result;        }    }    #endregion}You can use it like this:string json = ...;var serializer = new JavaScriptSerializer();serializer.RegisterConverters(new[] { new DynamicJsonConverter() });dynamic obj = serializer.Deserialize(json, typeof(object));So, given a JSON string:{  ""Items"":[    { ""Name"":""Apple"", ""Price"":12.3 },    { ""Name"":""Grape"", ""Price"":3.21 }  ],  ""Date"":""21/11/2010""}The following code will work at runtime:dynamic data = serializer.Deserialize(json, typeof(object));data.Date; // ""21/11/2010""data.Items.Count; // 2data.Items[0].Name; // ""Apple""data.Items[0].Price; // 12.3 (as a decimal)data.Items[1].Name; // ""Grape""data.Items[1].Price; // 3.21 (as a decimal)"
"data_i","edited Apr 09 '22 at 10:35","
        How to parse XML and get instances of a particular node attribute?
    ","I have many rows in XML and I'm trying to get instances of a particular node attribute.<foo>   <bar>      <type foobar=""1""/>      <type foobar=""2""/>   </bar></foo>How do I access the values of the attribute foobar? In this example, I want ""1"" and ""2"".","I suggest ElementTree.  There are other compatible implementations of the same API, such as lxml, and cElementTree in the Python standard library itself; but, in this context, what they chiefly add is even more speed -- the ease of programming part depends on the API, which ElementTree defines.First build an Element instance root from the XML, e.g. with the XML function, or by parsing a file with something like:import xml.etree.ElementTree as ETroot = ET.parse('thefile.xml').getroot()Or any of the many other ways shown at ElementTree. Then do something like:for type_tag in root.findall('bar/type'):    value = type_tag.get('foobar')    print(value)Output:12"
"data_i","asked Nov 25 '11 at 13:51","
        Remove all whitespace in a string
    ","I want to eliminate all the whitespace from a string, on both ends, and in between words.I have this Python code:def my_handle(self):    sentence = ' hello  apple  '    sentence.strip()But that only eliminates the whitespace on both sides of the string. How do I remove all whitespace?","If you want to remove leading and ending spaces, use str.strip():>>> ""  hello  apple  "".strip()'hello  apple'If you want to remove all space characters, use str.replace() (NB this only removes the “normal” ASCII space character ' ' U+0020 but not any other whitespace):>>> ""  hello  apple  "".replace("" "", """")'helloapple'If you want to remove duplicated spaces, use str.split() followed by str.join():>>> "" "".join(""  hello  apple  "".split())'hello apple'"
"data_i","edited Apr 25 '19 at 11:40","
        Copy array items into another array
    ","I have a JavaScript array dataArray which I want to push into a new array newArray. Except I don't want newArray[0] to be dataArray. I want to push in all the items into the new array:var newArray = [];newArray.pushValues(dataArray1);newArray.pushValues(dataArray2);// ...or even better:var newArray = new Array (   dataArray1.values(),   dataArray2.values(),   // ... where values() (or something equivalent) would push the individual values into the array, rather than the array itself);So now the new array contains all the values of the individual data arrays.  Is there some shorthand like pushValues available so I don't have to iterate over each individual dataArray, adding the items one by one?","Use the concat function, like so:var arrayA = [1, 2];var arrayB = [3, 4];var newArray = arrayA.concat(arrayB);The value of newArray will be [1, 2, 3, 4] (arrayA and arrayB remain unchanged; concat creates and returns a new array for the result)."
"data_i","edited May 23 '22 at 16:50","
        SQL Update from One Table to Another Based on a ID Match
    ","I have a database with account numbers and card numbers. I match these to a file to update any card numbers to the account number so that I am only working with account numbers.I created a view linking the table to the account/card database to return the Table ID and the related account number, and now I need to update those records where the ID matches the Account Number.This is the Sales_Import table, where the account number field needs to be updated:LeadIDAccountNumber147580781123515058078113261857006100100007267039And this is the RetrieveAccountNumber table, where I need to update from:LeadIDAccountNumber14770061001000072669571507006100100007267039I tried the below, but no luck so far:UPDATE [Sales_Lead].[dbo].[Sales_Import] SET    [AccountNumber] = (SELECT RetrieveAccountNumber.AccountNumber                           FROM   RetrieveAccountNumber                           WHERE  [Sales_Lead].[dbo].[Sales_Import]. LeadID =                                                 RetrieveAccountNumber.LeadID) It updates the card numbers to account numbers, but the account numbers get replaced by NULL","I believe an UPDATE FROM with a JOIN will help:MS SQLUPDATE    Sales_ImportSET    Sales_Import.AccountNumber = RAN.AccountNumberFROM    Sales_Import SIINNER JOIN    RetrieveAccountNumber RANON     SI.LeadID = RAN.LeadID;MySQL and MariaDBUPDATE    Sales_Import SI,    RetrieveAccountNumber RANSET    SI.AccountNumber = RAN.AccountNumberWHERE    SI.LeadID = RAN.LeadID;"
"data_i","edited Apr 09 '22 at 10:57","
        What's the difference between lists and tuples?
    ","What's the difference between tuples/lists and what are their  advantages/disadvantages?","Apart from tuples being immutable there is also a semantic distinction that should guide their usage. Tuples are heterogeneous data structures (i.e., their entries have different meanings), while lists are homogeneous sequences. Tuples have structure, lists have order. Using this distinction makes code more explicit and understandable.One example would be pairs of page and line number to reference locations in a book, e.g.:my_location = (42, 11)  # page number, line numberYou can then use this as a key in a dictionary to store notes on locations. A list on the other hand could be used to store multiple locations. Naturally one might want to add or remove locations from the list, so it makes sense that lists are mutable. On the other hand it doesn't make sense to add or remove items from an existing location - hence tuples are immutable.There might be situations where you want to change items within an existing location tuple, for example when iterating through the lines of a page. But tuple immutability forces you to create a new location tuple for each new value. This seems inconvenient on the face of it, but using immutable data like this is a cornerstone of value types and functional programming techniques, which can have substantial advantages.There are some interesting articles on this issue, e.g. ""Python Tuples are Not Just Constant Lists"" or ""Understanding tuples vs. lists in Python"". The official Python documentation also mentions this""Tuples are immutable, and usually contain an heterogeneous sequence ..."".In a statically typed language like Haskell the values in a tuple generally have different types and the length of the tuple must be fixed. In a list the values all have the same type and the length is not fixed. So the difference is very obvious.Finally there is the namedtuple in Python, which makes sense because a tuple is already supposed to have structure. This underlines the idea that tuples are a light-weight alternative to classes and instances."
"data_i","edited Oct 02 '18 at 14:09","
        How do I check if string contains substring?
    ","I have a shopping cart that displays product options in a dropdown menu and if they select ""yes"", I want to make some other fields on the page visible. The problem is that the shopping cart also includes the price modifier in the text, which can be different for each product. The following code works:$(document).ready(function() {    $('select[id=""Engraving""]').change(function() {        var str = $('select[id=""Engraving""] option:selected').text();        if (str == ""Yes (+ $6.95)"") {            $('.engraving').show();        } else {            $('.engraving').hide();        }    });});However I would rather use something like this, which doesn't work:$(document).ready(function() {    $('select[id=""Engraving""]').change(function() {        var str = $('select[id=""Engraving""] option:selected').text();        if (str *= ""Yes"") {            $('.engraving').show();        } else {            $('.engraving').hide();        }    });});I only want to perform the action if the selected option contains the word ""Yes"", and would ignore the price modifier.","Like this:if (str.indexOf(""Yes"") >= 0)...or you can use the tilde operator:if (~str.indexOf(""Yes""))This works because indexOf() returns -1 if the string wasn't found at all.Note that this is case-sensitive.If you want a case-insensitive search, you can writeif (str.toLowerCase().indexOf(""yes"") >= 0)Or:if (/yes/i.test(str))The latter is a regular expression or regex.Regex breakdown:/ indicates this is a regexyes means that the regex will find those exact characters in that exact order/ ends the regexi sets the regex as case-insensitive.test(str) determines if the regular expression matches strTo sum it up, it means it will see if it can find the letters y, e, and s in that exact order, case-insensitively, in the variable str"
"data_i","edited Jun 13 '21 at 23:48","
        How to escape braces (curly brackets) in a format string in .NET
    ","How can brackets be escaped in using string.Format?For example:String val = ""1,2,3""String.Format("" foo {{0}}"", val);This example doesn't throw an exception, but it outputs the string foo {0}.Is there a way to escape the brackets?","For you to output  foo {1, 2, 3} you have to do something like:string t = ""1, 2, 3"";string v = String.Format("" foo {{{0}}}"", t);To output a { you use {{ and to output a } you use }}.Or now, you can also use C# string interpolation like this (a feature available in C# 6.0)Escaping brackets: String interpolation $(""""). It is new feature in C# 6.0.var inVal = ""1, 2, 3"";var outVal = $"" foo {{{inVal}}}"";// The output will be:  foo {1, 2, 3}"
"data_i","edited May 07 '21 at 00:31","
        Group By Multiple Columns
    ","How can I do GroupBy multiple columns in LINQSomething similar to this in SQL:SELECT * FROM <TableName> GROUP BY <Column1>,<Column2>How can I convert this to LINQ:QuantityBreakdown(    MaterialID int,    ProductID int,    Quantity float)INSERT INTO @QuantityBreakdown (MaterialID, ProductID, Quantity)SELECT MaterialID, ProductID, SUM(Quantity)FROM @TransactionsGROUP BY MaterialID, ProductID","Use an anonymous type.Eggroup x by new { x.Column1, x.Column2 }"
"data_i","edited Aug 01 '21 at 22:11","
        How can I do Base64 encoding in Node.js?
    ","Does Node.js have built-in Base64 encoding yet?The reason why I ask this is that final() from crypto can only output hexadecimal, binary or ASCII data. For example:var cipher = crypto.createCipheriv('des-ede3-cbc', encryption_key, iv);var ciph = cipher.update(plaintext, 'utf8', 'hex');ciph += cipher.final('hex');var decipher = crypto.createDecipheriv('des-ede3-cbc', encryption_key, iv);var txt = decipher.update(ciph, 'hex', 'utf8');txt += decipher.final('utf8');According to the documentation, update() can output Base64-encoded data. However, final() doesn't support Base64. I tried and it will break.If I do this:var ciph = cipher.update(plaintext, 'utf8', 'base64');    ciph += cipher.final('hex');Then what should I use for decryption? Hexadecimal or Base64?Therefore, I'm looking for a function to Base64-encode my encrypted hexadecimal output.","Buffers can be used for taking a string or piece of data and doing Base64 encoding of the result. For example:> console.log(Buffer.from(""Hello World"").toString('base64'));SGVsbG8gV29ybGQ=> console.log(Buffer.from(""SGVsbG8gV29ybGQ="", 'base64').toString('ascii'))Hello WorldBuffers are a global object, so no require is needed. Buffers created with strings can take an optional encoding parameter to specify what encoding the string is in. The available toString and Buffer constructor encodings are as follows:'ascii' - for 7 bit ASCII data only. This encoding method is veryfast, and will strip the high bit if set.'utf8' - Multi byte encodedUnicode characters. Many web pages and other document formats useUTF-8.'ucs2' - 2-bytes, little endian encoded Unicode characters. Itcan encode only BMP(Basic Multilingual Plane, U+0000 - U+FFFF).'base64' - Base64 string encoding.'binary' - A way of encoding rawbinary data into strings by using only the first 8 bits of eachcharacter. This encoding method is deprecated and should be avoided infavor of Buffer objects where possible. This encoding will be removedin future versions of Node."
"data_i","edited Oct 03 '18 at 06:39","
        Grouping functions (tapply, by, aggregate) and the *apply family
    ","Whenever I want to do something ""map""py in R, I usually try to use a function in the apply family. However, I've never quite understood the differences between them -- how {sapply, lapply, etc.} apply the function to the input/grouped input, what the output will look like, or even what the input can be -- so I often just go through them all until I get what I want.Can someone explain how to use which one when?My current (probably incorrect/incomplete) understanding is...sapply(vec, f): input is a vector. output is a vector/matrix, where element i is f(vec[i]), giving you a matrix if f has a multi-element outputlapply(vec, f): same as sapply, but output is a list?apply(matrix, 1/2, f): input is a matrix. output is a vector, where element i is f(row/col i of the matrix)tapply(vector, grouping, f): output is a matrix/array, where an element in the matrix/array is the value of f at a grouping g of the vector, and g gets pushed to the row/col namesby(dataframe, grouping, f): let g be a grouping. apply f to each column of the group/dataframe. pretty print the grouping and the value of f at each column.aggregate(matrix, grouping, f): similar to by, but instead of pretty printing the output, aggregate sticks everything into a dataframe.Side question: I still haven't learned plyr or reshape -- would plyr or reshape replace all of these entirely?","R has many *apply functions which are ably described in the help files (e.g. ?apply). There are enough of them, though, that beginning useRs may have difficulty deciding which one is appropriate for their situation or even remembering them all. They may have a general sense that ""I should be using an *apply function here"", but it can be tough to keep them all straight at first.Despite the fact (noted in other answers) that much of the functionality of the *apply family is covered by the extremely popular plyr package, the base functions remain useful and worth knowing.This answer is intended to act as a sort of signpost for new useRs to help direct them to the correct *apply function for their particular problem. Note, this is not intended to simply regurgitate or replace the R documentation! The hope is that this answer helps you to decide which *apply function suits your situation and then it is up to you to research it further. With one exception, performance differences will not be addressed.apply - When you want to apply a function to the rows or columnsof a matrix (and higher-dimensional analogues); not generally advisable for data frames as it will coerce to a matrix first. # Two dimensional matrix M <- matrix(seq(1,16), 4, 4) # apply min to rows apply(M, 1, min) [1] 1 2 3 4 # apply max to columns apply(M, 2, max) [1]  4  8 12 16 # 3 dimensional array M <- array( seq(32), dim = c(4,4,2)) # Apply sum across each M[*, , ] - i.e Sum across 2nd and 3rd dimension apply(M, 1, sum) # Result is one-dimensional [1] 120 128 136 144 # Apply sum across each M[*, *, ] - i.e Sum across 3rd dimension apply(M, c(1,2), sum) # Result is two-dimensional      [,1] [,2] [,3] [,4] [1,]   18   26   34   42 [2,]   20   28   36   44 [3,]   22   30   38   46 [4,]   24   32   40   48If you want row/column means or sums for a 2D matrix, be sure toinvestigate the highly optimized, lightning-quick colMeans,rowMeans, colSums, rowSums.lapply - When you want to apply a function to each element of alist in turn and get a list back.This is the workhorse of many of the other *apply functions. Peelback their code and you will often find lapply underneath. x <- list(a = 1, b = 1:3, c = 10:100)  lapply(x, FUN = length)  $a  [1] 1 $b  [1] 3 $c  [1] 91 lapply(x, FUN = sum)  $a  [1] 1 $b  [1] 6 $c  [1] 5005sapply - When you want to apply a function to each element of alist in turn, but you want a vector back, rather than a list.If you find yourself typing unlist(lapply(...)), stop and considersapply. x <- list(a = 1, b = 1:3, c = 10:100) # Compare with above; a named vector, not a list  sapply(x, FUN = length)   a  b  c    1  3 91 sapply(x, FUN = sum)    a    b    c     1    6 5005 In more advanced uses of sapply it will attempt to coerce theresult to a multi-dimensional array, if appropriate. For example, if our function returns vectors of the same length, sapply will use them as columns of a matrix: sapply(1:5,function(x) rnorm(3,x))If our function returns a 2 dimensional matrix, sapply will do essentially the same thing, treating each returned matrix as a single long vector: sapply(1:5,function(x) matrix(x,2,2))Unless we specify simplify = ""array"", in which case it will use the individual matrices to build a multi-dimensional array: sapply(1:5,function(x) matrix(x,2,2), simplify = ""array"")Each of these behaviors is of course contingent on our function returning vectors or matrices of the same length or dimension.vapply - When you want to use sapply but perhaps need tosqueeze some more speed out of your code or want more type safety.For vapply, you basically give R an example of what sort of thingyour function will return, which can save some time coercing returnedvalues to fit in a single atomic vector. x <- list(a = 1, b = 1:3, c = 10:100) #Note that since the advantage here is mainly speed, this # example is only for illustration. We're telling R that # everything returned by length() should be an integer of  # length 1.  vapply(x, FUN = length, FUN.VALUE = 0L)  a  b  c   1  3 91mapply - For when you have several data structures (e.g.vectors, lists) and you want to apply a function to the 1st elementsof each, and then the 2nd elements of each, etc., coercing the resultto a vector/array as in sapply.This is multivariate in the sense that your function must acceptmultiple arguments. #Sums the 1st elements, the 2nd elements, etc.  mapply(sum, 1:5, 1:5, 1:5)  [1]  3  6  9 12 15 #To do rep(1,4), rep(2,3), etc. mapply(rep, 1:4, 4:1)    [[1]] [1] 1 1 1 1 [[2]] [1] 2 2 2 [[3]] [1] 3 3 [[4]] [1] 4Map - A wrapper to mapply with SIMPLIFY = FALSE, so it is guaranteed to return a list. Map(sum, 1:5, 1:5, 1:5) [[1]] [1] 3 [[2]] [1] 6 [[3]] [1] 9 [[4]] [1] 12 [[5]] [1] 15rapply - For when you want to apply a function to each element of a nested list structure, recursively.To give you some idea of how uncommon rapply is, I forgot about it when first posting this answer! Obviously, I'm sure many people use it, but YMMV. rapply is best illustrated with a user-defined function to apply: # Append ! to string, otherwise increment myFun <- function(x){     if(is.character(x)){       return(paste(x,""!"",sep=""""))     }     else{       return(x + 1)     } } #A nested list structure l <- list(a = list(a1 = ""Boo"", b1 = 2, c1 = ""Eeek""),            b = 3, c = ""Yikes"",            d = list(a2 = 1, b2 = list(a3 = ""Hey"", b3 = 5))) # Result is named vector, coerced to character           rapply(l, myFun) # Result is a nested list like l, with values altered rapply(l, myFun, how=""replace"")tapply - For when you want to apply a function to subsets of avector and the subsets are defined by some other vector, usually afactor.The black sheep of the *apply family, of sorts. The help file's use ofthe phrase ""ragged array"" can be a bit confusing, but it is actuallyquite simple.A vector: x <- 1:20A factor (of the same length!) defining groups: y <- factor(rep(letters[1:5], each = 4))Add up the values in x within each subgroup defined by y: tapply(x, y, sum)    a  b  c  d  e   10 26 42 58 74 More complex examples can be handled where the subgroups are definedby the unique combinations of a list of several factors. tapply issimilar in spirit to the split-apply-combine functions that arecommon in R (aggregate, by, ave, ddply, etc.) Hence itsblack sheep status."
"data_i","edited May 24 '14 at 15:38","
        jQuery how to find an element based on a data-attribute value?
    ","I've got the following scenario:var el = 'li';and there are 5 <li>'s on the page each with a data-slide=number attribute (number being 1,2,3,4,5 respectively).I now need to find the currently active slide number which is mapped to var current = $('ul').data(current); and is updated on each slide change.So far my tries have been unsuccessful, trying to construct the selector that would match the current slide:$('ul').find(el+[data-slide=+current+]);does not match/return anything…The reason I can't hardcode the li part is that this is a user accessible variable that can be changed to a different element if required, so it may not always be an li.Any ideas on what I'm missing?","You have to inject the value of current into an Attribute Equals selector:$(""ul"").find(`[data-slide='${current}']`)For older JavaScript environments (ES5 and earlier):$(""ul"").find(""[data-slide='"" + current + ""']""); "
"data_i","edited Jul 18 '21 at 21:48","
        How to install an npm package from GitHub directly
    ","Trying to install modules from GitHub results in this error:ENOENT error on package.json.Easily reproduced using express:npm install https://github.com/visionmedia/express throws error.npm install express  works.Why can't I install from GitHub?Here is the console output:npm http GET https://github.com/visionmedia/express.gitnpm http 200 https://github.com/visionmedia/express.gitnpm ERR! not a package /home/guym/tmp/npm-32312/1373176518024-0.6586997057311237/tmp.tgznpm ERR! Error: ENOENT, open '/home/guym/tmp/npm-32312/1373176518024-0.6586997057311237/package/package.json'npm ERR! If you need help, you may report this log at:npm ERR!     <http://github.com/isaacs/npm/issues>npm ERR! or email it to:npm ERR!     <npm-@googlegroups.com>npm ERR! System Linux 3.8.0-23-genericnpm ERR! command ""/usr/bin/node"" ""/usr/bin/npm"" ""install"" ""https://github.com/visionmedia/express.git""npm ERR! cwd /home/guym/dev_env/projects_GIT/proj/somenamenpm ERR! node -v v0.10.10npm ERR! npm -v 1.2.25npm ERR! path /home/guym/tmp/npm-32312/1373176518024-0.6586997057311237/package/package.jsonnpm ERR! code ENOENTnpm ERR! errno 34npm ERR!npm ERR! Additional logging details can be found in:npm ERR!     /home/guym/dev_env/projects_GIT/proj/somename/npm-debug.lognpm ERR! not ok code 0","Because https://github.com/visionmedia/express is the URL of a web page and not an npm module. Use this flavor:     git+{url}.gitgit+https://github.com/visionmedia/express.gitor this flavor if you need SSH:git+ssh://git@github.com/visionmedia/express.git"
"data_i","edited Dec 26 '19 at 12:39","
        How to install a previous exact version of a NPM package?
    ","I used nvm to download node v0.4.10 and installed npm to work with that version of node. I am trying to install express using npm install express -gand I get an error that express requires node version >= 0.5.0. Well, this is odd, since I am following the directions for a node+express+mongodb tutorial here that used node v0.4.10, so I am assuming express is/was available to node v0.4.10. If my assumption is correct, how do I tell npm to fetch a version that would work with my setup?","If you have to install an older version of a package, just specify itnpm install <package>@<version>For example: npm install express@3.0.0You can also add the --save flag to that command to add it to your package.json dependencies, or --save --save-exact flags if you want that exact version specified in your package.json dependencies.The install command is documented here: https://docs.npmjs.com/cli/installIf you're not sure what versions of a package are available, you can use:npm view <package> versionsAnd npm view can be used for viewing other things about a package too. https://docs.npmjs.com/cli/view"
"data_i","edited Nov 01 '17 at 01:20","
        Should I put #! (shebang) in Python scripts, and what form should it take?
    ","Should I put the shebang in my Python scripts? In what form?#!/usr/bin/env python or#!/usr/local/bin/pythonAre these equally portable? Which form is used most?Note: the tornado project uses the shebang. On the other hand the Django project doesn't.","The shebang line in any script determines the script's ability to be executed like a standalone executable without typing python beforehand in the terminal or when double clicking it in a file manager (when configured properly). It isn't necessary but generally put there so when someone sees the file opened in an editor, they immediately know what they're looking at. However, which shebang line you use is important.Correct usage for (defaults to version 3.latest) Python 3 scripts is:#!/usr/bin/env python3Correct usage for (defaults to version 2.latest) Python 2 scripts is:#!/usr/bin/env python2The following should not be used (except for the rare case that you are writing code which is compatible with both Python 2.x and 3.x):#!/usr/bin/env pythonThe reason for these recommendations, given in PEP 394, is that python can refer either to python2 or python3 on different systems.Also, do not use:#!/usr/local/bin/python""python may be installed at /usr/bin/python or /bin/python in thosecases, the above #! will fail.""―""#!/usr/bin/env python"" vs ""#!/usr/local/bin/python"""
"data_i","edited Sep 29 '21 at 12:45","
        How can I center text (horizontally and vertically) inside a div block?
    ","I have a div set to display:block (90px height and width), and I have some text inside.I need the text to be aligned in the center both vertically and horizontally.I have tried text-align:center, but it doesn't do the vertical centering part, so I tried vertical-align:middle, but it didn't work.Any ideas?","If it is one line of text and/or image, then it is easy to do. Just use:text-align: center;vertical-align: middle;line-height: 90px;       /* The same as your div height */That's it. If it can be multiple lines, then it is somewhat more complicated. But there are solutions on  http://pmob.co.uk/. Look for ""vertical align"".Since they tend to be hacks or adding complicated divs... I usually use a table with a single cell to do it... to make it as simple as possible.Update for 2020:Unless you need make it work on earlier browsers such as Internet Explorer 10, you can use flexbox. It is widely supported by all current major browsers. Basically, the container needs to be specified as a flex container, together with centering along its main and cross axis:#container {  display: flex;  justify-content: center;  align-items: center;}To specify a fixed width for the child, which is called a ""flex item"":#content {  flex: 0 0 120px;}Example: http://jsfiddle.net/2woqsef1/1/To shrink-wrap the content, it is even simpler: just remove the flex: ... line from the flex item, and it is automatically shrink-wrapped.Example: http://jsfiddle.net/2woqsef1/2/The examples above have been tested on major browsers including MS Edge and Internet Explorer 11.One technical note if you need to customize it: inside of the flex item, since this flex item is not a flex container itself, the old non-flexbox way of CSS works as expected.  However, if you add an additional flex item to the current flex container, the two flex items will be horizontally placed. To make them vertically placed, add the flex-direction: column; to the flex container.  This is how it works between a flex container and its immediate child elements.There is an alternative method of doing the centering: by not specifying center for the distribution on the main and cross axis for the flex container, but instead specify margin: auto on the flex item to take up all extra space in all four directions, and the evenly distributed margins will make the flex item centered in all directions. This works except when there are multiple flex items. Also, this technique works on MS Edge but not on Internet Explorer 11.Update for 2016 / 2017:It can be more commonly done with transform, and it works well even in older browsers such as Internet Explorer 10 and Internet Explorer 11. It can support multiple lines of text:position: relative;top: 50%;transform: translateY(-50%);Example: https://jsfiddle.net/wb8u02kL/1/To shrink-wrap the width:The solution above used a fixed width for the content area. To use a shrink-wrapped width, useposition: relative;float: left;top: 50%;left: 50%;transform: translate(-50%, -50%);Example: https://jsfiddle.net/wb8u02kL/2/If the support for Internet Explorer 10 is needed, then flexbox won't work and the method above and the line-height method would work. Otherwise, flexbox would do the job."
"data_i","edited Nov 03 '15 at 10:13","
        Assigning default values to shell variables with a single command in bash
    ","I have a whole bunch of tests on variables in a bash (3.00) shell script where if the variable is not set, then it assigns a default, e.g.:if [ -z ""${VARIABLE}"" ]; then     FOO='default'else     FOO=${VARIABLE}fiI seem to recall there's some syntax to doing this in one line, something resembling a ternary operator, e.g.:FOO=${ ${VARIABLE} : 'default' }(though I know that won't work...)Am I crazy, or does something like that exist?","Very close to what you posted, actually. You can use something called Bash parameter expansion to accomplish this.To get the assigned value, or default if it's missing:FOO=""${VARIABLE:-default}""  # If variable not set or null, use default.# If VARIABLE was unset or null, it still is after this (no assignment done).Or to assign default to VARIABLE at the same time:FOO=""${VARIABLE:=default}""  # If variable not set or null, set it to default."
"data_i","edited Jul 17 '22 at 05:10","
        Git replacing LF with CRLF
    ","On a Windows machine, I ran added some files using git add. I got warnings saying:LF will be replaced by CRLFWhat are the ramifications of this conversion?","These messages are due to an incorrect default value of core.autocrlf on Windows.The concept of autocrlf is to handle line endings conversions transparently. And it does!Bad news: the value needs to be configured manually.Good news: it should only be done one time per Git installation (per project setting is also possible).How autocrlf works:core.autocrlf=true:      core.autocrlf=input:     core.autocrlf=false:     repository               repository               repository      ^      V                 ^      V                 ^      V     /        \               /        \               /        \crlf->lf    lf->crlf     crlf->lf       \             /          \   /            \           /            \           /            \Here crlf = win-style end-of-line marker, lf = unix-style (also used on Mac since Mac OS X).(pre-osx cr is not affected for any of three options above.)When does this warning show up (under Windows)?    –  autocrlf = true if you have unix-style lf in one of your files (= RARELY),     –  autocrlf = input if you have win-style crlf in one of your files (= almost ALWAYS),     –  autocrlf = false – NEVER!What does this warning mean?The warning ""LF will be replaced by CRLF"" says that you (having autocrlf=true) will lose your unix-style LF after commit-checkout cycle (it will be replaced by windows-style CRLF). Git doesn't expect you to use unix-style LF under Windows.The warning ""CRLF will be replaced by LF"" says that you (having autocrlf=input) will lose your windows-style CRLF after a commit-checkout cycle (it will be replaced by unix-style LF). Don't use input under Windows.Yet another way to show how autocrlf works1) true:             x -> LF -> CRLF2) input:            x -> LF -> LF3) false:            x -> x -> xwhere x is either CRLF (windows-style) or LF (unix-style) and arrows stand forfile to commit -> repository -> checked out fileHow to fixThe default value for core.autocrlf is selected during Git installation and stored in system-wide gitconfig (%ProgramFiles(x86)%\git\etc\gitconfig on Windows,  /etc/gitconfig on Linux).  Also there're (cascading in the following order):    – ""global"" (per-user) gitconfig located at ~/.gitconfig, yet another     – ""global"" (per-user) gitconfig at $XDG_CONFIG_HOME/git/config or $HOME/.config/git/config and     – ""local"" (per-repo) gitconfig at .git/config in the working directory.So, write git config core.autocrlf in the working directory to check the currently used value and    – git config --system core.autocrlf false              # per-system solution     – git config --global core.autocrlf false                # per-user solution     – git config --local core.autocrlf false                  # per-project solutionWarnings    – git config settings can be overridden by gitattributes settings.    – crlf -> lf conversion only happens when adding new files, crlf files already existing in the repo aren't affected.Moral (for Windows):    -  use core.autocrlf = true if you plan to use this project under Unix as well (and unwilling to configure your editor/IDE to use unix line endings),     -  use core.autocrlf = false if you plan to use this project under Windows only (or you have configured your editor/IDE to use unix line endings),     -  never use core.autocrlf = input unless you have a good reason to (eg if you're using unix utilities under Windows or if you run into makefiles issues),PS What to choose when installing Git for Windows?If you're not going to use any of your projects under Unix, don't agree with the default first option. Choose the third one (Checkout as-is, commit as-is). You won't see this message. Ever.PPS: My personal preference is configuring the editor/IDE to use unix-style endings, and setting core.autocrlf to false.Update(2022)Since 2018, git can --renormalize repo fixing the existing line endings as required."
"data_i","edited Feb 15 '22 at 13:54","
        How do I install a Python package with a .whl file?
    ","I'm having trouble installing a Python package on my Windows machine, and would like to install it with Christoph Gohlke's Window binaries. (Which, to my experience, alleviated much of the fuss for many other package installations). However, only .whl files are available.http://www.lfd.uci.edu/~gohlke/pythonlibs/#jpypeBut how do I install .whl files?NotesI've found documents on wheel, but they don't seem so staightforward in explaining how to install .whl files.This question is a duplicate with this question, which wasn't directly answered.","I just used the following which was quite simple. First open a console then cd to where you've downloaded your file like some-package.whl and usepip install some-package.whlNote: if pip.exe is not recognized, you may find it in the ""Scripts"" directory from where python has been installed. If pip is not installed, this page can help:How do I install pip on Windows?Note: for clarificationIf you copy the *.whl file to your local drive (ex. C:\some-dir\some-file.whl) use the following command line parameters --  pip install C:/some-dir/some-file.whl"
"data_i","edited Jun 20 '22 at 07:05","
        What are ""named tuples"" in Python?
    ","What are named tuples and how do I use them?When should I use named tuples instead of normal tuples, or vice versa?Are there ""named lists"" too? (i.e. mutable named tuples)","Named tuples are basically easy-to-create, lightweight object types.  Named tuple instances can be referenced using object-like variable dereferencing or the standard tuple syntax.  They can be used similarly to struct or other common record types, except that they are immutable.  They were added in Python 2.6 and Python 3.0, although there is a recipe for implementation in Python 2.4.For example, it is common to represent a point as a tuple (x, y).  This leads to code like the following:pt1 = (1.0, 5.0)pt2 = (2.5, 1.5)from math import sqrtline_length = sqrt((pt1[0]-pt2[0])**2 + (pt1[1]-pt2[1])**2)Using a named tuple it becomes more readable:from collections import namedtuplePoint = namedtuple('Point', 'x y')pt1 = Point(1.0, 5.0)pt2 = Point(2.5, 1.5)from math import sqrtline_length = sqrt((pt1.x-pt2.x)**2 + (pt1.y-pt2.y)**2)However, named tuples are still backwards compatible with normal tuples, so the following will still work:Point = namedtuple('Point', 'x y')pt1 = Point(1.0, 5.0)pt2 = Point(2.5, 1.5)from math import sqrt# use index referencingline_length = sqrt((pt1[0]-pt2[0])**2 + (pt1[1]-pt2[1])**2) # use tuple unpackingx1, y1 = pt1Thus, you should use named tuples instead of tuples anywhere you think object notation will make your code more pythonic and more easily readable.  I personally have started using them to represent very simple value types, particularly when passing them as parameters to functions.  It makes the functions more readable, without seeing the context of the tuple packing.Furthermore, you can also replace ordinary immutable classes that have no functions, only fields with them.  You can even use your named tuple types as base classes:class Point(namedtuple('Point', 'x y')):    [...]However, as with tuples, attributes in named tuples are immutable:>>> Point = namedtuple('Point', 'x y')>>> pt1 = Point(1.0, 5.0)>>> pt1.x = 2.0AttributeError: can't set attributeIf you want to be able change the values, you need another type.  There is a handy recipe for mutable recordtypes which allow you to set new values to attributes.>>> from rcdtype import *>>> Point = recordtype('Point', 'x y')>>> pt1 = Point(1.0, 5.0)>>> pt1 = Point(1.0, 5.0)>>> pt1.x = 2.0>>> print(pt1[0])    2.0I am not aware of any form of ""named list"" that lets you add new fields, however.  You may just want to use a dictionary in this situation. Named tuples can be converted to dictionaries using pt1._asdict() which returns {'x': 1.0, 'y': 5.0} and can be operated upon with all the usual dictionary functions.  As already noted, you should check the documentation for more information from which these examples were constructed."
"data_i","edited Oct 24 '19 at 09:26","
        Does functional programming replace GoF design patterns?
    ","Since I started learning F# and OCaml last year, I've read a huge number of articles which insist that design patterns (especially in Java) are workarounds for the missing features in imperative languages. One article I found makes a fairly strong claim:Most people I've met have read   the Design Patterns book by the Gang of  Four (GoF). Any self respecting programmer  will tell you that the book is  language agnostic and the patterns  apply to software engineering in  general, regardless of which language  you use. This is a noble claim.  Unfortunately it is far removed from  the truth.Functional languages are extremely  expressive. In a functional language  one does not need design patterns  because the language is likely so high  level, you end up programming in  concepts that eliminate design  patterns all together.The main features of functional programming (FP) include functions as first-class values, currying, immutable values, etc. It doesn't seem obvious to me that OO design patterns are approximating any of those features.Additionally, in functional languages which support OOP (such as F# and OCaml), it seems obvious to me that programmers using these languages would use the same design patterns found available to every other OOP language. In fact, right now I use F# and OCaml every day, and there are no striking differences between the patterns I use in these languages vs. the patterns I use when I write in Java.Is there any truth to the claim that functional programming eliminates the need for OOP design patterns? If so, could you post or link to an example of a typical OOP design pattern and its functional equivalent?","The blog post you quoted overstates its claim a bit. FP doesn't eliminate the need for design patterns. The term ""design patterns"" just isn't widely used to describe the same thing in FP languages. But they exist. Functional languages have plenty of best practice rules of the form ""when you encounter problem X, use code that looks like Y"", which is basically what a design pattern is.However, it's correct that most OOP-specific design patterns are pretty much irrelevant in functional languages.I don't think it should be particularly controversial to say that design patterns in general only exist to patch up shortcomings in the language.And if another language can solve the same problem trivially, that other language won't have need of a design pattern for it. Users of that language may not even be aware that the problem exists, because, well, it's not a problem in that language.Here is what the Gang of Four has to say about this issue:The choice of programming language is important because it influences one's point of view. Our patterns assume Smalltalk/C++-level language features, and that choice determines what can and cannot be implemented easily. If we assumed procedural languages, we might have included design patterns called ""Inheritance"", ""Encapsulation,"" and ""Polymorphism"". Similarly, some of our patterns are supported directly by the less common object-oriented languages. CLOS has multi-methods, for example, which lessen the need for a pattern such as Visitor. In fact, there are enough differences between Smalltalk and C++ to mean that some patterns can be expressed more easily in one language than the other. (See Iterator for example.)(The above is a quote from the Introduction to the Design Patterns book, page 4, paragraph 3)The main features of functional  programming include functions as  first-class values, currying,  immutable values, etc. It doesn't seem  obvious to me that OO design patterns  are approximating any of those  features.What is the command pattern, if not an approximation of first-class functions? :)In an FP language, you'd simply pass a function as the argument to another function.In an OOP language, you have to wrap up the function in a class, which you can instantiate and then pass that object to the other function. The effect is the same, but in OOP it's called a design pattern, and it takes a whole lot more code.And what is the abstract factory pattern, if not currying? Pass parameters to a function a bit at a time, to configure what kind of value it spits out when you finally call it.So yes, several GoF design patterns are rendered redundant in FP languages, because more powerful and easier to use alternatives exist.But of course there are still design patterns which are not solved by FP languages. What is the FP equivalent of a singleton? (Disregarding for a moment that singletons are generally a terrible pattern to use.)And it works both ways too. As I said, FP has its design patterns too; people just don't usually think of them as such.But you may have run across monads. What are they, if not a design pattern for ""dealing with global state""? That's a problem that's so simple in OOP languages that no equivalent design pattern exists there.We don't need a design pattern for ""increment a static variable"", or ""read from that socket"", because it's just what you do.Saying a monad is a design pattern is as absurd as saying the Integers with their usual operations and zero element is a design pattern.  No, a monad is a mathematical pattern, not a design pattern.In (pure) functional languages, side effects and mutable state are impossible, unless you work around it with the monad ""design pattern"", or any of the other methods for allowing the same thing.Additionally, in functional languages  which support OOP (such as F# and  OCaml), it seems obvious to me that  programmers using these languages  would use the same design patterns  found available to every other OOP  language. In fact, right now I use F#  and OCaml everyday, and there are no  striking differences between the  patterns I use in these languages vs  the patterns I use when I write in  Java.Perhaps because you're still thinking imperatively? A lot of people, after dealing with imperative languages all their lives, have a hard time giving up on that habit when they try a functional language. (I've seen some pretty funny attempts at F#, where literally every function was just a string of 'let' statements, basically as if you'd taken a C program, and replaced all semicolons with 'let'. :))But another possibility might be that you just haven't realized that you're solving problems trivially which would require design patterns in an OOP language.When you use currying, or pass a function as an argument to another, stop and think about how you'd do that in an OOP language.Is there any truth to the claim that  functional programming eliminates the  need for OOP design patterns?Yep. :)When you work in a FP language, you no longer need the OOP-specific design patterns. But you still need some general design patterns, like MVC or other non-OOP specific stuff, and you need a couple of new FP-specific ""design patterns"" instead. All languages have their shortcomings, and design patterns are usually how we work around them.Anyway, you may find it interesting to try your hand at ""cleaner"" FP languages, like ML (my personal favorite, at least for learning purposes), or Haskell, where you don't have the OOP crutch to fall back on when you're faced with something new.As expected, a few people objected to my definition of design patterns as ""patching up shortcomings in a language"", so here's my justification:As already said, most design patterns are specific to one programming paradigm, or sometimes even one specific language. Often, they solve problems that only exist in that paradigm (see monads for FP, or abstract factories for OOP).Why doesn't the abstract factory pattern exist in FP? Because the problem it tries to solve does not exist there.So, if a problem exists in OOP languages, which does not exist in FP languages, then clearly that is a shortcoming of OOP languages. The problem can be solved, but your language does not do so, but requires a bunch of boilerplate code from you to work around it. Ideally, we'd like our programming language to magically  make all problems go away. Any problem that is still there is in principle a shortcoming of the language. ;)"
"data_i","edited Apr 19 '20 at 13:47","
        How to initialize all members of an array to the same value?
    ","I have a large array in C (not C++ if that makes a difference). I want to initialize all members of the same value.I could swear I once knew a simple way to do this. I could use memset() in my case, but isn't there a way to do this that is built right into the C syntax?","Unless that value is 0 (in which case you can omit some part of the initializerand the corresponding elements will be initialized to 0), there's no easy way.Don't overlook the obvious solution, though:int myArray[10] = { 5, 5, 5, 5, 5, 5, 5, 5, 5, 5 };Elements with missing values will be initialized to 0:int myArray[10] = { 1, 2 }; // initialize to 1,2,0,0,0...So this will initialize all elements to 0:int myArray[10] = { 0 }; // all elements 0In C++, an empty initialization list will also initialize every element to 0.This is not allowed with C until C23:int myArray[10] = {}; // all elements 0 in C++ and C23Remember that objects with static storage duration will initialize to 0 if noinitializer is specified:static int myArray[10]; // all elements 0And that ""0"" doesn't necessarily mean ""all-bits-zero"", so using the above isbetter and more portable than memset(). (Floating point values will beinitialized to +0, pointers to null value, etc.)"
"data_i","edited Jun 16 '16 at 08:41","
        R cannot be resolved - Android error
    ","I just downloaded and installed the new Android SDK. I wanted to create a simple application to test drive it.The wizard created this code:package eu.mauriziopz.gps;import android.app.Activity;import android.os.Bundle;public class ggps extends Activity {    /** Called when the activity is first created. */    @Override    public void onCreate(Bundle savedInstanceState) {        super.onCreate(savedInstanceState);        setContentView(R.layout.main);    }}but Eclipse gives me the errorR cannot be resolvedon linesetContentView(R.layout.main);Why?PS: I do have an XML file named main.xml under res/layout/.","After tracking down this problem as well, I found this note in the Android documentation:http://source.android.com/source/using-eclipse.html*Note: Eclipse sometimes likes to add an ""import android.R"" statement at the  top of your files that use resources,  especially when you ask Eclipse to  sort or otherwise manage imports. This  will cause your make to break. Look  out for these erroneous import  statements and delete them.*While going through the Android sample tutorials, I would often use the Ctrl + Shift + O command to ""Organize Imports"" and generate any missing import statements. Sometimes this would generate the incorrect import statement which would hide the R.java class that is automatically generated when you build."
"data_i","edited Jul 05 '18 at 03:59","
        Why use Redux over Facebook Flux?
    ","I've read this answer, reducing boilerplate, looked at few GitHub examples and even tried redux a little bit (todo apps). As I understand, official redux doc motivations provide pros comparing to traditional MVC architectures. BUT it doesn't provide an answer to the question: Why you should use Redux over Facebook Flux? Is that only a question of programming styles: functional vs non-functional? Or the question is in abilities/dev-tools that follow from redux approach? Maybe scaling? Or testing?Am I right if I say that redux is a flux for people who come from functional languages? To answer this question you may compare the complexity of implementation redux's motivation points on flux vs redux.Here are motivation points from official redux doc motivations:Handling optimistic updates (as I understand, it hardly depends on 5th point. Is it hard to implement it in facebook flux?)Rendering on the server (facebook flux also can do this. Any benefits comparing to redux?)Fetching data before performing route transitions (Why it can't be achieved in facebook flux? What's the benefits?)Hot reload (It's possible with React Hot Reload. Why do we need redux?)Undo/Redo functionalityAny other points? Like persisting state...","Redux author here!  Redux is not that different from Flux. Overall it has same architecture, but Redux is able to cut some complexity corners by using functional composition where Flux uses callback registration.There is not a fundamental difference in Redux, but I find it makes certain abstractions easier, or at least possible to implement, that would be hard or impossible to implement in Flux.Reducer CompositionTake, for example, pagination. My Flux + React Router example handles pagination, but the code for that is awful. One of the reasons it's awful is that Flux makes it unnatural to reuse functionality across stores. If two stores need to handle pagination in response to different actions, they either need to inherit from a common base store (bad! you're locking yourself into a particular design when you use inheritance), or call an externally defined function from within the event handler, which will need to somehow operate on the Flux store's private state. The whole thing is messy (although definitely in the realm of possible).On the other hand, with Redux pagination is natural thanks to reducer composition. It's reducers all the way down, so you can write a reducer factory that generates pagination reducers and then use it in your reducer tree. The key to why it's so easy is because in Flux, stores are flat, but in Redux, reducers can be nested via functional composition, just like React components can be nested.This pattern also enables wonderful features like no-user-code undo/redo. Can you imagine plugging Undo/Redo into a Flux app being two lines of code? Hardly. With Redux, it is—again, thanks to reducer composition pattern. I need to highlight there's nothing new about it—this is the pattern pioneered and described in detail in Elm Architecture which was itself influenced by Flux.Server RenderingPeople have been rendering on the server fine with Flux, but seeing that we have 20 Flux libraries each attempting to make server rendering “easier”, perhaps Flux has some rough edges on the server. The truth is Facebook doesn't do much server rendering, so they haven't been very concerned about it, and rely on the ecosystem to make it easier.In traditional Flux, stores are singletons. This means it's hard to separate the data for different requests on the server. Not impossible, but hard. This is why most Flux libraries (as well as the new Flux Utils) now suggest you use classes instead of singletons, so you can instantiate stores per request.There are still the following problems that you need to solve in Flux (either yourself or with the help of your favorite Flux library such as Flummox or Alt):If stores are classes, how do I create and destroy them with dispatcher per request? When do I register stores?How do I hydrate the data from the stores and later rehydrate it on the client? Do I need to implement special methods for this?Admittedly Flux frameworks (not vanilla Flux) have solutions to these problems, but I find them overcomplicated. For example, Flummox asks you to implement serialize() and deserialize() in your stores. Alt solves this nicer by providing takeSnapshot() that automatically serializes your state in a JSON tree.Redux just goes further: since there is just a single store (managed by many reducers), you don't need any special API to manage the (re)hydration. You don't need to “flush” or “hydrate” stores—there's just a single store, and you can read its current state, or create a new store with a new state. Each request gets a separate store instance. Read more about server rendering with Redux.Again, this is a case of something possible both in Flux and Redux, but Flux libraries solve this problem by introducing a ton of API and conventions, and Redux doesn't even have to solve it because it doesn't have that problem in the first place thanks to conceptual simplicity.Developer ExperienceI didn't actually intend Redux to become a popular Flux library—I wrote it as I was working on my ReactEurope talk on hot reloading with time travel. I had one main objective: make it possible to change reducer code on the fly or even “change the past” by crossing out actions, and see the state being recalculated.I haven't seen a single Flux library that is able to do this. React Hot Loader also doesn't let you do this—in fact it breaks if you edit Flux stores because it doesn't know what to do with them.When Redux needs to reload the reducer code, it calls replaceReducer(), and the app runs with the new code. In Flux, data and functions are entangled in Flux stores, so you can't “just replace the functions”. Moreover, you'd have to somehow re-register the new versions with the Dispatcher—something Redux doesn't even have.EcosystemRedux has a rich and fast-growing ecosystem. This is because it provides a few extension points such as middleware. It was designed with use cases such as logging, support for Promises, Observables, routing, immutability dev checks, persistence, etc, in mind. Not all of these will turn out to be useful, but it's nice to have access to a set of tools that can be easily combined to work together.SimplicityRedux preserves all the benefits of Flux (recording and replaying of actions, unidirectional data flow, dependent mutations) and adds new benefits (easy undo-redo, hot reloading) without introducing Dispatcher and store registration.Keeping it simple is important because it keeps you sane while you implement higher-level abstractions.Unlike most Flux libraries, Redux API surface is tiny. If you remove the developer warnings, comments, and sanity checks, it's 99 lines. There is no tricky async code to debug.You can actually read it and understand all of Redux.See also my answer on downsides of using Redux compared to Flux."
"data_i","edited Feb 20 '18 at 16:42","
        Best way to remove an event handler in jQuery?
    ","I have an input type=""image"". This acts like the cell notes in Microsoft Excel. If someone enters a number into the text box that this input-image is paired with, I setup an event handler for the input-image. Then when the user clicks the image, they get a little popup to add some notes to the data.My problem is that when a user enters a zero into the text box, I need to disable the input-image's event handler. I have tried the following, but to no avail.$('#myimage').click(function { return false; });","jQuery ≥ 1.7With jQuery 1.7 onward the event API has been updated, .bind()/.unbind() are still available for backwards compatibility, but the preferred method is using the on()/off() functions. The below would now be,$('#myimage').click(function() { return false; }); // Adds another click event$('#myimage').off('click');$('#myimage').on('click.mynamespace', function() { /* Do stuff */ });$('#myimage').off('click.mynamespace');jQuery < 1.7In your example code you are simply adding another click event to the image, not overriding the previous one:$('#myimage').click(function() { return false; }); // Adds another click eventBoth click events will then get fired.As people have said you can use unbind to remove all click events:$('#myimage').unbind('click');If you want to add a single event and then remove it (without removing any others that might have been added) then you can use event namespacing:$('#myimage').bind('click.mynamespace', function() { /* Do stuff */ });and to remove just your event:$('#myimage').unbind('click.mynamespace');"
"data_i","edited Dec 08 '21 at 16:04","
        How do you test that a Python function throws an exception?
    ","How does one write a unittest that fails only if a function doesn't throw an expected exception?","Use TestCase.assertRaises (or TestCase.failUnlessRaises) from the unittest module, for example:import mymodclass MyTestCase(unittest.TestCase):    def test1(self):        self.assertRaises(SomeCoolException, mymod.myfunc)"
"data_i","edited Aug 16 '17 at 10:58","
        What is your most productive shortcut with Vim?
    ","I've heard a lot about Vim, both pros and cons.It really seems you should be (as a developer) faster with Vim than with any other editor.I'm using Vim to do some basic stuff and I'm at best 10 times less productive with Vim.The only two things you should care about when you talk about speed (you may not care enough about them, but you should) are:Using alternatively left and righthands is the fastest way to use thekeyboard. Never touching the mouse is thesecond way to be as fast as possible.It takes ages for you to move your hand,grab the mouse, move it, and bring itback to the keyboard (and you often haveto look at the keyboard to be sure youreturned your hand properly to the right place)Here are two examples demonstrating why I'm far less productive with Vim.Copy/Cut & paste. I do it all the time. With all the contemporary editors you press Shift  with the left hand, and you move the cursor with your right hand to select text. Then Ctrl+C copies, you move the cursor and Ctrl+V pastes.With Vim it's horrible:yy to copy one line (you almost never want the whole line!)[number xx]yy to copy xx lines into the buffer. But you never know exactly if you've selected what you wanted. I often have to do [number xx]dd then u to undo!Another example? Search & replace.In PSPad: Ctrl+f then type what you want you search for, then press Enter.In Vim: /, then type what you want to search for, then if there are some special characters put \ before each special character, then press Enter.And everything with Vim is like that: it seems I don't know how to handle it the right way.NB : I've already read the Vim cheat sheet :)My question is:What is the way you use Vim that makes you more productive than with a contemporary editor?","Your problem with Vim is that  you don't grok vi.You mention cutting with yy and complain that you almost never want to cut whole lines.  In fact programmers, editing source code, very often want to work on whole lines, ranges of lines and blocks of code.  However, yy is only one of many way to yank text into the anonymous copy buffer (or ""register"" as it's called in vi).The ""Zen"" of vi is that you're speaking a language.  The initial y is a verb.  The statement yy is a synonym for y_. The y is doubled up to make it easier to type, since it is such a common operation.This can also be expressed as dd P (delete the current line and paste a copy back into place; leaving a copy in the anonymous register as a side effect).  The y and d ""verbs"" take any movement as their ""subject.""  Thus yW is ""yank from here (the cursor) to the end of the current/next (big) word"" and y'a is ""yank from here to the line containing the mark named 'a'.""If you only understand basic up, down, left, and right cursor movements then vi will be no more productive than a copy of ""notepad"" for you.  (Okay, you'll still have syntax highlighting and the ability to handle files larger than a piddling ~45KB or so; but work with me here).vi has 26 ""marks"" and 26 ""registers.""  A mark is set to any cursor location using the m command.  Each mark is designated by a single lower case letter.  Thus ma sets the 'a' mark to the current location, and mz sets the 'z' mark.  You can move to the line containing a mark using the ' (single quote) command.  Thus 'a moves to the beginning of the line containing the 'a' mark.  You can move to the precise location of any mark using the ` (backquote) command.  Thus  `z will move directly to the exact location of the 'z' mark.Because these are ""movements"" they can also be used as subjects for other ""statements.""So, one way to cut an arbitrary selection of text would be to drop a mark (I usually use 'a' as my ""first"" mark, 'z' as my next mark, 'b' as another, and 'e' as yet another (I don't recall ever having interactively used more than four marks in 15 years of using vi; one creates one's own conventions regarding how marks and registers are used by macros that don't disturb one's interactive context).  Then we go to the other end of our desired text; we can start at either end, it doesn't matter.  Then we can simply use d`a to cut or y`a to copy.  Thus the whole process has a 5 keystrokes overhead (six if we started in ""insert"" mode and needed to Esc out command mode).  Once we've cut or copied then pasting in a copy is a single keystroke: p.I say that this is one way to cut or copy text.  However, it is only one of many.  Frequently we can more succinctly describe the range of text without moving our cursor around and dropping a mark.  For example if I'm in a paragraph of text I can use { and } movements to the beginning or end of the paragraph respectively.  So, to move a paragraph of text I cut it using { d} (3 keystrokes).  (If I happen to already be on the first or last line of the paragraph I can then simply use d} or d{ respectively.The notion of ""paragraph"" defaults to something which is usually intuitively reasonable.  Thus it often works for code as well as prose.Frequently we know some pattern (regular expression) that marks one end or the other of the text in which we're interested.  Searching forwards or backwards are movements in vi.  Thus they can also be used as ""subjects"" in our ""statements.""  So I can use d/foo to cut from the current line to the next line containing the string ""foo"" and y?bar to copy from the current line to the most recent (previous) line containing ""bar.""  If I don't want whole lines I can still use the search movements (as statements of their own), drop my mark(s) and use the  `x commands as described previously.In addition to ""verbs"" and ""subjects"" vi also has ""objects"" (in the grammatical sense of the term).  So far I've only described the use of the anonymous register.  However, I can use any of the 26 ""named"" registers by prefixing the ""object"" reference with "" (the double quote modifier).  Thus if I use ""add I'm cutting the current line into the 'a' register and if I use ""by/foo then I'm yanking a copy of the text from here to the next line containing ""foo"" into the 'b' register.  To paste from a register I simply prefix the paste with the same modifier sequence: ""ap pastes a copy of the 'a' register's contents into the text after the cursor and ""bP pastes a copy from 'b' to before the current line.This notion of ""prefixes"" also adds the analogs of grammatical ""adjectives"" and ""adverbs'  to our text manipulation ""language.""  Most commands (verbs) and movement (verbs or objects, depending on context) can also take numeric prefixes. Thus 3J means ""join the next three lines"" and d5} means ""delete from the current line through the end of the fifth paragraph down from here.""This is all intermediate level vi.  None of it is Vim specific and there are far more advanced tricks in vi if you're ready to learn them.  If you were to master just these intermediate concepts then you'd probably find that you rarely need to write any macros because the text manipulation language is sufficiently concise and expressive to do most things easily enough using the editor's ""native"" language.A sampling of more advanced tricks:There are a number of : commands, most notably the :% s/foo/bar/g global substitution technique.  (That's not advanced but other : commands can be).  The whole : set of commands was historically inherited by vi's previous incarnations as the ed (line editor) and later the ex (extended line editor) utilities.  In fact vi is so named because it's the visual interface to ex.: commands normally operate over lines of text.  ed and ex were written in an era when terminal screens were uncommon and many terminals were ""teletype"" (TTY) devices.  So it was common to work from printed copies of the text, using commands through an extremely terse interface (common connection speeds were 110 baud, or, roughly, 11 characters per second -- which is slower than a fast typist; lags were common on multi-user interactive sessions; additionally there was often some motivation to conserve paper).So the syntax of most : commands includes an address or range of addresses (line number) followed by a command.  Naturally one could use literal line numbers: :127,215 s/foo/bar to change the first occurrence of ""foo"" into ""bar"" on each line between 127 and 215.  One could also use some abbreviations such as . or $ for current and last lines respectively.  One could also use relative prefixes + and - to refer to offsets after or before the curent line, respectively.  Thus: :.,$j meaning ""from the current line to the last line, join them all into one line"".  :% is synonymous with :1,$ (all the lines).The :... g and :... v commands bear some explanation as they are incredibly powerful.  :... g is a prefix for ""globally"" applying a subsequent command to all lines which match a pattern (regular expression) while :... v applies such a command to all lines which do NOT match the given pattern (""v"" from ""conVerse"").  As with other ex commands these can be prefixed by addressing/range references.  Thus :.,+21g/foo/d means ""delete any lines containing the string ""foo"" from the current one through the next 21 lines"" while :.,$v/bar/d means ""from here to the end of the file, delete any lines which DON'T contain the string ""bar.""It's interesting that the common Unix command grep was actually inspired by this ex command (and is named after the way in which it was documented).  The ex command :g/re/p (grep) was the way they documented how to ""globally"" ""print"" lines containing a ""regular expression"" (re).  When ed and ex were used, the :p command was one of the first that anyone learned and often the first one used when editing any file.  It was how you printed the current contents (usually just one page full at a time using :.,+25p or some such).Note that :% g/.../d or (its reVerse/conVerse counterpart: :% v/.../d are the most common usage patterns.  However there are  couple of other ex commands which are worth remembering:We can use m to move lines around, and j to join lines.  For example if you have a list and you want to separate all the stuff matching (or conversely NOT matching some pattern) without deleting them, then you can use something like: :% g/foo/m$ ... and all the ""foo"" lines will have been moved to the end of the file.  (Note the other tip about using the end of your file as a scratch space).  This will have preserved the relative order of all the ""foo"" lines while having extracted them from the rest of the list.  (This would be equivalent to doing something like: 1G!GGmap!Ggrep foo<ENTER>1G:1,'a g/foo'/d (copy the file to its own tail, filter the tail through grep, and delete all the stuff from the head).To join lines usually I can find a pattern for all the lines which need to be joined to their predecessor (all the lines which start with ""^   "" rather than ""^ * "" in some bullet list, for example).  For that case I'd use: :% g/^   /-1j (for every matching line, go up one line and join them). (BTW: for bullet lists trying to search for the bullet lines and join to the next doesn't work for a couple reasons ... it can join one bullet line to another, and it won't join any bullet line to all of its continuations; it'll only work pairwise on the matches).Almost needless to mention you can use our old friend s (substitute) with the g and v (global/converse-global) commands.  Usually you don't need to do so.  However, consider some case where you want to perform a substitution only on lines matching some other pattern.  Often you can use a complicated pattern with captures and use back references to preserve the portions of the lines that you DON'T want to change.  However, it will often be easier to separate the match from the substitution: :% g/foo/s/bar/zzz/g -- for every line containing ""foo"" substitute all ""bar"" with ""zzz.""  (Something like :% s/\(.*foo.*\)bar\(.*\)/\1zzz\2/g would only work for the cases those instances of ""bar"" which were PRECEDED by ""foo"" on the same line; it's ungainly enough already, and would have to be mangled further to catch all the cases where ""bar"" preceded ""foo"")The point is that there are more than just p, s, and d lines in the ex command set.The : addresses can also refer to marks.  Thus you can use: :'a,'bg/foo/j to join any line containing the string foo to its subsequent line, if it lies between the lines between the 'a' and 'b' marks.  (Yes, all of the preceding ex command examples can be limited to subsets of the file's lines by prefixing with these sorts of addressing expressions).That's pretty obscure (I've only used something like that a few times in the last 15 years). However, I'll freely admit that I've often done things iteratively and interactively that could probably have been done more efficiently if I'd taken the time to think out the correct incantation.Another very useful vi or ex command is :r to read in the contents of another file.  Thus: :r foo inserts the contents of the file named ""foo"" at the current line.More powerful is the :r! command.  This reads the results of a command.  It's the same as suspending the vi session, running a command, redirecting its output to a temporary file, resuming your vi session, and reading in the contents from the temp. file.Even more powerful are the ! (bang) and :... ! (ex bang) commands.  These also execute external commands and read the results into the current text. However, they also filter selections of our text through the command!  This we can sort all the lines in our file using 1G!Gsort (G is the vi ""goto"" command; it defaults to going to the last line of the file, but can be prefixed by a line number, such as 1, the first line).  This is equivalent to the ex variant :1,$!sort.  Writers often use ! with the Unix fmt or fold utilities for reformating or ""word wrapping"" selections of text.  A very common macro is {!}fmt (reformat the current paragraph).  Programmers sometimes use it to run their code, or just portions of it, through indent or other code reformatting tools.Using the :r! and ! commands means that any external utility or filter can be treated as an extension of our editor.  I have occasionally used these with scripts that pulled data from a database, or with wget or lynx commands that pulled data off a website, or ssh commands that pulled data from remote systems.Another useful ex command is :so (short for :source).  This reads the contents of a file as a series of commands.  When you start vi it normally, implicitly, performs a :source on ~/.exinitrc file (and Vim usually does this on ~/.vimrc, naturally enough).  The use of this is that you can change your editor profile on the fly by simply sourcing in a new set of macros, abbreviations, and editor settings.  If you're sneaky you can even use this as a trick for storing sequences of ex editing commands to apply to files on demand.For example I have a seven line file (36 characters) which runs a file through wc, and inserts a C-style comment at the top of the file containing that word count data.  I can apply that ""macro"" to a file by using a command like: vim +'so mymacro.ex' ./mytarget(The + command line option to vi and Vim is normally used to start the editing session at a given line number.  However it's a little known fact that one can follow the + by any valid ex command/expression, such as a ""source"" command as I've done here; for a simple example I have scripts which invoke: vi +'/foo/d|wq!' ~/.ssh/known_hosts to remove an entry from my SSH known hosts file non-interactively while I'm re-imaging a set of servers).Usually it's far easier to write such ""macros"" using Perl, AWK, sed (which is, in fact, like grep a utility inspired by the ed command).The @ command is probably the most obscure vi command.  In occasionally teaching advanced systems administration courses for close to a decade I've met very few people who've ever used it.  @ executes the contents of a register as if it were a vi or ex command.Example: I often use: :r!locate ... to find some file on my system and read its name into my document.  From there I delete any extraneous hits, leaving only the full path to the file I'm interested in.  Rather than laboriously Tab-ing through each component of the path (or worse, if I happen to be stuck on a machine without Tab completion support in its copy of vi) I just use:0i:r (to turn the current line into a valid :r command),""cdd (to delete the line into the ""c"" register) and@c execute that command.That's only 10 keystrokes (and the expression ""cdd @c is effectively a finger macro for me, so I can type it almost as quickly as any common six letter word).A sobering thoughtI've only scratched to surface of vi's power and none of what I've described here is even part of the ""improvements"" for which vim is named!  All of what I've described here should work on any old copy of vi from 20 or 30 years ago.There are people who have used considerably more of vi's power than I ever will."
"data_i","edited Jan 02 '20 at 09:56","
        What is the difference between  and ?
    
    
        
            Asked
            Aug 04 '11 at 10:33
        
            Active
            Aug 07 '22 at 13:06
        
        
            Viewed 7.4e+01k times
        
    

    
        
            
                    
    
        
            
            1123
            
            
                235
            
        
    
    
        What is the difference between <section> and <div> in HTML? Aren't we defining sections in both cases?
        
        
            
                
                    
                    html
                    
                
            
        
        
        
            
                
                
                
                    
                        
                        

    edited Jan 02 '20 at 09:56
        
    
        Roy Bogado
        4,229
            1
            13
            30
        


                        
                    
                
                
                
                    
                    
                        

    asked Aug 04 '11 at 10:33
        
    
        Simplicity
        45,428
            92
            246
            379
        


                    
                    
                
            
        
    
    
        
        
            
                    
                        
                            1
                        
                    
                    
                    
    
    
        See also: [Using section element for stylistic layout and wrappers](http://stackoverflow.com/q/18839218/1591669)
        – unor
                Jan 18 '14 at 15:00
    

                    
                
                
            
        
    
    
            
        

        
            
            
                
                    
                        13 Answers13
                    
                
            
            
            
            
                
                        
    
        
            
            1188
            
            
        
    
    
        <section> means that the content inside is grouped (i.e. relates to a single theme), and should appear as an entry in an outline of the page.
<div>, on the other hand, does not convey any meaning, aside from any found in its class, lang and title attributes.
So no: using a <div> does not define a section in HTML.
From the spec:
<section>

The <section> element represents a generic section of a document or application. A section, in this context, is a thematic grouping of content. Each section should be identified, typically by including a heading (h1-h6 element) as a child of the <section> element.
Examples of sections would be chapters, the various tabbed pages in a tabbed dialog box, or the numbered sections of a thesis. A Web site’s home page could be split into sections for an introduction, news items, and contact information.
...
The <section> element is not a generic container element. When an element is needed only for styling purposes or as a convenience for scripting, authors are encouraged to use the <div> element instead. A general rule is that the <section> element is appropriate only if the element’s contents would be listed explicitly in the document’s outline.

(https://www.w3.org/TR/html/sections.html#the-section-element)
<div>

The <div> element has no special meaning at all. It represents its children. It can be used with the class, lang, and title attributes to mark up semantics common to a group of consecutive elements.
Note: Authors are strongly encouraged to view the <div> element as an element of last resort, for when no other element is suitable. Use of more appropriate elements instead of the <div> element leads to better accessibility for readers and easier maintainability for authors.

(https://www.w3.org/TR/html/grouping-content.html#the-div-element)
Sections are most relevant in landmark navigation for assistive technology. To appear in the document outline or landmark list, they need a name, which can be assigned by means of aria-label, aria-labelledby or title:
<section aria-labelledby=""s3-h2"">
  <h2 id=""s3-h2"">Introduction</h2>
  …

For example VoiceOver on Mac then can provide an outline to navigate directly to that section.
        
        
            
                
                
                
                    
                        
                        

    edited Jul 05 '22 at 16:28
        
    
        Andy
        3,290
            2
            22
            44
        


                        
                    
                
                
                
                    
                    
                        

    answered Aug 04 '11 at 12:10
        
    
        Paul D. Waite
        94,451
            54
            196
            266
        


                    
                    
                
            
        
    
    
        
        
            
                    
                        
                            35
                        
                    
                    
                    
    
    
        Thinking more about `section` vs. `div`, including in light of this answer, I've come to the conclusion that they are exactly the same element. The W3C says a `div` ""represents its children"". Well, isn't that also what the `section` element does? Yes, `section` implies its children are grouped together, but by the very act of putting children inside a `div`, you are also, yes, **grouping them together**. At least the way I do it, I don't know about you guys.
        – trysis
                Aug 05 '14 at 19:11
    

                    
                
                
                
                    
                        
                            15
                        
                    
                    
                    
    
    
        @trysis: “Thinking more about `section` vs. `div`” — don’t think too much about it. HTML isn’t complicated. “by the very act of putting children inside a `div`, you are also, yes, **grouping them together**.” Not according to the HTML spec you’re not. You’re wrapping them in a `div` for styling purposes, or JavaScript convenience, or something else that the W3C hasn’t thought of yet, but doesn’t indicate to readers that the child elements are a group.
        – Paul D. Waite
                Aug 06 '14 at 09:39
    

                    
                
                
                
                    
                        
                            
                        
                    
                    
                    
    
    
        @trysis: when they say a `` “represents its children” they mean that the `` adds no extra meaning to its children, and in meaning terms should be thought of as entirely interchangeable with its children.
        – Paul D. Waite
                Aug 22 '14 at 08:21
    

                    
                
                
                
                    
                        
                            4
                        
                    
                    
                    
    
    
        +1. imo section, header, footer, nav, div, etc. are all **technically** same. But **semantically**, they all are different.
        – musafar006
                Dec 05 '15 at 12:39
    

                    
                
                
                
                    
                        
                            
                        
                    
                    
                    
    
    
        Why does it say: ""encouraged to view the div element as an element of last resort""?
        – Martian2049
                Jul 08 '16 at 03:07
    

                    
                
                
                
                    
                        
                            14
                        
                    
                    
                    
    
    
        @Matian2040: because the purpose of HTML is to add meaning to text, for example `This is a paragraph` or `This is a second-level heading`. Because `` adds no meaning, you’d only use it if there isn’t another HTML element that adds appropriate meaning to the text in question.
        – Paul D. Waite
                Jul 08 '16 at 09:17
    

                    
                
                
                
                    
                        
                            9
                        
                    
                    
                    
    
    
        So there is not a single advantage if using sections? lol, why does it even exist then?!
        – Black
                Nov 16 '16 at 15:36
    

                    
                
                
                
                    
                        
                            21
                        
                    
                    
                    
    
    
        @EdwardBlack: it conveys a different meaning than other tags do. Conveying meaning is the entire point of HTML.
        – Paul D. Waite
                Nov 16 '16 at 16:05
    

                    
                
                
                
                    
                        
                            
                        
                    
                    
                    
    
    
        There is a contradiction in each note. I use a few `` for styling purposes, and the first note makes it clear I am correct to use ``. However, the second note makes it clear I should only use `` as a last resort, and its not really a last resort for me to use ``.
        – Dan Bray
                Jan 08 '17 at 17:32
    

                    
                
                
                
                    
                        
                            2
                        
                    
                    
                    
    
    
        @DanBray: “its not really a last resort for me to use ``”— I think what it means by “last resort” is that if there’s any HTML element whose meaning kind of matches your content, you should use that element instead of ``. I don’t think that’s a contradiction in the spec, although if you use `` when your content would be better described by a different element, then you’re not following the spec.
        – Paul D. Waite
                Jan 09 '17 at 08:27
    

                    
                
                
                
                    
                        
                            1
                        
                    
                    
                    
    
    
        Is using  maybe helping blind people to browse a website?
        – John
                Aug 01 '17 at 20:20
    

                    
                
                
                
                    
                        
                            
                        
                    
                    
                    
    
    
        @John: from my very limited experience of testing with screenreaders and observing screen reader users, I don’t think it would have much practical effect.
        – Paul D. Waite
                Aug 02 '17 at 07:01
    

                    
                
                
                
                    
                        
                            3
                        
                    
                    
                    
    
    
         it to say that the CONTENT is linked. For example, These 3 Paragraphs are do to with ""Notes"" or ""Listed sources"". The actual Text you are viewing. (Or for Accessibility sake, The screen reader is reading).  on the other hand, Portrays no meaning to the text/content that it is displaying. It could have 3 paragraphs inside the div, but for a screen reader, they are just 3 completely independent paragraphs that happen to sit under a  that is colouring the text green, which a blind person couldn't see.  groups content,  groups structure. Hope that helps.
        – WORMSS
                Jan 15 '18 at 14:56
    

                    
                
                
                
                    
                        
                            1
                        
                    
                    
                    
    
    
        So is  just about search engine optimization, then?  I'm not understanding what the difference would be for the user viewing the page.
        – Nightmare Games
                Apr 28 '18 at 16:32
    

                    
                
                
                
                    
                        
                            
                        
                    
                    
                    
    
    
        @NightmareGames: unless browsers (including screen readers) treated the `section` element differently (which I don’t think they do, although I could be wrong), then there would be no difference for users viewing the page. Unless search engines deal with `section` elements differently (which, again, I don’t think they do), then there’s no difference there either.
        – Paul D. Waite
                Apr 29 '18 at 21:19
    

                    
                
                
                
                    
                        
                            2
                        
                    
                    
                    
    
    
        It might be noteworthy that there is also a **technical** difference: https://stackoverflow.com/a/58624781/3744304
        – connexo
                Oct 30 '19 at 11:58
    

                    
                
                
                
                    
                        
                            
                        
                    
                    
                    
    
    
        @connexo: If the only technical difference between them is a property that has been marked obsolete, that seems to imply that browsers are not even able to treat them differently. Once the DOM tree is composed, knowledge of what the original tag was is lost. Thus the only benefit (though still an important one) is the semantic meaning that can be used for improving accessibility for visually impaired users, etc. I would assume that accessibility software needs to access the html source of the page.
        – John Pankowicz
                Jan 24 '20 at 17:43
    

                    
                
                
                
                    
                        
                            2
                        
                    
                    
                    
    
    
        I am so inspired by the discussion series above.  I am very new to web design.  I learned that HTML/CSS/Javascript should belong to a design called separation of concerns.  So CSS focuses on styling, javascript focuses on action and reaction, and html focuses on containing information.  If you are viewing HTML from the Javascript point of view, you may find many things meaningless just because you are using a wrong perspective.  HTML is also a document that we programmers, as human beings, need to manipulate.  So giving sufficient semantic tags help enhance readability and should be respected.
        – Ken T
                Aug 27 '20 at 18:46
    

                    
                
                
                
                    
                        
                            1
                        
                    
                    
                    
    
    
        Well put, @KenT. You could say there also is a 4th perspective: The accessibility tree. It’s what users with assistive technology like screen readers use. And semantic HTML is crucial for a useful accessibility tree.
        – Andy
                Jul 05 '22 at 16:30
    

                    
                
                
            
        
    
    
                
            
            
            
            
                
                        
    
        
            
            87
            
            
        
    
    
        <section> marks up a section, <div> marks up a generic block with no associated semantics.
        
        
            
                
                
                
                    
                    
                        

    answered Aug 04 '11 at 10:34
        
    
        Quentin
        874,809
            121
            1,171
            1,285
        


                    
                    
                
            
        
    
    
        
        
            
                    
                        
                            1
                        
                    
                    
                    
    
    
        @MarwenTrabelsi — The link isn't dead. ""Section"" is a standard English word. Dictionaries are available.
        – Quentin
                Oct 18 '19 at 08:33
    

                    
                
                
                
                    
                        
                            
                        
                    
                    
                    
    
    
        @MarwenTrabelsi — The terms you call ""abstract and wide"" *are* the key differences.
        – Quentin
                Oct 18 '19 at 08:54
    

                    
                
                
                
                    
                        
                            
                        
                    
                    
                    
    
    
        This seems like a more ""in your face"" kinda answer. And I mean it in a good way. Like no nonsense to the point. Thanks.
        – Max
                Mar 10 '22 at 15:32
    

                    
                
                
            
        
    
    
                
            
            
            
            
                
                        
    
        
            
            72
            
            
        
    
    
        Just an observation - haven't found any documentation corroborating this
If a section contains another section, a h1-header in the inner section is displayed in a smaller font than a h1- header in outer section.
When using div instead of section the inner div h1-header is diplayed as h1.
<section>
  <h1>Level1</h1>
  some text
  <section>
    <h1>Level2</h1>
    some more text
  </section>
</section>

-- the Level2 - header is displayed in a smaller font than the Level1 - header.
When using css to color h1 header, the inner h1 were also colored (behaves as regular h1).
It's the same behaviour in Firefox 18, IE 10 and Chrome 28.
        
        
            
                
                
                
                    
                        
                        

    edited Sep 18 '18 at 18:03
        
    
        David Storfer
        337
            
            3
            11
        


                        
                    
                
                
                
                    
                    
                        

    answered Aug 01 '13 at 14:28
        
    
        runec
        1,637
            
            12
            21
        


                    
                    
                
            
        
    
    
        
        
            
                    
                        
                            4
                        
                    
                    
                    
    
    
        How very weird... created  a quick stackblitz to demo this as it's still a thing https://stackblitz.com/edit/angular-h1ayez
        – Gavin Mannion
                Mar 04 '20 at 16:56
    

                    
                
                
                
                    
                        
                            
                        
                    
                    
                    
    
    
        Exactly like sections in Latex language, it's called subsection there.
        – SdSaati
                Sep 01 '20 at 16:21
    

                    
                
                
                
                    
                        
                            1
                        
                    
                    
                    
    
    
        The MDN docs make mention of avoiding multiple h1's in a single page, even though it's technically supported. I imagine that's the bug (?) that results in the strange styling of h1's nested in sections.

In the demo posted by @GavinMannion (thanks), you will note that all the h2's are styled the same, no matter the level of nesting within sections. TLDR, h1's are treated differently, and sections should only start with h2's rather than h1.
        – Alan
                Nov 21 '20 at 02:32
    

                    
                
                
                
                    
                        
                            
                        
                    
                    
                    
    
    
        @GavinMannion: Nice example. Interestingly, it does not have any affect on `` elements... i.e all `` are rendered in the same font-size. Wow! Amazing!
        – Nawaz
                Jun 28 '22 at 23:07
    

                    
                
                
            
        
    
    
                
            
            
            
            
                
                        
    
        
            
            69
            
            
        
    
    
        <div> Vs <Section>
Round 1
<div>: The HTML  element (or HTML Document Division Element) is the generic container for flow content, which does not inherently represent anything. It can be used to group elements for styling purposes (using the class or id attributes), or because they share attribute values, such as lang. It should be used only when no other semantic element (such as <article> or <nav>) is appropriate.
<section>: The HTML Section element (<section>) represents a generic section of a document, i.e., a thematic grouping of content, typically with a heading.
Round 2
<div>: Browser Support

<section>: Browser Support
The numbers in the table specifies the first browser version that fully supports the element.

In that vein, a div is relevant only from a pure CSS or DOM perspective, whereas a section is relevant also for semantics and, in a near future, for indexing by search engines.
        
        
            
                
                
                
                    
                    
                    
                        edited Jul 17 '14 at 06:53
                        
                        
                            Subodh Ghulaxe
                            
                        
                    
                    
                    
                
                
                
                    
                    
                        

    answered Jun 17 '14 at 12:00
        
    
        Subodh Ghulaxe
        18,045
            14
            82
            99
        


                    
                    
                
            
        
    
    
        
        
            
                    
                        
                            11
                        
                    
                    
                    
    
    
        Browser support is a non-issue here, it's about semantics. If you're using HTML5, you'll probably use a polyfill anyway.
        – Jack
                Sep 19 '14 at 21:22
    

                    
                
                
                
                    
                        
                            
                        
                    
                    
                    
    
    
        @JackTuck And what if you don't want to use such kludges?
        – Mr Lister
                Oct 10 '15 at 14:38
    

                    
                
                
            
        
    
    
                
            
            
            
            
                
                        
    
        
            
            35
            
            
        
    
    
        In the HTML5 standard, the <section> element is defined as a block of related elements.
The <div> element is defined as a block of children elements.
        
        
            
                
                
                
                    
                        
                        

    edited Apr 29 '16 at 15:53
        
    
        cf-
        8,388
            9
            33
            58
        


                        
                    
                
                
                
                    
                    
                        

    answered Apr 29 '16 at 14:51
        
    
        srikanth_k
        2,607
            3
            15
            18
        


                    
                    
                
            
        
    
    
        
        
            
                    
                        
                            1
                        
                    
                    
                    
    
    
        I dont know why someone marked this down. Short, sweet, and too the point.
        – user6031759
                Jun 21 '16 at 14:39
    

                    
                
                
                
                    
                        
                            1
                        
                    
                    
                    
    
    
        -1 it's don't make any sense, how you want to group related elements in the hierarchical structure document (XML/HTML), you can only group block of children elements using any tag.
        – Svisstack
                Feb 24 '18 at 21:34
    

                    
                
                
                
                    
                        
                            
                        
                    
                    
                    
    
    
        @Svisstack You are correct that any enclosing tag  (ie. not self-closing/void) can group blocks of child elements. Though I think this is getting more into what is the relation of the children. Do they all have a related context to convey? For example: a form containing several inputs would be grouped together for functionality/styling reasons. But this form is not a section of the website, but instead a piece with a function. Now lets say your page was describing a product. Different parts about the product would be listed in a section element because the elements convey a collective idea.
        – Xandor
                May 27 '19 at 16:58
    

                    
                
                
            
        
    
    
                
            
            
            
            
                
                        
    
        
            
            25
            
            
        
    
    
        Take caution not to overuse the section tag as a replacement for a div element.  A section tag should define a significant region within the context of the body.  Semantically, HTML5 encourages us to define our document as follows:


<html>
<head></head>
<body>
    <header></header>
    <section>
        <h1></h1>
        <div>
            <span></span>
        </div>
        <div></div>
    </section>
    <footer></footer>
</body>
</html>


This strategy allows web robots and automated screen readers to better understand the flow of your content.  This markup clearly defines where your major page content is contained.  Of course, headers and footers are often common across hundreds if not thousands of pages within a website.  The section tag should be limited to explain where the unique content is contained.  Within the section tag, we should then continue to markup and control the content with HTML tags which are lower in the hierarchy, like h1, div, span, etc.
In most simple pages, there should only be a single section tag, not multiple ones.  Please also consider also that there are other interesting HTML5 tags which are similar to section.  Consider using article, summary, aside and others within your document flow.  As you can see, these tags further enhance our ability to define the major regions of the HTML document.
        
        
            
                
                
                
                    
                    
                        

    answered May 15 '16 at 12:06
        
    
        KoolWebDezign
        251
            
            3
            2
        


                    
                    
                
            
        
    
    
        
        
            
                    
                        
                            
                        
                    
                    
                    
    
    
        ""In most simple pages, there should only be a single section tag"". Can you give a non-simple example where you would want to use multiple section tags in a single page?
        – styfle
                Jun 22 '17 at 14:54
    

                    
                
                
                
                    
                        
                            10
                        
                    
                    
                    
    
    
        I would use the `main` tag in there, and inside it, one or more `section` tags.
        – Chazy Chaz
                Jul 03 '17 at 21:50
    

                    
                
                
                
                    
                        
                            2
                        
                    
                    
                    
    
    
        If you follow the spec, your `section` should be `main`, the `div` should be `article` and the `span` would likely be `section` (depending on what it's doing)
        – Tom B
                Oct 19 '20 at 09:19
    

                    
                
                
            
        
    
    
                
            
            
            
            
                
                        
    
        
            
            14
            
            
        
    
    
        <div>—the generic flow container we all know and love. It’s a block-level element with no additional semantic meaning (W3C:Markup, WhatWG)
<section>—a generic document or application section. A  normally has a heading (title) and maybe a footer too. It’s a chunk of related content, like a subsection of a long article, a major part of the page (eg the news section on the homepage), or a page in a webapp’s tabbed interface. (W3C:Markup, WhatWG)
My suggestion: 
div: used lower version( i think 4.01 to still) html element(lot of designers handled that).
section: recently comming (html5) html element.
        
        
            
                
                
                
                    
                        
                        

    edited Aug 04 '11 at 12:15
        
    
        Paul D. Waite
        94,451
            54
            196
            266
        


                        
                    
                
                
                
                    
                    
                        

    answered Aug 04 '11 at 12:13
        
    
        anglimasS
        1,292
            2
            16
            40
        


                    
                    
                
            
        
    
    
        
    
    
                
            
            
            
            
                
                        
    
        
            
            12
            
            
        
    
    
        Using <section> may be neater, help screen readers and SEO while <div> is smaller in bytes and quicker to type
Overall very little difference.
Also, would not recommend putting <section> in a <section>, instead place a <div> inside a <section>
        
        
            
                
                
                
                    
                    
                        

    answered Jan 19 '18 at 07:28
        
    
        drooh
        460
            4
            17
            41
        


                    
                    
                
            
        
    
    
        
    
    
                
            
            
            
            
                
                        
    
        
            
            10
            
            
        
    
    
        The section tag provides a more semantic syntax for html. div is a generic tag for a section.
When you use section tag for appropriate content, it can be used for search engine optimization also. section tag also makes it easy for html parsing. for more info, refer. http://blog.whatwg.org/is-not-just-a-semantic
        
        
            
                
                
                
                    
                    
                        

    answered Aug 04 '11 at 10:37
        
    
        Poomalairaj
        4,678
            3
            20
            27
        


                    
                    
                
            
        
    
    
        
        
            
                    
                        
                            1
                        
                    
                    
                    
    
    
        “section tag also makes it easy for html parsing” — eh? Do you mean for generating an outline of the page?
        – Paul D. Waite
                Aug 04 '11 at 12:14
    

                    
                
                
            
        
    
    
                
            
            
            
            
                
                        
    
        
            
            3
            
            
        
    
    
        <section></section>

The HTML <section> element represents a generic section of a
  document, i.e., a thematic grouping of content, typically with a
  heading. Each <section> should be identified, typically by including
  a heading (<h1>-<h6> element) as a child of the <section>
  element. For Details Please following link.

References :
http://www.w3schools.com/tags/tag_section.asp
https://developer.mozilla.org/en/docs/Web/HTML/Element/section
<div></div>

The HTML <div> element (or HTML Document Division Element) is the
  generic container for flow content, which does not inherently
  represent anything. It can be used to group elements for styling
  purposes (using the class or id attributes), or because they share
  attribute values, such as lang. It should be used only when no other
  semantic element (such as <article> or <nav>) is appropriate.

References: 
- http://www.w3schools.com/tags/tag_div.asp
- https://developer.mozilla.org/en/docs/Web/HTML/Element/div
Here are some links that discuss more about the differences between them:
http://html5doctor.com/avoiding-common-html5-mistakes/
https://teamtreehouse.com/community/use-div-or-section-element
http://webdesign.about.com/od/html5tags/fl/div-vs-section.htm

        
        
            
                
                
                
                    
                        
                        

    edited Feb 03 '17 at 05:08
        
    
        Ashwin Krishnamurthy
        3,694
            3
            26
            49
        


                        
                    
                
                
                
                    
                    
                        

    answered May 16 '16 at 09:45
        
    
        Asad Ali
        395
            
            6
            22
        


                    
                    
                
            
        
    
    
        
    
    
                
            
            
            
            
                
                        
    
        
            
            1
            
            
        
    
    
        The <section> tag defines sections in a document, such as chapters, headers, footers, or any other sections of the document.
whereas:
The <div> tag defines a division or a section in an HTML document.
The <div> tag is used to group block-elements to format them with CSS.
        
        
            
                
                
                
                    
                        
                        

    edited May 11 '15 at 03:44
        
    
        steveax
        17,217
            6
            43
            59
        


                        
                    
                
                
                
                    
                    
                        

    answered May 11 '15 at 03:11
        
    
        Jeeves
        420
            1
            7
            24
        


                    
                    
                
            
        
    
    
        
        
            
                    
                        
                            2
                        
                    
                    
                    
    
    
        Headers, footers and other sections of the document have their own semantic tags. (``, ``, ``, `` etc.)
        – Oliver
                Feb 16 '17 at 00:52
    

                    
                
                
            
        
    
    
                
            
            
            
            
                
                        
    
        
            
            0
            
            
        
    
    
        Many web sites contain HTML code like: <div id=""nav""> <div class=""header""> <div id=""footer""> to indicate navigation, header, and footer. So <div> was used to define different parts of a web page in html4 but <div> doesn't mean anything particular therefore html5 introduced many semantic elements <section> is one of them which give enough information to screen readers, search engines and browsers etc, to identify the different part of websites.
the main difference is if you use only <div> to define website parts. it's less readable.
if you use semantic elements instead of div tag. they can help to improve readability of your website not only to humans for other programs(screen reader, search engine etc) also. we still can use <div> inside semantic elements as a container.
        
        
            
                
                
                
                    
                    
                        

    answered Aug 07 '22 at 13:06
        
    
        Bala
        414
            
            6
            15
        


                    
                    
                
            
        
    
    
        
    
    
                
            
            
            
            
                
                        
    
        
            
            -1
            
            
        
    
    
        Here is a tip on how I distinguish couple of recent html5 elements in the case of a web application (purely subjective). 
<section> marks a widget in a graphical user interface, whereas <div> is the container of the components of a widget like a container holding a button, and a label etc.
<article> groups widgets that share a purpose.
<header> is title and menubar.
<footer> is the statusbar.
        
        
            
                
                
                
                    
                    
                        

    answered Sep 18 '18 at 16:17
        
    
        Kaan E.
        515
            
            4
            14
        


                    
                    
                
            
        
    
    
        
        
            
                    
                        
                            9
                        
                    
                    
                    
    
    
        This is so wrong I'm not even sure where to start. You are assigning visual meaning to elements that have 0 visual meaning and are 100% semantic. If you replaced  and  in your comment with  then you would be correct.
        – Seth Warburton
                Jun 30 '20 at 13:19
    

                    
                
                
            
        
    
    
                
            
            
        
    
    
    
        
            

Linked


    
    1
    Why these blocks are positioned incorrectly, everything seems to be right?
    



    
    0
    make: *** No rule to make target `clean'. Stop
    



    
    1
    Bootstrap Column Alignment
    



    
    1
    What is Difference Between Section Tag in HTML5 and same section define in div class=""section""
    



    
    1
    Are <section>, <div>, and <span> all basically the same thing?
    



    
    0
    How to organize HTML5 structure for better practices and better code readability?
    



    
    2
    Difference between <section> and <div> in <aside> sidebar
    



    
    82
    How to properly use h1 in HTML5
    



    
    -1
    jQuery stops working when nesting div
    



    
    0
    Could <Section> and <div> be used interchangeably in html?
    



    
    6
    Is there any way to allow CSS margins to collapse through a fieldset boundary?
    



    
    -2
    What sort of tags, excluding div, can be used to make a login page with html5?
    



    
    0
    Technical differences of div vs section vs article
    



    
    0
    How to make a function set css width with a JavaScript variable?
    



    
    0
    What is the difference between the SECTION element and DIV element in HTML?
    



    
    2
    Header in semantic HTML5
    



    
    3
    What is the exact difference between <div> and <section>? Like I know Section has 'meaning' and div doesn't, but what does that mean?
    



    
    1
    Is the element <header> or <section> mechanically different than <div>?
    




        

        
            

Related


    
    1
    What is Difference Between Section Tag in HTML5 and same section define in div class=""section""
    



    
    1
    Are <section>, <div>, and <span> all basically the same thing?
    



    
    2
    Difference between <section> and <div> in <aside> sidebar
    



    
    1
    HTML section vs div and differences
    



    
    0
    What is the difference between the SECTION element and DIV element in HTML?
    



    
    3
    What is the exact difference between <div> and <section>? Like I know Section has 'meaning' and div doesn't, but what does that mean?
    



    
    1
    Is the element <header> or <section> mechanically different than <div>?
    




        
    
    

            ","What is the difference between <section> and <div> in HTML? Aren't we defining sections in both cases?","<section> means that the content inside is grouped (i.e. relates to a single theme), and should appear as an entry in an outline of the page.<div>, on the other hand, does not convey any meaning, aside from any found in its class, lang and title attributes.So no: using a <div> does not define a section in HTML.From the spec:<section>The <section> element represents a generic section of a document or application. A section, in this context, is a thematic grouping of content. Each section should be identified, typically by including a heading (h1-h6 element) as a child of the <section> element.Examples of sections would be chapters, the various tabbed pages in a tabbed dialog box, or the numbered sections of a thesis. A Web site’s home page could be split into sections for an introduction, news items, and contact information....The <section> element is not a generic container element. When an element is needed only for styling purposes or as a convenience for scripting, authors are encouraged to use the <div> element instead. A general rule is that the <section> element is appropriate only if the element’s contents would be listed explicitly in the document’s outline.(https://www.w3.org/TR/html/sections.html#the-section-element)<div>The <div> element has no special meaning at all. It represents its children. It can be used with the class, lang, and title attributes to mark up semantics common to a group of consecutive elements.Note: Authors are strongly encouraged to view the <div> element as an element of last resort, for when no other element is suitable. Use of more appropriate elements instead of the <div> element leads to better accessibility for readers and easier maintainability for authors.(https://www.w3.org/TR/html/grouping-content.html#the-div-element)Sections are most relevant in landmark navigation for assistive technology. To appear in the document outline or landmark list, they need a name, which can be assigned by means of aria-label, aria-labelledby or title:<section aria-labelledby=""s3-h2"">  <h2 id=""s3-h2"">Introduction</h2>  …For example VoiceOver on Mac then can provide an outline to navigate directly to that section."
"data_i","edited Sep 06 '22 at 22:03","
        How to force browsers to reload cached CSS and JS files?
    ","I have noticed that some browsers (in particular, Firefox and Opera) are very zealous in using cached copies of .css and .js files, even between browser sessions. This leads to a problem when you update one of these files, but the user's browser keeps on using the cached copy.What is the most elegant way of forcing the user's browser to reload the file when it has changed?Ideally, the solution would not force the browser to reload the file on every visit to the page.I have found John Millikin's and da5id's suggestion to be useful. It turns out there is a term for this: auto-versioning.I have posted a new answer below which is a combination of my original solution and John's suggestion.Another idea that was suggested by SCdF would be to append a bogus query string to the file. (Some Python code, to automatically use the timestamp as a bogus query string, was submitted by pi..)However, there is some discussion as to whether or not the browser would cache a file with a query string. (Remember, we want the browser to cache the file and use it on future visits. We only want it to fetch the file again when it has changed.)","This solution is written in PHP, but it should be easily adapted to other languages.The original .htaccess regex can cause problems with files like json-1.3.js. The solution is to only rewrite if there are exactly 10 digits at the end. (Because 10 digits covers all timestamps from 9/9/2001 to 11/20/2286.)First, we use the following rewrite rule in .htaccess:RewriteEngine onRewriteRule ^(.*)\.[\d]{10}\.(css|js)$ $1.$2 [L]Now, we write the following PHP function:/** *  Given a file, i.e. /css/base.css, replaces it with a string containing the *  file's mtime, i.e. /css/base.1221534296.css. * *  @param $file  The file to be loaded.  Must be an absolute path (i.e. *                starting with slash). */function auto_version($file){  if(strpos($file, '/') !== 0 || !file_exists($_SERVER['DOCUMENT_ROOT'] . $file))    return $file;  $mtime = filemtime($_SERVER['DOCUMENT_ROOT'] . $file);  return preg_replace('{\\.([^./]+)$}', "".$mtime.\$1"", $file);}Now, wherever you include your CSS, change it from this:<link rel=""stylesheet"" href=""/css/base.css"" type=""text/css"" />To this:<link rel=""stylesheet"" href=""<?php echo auto_version('/css/base.css'); ?>"" type=""text/css"" />This way, you never have to modify the link tag again, and the user will always see the latest CSS.  The browser will be able to cache the CSS file, but when you make any changes to your CSS the browser will see this as a new URL, so it won't use the cached copy.This can also work with images, favicons, and JavaScript. Basically anything that is not dynamically generated."
"data_i","edited Apr 16 '20 at 17:56","
        What is attr_accessor in Ruby?
    ","I am having a hard time understanding attr_accessor in Ruby.Can someone explain this to me?","Let's say you have a class Person.class Personendperson = Person.newperson.name # => no method errorObviously we never defined method name. Let's do that.class Person  def name    @name # simply returning an instance variable @name  endendperson = Person.newperson.name # => nilperson.name = ""Dennis"" # => no method errorAha, we can read the name, but that doesn't mean we can assign the name. Those are two different methods. The former is called reader and latter is called writer. We didn't create the writer yet so let's do that.class Person  def name    @name  end  def name=(str)    @name = str  endendperson = Person.newperson.name = 'Dennis'person.name # => ""Dennis""Awesome. Now we can write and read instance variable @name using reader and writer methods. Except, this is done so frequently, why waste time writing these methods every time? We can do it easier.class Person  attr_reader :name  attr_writer :nameendEven this can get repetitive. When you want both reader and writer just use accessor!class Person  attr_accessor :nameendperson = Person.newperson.name = ""Dennis""person.name # => ""Dennis""Works the same way! And guess what: the instance variable @name in our person object will be set just like when we did it manually, so you can use it in other methods.class Person  attr_accessor :name  def greeting    ""Hello #{@name}""  endendperson = Person.newperson.name = ""Dennis""person.greeting # => ""Hello Dennis""That's it. In order to understand how attr_reader, attr_writer, and attr_accessor methods actually generate methods for you, read other answers, books, ruby docs. "
"data_i","asked Feb 16 '17 at 12:22","
        In Typescript, what is the ! (exclamation mark / bang) operator when dereferencing a member?
    ","When looking at the sourcecode for a tslint rule, I came across the following statement:if (node.parent!.kind === ts.SyntaxKind.ObjectLiteralExpression) {    return;}Notice the ! operator after node.parent. Interesting!I first tried compiling the file locally with my currently installed version of TS (1.5.3). The resulting error pointed to the exact location of the bang:$ tsc --noImplicitAny memberAccessRule.ts noPublicModifierRule.ts(57,24): error TS1005: ')' expected.Next I upgraded to the latest TS (2.1.6), which compiled it without issue. So it seems to be feature of TS 2.x. But the transpilation ignored the bang completely, resulting in the following JS:if (node.parent.kind === ts.SyntaxKind.ObjectLiteralExpression) {    return;}My Google fu has thus far failed me. What is TS's exclamation mark operator, and how does it work?","That's the non-null assertion operator. It is a way to tell the compiler ""this expression cannot be null or undefined here, so don't complain about the possibility of it being null or undefined."" Sometimes the type checker is unable to make that determination itself.It is explained here:A new ! post-fix expression operator may be used to assert that its operand is non-null and non-undefined in contexts where the type checker is unable to conclude that fact. Specifically, the operation x! produces a value of the type of x with null and undefined excluded. Similar to type assertions of the forms <T>x and x as T, the ! non-null assertion operator is simply removed in the emitted JavaScript code.I find the use of the term ""assert"" a bit misleading in that explanation. It is ""assert"" in the sense that the developer is asserting it, not in the sense that a test is going to be performed. The last line indeed indicates that it results in no JavaScript code being emitted."
"data_i","edited Apr 11 '19 at 11:40","
        Create Git branch with current changes
    ","I started working on my master branch thinking that my task would be easy. After a while I realized it would take more work and I want to do all this work in a new branch.  How can I create a new branch and take all these changes with me without dirtying master?","If you hadn't made any commit yet, only (1: branch) and (3: checkout) would be enough.Or, in one command: git checkout -b newBranchWith Git 2.23+ (Q3 2019), the new command git switch would create the branch in one line (with the same kind of reset --hard, so beware of its effect):# First, save your work in progress!git stash# Then, one command to create *and* switch to a new branchgit switch -f -c topic/wip HEAD~3Or, as suggested in Alia's answer, use git switch -m, without git stash:git switch -c topic/wip -m--mergeIf you have local modifications to one or more files that are different between the current branch and the branch to which you are switching, the command refuses to switch branches in order to preserve your modifications in context.However, with this option, a three-way merge between the current branch, your working tree contents, and the new branch is done, and you will be on the new branch.When a merge conflict happens, the index entries for conflicting paths are left unmerged, and you need to resolve the conflicts and mark the resolved paths with git add (or git rm if the merge should result in deletion of the path).As mentioned in the git reset man page:$ git stash                # (0) Save your work in progress$ git branch topic/wip     # (1)$ git reset --hard HEAD~3  # (2)  NOTE: use $git reset --soft HEAD~3 (explanation below)$ git checkout topic/wip   # (3)You have made some commits, but realize they were premature to be in the ""master"" branch. You want to continue polishing them in a topic branch, so create ""topic/wip"" branch off of the current HEAD.Rewind the master branch to get rid of those three commits.Switch to ""topic/wip"" branch and keep working.Again: new way (since 2019 and Git2.23) to do all that in one command:git switch -f -c topic/wip HEAD~3Note: due to the ""destructive"" effect of a git reset --hard command (it does resets the index and working tree. Any changes to tracked files in the working tree since <commit> are discarded), I would rather go with:$ git reset --soft HEAD~3  # (2)This would make sure I'm not losing any private file (not added to the index).The --soft option won't touch the index file nor the working tree at all (but resets the head to <commit>, just like all modes do)."
"data_i","edited Jul 11 '22 at 00:05","
        How do I import other Python files?
    ","How do I import files in Python? I want to import:a file (e.g. file.py)a foldera file dynamically at runtime, based on user inputone specific part of a file (e.g. a single function)","There are many ways to import a python file, all with their pros and cons.Don't just hastily pick the first import strategy that works for you or else you'll have to rewrite the codebase later on when you find it doesn't meet your needs.  I'll start out explaining the easiest example #1, then I'll move toward the most professional and robust example #7Example 1, Import a python module with python interpreter:Put this in /home/el/foo/fox.py:def what_does_the_fox_say():  print(""vixens cry"")Get into the python interpreter: el@apollo:/home/el/foo$ pythonPython 2.7.3 (default, Sep 26 2013, 20:03:06) >>> import fox>>> fox.what_does_the_fox_say()vixens cry>>> You imported fox through the python interpreter, invoked the python function what_does_the_fox_say() from within fox.py.  Example 2, Use execfile or (exec in Python 3) in a script to execute the other python file in place:Put this in /home/el/foo2/mylib.py:def moobar():  print(""hi"")Put this in /home/el/foo2/main.py:execfile(""/home/el/foo2/mylib.py"")moobar()run the file:el@apollo:/home/el/foo$ python main.pyhiThe function moobar was imported from mylib.py and made available in main.pyExample 3, Use from ... import ... functionality:Put this in /home/el/foo3/chekov.py:def question():  print ""where are the nuclear wessels?""Put this in /home/el/foo3/main.py:from chekov import questionquestion()Run it like this:el@apollo:/home/el/foo3$ python main.py where are the nuclear wessels?If you defined other functions in chekov.py, they would not be available unless you import *Example 4, Import riaa.py if it's in a different file location from where it is importedPut this in /home/el/foo4/stuff/riaa.py:def watchout():  print ""computers are transforming into a noose and a yoke for humans""Put this in /home/el/foo4/main.py:import sys import ossys.path.append(os.path.abspath(""/home/el/foo4/stuff""))from riaa import *watchout()Run it:el@apollo:/home/el/foo4$ python main.py computers are transforming into a noose and a yoke for humansThat imports everything in the foreign file from a different directory.Example 5, use os.system(""python yourfile.py"")import osos.system(""python yourfile.py"")Example 6, import your file via piggybacking the python startuphook:Update: This example used to work for both python2 and 3, but now only works for python2.  python3 got rid of this user startuphook feature set because it was abused by low-skill python library writers, using it to impolitely inject their code into the global namespace, before all user-defined programs.  If you want this to work for python3, you'll have to get more creative.  If I tell you how to do it, python developers will disable that feature set as well, so you're on your own.  See: https://docs.python.org/2/library/user.htmlPut this code into your home directory in ~/.pythonrc.pyclass secretclass:    def secretmessage(cls, myarg):        return myarg + "" is if.. up in the sky, the sky""    secretmessage = classmethod( secretmessage )    def skycake(cls):        return ""cookie and sky pie people can't go up and ""    skycake = classmethod( skycake )Put this code into your main.py (can be anywhere):import usermsg = ""The only way skycake tates good"" msg = user.secretclass.secretmessage(msg)msg += user.secretclass.skycake()print(msg + "" have the sky pie! SKYCAKE!"")Run it, you should get this:$ python main.pyThe only way skycake tates good is if.. up in the sky, the skycookie and sky pie people can't go up and  have the sky pie! SKYCAKE!If you get an error here: ModuleNotFoundError: No module named 'user' then it means you're using python3, startuphooks are disabled there by default.Credit for this jist goes to: https://github.com/docwhat/homedir-examples/blob/master/python-commandline/.pythonrc.py  Send along your up-boats.Example 7, Most Robust: Import files in python with the bare import command:Make a new directory /home/el/foo5/Make a new directory /home/el/foo5/herpMake an empty file named __init__.py under herp:el@apollo:/home/el/foo5/herp$ touch __init__.pyel@apollo:/home/el/foo5/herp$ ls__init__.pyMake a new directory /home/el/foo5/herp/derpUnder derp, make another __init__.py file:el@apollo:/home/el/foo5/herp/derp$ touch __init__.pyel@apollo:/home/el/foo5/herp/derp$ ls__init__.pyUnder /home/el/foo5/herp/derp make a new file called yolo.py Put this in there:def skycake():  print ""SkyCake evolves to stay just beyond the cognitive reach of "" +  ""the bulk of men. SKYCAKE!!""The moment of truth, Make the new file /home/el/foo5/main.py, put this in there;from herp.derp.yolo import skycakeskycake()Run it:el@apollo:/home/el/foo5$ python main.pySkyCake evolves to stay just beyond the cognitive reach of the bulk of men. SKYCAKE!!The empty __init__.py file communicates to the python interpreter that the developer intends this directory to be an importable package.If you want to see my post on how to include ALL .py files under a directory see here: https://stackoverflow.com/a/20753073/445131"
"data_i","edited Jan 08 '16 at 12:58","
        Is there a regular expression to detect a valid regular expression?
    ","Is it possible to detect a valid regular expression with another regular expression?  If so please give example code below.","/^                                             # start of string(                                             # first group start  (?:    (?:[^?+*{}()[\]\\|]+                      # literals and ^, $     | \\.                                    # escaped characters     | \[ (?: \^?\\. | \^[^\\] | [^\\^] )     # character classes          (?: [^\]\\]+ | \\. )* \]     | \( (?:\?[:=!]|\?<[=!]|\?>)? (?1)?? \)  # parenthesis, with recursive content     | \(\? (?:R|[+-]?\d+) \)                 # recursive matching     )    (?: (?:[?+*]|\{\d+(?:,\d*)?\}) [?+]? )?   # quantifiers  | \|                                        # alternative  )*                                          # repeat content)                                             # end first group$                                             # end of string/This is a recursive regex, and is not supported by many regex engines. PCRE based ones should support it.Without whitespace and comments:/^((?:(?:[^?+*{}()[\]\\|]+|\\.|\[(?:\^?\\.|\^[^\\]|[^\\^])(?:[^\]\\]+|\\.)*\]|\((?:\?[:=!]|\?<[=!]|\?>)?(?1)??\)|\(\?(?:R|[+-]?\d+)\))(?:(?:[?+*]|\{\d+(?:,\d*)?\})[?+]?)?|\|)*)$/.NET does not support recursion directly. (The (?1) and (?R) constructs.) The recursion would have to be converted to counting balanced groups:^                                         # start of string(?:  (?: [^?+*{}()[\]\\|]+                   # literals and ^, $   | \\.                                  # escaped characters   | \[ (?: \^?\\. | \^[^\\] | [^\\^] )   # character classes        (?: [^\]\\]+ | \\. )* \]   | \( (?:\?[:=!]         | \?<[=!]         | \?>         | \?<[^\W\d]\w*>         | \?'[^\W\d]\w*'         )?                               # opening of group     (?<N>)                               #   increment counter   | \)                                   # closing of group     (?<-N>)                              #   decrement counter   )  (?: (?:[?+*]|\{\d+(?:,\d*)?\}) [?+]? )? # quantifiers| \|                                      # alternative)*                                        # repeat content$                                         # end of string(?(N)(?!))                                # fail if counter is non-zero.Compacted:^(?:(?:[^?+*{}()[\]\\|]+|\\.|\[(?:\^?\\.|\^[^\\]|[^\\^])(?:[^\]\\]+|\\.)*\]|\((?:\?[:=!]|\?<[=!]|\?>|\?<[^\W\d]\w*>|\?'[^\W\d]\w*')?(?<N>)|\)(?<-N>))(?:(?:[?+*]|\{\d+(?:,\d*)?\})[?+]?)?|\|)*$(?(N)(?!))From the comments:Will this validate substitutions and translations?It will validate just the regex part of substitutions and translations. s/<this part>/.../It is not theoretically possible to match all valid regex grammars with a regex. It is possible if the regex engine supports recursion, such as PCRE, but that can't really be called regular expressions any more.Indeed, a ""recursive regular expression"" is not a regular expression. But this an often-accepted extension to regex engines... Ironically, this extended regex doesn't match extended regexes.""In theory, theory and practice are the same. In practice, they're not."" Almost everyone who knows regular expressions knows that regular expressions does not support recursion. But PCRE and most other implementations support much more than basic regular expressions.using this with shell script in the grep command , it shows me some error.. grep: Invalid content of {} . I am making a script that could grep a code base to find all the files that contain regular expressionsThis pattern exploits an extension called recursive regular expressions. This is not supported by the POSIX flavor of regex. You could try with the -P switch, to enable the PCRE regex flavor.Regex itself ""is not a regular language and hence cannot be parsed by regular expression...""This is true for classical regular expressions. Some modern implementations allow recursion, which makes it into a Context Free language, although it is somewhat verbose for this task.I see where you're matching []()/\. and other special regex characters. Where are you allowing non-special characters? It seems like this will match ^(?:[\.]+)$, but not ^abcdefg$. That's a valid regex.[^?+*{}()[\]\\|] will match any single character, not part of any of the other constructs. This includes both literal (a - z), and certain special characters (^, $, .)."
"data_i","edited May 26 '11 at 17:13","
        Format number to always show 2 decimal places
    ","I would like to format my numbers to always display 2 decimal places, rounding where applicable.Examples:number     display------     -------1          1.001.341      1.341.345      1.35I have been using this: parseFloat(num).toFixed(2);But it's displaying 1 as 1, rather than 1.00.","(Math.round(num * 100) / 100).toFixed(2);Live Demovar num1 = ""1"";document.getElementById('num1').innerHTML = (Math.round(num1 * 100) / 100).toFixed(2);var num2 = ""1.341"";document.getElementById('num2').innerHTML = (Math.round(num2 * 100) / 100).toFixed(2);var num3 = ""1.345"";document.getElementById('num3').innerHTML = (Math.round(num3 * 100) / 100).toFixed(2);span {    border: 1px solid #000;    margin: 5px;    padding: 5px;}<span id=""num1""></span><span id=""num2""></span><span id=""num3""></span>Note that it will round to 2 decimal places, so the input 1.346 will return 1.35."
"data_i","edited Sep 14 '22 at 13:52","
        How to make links in a TextView clickable
    ","I have the following TextView defined:<TextView     android:layout_width=""wrap_content""    android:layout_height=""wrap_content"" android:text=""@string/txtCredits""    android:autoLink=""web"" android:id=""@+id/infoTxtCredits""    android:layout_centerInParent=""true""    android:linksClickable=""true""/>where @string/txtCredits is a string resource that contains <a href=""some site"">Link text</a>.Android is highlighting the links in the TextView, but they do not respond to clicks. What am I doing wrong?  Do I have to set an onClickListener for the TextView in my activity for something as simple as this?It looks like it has to do with the way I define my string resource.This does not work:<string name=""txtCredits""><a href=""http://www.google.com"">Google</a></string>But this does:<string name=""txtCredits"">www.google.com</string>Which is a bummer because I would much rather show a text link than show the full URL.","Buried in the API demos, I found the solution to my problem:File Link.java:    // text2 has links specified by putting <a> tags in the string    // resource.  By default these links will appear but not    // respond to user input.  To make them active, you need to    // call setMovementMethod() on the TextView object.    TextView t2 = (TextView) findViewById(R.id.text2);    t2.setMovementMethod(LinkMovementMethod.getInstance());I removed most of the attributes on my TextView to match what was in the demo.<TextView    android:id=""@+id/text2""    android:layout_width=""wrap_content""    android:layout_height=""wrap_content""    android:text=""@string/txtCredits""/>That solved it. It is pretty difficult to uncover and fix.Important: Don't forget to remove autoLink=""web"" if you are calling setMovementMethod()."
"data_i","edited Jun 15 '20 at 10:16","
        Get property value from string using reflection
    ","I am trying implement the Data transformation using Reflection1 example in my code.The GetSourceValue function has a switch comparing various types, but I want to remove these types and properties and have GetSourceValue get the value of the property using only a single string as the parameter.  I want to pass a class and property in the string and resolve the value of the property.Is this possible?1Web Archive version of original blog post"," public static object GetPropValue(object src, string propName) {     return src.GetType().GetProperty(propName).GetValue(src, null); }Of course, you will want to add validation and whatnot, but that is the gist of it."
"data_i","edited Apr 17 '15 at 23:55","
        Node.js + Nginx - What now?
    ","I've set up Node.js and Nginx on my server. Now I want to use it, but, before I start there are 2 questions:How should they work together? How should I handle the requests?There are 2 concepts for a Node.js server, which one is better:   a. Create a separate HTTP server for each website that needs it. Then load all JavaScript code at the start of the program, so the code is interpreted once.b. Create one single Node.js server which handles all Node.js requests. This reads the requested files and evals their contents. So the files are interpreted on each request, but the server logic is much simpler.It's not clear for me how to use Node.js correctly.","Nginx works as a front end server, which in this case proxies the requests to a node.js server. Therefore you need to setup an Nginx config file for node.This is what I have done in my Ubuntu box:Create the file yourdomain.example at /etc/nginx/sites-available/:vim /etc/nginx/sites-available/yourdomain.exampleIn it you should have something like:# the IP(s) on which your node server is running. I chose port 3000.upstream app_yourdomain {    server 127.0.0.1:3000;    keepalive 8;}# the nginx server instanceserver {    listen 80;    listen [::]:80;    server_name yourdomain.example www.yourdomain.example;    access_log /var/log/nginx/yourdomain.example.log;    # pass the request to the node.js server with the correct headers    # and much more can be added, see nginx config options    location / {      proxy_set_header X-Real-IP $remote_addr;      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;      proxy_set_header Host $http_host;      proxy_set_header X-NginX-Proxy true;      proxy_pass http://app_yourdomain/;      proxy_redirect off;    } }If you want Nginx (>= 1.3.13) to handle websocket requests as well, add the following lines in the location / section:proxy_http_version 1.1;proxy_set_header Upgrade $http_upgrade;proxy_set_header Connection ""upgrade"";Once you have this setup you must enable the site defined in the config file above:cd /etc/nginx/sites-enabled/ln -s /etc/nginx/sites-available/yourdomain.example yourdomain.exampleCreate your node server app at /var/www/yourdomain/app.js and run it at localhost:3000var http = require('http');http.createServer(function (req, res) {    res.writeHead(200, {'Content-Type': 'text/plain'});    res.end('Hello World\n');}).listen(3000, ""127.0.0.1"");console.log('Server running at http://127.0.0.1:3000/');Test for syntax mistakes:nginx -tRestart Nginx:sudo /etc/init.d/nginx restartLastly start the node server:cd /var/www/yourdomain/ && node app.jsNow you should see ""Hello World"" at yourdomain.exampleOne last note with to starting the node server: you should use some kind of monitoring system for the node daemon. There is an awesome tutorial on node with upstart and monit."
"data_i","edited Jan 07 '17 at 15:01","
        How do I use $scope.$watch and $scope.$apply in AngularJS?
    ","I don't understand how to use $scope.$watch and $scope.$apply. The official documentation isn't helpful.What I don't understand specifically:Are they connected to the DOM?How can I update DOM changes to the model?What is the connection point between them?I tried this tutorial, but it takes the understanding of $watch and $apply for granted.What do $apply and $watch do, and how do I use them appropriately?","You need to be aware about how AngularJS works in order to understand it.Digest cycle and $scopeFirst and foremost, AngularJS defines a concept of a so-called digest cycle. This cycle can be considered as a loop, during which AngularJS checks if there are any changes to all the variables watched by all the $scopes. So if you have $scope.myVar defined in your controller and this variable was marked for being watched, then you are implicitly telling AngularJS to monitor the changes on myVar in each iteration of the loop.A natural follow-up question would be: Is everything attached to $scope being watched? Fortunately, no. If you would watch for changes to every object in your $scope, then quickly a digest loop would take ages to evaluate and you would quickly run into performance issues. That is why the AngularJS team gave us two ways of declaring some $scope variable as being watched (read below).$watch helps to listen for $scope changesThere are two ways of declaring a $scope variable as being watched.By using it in your template via the expression <span>{{myVar}}</span>By adding it manually via the $watch serviceAd 1)This is the most common scenario and I'm sure you've seen it before, but you didn't know that this has created a watch in the background. Yes, it had! Using AngularJS directives (such as ng-repeat) can also create implicit watches.Ad 2)This is how you create your own watches. $watch service helps you to run some code when some value attached to the $scope has changed. It is rarely used, but sometimes is helpful. For instance, if you want to run some code each time 'myVar' changes, you could do the following:function MyController($scope) {    $scope.myVar = 1;    $scope.$watch('myVar', function() {        alert('hey, myVar has changed!');    });    $scope.buttonClicked = function() {        $scope.myVar = 2; // This will trigger $watch expression to kick in    };}$apply enables to integrate changes with the digest cycleYou can think of the $apply function as of an integration mechanism. You see, each time you change some watched variable attached to the $scope object directly, AngularJS will know that the change has happened. This is because AngularJS already knew to monitor those changes. So if it happens in code managed by the framework, the digest cycle will carry on.However, sometimes you want to change some value outside of the AngularJS world and see the changes propagate normally.Consider this - you have a $scope.myVar value which will be modified within a jQuery's $.ajax() handler. This will happen at some point in future. AngularJS can't wait for this to happen, since it hasn't been instructed to wait on jQuery.To tackle this, $apply has been introduced. It lets you start the digestion cycle explicitly. However, you should only use this to migrate some data to AngularJS (integration with other frameworks), but never use this method combined with regular AngularJS code, as AngularJS will throw an error then.How is all of this related to the DOM?Well, you should really follow the tutorial again, now that you know all this. The digest cycle will make sure that the UI and the JavaScript code stay synchronised, by evaluating every watcher attached to all $scopes as long as nothing changes. If no more changes happen in the digest loop, then it's considered to be finished.You can attach objects to the $scope object either explicitly in the Controller, or by declaring them in {{expression}} form directly in the view.Further readings:Make Your Own AngularJS, Part 1: Scopes And Digest"
"data_i","edited Jul 04 '14 at 20:44","
        LINQ query on a DataTable
    ","I'm trying to perform a LINQ query on a DataTable object and bizarrely I am finding that performing such queries on DataTables is not straightforward. For example:var results = from myRow in myDataTablewhere results.Field(""RowNo"") == 1select results;This is not allowed. How do I get something like this working?I'm amazed that LINQ queries are not allowed on DataTables!","You can't query against the DataTable's Rows collection, since DataRowCollection doesn't implement IEnumerable<T>. You need to use the AsEnumerable() extension for DataTable. Like so:var results = from myRow in myDataTable.AsEnumerable()where myRow.Field<int>(""RowNo"") == 1select myRow;And as @Keith says, you'll need to add a reference to System.Data.DataSetExtensionsAsEnumerable() returns IEnumerable<DataRow>. If you need to convert IEnumerable<DataRow> to a DataTable, use the CopyToDataTable() extension.Below is query with Lambda Expression,var result = myDataTable    .AsEnumerable()    .Where(myRow => myRow.Field<int>(""RowNo"") == 1);"
"data_i","edited Oct 02 '20 at 13:09","
        Get unique values from a list in python
    ","I want to get the unique values from the following list:['nowplaying', 'PBS', 'PBS', 'nowplaying', 'job', 'debate', 'thenandnow']The output which I require is:['nowplaying', 'PBS', 'job', 'debate', 'thenandnow']This code works:output = []for x in trends:    if x not in output:        output.append(x)print(output)is there a better solution I should use?","First declare your list properly, separated by commas. You can get the unique values by converting the list to a set.mylist = ['nowplaying', 'PBS', 'PBS', 'nowplaying', 'job', 'debate', 'thenandnow']myset = set(mylist)print(myset)If you use it further as a list, you should convert it back to a list by doing:mynewlist = list(myset)Another possibility, probably faster would be to use a set from the beginning, instead of a list. Then your code should be:output = set()for x in trends:    output.add(x)print(output)As it has been pointed out, sets do not maintain the original order. If you need that, you should look for an ordered set implementation (see this question for more)."
"data_i","edited Sep 22 '21 at 11:20","
        What's the difference between OpenID and OAuth?
    ","I'm really trying to understand the difference between OpenID and OAuth? Maybe they're two totally separate things?","OpenID is about authentication (ie. proving who you are), OAuth is about authorisation (ie. to grant access to functionality/data/etc.. without having to deal with the original authentication).OAuth could be used in external partner sites to allow access to protected data without them having to re-authenticate a user.The blog post ""OpenID versus OAuth from the user’s perspective"" has a simple comparison of the two from the user's perspective and ""OAuth-OpenID: You’re Barking Up the Wrong Tree if you Think They’re the Same Thing"" has more information about it."
"data_i","edited Jun 25 '18 at 15:03","
        What is the difference between canonical name, simple name and class name in Java Class?
    ","In Java, what is the difference between these:Object o1 = ....o1.getClass().getSimpleName();o1.getClass().getName();o1.getClass().getCanonicalName();I have checked the Javadoc multiple times and yet this never explains it well.I also ran a test and that didn't reflect any real meaning behind the way these methods are called.","If you're unsure about something, try writing a test first.I did this:class ClassNameTest {    public static void main(final String... arguments) {        printNamesForClass(            int.class,            ""int.class (primitive)"");        printNamesForClass(            String.class,            ""String.class (ordinary class)"");        printNamesForClass(            java.util.HashMap.SimpleEntry.class,            ""java.util.HashMap.SimpleEntry.class (nested class)"");        printNamesForClass(            new java.io.Serializable(){}.getClass(),            ""new java.io.Serializable(){}.getClass() (anonymous inner class)"");    }    private static void printNamesForClass(final Class<?> clazz, final String label) {        System.out.println(label + "":"");        System.out.println(""    getName():          "" + clazz.getName());        System.out.println(""    getCanonicalName(): "" + clazz.getCanonicalName());        System.out.println(""    getSimpleName():    "" + clazz.getSimpleName());        System.out.println(""    getTypeName():      "" + clazz.getTypeName()); // added in Java 8        System.out.println();    }}Prints:int.class (primitive):    getName():          int    getCanonicalName(): int    getSimpleName():    int    getTypeName():      intString.class (ordinary class):    getName():          java.lang.String    getCanonicalName(): java.lang.String    getSimpleName():    String    getTypeName():      java.lang.Stringjava.util.HashMap.SimpleEntry.class (nested class):    getName():          java.util.AbstractMap$SimpleEntry    getCanonicalName(): java.util.AbstractMap.SimpleEntry    getSimpleName():    SimpleEntry    getTypeName():      java.util.AbstractMap$SimpleEntrynew java.io.Serializable(){}.getClass() (anonymous inner class):    getName():          ClassNameTest$1    getCanonicalName(): null    getSimpleName():        getTypeName():      ClassNameTest$1There's an empty entry in the last block where getSimpleName returns an empty string.The upshot looking at this is:the name is the name that you'd use to dynamically load the class with, for example, a call to Class.forName with the default ClassLoader. Within the scope of a certain ClassLoader, all classes have unique names.the canonical name is the name that would be used in an import statement. It might be useful during toString or logging operations. When the javac compiler has complete view of a classpath, it enforces uniqueness of canonical names within it by clashing fully qualified class and package names at compile time. However JVMs must accept such name clashes, and thus canonical names do not uniquely identify classes within a ClassLoader. (In hindsight, a better name for this getter would have been getJavaName; but this method dates from a time when the JVM was used solely to run Java programs.)the simple name loosely identifies the class, again might be useful during toString or logging operations but is not guaranteed to be unique.the type name returns ""an informative string for the name of this type"", ""It's like toString: it's purely informative and has no contract value"". (as written by sir4ur0n)Also you can commonly reference the Java Language Specification documentation for these types technical Java API details:Here's the Java 11 Specification on this subject matter:  https://docs.oracle.com/javase/specs/jls/se11/html/jls-6.html#jls-6.7Example 6.7-2. and Example 6.7-2. goes over Fully Qualified Names and Fully Qualified Names v. Canonical Name respectively"
"data_i","edited Jun 01 '22 at 14:47","
        Parameterize an SQL IN clause
    ","How do I parameterize a query containing an IN clause with a variable number of arguments, like this one?SELECT * FROM Tags WHERE Name IN ('ruby','rails','scruffy','rubyonrails')ORDER BY Count DESCIn this query, the number of arguments could be anywhere from 1 to 5.I would prefer not to use a dedicated stored procedure for this (or XML), but if there is some elegant way specific to SQL Server 2008, I am open to that.","You can parameterize each value, so something like:string[] tags = new string[] { ""ruby"", ""rails"", ""scruffy"", ""rubyonrails"" };string cmdText = ""SELECT * FROM Tags WHERE Name IN ({0})"";string[] paramNames = tags.Select(    (s, i) => ""@tag"" + i.ToString()).ToArray();string inClause = string.Join("", "", paramNames);using (SqlCommand cmd = new SqlCommand(string.Format(cmdText, inClause))) {    for(int i = 0; i < paramNames.Length; i++) {       cmd.Parameters.AddWithValue(paramNames[i], tags[i]);    }}Which will give you:cmd.CommandText = ""SELECT * FROM Tags WHERE Name IN (@tag0, @tag1, @tag2, @tag3)""cmd.Parameters[""@tag0""] = ""ruby""cmd.Parameters[""@tag1""] = ""rails""cmd.Parameters[""@tag2""] = ""scruffy""cmd.Parameters[""@tag3""] = ""rubyonrails""No, this is not open to SQL injection. The only injected text into CommandText is not based on user input. It's solely based on the hardcoded ""@tag"" prefix, and the index of an array. The index will always be an integer, is not user generated, and is safe.The user inputted values are still stuffed into parameters, so there is no vulnerability there.Edit:Injection concerns aside, take care to note that constructing the command text to accomodate a variable number of parameters (as above) impede's SQL server's ability to take advantage of cached queries. The net result is that you almost certainly lose the value of using parameters in the first place (as opposed to merely inserting the predicate strings into the SQL itself).Not that cached query plans aren't valuable, but IMO this query isn't nearly complicated enough to see much benefit from it. While the compilation costs may approach (or even exceed) the execution costs, you're still talking milliseconds. If you have enough RAM, I'd expect SQL Server would probably cache a plan for the common counts of parameters as well. I suppose you could always add five parameters, and let the unspecified tags be NULL - the query plan should be the same, but it seems pretty ugly to me and I'm not sure that it'd worth the micro-optimization (although, on Stack Overflow - it may very well be worth it).Also, SQL Server 7 and later will auto-parameterize queries, so using parameters isn't really necessary from a performance standpoint - it is, however, critical from a security standpoint - especially with user inputted data like this."
"data_i","edited Mar 29 '22 at 19:33","
        How do I get the current absolute URL in Ruby on Rails?
    ","How can I get the current absolute URL in my Ruby on Rails view?The request.request_uri only returns the relative URL.","For Rails 3.2 or Rails 4+You should use request.original_url to get the current URL.  Source code on current repo found here.This method is documented at original_url method, but if you're curious, the implementation is:def original_url  base_url + original_fullpathendFor Rails 3:You can write ""#{request.protocol}#{request.host_with_port}#{request.fullpath}"", since request.url is now deprecated.For Rails 2:You  can write request.url instead of request.request_uri.  This combines the protocol (usually http://) with the host, and request_uri to give you the full address."
"data_i","edited Jul 29 '22 at 04:26","
        What is a cross-platform way to get the home directory?
    ","I need to get the location of the home directory of the current logged-on user. Currently, I've been using the following on Linux:os.getenv(""HOME"")However, this does not work on Windows. What is the correct cross-platform way to do this ?","You want to use os.path.expanduser.This will ensure it works on all platforms:from os.path import expanduserhome = expanduser(""~"")If you're on Python 3.5+ you can use pathlib.Path.home():from pathlib import Pathhome = str(Path.home())"
"data_i","edited Nov 26 '14 at 14:42","
        Download a file with Android, and showing the progress in a ProgressDialog
    ","I am trying to write a simple application that gets updated. For this I need a simple function that can download a file and show the current progress in a ProgressDialog. I know how to do the ProgressDialog, but I'm not sure how to display the current progress and how to download the file in the first place.","There are many ways to download files. Following I will post most common ways; it is up to you to decide which method is better for your app.Use AsyncTask and show the download progress in a dialog=============================================================This method will allow you to execute some background processes and update the UI at the same time (in this case, we'll update a progress bar).Imports:import android.os.PowerManager;import java.io.InputStream;import java.io.OutputStream;import java.io.FileOutputStream;import java.net.HttpURLConnection;This is an example code:// declare the dialog as a member field of your activityProgressDialog mProgressDialog;// instantiate it within the onCreate methodmProgressDialog = new ProgressDialog(YourActivity.this);mProgressDialog.setMessage(""A message"");mProgressDialog.setIndeterminate(true);mProgressDialog.setProgressStyle(ProgressDialog.STYLE_HORIZONTAL);mProgressDialog.setCancelable(true);// execute this when the downloader must be firedfinal DownloadTask downloadTask = new DownloadTask(YourActivity.this);downloadTask.execute(""the url to the file you want to download"");mProgressDialog.setOnCancelListener(new DialogInterface.OnCancelListener() {    @Override    public void onCancel(DialogInterface dialog) {        downloadTask.cancel(true); //cancel the task    }});The AsyncTask will look like this:// usually, subclasses of AsyncTask are declared inside the activity class.// that way, you can easily modify the UI thread from hereprivate class DownloadTask extends AsyncTask<String, Integer, String> {    private Context context;    private PowerManager.WakeLock mWakeLock;    public DownloadTask(Context context) {        this.context = context;    }    @Override    protected String doInBackground(String... sUrl) {        InputStream input = null;        OutputStream output = null;        HttpURLConnection connection = null;        try {            URL url = new URL(sUrl[0]);            connection = (HttpURLConnection) url.openConnection();            connection.connect();            // expect HTTP 200 OK, so we don't mistakenly save error report            // instead of the file            if (connection.getResponseCode() != HttpURLConnection.HTTP_OK) {                return ""Server returned HTTP "" + connection.getResponseCode()                        + "" "" + connection.getResponseMessage();            }            // this will be useful to display download percentage            // might be -1: server did not report the length            int fileLength = connection.getContentLength();            // download the file            input = connection.getInputStream();            output = new FileOutputStream(""/sdcard/file_name.extension"");            byte data[] = new byte[4096];            long total = 0;            int count;            while ((count = input.read(data)) != -1) {                // allow canceling with back button                if (isCancelled()) {                    input.close();                    return null;                }                total += count;                // publishing the progress....                if (fileLength > 0) // only if total length is known                    publishProgress((int) (total * 100 / fileLength));                output.write(data, 0, count);            }        } catch (Exception e) {            return e.toString();        } finally {            try {                if (output != null)                    output.close();                if (input != null)                    input.close();            } catch (IOException ignored) {            }            if (connection != null)                connection.disconnect();        }        return null;    }The method above (doInBackground) runs always on a background thread. You shouldn't do any UI tasks there. On the other hand, the onProgressUpdate and onPreExecute run on the UI thread, so there you can change the progress bar:    @Override    protected void onPreExecute() {        super.onPreExecute();        // take CPU lock to prevent CPU from going off if the user         // presses the power button during download        PowerManager pm = (PowerManager) context.getSystemService(Context.POWER_SERVICE);        mWakeLock = pm.newWakeLock(PowerManager.PARTIAL_WAKE_LOCK,             getClass().getName());        mWakeLock.acquire();        mProgressDialog.show();    }        @Override    protected void onProgressUpdate(Integer... progress) {        super.onProgressUpdate(progress);        // if we get here, length is known, now set indeterminate to false        mProgressDialog.setIndeterminate(false);        mProgressDialog.setMax(100);        mProgressDialog.setProgress(progress[0]);    }    @Override    protected void onPostExecute(String result) {        mWakeLock.release();        mProgressDialog.dismiss();        if (result != null)            Toast.makeText(context,""Download error: ""+result, Toast.LENGTH_LONG).show();        else            Toast.makeText(context,""File downloaded"", Toast.LENGTH_SHORT).show();    }}For this to run, you need the WAKE_LOCK permission.<uses-permission android:name=""android.permission.WAKE_LOCK"" />Download from Service========================The big question here is: how do I update my activity from a service?. In the next example we are going to use two classes you may not be aware of: ResultReceiver and IntentService. ResultReceiver is the one that will allow us to update our thread from a service; IntentService is a subclass of Service which spawns a thread to do background work from there (you should know that a Service runs actually in the same thread of your app; when you extends Service, you must manually spawn new threads to run CPU blocking operations).Download service can look like this:public class DownloadService extends IntentService {    public static final int UPDATE_PROGRESS = 8344;    public DownloadService() {        super(""DownloadService"");    }    @Override    protected void onHandleIntent(Intent intent) {        String urlToDownload = intent.getStringExtra(""url"");        ResultReceiver receiver = (ResultReceiver) intent.getParcelableExtra(""receiver"");        try {                        //create url and connect            URL url = new URL(urlToDownload);            URLConnection connection = url.openConnection();            connection.connect();            // this will be useful so that you can show a typical 0-100% progress bar            int fileLength = connection.getContentLength();            // download the file            InputStream input = new BufferedInputStream(connection.getInputStream());            String path = ""/sdcard/BarcodeScanner-debug.apk"" ;            OutputStream output = new FileOutputStream(path);            byte data[] = new byte[1024];            long total = 0;            int count;            while ((count = input.read(data)) != -1) {                total += count;                // publishing the progress....                Bundle resultData = new Bundle();                resultData.putInt(""progress"" ,(int) (total * 100 / fileLength));                receiver.send(UPDATE_PROGRESS, resultData);                output.write(data, 0, count);            }            // close streams             output.flush();            output.close();            input.close();        } catch (IOException e) {            e.printStackTrace();        }        Bundle resultData = new Bundle();        resultData.putInt(""progress"" ,100);        receiver.send(UPDATE_PROGRESS, resultData);    }}Add the service to your manifest:<service android:name="".DownloadService""/>And the activity will look like this:// initialize the progress dialog like in the first example// this is how you fire the downloadermProgressDialog.show();Intent intent = new Intent(this, DownloadService.class);intent.putExtra(""url"", ""url of the file to download"");intent.putExtra(""receiver"", new DownloadReceiver(new Handler()));startService(intent);Here is were ResultReceiver comes to play:private class DownloadReceiver extends ResultReceiver{    public DownloadReceiver(Handler handler) {        super(handler);    }    @Override    protected void onReceiveResult(int resultCode, Bundle resultData) {        super.onReceiveResult(resultCode, resultData);        if (resultCode == DownloadService.UPDATE_PROGRESS) {            int progress = resultData.getInt(""progress""); //get the progress            dialog.setProgress(progress);            if (progress == 100) {                dialog.dismiss();            }        }    }}2.1 Use Groundy libraryGroundy is a library that basically helps you run pieces of code in a background service, and it is based on the ResultReceiver concept shown above. This library is deprecated at the moment. This is how the whole code would look like:The activity where you are showing the dialog...public class MainActivity extends Activity {    private ProgressDialog mProgressDialog;    @Override    public void onCreate(Bundle savedInstanceState) {        super.onCreate(savedInstanceState);        setContentView(R.layout.main);        findViewById(R.id.btn_download).setOnClickListener(new View.OnClickListener() {            public void onClick(View view) {                String url = ((EditText) findViewById(R.id.edit_url)).getText().toString().trim();                Bundle extras = new Bundler().add(DownloadTask.PARAM_URL, url).build();                Groundy.create(DownloadExample.this, DownloadTask.class)                        .receiver(mReceiver)                        .params(extras)                        .queue();                mProgressDialog = new ProgressDialog(MainActivity.this);                mProgressDialog.setProgressStyle(ProgressDialog.STYLE_HORIZONTAL);                mProgressDialog.setCancelable(false);                mProgressDialog.show();            }        });    }    private ResultReceiver mReceiver = new ResultReceiver(new Handler()) {        @Override        protected void onReceiveResult(int resultCode, Bundle resultData) {            super.onReceiveResult(resultCode, resultData);            switch (resultCode) {                case Groundy.STATUS_PROGRESS:                    mProgressDialog.setProgress(resultData.getInt(Groundy.KEY_PROGRESS));                    break;                case Groundy.STATUS_FINISHED:                    Toast.makeText(DownloadExample.this, R.string.file_downloaded, Toast.LENGTH_LONG);                    mProgressDialog.dismiss();                    break;                case Groundy.STATUS_ERROR:                    Toast.makeText(DownloadExample.this, resultData.getString(Groundy.KEY_ERROR), Toast.LENGTH_LONG).show();                    mProgressDialog.dismiss();                    break;            }        }    };}A GroundyTask implementation used by Groundy to download the file and show the progress:public class DownloadTask extends GroundyTask {        public static final String PARAM_URL = ""com.groundy.sample.param.url"";    @Override    protected boolean doInBackground() {        try {            String url = getParameters().getString(PARAM_URL);            File dest = new File(getContext().getFilesDir(), new File(url).getName());            DownloadUtils.downloadFile(getContext(), url, dest, DownloadUtils.getDownloadListenerForTask(this));            return true;        } catch (Exception pokemon) {            return false;        }    }}And just add this to the manifest:<service android:name=""com.codeslap.groundy.GroundyService""/>It couldn't be easier I think. Just grab the latest jar from Github and you are ready to go. Keep in mind that Groundy's main purpose is to make calls to external REST apis in a background service and post results to the UI with easily. If you are doing something like that in your app, it could be really useful.2.2 Use https://github.com/koush/ionUse DownloadManager class (GingerBread and newer only)=============================================================GingerBread brought a new feature, DownloadManager, which allows you to download files easily and delegate the hard work of handling threads, streams, etc. to the system.First, let's see a utility method:/** * @param context used to check the device version and DownloadManager information * @return true if the download manager is available */public static boolean isDownloadManagerAvailable(Context context) {    if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.GINGERBREAD) {        return true;    }    return false;}Method's name explains it all. Once you are sure DownloadManager is available, you can do something like this:String url = ""url you want to download"";DownloadManager.Request request = new DownloadManager.Request(Uri.parse(url));request.setDescription(""Some descrition"");request.setTitle(""Some title"");// in order for this if to run, you must use the android 3.2 to compile your appif (Build.VERSION.SDK_INT >= Build.VERSION_CODES.HONEYCOMB) {    request.allowScanningByMediaScanner();    request.setNotificationVisibility(DownloadManager.Request.VISIBILITY_VISIBLE_NOTIFY_COMPLETED);}request.setDestinationInExternalPublicDir(Environment.DIRECTORY_DOWNLOADS, ""name-of-the-file.ext"");// get download service and enqueue fileDownloadManager manager = (DownloadManager) getSystemService(Context.DOWNLOAD_SERVICE);manager.enqueue(request);Download progress will be showing in the notification bar.Final thoughtsFirst and second methods are just the tip of the iceberg. There are lots of things you have to keep in mind if you want your app to be robust. Here is a brief list:You must check whether user has an internet connection availableMake sure you have the right permissions (INTERNET and WRITE_EXTERNAL_STORAGE); also ACCESS_NETWORK_STATE if you want to check internet availability.Make sure the directory were you are going to download files exist and has write permissions.If download is too big you may want to implement a way to resume the download if previous attempts failed.Users will be grateful if you allow them to interrupt the download.Unless you need detailed control of the download process, then consider using DownloadManager (3) because it already handles most of the items listed above.But also consider that your needs may change. For example, DownloadManager does no response caching. It will blindly download the same big file multiple times. There's no easy way to fix it after the fact. Where if you start with a basic HttpURLConnection (1, 2), then all you need is to add an HttpResponseCache. So the initial effort of learning the basic, standard tools can be a good investment.This class was deprecated in API level 26. ProgressDialog is a modaldialog, which prevents the user from interacting with the app. Insteadof using this class, you should use a progress indicator likeProgressBar, which can be embedded in your app's UI. Alternatively,you can use a notification to inform the user of the task's progress. For more details Link"
"data_i","edited Jun 29 '20 at 22:58","
        Collection was modified; enumeration operation may not execute
    ","I can't get to the bottom of this error, because when the debugger is attached, it does not seem to occur.Collection was modified; enumeration operation may not executeBelow is the code.This is a WCF server in a Windows service. The method NotifySubscribers() is called by the service whenever there is a data event (at random intervals, but not very often - about 800 times per day).When a Windows Forms client subscribes, the subscriber ID is added to the subscribers dictionary, and when the client unsubscribes, it is deleted from the dictionary. The error happens when (or after) a client unsubscribes. It appears that the next time the NotifySubscribers() method is called, the foreach() loop fails with the error in the subject line. The method writes the error into the application log as shown in the code below. When a debugger is attached and a client unsubscribes, the code executes fine.Do you see a problem with this code? Do I need to make the dictionary thread-safe?[ServiceBehavior(InstanceContextMode=InstanceContextMode.Single)]public class SubscriptionServer : ISubscriptionServer{    private static IDictionary<Guid, Subscriber> subscribers;    public SubscriptionServer()    {                    subscribers = new Dictionary<Guid, Subscriber>();    }    public void NotifySubscribers(DataRecord sr)    {        foreach(Subscriber s in subscribers.Values)        {            try            {                s.Callback.SignalData(sr);            }            catch (Exception e)            {                DCS.WriteToApplicationLog(e.Message,                   System.Diagnostics.EventLogEntryType.Error);                UnsubscribeEvent(s.ClientId);            }        }    }        public Guid SubscribeEvent(string clientDescription)    {        Subscriber subscriber = new Subscriber();        subscriber.Callback = OperationContext.Current.                GetCallbackChannel<IDCSCallback>();        subscribers.Add(subscriber.ClientId, subscriber);                return subscriber.ClientId;    }    public void UnsubscribeEvent(Guid clientId)    {        try        {            subscribers.Remove(clientId);        }        catch(Exception e)        {            System.Diagnostics.Debug.WriteLine(""Unsubscribe Error "" +                     e.Message);        }    }}","What's likely happening is that SignalData is indirectly changing the subscribers dictionary under the hood during the loop and leading to that message.  You can verify this by changingforeach(Subscriber s in subscribers.Values)Toforeach(Subscriber s in subscribers.Values.ToList())If I'm right, the problem will disappear.Calling subscribers.Values.ToList() copies the values of subscribers.Values to a separate list at the start of the foreach. Nothing else has access to this list (it doesn't even have a variable name!), so nothing can modify it inside the loop."
"data_i","edited Jan 20 '20 at 09:21","
        How do I kill the process currently using a port on localhost in Windows?
    ","How can I remove the current process/application which is already assigned to a port?For example: localhost:8080","Step 1:Open up cmd.exe (note: you may need to run it as an administrator, but this isn't always necessary), then run the below command:netstat -ano | findstr :<PORT>(Replace <PORT> with the port number you want, but keep the colon)The area circled in red shows the PID (process identifier). Locate the PID of the process that's using the port you want.Step 2:Next, run the following command:taskkill /PID <PID> /F(No colon this time)Lastly, you can check whether the operation succeeded or not by re-running the command in ""Step 1"". If it was successful you shouldn't see any more search results for that port number."
"data_i","edited May 06 '22 at 13:49","
        React-router URLs don't work when refreshing or writing manually
    ","I'm using React-router and it works fine while I'm clicking on link buttons, but when I refresh my webpage it does not load what I want.For instance, I am in localhost/joblist and everything is fine because I arrived here pressing a link. But if I refresh the webpage I get:Cannot GET /joblistBy default, it didn't work like this. Initially I had my URL as localhost/#/ and localhost/#/joblist and they worked perfectly fine. But I don't like this kind of URL, so trying to erase that #, I wrote:Router.run(routes, Router.HistoryLocation, function (Handler) { React.render(<Handler/>, document.body);});This problem does not happen with localhost/, this one always returns what I want.This app is single-page, so /joblist doesn't need to ask anything to any server.My entire router.var routes = (    <Route name=""app"" path=""/"" handler={App}>        <Route name=""joblist"" path=""/joblist"" handler={JobList}/>        <DefaultRoute handler={Dashboard}/>        <NotFoundRoute handler={NotFound}/>    </Route>);Router.run(routes, Router.HistoryLocation, function (Handler) {  React.render(<Handler/>, document.body);});","Server-side vs Client-sideThe first big thing to understand about this is that there are now 2 places where the URL is interpreted, whereas there used to be only 1 in 'the old days'. In the past, when life was simple, some user sent a request for http://example.com/about to the server, which inspected the path part of the URL, determined the user was requesting the about page, and then sent back that page.With client-side routing, which is what React Router provides, things are less simple. At first, the client does not have any JavaScript code loaded yet. So the very first request will always be to the server. That will then return a page that contains the needed script tags to load React and React Router, etc. Only when those scripts have loaded does phase 2 start. In phase 2, when the user clicks on the 'About us' navigation link, for example, the URL is changed locally only to http://example.com/about (made possible by the History API), but no request to the server is made.  Instead, React Router does its thing on the client-side, determines which React view to render, and renders it. Assuming your about page does not need to make any REST calls, it's done already. You have transitioned from Home to About Us without any server request having fired.So basically when you click a link, some JavaScript runs that manipulates the URL in the address bar, without causing a page refresh, which in turn causes React Router to perform a page transition on the client-side.But now consider what happens if you copy-paste the URL in the address bar and e-mail it to a friend. Your friend has not loaded your website yet. In other words, she is still in phase 1. No React Router is running on her machine yet. So her browser will make a server request to http://example.com/about.And this is where your trouble starts. Until now, you could get away with just placing a static HTML at the webroot of your server. But that would give 404 errors for all other URLs when requested from the server. Those same URLs work fine on the client-side, because there React Router is doing the routing for you, but they fail on the server-side unless you make your server understand them.Combining server- and client-side routingIf you want the http://example.com/about URL to work on both the server- and the client-side, you need to set up routes for it on both the server- and the client-side. It makes sense, right?And this is where your choices begin. Solutions range from bypassing the problem altogether, via a catch-all route that returns the bootstrap HTML, to the full-on isomorphic approach where both the server and the client run the same JavaScript code.Bypassing the problem altogether: Hash HistoryWith Hash History, instead of Browser History, your URL for the about page would look something like this:http://example.com/#/aboutThe part after the hash (#) symbol is not sent to the server. So the server only sees http://example.com/ and sends the index page as expected. React Router will pick up the #/about part and show the correct page.Downsides:'ugly' URLsServer-side rendering is not possible with this approach. As far as search engine optimization (SEO) is concerned, your website consists of a single page with hardly any content on it.Catch-allWith this approach, you do use the Browser History, but just set up a catch-all on the server that sends /* to index.html, effectively giving you much the same situation as with Hash History. You do have clean URLs however and you could improve upon this scheme later without having to invalidate all your user's favorites.Downsides:More complex to set upStill no good SEOHybridIn the hybrid approach, you expand upon the catch-all scenario by adding specific scripts for specific routes. You could make some simple PHP scripts to return the most important pages of your site with content included, so Googlebot can at least see what's on your page.Downsides:Even more complex to set upOnly good SEO for those routes you give the special treatmentDuplicating code for rendering content on server and clientIsomorphicWhat if we use Node.js as our server so we can run the same JavaScript code on both ends? Now, we have all our routes defined in a single react-router configuration and we don't need to duplicate our rendering code. This is 'the holy grail' so to speak. The server sends the exact same markup as we would end up with if the page transition had happened on the client. This solution is optimal in terms of SEO.Downsides:Server must (be able to) run JavaScript. I've experimented with Java in conjunction with Nashorn, but it's not working for me. In practice, it mostly means you must use a Node.js based server.Many tricky environmental issues (using window on server-side, etc.)Steep learning curveWhich should I use?Choose the one that you can get away with. Personally, I think the catch-all is simple enough to set up, so that would be my minimum. This setup allows you to improve on things over time. If you are already using Node.js as your server platform, I'd definitely investigate doing an isomorphic app. Yes, it's tough at first, but once you get the hang of it it's actually a very elegant solution to the problem.So basically, for me, that would be the deciding factor. If my server runs on Node.js, I'd go isomorphic; otherwise, I would go for the Catch-all solution and just expand on it (Hybrid solution) as time progresses and SEO requirements demand it.If you'd like to learn more about isomorphic (also called 'universal') rendering with React, there are some good tutorials on the subject:React to the future with isomorphic appsThe Pain and the Joy of creating isomorphic apps in ReactJSHow to Implement Node + React Isomorphic JavaScript & Why it MattersAlso, to get you started, I recommend looking at some starter kits. Pick one that matches your choices for the technology stack (remember, React is just the V in MVC, you need more stuff to build a full app). Start with looking at the one published by Facebook itself:Create React AppOr pick one of the many by the community. There is a nice site now that tries to index all of them:Pick your perfect React starter projectI started with these:React Isomorphic StarterkitReact Redux Universal Hot ExampleCurrently, I am using a homebrewed version of universal rendering that was inspired by the two starter kits above, but they are out of date now.Good luck with your quest!"
"data_i","edited Jul 27 '20 at 11:49","
        How can you encode a string to Base64 in JavaScript?
    ","I have a PHP script that can encode a PNG image to a Base64 string.I'd like to do the same thing using JavaScript. I know how to open files, but I'm not sure how to do the encoding. I'm not used to working with binary data.","You can use btoa() and atob() to convert to and from base64 encoding.There appears to be some confusion in the comments regarding what these functions accept/return, so…btoa() accepts a “string” where each character represents an 8-bit byte – if you pass a string containing characters that can’t be represented in 8 bits, it will probably break. This isn’t a problem if you’re actually treating the string as a byte array, but if you’re trying to do something else then you’ll have to encode it first.atob() returns a “string” where each character represents an 8-bit byte – that is, its value will be between 0 and 0xff. This does not mean it’s ASCII – presumably if you’re using this function at all, you expect to be working with binary data and not text.See also:How do I load binary image data using Javascript and XMLHttpRequest?Most comments here are outdated. You can probably use both btoa() and atob(), unless you support really outdated browsers.Check here:https://caniuse.com/?search=atobhttps://caniuse.com/?search=btoa"
"data_i","edited Jan 02 '17 at 00:16","
        What is the difference between public, private, and protected?
    ","When and why should I use public, private, and protected functions and variables inside a class? What is the difference between them?Examples:// Publicpublic $variable;public function doSomething() {  // ...}// Privateprivate $variable;private function doSomething() {  // ...}// Protectedprotected $variable;protected function doSomething() {  // ...}","You use:public scope to make that property/method available from anywhere, other classes and instances of the object.private scope when you want your property/method to be visible in its own class only.protected scope when you want to make your property/method visible in all classes that extend current class including the parent class.If you don't use any visibility modifier, the property / method will be public.More: (For comprehensive information)PHP Manual - Visibility"
"data_i","edited Sep 24 '11 at 05:47","
        Why would a JavaScript variable start with a dollar sign?
    ","I quite often see JavaScript with variables that start with a dollar sign. When/why would you choose to prefix a variable in this way?(I'm not asking about $('p.foo') syntax that you see in jQuery and others, but normal variables like $name and $order)","Very common use in jQuery is to distinguish jQuery objects stored in variables from other variables.  For example, I would define:var $email = $(""#email""); // refers to the jQuery object representation of the dom objectvar email_field = $(""#email"").get(0); // refers to the dom object itselfI find this to be very helpful in writing jQuery code and makes it easy to see jQuery objects which have a different set of properties."
"data_i","edited Feb 06 '18 at 14:54","
        How to get the browser to navigate to URL in JavaScript
    ","What is the best (correct, modern, cross-browser, safe) way to get a web browser to navigate to a URL of your choice using JavaScript?","This works in all browsers:window.location.href = '...';If you wanted to change the page without it reflecting in the browser back history, you can do:window.location.replace('...');"
"data_i","edited Oct 29 '18 at 14:02","
        What is the difference between old style and new style classes in Python?
    ","What is the difference between old style and new style classes in Python?  When should I use one or the other?","From New-style and classic classes:Up to Python 2.1, old-style classes were the only flavour available to the user.The concept of (old-style) class is unrelated to the concept of type:  if x is an instance of an old-style class, then x.__class__  designates the class of x, but type(x) is always <type  'instance'>. This reflects the fact that all old-style instances, independently of  their class, are implemented with a single built-in type, called  instance.New-style classes were introduced in Python 2.2 to unify the concepts of class and type.   A new-style class is simply a user-defined type, no more, no less.If x is an instance of a new-style class, then type(x) is typically  the same as x.__class__ (although this is not guaranteed – a  new-style class instance is permitted to override the value returned  for x.__class__).The major motivation for introducing new-style classes is to provide a unified object model with a full meta-model. It also has a number of immediate benefits, like the ability to  subclass most built-in types, or the introduction of ""descriptors"",  which enable computed properties.For compatibility reasons, classes are still old-style by default. New-style classes are created by specifying another new-style class  (i.e. a type) as a parent class, or the ""top-level type"" object if no  other parent is needed. The behaviour of new-style classes differs from that of old-style  classes in a number of important details in addition to what type  returns. Some of these changes are fundamental to the new object model, like  the way special methods are invoked. Others are ""fixes"" that could not  be implemented before for compatibility concerns, like the method  resolution order in case of multiple inheritance.Python 3 only has new-style classes. No matter if you subclass from object or not, classes are new-style  in Python 3."
"data_i","edited Jan 22 '20 at 17:05","
        WebSockets vs. Server-Sent events/EventSource
    ","Both WebSockets and Server-Sent Events are capable of pushing data to browsers. To me they seem to be competing technologies. What is the difference between them? When would you choose one over the other?","Websockets and SSE (Server Sent Events) are both capable of pushing data to browsers, however they are not competing technologies. Websockets connections can both send data to the browser and receive data from the browser. A good example of an application that could use websockets is a chat application.SSE connections can only push data to the browser. Online stock quotes, or twitters updating timeline or feed are good examples of an application that could benefit from SSE.In practice since everything that can be done with SSE can also be done with Websockets, Websockets is getting a lot more attention and love, and many more browsers support Websockets than SSE.However, it can be overkill for some types of application, and the backend could be easier to implement with a protocol such as SSE. Furthermore SSE can be polyfilled into older browsers that do not support it natively using just JavaScript. Some implementations of SSE polyfills can be found on the Modernizr github page.Gotchas:SSE suffers from a limitation to the maximum number of open connections, which can be specially painful when opening various tabs as the limit is per browser and set to a very low number (6). The issue has been marked as ""Won't fix"" in Chrome and Firefox. This limit is per browser + domain, so that means that you can open 6 SSE connections across all of the tabs to www.example1.com and another 6 SSE connections to www.example2.com (thanks Phate).Only WS can transmit both binary data and UTF-8, SSE is limited to UTF-8. (Thanks to Chado Nihi).Some enterprise firewalls with packet inspection have trouble dealing with WebSockets (Sophos XG Firewall, WatchGuard, McAfee Web Gateway).HTML5Rocks has some good information on SSE. From that page:Server-Sent Events vs. WebSocketsWhy would you choose Server-Sent Events over WebSockets? Good question.One reason SSEs have been kept in the shadow is because later APIs like WebSockets provide a richer protocol to perform bi-directional, full-duplex communication. Having a two-way channel is more attractive for things like games, messaging apps, and for cases where you need near real-time updates in both directions. However, in some scenarios data doesn't need to be sent from the client. You simply need updates from some server action. A few examples would be friends' status updates, stock tickers, news feeds, or other automated data push mechanisms (e.g. updating a client-side Web SQL Database or IndexedDB object store). If you'll need to send data to a server, XMLHttpRequest is always a friend.SSEs are sent over traditional HTTP. That means they do not require a special protocol or server implementation to get working. WebSockets on the other hand, require full-duplex connections and new Web Socket servers to handle the protocol. In addition, Server-Sent Events have a variety of features that WebSockets lack by design such as automatic reconnection, event IDs, and the ability to send arbitrary events.TLDR summary:Advantages of SSE over Websockets:Transported over simple HTTP instead of a custom protocolCan be poly-filled with javascript to ""backport"" SSE to browsers that do not support it yet.Built in support for re-connection and event-idSimpler protocolNo trouble with corporate firewalls doing packet inspectionAdvantages of Websockets over SSE:Real time, two directional communication.Native support in more browsersIdeal use cases of SSE:Stock ticker streamingtwitter feed updatingNotifications to browserSSE gotchas:No binary supportMaximum open connections limit "
"data_i","edited Jun 23 '17 at 21:36","
        How can I make Bootstrap columns all the same height?
    ","I'm using Bootstrap. How can I make three columns all the same height?Here is a screenshot of the problem. I would like the blue and red columns to be the same height as the yellow column. Here is the code: <link href=""https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css"" rel=""stylesheet""/><div class=""container-fluid""><div class=""row"">    <div class=""col-xs-4 panel"" style=""background-color: red"">        some content    </div>    <div class=""col-xs-4 panel"" style=""background-color: yellow"">        catz        <img width=""100"" height=""100"" src=""https://lorempixel.com/100/100/cats/"">    </div>    <div class=""col-xs-4 panel"" style=""background-color: blue"">        some more content    </div></div></div>","LATEST SOLUTION (2022)Solution 4 using Bootstrap 4 or 5Bootstrap 4 and 5 use Flexbox by default, so there is no need for extra CSS.Demo<div class=""container"">    <div class=""row "">        <div class=""col-md-4"" style=""background-color: red"">          some content        </div>        <div class=""col-md-4"" style=""background-color: yellow"">          catz          <img width=""100"" height=""100"" src=""https://placekitten.com/100/100/"">        </div>        <div class=""col-md-4"" style=""background-color: green"">          some more content        </div>    </div></div>Solution 1 using negative margins (doesn't break responsiveness)Demo.row{    overflow: hidden; }[class*=""col-""]{    margin-bottom: -99999px;    padding-bottom: 99999px;}Solution 2 using tableDemo.row {    display: table;}[class*=""col-""] {    float: none;    display: table-cell;    vertical-align: top;}Solution 3 using flex added August 2015. Comments posted before this don't apply to this solution.Demo.row {  display: -webkit-box;  display: -webkit-flex;  display: -ms-flexbox;  display:         flex;  flex-wrap: wrap;}.row > [class*='col-'] {  display: flex;  flex-direction: column;}"
"data_i","edited Jan 21 '21 at 10:07","
        How to sort an object array by date property?
    ","Say I have an array of a few objects:var array = [{id: 1, date: Mar 12 2012 10:00:00 AM}, {id: 2, date: Mar 8 2012 08:00:00 AM}];How can I sort this array by the date element in order from the date closest to the current date and time down? Keep in mind that the array may have many objects, but for the sake of simplicity I used 2.Would I use the sort function and a custom comparator?","Simplest Answerarray.sort(function(a,b){  // Turn your strings into dates, and then subtract them  // to get a value that is either negative, positive, or zero.  return new Date(b.date) - new Date(a.date);});More Generic Answerarray.sort(function(o1,o2){  if (sort_o1_before_o2)    return -1;  else if(sort_o1_after_o2) return  1;  else                      return  0;});Or more tersely:array.sort(function(o1,o2){  return sort_o1_before_o2 ? -1 : sort_o1_after_o2 ? 1 : 0;});Generic, Powerful AnswerDefine a custom non-enumerable sortBy function using a Schwartzian transform on all arrays :(function(){  if (typeof Object.defineProperty === 'function'){    try{Object.defineProperty(Array.prototype,'sortBy',{value:sb}); }catch(e){}  }  if (!Array.prototype.sortBy) Array.prototype.sortBy = sb;  function sb(f){    for (var i=this.length;i;){      var o = this[--i];      this[i] = [].concat(f.call(o,o,i),o);    }    this.sort(function(a,b){      for (var i=0,len=a.length;i<len;++i){        if (a[i]!=b[i]) return a[i]<b[i]?-1:1;      }      return 0;    });    for (var i=this.length;i;){      this[--i]=this[i][this[i].length-1];    }    return this;  }})();Use it like so:array.sortBy(function(o){ return o.date });If your date is not directly comparable, make a comparable date out of it, e.g.array.sortBy(function(o){ return new Date( o.date ) });You can also use this to sort by multiple criteria if you return an array of values:// Sort by date, then score (reversed), then namearray.sortBy(function(o){ return [ o.date, -o.score, o.name ] };See http://phrogz.net/JS/Array.prototype.sortBy.js for more details."
"data_i","edited Oct 22 '16 at 13:01","
        Static Classes In Java
    ","Is there anything like static class in java?What is the meaning of such a class. Do all the methods of the static class need to be static too?Is it required the other way round, that if a class contains all the static methods, shall the class be static too?What are static classes good  for?","Java has static nested classes but it sounds like you're looking for a top-level static class. Java has no way of making a top-level class static but you can simulate a static class like this:Declare your class final - Prevents extension of the class since extending a static class makes no senseMake the constructor private - Prevents instantiation by client code as it makes no sense to instantiate a static classMake all the members and functions of the class static -  Since the class cannot be instantiated no instance methods can be called or instance fields accessedNote that the compiler will not prevent you from declaring an instance (non-static) member. The issue will only show up if you attempt to call the instance memberSimple example per suggestions from above:public class TestMyStaticClass {     public static void main(String []args){        MyStaticClass.setMyStaticMember(5);        System.out.println(""Static value: "" + MyStaticClass.getMyStaticMember());        System.out.println(""Value squared: "" + MyStaticClass.squareMyStaticMember());        // MyStaticClass x = new MyStaticClass(); // results in compile time error     }}// A top-level Java class mimicking static class behaviorpublic final class MyStaticClass {    private MyStaticClass () { // private constructor        myStaticMember = 1;    }    private static int myStaticMember;    public static void setMyStaticMember(int val) {        myStaticMember = val;    }    public static int getMyStaticMember() {        return myStaticMember;    }    public static int squareMyStaticMember() {        return myStaticMember * myStaticMember;    }}What good are static classes? A good use of a static class is in defining one-off, utility and/or library classes where instantiation would not make sense. A great example is the Math class that contains some mathematical constants such as PI and E and simply provides mathematical calculations. Requiring instantiation in such a case would be unnecessary and confusing. See the Math class and source code. Notice that it is final and all of its members are static. If Java allowed top-level classes to be declared static then the Math class would indeed be static."
"data_i","edited Apr 16 '20 at 08:09","
        What is the difference between angular-route and angular-ui-router?
    ","I'm planning to use AngularJS in my big applications. So I'm in the process to find out the right modules to use.What is the difference between ngRoute (angular-route.js) and ui-router (angular-ui-router.js) modules?In many articles when ngRoute is used, route is configured with $routeProvider. However, when used with ui-router, route is configured with $stateProvider and $urlRouterProvider. Which module should I use for better manageability and extensibility?","ui-router is a 3rd-party module and is very powerful.  It supports everything the normal ngRoute can do as well as many extra functions.Here are some common reason ui-router is chosen over ngRoute:ui-router allows for nested views and multiple named views.  This is very useful with larger app where you may have pages that inherit from other sections.ui-router allows for you to have strong-type linking between states based on state names.  Change the url in one place will update every link to that state when you build your links with ui-sref. Very useful for larger projects where URLs might change.There is also the concept of the decorator which could be used to allow your routes to be dynamically created based on the URL that is trying to be accessed. This could mean that you will not need to specify all of your routes before hand.states allow you to map and access different information about different states and you can easily pass information between states via $stateParams.You can easily determine if you are in a state or parent of a state to adjust UI element (highlighting the navigation of the current state) within your templates via $state provided by ui-router which you can expose via setting it in $rootScope on run.In essence, ui-router is ngRouter with more features, under the sheets it is quite different. These additional features are very useful for larger applications.More Information:Github: https://github.com/angular-ui/ui-routerDocumentation:API Reference: http://angular-ui.github.io/ui-router/site/#/apiGuide: https://github.com/angular-ui/ui-router/wikiFAQs: https://github.com/angular-ui/ui-router/wiki/Frequently-Asked-QuestionsSample Application: http://angular-ui.github.io/ui-router/sample/#/ "
"data_i","edited Apr 10 '22 at 12:32","
        How to sort a list of objects based on an attribute of the objects?
    ","I have a list of Python objects that I want to sort by a specific attribute of each object:>>> ut[Tag(name=""toe"", count=10), Tag(name=""leg"", count=2), ...]How do I sort the list by .count in descending order?","# To sort the list in place...ut.sort(key=lambda x: x.count, reverse=True)# To return a new list, use the sorted() built-in function...newlist = sorted(ut, key=lambda x: x.count, reverse=True)More on sorting by keys. "
"data_i","edited May 05 '22 at 21:46","
        :: (double colon) operator in Java 8
    ","I was exploring the Java 8 source and found this particular part of code very surprising:// Defined in IntPipeline.java@Overridepublic final OptionalInt reduce(IntBinaryOperator op) {    return evaluate(ReduceOps.makeInt(op));}@Overridepublic final OptionalInt max() {    return reduce(Math::max); // This is the gotcha line}// Defined in Math.javapublic static int max(int a, int b) {    return (a >= b) ? a : b;}Is Math::max something like a method pointer? How does a normal static method get converted to IntBinaryOperator?","Usually, one would call the reduce method using Math.max(int, int) as follows:reduce(new IntBinaryOperator() {    int applyAsInt(int left, int right) {        return Math.max(left, right);    }});That requires a lot of syntax for just calling Math.max. That's where lambda expressions come into play. Since Java 8 it is allowed to do the same thing in a much shorter way:reduce((int left, int right) -> Math.max(left, right));How does this work? The java compiler ""detects"", that you want to implement a method that accepts two ints and returns one int. This is equivalent to the formal parameters of the one and only method of interface IntBinaryOperator (the parameter of method reduce you want to call). So the compiler does the rest for you - it just assumes you want to implement IntBinaryOperator.But as Math.max(int, int) itself fulfills the formal requirements of IntBinaryOperator, it can be used directly. Because Java 7 does not have any syntax that allows a method itself to be passed as an argument (you can only pass method results, but never method references), the :: syntax was introduced in Java 8 to reference methods:reduce(Math::max);Note that this will be interpreted by the compiler, not by the JVM at runtime! Although it produces different bytecodes for all three code snippets, they are semantically equal, so the last two can be considered to be short (and probably more efficient) versions of the IntBinaryOperator implementation above!(See also Translation of Lambda Expressions)"
"data_i","edited Aug 20 '21 at 10:32","
        Adding HTML entities using CSS content
    ","How do you use the CSS content property to add HTML entities?Using something like this just prints &nbsp; to the screen instead of the non-breaking space:.breadcrumbs a:before {  content: '&nbsp;';}","You have to use the escaped unicode :Like.breadcrumbs a:before {  content: '\0000a0';}More info on : http://www.evotech.net/blog/2007/04/named-html-entities-in-numeric-order/"
"data_i","edited Dec 03 '15 at 19:56","
        What is a typedef enum in Objective-C?
    ","I don't think I fundamentally understand what an enum is, and when to use it.  For example:typedef enum {    kCircle,    kRectangle,    kOblateSpheroid} ShapeType;What is really being declared here?","Three things are being declared here: an anonymous enumerated type is declared, ShapeType is being declared a typedef for that anonymous enumeration, and the three names kCircle, kRectangle, and kOblateSpheroid are being declared as integral constants.Let's break that down.  In the simplest case, an enumeration can be declared asenum tagname { ... };This declares an enumeration with the tag tagname.  In C and Objective-C (but not C++), any references to this must be preceded with the enum keyword.  For example:enum tagname x;  // declare x of type 'enum tagname'tagname x;  // ERROR in C/Objective-C, OK in C++In order to avoid having to use the enum keyword everywhere, a typedef can be created:enum tagname { ... };typedef enum tagname tagname;  // declare 'tagname' as a typedef for 'enum tagname'This can be simplified into one line:typedef enum tagname { ... } tagname;  // declare both 'enum tagname' and 'tagname'And finally, if we don't need to be able to use enum tagname with the enum keyword, we can make the enum anonymous and only declare it with the typedef name:typedef enum { ... } tagname;Now, in this case, we're declaring ShapeType to be a typedef'ed name of an anonymous enumeration.  ShapeType is really just an integral type, and should only be used to declare variables which hold one of the values listed in the declaration (that is, one of kCircle, kRectangle, and kOblateSpheroid).  You can assign a ShapeType variable another value by casting, though, so you have to be careful when reading enum values.Finally, kCircle, kRectangle, and kOblateSpheroid are declared as integral constants in the global namespace.  Since no specific values were specified, they get assigned to consecutive integers starting with 0, so kCircle is 0, kRectangle is 1, and kOblateSpheroid is 2."
"data_i","edited Jul 12 '15 at 06:00","
        What is an idempotent operation?
    ","What is an idempotent operation?","In computing, an idempotent operation is one that has no additional effect if it is called more than once with the same input parameters. For example, removing an item from a set can be considered an idempotent operation on the set.In mathematics, an idempotent operation is one where f(f(x)) = f(x). For example, the abs() function is idempotent because abs(abs(x)) = abs(x) for all x. These slightly different definitions can be reconciled by considering that x in the mathematical definition represents the state of an object, and f is an operation that may mutate that object. For example, consider the Python set and its discard method. The discard method removes an element from a set, and does nothing if the element does not exist. So:my_set.discard(x)has exactly the same effect as doing the same operation twice:my_set.discard(x)my_set.discard(x)Idempotent operations are often used in the design of network protocols, where a request to perform an operation is guaranteed to happen at least once, but might also happen more than once. If the operation is idempotent, then there is no harm in performing the operation two or more times.See the Wikipedia article on idempotence for more information.The above answer previously had some incorrect and misleading examples. Comments below written before April 2014 refer to an older revision."
"data_i","edited May 02 '19 at 11:23","
        Usage of __slots__?
    ","What is the purpose of __slots__ in Python — especially with respect to when I would want to use it, and when not?","In Python, what is the purpose of __slots__ and what are the cases one should avoid this?TLDR:The special attribute __slots__ allows you to explicitly state which instance attributes you expect your object instances to have, with the expected results:faster attribute access.space savings in memory.The space savings is fromStoring value references in slots instead of __dict__.Denying __dict__ and __weakref__ creation if parent classes deny them and you declare __slots__.Quick CaveatsSmall caveat, you should only declare a particular slot one time in an inheritance tree. For example:class Base:    __slots__ = 'foo', 'bar'class Right(Base):    __slots__ = 'baz', class Wrong(Base):    __slots__ = 'foo', 'bar', 'baz'        # redundant foo and barPython doesn't object when you get this wrong (it probably should), problems might not otherwise manifest, but your objects will take up more space than they otherwise should. Python 3.8:>>> from sys import getsizeof>>> getsizeof(Right()), getsizeof(Wrong())(56, 72)This is because the Base's slot descriptor has a slot separate from the Wrong's. This shouldn't usually come up, but it could:>>> w = Wrong()>>> w.foo = 'foo'>>> Base.foo.__get__(w)Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>AttributeError: foo>>> Wrong.foo.__get__(w)'foo'The biggest caveat is for multiple inheritance - multiple ""parent classes with nonempty slots"" cannot be combined.To accommodate this restriction, follow best practices: Factor out all but one or all parents' abstraction which their concrete class respectively and your new concrete class collectively will inherit from - giving the abstraction(s) empty slots (just like abstract base classes in the standard library).See section on multiple inheritance below for an example.Requirements:To have attributes named in __slots__ to actually be stored in slots instead of a __dict__, a class must inherit from object (automatic in Python 3, but must be explicit in Python 2).To prevent the creation of a __dict__, you must inherit from object and all classes in the inheritance must declare __slots__ and none of them can have a '__dict__' entry.There are a lot of details if you wish to keep reading.Why use __slots__: Faster attribute access.The creator of Python, Guido van Rossum, states that he actually created __slots__ for faster attribute access.It is trivial to demonstrate measurably significant faster access:import timeitclass Foo(object): __slots__ = 'foo',class Bar(object): passslotted = Foo()not_slotted = Bar()def get_set_delete_fn(obj):    def get_set_delete():        obj.foo = 'foo'        obj.foo        del obj.foo    return get_set_deleteand>>> min(timeit.repeat(get_set_delete_fn(slotted)))0.2846834529991611>>> min(timeit.repeat(get_set_delete_fn(not_slotted)))0.3664822799983085The slotted access is almost 30% faster in Python 3.5 on Ubuntu.>>> 0.3664822799983085 / 0.28468345299916111.2873325658284342In Python 2 on Windows I have measured it about 15% faster.Why use __slots__:  Memory SavingsAnother purpose of __slots__ is to reduce the space in memory that each object instance takes up.My own contribution to the documentation clearly states the reasons behind this:The space saved over using __dict__ can be significant.SQLAlchemy attributes a lot of memory savings to __slots__.To verify this, using the Anaconda distribution of Python 2.7 on Ubuntu Linux, with guppy.hpy (aka heapy) and sys.getsizeof, the size of a class instance without __slots__ declared, and nothing else, is 64 bytes. That does not include the __dict__. Thank you Python for lazy evaluation again, the __dict__ is apparently not called into existence until it is referenced, but classes without data are usually useless. When called into existence, the __dict__ attribute is a minimum of 280 bytes additionally.In contrast, a class instance with __slots__ declared to be () (no data) is only 16 bytes, and 56 total bytes with one item in slots, 64 with two.For 64 bit Python, I illustrate the memory consumption in bytes in Python 2.7 and 3.6, for __slots__ and __dict__ (no slots defined) for each point where the dict grows in 3.6 (except for 0, 1, and 2 attributes):       Python 2.7             Python 3.6attrs  __slots__  __dict__*   __slots__  __dict__* | *(no slots defined)none   16         56 + 272†   16         56 + 112† | †if __dict__ referencedone    48         56 + 272    48         56 + 112two    56         56 + 272    56         56 + 112six    88         56 + 1040   88         56 + 15211     128        56 + 1040   128        56 + 24022     216        56 + 3344   216        56 + 408     43     384        56 + 3344   384        56 + 752So, in spite of smaller dicts in Python 3, we see how nicely __slots__ scale for instances to save us memory, and that is a major reason you would want to use __slots__.Just for completeness of my notes, note that there is a one-time cost per slot in the class's namespace of 64 bytes in Python 2, and 72 bytes in Python 3, because slots use data descriptors like properties, called ""members"".>>> Foo.foo<member 'foo' of 'Foo' objects>>>> type(Foo.foo)<class 'member_descriptor'>>>> getsizeof(Foo.foo)72Demonstration of __slots__:To deny the creation of a __dict__, you must subclass object. Everything subclasses object in Python 3, but in Python 2 you had to be explicit:class Base(object):     __slots__ = ()now:>>> b = Base()>>> b.a = 'a'Traceback (most recent call last):  File ""<pyshell#38>"", line 1, in <module>    b.a = 'a'AttributeError: 'Base' object has no attribute 'a'Or subclass another class that defines __slots__class Child(Base):    __slots__ = ('a',)and now:c = Child()c.a = 'a'but:>>> c.b = 'b'Traceback (most recent call last):  File ""<pyshell#42>"", line 1, in <module>    c.b = 'b'AttributeError: 'Child' object has no attribute 'b'To allow __dict__ creation while subclassing slotted objects, just add '__dict__' to the __slots__ (note that slots are ordered, and you shouldn't repeat slots that are already in parent classes):class SlottedWithDict(Child):     __slots__ = ('__dict__', 'b')swd = SlottedWithDict()swd.a = 'a'swd.b = 'b'swd.c = 'c'and>>> swd.__dict__{'c': 'c'}Or you don't even need to declare __slots__ in your subclass, and you will still use slots from the parents, but not restrict the creation of a __dict__:class NoSlots(Child): passns = NoSlots()ns.a = 'a'ns.b = 'b'And:>>> ns.__dict__{'b': 'b'}However, __slots__ may cause problems for multiple inheritance:class BaseA(object):     __slots__ = ('a',)class BaseB(object):     __slots__ = ('b',)Because creating a child class from parents with both non-empty slots fails:>>> class Child(BaseA, BaseB): __slots__ = ()Traceback (most recent call last):  File ""<pyshell#68>"", line 1, in <module>    class Child(BaseA, BaseB): __slots__ = ()TypeError: Error when calling the metaclass bases    multiple bases have instance lay-out conflictIf you run into this problem, You could just remove __slots__ from the parents, or if you have control of the parents, give them empty slots, or refactor to abstractions:from abc import ABCclass AbstractA(ABC):    __slots__ = ()class BaseA(AbstractA):     __slots__ = ('a',)class AbstractB(ABC):    __slots__ = ()class BaseB(AbstractB):     __slots__ = ('b',)class Child(AbstractA, AbstractB):     __slots__ = ('a', 'b')c = Child() # no problem!Add '__dict__' to __slots__ to get dynamic assignment:class Foo(object):    __slots__ = 'bar', 'baz', '__dict__'and now:>>> foo = Foo()>>> foo.boink = 'boink'So with '__dict__' in slots we lose some of the size benefits with the upside of having dynamic assignment and still having slots for the names we do expect.When you inherit from an object that isn't slotted, you get the same sort of semantics when you use __slots__ - names that are in __slots__ point to  slotted values, while any other values are put in the instance's __dict__.Avoiding __slots__ because you want to be able to add attributes on the fly is actually not a good reason - just add ""__dict__"" to your __slots__ if this is required.You can similarly add __weakref__ to __slots__ explicitly if you need that feature.Set to empty tuple when subclassing a namedtuple:The namedtuple builtin make immutable instances that are very lightweight (essentially, the size of tuples) but to get the benefits, you need to do it yourself if you subclass them:from collections import namedtupleclass MyNT(namedtuple('MyNT', 'bar baz')):    """"""MyNT is an immutable and lightweight object""""""    __slots__ = ()usage:>>> nt = MyNT('bar', 'baz')>>> nt.bar'bar'>>> nt.baz'baz'And trying to assign an unexpected attribute raises an AttributeError because we have prevented the creation of __dict__:>>> nt.quux = 'quux'Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>AttributeError: 'MyNT' object has no attribute 'quux'You can allow __dict__ creation by leaving off __slots__ = (), but you can't use non-empty __slots__ with subtypes of tuple.Biggest Caveat: Multiple inheritanceEven when non-empty slots are the same for multiple parents, they cannot be used together:class Foo(object):     __slots__ = 'foo', 'bar'class Bar(object):    __slots__ = 'foo', 'bar' # alas, would work if empty, i.e. ()>>> class Baz(Foo, Bar): passTraceback (most recent call last):  File ""<stdin>"", line 1, in <module>TypeError: Error when calling the metaclass bases    multiple bases have instance lay-out conflictUsing an empty __slots__ in the parent seems to provide the most flexibility, allowing the child to choose to prevent or allow (by adding '__dict__' to get dynamic assignment, see section above) the creation of a __dict__:class Foo(object): __slots__ = ()class Bar(object): __slots__ = ()class Baz(Foo, Bar): __slots__ = ('foo', 'bar')b = Baz()b.foo, b.bar = 'foo', 'bar'You don't have to have slots - so if you add them, and remove them later, it shouldn't cause any problems.Going out on a limb here: If you're composing mixins or using abstract base classes, which aren't intended to be instantiated, an empty __slots__ in those parents seems to be the best way to go in terms of flexibility for subclassers.To demonstrate, first, let's create a class with code we'd like to use under multiple inheritanceclass AbstractBase:    __slots__ = ()    def __init__(self, a, b):        self.a = a        self.b = b    def __repr__(self):        return f'{type(self).__name__}({repr(self.a)}, {repr(self.b)})'We could use the above directly by inheriting and declaring the expected slots:class Foo(AbstractBase):    __slots__ = 'a', 'b'But we don't care about that, that's trivial single inheritance, we need another class we might also inherit from, maybe with a noisy attribute:class AbstractBaseC:    __slots__ = ()    @property    def c(self):        print('getting c!')        return self._c    @c.setter    def c(self, arg):        print('setting c!')        self._c = argNow if both bases had nonempty slots, we couldn't do the below. (In fact, if we wanted, we could have given AbstractBase nonempty slots a and b, and left them out of the below declaration - leaving them in would be wrong):class Concretion(AbstractBase, AbstractBaseC):    __slots__ = 'a b _c'.split()And now we have functionality from both via multiple inheritance, and can still deny __dict__ and __weakref__ instantiation:>>> c = Concretion('a', 'b')>>> c.c = csetting c!>>> c.cgetting c!Concretion('a', 'b')>>> c.d = 'd'Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>AttributeError: 'Concretion' object has no attribute 'd'Other cases to avoid slots:Avoid them when you want to perform __class__ assignment with another class that doesn't have them (and you can't add them) unless the slot layouts are identical. (I am very interested in learning who is doing this and why.)Avoid them if you want to subclass variable length builtins like long, tuple, or str, and you want to add attributes to them.Avoid them if you insist on providing default values via class attributes for instance variables.You may be able to tease out further caveats from the rest of the __slots__ documentation (the 3.7 dev docs are the most current), which I have made significant recent contributions to.Critiques of other answersThe current top answers cite outdated information and are quite hand-wavy and miss the mark in some important ways.Do not ""only use __slots__ when instantiating lots of objects""I quote:""You would want to use __slots__ if you are going to instantiate a lot (hundreds, thousands) of objects of the same class.""Abstract Base Classes, for example, from the collections module, are not instantiated, yet __slots__ are declared for them.Why?If a user wishes to deny __dict__ or __weakref__ creation, those things must not be available in the parent classes.__slots__ contributes to reusability when creating interfaces or mixins.It is true that many Python users aren't writing for reusability, but when you are, having the option to deny unnecessary space usage is valuable.__slots__ doesn't break picklingWhen pickling a slotted object, you may find it complains with a misleading TypeError:>>> pickle.loads(pickle.dumps(f))TypeError: a class that defines __slots__ without defining __getstate__ cannot be pickledThis is actually incorrect. This message comes from the oldest protocol, which is the default. You can select the latest protocol with the -1 argument. In Python 2.7 this would be 2 (which was introduced in 2.3), and in 3.6 it is 4.>>> pickle.loads(pickle.dumps(f, -1))<__main__.Foo object at 0x1129C770>in Python 2.7:>>> pickle.loads(pickle.dumps(f, 2))<__main__.Foo object at 0x1129C770>in Python 3.6>>> pickle.loads(pickle.dumps(f, 4))<__main__.Foo object at 0x1129C770>So I would keep this in mind, as it is a solved problem.Critique of the (until Oct 2, 2016) accepted answerThe first paragraph is half short explanation, half predictive. Here's the only part that actually answers the questionThe proper use of __slots__ is to save space in objects. Instead of having a dynamic dict that allows adding attributes to objects at anytime, there is a static structure which does not allow additions after creation. This saves the overhead of one dict for every object that uses slotsThe second half is wishful thinking, and off the mark:While this is sometimes a useful optimization, it would be completely unnecessary if the Python interpreter was dynamic enough so that it would only require the dict when there actually were additions to the object.Python actually does something similar to this, only creating the __dict__ when it is accessed, but creating lots of objects with no data is fairly ridiculous.The second paragraph oversimplifies and misses actual reasons to avoid __slots__. The below is not a real reason to avoid slots (for actual reasons, see the rest of my answer above.):They change the behavior of the objects that have slots in a way that can be abused by control freaks and static typing weenies.It then goes on to discuss other ways of accomplishing that perverse goal with Python, not discussing anything to do with __slots__.The third paragraph is more wishful thinking. Together it is mostly off-the-mark content that the answerer didn't even author and contributes to ammunition for critics of the site.Memory usage evidenceCreate some normal objects and slotted objects:>>> class Foo(object): pass>>> class Bar(object): __slots__ = ()Instantiate a million of them:>>> foos = [Foo() for f in xrange(1000000)]>>> bars = [Bar() for b in xrange(1000000)]Inspect with guppy.hpy().heap():>>> guppy.hpy().heap()Partition of a set of 2028259 objects. Total size = 99763360 bytes. Index  Count   %     Size   % Cumulative  % Kind (class / dict of class)     0 1000000  49 64000000  64  64000000  64 __main__.Foo     1     169   0 16281480  16  80281480  80 list     2 1000000  49 16000000  16  96281480  97 __main__.Bar     3   12284   1   987472   1  97268952  97 str...Access the regular objects and their __dict__ and inspect again:>>> for f in foos:...     f.__dict__>>> guppy.hpy().heap()Partition of a set of 3028258 objects. Total size = 379763480 bytes. Index  Count   %      Size    % Cumulative  % Kind (class / dict of class)     0 1000000  33 280000000  74 280000000  74 dict of __main__.Foo     1 1000000  33  64000000  17 344000000  91 __main__.Foo     2     169   0  16281480   4 360281480  95 list     3 1000000  33  16000000   4 376281480  99 __main__.Bar     4   12284   0    987472   0 377268952  99 str...This is consistent with the history of Python, from Unifying types and classes in Python 2.2If you subclass a built-in type, extra space is automatically added to the instances to accomodate __dict__ and __weakrefs__. (The __dict__ is not initialized until you use it though, so you shouldn't worry about the space occupied by an empty dictionary for each instance you create.) If you don't need this extra space, you can add the phrase ""__slots__ = []"" to your class."
"data_i","edited Mar 16 '20 at 00:55","
        Find out which remote branch a local branch is tracking
    ","See also: How can I see which Git branches are tracking which remote / upstream branch?How can I find out which remote branch a local branch is tracking?Do I need to parse git config output, or is there a command that would do this for me?","Here is a command that gives you all tracking branches (configured for 'pull'), see:$ git branch -vv  main   aaf02f0 [main/master: ahead 25] Some other commit* master add0a03 [jdsumsion/master] Some commitYou have to wade through the SHA and any long-wrapping commit messages, but it's quick to type and I get the tracking branches aligned vertically in the 3rd column.If you need info on both 'pull' and 'push' configuration per branch, see the other answer on git remote show origin.UpdateStarting in git version 1.8.5 you can show the upstream branch with git status and git status -sb"
"data_i","edited Apr 10 '22 at 12:22","
        Maximum and Minimum values for ints
    ","How do I represent minimum and maximum values for integers in Python? In Java, we have Integer.MIN_VALUE and Integer.MAX_VALUE.","Python 3In Python 3, this question doesn't apply. The plain int type is unbound.However, you might actually be looking for information about the current interpreter's word size, which will be the same as the machine's word size in most cases. That information is still available in Python 3 as sys.maxsize, which is the maximum value representable by a signed word. Equivalently, it's the size of the largest possible list or in-memory sequence.Generally, the maximum value representable by an unsigned word will be sys.maxsize * 2 + 1, and the number of bits in a word will be math.log2(sys.maxsize * 2 + 2). See this answer for more information.Python 2In Python 2, the maximum value for plain int values is available as sys.maxint:>>> sys.maxint9223372036854775807You can calculate the minimum value with -sys.maxint - 1 as shown here.Python seamlessly switches from plain to long integers once you exceed this value. So most of the time, you won't need to know it."
"data_i","edited Apr 01 '19 at 17:01","
        How to search a Git repository by commit message?
    ","I checked some source code into GIT with the commit message ""Build 0051"".However, I can't seem to find that source code any more - how do I extract this source from the GIT repository, using the command line?UpdateChecked in versions 0043, 0044, 0045 and 0046 using SmartGIT.Checked out 0043, and checked in versions up to 0051 on a different branch.Checked out 0043 again.Now, 0051 has disappeared.UpdateThe source code is definitely there, now its a matter of checking it out:C:\Source>git log -g --grep=""0052""commit 77b1f718d19e5cf46e2fab8405a9a0859c9c2889Reflog: HEAD@{10} (unknown <Mike@.(none)>)Reflog message: commit: 20110819 - 1724 - GL: Intermediate version. File version:  v0.5.0 build 0052.Author: unknown <Mike@.(none)>Date:   Fri Aug 19 17:24:51 2011 +0100    20110819 - 1724 - GL: Intermediate version. File version: v0.5.0 build 0052.C:\Source>","To search the commit log (across all branches) for the given text:git log --all --grep='Build 0051'To search the actual content of commits through a repo's history, use:git grep 'Build 0051' $(git rev-list --all)to show all instances of the given text, the containing file name, and the commit sha1.Finally, as a last resort in case your commit is dangling and not connected to history at all, you can search the reflog itself with the -g flag (short for --walk-reflogs:git log -g --grep='Build 0051'EDIT: if you seem to have lost your history, check the reflog as your safety net. Look for Build 0051 in one of the commits listed bygit reflogYou may have simply set your HEAD to a part of history in which the 'Build 0051' commit is not visible, or you may have actually blown it away. The git-ready reflog  article may be of help.To recover your commit from the reflog: do a git checkout of the commit you found (and optionally make a new branch or tag of it for reference)git checkout 77b1f718d19e5cf46e2fab8405a9a0859c9c2889# alternative, using reflog (see git-ready link provided)# git checkout HEAD@{10}git checkout -b build_0051 # make a new branch with the build_0051 as the tip"
"data_i","edited Sep 11 '17 at 17:15","
        Calculate distance between two latitude-longitude points? (Haversine formula)
    ","How do I calculate the distance between two points specified by latitude and longitude?For clarification, I'd like the distance in kilometers; the points use the WGS84 system and I'd like to understand the relative accuracies of the approaches available.","This link might be helpful to you, as it details the use of the Haversine formula to calculate the distance.Excerpt:This script [in Javascript] calculates great-circle distances between the two points –  that is, the shortest distance over the earth’s surface – using the  ‘Haversine’ formula.function getDistanceFromLatLonInKm(lat1,lon1,lat2,lon2) {  var R = 6371; // Radius of the earth in km  var dLat = deg2rad(lat2-lat1);  // deg2rad below  var dLon = deg2rad(lon2-lon1);   var a =     Math.sin(dLat/2) * Math.sin(dLat/2) +    Math.cos(deg2rad(lat1)) * Math.cos(deg2rad(lat2)) *     Math.sin(dLon/2) * Math.sin(dLon/2)    ;   var c = 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1-a));   var d = R * c; // Distance in km  return d;}function deg2rad(deg) {  return deg * (Math.PI/180)}"
"data_i","edited Jan 26 '16 at 23:14","
        What does 'synchronized' mean?
    ","I have some questions regarding the usage and significance of the synchronized keyword. What is the significance of the synchronized keyword?When should methods be synchronized?What does it mean programmatically and logically?","The synchronized keyword is all about different threads reading and writing to the same variables, objects and resources.  This is not a trivial topic in Java, but here is a quote from Sun:synchronized methods enable a simple  strategy for preventing thread  interference and memory consistency  errors: if an object is visible to  more than one thread, all reads or  writes to that object's variables are  done through synchronized methods.In a very, very small nutshell: When you have two threads that are reading and writing to the same 'resource', say a variable named foo, you need to ensure that these threads access the variable in an atomic way.  Without the synchronized keyword, your thread 1 may not see the change thread 2 made to foo, or worse, it may only be half changed.  This would not be what you logically expect.Again, this is a non-trivial topic in Java.  To learn more, explore topics here on SO and the Interwebs  about:ConcurrencyJava Memory ModelKeep exploring these topics until the name ""Brian Goetz"" becomes permanently associated with the term ""concurrency"" in your brain.  "
"data_i","edited Oct 17 '19 at 10:23","
        PHP array delete by value (not key)
    ","I have a PHP array as follows:$messages = [312, 401, 1599, 3, ...];I want to delete the element containing the value $del_val (for example, $del_val=401), but I don't know its key. This might help: each value can only be there once.I'm looking for the simplest function to perform this task, please.","Using array_search() and unset, try the following:if (($key = array_search($del_val, $messages)) !== false) {    unset($messages[$key]);}array_search() returns the key of the element it finds, which can be used to remove that element from the original array using unset(). It will return FALSE on failure, however it can return a false-y value on success (your key may be 0 for example), which is why the strict comparison !== operator is used.The if() statement will check whether array_search() returned a value, and will only perform an action if it did."
"data_i","edited Sep 06 '22 at 16:11","
        How do I quickly rename a MySQL database (change schema name)?
    ","The MySQL manual at MySQL covers this.Usually I just dump the database and reimport it with a new name. This is not an option for very big databases. Apparently RENAME {DATABASE | SCHEMA} db_name TO new_db_name; does bad things, exists only in a handful of versions, and is a bad idea overall.This needs to work with InnoDB, which stores things very differently than MyISAM.","For InnoDB, the following seems to work: create the new empty database, then rename each table in turn into the new database:RENAME TABLE old_db.table TO new_db.table;You will need to adjust the permissions after that.For scripting in a shell, you can use either of the following:mysql -u username -ppassword old_db -sNe 'show tables' | while read table; \     do mysql -u username -ppassword -sNe ""rename table old_db.$table to new_db.$table""; doneORfor table in `mysql -u root -ppassword -s -N -e ""use old_db;show tables from old_db;""`; do mysql -u root -ppassword -s -N -e ""use old_db;rename table old_db.$table to new_db.$table;""; done;Notes:There is no space between the option -p and the password. If your database has no password, remove the -u username -ppassword part.If some table has a trigger, it cannot be moved to another database using above method (will result Trigger in wrong schema error). If that is the case, use a traditional way to clone a database and then drop the old one:mysqldump old_db | mysql new_dbIf you have stored procedures, you can copy them afterwards:mysqldump -R old_db | mysql new_db"
"data_i","edited Jun 27 '20 at 21:44","
        Get the value in an input text box
    ","What are the ways to get and render an input value using jQuery?Here is one: $(document).ready(function() {  $(""#txt_name"").keyup(function() {    alert($(this).val());  });})<script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/1.4.3/jquery.min.js""></script><input type=""text"" id=""txt_name"" />","//Getvar bla = $('#txt_name').val();//Set$('#txt_name').val(bla);"
"data_i","edited Aug 21 '19 at 14:03","
        How do I call Objective-C code from Swift?
    ","In Swift, how does one call Objective-C code?Apple mentioned that they could co-exist in one application, but does this mean that one could technically re-use old classes made in Objective-C whilst building new classes in Swift?","Using Objective-C Classes in SwiftIf you have an existing class that you'd like to use, perform Step 2 and then skip to Step 5. (For some cases, I had to add an explicit #import <Foundation/Foundation.h to an older Objective-C File.)Step 1: Add Objective-C Implementation -- .mAdd a .m file to your class, and name it CustomObject.m.Step 2: Add Bridging HeaderWhen adding your .m file, you'll likely be hit with a prompt that looks like this:Click Yes!  If you did not see the prompt, or accidentally deleted your bridging header, add a new .h file to your project and name it <#YourProjectName#>-Bridging-Header.h.In some situations, particularly when working with Objective-C frameworks, you don't add an Objective-C class explicitly and Xcode can't find the linker. In this case, create your .h file named as mentioned above, then make sure you link its path in your target's project settings like so:Note:It's best practice to link your project using the $(SRCROOT) macro so that if you move your project, or work on it with others using a remote repository, it will still work. $(SRCROOT) can be thought of as the directory that contains your .xcodeproj file. It might look like this:$(SRCROOT)/Folder/Folder/<#YourProjectName#>-Bridging-Header.hStep 3: Add Objective-C Header -- .hAdd another .h file and name it CustomObject.h.Step 4: Build your Objective-C ClassIn CustomObject.h#import <Foundation/Foundation.h>@interface CustomObject : NSObject@property (strong, nonatomic) id someProperty;- (void) someMethod;@endIn CustomObject.m#import ""CustomObject.h""@implementation CustomObject - (void) someMethod {    NSLog(@""SomeMethod Ran"");}@endStep 5: Add Class to Bridging-HeaderIn YourProject-Bridging-Header.h:#import ""CustomObject.h""Step 6: Use your ObjectIn SomeSwiftFile.swift:var instanceOfCustomObject = CustomObject()instanceOfCustomObject.someProperty = ""Hello World""print(instanceOfCustomObject.someProperty)instanceOfCustomObject.someMethod()There is no need to import explicitly; that's what the bridging header is for.  Using Swift Classes in Objective-CStep 1: Create New Swift ClassAdd a .swift file to your project, and name it MySwiftObject.swift.In MySwiftObject.swift:import Foundation@objc(MySwiftObject)class MySwiftObject : NSObject {    @objc    var someProperty: AnyObject = ""Some Initializer Val"" as NSString    init() {}    @objc    func someFunction(someArg: Any) -> NSString {        return ""You sent me \(someArg)""    }}Step 2: Import Swift Files to ObjC ClassIn SomeRandomClass.m:#import ""<#YourProjectName#>-Swift.h""The file:<#YourProjectName#>-Swift.h should already be created automatically in your project, even if you can not see it.Step 3: Use your classMySwiftObject * myOb = [MySwiftObject new];NSLog(@""MyOb.someProperty: %@"", myOb.someProperty);myOb.someProperty = @""Hello World"";NSLog(@""MyOb.someProperty: %@"", myOb.someProperty);NSString * retString = [myOb someFunctionWithSomeArg:@""Arg""];NSLog(@""RetString: %@"", retString);Notes:If Code Completion isn't behaving as you expect, try running a quick build with ⌘⇧R to help Xcode find some of the Objective-C code from a Swift context and vice versa. If you add a .swift file to an older project and get the error dyld: Library not loaded: @rpath/libswift_stdlib_core.dylib, try completely restarting Xcode.While it was originally possible to use pure Swift classes (Not descendents of NSObject) which are visible to Objective-C by using the @objc prefix, this is no longer possible. Now, to be visible in Objective-C, the Swift object must either be a class conforming to NSObjectProtocol (easiest way to do this is to inherit from NSObject), or to be an enum marked @objc with a raw value of some integer type like Int. You may view the edit history for an example of Swift 1.x code using @objc without these restrictions."
"data_i","edited Dec 11 '21 at 19:26","
        Git push results in ""Authentication Failed""
    ","I have been using GitHub for a little while, and I have been fine with git add, git commit, and git push, so far without any problems. Suddenly I am having an error that says:fatal: Authentication FailedIn the terminal I cloned a repository, worked on a file and then I used git add to add the file to the commit log and when I did git commit, it worked fine. Finally, git push asks for username and password. I put those in correctly and every time I do this, it says the same error.What is the cause of this problem and how can I fix it?The contents of .git/config are:[core]        repositoryformatversion = 0        filemode = true        bare = false        logallrefupdates = true[remote ""origin""]        url = http://www.github.com/######/Random-Python-Tests        fetch = +refs/heads/*:refs/remotes/origin/*[branch ""master""]        remote = origin        merge = refs/heads/master[user]        name = #####        email = ############","If you enabled two-factor authentication in your GitHub account youwon't be able to push via HTTPS using your accounts password. Insteadyou need to generate a personal access token. This can be done in theapplication settings of your GitHub account. Using this token as yourpassword should allow you to push to your remote repository via HTTPS.Use your username as usual.Creating a personal access tokenYou may also need to update the origin for your repository if it is set to HTTPS. Do this to switch to SSH:git remote -vgit remote set-url origin git@github.com:USERNAME/REPONAME.git"
"data_i","edited Jan 10 '13 at 04:40","
        MySQL error code: 1175 during UPDATE in MySQL Workbench
    ","I'm trying to update the column visited to give it the value 1. I use MySQL workbench, and I'm writing the statement in the SQL editor from inside the workbench. I'm writing the following command:UPDATE tablename SET columnname=1;It gives me the following error:You are using safe update mode and you tried to update a table without  a WHERE that uses a KEY column To disable safe mode, toggle the option  ....I followed the instructions, and I unchecked the safe update option from the Edit menu then Preferences then SQL Editor. The same error still appear & I'm not able to update this value. Please, tell me what is wrong?","It looks like your MySql session has the safe-updates option set. This means that you can't update or delete records without specifying a key (ex. primary key) in the where clause.Try:SET SQL_SAFE_UPDATES = 0;Or you can modify your query to follow the rule (use primary key in where clause)."
"data_i","edited Jun 20 '22 at 09:30","
        Use of PUT vs PATCH methods in REST API real life scenarios
    ","First of all, some definitions:PUT is defined in Section 9.6 RFC 2616:The PUT method requests that the enclosed entity be stored under the supplied Request-URI. If the Request-URI refers to an already existing resource, the enclosed entity SHOULD be considered as a modified version of the one residing on the origin server. If the Request-URI does not point to an existing resource, and that URI is capable of being defined as a new resource by the requesting user agent, the origin server can create the resource with that URI.PATCH is defined in RFC 5789:The PATCH method requests that a set of changes described in therequest entity be applied to the resource identified by the Request-URI.Also according to RFC 2616 Section 9.1.2 PUT is Idempotent while PATCH is not.Now let us take a look at a real example. When I do POST to /users with the data {username: 'skwee357', email: 'skwee357@domain.example'} and the server is capable of creating a resource, it will respond with 201 and resource location (lets assume /users/1) and any next call to GET /users/1 will return {id: 1, username: 'skwee357', email: 'skwee357@domain.example'}.Now let us say I want to modify my email. Email modification is considered ""a set of changes"" and therefore I should PATCH /users/1 with ""patch document"". In my case it would be the JSON document: {email: 'skwee357@newdomain.example'}. The server then returns 200 (assuming permission are ok). This brings me to first question:PATCH is NOT idempotent. It said so in RFC 2616 and RFC 5789. However if I issue the same PATCH request (with my new email), I will get the same resource state (with my email being modified to the requested value). Why is PATCH not then idempotent?PATCH is a relatively new verb (RFC introduced in March 2010), and it comes to solve the problem of ""patching"" or modifying a set of fields. Before PATCH was introduced, everybody used PUT to update resources. But after PATCH was introduced, it leaves me confused about what PUT is used for. And this brings me to my second (and the main) question:What is the real difference between PUT and PATCH? I have read somewhere that PUT might be used to replace entire entity under specific resource, so one should send the full entity (instead of set of attributes as with PATCH). What is the real practical usage for such case? When would you like to replace / overwrite an entity at a specific resource URI and why is such an operation not considered updating / patching the entity? The only practical use case I see for PUT is issuing a PUT on a collection, i.e. /users to replace the entire collection. Issuing PUT on a specific entity makes no sense after PATCH was introduced. Am I wrong?","NOTE: When I first spent time reading about REST, idempotence was a confusing concept to try to get right. I still didn't get it quite right in my original answer, as further comments (and Jason Hoetger's answer) have shown. For a while, I have resisted updating this answer extensively, to avoid effectively plagiarizing Jason, but I'm editing it now because, well, I was asked to (in the comments).After reading my answer, I suggest you also read Jason Hoetger's excellent answer to this question, and I will try to make my answer better without simply stealing from Jason.Why is PUT idempotent?As you noted in your RFC 2616 citation, PUT is considered idempotent. When you PUT a resource, these two assumptions are in play:You are referring to an entity, not to a collection.The entity you are supplying is complete (the entire entity).Let's look at one of your examples.{ ""username"": ""skwee357"", ""email"": ""skwee357@domain.example"" }If you POST this document to /users, as you suggest, then you might get back an entity such as## /users/1{    ""username"": ""skwee357"",    ""email"": ""skwee357@domain.example""}If you want to modify this entity later, you choose between PUT and PATCH. A PUT might look like this:PUT /users/1{    ""username"": ""skwee357"",    ""email"": ""skwee357@gmail.com""       // new email address}You can accomplish the same using PATCH. That might look like this:PATCH /users/1{    ""email"": ""skwee357@gmail.com""       // new email address}You'll notice a difference right away between these two. The PUT included all of the parameters on this user, but PATCH only included the one that was being modified (email).When using PUT, it is assumed that you are sending the complete entity, and that complete entity replaces any existing entity at that URI. In the above example, the PUT and PATCH accomplish the same goal: they both change this user's email address. But PUT handles it by replacing the entire entity, while PATCH only updates the fields that were supplied, leaving the others alone.Since PUT requests include the entire entity, if you issue the same request repeatedly, it should always have the same outcome (the data you sent is now the entire data of the entity). Therefore PUT is idempotent.Using PUT wrongWhat happens if you use the above PATCH data in a PUT request?GET /users/1{    ""username"": ""skwee357"",    ""email"": ""skwee357@domain.example""}PUT /users/1{    ""email"": ""skwee357@gmail.com""       // new email address}GET /users/1{    ""email"": ""skwee357@gmail.com""      // new email address... and nothing else!}(I'm assuming for the purposes of this question that the server doesn't have any specific required fields, and would allow this to happen... that may not be the case in reality.)Since we used PUT, but only supplied email, now that's the only thing in this entity. This has resulted in data loss.This example is here for illustrative purposes -- don't ever actually do this (unless your intent is to drop the omitted fields, of course... then you are using PUT as it should be used). This PUT request is technically idempotent, but that doesn't mean it isn't a terrible, broken idea.How can PATCH be idempotent?In the above example, PATCH was idempotent. You made a change, but if you made the same change again and again, it would always give back the same result: you changed the email address to the new value.GET /users/1{    ""username"": ""skwee357"",    ""email"": ""skwee357@domain.example""}PATCH /users/1{    ""email"": ""skwee357@gmail.com""       // new email address}GET /users/1{    ""username"": ""skwee357"",    ""email"": ""skwee357@gmail.com""       // email address was changed}PATCH /users/1{    ""email"": ""skwee357@gmail.com""       // new email address... again}GET /users/1{    ""username"": ""skwee357"",    ""email"": ""skwee357@gmail.com""       // nothing changed since last GET}My original example, fixed for accuracyI originally had examples that I thought were showing non-idempotency, but they were misleading / incorrect. I am going to keep the examples, but use them to illustrate a different thing: that multiple PATCH documents against the same entity, modifying different attributes, do not make the PATCHes non-idempotent.Let's say that at some past time, a user was added. This is the state that you are starting from.{  ""id"": 1,  ""name"": ""Sam Kwee"",  ""email"": ""skwee357@olddomain.example"",  ""address"": ""123 Mockingbird Lane"",  ""city"": ""New York"",  ""state"": ""NY"",  ""zip"": ""10001""}After a PATCH, you have a modified entity:PATCH /users/1{""email"": ""skwee357@newdomain.example""}{  ""id"": 1,  ""name"": ""Sam Kwee"",  ""email"": ""skwee357@newdomain.example"",    // the email changed, yay!  ""address"": ""123 Mockingbird Lane"",  ""city"": ""New York"",  ""state"": ""NY"",  ""zip"": ""10001""}If you then repeatedly apply your PATCH, you will continue to get the same result: the email was changed to the new value. A goes in, A comes out, therefore this is idempotent.An hour later, after you have gone to make some coffee and take a break, someone else comes along with their own PATCH. It seems the Post Office has been making some changes.PATCH /users/1{""zip"": ""12345""}{  ""id"": 1,  ""name"": ""Sam Kwee"",  ""email"": ""skwee357@newdomain.example"",  // still the new email you set  ""address"": ""123 Mockingbird Lane"",  ""city"": ""New York"",  ""state"": ""NY"",  ""zip"": ""12345""                      // and this change as well}Since this PATCH from the post office doesn't concern itself with email, only zip code, if it is repeatedly applied, it will also get the same result: the zip code is set to the new value. A goes in, A comes out, therefore this is also idempotent.The next day, you decide to send your PATCH again.PATCH /users/1{""email"": ""skwee357@newdomain.example""}{  ""id"": 1,  ""name"": ""Sam Kwee"",  ""email"": ""skwee357@newdomain.example"",  ""address"": ""123 Mockingbird Lane"",  ""city"": ""New York"",  ""state"": ""NY"",  ""zip"": ""12345""}Your patch has the same effect it had yesterday: it set the email address. A went in, A came out, therefore this is idempotent as well.What I got wrong in my original answerI want to draw an important distinction (something I got wrong in my original answer). Many servers will respond to your REST requests by sending back the new entity state, with your modifications (if any). So, when you get this response back, it is different from the one you got back yesterday, because the zip code is not the one you received last time. However, your request was not concerned with the zip code, only with the email. So your PATCH document is still idempotent - the email you sent in PATCH is now the email address on the entity.So when is PATCH not idempotent, then?For a full treatment of this question, I again refer you to Jason Hoetger's answer which already fully answers that."
"data_i","edited Mar 12 '21 at 02:39","
        Is Safari on iOS 6 caching $.ajax results?
    ","Since the upgrade to iOS 6, we are seeing Safari's web view take the liberty of caching $.ajax calls. This is in the context of a PhoneGap application so it is using the Safari WebView. Our $.ajax calls are POST methods and we have cache set to false {cache:false}, but still this is happening. We tried manually adding a TimeStamp to the headers but it did not help.We did more research and found that Safari is only returning cached results for web services that have a function signature that is static and does not change from call to call.  For instance, imagine a function called something like:getNewRecordID(intRecordType)This function receives the same input parameters over and over again, but the data it returns should be different every time.Must be in Apple's haste to make iOS 6 zip along impressively they got too happy with the cache settings.  Has anyone else seen this behavior on iOS 6? If so, what exactly is causing it?The workaround that we found was to modify the function signature to be something like this:getNewRecordID(intRecordType, strTimestamp)and then always pass in a TimeStamp parameter as well, and just discard that value on the server side.  This works around the issue.","After a bit of investigation, turns out that Safari on iOS6 will cache POSTs that have either no Cache-Control headers or even ""Cache-Control: max-age=0"".The only way I've found of preventing this caching from happening at a global level rather than having to hack random querystrings onto the end of service calls is to set ""Cache-Control: no-cache"".So:No Cache-Control or Expires headers = iOS6 Safari will cacheCache-Control max-age=0 and an immediate Expires = iOS6 Safari will cacheCache-Control: no-cache = iOS6 Safari will NOT cacheI suspect that Apple is taking advantage of this from the HTTP spec in section 9.5 about POST:Responses to this method are not cacheable, unless the response     includes appropriate Cache-Control or Expires header fields. However,     the 303 (See Other) response can be used to direct the user agent to     retrieve a cacheable resource.So in theory you can cache POST responses...who knew. But no other browser maker has ever thought it would be a good idea until now. But that does NOT account for the caching when no Cache-Control or Expires headers are set, only when there are some set. So it must be a bug.Below is what I use in the right bit of my Apache config to target the whole of my API because as it happens I don't actually want to cache anything, even gets. What I don't know is how to set this just for POSTs.Header set Cache-Control ""no-cache""Update: Just noticed that I didn't point out that it is only when the POST is the same, so change any of the POST data or URL and you're fine. So you can as mentioned elsewhere just add some random data to the URL or a bit of POST data.Update: You can limit the ""no-cache"" just to POSTs if you wish like this in Apache:SetEnvIf Request_Method ""POST"" IS_POSTHeader set Cache-Control ""no-cache"" env=IS_POST"
"data_i","edited Nov 21 '20 at 09:30","
        How do I use PHP to get the current year?
    ","I want to put a copyright notice in the footer of a web site, but I think it's incredibly tacky for the year to be outdated.How would I make the year update automatically with PHP 4 or PHP 5?","You can use either date or strftime. In this case I'd say it doesn't matter as a year is a year, no matter what (unless there's a locale that formats the year differently?)For example:<?php echo date(""Y""); ?>On a side note, when formatting dates in PHP it matters when you want to format your date in a different locale than your default. If so, you have to use setlocale and strftime. According to the php manual on date:To format dates in other languages,  you should use the setlocale() and  strftime()  functions instead of  date().From this point of view, I think it would be best to use strftime as much as possible, if you even have a remote possibility of having to localize your application. If that's not an issue, pick the one you like best."
"data_i","edited Jan 10 '17 at 02:16","
        How to iterate over arguments in a Bash script
    ","I have a complex command that I'd like to make a shell/bash script of.  I can write it in terms of $1 easily:foo $1 args -o $1.extI want to be able to pass multiple input names to the script. What's the right way to do it?  And, of course, I want to handle filenames with spaces in them.","Use ""$@"" to represent all the arguments:for var in ""$@""do    echo ""$var""doneThis will iterate over each argument and print it out on a separate line.  $@ behaves like $* except that when quoted the arguments are broken up properly if there are spaces in them:sh test.sh 1 2 '3 4'123 4"
"data_i","edited Nov 12 '20 at 12:24","
        Selecting and manipulating CSS pseudo-elements such as ::before and ::after using javascript (or jQuery)
    ","Is there any way to select/manipulate CSS pseudo-elements such as ::before and ::after (and the old version with one semi-colon) using jQuery?For example, my stylesheet has the following rule:.span::after{ content:'foo' }How can I change 'foo' to 'bar' using vanilla JS or jQuery?","You could also pass the content to the pseudo element with a data attribute and then use jQuery to manipulate that:In HTML:<span>foo</span>In jQuery:$('span').hover(function(){    $(this).attr('data-content','bar');});In CSS: span:after {    content: attr(data-content) ' any other text you may want';}If you want to prevent the 'other text' from showing up, you could combine this with seucolega's solution like this:In HTML:<span>foo</span>In jQuery:$('span').hover(function(){    $(this).addClass('change').attr('data-content','bar');});In CSS: span.change:after {    content: attr(data-content) ' any other text you may want';}"
"data_i","edited May 06 '20 at 00:28","
        Show git diff on file in staging area
    ","Is there a way I can see the changes that were made to a file after I have done git add file?That is, when I do: git add filegit diff fileno diff is shown. I guess there's a way to see the differences since the last commit but I don't know what that is.","You can show changes that have been staged with the --cached flag:$ git diff --cachedIn more recent versions of git, you can also use the --staged flag (--staged is a synonym for --cached):$ git diff --staged"
"data_i","edited Apr 17 '20 at 18:09","
        Return multiple values in JavaScript?
    ","I am trying to return two values in JavaScript. Is this possible?  var newCodes = function() {      var dCodes = fg.codecsCodes.rs;    var dCodes2 = fg.codecsCodes2.rs;    return dCodes, dCodes2;};","No, but you could return an array containing your values:function getValues() {    return [getFirstValue(), getSecondValue()];}Then you can access them like so:var values = getValues();var first = values[0];var second = values[1];With the latest ECMAScript 6 syntax*, you can also destructure the return value more intuitively:const [first, second] = getValues();If you want to put ""labels"" on each of the returned values (easier to maintain), you can return an object:function getValues() {    return {        first: getFirstValue(),        second: getSecondValue(),    };}And to access them:var values = getValues();var first = values.first;var second = values.second;Or with ES6 syntax:const {first, second} = getValues();* See this table for browser compatibility. Basically, all modern browsers aside from IE support this syntax, but you can compile ES6 code down to IE-compatible JavaScript at build time with tools like Babel."
"data_i","edited Mar 16 '22 at 16:47","
        How can I trigger the same function from multiple events with jQuery?
    ","Is there a way to have keyup, keypress, blur, and change events call the same function in one line or do I have to do them separately?The problem I have is that I need to validate some data with a db lookup and would like to make sure validation is not missed in any case, whether it is typed or pasted into the box.","You can use .on() to bind a function to multiple events:$('#element').on('keyup keypress blur change', function(e) {    // e.type is the type of event fired});Or just pass the function as the parameter to normal event functions:var myFunction = function() {   ...}$('#element')    .keyup(myFunction)    .keypress(myFunction)    .blur(myFunction)    .change(myFunction)"
"data_i","edited Nov 20 '13 at 15:40","
        How can I get the application's path in a .NET console application?
    ","How do I find the application's path in a console application?In Windows Forms, I can use Application.StartupPath to find the current path, but this doesn't seem to be available in a console application.","System.Reflection.Assembly.GetExecutingAssembly().Location1Combine that with System.IO.Path.GetDirectoryName if all you want is the directory.1As per Mr.Mindor's comment:System.Reflection.Assembly.GetExecutingAssembly().Location returns where the executing assembly is currently located, which may or may not be where the assembly is located when not executing. In the case of shadow copying assemblies, you will get a path in a temp directory. System.Reflection.Assembly.GetExecutingAssembly().CodeBase will return the 'permanent' path of the assembly."
"data_i","edited Aug 19 '20 at 20:46","
        How do I retrieve an HTML element's actual width and height?
    ","Suppose that I have a <div> that I wish to center in the browser's display (viewport). To do so, I need to calculate the width and height of the <div> element. What should I use? Please include information on browser compatibility.","You should use the .offsetWidth and .offsetHeight properties.Note they belong to the element, not .style.var width = document.getElementById('foo').offsetWidth;The .getBoundingClientRect() function returns the dimensions and location of the element as floating-point numbers after performing CSS transforms.> console.log(document.getElementById('foo').getBoundingClientRect())DOMRect {    bottom: 177,    height: 54.7,    left: 278.5,​    right: 909.5,    top: 122.3,    width: 631,    x: 278.5,    y: 122.3,}"
"data_i","edited Mar 15 '21 at 10:32","
        What is the difference between ++i and i++?
    ","In C, what is the difference between using ++i and i++, and which should be used in the incrementation block of a for loop?","++i will increment the value of i, and then return the incremented value. i = 1; j = ++i; (i is 2, j is 2)i++ will increment the value of i, but return the original value that i held before being incremented. i = 1; j = i++; (i is 2, j is 1)For a for loop, either works. ++i seems more common, perhaps because that is what is used in K&R.In any case, follow the guideline ""prefer ++i over i++"" and you won't go wrong.There's a couple of comments regarding the efficiency of ++i and i++. In any non-student-project compiler, there will be no performance difference.  You can verify this by looking at the generated code, which will be identical.The efficiency question is interesting... here's my attempt at an answer:Is there a performance difference between i++ and ++i in C?As @OnFreund notes, it's different for a C++ object, since operator++() is a function and the compiler can't know to optimize away the creation of a temporary object to hold the intermediate value."
"data_i","edited Oct 07 '14 at 08:08","
        Error message ""No exports were found that match the constraint contract name""
    ","This morning I faced a problem while opening my Visual Studio solution, and when I tried to run it, it said:No exports were found that match the constraint contract nameHow can I fix this problem?","I solved this problem by clearing Visual Studio Component Model Cache.Just delete or rename this folder: %LocalAppData%\Microsoft\VisualStudio\11.0\ComponentModelCacheor%LocalAppData%\Microsoft\VPDExpress\11.0\ComponentModelCacheand restart Visual Studio.The version of Visual Studio you have is specified by the number e.g.Visual Studio 2012 is 11.0 (as shown above)Visual Studio 2013 is 12.0Visual Studio 2015 is 14.0Visual Studio 2017 is 15.0Visual Studio 2019 is 16.0For those that don't know: %LocalAppData%\ is the same as C:\Users\{yourUsername}\AppData\LocalFor those who have multiple versions of Visual Studio installed, e.g. 2012 and 2013, it might help to remove the ComponentModelCache for both versions before restarting Visual Studio, e.g. 11.0 and 12.0."
"data_i","edited Aug 06 '21 at 16:10","
        How to convert UTF-8 byte[] to string
    ","I have a byte[] array that is loaded from a file that I happen to known contains UTF-8.In some debugging code, I need to convert it to a string. Is there a one-liner that will do this?Under the covers it should be just an allocation and a memcopy, so even if it is not implemented, it should be possible.","string result = System.Text.Encoding.UTF8.GetString(byteArray);"
"data_i","edited Apr 27 '20 at 12:11","
        List all environment variables from the command line
    ","Is it possible to list all environment variables from a Windows' command prompt?Something equivalent to PowerShell's gci env: (or ls env: or dir env:).","Just do:SETYou can also do SET prefix to see all variables with names starting with prefix.For example, if you want to read only derbydb from the environment variables, do the following: set derby ...and you will get the following: DERBY_HOME=c:\Users\amro-a\Desktop\db-derby-10.10.1.1-bin\db-derby-10.10.1.1-bin"
"data_i","edited Apr 16 '20 at 11:01","
        Why does the C preprocessor interpret the word ""linux"" as the constant ""1""?
    ","Why does the C preprocessor in GCC interpret the word linux (small letters) as the constant 1?test.c:#include <stdio.h>int main(void){           int linux = 5;    return 0;}Result of $ gcc -E test.c (stop after the preprocessing stage):....int main(void){    int 1 = 5;    return 0;}Which of course yields an error.(BTW: There is no #define linux in the stdio.h file.)","In the Old Days (pre-ANSI), predefining symbols such as unix and vax was a way to allow code to detect at compile time what system it was being compiled for. There was no official language standard back then (beyond the reference material at the back of the first edition of K&R), and C code of any complexity was typically a complex maze of #ifdefs to allow for differences between systems. These macro definitions were generally set by the compiler itself, not defined in a library header file. Since there were no real rules about which identifiers could be used by the implementation and which were reserved for programmers, compiler writers felt free to use simple names like unix and assumed that programmers would simply avoid using those names for their own purposes.The 1989 ANSI C standard introduced rules restricting what symbols an implementation could legally predefine. A macro predefined by the compiler could only have a name starting with two underscores, or with an underscore followed by an uppercase letter, leaving programmers free to use identifiers not matching that pattern and not used in the standard library.As a result, any compiler that predefines unix or linux is non-conforming, since it will fail to compile perfectly legal code that uses something like int linux = 5;.As it happens, gcc is non-conforming by default -- but it can be made to conform (reasonably well) with the right command-line options:gcc -std=c90 -pedantic ... # or -std=c89 or -ansigcc -std=c99 -pedanticgcc -std=c11 -pedanticSee the gcc manual for more details.gcc will be phasing out these definitions in future releases, so you shouldn't write code that depends on them. If your program needs to know whether it's being compiled for a Linux target or not it can check whether __linux__ is defined (assuming you're using gcc or a compiler that's compatible with it). See the GNU C preprocessor manual for more information.A largely irrelevant aside: the ""Best One Liner"" winner of the 1987 International Obfuscated C Code Contest, by David Korn (yes, the author of the Korn Shell) took advantage of the predefined unix macro:main() { printf(&unix[""\021%six\012\0""],(unix)[""have""]+""fun""-0x60);}It prints ""unix"", but for reasons that have absolutely nothing to do with the spelling of the macro name."
"data_i","edited Apr 19 '20 at 13:53","
        Why would you use Expression> rather than Func?
    ","I understand lambdas and the Func and Action delegates. But expressions stump me. In what circumstances would you use an Expression<Func<T>> rather than a plain old Func<T>?","When you want to treat lambda expressions as expression trees and look inside them instead of executing them. For example, LINQ to SQL gets the expression and converts it to the equivalent SQL statement and submits it to server (rather than executing the lambda).Conceptually, Expression<Func<T>> is completely different from Func<T>. Func<T> denotes a delegate which is pretty much a pointer to a method and Expression<Func<T>> denotes a tree data structure for a lambda expression. This tree structure describes what a lambda expression does rather than doing the actual thing. It basically holds data about the composition of expressions, variables, method calls, ... (for example it holds information such as this lambda is some constant + some parameter). You can use this description to convert it to an actual method (with Expression.Compile) or do other stuff (like the LINQ to SQL example) with it. The act of treating lambdas as anonymous methods and expression trees is purely a compile time thing.Func<int> myFunc = () => 10; // similar to: int myAnonMethod() { return 10; }will effectively compile to an IL method that gets nothing and returns 10.Expression<Func<int>> myExpression = () => 10;will be converted to a data structure that describes an expression that gets no parameters and returns the value 10:larger imageWhile they both look the same at compile time, what the compiler generates is totally different."
"data_i","edited Jun 13 '22 at 02:49","
        Converting from a string to boolean in Python
    ","How do I convert a string into a boolean in Python? This attempt returns True:>>> bool(""False"")True","Really, you just compare the string to whatever you expect to accept as representing true, so you can do this:s == 'True'Or to checks against a whole bunch of values:s.lower() in ['true', '1', 't', 'y', 'yes', 'yeah', 'yup', 'certainly', 'uh-huh']Be cautious when using the following:>>> bool(""foo"")True>>> bool("""")FalseEmpty strings evaluate to False, but everything else evaluates to True. So this should not be used for any kind of parsing purposes."
"data_i","edited Nov 14 '19 at 11:33","
        How to change the name of an iOS app?
    ","I began an iPhone project the other day with a silly development code name, and now I want to change the name of the project since it's nearly finished. But I'm not sure how to do this with Xcode, trying the obvious of changing the application's name in the info.plist file, causes the signing process to go wrong (I think...) and my app won't launch giving me a Launcher error.I guess I could make a new project and copy paste everything over, but it seems so primitive that I'm hoping for a more civilized solution.","Go to Targets in Xcode.Build Settings on your project's target (your current development name).Search for Product Name under Packaging. Change its value to what you want your new project name to be."
"data_i","edited Oct 19 '15 at 15:38","
        Do the parentheses after the type name make a difference with new?
    ","If 'Test' is an ordinary class, is there any difference between:Test* test = new Test;andTest* test = new Test();","Let's get pedantic, because there are differences that can actually affect your code's behavior. Much of the following is taken from comments made to an ""Old New Thing"" article.Sometimes the memory returned by the new operator will be initialized, and sometimes it won't depending on whether the type you're newing up is a POD (plain old data), or if it's a class that contains POD members and is using a compiler-generated default constructor.In C++1998 there are 2 types of initialization: zero and defaultIn C++2003 a 3rd type of initialization, value initialization was added.Assume:struct A { int m; }; // PODstruct B { ~B(); int m; }; // non-POD, compiler generated default ctorstruct C { C() : m() {}; ~C(); int m; }; // non-POD, default-initialising mIn a C++98 compiler, the following should occur:new A   - indeterminate valuenew A() - zero-initializenew B   - default construct (B::m is uninitialized)new B() - default construct (B::m is uninitialized)new C   - default construct (C::m is zero-initialized)new C() - default construct (C::m is zero-initialized)In a C++03 conformant compiler, things should work like so:new A    - indeterminate valuenew A()  - value-initialize A, which is zero-initialization since it's a POD.new B    - default-initializes (leaves B::m uninitialized)new B()  - value-initializes B which zero-initializes all fields since its default ctor is compiler generated as opposed to user-defined.new C    - default-initializes C, which calls the default ctor.new C()  - value-initializes C, which calls the default ctor.So in all versions of C++ there's a difference between new A and new A() because A is a POD.And there's a difference in behavior between C++98 and C++03 for the case new B().This is one of the dusty corners of C++ that can drive you crazy. When constructing an object, sometimes you want/need the parens, sometimes you absolutely cannot have them, and sometimes it doesn't matter."
"data_i","edited Jul 07 '21 at 21:17","
        How to add dividers and spaces between items in RecyclerView
    ","This is an example of how it could have been done previously in the ListView class, using the divider and dividerHeight parameters:<ListView    android:id=""@+id/activity_home_list_view""    android:layout_width=""match_parent""    android:layout_height=""match_parent""    android:divider=""@android:color/transparent""    android:dividerHeight=""8dp""/>However, I don't see such possibility in the RecyclerView class.<android.support.v7.widget.RecyclerView    android:id=""@+id/activity_home_recycler_view""    android:layout_width=""match_parent""    android:layout_height=""match_parent""    android:scrollbars=""vertical""/>In that case, is it ok to define margins and/or add a custom divider view directly into a list item's layout or is there a better way to achieve my goal?","October 2016 UpdateThe version 25.0.0 of Android Support Library introduced the DividerItemDecoration class:DividerItemDecoration is a RecyclerView.ItemDecoration that can be used as a divider between items of a LinearLayoutManager. It supports both HORIZONTAL and VERTICAL orientations.Usage:DividerItemDecoration dividerItemDecoration = new DividerItemDecoration(recyclerView.getContext(),    layoutManager.getOrientation());recyclerView.addItemDecoration(dividerItemDecoration);Previous answerSome answers either use methods that have since become deprecated, or don't give a complete solution, so I tried to do a short, up-to-date wrap-up.Unlike ListView, the RecyclerView class doesn't have any divider-related parameters. Instead, you need to extend ItemDecoration, a RecyclerView's inner class:An ItemDecoration allows the application to add a special drawing and layout offset to specific item views from the adapter's data set. This can be useful for drawing dividers between items, highlights, visual grouping boundaries and more.All ItemDecorations are drawn in the order they were added, before the item views (in onDraw()) and after the items (in onDrawOver(Canvas, RecyclerView, RecyclerView.State).Vertical spacing ItemDecorationExtend ItemDecoration, add a custom constructor which takes space height as a parameter and override the getItemOffsets() method:public class VerticalSpaceItemDecoration extends RecyclerView.ItemDecoration {    private final int verticalSpaceHeight;    public VerticalSpaceItemDecoration(int verticalSpaceHeight) {        this.verticalSpaceHeight = verticalSpaceHeight;    }    @Override    public void getItemOffsets(Rect outRect, View view, RecyclerView parent,            RecyclerView.State state) {        outRect.bottom = verticalSpaceHeight;    }}If you don't want to insert space below the last item, add the following condition:if (parent.getChildAdapterPosition(view) != parent.getAdapter().getItemCount() - 1) {            outRect.bottom = verticalSpaceHeight;}Note: you can also modify outRect.top, outRect.left and outRect.right properties for the desired effect.Divider ItemDecorationExtend ItemDecoration and override the onDraw() method:public class DividerItemDecoration extends RecyclerView.ItemDecoration {    private static final int[] ATTRS = new int[]{android.R.attr.listDivider};    private Drawable divider;    /**     * Default divider will be used     */    public DividerItemDecoration(Context context) {        final TypedArray styledAttributes = context.obtainStyledAttributes(ATTRS);        divider = styledAttributes.getDrawable(0);        styledAttributes.recycle();    }    /**     * Custom divider will be used     */    public DividerItemDecoration(Context context, int resId) {        divider = ContextCompat.getDrawable(context, resId);    }    @Override    public void onDraw(Canvas c, RecyclerView parent, RecyclerView.State state) {        int left = parent.getPaddingLeft();        int right = parent.getWidth() - parent.getPaddingRight();        int childCount = parent.getChildCount();        for (int i = 0; i < childCount; i++) {            View child = parent.getChildAt(i);            RecyclerView.LayoutParams params = (RecyclerView.LayoutParams) child.getLayoutParams();            int top = child.getBottom() + params.bottomMargin;            int bottom = top + divider.getIntrinsicHeight();            divider.setBounds(left, top, right, bottom);            divider.draw(c);        }    }}You can either call the first constructor that uses the default Android divider attributes, or the second one that uses your own drawable, for example drawable/divider.xml:<?xml version=""1.0"" encoding=""utf-8""?><shape xmlns:android=""http://schemas.android.com/apk/res/android""       android:shape=""rectangle"">    <size android:height=""1dp"" />    <solid android:color=""#ff992900"" /></shape>Note: if you want the divider to be drawn over your items, override the onDrawOver() method instead.UsageTo use your new class, add VerticalSpaceItemDecoration or DividerSpaceItemDecoration to RecyclerView, for example in your fragment's onCreateView() method:private static final int VERTICAL_ITEM_SPACE = 48;private RecyclerView recyclerView;private LinearLayoutManager linearLayoutManager;@Overridepublic View onCreateView(LayoutInflater inflater, ViewGroup container,        Bundle savedInstanceState) {    View rootView = inflater.inflate(R.layout.fragment_feed, container, false);    recyclerView = (RecyclerView) rootView.findViewById(R.id.fragment_home_recycler_view);    linearLayoutManager = new LinearLayoutManager(getActivity());    recyclerView.setLayoutManager(linearLayoutManager);    //add ItemDecoration    recyclerView.addItemDecoration(new VerticalSpaceItemDecoration(VERTICAL_ITEM_SPACE));    //or    recyclerView.addItemDecoration(new DividerItemDecoration(getActivity()));    //or    recyclerView.addItemDecoration(            new DividerItemDecoration(getActivity(), R.drawable.divider));    recyclerView.setAdapter(...);    return rootView;}There's also Lucas Rocha's library which is supposed to simplify the item decoration process. I haven't tried it though.Among its features are:A collection of stock item decorations including:Item spacing Horizontal/vertical dividers.List item"
"data_i","edited Jun 08 '18 at 12:38","
        Is there a float input type in HTML5?
    ","According to html5.org, the ""number"" input type's ""value attribute, if specified and not empty, must have a value that is a valid floating point number.""Yet it is simply (in the latest version of Chrome, anyway), an ""updown"" control with integers, not floats:<input type=""number"" id=""totalAmt""></input>Is there a floating point input element native to HTML5, or a way to make the number input type work with floats, not ints? Or must I resort to a jQuery UI plugin?","The number type has a step value controlling which numbers are valid (along with max and min), which defaults to 1. This value is also used by implementations for the stepper buttons (i.e. pressing up increases by step).Simply change this value to whatever is appropriate. For money, two decimal places are probably expected:<label for=""totalAmt"">Total Amount</label><input type=""number"" step=""0.01"" id=""totalAmt"">(I'd also set min=0 if it can only be positive)If you'd prefer to allow any number of decimal places, you can use step=""any"" (though for currencies, I'd recommend sticking to 0.01). In Chrome & Firefox, the stepper buttons will increment / decrement by 1 when using any. (thanks to Michal Stefanow's answer for pointing out any, and see the relevant spec here)Here's a playground showing how various steps affect various input types:<form>  <input type=number step=1 /> Step 1 (default)<br />  <input type=number step=0.01 /> Step 0.01<br />  <input type=number step=any /> Step any<br />  <input type=range step=20 /> Step 20<br />  <input type=datetime-local step=60 /> Step 60 (default)<br />  <input type=datetime-local step=1 /> Step 1<br />  <input type=datetime-local step=any /> Step any<br />  <input type=datetime-local step=0.001 /> Step 0.001<br />  <input type=datetime-local step=3600 /> Step 3600 (1 hour)<br />  <input type=datetime-local step=86400 /> Step 86400 (1 day)<br />  <input type=datetime-local step=70 /> Step 70 (1 min, 10 sec)<br /></form>As usual, I'll add a quick note: remember that client-side validation is just a convenience to the user. You must also validate on the server-side!"
"data_i","edited Jun 20 '20 at 09:12","
        jQuery's jquery-1.10.2.min.map is triggering a 404 (Not Found)
    ","I'm seeing error messages about a file, min.map, being not found:GET jQuery's jquery-1.10.2.min.map is triggering a 404 (Not Found)ScreenshotWhere is this coming from?","If Chrome DevTools is reporting a 404 for a .map file (maybe jquery-1.10.2.min.map, jquery.min.map or jquery-2.0.3.min.map, but can happen with anything) first thing to know is this is only requested when using the DevTools. Your users will not be hitting this 404.Now you can fix this or disable the sourcemap functionality. Fix: get the filesNext, it's an easy fix. Head to http://jquery.com/download/ and click the Download the map file link for your version, and you'll want the uncompressed file downloaded as well.Having the map file in place allows you do debug your minified jQuery via the original sources, which will save a lot of time and frustration if you don't like dealing with variable names like a and c. More about sourcemaps here: An Introduction to JavaScript Source MapsDodge: disable sourcemapsInstead of getting the files, you can alternatively disable JavaScript source maps completely for now, in your settings. This is a fine choice if you never plan on debugging JavaScript on this page.Use the cog icon in the bottom right of the DevTools, to open settings, then:"
"data_i","edited Jul 04 '22 at 15:33","
        How can I access and process nested objects, arrays, or JSON?
    ","I have a nested data structure containing objects and arrays. How can I extract the information, i.e. access a specific or multiple values (or keys)?For example:var data = {    code: 42,    items: [{        id: 1,        name: 'foo'    }, {        id: 2,        name: 'bar'    }]};How could I access the name of the second item in items?","PreliminariesJavaScript has only one data type which can contain multiple values: Object. An Array is a special form of object.(Plain) Objects have the form{key: value, key: value, ...}Arrays have the form[value, value, ...]Both arrays and objects expose a key -> value structure. Keys in an array must be numeric, whereas any string can be used as key in objects. The key-value pairs are also called the ""properties"".Properties can be accessed either using dot notationconst value = obj.someProperty;or bracket notation, if the property name would not be a valid JavaScript identifier name [spec], or the name is the value of a variable:// the space is not a valid character in identifier namesconst value = obj[""some Property""];// property name as variableconst name = ""some Property"";const value = obj[name];For that reason, array elements can only be accessed using bracket notation:const value = arr[5]; // arr.5 would be a syntax error// property name / index as variableconst x = 5;const value = arr[x];Wait... what about JSON?JSON is a textual representation of data, just like XML, YAML, CSV, and others. To work with such data, it first has to be converted to JavaScript data types, i.e. arrays and objects (and how to work with those was just explained). How to parse JSON is explained in the question Parse JSON in JavaScript? .Further reading materialHow to access arrays and objects is fundamental JavaScript knowledge and therefore it is advisable to read the MDN JavaScript Guide, especially the sectionsWorking with ObjectsArraysEloquent JavaScript - Data StructuresAccessing nested data structuresA nested data structure is an array or object which refers to other arrays or objects, i.e. its values are arrays or objects. Such structures can be accessed by consecutively applying dot or bracket notation. Here is an example:const data = {    code: 42,    items: [{        id: 1,        name: 'foo'    }, {        id: 2,        name: 'bar'    }]};Let's assume we want to access the name of the second item. Here is how we can do it step-by-step:As we can see data is an object, hence we can access its properties using dot notation. The items property is accessed as follows:data.itemsThe value is an array, to access its second element, we have to use bracket notation:data.items[1]This value is an object and we use dot notation again to access the name property. So we eventually get:const item_name = data.items[1].name;Alternatively, we could have used bracket notation for any of the properties, especially if the name contained characters that would have made it invalid for dot notation usage:const item_name = data['items'][1]['name'];I'm trying to access a property but I get only undefined back?Most of the time when you are getting undefined, the object/array simply doesn't have a property with that name.const foo = {bar: {baz: 42}};console.log(foo.baz); // undefinedUse console.log or console.dir and inspect the structure of object / array. The property you are trying to access might be actually defined on a nested object / array.console.log(foo.bar.baz); // 42What if the property names are dynamic and I don't know them beforehand?If the property names are unknown or we want to access all properties of an object / elements of an array, we can use the for...in [MDN] loop for objects and the for [MDN] loop for arrays to iterate over all properties / elements.ObjectsTo iterate over all properties of data, we can iterate over the object like so:for (const prop in data) {    // `prop` contains the name of each property, i.e. `'code'` or `'items'`    // consequently, `data[prop]` refers to the value of each property, i.e.    // either `42` or the array}Depending on where the object comes from (and what you want to do), you might have to test in each iteration whether the property is really a property of the object, or it is an inherited property. You can do this with Object#hasOwnProperty [MDN].As alternative to for...in with hasOwnProperty, you can use Object.keys [MDN] to get an array of property names:Object.keys(data).forEach(function(prop) {  // `prop` is the property name  // `data[prop]` is the property value});ArraysTo iterate over all elements of the data.items array, we use a for loop:for(let i = 0, l = data.items.length; i < l; i++) {    // `i` will take on the values `0`, `1`, `2`,..., i.e. in each iteration    // we can access the next element in the array with `data.items[i]`, example:    //     // var obj = data.items[i];    //     // Since each element is an object (in our example),    // we can now access the objects properties with `obj.id` and `obj.name`.     // We could also use `data.items[i].id`.}One could also use for...in to iterate over arrays, but there are reasons why this should be avoided: Why is 'for(var item in list)' with arrays considered bad practice in JavaScript?.With the increasing browser support of ECMAScript 5, the array method forEach [MDN] becomes an interesting alternative as well:data.items.forEach(function(value, index, array) {    // The callback is executed for each element in the array.    // `value` is the element itself (equivalent to `array[index]`)    // `index` will be the index of the element in the array    // `array` is a reference to the array itself (i.e. `data.items` in this case)}); In environments supporting ES2015 (ES6), you can also use the for...of [MDN] loop, which not only works for arrays, but for any iterable:for (const item of data.items) {   // `item` is the array element, **not** the index}In each iteration, for...of directly gives us the next element of the iterable, there is no ""index"" to access or use.What if the ""depth"" of the data structure is unknown to me?In addition to unknown keys, the ""depth"" of the data structure (i.e. how many nested objects) it has, might be unknown as well. How to access deeply nested properties usually depends on the exact data structure.But if the data structure contains repeating patterns, e.g. the representation of a binary tree, the solution typically includes to recursively [Wikipedia] access each level of the data structure.Here is an example to get the first leaf node of a binary tree:function getLeaf(node) {    if (node.leftChild) {        return getLeaf(node.leftChild); // <- recursive call    }    else if (node.rightChild) {        return getLeaf(node.rightChild); // <- recursive call    }    else { // node must be a leaf node        return node;    }}const first_leaf = getLeaf(root);const root = {    leftChild: {        leftChild: {            leftChild: null,            rightChild: null,            data: 42        },        rightChild: {            leftChild: null,            rightChild: null,            data: 5        }    },    rightChild: {        leftChild: {            leftChild: null,            rightChild: null,            data: 6        },        rightChild: {            leftChild: null,            rightChild: null,            data: 7        }    }};function getLeaf(node) {    if (node.leftChild) {        return getLeaf(node.leftChild);    } else if (node.rightChild) {        return getLeaf(node.rightChild);    } else { // node must be a leaf node        return node;    }}console.log(getLeaf(root).data);A more generic way to access a nested data structure with unknown keys and depth is to test the type of the value and act accordingly.Here is an example which adds all primitive values inside a nested data structure into an array (assuming it does not contain any functions). If we encounter an object (or array) we simply call toArray again on that value (recursive call).function toArray(obj) {    const result = [];    for (const prop in obj) {        const value = obj[prop];        if (typeof value === 'object') {            result.push(toArray(value)); // <- recursive call        }        else {            result.push(value);        }    }    return result;}const data = {  code: 42,  items: [{    id: 1,    name: 'foo'  }, {    id: 2,    name: 'bar'  }]};function toArray(obj) {  const result = [];  for (const prop in obj) {    const value = obj[prop];    if (typeof value === 'object') {      result.push(toArray(value));    } else {      result.push(value);    }  }  return result;}console.log(toArray(data));HelpersSince the structure of a complex object or array is not necessarily obvious, we can inspect the value at each step to decide how to move further. console.log [MDN] and console.dir [MDN] help us doing this. For example (output of the Chrome console):> console.log(data.items) [ Object, Object ]Here we see that that data.items is an array with two elements which are both objects. In Chrome console the objects can even be expanded and inspected immediately.> console.log(data.items[1])  Object     id: 2     name: ""bar""     __proto__: ObjectThis tells us that data.items[1] is an object, and after expanding it we see that it has three properties, id, name and __proto__. The latter is an internal property used for the prototype chain of the object. The prototype chain and inheritance is out of scope for this answer, though."
"data_i","edited Sep 14 '19 at 19:41","
        How to convert list to string
    ","How can I convert a list to a string using Python?","Use ''.join:xs = ['1', '2', '3']s = ''.join(xs)If the list contains integers, convert the elements to string before joining them:xs = [1, 2, 3]s = ''.join(str(x) for x in xs)"
"data_i","edited Dec 12 '19 at 14:04","
        What is the difference between g++ and gcc?
    ","What is the difference between g++ and gcc?  Which one of them should be used for general c++ development?","gcc and g++ are compiler-drivers of the GNU Compiler Collection (which was once upon a time just the GNU C Compiler).Even though they automatically determine which backends (cc1 cc1plus ...) to call depending on the file-type, unless overridden with -x language, they have some differences.The probably most important difference in their defaults is which libraries they link against automatically.According to GCC's online documentation link options and how g++ is invoked, g++ is equivalent to gcc -xc++ -lstdc++ -shared-libgcc (the 1st is a compiler option, the 2nd two are linker options). This can be checked by running both with the -v option (it displays the backend toolchain commands being run)."
"data_i","edited May 10 '21 at 11:20","
        How to manage startActivityForResult on Android
    ","In my activity, I'm calling a second activity from the main activity by startActivityForResult. In my second activity, there are some methods that finish this activity (maybe without a result), however, just one of them returns a result.For example, from the main activity, I call a second one. In this activity, I'm checking some features of a handset, such as does it have a camera. If it doesn't have then I'll close this activity. Also, during the preparation of MediaRecorder or MediaPlayer if a problem happens then I'll close this activity.If its device has a camera and recording is done completely, then after recording a video if a user clicks on the done button then I'll send the result (address of the recorded video) back to the main activity.How do I check the result from the main activity?","From your FirstActivity, call the SecondActivity using the startActivityForResult() method.For example:int LAUNCH_SECOND_ACTIVITY = 1Intent i = new Intent(this, SecondActivity.class);startActivityForResult(i, LAUNCH_SECOND_ACTIVITY);In your SecondActivity, set the data which you want to return back to FirstActivity. If you don't want to return back, don't set any.For example: In SecondActivity if you want to send back data:Intent returnIntent = new Intent();returnIntent.putExtra(""result"",result);setResult(Activity.RESULT_OK,returnIntent);finish();If you don't want to return data:Intent returnIntent = new Intent();setResult(Activity.RESULT_CANCELED, returnIntent);finish();Now in your FirstActivity class, write the following code for the onActivityResult() method.@Overrideprotected void onActivityResult(int requestCode, int resultCode, Intent data) {    super.onActivityResult(requestCode, resultCode, data);    if (requestCode == LAUNCH_SECOND_ACTIVITY) {        if(resultCode == Activity.RESULT_OK){            String result=data.getStringExtra(""result"");        }        if (resultCode == Activity.RESULT_CANCELED) {            // Write your code if there's no result        }    }} //onActivityResultTo implement passing data between two activities in a much better way in Kotlin, please go through 'A better way to pass data between Activities'."
"data_i","edited Mar 14 '18 at 17:41","
        How can I move a tag on a git branch to a different commit?
    ","I created a tag on the master branch called v0.1 like this:git tag -a v0.1But then I realized there were still some changes I needed to merge into master for release 0.1, so I did that. But now my v0.1 tag is stuck on (to invoke the post-it note analogy) the wrong commit. I want it to be stuck on the most recent commit on master, but instead it is stuck on the second most recent commit on master.How can I move it to the most recent commit on master?","Use the -f option to git tag:-f--force    Replace an existing tag with the given name (instead of failing)You probably want to use -f in conjunction with -a to force-create an annotated tag instead of a non-annotated one.ExampleDelete the tag on any remote before you pushgit push origin :refs/tags/<tagname>Replace the tag to reference the most recent commitgit tag -fa <tagname>Push the tag to the remote origingit push origin master --tags"
"data_i","edited Dec 25 '17 at 15:07","
        Error: Can't set headers after they are sent to the client
    ","I'm fairly new to Node.js and I am having some issues.I am using Node.js 4.10 and Express 2.4.3.When I try to access http://127.0.0.1:8888/auth/facebook, i'll be redirected to http://127.0.0.1:8888/auth/facebook_callback.I then received the following error:Error: Can't render headers after they are sent to the client.    at ServerResponse.<anonymous> (http.js:573:11)    at ServerResponse._renderHeaders (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/patch.js:64:25)    at ServerResponse.writeHead (http.js:813:20)    at /home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect-auth/lib/auth.strategies/facebook.js:28:15    at /home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect-auth/lib/index.js:113:13    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect-auth/lib/strategyExecutor.js:45:39)    at [object Object].pass (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect-auth/lib/authExecutionScope.js:32:3)    at [object Object].halt (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect-auth/lib/authExecutionScope.js:29:8)    at [object Object].redirect (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect-auth/lib/authExecutionScope.js:16:8)    at [object Object].<anonymous> (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect-auth/lib/auth.strategies/facebook.js:77:15)Error: Can't set headers after they are sent.    at ServerResponse.<anonymous> (http.js:527:11)    at ServerResponse.setHeader (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/patch.js:50:20)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:162:13)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:195:11)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:150:23)    at param (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/middleware/router.js:189:13)    at pass (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/middleware/router.js:191:10)    at Object.router [as handle] (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/middleware/router.js:197:6)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:198:15)    at Object.auth [as handle] (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect-auth/lib/index.js:153:7)Error: Can't set headers after they are sent.    at ServerResponse.<anonymous> (http.js:527:11)    at ServerResponse.setHeader (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/patch.js:50:20)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:162:13)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:207:9)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:150:23)    at param (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/middleware/router.js:189:13)    at pass (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/middleware/router.js:191:10)    at Object.router [as handle] (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/middleware/router.js:197:6)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:198:15)    at Object.auth [as handle] (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect-auth/lib/index.js:153:7)Error: Can't set headers after they are sent.    at ServerResponse.<anonymous> (http.js:527:11)    at ServerResponse.setHeader (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/patch.js:50:20)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:162:13)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:150:23)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:207:9)    at Object.auth [as handle] (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect-auth/lib/index.js:153:7)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:198:15)    at HTTPServer.handle (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:211:3)    at Object.handle (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:105:14)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:198:15)Error: Can't set headers after they are sent.    at ServerResponse.<anonymous> (http.js:527:11)    at ServerResponse.setHeader (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/patch.js:50:20)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:162:13)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:150:23)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:207:9)    at HTTPServer.handle (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:211:3)    at Object.handle (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:105:14)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:198:15)    at /home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/middleware/session.js:323:9    at /home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/middleware/session.js:338:9node.js:134        throw e; // process.nextTick error, or 'error' event on first tick        ^Error: Can't set headers after they are sent.    at ServerResponse.<anonymous> (http.js:527:11)    at ServerResponse.setHeader (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/patch.js:50:20)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:162:13)    at next (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/http.js:207:9)    at /home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/middleware/session.js:323:9    at /home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/middleware/session.js:338:9    at Array.<anonymous> (/home/eugene/public_html/all_things_node/projects/fb2/node_modules/connect/lib/middleware/session/memory.js:57:7)    at EventEmitter._tickCallback (node.js:126:26)The following is my code:var fbId= ""XXX"";var fbSecret= ""XXXXXX"";var fbCallbackAddress= ""http://127.0.0.1:8888/auth/facebook_callback""var cookieSecret = ""node"";     // enter a random hash for securityvar express= require('express');var auth = require('connect-auth')var app = express.createServer();app.configure(function(){    app.use(express.bodyParser());    app.use(express.methodOverride());    app.use(express.cookieParser());    app.use(express.session({secret: cookieSecret}));    app.use(auth([        auth.Facebook({            appId : fbId,            appSecret: fbSecret,            callback: fbCallbackAddress,            scope: 'offline_access,email,user_about_me,user_activities,manage_pages,publish_stream',            failedUri: '/noauth'        })    ]));    app.use(app.router);});app.get('/auth/facebook', function(req, res) {  req.authenticate(""facebook"", function(error, authenticated) {    if (authenticated) {      res.redirect(""/great"");      console.log(""ok cool."");      console.log(res['req']['session']);    }  });});app.get('/noauth', function(req, res) {  console.log('Authentication Failed');  res.send('Authentication Failed');});app.get('/great', function( req, res) {  res.send('Supercoolstuff');});app.listen(8888);May I know what is wrong with my code?","The res object in Express is a subclass of Node.js's http.ServerResponse (read the http.js source). You are allowed to call res.setHeader(name, value) as often as you want until you call res.writeHead(statusCode). After writeHead, the headers are baked in and you can only call res.write(data), and finally res.end(data).The error ""Error: Can't set headers after they are sent."" means that you're already in the Body or Finished state, but some function tried to set a header or statusCode. When you see this error, try to look for anything that tries to send a header after some of the body has already been written. For example, look for callbacks that are accidentally called twice, or any error that happens after the body is sent.In your case, you called res.redirect(), which caused the response to become Finished. Then your code threw an error (res.req is null). and since the error happened within your actual function(req, res, next) (not within a callback), Connect was able to catch it and then tried to send a 500 error page. But since the headers were already sent, Node.js's setHeader threw the error that you saw.Comprehensive list of Node.js/Express response methods and when they must be called:Response must be in Head and remains in Head:res.writeContinue()res.statusCode = 404res.setHeader(name, value)res.getHeader(name)res.removeHeader(name)res.header(key[, val]) (Express only)res.charset = 'utf-8' (Express only; only affects Express-specific methods)res.contentType(type) (Express only)Response must be in Head and becomes Body:res.writeHead(statusCode, [reasonPhrase], [headers])Response can be in either Head/Body and remains in Body:res.write(chunk, encoding='utf8')Response can be in either Head/Body and becomes Finished:res.end([data], [encoding])Response can be in either Head/Body and remains in its current state:res.addTrailers(headers)Response must be in Head and becomes Finished:return next([err]) (Connect/Express only)Any exceptions within middleware function(req, res, next) (Connect/Express only)res.send(body|status[, headers|status[, status]]) (Express only)res.attachment(filename) (Express only)res.sendfile(path[, options[, callback]]) (Express only)res.json(obj[, headers|status[, status]]) (Express only)res.redirect(url[, status]) (Express only)res.cookie(name, val[, options]) (Express only)res.clearCookie(name[, options]) (Express only)res.render(view[, options[, fn]]) (Express only)res.partial(view[, options]) (Express only)"
"data_i","edited Jun 08 '21 at 07:28","
        When should I use CROSS APPLY over INNER JOIN?
    ","What is the main purpose of using CROSS APPLY?I have read (vaguely, through posts on the Internet) that cross apply can be more efficient when selecting over large data sets if you are partitioning. (Paging comes to mind)I also know that CROSS APPLY doesn't require a UDF as the right-table.In most INNER JOIN queries (one-to-many relationships), I could rewrite them to use CROSS APPLY, but they always give me equivalent execution plans. Can anyone give me a good example of when CROSS APPLY makes a difference in those cases where INNER JOIN will work as well?Edit:Here's a trivial example, where the execution plans are exactly the same.  (Show me one where they differ and where cross apply is faster/more efficient)create table Company (    companyId int identity(1,1),   companyName varchar(100),   zipcode varchar(10) ,   constraint PK_Company primary key (companyId))GOcreate table Person (    personId int identity(1,1),   personName varchar(100),   companyId int,   constraint FK_Person_CompanyId foreign key (companyId) references dbo.Company(companyId),   constraint PK_Person primary key (personId))GOinsert Companyselect 'ABC Company', '19808' unionselect 'XYZ Company', '08534' unionselect '123 Company', '10016'insert Personselect 'Alan', 1 unionselect 'Bobby', 1 unionselect 'Chris', 1 unionselect 'Xavier', 2 unionselect 'Yoshi', 2 unionselect 'Zambrano', 2 unionselect 'Player 1', 3 unionselect 'Player 2', 3 unionselect 'Player 3', 3 /* using CROSS APPLY */select *from Person pcross apply (    select *    from Company c    where p.companyid = c.companyId) Czip/* the equivalent query using INNER JOIN */select *from Person pinner join Company c on p.companyid = c.companyId","Can anyone give me a good example of when CROSS APPLY makes a difference in those cases where INNER JOIN will work as well?See the article in my blog for detailed performance comparison:INNER JOIN vs. CROSS APPLYCROSS APPLY works better on things that have no simple JOIN condition.This one selects 3 last records from t2 for each record from t1:SELECT  t1.*, t2o.*FROM    t1CROSS APPLY        (        SELECT  TOP 3 *        FROM    t2        WHERE   t2.t1_id = t1.id        ORDER BY                t2.rank DESC        ) t2oIt cannot be easily formulated with an INNER JOIN condition.You could probably do something like that using CTE's and window function:WITH    t2o AS        (        SELECT  t2.*, ROW_NUMBER() OVER (PARTITION BY t1_id ORDER BY rank) AS rn        FROM    t2        )SELECT  t1.*, t2o.*FROM    t1INNER JOIN        t2oON      t2o.t1_id = t1.id        AND t2o.rn <= 3, but this is less readable and probably less efficient.Update:Just checked.master is a table of about 20,000,000 records with a PRIMARY KEY on id.This query:WITH    q AS        (        SELECT  *, ROW_NUMBER() OVER (ORDER BY id) AS rn        FROM    master        ),        t AS         (        SELECT  1 AS id        UNION ALL        SELECT  2        )SELECT  *FROM    tJOIN    qON      q.rn <= t.idruns for almost 30 seconds, while this one:WITH    t AS         (        SELECT  1 AS id        UNION ALL        SELECT  2        )SELECT  *FROM    tCROSS APPLY        (        SELECT  TOP (t.id) m.*        FROM    master m        ORDER BY                id        ) qis instant."
"data_i","edited Mar 05 '19 at 02:35","
        How is an HTTP POST request made in node.js?
    ","How can I make an outbound HTTP POST request, with data, in node.js?","request is now deprecated. It is recommended you use an alternativeIn no particular order and dreadfully incomplete:native HTTP/S, const https = require('https');node-fetchaxiosgotsuperagentbentmake-fetch-happenunfetchtiny-json-httpneedleurllibStats comparisionSome code examplesOriginal answer:This gets a lot easier if you use the request library.var request = require('request');request.post(    'http://www.yoursite.com/formpage',    { json: { key: 'value' } },    function (error, response, body) {        if (!error && response.statusCode == 200) {            console.log(body);        }    });Aside from providing a nice syntax it makes json requests easy, handles oauth signing (for twitter, etc.), can do multi-part forms (e.g. for uploading files) and streaming.To install request use command npm install request"
"data_i","edited Apr 19 '20 at 17:13","
        Can I call a constructor from another constructor (do constructor chaining) in C++?
    ","As a C# developer I'm used to running through constructors:class Test {    public Test() {        DoSomething();    }    public Test(int count) : this() {        DoSomethingWithCount(count);    }    public Test(int count, string name) : this(count) {        DoSomethingWithName(name);    }}Is there a way to do this in C++?I tried calling the Class name and using the 'this' keyword, but both fail.","C++11: Yes!C++11 and onwards has this same feature (called delegating constructors). The syntax is slightly different from C#:class Foo {public:   Foo(char x, int y) {}  Foo(int y) : Foo('a', y) {}};C++03: NoUnfortunately, there's no way to do this in C++03, but there are two ways of simulating this:You can combine two (or more) constructors via default parameters:class Foo {public:  Foo(char x, int y=0);  // combines two constructors (char) and (char, int)  // ...};Use an init method to share common code:class Foo {public:  Foo(char x);  Foo(char x, int y);  // ...private:  void init(char x, int y);};Foo::Foo(char x){  init(x, int(x) + 7);  // ...}Foo::Foo(char x, int y){  init(x, y);  // ...}void Foo::init(char x, int y){  // ...}See the C++FAQ entry for reference."
"data_i","edited Mar 28 '12 at 03:50","
        What is the difference between a port and a socket?
    ","This was a question raised by one of the software engineers in my organisation.  I'm interested in the broadest definition.","SummaryA TCP socket is an endpoint instance defined by an IP address and a port in the context of either a particular TCP connection or the listening state.A port is a virtualisation identifier defining a service endpoint (as distinct from a service instance endpoint aka session identifier).A TCP socket is not a connection, it is the endpoint of a specific connection.There can be concurrent connections to a service endpoint, because a connection is identified by both its local and remote endpoints, allowing traffic to be routed to a specific service instance.There can only be one listener socket for a given address/port combination.ExpositionThis was an interesting question that forced me to re-examine a number of things I thought I knew inside out. You'd think a name like ""socket"" would be self-explanatory: it was obviously chosen to evoke imagery of the endpoint into which you plug a network cable, there being strong functional parallels. Nevertheless, in network parlance the word ""socket"" carries so much baggage that a careful re-examination is necessary.In the broadest possible sense, a port is a point of ingress or egress. Although not used in a networking context, the French word porte literally means door or gateway, further emphasising the fact that ports are transportation endpoints whether you ship data or big steel containers.For the purpose of this discussion I will limit consideration to the context of TCP-IP networks. The OSI model is all very well but has never been completely implemented, much less widely deployed in high-traffic high-stress conditions.The combination of an IP address and a port is strictly known as an endpoint and is sometimes called a socket. This usage originates with RFC793, the original TCP specification.A TCP connection is defined by two endpoints aka sockets.An endpoint (socket) is defined by the combination of a network address and a port identifier. Note that address/port does not completely identify a socket (more on this later).The purpose of ports is to differentiate multiple endpoints on a given network address. You could say that a port is a virtualised endpoint. This virtualisation makes multiple concurrent connections on a single network interface possible.It is the socket pair (the 4-tupleconsisting of the client IP address,client port number, server IP address,and server port number) that specifiesthe two endpoints that uniquelyidentifies each TCP connection in aninternet. (TCP-IP Illustrated Volume 1, W. Richard Stevens)In most C-derived languages, TCP connections are established and manipulated using methods on an instance of a Socket class. Although it is common to operate on a higher level of abstraction, typically an instance of a NetworkStream class, this generally exposes a reference to a socket object. To the coder this socket object appears to represent the connection because the connection is created and manipulated using methods of the socket object.In C#, to establish a TCP connection (to an existing listener) first you create a TcpClient. If you don't specify an endpoint to the TcpClient constructor it uses defaults - one way or another the local endpoint is defined. Then you invoke the Connectmethod on the instance you've created. This method requires a parameter describing the other endpoint.All this is a bit confusing and leads you to believe that a socket is a connection, which is bollocks. I was labouring under this misapprehension until Richard Dorman asked the question.Having done a lot of reading and thinking, I'm now convinced that it would make a lot more sense to have a class TcpConnection with a constructor that takes two arguments, LocalEndpoint and RemoteEndpoint. You could probably support a single argument RemoteEndpoint when defaults are acceptable for the local endpoint. This is ambiguous on multihomed computers, but the ambiguity can be resolved using the routing table by selecting the interface with the shortest route to the remote endpoint.Clarity would be enhanced in other respects, too. A socket is not identified by the combination of IP address and port:[...]TCP demultiplexes incoming segments using all four values that comprise the local and foreign addresses: destination IP address, destination port number, source IP address, and source port number. TCP cannot determine which process gets an incoming segment by looking at the destination port only. Also, the only one of the [various] endpoints at [a given port number] that will receive incoming connection requests is the one in the listen state. (p255, TCP-IP Illustrated Volume 1, W. Richard Stevens)As you can see, it is not just possible but quite likely for a network service to have numerous sockets with the same address/port, but only one listener socket on a particular address/port combination. Typical library implementations present a socket class, an instance of which is used to create and manage a connection. This is extremely unfortunate, since it causes confusion and has lead to widespread conflation of the two concepts.Hagrawal doesn't believe me (see comments) so here's a real sample. I connected a web browser to http://dilbert.com and then ran netstat -an -p tcp. The last six lines of the output contain two examples of the fact that address and port are not enough to uniquely identify a socket. There are two distinct connections between 192.168.1.3 (my workstation) and 54.252.94.236:80 (the remote HTTP server)  TCP    192.168.1.3:63240      54.252.94.236:80       SYN_SENT  TCP    192.168.1.3:63241      54.252.94.236:80       SYN_SENT  TCP    192.168.1.3:63242      207.38.110.62:80       SYN_SENT  TCP    192.168.1.3:63243      207.38.110.62:80       SYN_SENT  TCP    192.168.1.3:64161      65.54.225.168:443      ESTABLISHEDSince a socket is the endpoint of a connection, there are two sockets with the address/port combination 207.38.110.62:80 and two more with the address/port combination 54.252.94.236:80.I think Hagrawal's misunderstanding arises from my very careful use of the word ""identifies"". I mean ""completely, unambiguously and uniquely identifies"". In the above sample there are two endpoints with the address/port combination 54.252.94.236:80. If all you have is address and port, you don't have enough information to tell these sockets apart. It's not enough information to identify a socket.AddendumParagraph two of section 2.7 of RFC793 saysA connection is fully specified by the pair of sockets at the ends.  Alocal socket may participate in many connections to different foreignsockets.This definition of socket is not helpful from a programming perspective because it is not the same as a socket object, which is the endpoint of a particular connection. To a programmer, and most of this question's audience are programmers, this is a vital functional difference.@plugwash makes a salient observation.The fundamental problem is that the TCP RFC definition of socket is in conflict with the defintion of socket used by all major operating systems and libraries.By definition the RFC is correct. When a library misuses terminology, this does not supersede the RFC. Instead, it imposes a burden of responsibility on users of that library to understand both interpretations and to be careful with words and context. Where RFCs do not agree, the most recent and most directly applicable RFC takes precedence.ReferencesTCP-IP Illustrated Volume 1 The Protocols, W. Richard Stevens, 1994 Addison WesleyRFC793, Information Sciences Institute, University of Southern California for DARPARFC147, The Definition of a Socket, Joel M. Winett, Lincoln Laboratory"
"data_i","edited Apr 17 '20 at 18:26","
        What is the difference between String.slice and String.substring?
    ","Does anyone know what the difference is between these two methods?String.prototype.sliceString.prototype.substring","slice() works like substring() with a few different behaviors.Syntax: string.slice(start, stop);Syntax: string.substring(start, stop);What they have in common:If start equals stop: returns an empty stringIf stop is omitted: extracts characters to the end of the stringIf either argument is greater than the string's length, the string's length will be used instead.Distinctions of substring():If start > stop, then substring will swap those 2 arguments.If either argument is negative or is NaN, it is treated as if it were 0.Distinctions of slice():If start > stop, slice() will return the empty string. ("""")If start is negative: sets char from the end of string, exactly like substr() in Firefox. This behavior is observed in both Firefox and IE.If stop is negative: sets stop to: string.length – Math.abs(stop) (original value), except bounded at 0 (thus, Math.max(0, string.length + stop)) as covered in the ECMA specification.Source: Rudimentary Art of Programming & Development: Javascript: substr() v.s. substring()"
"data_i","edited Aug 31 '15 at 20:20","
        What's the difference between HEAD^ and HEAD~ in Git?
    ","When I specify an ancestor commit object in Git, I'm confused between HEAD^ and HEAD~.Both have a ""numbered"" version like HEAD^3 and HEAD~2.They seem very similar or the same to me, but are there any differences between the tilde and the caret?","Rules of thumbUse ~ most of the time — to go back a number of generations, usually what you wantUse ^ on merge commits — because they have two or more (immediate) parentsMnemonics:Tilde ~ is almost linear in appearance and wants to go backward in a straight lineCaret ^ suggests an interesting segment of a tree or a fork in the roadTildeThe “Specifying Revisions” section of the git rev-parse documentation defines ~ as<rev>~<n>, e.g. master~3A suffix ~<n> to a revision parameter means the commit object that is the nth generation ancestor of the named commit object, following only the first parents. For example, <rev>~3 is equivalent to <rev>^^^ which is equivalent to <rev>^1^1^1 …You can get to parents of any commit, not just HEAD. You can also move back through generations: for example, master~2 means the grandparent of the tip of the master branch, favoring the first parent on merge commits.CaretGit history is nonlinear: a directed acyclic graph (DAG) or tree. For a commit with only one parent, rev~ and rev^ mean the same thing. The caret selector becomes useful with merge commits because each one is the child of two or more parents — and strains language borrowed from biology.HEAD^ means the first immediate parent of the tip of the current branch. HEAD^ is short for HEAD^1, and you can also address HEAD^2 and so on as appropriate. The same section of the git rev-parse documentation defines it as<rev>^, e.g. HEAD^, v1.5.1^0A suffix ^ to a revision parameter means the first parent of that commit object. ^<n> means the nth parent ([e.g.] <rev>^ is equivalent to <rev>^1). As a special rule, <rev>^0 means the commit itself and is used when <rev> is the object name of a tag object that refers to a commit object.ExamplesThese specifiers or selectors can be chained arbitrarily, e.g., topic~3^2 in English is the second parent of the merge commit that is the great-grandparent (three generations back) of the current tip of the branch topic.The aforementioned section of the git rev-parse documentation traces many paths through a notional git history. Time flows generally downward. Commits D, F, B, and A are merge commits.Here is an illustration, by Jon Loeliger. Both commit nodes B and C are parents of commit node A. Parent commits are ordered left-to-right. (N.B. The git log --graph command displays history in the opposite order.)G   H   I   J \ /     \ /  D   E   F   \  |  / \    \ | /   |     \|/    |      B     C       \   /        \ /         AA =      = A^0B = A^   = A^1     = A~1C = A^2D = A^^  = A^1^1   = A~2E = B^2  = A^^2F = B^3  = A^^3G = A^^^ = A^1^1^1 = A~3H = D^2  = B^^2    = A^^^2  = A~2^2I = F^   = B^3^    = A^^3^J = F^2  = B^3^2   = A^^3^2Run the code below to create a git repository whose history matches the quoted illustration.#! /usr/bin/env perluse strict;use warnings;use subs qw/ postorder /;use File::Temp qw/ mkdtemp /;my %sha1;my %parents = (  A => [ qw/ B C /               ],  B => [ qw/     D E F /         ],  C => [ qw/         F /         ],  D => [ qw/           G H /     ],  F => [ qw/               I J / ],);sub postorder {  my($root,$hash) = @_;  my @parents = @{ $parents{$root} || [] };  postorder($_, $hash) for @parents;  return if $sha1{$root};  @parents = map ""-p $sha1{$_}"", @parents;  chomp($sha1{$root} = `git commit-tree @parents -m ""$root"" $hash`);  die ""$0: git commit-tree failed"" if $?;  system(""git tag -a -m '$sha1{$root}' '$root' '$sha1{$root}'"") == 0 or die ""$0: git tag failed"";}$0 =~ s!^.*/!!;  # / fix Stack Overflow highlightingmy $repo = mkdtemp ""repoXXXXXXXX"";chdir $repo or die ""$0: chdir: $!"";system(""git init"") == 0               or die ""$0: git init failed"";chomp(my $tree = `git write-tree`);      die ""$0: git write-tree failed"" if $?;postorder 'A', $tree;system ""git update-ref HEAD   $sha1{A}""; die ""$0: git update-ref failed"" if $?;system ""git update-ref master $sha1{A}""; die ""$0: git update-ref failed"" if $?;# for browsing history - http://blog.kfish.org/2010/04/git-lola.htmlsystem ""git config alias.lol  'log --graph --decorate --pretty=oneline --abbrev-commit'"";system ""git config alias.lola 'log --graph --decorate --pretty=oneline --abbrev-commit --all'"";It adds aliases in the new throwaway repo only for git lol and git lola so you can view history as in$ git lol*   29392c8 (HEAD -> master, tag: A) A|\| * a1ef6fd (tag: C) C| ||  \*-. \   8ae20e9 (tag: B) B|\ \ \| | |/| | *   03160db (tag: F) F| | |\| | | * 9df28cb (tag: J) J| | * 2afd329 (tag: I) I| * a77cb1f (tag: E) E*   cd75703 (tag: D) D|\| * 3043d25 (tag: H) H* 4ab0473 (tag: G) GNote that on your machine the SHA-1 object names will differ from those above, but the tags allow you to address commits by name and check your understanding.$ git log -1 --format=%f $(git rev-parse A^)B$ git log -1 --format=%f $(git rev-parse A~^3~)I$ git log -1 --format=%f $(git rev-parse A^2~)FThe “Specifying Revisions” in the git rev-parse documentation is full of great information and is worth an in-depth read. See also Git Tools - Revision Selection from the book Pro Git.Order of Parent CommitsThe commit 89e4fcb0dd from git’s own history is a merge commit, as git show 89e4fcb0dd indicates with the Merge header line that displays the immediate ancestors’ object names.commit 89e4fcb0dd01b42e82b8f27f9a575111a26844dfMerge: c670b1f876 649bf3a42f b67d40adbbAuthor: Junio C Hamano <gitster@pobox.com>Date:   Mon Oct 29 10:15:31 2018 +0900    Merge branches 'bp/reset-quiet' and 'js/mingw-http-ssl' into nd/config-split […]We can confirm the ordering by asking git rev-parse to show 89e4fcb0dd’s immediate parents in sequence.$ git rev-parse 89e4fcb0dd^1 89e4fcb0dd^2 89e4fcb0dd^3c670b1f876521c9f7cd40184bf7ed05aad843433649bf3a42f344e71b1b5a7f562576f911a1f7423b67d40adbbaf4f5c4898001bf062a9fd67e43368Querying the non-existent fourth parent results in an error.$ git rev-parse 89e4fcb0dd^489e4fcb0dd^4fatal: ambiguous argument '89e4fcb0dd^4': unknown revision or path not in the working tree.Use '--' to separate paths from revisions, like this:'git <command> [<revision>...] -- [<file>...]'If you want to extract the parents only, use pretty format %P for the full hashes$ git log -1 --pretty=%P 89e4fcb0ddc670b1f876521c9f7cd40184bf7ed05aad843433 649bf3a42f344e71b1b5a7f562576f911a1f7423 b67d40adbbaf4f5c4898001bf062a9fd67e43368or %p for abbreviated parents.$ git log -1 --pretty=%p 89e4fcb0ddc670b1f876 649bf3a42f b67d40adbb"
"data_i","edited Oct 08 '18 at 14:09","
        How do you auto format code in Visual Studio?
    ","I know Visual Studio can auto format to make my methods and loops indented properly, but I cannot find the setting.","To format a selection: Ctrl+K, Ctrl+FTo format a document: Ctrl+K, Ctrl+DSee the pre-defined keyboard shortcuts. (These two are Edit.FormatSelection and Edit.FormatDocument.)Note for macOSOn macOS, use the CMD ⌘ key instead of Ctrl:To format a selection: CMD ⌘+K, CMD ⌘+FTo format a document:CMD ⌘+K, CMD ⌘+D"
"data_i","edited Jul 23 '21 at 13:48","
        How can the default node version be set using NVM?
    ","I have installed nvm (ubuntu with zsh shell) with two node version: v6.11.5 and v9.0.0 and the default version in nvm is the v9.0.0Every time I need to change the node version$ nvm list         v6.11.5->       v9.0.0         systemdefault -> node (-> v9.0.0)node -> stable (-> v9.0.0) (default)stable -> 9.0 (-> v9.0.0) (default)$ nvm v6How could I change the nvm version default to define v6.11.5?","(nvm maintainer here)nvm alias default 6.11.5 if you want it pegged to that specific version.You can also do nvm alias default 16.Either way, you'll want to upgrade to the latest version of nvm (v0.33.11 as of this writing)$ nvm alias default 16.14.2# nvm set default node.js version 16.14.2$ node -v# v16.14.2"
"data_i","edited Jun 11 '16 at 16:06","
        Returning JSON from a PHP Script
    ","I want to return JSON from a PHP script.Do I just echo the result? Do I have to set the Content-Type header?","While you're usually fine without it, you can and should set the Content-Type header:<?php$data = /** whatever you're serializing **/;header('Content-Type: application/json; charset=utf-8');echo json_encode($data);If I'm not using a particular framework, I usually allow some request params to modify the output behavior.  It can be useful, generally for quick troubleshooting, to not send a header, or sometimes print_r the data payload to eyeball it (though in most cases, it shouldn't be necessary)."
"data_i","edited Jan 15 '18 at 05:58","
        Why can't variables be declared in a switch statement?
    ","I've always wondered this - why can't you declare variables after a case label in a switch statement?  In C++ you can declare variables pretty much anywhere (and declaring them close to first use is obviously a good thing) but the following still won't work:switch (val)  {  case VAL:    // This won't work  int newVal = 42;    break;case ANOTHER_VAL:    ...  break;}  The above gives me the following error (MSC):initialization of 'newVal' is skipped by 'case' labelThis seems to be a limitation in other languages too.  Why is this such a problem?","Case statements are only labels. This means the compiler will interpret this as a jump directly to the label. In C++, the problem here is one of scope. Your curly brackets define the scope as everything inside the switch statement. This means that you are left with a scope where a jump will be performed further into the code skipping the initialization. The correct way to handle this is to define a scope specific to that case statement and define your variable within it:switch (val){   case VAL:  {  // This will work  int newVal = 42;    break;}case ANOTHER_VAL:  ...break;}"
"data_i","edited Nov 16 '19 at 19:01","
        How can I get the current stack trace in Java?
    ","How do I get the current stack trace in Java, like how in .NET you can do Environment.StackTrace?I found Thread.dumpStack() but it is not what I want - I want to get the stack trace back, not print it out.","You can use Thread.currentThread().getStackTrace().That returns an array of StackTraceElements that represent the current stack trace of a program."
"data_i","edited Apr 19 '20 at 11:56","
        angular.service vs angular.factory
    ","I have seen both angular.factory() and angular.service() used to declare services; however, I cannot find angular.service anywhere in official documentation.What is the difference between the two methods?Which should be used for what (assuming they do different things)?","  angular.service('myService', myServiceFunction);  angular.factory('myFactory', myFactoryFunction);I had trouble wrapping my head around this concept until I put it to myself this way:Service: the function that you write will be new-ed:  myInjectedService  <----  new myServiceFunction()Factory: the function (constructor) that you write will be invoked:  myInjectedFactory  <---  myFactoryFunction()What you do with that is up to you, but there are some useful patterns...Such as writing a service function to expose a public API:function myServiceFunction() {  this.awesomeApi = function(optional) {    // calculate some stuff    return awesomeListOfValues;  }}---------------------------------------------------------------------------------// Injected in your controller$scope.awesome = myInjectedService.awesomeApi();Or using a factory function to expose a public API:function myFactoryFunction() {  var aPrivateVariable = ""yay"";  function hello() {    return ""hello mars "" + aPrivateVariable;  }    // expose a public API  return {    hello: hello  };}---------------------------------------------------------------------------------// Injected in your controller$scope.hello = myInjectedFactory.hello();Or using a factory function to return a constructor:function myFactoryFunction() {    return function() {        var a = 2;        this.a2 = function() {            return a*2;        };    };}---------------------------------------------------------------------------------// Injected in your controllervar myShinyNewObject = new myInjectedFactory();$scope.four = myShinyNewObject.a2();Which one to use?...You can accomplish the same thing with both. However, in some cases the factory gives you a little bit more flexibility to create an injectable with a simpler syntax. That's because while myInjectedService must always be an object, myInjectedFactory can be an object, a function reference, or any value at all. For example, if you wrote a service to create a constructor (as in the last example above), it would have to be instantiated like so:var myShinyNewObject = new myInjectedService.myFunction()which is arguably less desirable than this:var myShinyNewObject = new myInjectedFactory();(But you should be wary about using this type of pattern in the first place because new-ing objects in your controllers creates hard-to-track dependencies that are difficult to mock for testing. Better to have a service manage a collection of objects for you than use new() wily-nilly.)One more thing, they are all Singletons...Also keep in mind that in both cases, angular is helping you manage a singleton. Regardless of where or how many times you inject your service or function, you will get the same reference to the same object or function. (With the exception of when a factory simply returns a value like a number or string. In that case, you will always get the same value, but not a reference.)"
"data_i","edited Dec 09 '14 at 02:45","
        How to make --no-ri --no-rdoc the default for gem install?
    ","I don't use the RI or RDoc output from the gems I install in my machine or in the servers I handle (I use other means of documentation).Every gem I install installs RI and RDoc documentation by default, because I forget to set --no-ri --no-rdoc.Is there a way to make those two flags the default?","You just add the following line to your local ~/.gemrc file (it is in your home folder):gem: --no-documentbyecho 'gem: --no-document' >> ~/.gemrcor you can add this line to the global gemrc config file.Here is how to find it (in Linux):strace gem source 2>&1 | grep gemrcThe --no-document option is documented in the RubyGems CLI Reference."
"data_i","edited May 08 '18 at 12:58","
        How to get the sizes of the tables of a MySQL database?
    ","I can run this query to get the sizes of all tables in a MySQL database:show table status from myDatabaseName;I would like some help in understanding the results. I am looking for tables with the largest sizes. Which column should I look at?","You can use this query to show the size of a table (although you need to substitute the variables first):SELECT     table_name AS `Table`,     round(((data_length + index_length) / 1024 / 1024), 2) `Size in MB` FROM information_schema.TABLES WHERE table_schema = ""$DB_NAME""    AND table_name = ""$TABLE_NAME"";or this query to list the size of every table in every database, largest first:SELECT      table_schema as `Database`,      table_name AS `Table`,      round(((data_length + index_length) / 1024 / 1024), 2) `Size in MB` FROM information_schema.TABLES ORDER BY (data_length + index_length) DESC;"
"data_i","edited Aug 12 '20 at 12:55","
        Insert into a MySQL table or update if exists
    ","I want to add a row to a database table, but if a row exists with the same unique key I want to update the row.For example:INSERT INTO table_name (ID, NAME, AGE) VALUES(1, ""A"", 19);Let’s say the unique key is ID, and in my Database, there is a row with ID = 1. In that case, I want to update that row with these values. Normally this gives an error.If I use INSERT IGNORE it will ignore the error, but it still won’t update.","Use INSERT ... ON DUPLICATE KEY UPDATEQUERY:INSERT INTO table (id, name, age) VALUES(1, ""A"", 19) ON DUPLICATE KEY UPDATE    name=""A"", age=19"
"data_i","edited Apr 17 '20 at 18:13","
        Using ls to list directories and their total sizes
    ","Is it possible to use ls in Unix to list the total size of a sub-directory and all its contents as opposed to the usual 4K that (I assume) is just the directory file itself?total 12Kdrwxrwxr-x  6 *** *** 4.0K 2009-06-19 10:10 branchesdrwxrwxr-x 13 *** *** 4.0K 2009-06-19 10:52 tagsdrwxrwxr-x 16 *** *** 4.0K 2009-06-19 10:02 trunkAfter scouring the man pages I'm coming up empty.","Try something like:du -sh *short version of:du --summarize --human-readable *Explanation:du: Disk Usage-s: Display a summary for each specified file.  (Equivalent to -d 0)-h: ""Human-readable"" output.  Use unit suffixes: Byte, Kibibyte (KiB), Mebibyte (MiB), Gibibyte (GiB), Tebibyte (TiB) and Pebibyte (PiB). (BASE2)"
"data_i","edited Jan 12 '21 at 14:28","
        Checking whether a variable is an integer or not
    ","How do I check whether a variable is an integer?","If you need to do this, doisinstance(<var>, int)unless you are in Python 2.x in which case you wantisinstance(<var>, (int, long))Do not use type. It is almost never the right answer in Python, since it blocks all the flexibility of polymorphism. For instance, if you subclass int, your new class should register as an int, which type will not do:class Spam(int): passx = Spam(0)type(x) == int # Falseisinstance(x, int) # TrueThis adheres to Python's strong polymorphism: you should allow any object that behaves like an int, instead of mandating that it be one.BUTThe classical Python mentality, though, is that it's easier to ask forgiveness than permission. In other words, don't check whether x is an integer; assume that it is and catch the exception results if it isn't:try:    x += 1except TypeError:    ...This mentality is slowly being overtaken by the use of abstract base classes, which let you register exactly what properties your object should have (adding? multiplying? doubling?) by making it inherit from a specially-constructed class. That would be the best solution, since it will permit exactly those objects with the necessary and sufficient attributes, but you will have to read the docs on how to use it."
"data_i","edited Oct 18 '17 at 19:39","
        Best way to use multiple SSH private keys on one client
    ","I want to use multiple private keys to connect to different servers or different portions of the same server (my uses are system administration of server, administration of Git, and normal Git usage within the same server). I tried simply stacking the keys in the id_rsa files to no avail.Apparently a straightforward way to do this is to use the command ssh -i <key location> login@server.example.com That is quite cumbersome.Any suggestions as to how to go about doing this a bit easier?","From my .ssh/config:Host myshortname realname.example.com    HostName realname.example.com    IdentityFile ~/.ssh/realname_rsa # private key for realname    User remoteusernameHost myother realname2.example.org    HostName realname2.example.org    IdentityFile ~/.ssh/realname2_rsa  # different private key for realname2    User remoteusernameThen you can use the following to connect:ssh myshortnamessh myotherAnd so on."
"data_i","edited Sep 22 '21 at 18:53","
        How can I generate an MD5 hash in Java?
    ","Is there any method to generate MD5 hash of a string in Java?","The MessageDigest class can provide you with an instance of the MD5 digest.When working with strings and the crypto classes be sure to always specify the encoding you want the byte representation in. If you just use string.getBytes() it will use the platform default. (Not all platforms use the same defaults)import java.security.*;..byte[] bytesOfMessage = yourString.getBytes(""UTF-8"");MessageDigest md = MessageDigest.getInstance(""MD5"");byte[] theMD5digest = md.digest(bytesOfMessage);If you have a lot of data take a look at the .update(xxx) methods which can be called repeatedly. Then call .digest() to obtain the resulting hash."
"data_i","edited Apr 10 '22 at 12:20","
        Should I use 'has_key()' or 'in' on Python dicts?
    ","Given:>>> d = {'a': 1, 'b': 2}Which of the following is the best way to check if 'a' is in d?>>> 'a' in dTrue>>> d.has_key('a')True","in is definitely more pythonic.In fact has_key() was removed in Python 3.x."
"data_i","asked Oct 03 '12 at 13:01","
        How do you explicitly set a new property on `window` in TypeScript?
    ","I setup global namespaces for my objects by explicitly setting a property on window.window.MyNamespace = window.MyNamespace || {};TypeScript underlines MyNamespace and complains that:The property 'MyNamespace' does not exist on value of type 'window'  any""I can make the code work by declaring MyNamespace as an ambient variable and dropping the window explicitness but I don't want to do that.declare var MyNamespace: any;MyNamespace = MyNamespace || {};How can I keep window in there and make TypeScript happy?As a side note I find it especially funny that TypeScript complains since it tells me that window is of type any which by definitely can contain anything.","I just found the answer to this in another Stack Overflow question's answer.declare global {    interface Window { MyNamespace: any; }}window.MyNamespace = window.MyNamespace || {};Basically, you need to extend the existing window interface to tell it about your new property."
"data_i","edited Mar 14 '18 at 21:03","
        Static way to get 'Context' in Android?
    ","Is there a way to get the current Context instance inside a static method? I'm looking for that way because I hate saving the 'Context' instance each time it changes.","Do this:In the Android Manifest file, declare the following.<application android:name=""com.xyz.MyApplication""></application>Then write the class:public class MyApplication extends Application {    private static Context context;    public void onCreate() {        super.onCreate();        MyApplication.context = getApplicationContext();    }    public static Context getAppContext() {        return MyApplication.context;    }}Now everywhere call MyApplication.getAppContext() to get your application context statically."
"data_i","edited Nov 02 '21 at 10:29","
        Is there any difference between a GUID and a UUID?
    ","I see these two acronyms being thrown around and I was wondering if there are any differences between a GUID and a UUID?","The simple answer is: **no difference, they are the same thing.2020-08-20 Update: While GUIDs (as used by Microsoft) and UUIDs (as defined by RFC4122) look similar and serve similar purposes, there are subtle-but-occasionally-important differences.  Specifically, some Microsoft GUID docs allow GUIDs to contain any hex digit in any position, while RFC4122 requires certain values for the version and variant fields.  Also, [per that same link], GUIDs should be all-upper case, whereas UUIDs should be ""output as lower case characters and are case insensitive on input"".  This can lead to incompatibilities between code libraries (such as this).(Original answer follows)Treat them as a 16 byte (128 bits) value that is used as a unique value.  In Microsoft-speak they are called GUIDs, but call them UUIDs when not using Microsoft-speak.Even the authors of the UUID specification and Microsoft claim they are synonyms:From the introduction to IETF RFC 4122 ""A Universally Unique IDentifier (UUID) URN Namespace"": ""a Uniform Resource Name namespace for UUIDs (Universally Unique IDentifier), also known as GUIDs (Globally Unique IDentifier).""From the ITU-T Recommendation X.667, ISO/IEC 9834-8:2004 International Standard: ""UUIDs are also known as Globally Unique Identifiers (GUIDs), but this term is not used in this Recommendation.""And Microsoft even claims a GUID is specified by the UUID RFC: ""In Microsoft Windows programming and in Windows operating systems, a globally unique identifier (GUID), as specified in [RFC4122], is ... The term universally unique identifier (UUID) is sometimes used in Windows protocol specifications as a synonym for GUID.""But the correct answer depends on what the question means when it says ""UUID""...The first part depends on what the asker is thinking when they are saying ""UUID"".Microsoft's claim implies that all UUIDs are GUIDs. But are all GUIDs real UUIDs? That is, is the set of all UUIDs just a proper subset of the set of all GUIDs, or is it the exact same set?Looking at the details of the RFC 4122, there are four different ""variants"" of UUIDs.  This is mostly because such 16 byte identifiers were in use before those specifications were brought together in the creation of a UUID specification. From section 4.1.1 of RFC 4122, the four variants of UUID are:Reserved, Network Computing System backward compatibilityThe variant specified in RFC 4122 (of which there are five sub-variants, which are called ""versions"")Reserved, Microsoft Corporation backward compatibilityReserved for future definition.According to RFC 4122, all UUID variants are ""real UUIDs"", then all GUIDs are real UUIDs. To the literal question ""is there any difference between GUID and UUID"" the answer is definitely no for RFC 4122 UUIDs: no difference (but subject to the second part below).But not all GUIDs are variant 2 UUIDs (e.g. Microsoft COM has GUIDs which are variant 3 UUIDs). If the question was ""is there any difference between GUID and variant 2 UUIDs"", then the answer would be yes -- they can be different. Someone asking the question probably doesn't know about variants and they might be only thinking of variant 2 UUIDs when they say the word ""UUID"" (e.g. they vaguely know of the MAC address+time and the random number algorithms forms of UUID, which are both versions of variant 2). In which case, the answer is yes different.So the answer, in part, depends on what the person asking is thinking when they say the word ""UUID"". Do they mean variant 2 UUID (because that is the only variant they are aware of) or all UUIDs?The second part depends on which specification being used as the definition of UUID.If you think that was confusing, read the ITU-T X.667 ISO/IEC 9834-8:2004 which is supposed to be aligned and fully technically compatible with RFC 4122.  It has an extra sentence in Clause 11.2 that says, ""All UUIDs conforming to this Recommendation | International Standard shall have variant bits with bit 7 of octet 7 set to 1 and bit 6 of octet 7 set to 0"". Which means that only variant 2 UUID conform to that Standard (those two bit values mean variant 2). If that is true, then not all GUIDs are conforming ITU-T/ISO/IEC UUIDs, because conformant ITU-T/ISO/IEC UUIDs can only be variant 2 values.Therefore, the real answer also depends on which specification of UUID the question is asking about. Assuming we are clearly talking about all UUIDs and not just variant 2 UUIDs: there is no difference between GUID and IETF's UUIDs, but yes difference between GUID and conforming ITU-T/ISO/IEC's UUIDs!Binary encodings could differWhen encoded in binary (as opposed to the human-readable text format), the GUID may be stored in a structure with four different fields as follows. This format differs from the [UUID standard] 8 only in the byte order of the first 3 fields.Bits  Bytes Name   Endianness  Endianness                   (GUID)      RFC 412232    4     Data1  Native      Big16    2     Data2  Native      Big16    2     Data3  Native      Big64    8     Data4  Big         Big"
"data_i","edited Mar 21 '16 at 04:28","
        How do I clear/delete the current line in terminal?
    ","If I'm using terminal and typing in a line of text for a command, is there a hotkey or any way to clear/delete that line?For example, if my current line/command is something really long like:> git log --graph --all --blah..uh oh i want to cancel and clear this line <cursor is here now>Is there a hotkey or command to go from the above to:>?Usually I will press the ↓ key, and if my current line is a brand new one on the history, that will clear it.  But if I'm going through my command history via the ↑ key and start editing or using those commands, ↓ will only change the prompt to the next newest command in history, so it doesn't work here unless I press ↓ multiple times.","You can use Ctrl+U to clear up to the beginning.You can use Ctrl+W to delete just a word.You can also use Ctrl+C to cancel.If you want to keep the history, you can use Alt+Shift+# to make it a comment.Bash Emacs Editing Mode Cheat Sheet"
"data_i","edited Jun 26 '20 at 20:38","
        Getting the ID of the element that fired an event
    ","Is there any way to get the ID of the element that fires an event?I'm thinking something like:$(document).ready(function() {  $(""a"").click(function() {    var test = caller.id;    alert(test.val());  });});<script type=""text/javascript"" src=""starterkit/jquery.js""></script><form class=""item"" id=""aaa"">  <input class=""title""></input></form><form class=""item"" id=""bbb"">  <input class=""title""></input></form>Except of course that the var test should contain the id ""aaa"", if the event is fired from the first form, and ""bbb"", if the event is fired from the second form.","In jQuery event.target always refers to the element that triggered the event, where event is the parameter passed to the function. http://api.jquery.com/category/events/event-object/$(document).ready(function() {    $(""a"").click(function(event) {        alert(event.target.id);    });});Note also that this will also work, but that it is not a jQuery object, so if you wish to use a jQuery function on it then you must refer to it as $(this), e.g.:$(document).ready(function() {    $(""a"").click(function(event) {        // this.append wouldn't work        $(this).append("" Clicked"");    });});"
"data_i","edited Apr 17 '16 at 08:26","
        Can you force Visual Studio to always run as an Administrator in Windows 8?
    ","In Windows 7, you could go into a programs compatibility settings and check off to always run as an Administrator. Is there a similar option in Windows 8? I've always disabled UAC on my machines, and did the same after my Windows 8 upgrade, or so I thought. It turns out there is no off option, only turning off the notifications. This means nothing is run as an Administrator despite being in the Administrator group. I need to keep closing and reopening my consoles\Visual Studio when I try to debug (attach to process, not F5), which is very frustrating. It's really annoying that I need to either remember to take extra steps to open it as an Administrator or tell it to close and re-open when I go to debug for the first time.","In Windows 8, Windows 10, and Windows 11, you have to right-click devenv.exe and select ""Troubleshoot compatibility"".Select ""Troubleshoot program""Check ""The program requires additional permissions""Click ""Next""Click ""Test the program...""Wait for the program to launchClick ""Next""Select ""Yes, save these settings for this program""Click ""Close""If, when you open Visual Studio it asks to save changes to devenv.sln, see this answer to disable it:Disable Visual Studio devenv solution save dialogIf you change your mind and wish to undo the ""Run As Administrator"" Compatibility setting, see the answer here: How to Fix Unrecognized Guid format in Visual Studio 2015"
"data_i","edited Apr 14 '18 at 15:58","
        INNER JOIN ON vs WHERE clause
    ","For simplicity, assume all relevant fields are NOT NULL.You can do:SELECT    table1.this, table2.that, table2.somethingelseFROM    table1, table2WHERE    table1.foreignkey = table2.primarykey    AND (some other conditions)Or else:SELECT    table1.this, table2.that, table2.somethingelseFROM    table1 INNER JOIN table2    ON table1.foreignkey = table2.primarykeyWHERE    (some other conditions)Do these two work on the same way in MySQL?","INNER JOIN is ANSI syntax that you should use.It is generally considered more readable, especially when you join lots of tables.It can also be easily replaced with an OUTER JOIN whenever a need arises.The WHERE syntax is more relational model oriented.A result of two tables JOINed is a cartesian product of the tables to which a filter is applied which selects only those rows with joining columns matching.It's easier to see this with the WHERE syntax.As for your example, in MySQL (and in SQL generally) these two queries are synonyms.Also, note that MySQL also has a STRAIGHT_JOIN clause.Using this clause, you can control the JOIN order: which table is scanned in the outer loop and which one is in the inner loop.You cannot control this in MySQL using WHERE syntax."
"data_i","edited Jan 21 '20 at 18:51","
        jQuery AJAX submit form
    ","I have a form with name orderproductForm and an undefined number of inputs.I want to do some kind of jQuery.get or ajax or anything like that that would call a page through Ajax, and send along all the inputs of the form orderproductForm.I suppose one way would be to do something likejQuery.get(""myurl"",          {action : document.orderproductForm.action.value,           cartproductid : document.orderproductForm.cartproductid.value,           productid : document.orderproductForm.productid.value,           ...However I do not know exactly all the form inputs. Is there a feature, function or something that would just send ALL the form inputs?","This is a simple reference:// this is the id of the form$(""#idForm"").submit(function(e) {    e.preventDefault(); // avoid to execute the actual submit of the form.    var form = $(this);    var actionUrl = form.attr('action');        $.ajax({        type: ""POST"",        url: actionUrl,        data: form.serialize(), // serializes the form's elements.        success: function(data)        {          alert(data); // show response from the php script.        }    });    });"
"data_i","edited Apr 09 '17 at 19:00","
        Save PL/pgSQL output from PostgreSQL to a CSV file
    ","What is the easiest way to save PL/pgSQL output from a PostgreSQL database to a CSV file? I'm using PostgreSQL 8.4 with pgAdmin III and PSQL plugin where I run queries from.","Do you want the resulting file on the server, or on the client?Server sideIf you want something easy to re-use or automate, you can use Postgresql's built in COPY command. e.g.Copy (Select * From foo) To '/tmp/test.csv' With CSV DELIMITER ',' HEADER;This approach runs entirely on the remote server - it can't write to your local PC. It also needs to be run as a Postgres ""superuser"" (normally called ""root"") because Postgres can't stop it doing nasty things with that machine's local filesystem.That doesn't actually mean you have to be connected as a superuser (automating that would be a security risk of a different kind), because you can use the SECURITY DEFINER option to CREATE FUNCTION to make a function which runs as though you were a superuser.The crucial part is that your function is there to perform additional checks, not just by-pass the security - so you could write a function which exports the exact data you need, or you could write something which can accept various options as long as they meet a strict whitelist. You need to check two things:Which files should the user be allowed to read/write on disk? This might be a particular directory, for instance, and the filename might have to have a suitable prefix or extension.Which tables should the user be able to read/write in the database? This would normally be defined by GRANTs in the database, but the function is now running as a superuser, so tables which would normally be ""out of bounds"" will be fully accessible. You probably don’t want to let someone invoke your function and add rows on the end of your “users” table…I've written a blog post expanding on this approach, including some examples of functions that export (or import) files and tables meeting strict conditions.Client sideThe other approach is to do the file handling on the client side, i.e. in your application or script. The Postgres server doesn't need to know what file you're copying to, it just spits out the data and the client puts it somewhere.The underlying syntax for this is the COPY TO STDOUT command, and graphical tools like pgAdmin will wrap it for you in a nice dialog.The psql command-line client has a special ""meta-command"" called \copy, which takes all the same options as the ""real"" COPY, but is run inside the client:\copy (Select * From foo) To '/tmp/test.csv' With CSV DELIMITER ',' HEADERNote that there is no terminating ;, because meta-commands are terminated by newline, unlike SQL commands.From the docs:Do not confuse COPY with the psql instruction \copy. \copy invokes COPY FROM STDIN or COPY TO STDOUT, and then fetches/stores the data in a file accessible to the psql client. Thus, file accessibility and access rights depend on the client rather than the server when \copy is used.Your application programming language may also have support for pushing or fetching the data, but you cannot generally use COPY FROM STDIN/TO STDOUT within a standard SQL statement, because there is no way of connecting the input/output stream. PHP's PostgreSQL handler (not PDO) includes very basic pg_copy_from and pg_copy_to functions which copy to/from a PHP array, which may not be efficient for large data sets."
"data_i","edited Oct 08 '15 at 06:00","
        push_back vs emplace_back
    ","I'm a bit confused regarding the difference between push_back and emplace_back.void emplace_back(Type&& _Val);void push_back(const Type& _Val);void push_back(Type&& _Val);As there is a push_back overload taking a rvalue reference I don't quite see what the purpose of emplace_back becomes?","In addition to what visitor said :The function void emplace_back(Type&& _Val) provided by MSCV10 is non conforming and redundant, because as you noted it is strictly equivalent to push_back(Type&& _Val).But the real C++0x form of emplace_back is really useful: void emplace_back(Args&&...);Instead of taking a value_type it takes a variadic list of arguments, so that means that you can now perfectly forward the arguments and construct directly an object into a container without a temporary at all. That's useful because no matter how much cleverness RVO and move semantic bring to the table there is still complicated cases where a push_back is likely to make unnecessary copies (or move). For example, with the traditional insert() function of a std::map, you have to create a temporary, which will then be copied into a std::pair<Key, Value>, which will then be copied into the map : std::map<int, Complicated> m;int anInt = 4;double aDouble = 5.0;std::string aString = ""C++"";// cross your finger so that the optimizer is really goodm.insert(std::make_pair(4, Complicated(anInt, aDouble, aString))); // should be easier for the optimizerm.emplace(4, anInt, aDouble, aString);So why didn't they implement the right version of emplace_back in MSVC? Actually, it bugged me too a while ago, so I asked the same question on the Visual C++ blog. Here is the answer from Stephan T Lavavej, the official maintainer of the Visual C++ standard library implementation at Microsoft.Q: Are beta 2 emplace functions just some kind of placeholder right now?A: As you may know, variadic templates  aren't implemented in VC10. We  simulate them with preprocessor  machinery for things like  make_shared<T>(), tuple, and the new  things in <functional>. This  preprocessor machinery is relatively  difficult to use and maintain. Also,  it significantly affects compilation  speed, as we have to repeatedly  include subheaders. Due to a  combination of our time constraints  and compilation speed concerns, we  haven't simulated variadic templates  in our emplace functions.When variadic templates are  implemented in the compiler, you can  expect that we'll take advantage of  them in the libraries, including in  our emplace functions. We take  conformance very seriously, but  unfortunately, we can't do everything  all at once.It's an understandable decision. Everyone who tried just once to emulate variadic template with preprocessor horrible tricks knows how disgusting this stuff gets. "
"data_i","edited Jun 24 '19 at 19:00","
        Detecting request type in PHP (GET, POST, PUT or DELETE)
    ","How can I detect which request type was used (GET, POST, PUT or DELETE) in PHP?","By using$_SERVER['REQUEST_METHOD']Exampleif ($_SERVER['REQUEST_METHOD'] === 'POST') {     // The request is using the POST method}For more details please see the documentation for the $_SERVER variable."
"data_i","edited Feb 12 '22 at 20:38","
        Android Studio: Add jar as library?
    ","I'm trying to use the new Android Studio but I can't seem to get it working correctly.I'm using the Gson library to serialize/deserialize JSON-objects. But the library somehow isn't included in the build.I had created a new project with just a MainActivity.Copied gson-2.2.3.jar in the /libs folder and added it as a library dependancy(right click->Add as library). This includes the jar in android studio so it can be referenced from the source files.When I try to run the project it cannot compile so I added:compile files('libs/gson-2.2.3.jar')to the dependencies in de .gradle file. After that it compiles correctly but when running the application I get a ClassDefNotFoundException.Does anyone know what I'm doing wrong?","I've been struggling with the same thing for many hours, trying to get the Gson jar to work no less. I finally cracked it – here are the steps I took:Put the Gson jar (in my case, gson-2.2.4.jar) into the libs folderRight click it and hit 'Add as library'Ensure that compile files('libs/gson-2.2.4.jar') is in your build.gradle file (or compile fileTree(dir: 'libs', include: '*.jar') if you are using many jar files) Edit : Use implementation files('libs/gson-2.2.4.jar') (or implementation fileTree(dir: 'libs', include: '*.jar')) in Android Studio 3.0+Do a clean build (you can probably do this fine in Android Studio, but to make sure I navigated in a terminal to the root folder of my app and typed gradlew clean. I'm on Mac OS X, the command might be different on your systemAfter I did the above four, it started working fine. I think the 'Add as library' step was the one I'd previously missed, and it didn't work until I cleaned it either.[Edit - added the build.gradle step which is also necessary as others have pointed out]"
"data_i","edited Sep 09 '16 at 19:33","
        StringBuilder vs String concatenation in toString() in Java
    ","Given the 2 toString() implementations below, which one is preferred:public String toString(){    return ""{a:""+ a + "", b:"" + b + "", c: "" + c +""}"";}orpublic String toString(){    StringBuilder sb = new StringBuilder(100);    return sb.append(""{a:"").append(a)          .append("", b:"").append(b)          .append("", c:"").append(c)          .append(""}"")          .toString();}?More importantly, given we have only 3 properties it might not make a difference, but at what point would you switch from + concat to  StringBuilder?","Version 1 is preferable because it is shorter and the compiler will in fact turn it into version 2 - no performance difference whatsoever.More importantly given we have only 3  properties it might not make a  difference, but at what point do you  switch from concat to builder?At the point where you're concatenating in a loop - that's usually when the compiler can't substitute StringBuilder by itself."
"data_i","edited Aug 15 '19 at 19:23","
        Update Git submodule to latest commit on origin
    ","I have a project with a Git submodule. It is from an ssh://... URL, and is on commit A. Commit B has been pushed to that URL, and I want the submodule to retrieve the commit, and change to it.Now, my understanding is that git submodule update should do this, but it doesn't. It doesn't do anything (no output, success exit code). Here's an example:$ mkdir foo$ cd foo$ git init .Initialized empty Git repository in /.../foo/.git/$ git submodule add ssh://user@host/git/mod modCloning into mod...user@host's password: hunter2remote: Counting objects: 131, done.remote: Compressing objects: 100% (115/115), done.remote: Total 131 (delta 54), reused 0 (delta 0)Receiving objects: 100% (131/131), 16.16 KiB, done.Resolving deltas: 100% (54/54), done.$ git commit -m ""Hello world.""[master (root-commit) 565b235] Hello world. 2 files changed, 4 insertions(+), 0 deletions(-) create mode 100644 .gitmodules create mode 160000 mod# At this point, ssh://user@host/git/mod changes; submodule needs to change too.$ git submodule initSubmodule 'mod' (ssh://user@host/git/mod) registered for path 'mod'$ git submodule update$ git submodule syncSynchronizing submodule url for 'mod'$ git submodule update$ man git-submodule $ git submodule update --rebase$ git submodule update$ echo $?0$ git status# On branch masternothing to commit (working directory clean)$ git submodule update mod$ ...I've also tried git fetch mod, which appears to do a fetch (but can't possibly, because it's not prompting for a password!), but git log and git show deny the existence of new commits. Thus far I've just been rm-ing the module and re-adding it, but this is both wrong in principle and tedious in practice.","The git submodule update command actually tells Git that you want your submodules to each check out the commit already specified in the index of the superproject. If you want to update your submodules to the latest commit available from their remote, you will need to do this directly in the submodules.So in summary:# Get the submodule initiallygit submodule add ssh://bla submodule_dirgit submodule init# Time passes, submodule upstream is updated# and you now want to update# Change to the submodule directorycd submodule_dir# Checkout desired branchgit checkout master# Updategit pull# Get back to your project rootcd ..# Now the submodules are in the state you want, sogit commit -am ""Pulled down update to submodule_dir""Or, if you're a busy person:git submodule foreach git pull origin master"
"data_i","edited Nov 27 '12 at 21:17","
        Git: How do I list only local branches?
    ","git branch -a shows both remote and local branches.git branch -r shows remote branches.Is there a way to list just the local branches?","Just git branch without options.From the manpage:With no arguments, existing branches are listed and the current branch will be highlighted with an asterisk."
"data_i","edited Mar 01 '18 at 20:54","
        How to subtract a day from a date?
    ","I have a Python datetime.datetime object. What is the best way to subtract one day?","You can use a timedelta object:from datetime import datetime, timedelta    d = datetime.today() - timedelta(days=days_to_subtract)"
"data_i","edited May 31 '19 at 02:40","
        How to replace local branch with remote branch entirely in Git?
    ","I have two branches:local branch (the one which I work with)remote branch (public, only well-tested commits go there)Recently I seriously messed up my local branch.How would I replace the local branch entirely with the remote one, so I can continue my work from where the remote branch is now?I have already searched SO and checking out to the remote branch locally does not have any effect.","Make sure you've checked out the branch you're replacing (from Zoltán's comment).Assuming that master is the local branch you're replacing, and that ""origin/master"" is the remote branch you want to reset to:git reset --hard origin/masterThis updates your local HEAD branch to be the same revision as origin/master, and --hard will sync this change into the index and workspace as well."
"data_i","edited Oct 06 '17 at 22:20","
        What is JavaScript's highest integer value that a number can go to without losing precision?
    ","Is this defined by the language? Is there a defined maximum? Is it different in different browsers?","JavaScript has two number types: Number and BigInt. The most frequently-used number type, Number, is a 64-bit floating point IEEE 754 number. The largest exact integral value of this type is Number.MAX_SAFE_INTEGER, which is:253-1, or +/- 9,007,199,254,740,991, ornine quadrillion seven trillion one hundred ninety-nine billion two hundred fifty-four million seven hundred forty thousand nine hundred ninety-one To put this in perspective: one quadrillion bytes is a petabyte (or one thousand terabytes).""Safe"" in this context refers to the ability to represent integers exactly and to correctly compare them.From the spec:Note that all the positive and negative integers whose magnitude is no  greater than 253 are representable in the Number type (indeed, the  integer 0 has two representations, +0 and -0).To safely use integers larger than this, you need to use BigInt, which has no upper bound. Note that the bitwise operators and shift operators operate on 32-bit integers, so in that case, the max safe integer is 231-1, or 2,147,483,647.  const log = console.logvar x = 9007199254740992var y = -xlog(x == x + 1) // true !log(y == y - 1) // also true !// Arithmetic operators work, but bitwise/shifts only operate on int32:log(x / 2)      // 4503599627370496log(x >> 1)     // 0log(x | 1)      // 1Technical note on the subject of the number 9,007,199,254,740,992: There is an exact IEEE-754 representation of this value, and you can assign and read this value from a variable, so for very carefully chosen applications in the domain of integers less than or equal to this value, you could treat this as a maximum value.In the general case, you must treat this IEEE-754 value as inexact, because it is ambiguous whether it is encoding the logical value 9,007,199,254,740,992 or  9,007,199,254,740,993. "
"data_i","edited Feb 18 '21 at 11:40","
        Find the min/max element of an array in JavaScript
    ","How can I easily obtain the min or max element of a JavaScript array?Example pseudocode:let array = [100, 0, 50]array.min() //=> 0array.max() //=> 100","How about augmenting the built-in Array object to use Math.max/Math.min instead:Array.prototype.max = function() {  return Math.max.apply(null, this);};Array.prototype.min = function() {  return Math.min.apply(null, this);};let p = [35,2,65,7,8,9,12,121,33,99];console.log(`Max value is: ${p.max()}` +  `\nMin value is: ${p.min()}`);Here is a JSFiddle.Augmenting the built-ins can cause collisions with other libraries (some see), so you may be more comfortable with just apply'ing Math.xxx() to your array directly:var min = Math.min.apply(null, arr),    max = Math.max.apply(null, arr);Alternately, assuming your browser supports ECMAScript 6, you can use spread syntax which functions similarly to the apply method:var min = Math.min( ...arr ),    max = Math.max( ...arr );"
"data_i","edited Sep 12 '16 at 17:03","
        What is a clearfix?
    ","Recently I was looking through some website's code, and saw that every <div>  had a class clearfix.After a quick Google search, I learned that it is for IE6 sometimes, but what actually is a clearfix? Could you provide some examples of a layout with a clearfix, compared to a layout without a clearfix?","If you don't need to support IE9 or lower, you can use flexbox freely, and don't need to use floated layouts.It's worth noting that today, the use of floated elements for layout is getting more and more discouraged with the use of better alternatives.display: inline-block - BetterFlexbox - Best (but limited browser support)Flexbox is supported from Firefox 18, Chrome 21, Opera 12.10, and Internet Explorer 10, Safari 6.1 (including Mobile Safari) and Android's default browser 4.4.For a detailed browser list see: https://caniuse.com/flexbox.(Perhaps once its position is established completely, it may be the absolutely recommended way of laying out elements.)A clearfix is a way for an element to automatically clear its child elements, so that you don't need to add additional markup. It's generally used in float layouts where elements are floated to be stacked horizontally.The clearfix is a way to combat the zero-height container problem for floated elementsA clearfix is performed as follows:.clearfix::after {   content: "" ""; /* Older browser do not support empty content */   visibility: hidden;   display: block;   height: 0;   clear: both;}Or, if you don't require IE<8 support, the following is fine too:.clearfix::after {  content: """";  display: table;  clear: both;}Normally you would need to do something as follows:<div>    <div style=""float: left;"">Sidebar</div>    <div style=""clear: both;""></div> <!-- Clear the float --></div>With clearfix, you only need the following:<div class=""clearfix"">    <div style=""float: left;"" class=""clearfix"">Sidebar</div>    <!-- No Clearing div! --></div>Read about it in this article - by Chris Coyer @ CSS-Tricks"
"data_i","edited Feb 07 '21 at 02:18","
        Converting unix timestamp string to readable date
    ","I have a string representing a unix timestamp (i.e. ""1284101485"") in Python, and I'd like to convert it to a readable date. When I use time.strftime, I get a TypeError:>>>import time>>>print time.strftime(""%B %d %Y"", ""1284101485"")Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>TypeError: argument must be 9-item sequence, not str","Use datetime module:from datetime import datetimets = int('1284101485')# if you encounter a ""year is out of range"" error the timestamp# may be in milliseconds, try `ts /= 1000` in that caseprint(datetime.utcfromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S'))"
"data_i","edited Mar 03 '17 at 16:57","
        How do I check in SQLite whether a table exists?
    ","How do I, reliably, check in SQLite, whether a particular user table exists?I am not asking for unreliable ways like checking if a ""select *"" on the table returned an error or not (is this even a good idea?).The reason is like this:In my program, I need to create and then populate some tables if they do not exist already.If they do already exist, I need to update some tables.Should I take some other path instead to signal that the tables in question have already been created - say for example, by creating/putting/setting a certain flag in my program initialization/settings file on disk or something?Or does my approach make sense?","I missed that FAQ entry.Anyway, for future reference, the complete query is:SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}';Where {table_name} is the name of the table to check.Documentation section for reference: Database File Format. 2.6. Storage Of The SQL Database SchemaThis will return a list of tables with the name specified; that is, the cursor will have a count of 0 (does not exist) or a count of 1 (does exist)"
"data_i","edited Aug 08 '21 at 11:07","
        Switch statement for multiple cases in JavaScript
    ","I need multiple cases in switch statement in JavaScript, Something like:switch (varName){   case ""afshin"", ""saeed"", ""larry"":       alert('Hey');       break;   default:       alert('Default case');       break;}How can I do that? If there's no way to do something like that in JavaScript, I want to know an alternative solution that also follows the DRY concept.","Use the fall-through feature of the switch statement. A matched case will run until a break (or the end of the switch statement) is found, so you could write it like:switch (varName){   case ""afshin"":   case ""saeed"":   case ""larry"":        alert('Hey');       break;   default:        alert('Default case');}"
"data_i","edited Oct 31 '17 at 08:50","
        How to ""comment-out"" (add comment) in a batch/cmd?
    ","I have a batch file that runs several python scripts that do table modifications.  I want to have users comment out the 1-2 python scripts that they don't want to run, rather than removing them from the batch file (so the next user knows these scripts exist as options!)I also want to add comments to bring to their attention specifically the variables they need to update in the Batch file before they run it. I see that I can use REM. But it looks like that's more for updating the user with progress after they've run it.  Is there a syntax for more appropriately adding a comment?","Use :: or REM::   commentttttttttttREM  commentttttttttttBUT (as people noted):if they are not in the beginning of line, then add & character:your commands here      & ::  commentttttttttttInside nested parts (IF/ELSE, FOR loops, etc...) :: should be followed with normal line, otherwise it gives error (use REM there).:: may also fail within setlocal ENABLEDELAYEDEXPANSION"
"data_i","edited Jun 04 '22 at 22:27","
        How to print a number using commas as thousands separators
    ","How do I print an integer with commas as thousands separators?1234567   ⟶   1,234,567It does not need to be locale-specific to decide between periods and commas.","Locale unaware'{:,}'.format(value)  # For Python ≥2.7f'{value:,}'          # For Python ≥3.6Locale awareimport localelocale.setlocale(locale.LC_ALL, '')  # Use '' for auto, or force e.g. to 'en_US.UTF-8''{:n}'.format(value)  # For Python ≥2.7f'{value:n}'          # For Python ≥3.6ReferencePer Format Specification Mini-Language,The ',' option signals the use of a comma for a thousands separator. For a locale aware separator, use the 'n' integer presentation type instead."
"data_i","edited Sep 04 '14 at 14:44","
        What characters do I need to escape in XML documents?
    ","What characters must be escaped in XML documents, or where could I find such a list?","If you use an appropriate class or library, they will do the escaping for you. Many XML issues are caused by string concatenation.XML escape charactersThere are only five:""   &quot;'   &apos;<   &lt;>   &gt;&   &amp;Escaping characters depends on where the special character is used.The examples can be validated at the W3C Markup Validation Service.TextThe safe way is to escape all five characters in text. However, the three characters "", ' and > needn't be escaped in text:<?xml version=""1.0""?><valid>""'></valid>AttributesThe safe way is to escape all five characters in attributes. However, the > character needn't be escaped in attributes:<?xml version=""1.0""?><valid attribute="">""/>The ' character needn't be escaped in attributes if the quotes are "":<?xml version=""1.0""?><valid attribute=""'""/>Likewise, the "" needn't be escaped in attributes if the quotes are ':<?xml version=""1.0""?><valid attribute='""'/>CommentsAll five special characters must not be escaped in comments:<?xml version=""1.0""?><valid><!-- ""'<>& --></valid>CDATAAll five special characters must not be escaped in CDATA sections:<?xml version=""1.0""?><valid><![CDATA[""'<>&]]></valid>Processing instructionsAll five special characters must not be escaped in XML processing instructions:<?xml version=""1.0""?><?process <""'&> ?><valid/>XML vs. HTMLHTML has its own set of escape codes which cover a lot more characters."
"data_i","edited Jun 20 '20 at 09:12","
        How do you keep parents of floated elements from collapsing?
    ","Although elements like <div>s normally grow to fit their contents, using the float property can cause a startling problem for CSS newbies: If floated elements have non-floated parent elements, the parent will collapse.For example:<div>  <div style=""float: left;"">Div 1</div>  <div style=""float: left;"">Div 2</div></div>The parent div in this example will not expand to contain its floated children - it will appear to have height: 0.How do you solve this problem?I would like to create an exhaustive list of solutions here. If you're aware of cross-browser compatibility issues, please point them out.Solution 1Float the parent.<div style=""float: left;"">  <div style=""float: left;"">Div 1</div>  <div style=""float: left;"">Div 2</div></div>Pros: Semantic code.Cons: You may not always want the parent floated. Even if you do, do you float the parents' parent, and so on? Must you float every ancestor element?Solution 2Give the parent an explicit height.<div style=""height: 300px;"">  <div style=""float: left;"">Div 1</div>  <div style=""float: left;"">Div 2</div></div>Pros: Semantic code.Cons: Not flexible - if the content changes or the browser is resized, the layout will break.Solution 3Append a ""spacer"" element inside the parent element, like this:<div>  <div style=""float: left;"">Div 1</div>  <div style=""float: left;"">Div 2</div>  <div class=""spacer"" style=""clear: both;""></div></div>Pros: Straightforward to code.Cons: Not semantic; the spacer div exists only as a layout hack.Solution 4Set parent to overflow: auto.<div style=""overflow: auto;"">  <div style=""float: left;"">Div 1</div>  <div style=""float: left;"">Div 2</div></div>Pros: Doesn't require extra div.Cons: Seems like a hack - that's not the overflow property's stated purpose.Comments? Other suggestions?","Solution 1:The most reliable and unobtrusive method appears to be this:Demo: http://jsfiddle.net/SO_AMK/wXaEH/HTML: <div class=""clearfix"">    <div style=""float: left;"">Div 1</div>    <div style=""float: left;"">Div 2</div></div>​CSS: .clearfix::after {    content: "" "";   display: block;    height: 0;    clear: both;}​With a little CSS targeting, you don't even need to add a class to the parent DIV.This solution is backward compatible with IE8 so you don't need to worry about older browsers failing.Solution 2:An adaptation of solution 1 has been suggested and is as follows:Demo: http://jsfiddle.net/wXaEH/162/HTML: <div class=""clearfix"">    <div style=""float: left;"">Div 1</div>    <div style=""float: left;"">Div 2</div></div>​CSS: .clearfix::after {    content: "" "";   display: block;    height: 0;    clear: both;   *zoom: expression( this.runtimeStyle['zoom'] = '1', this.innerHTML += '<div class=""ie7-clear""></div>' );}.ie7-clear {    display: block;    clear: both;}This solution appears to be backward compatible to IE5.5 but is untested.Solution 3:It's also possible to set display: inline-block; and width: 100%; to emulate a normal block element while not collapsing.Demo: http://jsfiddle.net/SO_AMK/ae5ey/CSS: .clearfix {    display: inline-block;    width: 100%;}This solution should be backward compatible with IE5.5 but has only been tested in IE6."
"data_i","edited Jun 13 '22 at 16:51","
        Convert a String representation of a Dictionary to a dictionary
    ","How can I convert the str representation of a dict, such as the following string, into a dict?s = ""{'muffin' : 'lolz', 'foo' : 'kitty'}""I prefer not to use eval. What else can I use?The main reason for this, is one of my coworkers classes he wrote, converts all input into strings. I'm not in the mood to go and modify his classes, to deal with this issue.","You can use the built-in ast.literal_eval:>>> import ast>>> ast.literal_eval(""{'muffin' : 'lolz', 'foo' : 'kitty'}""){'muffin': 'lolz', 'foo': 'kitty'}This is safer than using eval.  As its own docs say:>>> help(ast.literal_eval)Help on function literal_eval in module ast:literal_eval(node_or_string)    Safely evaluate an expression node or a string containing a Python    expression.  The string or node provided may only consist of the following    Python literal structures: strings, numbers, tuples, lists, dicts, booleans,    and None.For example:>>> eval(""shutil.rmtree('mongo')"")Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""<string>"", line 1, in <module>  File ""/opt/Python-2.6.1/lib/python2.6/shutil.py"", line 208, in rmtree    onerror(os.listdir, path, sys.exc_info())  File ""/opt/Python-2.6.1/lib/python2.6/shutil.py"", line 206, in rmtree    names = os.listdir(path)OSError: [Errno 2] No such file or directory: 'mongo'>>> ast.literal_eval(""shutil.rmtree('mongo')"")Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""/opt/Python-2.6.1/lib/python2.6/ast.py"", line 68, in literal_eval    return _convert(node_or_string)  File ""/opt/Python-2.6.1/lib/python2.6/ast.py"", line 67, in _convert    raise ValueError('malformed string')ValueError: malformed string"
"data_i","edited Apr 20 '18 at 20:01","
        Another git process seems to be running in this repository
    ","I'm trying to learn how to use Git and have created a small project with an HTML, CSS, and Javascript file. I made a branch from my basically empty project and then made some changes to my code. I tried staging the changes but I get the following error message:Another git process seems to be running in this repository, e.g.an editor opened by 'git commit'. Please make sure all processesare terminated then try again. If it still fails, a git processmay have crashed in this repository earlier:remove the file manually to continue.Granted, I did run into problems trying to commit my empty project earlier and just quit git bash since I didn't know how to get out of where I somehow had gotten. Is there any way for me to fix this or should I just start a new repository?","Try deleting index.lock file in your .git directory or in one of your worktrees .git/worktrees/*/index.lock if you are in a worktree.rm -f .git/index.lockSuch problems generally occur when you execute two git commands simultaneously; maybe one from the command prompt and one from an IDE."
"data_i","edited Dec 31 '20 at 02:00","
        When should I use curly braces for ES6 import?
    ","It seems to be obvious, but I found myself a bit confused about when to use curly braces for importing a single module in ES6. For example, in the React-Native project I am working on, I have the following file and its content:File initialState.jsvar initialState = {    todo: {        todos: [            {id: 1, task: 'Finish Coding', completed: false},            {id: 2, task: 'Do Laundry', completed: false},            {id: 2, task: 'Shopping Groceries', completed: false},        ]    }};export default initialState;In the TodoReducer.js, I have to import it without curly braces:import initialState from './todoInitialState';If I enclose the initialState in curly braces, I get the following error for the following line of code:Cannot read property todo of undefinedFile TodoReducer.js:export default function todos(state = initialState.todo, action) {    // ...}Similar errors also happen to my components with the curly braces. I was wondering when I should use curly braces for a single import, because obviously, when importing multiple component/modules, you have to enclose them in curly braces, which I know.The Stack Overflow post at here does not answer my question, instead I am asking when I should or should not use curly braces for importing a single module, or I should never use curly braces for importing a single module in ES6 (this is apparently not the case, as I have seen single import with curly braces required).","This is a default import:// B.jsimport A from './A'It only works if A has the default export:// A.jsexport default 42In this case it doesn’t matter what name you assign to it when importing:// B.jsimport A from './A'import MyA from './A'import Something from './A'Because it will always resolve to whatever is the default export of A.This is a named import called A:import { A } from './A'It only works if A contains a named export called A:export const A = 42In this case the name matters because you’re importing a specific thing by its export name:// B.jsimport { A } from './A'import { myA } from './A' // Doesn't work!import { Something } from './A' // Doesn't work!To make these work, you would add a corresponding named export to A:// A.jsexport const A = 42export const myA = 43export const Something = 44A module can only have one default export, but as many named exports as you'd like (zero, one, two, or many). You can import them all together:// B.jsimport A, { myA, Something } from './A'Here, we import the default export as A, and named exports called myA and Something, respectively.// A.jsexport default 42export const myA = 43export const Something = 44We can also assign them all different names when importing:// B.jsimport X, { myA as myX, Something as XSomething } from './A'The default exports tend to be used for whatever you normally expect to get from the module. The named exports tend to be used for utilities that might be handy, but aren’t always necessary. However it is up to you to choose how to export things: for example, a module might have no default export at all.This is a great guide to ES modules, explaining the difference between default and named exports."
"data_i","edited Feb 28 '21 at 07:58","
        Angular: conditional class with *ngClass
    ","What is wrong with my Angular code? I am getting the following error:Cannot read property 'remove' of undefined at BrowserDomAdapter.removeClass<ol>  <li *ngClass=""{active: step==='step1'}"" (click)=""step='step1'"">Step1</li>  <li *ngClass=""{active: step==='step2'}"" (click)=""step='step2'"">Step2</li>  <li *ngClass=""{active: step==='step3'}"" (click)=""step='step3'"">Step3</li></ol>","Angular version 2+ provides several ways to add classes conditionally:type one    [class.my_class] = ""step === 'step1'""type two    [ngClass]=""{'my_class': step === 'step1'}""and multiple option:    [ngClass]=""{'my_class': step === 'step1', 'my_class2' : step === 'step2' }""type three    [ngClass]=""{1 : 'my_class1', 2 : 'my_class2', 3 : 'my_class4'}[step]""type four    [ngClass]=""step == 'step1' ? 'my_class1' : 'my_class2'""You can find these examples on the documentation page"
"data_i","edited Aug 29 '14 at 16:19","
        How do I declare a namespace in JavaScript?
    ","How do I create a namespace in JavaScript so that my objects and functions aren't overwritten by other same-named objects and functions? I've used the following:if (Foo == null || typeof(Foo) != ""object"") { var Foo = new Object();}Is there a more elegant or succinct way of doing this?","I use the approach found on the Enterprise jQuery site:Here is their example showing how to declare private & public properties and functions. Everything is done as a self-executing anonymous function.(function( skillet, $, undefined ) {    //Private Property    var isHot = true;    //Public Property    skillet.ingredient = ""Bacon Strips"";    //Public Method    skillet.fry = function() {        var oliveOil;        addItem( ""\t\n Butter \n\t"" );        addItem( oliveOil );        console.log( ""Frying "" + skillet.ingredient );    };    //Private Method    function addItem( item ) {        if ( item !== undefined ) {            console.log( ""Adding "" + $.trim(item) );        }    }}( window.skillet = window.skillet || {}, jQuery ));So if you want to access one of the public members you would just go skillet.fry() or skillet.ingredients.What's really cool is that you can now extend the namespace using the exact same syntax.//Adding new Functionality to the skillet(function( skillet, $, undefined ) {    //Private Property    var amountOfGrease = ""1 Cup"";    //Public Method    skillet.toString = function() {        console.log( skillet.quantity + "" "" +                     skillet.ingredient + "" & "" +                     amountOfGrease + "" of Grease"" );        console.log( isHot ? ""Hot"" : ""Cold"" );    };}( window.skillet = window.skillet || {}, jQuery ));The third undefined argumentThe third, undefined argument is the source of the variable of value undefined. I'm not sure if it's still relevant today, but while working with older browsers / JavaScript standards (ecmascript 5, javascript < 1.8.5 ~ firefox 4), the global-scope variable undefined is writable, so anyone could rewrite its value. The third argument (when not passed a value) creates a variable named undefined which is scoped to the namespace/function. Because no value was passed when you created the name space, it defaults to the value undefined."
"data_i","edited May 28 '13 at 11:35","
        How to convert a Drawable to a Bitmap?
    ","I would like to set a certain Drawable as the device's wallpaper, but all wallpaper functions accept Bitmaps only. I cannot use WallpaperManager because I'm pre 2.1.Also, my drawables are downloaded from the web and do not reside in R.drawable.","This piece of code helps.Bitmap icon = BitmapFactory.decodeResource(context.getResources(),                                           R.drawable.icon_resource);Here a version where the image gets downloaded.String name = c.getString(str_url);URL url_value = new URL(name);ImageView profile = (ImageView)v.findViewById(R.id.vdo_icon);if (profile != null) {    Bitmap mIcon1 =        BitmapFactory.decodeStream(url_value.openConnection().getInputStream());    profile.setImageBitmap(mIcon1);}"
"data_i","edited Jun 04 '22 at 22:31","
        Convert list of dictionaries to a pandas DataFrame
    ","How can I convert a list of dictionaries into a DataFrame? Given:[{'points': 50, 'time': '5:00', 'year': 2010},  {'points': 25, 'time': '6:00', 'month': ""february""},  {'points':90, 'time': '9:00', 'month': 'january'},  {'points_h1':20, 'month': 'june'}]I want to turn the above into a DataFrame:      month  points  points_h1  time  year0       NaN      50        NaN  5:00  20101  february      25        NaN  6:00   NaN2   january      90        NaN  9:00   NaN3      june     NaN         20   NaN   NaNNote: Order of the columns does not matter.","If ds is a list of dicts:df = pd.DataFrame(ds)Note: this does not work with nested data."
"data_i","edited Dec 10 '18 at 03:43","
        Getting error: Peer authentication failed for user ""postgres"", when trying to get pgsql working with rails
    ","I'm getting the error:FATAL: Peer authentication failed for user ""postgres""when I try to make postgres work with Rails. Here's my pg_hba.conf, my database.yml, and a dump of the full trace.I changed authentication to md5 in pg_hba and tried different things, but none seem to work. I also tried creating a new user and database as per Rails 3.2, FATAL: Peer authentication failed for user (PG::Error)But they don't show up on pgadmin or even when I run sudo -u postgres psql -l.Any idea where I'm going wrong?","The problem is still your pg_hba.conf file*.This line:local   all             postgres                                peerShould be:local   all             postgres                                md5After altering this file, don't forget to restart your PostgreSQL server. If you're on Linux, that would be sudo service postgresql restart.Locating hba.confNote that the location of this file isn't very consistent.You can use locate pg_hba.conf or ask PostgreSQL SHOW hba_file; to discover the file location.Usual locations are /etc/postgresql/[version]/main/pg_hba.conf and /var/lib/pgsql/data/pg_hba.conf.These are brief descriptions of the peer vs md5 options according to the official PostgreSQL docs on authentication methods.Peer authenticationThe peer authentication method works by obtaining the client'soperating system user name from the kernel and using it as the alloweddatabase user name (with optional user name mapping). This method isonly supported on local connections.Password authenticationThe password-based authentication methods are md5 and password. Thesemethods operate similarly except for the way that the password is sentacross the connection, namely MD5-hashed and clear-text respectively.If you are at all concerned about password ""sniffing"" attacks then md5is preferred. Plain password should always be avoided if possible.However, md5 cannot be used with the db_user_namespace feature. If theconnection is protected by SSL encryption then password can be usedsafely (though SSL certificate authentication might be a better choiceif one is depending on using SSL)."
"data_i","edited May 03 '16 at 13:01","
        Randomize a List
    ","What is the best way to randomize the order of a generic list in C#? I've got a finite set of 75 numbers in a list I would like to assign a random order to, in order to draw them for a lottery type application.","Shuffle any (I)List with an extension method based on the Fisher-Yates shuffle:private static Random rng = new Random();  public static void Shuffle<T>(this IList<T> list)  {      int n = list.Count;      while (n > 1) {          n--;          int k = rng.Next(n + 1);          T value = list[k];          list[k] = list[n];          list[n] = value;      }  }Usage:List<Product> products = GetProducts();products.Shuffle();The code above uses the much criticised System.Random method to select swap candidates. It's fast but not as random as it should be. If you need a better quality of randomness in your shuffles use the random number generator in System.Security.Cryptography like so:using System.Security.Cryptography;...public static void Shuffle<T>(this IList<T> list){    RNGCryptoServiceProvider provider = new RNGCryptoServiceProvider();    int n = list.Count;    while (n > 1)    {        byte[] box = new byte[1];        do provider.GetBytes(box);        while (!(box[0] < n * (Byte.MaxValue / n)));        int k = (box[0] % n);        n--;        T value = list[k];        list[k] = list[n];        list[n] = value;    }}A simple comparison is available at this blog (WayBack Machine).Edit: Since writing this answer a couple years back, many people have commented or written to me, to point out the big silly flaw in my comparison. They are of course right. There's nothing wrong with System.Random if it's used in the way it was intended. In my first example above, I instantiate the rng variable inside of the Shuffle method, which is asking for trouble if the method is going to be called repeatedly. Below is a fixed, full example based on a really useful comment received today from @weston here on SO.Program.cs:using System;using System.Collections.Generic;using System.Threading;namespace SimpleLottery{  class Program  {    private static void Main(string[] args)    {      var numbers = new List<int>(Enumerable.Range(1, 75));      numbers.Shuffle();      Console.WriteLine(""The winning numbers are: {0}"", string.Join("",  "", numbers.GetRange(0, 5)));    }  }  public static class ThreadSafeRandom  {      [ThreadStatic] private static Random Local;      public static Random ThisThreadsRandom      {          get { return Local ?? (Local = new Random(unchecked(Environment.TickCount * 31 + Thread.CurrentThread.ManagedThreadId))); }      }  }  static class MyExtensions  {    public static void Shuffle<T>(this IList<T> list)    {      int n = list.Count;      while (n > 1)      {        n--;        int k = ThreadSafeRandom.ThisThreadsRandom.Next(n + 1);        T value = list[k];        list[k] = list[n];        list[n] = value;      }    }  }}"
"data_i","asked Sep 17 '08 at 11:44","
        How do I use sudo to redirect output to a location I don't have permission to write to?
    ","I've been given sudo access on one of our development RedHat linux boxes, and I seem to find myself quite often needing to redirect output to a location I don't normally have write access to.The trouble is, this contrived example doesn't work:sudo ls -hal /root/ > /root/test.outI just receive the response:-bash: /root/test.out: Permission deniedHow can I get this to work?","Your command does not work because the redirection is performed by your shell which does not have the permission to write to /root/test.out. The redirection of the output is not performed by sudo.There are multiple solutions:Run a shell with sudo and give the command to it by using the -c option:sudo sh -c 'ls -hal /root/ > /root/test.out'Create a script with your commands and run that script with sudo:#!/bin/shls -hal /root/ > /root/test.outRun sudo ls.sh. See Steve Bennett's answer if you don't want to create a temporary file.Launch a shell with sudo -s then run your commands:[nobody@so]$ sudo -s[root@so]# ls -hal /root/ > /root/test.out[root@so]# ^D[nobody@so]$Use sudo tee (if you have to escape a lot when using the -c option):sudo ls -hal /root/ | sudo tee /root/test.out > /dev/nullThe redirect to /dev/null is needed to stop tee from outputting to the screen. To append instead of overwriting the output file (>>), use tee -a or tee --append (the last one is specific to GNU coreutils).Thanks go to Jd, Adam J. Forster and Johnathan for the second, third and fourth solutions."
"data_i","edited Nov 22 '19 at 07:38","
        HTML text input allow only numeric input
    ","Is there a quick way to set an HTML text input (<input type=text />) to only allow numeric keystrokes (plus '.')?","Note: This is an updated answer. Comments below refer to an old version which messed around with keycodes.JavaScriptTry it yourself on JSFiddle.You can filter the input values of a text <input> with the following setInputFilter function (supports Copy+Paste, Drag+Drop, keyboard shortcuts, context menu operations, non-typeable keys, the caret position, different keyboard layouts, validity error message, and all browsers since IE 9):// Restricts input for the given textbox to the given inputFilter function.function setInputFilter(textbox, inputFilter, errMsg) {  [""input"", ""keydown"", ""keyup"", ""mousedown"", ""mouseup"", ""select"", ""contextmenu"", ""drop"", ""focusout""].forEach(function(event) {    textbox.addEventListener(event, function(e) {      if (inputFilter(this.value)) {        // Accepted value        if ([""keydown"",""mousedown"",""focusout""].indexOf(e.type) >= 0){          this.classList.remove(""input-error"");          this.setCustomValidity("""");        }        this.oldValue = this.value;        this.oldSelectionStart = this.selectionStart;        this.oldSelectionEnd = this.selectionEnd;      } else if (this.hasOwnProperty(""oldValue"")) {        // Rejected value - restore the previous one        this.classList.add(""input-error"");        this.setCustomValidity(errMsg);        this.reportValidity();        this.value = this.oldValue;        this.setSelectionRange(this.oldSelectionStart, this.oldSelectionEnd);      } else {        // Rejected value - nothing to restore        this.value = """";      }    });  });}You can now use the setInputFilter function to install an input filter:setInputFilter(document.getElementById(""myTextBox""), function(value) {  return /^\d*\.?\d*$/.test(value); // Allow digits and '.' only, using a RegExp}, ""Only digits and '.' are allowed"");Apply your preferred style to input-error class. Here's a suggestion:.input-error{  outline: 1px solid red;}See the JSFiddle demo for more input filter examples. Also note that you still must do server side validation!TypeScriptHere is a TypeScript version of this.function setInputFilter(textbox: Element, inputFilter: (value: string) => boolean, errMsg: string): void {    [""input"", ""keydown"", ""keyup"", ""mousedown"", ""mouseup"", ""select"", ""contextmenu"", ""drop"", ""focusout""].forEach(function(event) {        textbox.addEventListener(event, function(this: (HTMLInputElement | HTMLTextAreaElement) & {oldValue: string; oldSelectionStart: number | null, oldSelectionEnd: number | null}) {            if (inputFilter(this.value)) {                this.oldValue = this.value;                this.oldSelectionStart = this.selectionStart;                this.oldSelectionEnd = this.selectionEnd;            } else if (Object.prototype.hasOwnProperty.call(this, 'oldValue')) {                this.value = this.oldValue;                if (this.oldSelectionStart !== null &&                    this.oldSelectionEnd !== null) {                    this.setSelectionRange(this.oldSelectionStart, this.oldSelectionEnd);                }            } else {                this.value = """";            }        });    });}jQueryThere is also a jQuery version of this. See this answer.HTML 5HTML 5 has a native solution with <input type=""number""> (see the specification), but note that browser support varies:Most browsers will only validate the input when submitting the form, and not when typing.Most mobile browsers don't support the step, min and max attributes.Chrome (version 71.0.3578.98) still allows the user to enter the characters e and E into the field. Also see this question.Firefox (version 64.0) and Edge (EdgeHTML version 17.17134) still allow the user to enter any text into the field.Try it yourself on w3schools.com."
"data_i","edited Oct 15 '21 at 15:24","
        Is there a ""theirs"" version of ""git merge -s ours""?
    ","When merging topic branch ""B"" into ""A"" using git merge, I get some conflicts. I know all the conflicts can be solved using the version in ""B"".I am aware of git merge -s ours. But what I want is something like git merge -s theirs.Why doesn't it exist? How can I achieve the same result after the conflicting merge with existing git commands? (git checkout every unmerged file from B)The ""solution"" of just discarding anything from branch A (the merge commit point to B version of the tree) is not what I am looking for.","A similar alternative is the --strategy-option (short form -X) option, which accepts theirs. For example:git checkout branchAgit merge -X theirs branchBHowever, this is more equivalent to -X ours than -s ours. The key difference being that -X performs a regular recursive merge, resolving any conflicts using the chosen side, whereas -s ours changes the merge to just completely ignore the other side.In some cases, the main problem using -X theirs instead of the hypothetical -s theirs is deleted files. In this case, just run git rm with the name of any files that were deleted:git rm {DELETED-FILE-NAME}After that, the -X theirs may work as expected.Of course, doing the actual removal with the git rm command will prevent the conflict from happening in the first place."
"data_i","edited Oct 22 '18 at 12:19","
        How to deal with persistent storage (e.g. databases) in Docker
    ","How do people deal with persistent storage for your Docker containers?I am currently using this approach: build the image, e.g. for PostgreSQL, and then start the container withdocker run --volumes-from c0dbc34fd631 -d app_name/postgresIMHO, that has the drawback, that I must not ever (by accident) delete container ""c0dbc34fd631"".Another idea would be to mount host volumes ""-v"" into the container, however, the userid within the container does not necessarily match the userid from the host, and then permissions might be messed up.Note: Instead of --volumes-from 'cryptic_id' you can also use --volumes-from my-data-container where my-data-container is a name you assigned to a data-only container, e.g. docker run --name my-data-container ... (see the accepted answer)","Docker 1.9.0 and aboveUse volume APIdocker volume create --name hellodocker run -d -v hello:/container/path/for/volume container_image my_commandThis means that the data-only container pattern must be abandoned in favour of the new volumes.Actually the volume API is only a better way to achieve what was the data-container pattern.If you create a container with a -v volume_name:/container/fs/path Docker will automatically create a named volume for you that can:Be listed through the docker volume lsBe identified through the docker volume inspect volume_nameBacked up as a normal directoryBacked up as before through a --volumes-from connectionThe new volume API adds a useful command that lets you identify dangling volumes:docker volume ls -f dangling=trueAnd then remove it through its name:docker volume rm <volume name>As @mpugach underlines in the comments, you can get rid of all the dangling volumes with a nice one-liner:docker volume rm $(docker volume ls -f dangling=true -q)# Or using 1.13.xdocker volume pruneDocker 1.8.x and belowThe approach that seems to work best for production is to use a data only container.The data only container is run on a barebones image and actually does nothing except exposing a data volume.Then you can run any other container to have access to the data container volumes:docker run --volumes-from data-container some-other-container command-to-executeHere you can get a good picture of how to arrange the different containers.Here there is a good insight on how volumes work.In this blog post there is a good description of the so-called container as volume pattern which clarifies the main point of having data only containers.Docker documentation has now the DEFINITIVE description of the container as volume/s pattern.Following is the backup/restore procedure for Docker 1.8.x and below.BACKUP:sudo docker run --rm --volumes-from DATA -v $(pwd):/backup busybox tar cvf /backup/backup.tar /data--rm: remove the container when it exits--volumes-from DATA: attach to the volumes shared by the DATA container-v $(pwd):/backup: bind mount the current directory into the container; to write the tar file tobusybox: a small simpler image - good for quick maintenancetar cvf /backup/backup.tar /data: creates an uncompressed tar file of all the files in the /data directoryRESTORE:# Create a new data container$ sudo docker run -v /data -name DATA2 busybox true# untar the backup files into the new container᾿s data volume$ sudo docker run --rm --volumes-from DATA2 -v $(pwd):/backup busybox tar xvf /backup/backup.tardata/data/sven.txt# Compare to the original container$ sudo docker run --rm --volumes-from DATA -v `pwd`:/backup busybox ls /datasven.txtHere is a nice article from the excellent Brian Goff explaining why it is good to use the same image for a container and a data container."
"data_i","edited Jun 02 '21 at 13:41","
        Undefined behavior and sequence points
    ","What are ""sequence points""?What is the relation between undefined behaviour and sequence points?I often use funny and convoluted expressions like a[++i] = i;, to make myself feel better. Why should I stop using them?If you've read this, be sure to visit the follow-up question Undefined behavior and sequence points reloaded.(Note: This is meant to be an entry to Stack Overflow's C++ FAQ. If you want to critique the idea of providing an FAQ in this form, then the posting on meta that started all this would be the place to do that. Answers to that question are monitored in the C++ chatroom, where the FAQ idea started out in the first place, so your answer is very likely to get read by those who came up with the idea.)","C++98 and C++03This answer is for the older versions of the C++ standard.  The C++11 and C++14 versions of the standard do not formally contain 'sequence points'; operations are 'sequenced before' or 'unsequenced' or 'indeterminately sequenced' instead.  The net effect is essentially the same, but the terminology is different.Disclaimer : Okay. This answer is a bit long. So have patience while reading it. If you already know these things, reading them again won't make you crazy.Pre-requisites : An elementary knowledge of C++ StandardWhat are Sequence Points?The Standard saysAt  certain specified points in the execution sequence called sequence points, all side effects of previous evaluationsshall be complete and no side effects of subsequent evaluations shall have taken place. (§1.9/7)Side effects? What are side effects?Evaluation  of  an  expression produces something and if in addition there is a change in the state of the execution environment it is said that the expression (its evaluation) has some side effect(s).For example:int x = y++; //where y is also an intIn addition to the initialization operation the value of y gets changed due to the side effect of ++ operator.So far so good. Moving on to sequence points. An alternation definition of seq-points given by the comp.lang.c author Steve Summit:Sequence point is a point in time at which the dust has settled and all side effects which have been seen so far are guaranteed to be complete.What are the common sequence points listed in the C++ Standard?Those are:at the end of the evaluation of full expression (§1.9/16) (A full-expression is an expression that is not a subexpression of another expression.)1Example :int a = 5; // ; is a sequence point herein the evaluation of each of the following expressions after the evaluation of the first expression (§1.9/18) 2a && b (§5.14)a || b (§5.15)a ? b : c (§5.16)a , b (§5.18) (here a , b is a comma operator; in func(a,a++) , is not a comma operator, it's merely a separator between the arguments a and a++. Thus the behaviour is undefined in that case (if a is considered to be a primitive type)) at a function call (whether or not the function is inline), after the evaluation of all function arguments (if any) whichtakes place before execution of any expressions or statements in the function body (§1.9/17).1 : Note : the evaluation of a full-expression can include the evaluation of subexpressions that are not lexicallypart of the full-expression.  For example, subexpressions involved in evaluating default argument expressions (8.3.6) are considered to be created in the expression that calls the function, not the expression that defines the default argument2 : The operators indicated are the built-in operators, as described in clause 5.  When one of these operators is overloaded (clause 13) in a valid context, thus designating a user-defined operator function, the expression designates a function invocation and the operands form an argument list, without an implied sequence point between them.What is Undefined Behaviour?The Standard defines Undefined Behaviour in Section §1.3.12 asbehavior, such as might arise upon use of an erroneous program construct or erroneous data, for which this International Standard imposes no  requirements 3.Undefined  behavior  may  also  be  expected  when  thisInternational Standard omits the description of any explicit definition of behavior. 3 : permissible undefined behavior ranges from ignoring the situation completely with unpredictable results, to behaving during translation or program execution in a documented manner characteristic of the environment (with or with-out the issuance of a diagnostic message), to terminating a translation or execution (with the issuance of a diagnostic message).In short, undefined behaviour means anything can happen from daemons flying out of your nose to  your girlfriend getting pregnant.What is the relation between Undefined Behaviour and Sequence Points?Before I get into that you must know the difference(s) between Undefined Behaviour, Unspecified Behaviour and Implementation Defined Behaviour.You must also know that the order of evaluation of operands of individual operators and subexpressions of individual expressions, and the order in which side effects take place, is unspecified.For example:int x = 5, y = 6;int z = x++ + y++; //it is unspecified whether x++ or y++ will be evaluated first.Another example here.Now the Standard in §5/4 saysBetween the previous and next sequence point a scalar object shall have its stored value modified at most once by the evaluation of an expression.What does it mean?Informally it means that between two sequence points a variable must not be modified more than once.In an expression statement, the next sequence point is usually at the terminating semicolon, and the previous sequence point is at the end of the previous statement. An expression may also contain intermediate sequence points.From the above sentence the following expressions invoke Undefined Behaviour:i++ * ++i;   // UB, i is modified more than once btw two SPsi = ++i;     // UB, same as above++i = 2;     // UB, same as abovei = ++i + 1; // UB, same as above++++++i;     // UB, parsed as (++(++(++i)))i = (i, ++i, ++i); // UB, there's no SP between `++i` (right most) and assignment to `i` (`i` is modified more than once btw two SPs)But the following expressions are fine:i = (i, ++i, 1) + 1; // well defined (AFAIK)i = (++i, i++, i);   // well defined int j = i;j = (++i, i++, j*i); // well definedFurthermore, the prior value shall be accessed only to determine the value to be stored.What does it mean? It means if an object is written to within a full expression, any and all accesses to it within the same expression must be directly involved in the computation of the value to be written.For example in i = i + 1 all the access of i (in L.H.S and in R.H.S) are directly involved in computation of the value to be written. So it is fine.This rule effectively constrains legal expressions to those in which the accesses demonstrably precede the modification.Example 1:std::printf(""%d %d"", i,++i); // invokes Undefined Behaviour because of Rule no 2Example 2:a[i] = i++ // or a[++i] = i or a[i++] = ++i etcis disallowed because one of the accesses of i (the one in a[i]) has nothing to do with the value which ends up being stored in i (which happens over in i++), and so there's no good way to define--either for our understanding or the compiler's--whether the access should take place before or after the incremented value is stored. So the behaviour is undefined.Example 3 :int x = i + i++ ;// Similar to aboveFollow up answer for C++11 here."
"data_i","edited Feb 25 '21 at 21:56","
        How to download a file over HTTP?
    ","I have a small utility that I use to download an MP3 file from a website on a schedule and then builds/updates a podcast XML file which I've added to iTunes.The text processing that creates/updates the XML file is written in Python. However, I use wget inside a Windows .bat file to download the actual MP3 file. I would prefer to have the entire utility written in Python.I struggled to find a way to actually download the file in Python, thus why I resorted to using wget.So, how do I download the file using Python?","One more, using urlretrieve:import urllib.requesturllib.request.urlretrieve(""http://www.example.com/songs/mp3.mp3"", ""mp3.mp3"")(for Python 2 use import urllib and urllib.urlretrieve)"
"data_i","edited Jun 21 '22 at 18:56","
        Sort array by firstname (alphabetically) in JavaScript
    ","I got an array (see below for one object in the array) that I need to sort by firstname using JavaScript.How can I do it?var user = {   bio: null,   email:  ""user@domain.example"",   firstname: ""Anna"",   id: 318,   lastAvatar: null,   lastMessage: null,   lastname: ""Nickson"",   nickname: ""anny""};","Shortest possible code with ES6!users.sort((a, b) => a.firstname.localeCompare(b.firstname))String.prototype.localeCompare() basic support is universal!"
"data_i","edited Jul 11 '22 at 16:06","
        How to add 30 minutes to a JavaScript Date object?
    ","I'd like to get a Date object which is 30 minutes later than another Date object.  How do I do it with JavaScript?","Using a LibraryIf you are doing a lot of date work, you may want to look into JavaScript date libraries like Datejs or Moment.js. For example, with Moment.js, this is simply:var newDateObj = moment(oldDateObj).add(30, 'm').toDate();Vanilla JavascriptThis is like chaos's answer, but in one line:var newDateObj = new Date(oldDateObj.getTime() + diff*60000);Where diff is the difference in minutes you want from oldDateObj's time. It can even be negative.Or as a reusable function, if you need to do this in multiple places:function addMinutes(date, minutes) {    return new Date(date.getTime() + minutes*60000);}And just in case this is not obvious, the reason we multiply minutes by 60000 is to convert minutes to milliseconds.Be Careful with Vanilla Javascript. Dates Are Hard!You may think you can add 24 hours to a date to get tomorrow's date, right? Wrong!addMinutes(myDate, 60*24); //DO NOT DO THISIt turns out, if the user observes daylight saving time, a day is not necessarily 24 hours long. There is one day a year that is only 23 hours long, and one day a year that is 25 hours long. For example, in most of the United States and Canada, 24 hours after midnight, Nov 2, 2014, is still Nov 2:const NOV = 10; //because JS months are off by one...addMinutes(new Date(2014, NOV, 2), 60*24); //In USA, prints 11pm on Nov 2, not 12am Nov 3!This is why using one of the afore-mentioned libraries is a safer bet if you have to do a lot of work with this.Below is a more generic version of this function that I wrote. I'd still recommend using a library, but that may be overkill/impossible for your project. The syntax is modeled after MySQL DATE_ADD function./** * Adds time to a date. Modelled after MySQL DATE_ADD function. * Example: dateAdd(new Date(), 'minute', 30)  //returns 30 minutes from now. * https://stackoverflow.com/a/1214753/18511 *  * @param date  Date to start with * @param interval  One of: year, quarter, month, week, day, hour, minute, second * @param units  Number of units of the given interval to add. */function dateAdd(date, interval, units) {  if(!(date instanceof Date))    return undefined;  var ret = new Date(date); //don't change original date  var checkRollover = function() { if(ret.getDate() != date.getDate()) ret.setDate(0);};  switch(String(interval).toLowerCase()) {    case 'year'   :  ret.setFullYear(ret.getFullYear() + units); checkRollover();  break;    case 'quarter':  ret.setMonth(ret.getMonth() + 3*units); checkRollover();  break;    case 'month'  :  ret.setMonth(ret.getMonth() + units); checkRollover();  break;    case 'week'   :  ret.setDate(ret.getDate() + 7*units);  break;    case 'day'    :  ret.setDate(ret.getDate() + units);  break;    case 'hour'   :  ret.setTime(ret.getTime() + units*3600000);  break;    case 'minute' :  ret.setTime(ret.getTime() + units*60000);  break;    case 'second' :  ret.setTime(ret.getTime() + units*1000);  break;    default       :  ret = undefined;  break;  }  return ret;}Working jsFiddle demo."
"data_i","edited Apr 17 '20 at 18:35","
        What does the ""~"" (tilde/squiggle/twiddle) CSS selector mean?
    ","Searching for the ~ character isn't easy. I was looking over some CSS and found this.check:checked ~ .content {}What does it mean?","The ~ selector is in fact the subsequent-sibling combinator (previously called general sibling combinator until 2017):The subsequent-sibling combinator is made of the ""tilde"" (U+007E, ~)character that separates two sequences of simple selectors. Theelements represented by the two sequences share the same parent in thedocument tree and the element represented by the first sequenceprecedes (not necessarily immediately) the element represented by thesecond one.Consider the following example:.a ~ .b {  background-color: powderblue;}<ul>  <li class=""b"">1st</li>  <li class=""a"">2nd</li>  <li>3rd</li>  <li class=""b"">4th</li>  <li class=""b"">5th</li></ul>.a ~ .b matches the 4th and 5th list item because they:Are .b elementsAre siblings of .aAppear after .a in HTML source order.Likewise, .check:checked ~ .content matches all .content elements that are siblings of .check:checked and appear after it."
"data_i","edited Apr 16 '20 at 10:57","
        What are the nuances of scope prototypal / prototypical inheritance in AngularJS?
    ","The API Reference Scope page says:A scope can inherit from a parent scope.The Developer Guide Scope page says:A scope (prototypically) inherits properties from its parent scope.So, does a child scope always prototypically inherit from its parent scope?  Are there exceptions?   When it does inherit, is it always normal JavaScript prototypal inheritance?","Quick answer: A child scope normally prototypically inherits from its parent scope, but not always.  One exception to this rule is a directive with scope: { ... } -- this creates an ""isolate"" scope that does not prototypically inherit.  This construct is often used when creating a ""reusable component"" directive.As for the nuances, scope inheritance is normally straightfoward... until you need 2-way data binding (i.e., form elements, ng-model) in the child scope.  Ng-repeat, ng-switch, and ng-include can trip you up if you try to bind to a primitive (e.g., number, string, boolean) in the parent scope from inside the child scope.  It doesn't work the way most people expect it should work.  The child scope gets its own property that hides/shadows the parent property of the same name.  Your workarounds aredefine objects in the parent for your model, then reference a property of that object  in the child:  parentObj.somePropuse $parent.parentScopeProperty (not always possible, but easier than 1. where possible)define a function on the parent scope, and call it from the child (not always possible)New AngularJS developers often do not realize that ng-repeat, ng-switch, ng-view, ng-include and ng-if all create new child scopes, so the problem often shows up when these directives are involved. (See this example for a quick illustration of the problem.)This issue with primitives can be easily avoided by following the ""best practice"" of always have a '.' in your ng-models – watch 3 minutes worth. Misko demonstrates the primitive binding issue with ng-switch.Having a '.' in your models will ensure that prototypal inheritance is in play. So, use<input type=""text"" ng-model=""someObj.prop1""><!--rather than<input type=""text"" ng-model=""prop1"">`-->L-o-n-g answer:JavaScript Prototypal InheritanceAlso placed on the AngularJS wiki: https://github.com/angular/angular.js/wiki/Understanding-ScopesIt is important to first have a solid understanding of prototypal inheritance, especially if you are coming from a server-side background and you are more familiar with class-ical inheritance.  So let's review that first.Suppose parentScope has properties aString, aNumber, anArray, anObject, and aFunction.  If childScope prototypically inherits from parentScope, we have:(Note that to save space, I show the anArray object as a single blue object with its three values, rather than an single blue object with three separate gray literals.)If we try to access a property defined on the parentScope from the child scope, JavaScript will first look in the child scope, not find the property, then look in the inherited scope, and find the property.  (If it didn't find the property in the parentScope, it would continue up the prototype chain... all the way up to the root scope). So, these are all true:childScope.aString === 'parent string'childScope.anArray[1] === 20childScope.anObject.property1 === 'parent prop1'childScope.aFunction() === 'parent output'Suppose we then do this:childScope.aString = 'child string'The prototype chain is not consulted, and a new aString property is added to the childScope.  This new property hides/shadows the parentScope property with the same name.  This will become very important when we discuss ng-repeat and ng-include below.Suppose we then do this:childScope.anArray[1] = '22'childScope.anObject.property1 = 'child prop1'The prototype chain is consulted because the objects (anArray and anObject) are not found in the childScope.  The objects are found in the parentScope, and the property values are updated on the original objects.  No new properties are added to the childScope;  no new objects are created.  (Note that in JavaScript arrays and functions are also objects.)Suppose we then do this:childScope.anArray = [100, 555]childScope.anObject = { name: 'Mark', country: 'USA' }The prototype chain is not consulted, and child scope gets two new object properties that hide/shadow the parentScope object properties with the same names.Takeaways:If we read childScope.propertyX, and childScope has propertyX, then the prototype chain is not consulted.If we set childScope.propertyX, the prototype chain is not consulted.One last scenario:delete childScope.anArraychildScope.anArray[1] === 22  // trueWe deleted the childScope property first, then when we try to access the property again, the prototype chain is consulted.Angular Scope InheritanceThe contenders:The following create new scopes, and inherit prototypically: ng-repeat, ng-include, ng-switch, ng-controller, directive with scope: true, directive with transclude: true.The following creates a new scope which does not inherit prototypically: directive with scope: { ... }.  This creates an ""isolate"" scope instead.Note, by default, directives do not create new scope -- i.e., the default is scope: false.ng-includeSuppose we have in our controller:$scope.myPrimitive = 50;$scope.myObject    = {aNumber: 11};And in our HTML:<script type=""text/ng-template"" id=""/tpl1.html""><input ng-model=""myPrimitive""></script><div ng-include src=""'/tpl1.html'""></div><script type=""text/ng-template"" id=""/tpl2.html""><input ng-model=""myObject.aNumber""></script><div ng-include src=""'/tpl2.html'""></div>Each ng-include generates a new child scope, which prototypically inherits from the parent scope.Typing (say, ""77"") into the first input textbox causes the child scope to get a new myPrimitive scope property that hides/shadows the parent scope property of the same name.  This is probably not what you want/expect.Typing (say, ""99"") into the second input textbox does not result in a new child property.  Because tpl2.html binds the model to an object property, prototypal inheritance kicks in when the ngModel looks for object myObject -- it finds it in the parent scope.We can rewrite the first template to use $parent, if we don't want to change our model from a primitive to an object:<input ng-model=""$parent.myPrimitive"">Typing (say, ""22"") into this input textbox does not result in a new child property.  The model is now bound to a property of the parent scope (because $parent is a child scope property that references the parent scope).For all scopes (prototypal or not), Angular always tracks a parent-child relationship (i.e., a hierarchy), via scope properties $parent, $$childHead and $$childTail.  I normally don't show these scope properties in the diagrams.For scenarios where form elements are not involved, another solution is to define a function on the parent scope to modify the primitive.  Then ensure the child always calls this function, which will be available to the child scope due to prototypal inheritance. E.g.,// in the parent scope$scope.setMyPrimitive = function(value) {     $scope.myPrimitive = value;}Here is a sample fiddle that uses this ""parent function"" approach.  (The fiddle was written as part of this answer: https://stackoverflow.com/a/14104318/215945.)See also https://stackoverflow.com/a/13782671/215945 and https://github.com/angular/angular.js/issues/1267.ng-switchng-switch scope inheritance works just like ng-include.  So if you need 2-way data binding to a primitive in the parent scope, use $parent, or change the model to be an object and then bind to a property of that object.  This will avoid child scope hiding/shadowing of parent scope properties.See also AngularJS, bind scope of a switch-case?ng-repeatNg-repeat works a little differently.  Suppose we have in our controller:$scope.myArrayOfPrimitives = [ 11, 22 ];$scope.myArrayOfObjects    = [{num: 101}, {num: 202}]And in our HTML:<ul><li ng-repeat=""num in myArrayOfPrimitives"">       <input ng-model=""num"">    </li><ul><ul><li ng-repeat=""obj in myArrayOfObjects"">       <input ng-model=""obj.num"">    </li><ul>For each item/iteration, ng-repeat creates a new scope, which prototypically inherits from the parent scope, but it also assigns the item's value to a new property on the new child scope.  (The name of the new property is the loop variable's name.)  Here's what the Angular source code for ng-repeat actually is:childScope = scope.$new();  // child scope prototypically inherits from parent scope...childScope[valueIdent] = value;  // creates a new childScope propertyIf item is a primitive (as in myArrayOfPrimitives), essentially a copy of the value is assigned to the new child scope property.  Changing the child scope property's value (i.e., using ng-model, hence child scope num) does not change the array the parent scope references.  So in the first ng-repeat above, each child scope gets a num property that is independent of the myArrayOfPrimitives array:This ng-repeat will not work (like you want/expect it to).  Typing into the textboxes changes the values in the gray boxes, which are only visible in the child scopes.  What we want is for the inputs to affect the myArrayOfPrimitives array, not a child scope primitive property.  To accomplish this, we need to change the model to be an array of objects.So, if item is an object, a reference to the original object (not a copy) is assigned to the new child scope property.  Changing the child scope property's value (i.e., using ng-model, hence obj.num) does change the object the parent scope references.  So in the second ng-repeat above, we have:(I colored one line gray just so that it is clear where it is going.)This works as expected.  Typing into the textboxes changes the values in the gray boxes, which are visible to both the child and parent scopes.See also Difficulty with ng-model, ng-repeat, and inputs and https://stackoverflow.com/a/13782671/215945ng-controllerNesting controllers using ng-controller results in normal prototypal inheritance, just like ng-include and ng-switch, so the same techniques apply.However, ""it is considered bad form for two controllers to share information via $scope inheritance"" -- http://onehungrymind.com/angularjs-sticky-notes-pt-1-architecture/A service should be used to share data between controllers instead.(If you really want to share data via controllers scope inheritance, there is nothing you need to do.  The child scope will have access to all of the parent scope properties.See also Controller load order differs when loading or navigating)directivesdefault (scope: false) - the directive does not create a new scope, so there is no inheritance here.  This is easy, but also dangerous because, e.g., a directive might think it is creating a new property on the scope, when in fact it is clobbering an existing property.  This is not a good choice for writing directives that are intended as reusable components.scope: true - the directive creates a new child scope that prototypically inherits from the parent scope.  If more than one directive (on the same DOM element) requests a new scope, only one new child scope is created.  Since we have ""normal"" prototypal inheritance, this is like ng-include and ng-switch, so be wary of 2-way data binding to parent scope primitives, and child scope hiding/shadowing of parent scope properties.scope: { ... } - the directive creates a new isolate/isolated scope.  It does not prototypically inherit.  This is usually your best choice when creating reusable components, since the directive cannot accidentally read or modify the parent scope.  However, such directives often need access to a few parent scope properties.  The object hash is used to set up two-way binding (using '=') or one-way binding (using '@') between the parent scope and the isolate scope.  There is also '&' to bind to parent scope expressions.  So, these all create local scope properties that are derived from the parent scope.Note that attributes are used to help set up the binding -- you can't just reference parent scope property names in the object hash, you have to use an attribute.  E.g., this won't work if you want to bind to parent property parentProp in the isolated scope: <div my-directive> and scope: { localProp: '@parentProp' }.  An attribute must be used to specify each parent property that the directive wants to bind to: <div my-directive the-Parent-Prop=parentProp> and scope: { localProp: '@theParentProp' }.Isolate scope's __proto__ references Object.Isolate scope's $parent references the parent scope, so although it is isolated and doesn't inherit prototypically from the parent scope, it is still a child scope.For the picture below we have<my-directive interpolated=""{{parentProp1}}"" twowayBinding=""parentProp2""> andscope: { interpolatedProp: '@interpolated', twowayBindingProp: '=twowayBinding' }Also, assume the directive does this in its linking function: scope.someIsolateProp = ""I'm isolated""For more information on isolate scopes see http://onehungrymind.com/angularjs-sticky-notes-pt-2-isolated-scope/transclude: true - the directive creates a new ""transcluded"" child scope, which prototypically inherits from the parent scope.  The transcluded and the isolated scope (if any) are siblings -- the $parent property of each scope references the same parent scope.  When a transcluded and an isolate scope both exist, isolate scope property $$nextSibling will reference the transcluded scope.  I'm not aware of any nuances with the transcluded scope.For the picture below, assume the same directive as above with this addition: transclude: trueThis fiddle has a showScope() function that can be used to examine an isolate and transcluded scope.  See the instructions in the comments in the fiddle.SummaryThere are four types of scopes:normal prototypal scope inheritance -- ng-include, ng-switch, ng-controller, directive with scope: truenormal prototypal scope inheritance with a copy/assignment -- ng-repeat.  Each iteration of ng-repeat creates a new child scope, and that new child scope always gets a new property.isolate scope -- directive with scope: {...}.  This one is not prototypal, but '=', '@', and '&' provide a mechanism to access parent scope properties, via attributes.transcluded scope -- directive with transclude: true.  This one is also normal prototypal scope inheritance, but it is also a sibling of any isolate scope.For all scopes (prototypal or not), Angular always tracks a parent-child relationship (i.e., a hierarchy), via properties $parent and $$childHead and $$childTail.Diagrams were generated with graphviz ""*.dot"" files, which are on github. Tim Caswell's ""Learning JavaScript with Object Graphs"" was the inspiration for using GraphViz for the diagrams. "
"data_i","edited Jun 15 '22 at 01:27","
        How can I navigate back to the last cursor position in Visual Studio Code?
    ","What is the keyboard shortcut to navigate back to the last cursor position in Visual Studio Code?","The keyboard shortcut commands are Go Forward and Go Back.On Windows:Alt + ← ... navigate backAlt + → ... navigate forwardOn Mac:Ctrl + - ... navigate backCtrl + Shift + - ... navigate forwardOn Ubuntu Linux:Ctrl + Alt + - .., navigate backCtrl + Shift + - ... navigate forward"
"data_i","edited Apr 19 '20 at 16:59","
        How do you comment out code in PowerShell?
    ","How do you comment out code in PowerShell (1.0 or 2.0)?","In PowerShell V1 there's only # to make the text after it a comment.# This is a comment in PowerShellIn PowerShell V2 <# #> can be used for block comments and more specifically for help comments.#REQUIRES -Version 2.0<#.SYNOPSIS    A brief description of the function or script. This keyword can be used    only once in each topic..DESCRIPTION    A detailed description of the function or script. This keyword can be    used only once in each topic..NOTES    File Name      : xxxx.ps1    Author         : J.P. Blanc (jean-paul_blanc@silogix-fr.com)    Prerequisite   : PowerShell V2 over Vista and upper.    Copyright 2011 - Jean Paul Blanc/Silogix.LINK    Script posted over:    http://silogix.fr.EXAMPLE    Example 1.EXAMPLE    Example 2#>Function blabla{}For more explanation about .SYNOPSIS and .* see about_Comment_Based_Help.Remark: These function comments are used by the Get-Help CmdLet and can be put before the keyword Function, or inside the {} before or after the code itself."
"data_i","edited Sep 25 '16 at 09:00","
        How do I rotate the Android emulator display?
    ","How can I rotate the Android emulator display to see it in landscape mode?","Windows: left Ctrl + F12Mac: Fn + Ctrl + F12"
"data_i","edited Oct 22 '15 at 17:13","
        'this' vs $scope in AngularJS controllers
    ","In the ""Create Components"" section of AngularJS's homepage, there is this example:controller: function($scope, $element) {  var panes = $scope.panes = [];  $scope.select = function(pane) {    angular.forEach(panes, function(pane) {      pane.selected = false;    });    pane.selected = true;  }  this.addPane = function(pane) {    if (panes.length == 0) $scope.select(pane);    panes.push(pane);  }}Notice how the select method is added to $scope, but the addPane method is added to this. If I change it to $scope.addPane, the code breaks.The documentation says that there in fact is a difference, but it doesn't mention what the difference is:Previous versions of Angular (pre 1.0 RC) allowed you to use this interchangeably with the $scope method, but this is no longer the case. Inside of methods defined on the scope this and $scope are interchangeable (angular sets this to $scope), but not otherwise inside your controller constructor.How does this and $scope work in AngularJS controllers?","""How does this and $scope work in AngularJS controllers?""Short answer:thisWhen the controller constructor function is called, this is the controller.When a function defined on a $scope object is called, this is the ""scope in effect when the function was called"".  This may (or may not!) be the $scope that the function is defined on.  So, inside the function, this and $scope may not be the same.$scopeEvery controller has an associated $scope object.A controller (constructor) function is responsible for setting model properties and functions/behaviour on its associated $scope.Only methods defined on this $scope object (and parent scope objects, if prototypical inheritance is in play) are accessible from the HTML/view.  E.g., from ng-click, filters, etc.Long answer:A controller function is a JavaScript constructor function.  When the constructor function executes (e.g., when a view loads), this (i.e., the ""function context"") is set to the controller object. So in the ""tabs"" controller constructor function, when the addPane function is createdthis.addPane = function(pane) { ... }it is created on the controller object, not on $scope.  Views cannot see the addPane function -- they only have access to functions defined on $scope.  In other words, in the HTML, this won't work:<a ng-click=""addPane(newPane)"">won't work</a>After the ""tabs"" controller constructor function executes, we have the following:The dashed black line indicates prototypal inheritance -- an isolate scope prototypically inherits from Scope.  (It does not prototypically inherit from the scope in effect where the directive was encountered in the HTML.)Now, the pane directive's link function wants to communicate with the tabs directive (which really means it needs to affect the tabs isolate $scope in some way).  Events could be used, but another mechanism is to have the pane directive require the tabs controller.  (There appears to be no mechanism for the pane directive to require the tabs $scope.)So, this begs the question: if we only have access to the tabs controller, how do we get access to the tabs isolate $scope (which is what we really want)?Well, the red dotted line is the answer.  The addPane() function's ""scope"" (I'm referring to JavaScript's function scope/closures here) gives the function access to the tabs isolate $scope.  I.e., addPane() has access to the ""tabs IsolateScope"" in the diagram above because of a closure that was created when addPane() was defined.  (If we instead defined addPane() on the tabs $scope object, the pane directive would not have access to this function, and hence it would have no way to communicate with the tabs $scope.)To answer the other part of your question: how does $scope work in controllers?:Within functions defined on $scope, this is set to ""the $scope in effect where/when the function was called"".  Suppose we have the following HTML:<div ng-controller=""ParentCtrl"">   <a ng-click=""logThisAndScope()"">log ""this"" and $scope</a> - parent scope   <div ng-controller=""ChildCtrl"">      <a ng-click=""logThisAndScope()"">log ""this"" and $scope</a> - child scope   </div></div>And the ParentCtrl (Solely) has$scope.logThisAndScope = function() {    console.log(this, $scope)}Clicking the first link will show that this and $scope are the same, since ""the scope in effect when the function was called"" is the scope associated with the ParentCtrl.Clicking the second link will reveal this and $scope are not the same, since ""the scope in effect when the function was called"" is the scope associated with the ChildCtrl.  So here, this is set to ChildCtrl's $scope.  Inside the method, $scope is still the ParentCtrl's $scope.FiddleI try to not use this inside of a function defined on $scope, as it becomes confusing which $scope is being affected, especially considering that ng-repeat, ng-include, ng-switch, and directives can all create their own child scopes."
"data_i","edited Mar 18 '20 at 10:02","
        What's the difference between git reset --mixed, --soft, and --hard?
    ","I'm looking to split a commit up and not sure which reset option to use.I was looking at the page In plain English, what does ""git reset"" do?, but I realized I don't really understand what the git index or staging area is and thus the explanations didn't help.Also, the use cases for --mixed and --soft look the same to me in that answer (when you want to fix and recommit). Can someone break it down even more?  I realize --mixed is probably the option to go with, but I want to know why. Lastly, what about --hard?Can someone give me a workflow example of how selecting the 3 options would happen?","When you modify a file in your repository, the change is initially unstaged. In order to commit it, you must stage it—that is, add it to the index—using git add. When you make a commit, the changes that are committed are those that have been added to the index.git reset changes, at minimum, where the current branch (HEAD) is pointing. The difference between --mixed and --soft is whether or not your index is also modified. So, if we're on branch master with this series of commits:- A - B - C (master)HEADpoints to C and the index matches C.When we run git reset --soft B, master (and thus HEAD) now points to B, but the index still has the changes from C; git status will show them as staged. So if we run git commit at this point, we'll get a new commit with the same changes as C.Okay, so starting from here again:- A - B - C (master)Now let's do git reset --mixed B. (Note: --mixed is the default option). Once again, master and HEAD point to B, but this time the index is also modified to match B. If we run git commit at this point, nothing will happen since the index matches HEAD. We still have the changes in the working directory, but since they're not in the index, git status shows them as unstaged. To commit them, you would git add and then commit as usual.And finally, --hard is the same as --mixed (it changes your HEAD and index), except that --hard also modifies your working directory. If we're at C and run git reset --hard B, then the changes added in C, as well as any uncommitted changes you have, will be removed, and the files in your working copy will match commit B. Since you can permanently lose changes this way, you should always run git status before doing a hard reset to make sure your working directory is clean or that you're okay with losing your uncommitted changes.And finally, a visualization:"
"data_i","edited Jun 30 '14 at 13:49","
        Difference between HashMap, LinkedHashMap and TreeMap
    ","What is the difference between HashMap, LinkedHashMap and TreeMap in Java? I don't see any difference in the output as all the three has keySet and values. What are Hashtables?Map m1 = new HashMap();m1.put(""map"", ""HashMap"");m1.put(""schildt"", ""java2"");m1.put(""mathew"", ""Hyden"");m1.put(""schildt"", ""java2s"");print(m1.keySet()); print(m1.values()); SortedMap sm = new TreeMap();sm.put(""map"", ""TreeMap"");sm.put(""schildt"", ""java2"");sm.put(""mathew"", ""Hyden"");sm.put(""schildt"", ""java2s"");print(sm.keySet()); print(sm.values());LinkedHashMap lm = new LinkedHashMap();lm.put(""map"", ""LinkedHashMap"");lm.put(""schildt"", ""java2"");lm.put(""mathew"", ""Hyden"");lm.put(""schildt"", ""java2s"");print(lm.keySet()); print(lm.values());","I prefer visual presentation:PropertyHashMapTreeMapLinkedHashMapIteration Orderno guaranteed order, will remain constant over timesorted according to the natural orderinginsertion-orderGet / put / remove / containsKeyO(1)O(log(n))O(1)InterfacesMapNavigableMap, Map, SortedMapMapNull values/keysallowedonly valuesallowedFail-fast behaviorFail-fast behavior of an iterator cannot be guaranteed, impossible to make any hard guarantees in the presence of unsynchronized concurrent modificationFail-fast behavior of an iterator cannot be guaranteed, impossible to make any hard guarantees in the presence of unsynchronized concurrent modificationFail-fast behavior of an iterator cannot be guaranteed, impossible to make any hard guarantees in the presence of unsynchronized concurrent modificationImplementationbucketsRed-Black Treedouble-linked bucketsIs synchronizedimplementation is not synchronizedimplementation is not synchronizedimplementation is not synchronized"
"data_i","edited Nov 05 '20 at 10:36","
        When to use static methods
    ","I am wondering when to use static methods? Say if I have a class with a few getters and setters, a method or two, and I want those methods only to be invokable on an instance object of the class. Does this mean I should use a static method?Example:Obj x = new Obj();x.someMethod();...or:Obj.someMethod(); // Is this the static way?I'm rather confused!","One rule-of-thumb: ask yourself ""Does it make sense to call this method, even if no object has been constructed yet?""  If so, it should definitely be static.So in a class Car you might have a method:double convertMpgToKpl(double mpg)...which would be static, because one might want to know what 35mpg converts to, even if nobody has ever built a Car.  But this method (which sets the efficiency of one particular Car):void setMileage(double mpg)...can't be static since it's inconceivable to call the method before any Car has been constructed.(By the way, the converse isn't always true: you might sometimes have a method which involves two Car objects, and still want it to be static.  E.g.:Car theMoreEfficientOf(Car c1, Car c2)Although this could be converted to a non-static version, some would argue that since there isn't a ""privileged"" choice of which Car is more important, you shouldn't force a caller to choose one Car as the object you'll invoke the method on.  This situation accounts for a fairly small fraction of all static methods, though."
"data_i","edited Dec 18 '21 at 10:16","
        How do I put an already-running process under nohup?
    ","I have a process that is already running for a long time and don't want to end it.How do I put it under nohup (that is, how do I cause it to continue running even if I close the terminal?)","Using the Job Control of bash to send the process into the background:Ctrl+Z to stop (pause) the program and get back to the shell.bg to run it in the background.disown -h [job-spec] where [job-spec] is the job number (like %1 for the first running job; find about your number with the jobs command) so that the job isn't killed when the terminal closes."
"data_i","edited Jun 09 '19 at 17:45","
        Angular HTML binding
    ","I am writing an Angular application and I have an HTML response I want to display. How do I do that? If I simply use the binding syntax {{myVal}} it encodes all HTML characters (of course).I need somehow to bind the innerHTML of a div to the variable value.","The correct syntax is the following:<div [innerHTML]=""theHtmlString""></div>Documentation Reference"
"data_i","edited Aug 03 '20 at 19:45","
        What is the correct way to check for string equality in JavaScript?
    ","What is the correct way to check for equality between Strings in JavaScript?","always Until you fully understand the differences and implications of using the == and === operators, use the === operator since it will save you from obscure (non-obvious) bugs and WTFs.  The ""regular"" == operator can have very unexpected results due to the type-coercion internally, so using === is always the recommended approach.For insight into this, and other ""good vs. bad"" parts of Javascript read up on Mr. Douglas Crockford and his work.  There's a great Google Tech Talk where he summarizes lots of good info: http://www.youtube.com/watch?v=hQVTIJBZookUpdate:The You Don't Know JS series by Kyle Simpson is excellent (and free to read online).  The series goes into the commonly misunderstood areas of the language and explains the ""bad parts"" that Crockford suggests you avoid.  By understanding them you can make proper use of them and avoid the pitfalls.The ""Up & Going"" book includes a section on Equality, with this specific summary of when to use the loose (==) vs strict (===) operators:To boil down a whole lot of details to a few simple takeaways, and help you know whether to use == or === in various situations, here are my simple rules:If either value (aka side) in a comparison could be the true or false value, avoid == and use ===.If either value in a comparison could be of these specific values (0, """", or [] -- empty array), avoid == and use ===.In all other cases, you're safe to use ==. Not only is it safe, but in many cases it simplifies your code in a way that improves readability.I still recommend Crockford's talk for developers who don't want to invest the time to really understand Javascript—it's good advice for a developer who only occasionally works in Javascript."
"data_i","edited Apr 17 '20 at 14:27","
        Use jQuery to hide a DIV when the user clicks outside of it
    ","I am using this code:$('body').click(function() {   $('.form_wrapper').hide();});$('.form_wrapper').click(function(event){   event.stopPropagation();});And this HTML:<div class=""form_wrapper"">   <a class=""agree"" href=""javascript:;"">I Agree</a>   <a class=""disagree"" href=""javascript:;"">Disagree</a></div>The problem is that I have links inside the div and when they no longer work when clicked.","Had the same problem, came up with this easy solution. It's even working recursive:$(document).mouseup(function(e) {    var container = $(""YOUR CONTAINER SELECTOR"");    // if the target of the click isn't the container nor a descendant of the container    if (!container.is(e.target) && container.has(e.target).length === 0)     {        container.hide();    }});"
"data_i","edited Aug 31 '22 at 11:13","
        Bash - Get Current Directory or Folder Name (Without Full Path) In Bash Script
    ","How could I retrieve the current working directory/folder name in a bash script, or even better, just a terminal command.pwd gives the full path of the current working directory, e.g. /opt/local/bin but I only want binThanks.","No need for basename, and especially no need for a subshell running pwd (which adds an extra, and expensive, fork operation); the shell can do this internally using parameter expansion:result=${PWD##*/}          # to assign to a variableresult=${result:-/}        # to correct for the case where PWD=/printf '%s\n' ""${PWD##*/}"" # to print to stdout                           # ...more robust than echo for unusual names                           #    (consider a directory named -e or -n)printf '%q\n' ""${PWD##*/}"" # to print to stdout, quoted for use as shell input                           # ...useful to make hidden characters readable.Note that if you're applying this technique in other circumstances (not PWD, but some other variable holding a directory name), you might need to trim any trailing slashes. The below uses bash's extglob support to work even with multiple trailing slashes:dirname=/path/to/somewhere//shopt -s extglob           # enable +(...) glob syntaxresult=${dirname%%+(/)}    # trim however many trailing slashes existresult=${result##*/}       # remove everything before the last / that still remainsresult=${result:-/}        # correct for dirname=/ caseprintf '%s\n' ""$result""Alternatively, without extglob:dirname=""/path/to/somewhere//""result=""${dirname%""${dirname##*[!/]}""}"" # extglob-free multi-trailing-/ trimresult=""${result##*/}""                  # remove everything before the last /result=${result:-/}                     # correct for dirname=/ case"
"data_i","edited Apr 17 '20 at 18:32","
        What's the difference between event.stopPropagation and event.preventDefault?
    ","They seem to be doing the same thing...Is one modern and one old? Or are they supported by different browsers?When I handle events myself (without framework) I just always check for both and execute both if present. (I also return false, but I have the feeling that doesn't work with events attached with node.addEventListener).So why both? Should I keep checking for both? Or is there actually a difference?(I know, a lot of questions, but they're all sort of the same =))","stopPropagation prevents further propagation of the current event in the capturing and bubbling phases.preventDefault prevents the default action the browser makes on that event.ExamplespreventDefault$(""#but"").click(function (event) {  event.preventDefault()})$(""#foo"").click(function () {  alert(""parent click event fired!"")})<script src=""https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js""></script><div id=""foo"">  <button id=""but"">button</button></div>stopPropagation$(""#but"").click(function (event) {  event.stopPropagation()})$(""#foo"").click(function () {  alert(""parent click event fired!"")})<script src=""https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js""></script><div id=""foo"">  <button id=""but"">button</button></div>With stopPropagation, only the button's click handler is called while the div's click handler never fires.Where as if you use preventDefault, only the browser's default action is stopped but the div's click handler still fires.Below are some docs on the DOM event properties and methods from MDN:event.cancelBubbleevent.preventDefault()event.returnValueevent.stopPropagation()For IE9 and FF you can just use preventDefault & stopPropagation.To support IE8 and lower replace stopPropagation with cancelBubble and replace preventDefault with returnValue"
"data_i","edited Sep 19 '19 at 11:56","
        What is the difference between JDK and JRE?
    ","What is the difference between JDK and JRE?What are their roles and when should I use one or the other?","The JRE is the Java Runtime Environment. It is a package of everything necessary to run a compiled Java program, including the Java Virtual Machine (JVM), the Java Class Library, the java command, and other infrastructure. However, it cannot be used to create new programs.The JDK is the Java Development Kit, the full-featured SDK for Java. It has everything the JRE has, but also the compiler (javac) and tools (like javadoc and jdb). It is capable of creating and compiling programs.Usually, if you only care about running Java programs on computer you will only install the JRE. It's all you need. On the other hand, if you are planning to do some Java programming, you need to install the JDK instead. Sometimes, even if you are not planning to do any Java development on a computer, you still need the JDK installed. For example, if you are deploying a web application with JSP, you are technically just running Java programs inside the application server. Why would you need the JDK then? Because the application server will convert JSP into Java servlets and needs to use the JDK to compile the servlets. I am sure that there are more examples."
"data_i","edited Feb 06 '18 at 12:29","
        How do I redirect with JavaScript?
    ","How do you redirect to a page from another page with JavaScript?","To redirect to another page, you can use:window.location = ""http://www.yoururl.com"";"
"data_i","edited Jun 29 '16 at 04:04","
        How to copy commits from one branch to another?
    ","I've got two branches from my master:v2.1: (version 2) I've been working on for several monthswss: that I created yesterday to add one specific feature to my master (in production)Is there a way to copy yesterday's commits from wss to v2.1?","Use git cherry-pick <commit>to apply <commit> to your current branch. I myself would probably cross-check the commits I pick in gitk and cherry-pick them with right-clicks on the commit entry there instead.If you want to go more automatic (with all its dangers) and assuming all commits since yesterday happened on wss you could generate the list of commits using git log (with --pretty suggested by Jefromi)git log --reverse --since=yesterday --pretty=%Hso everything together assuming you use bashfor commit in $(git log --reverse --since=yesterday --pretty=%H);do    git cherry-pick $commitdoneIf something goes wrong here (there is a lot of potential) you are in trouble since this works on the live checkout, so either do manual cherry-picks or use rebase like suggested by Jefromi."
"data_i","edited Jun 24 '22 at 16:36","
        Make body have 100% of the browser height
    ","I want to make body have 100% of the browser height. Can I do that using CSS?I tried setting height: 100%, but it doesn't work.I want to set a background color for a page to fill the entire browser window, but if the page has little content I get a ugly white bar at the bottom.","Try setting the height of the html element to 100% as well. html, body {    height: 100%;}Body looks to its parent (HTML) for how to scale the dynamic property, so the HTML element needs to have its height set as well. However the content of body will probably need to change dynamically.Setting min-height to 100% will accomplish this goal.html {  height: 100%;}body {  min-height: 100%;}"
"data_i","edited Apr 17 '20 at 14:21","
        Constants in Objective-C
    ","I'm developing a Cocoa application, and I'm using constant NSStrings as ways to store key names for my preferences.I understand this is a good idea because it allows easy changing of keys if necessary.Plus, it's the whole 'separate your data from your logic' notion.Anyway, is there a good way to make these constants defined once for the whole application?  I'm sure that there's an easy and intelligent way, but right now my classes just redefine the ones they use. ","You should create a header file like:// Constants.hFOUNDATION_EXPORT NSString *const MyFirstConstant;FOUNDATION_EXPORT NSString *const MySecondConstant;//etc.(You can use extern instead of FOUNDATION_EXPORT if your code will not be used in mixed C/C++ environments or on other platforms.)You can include this file in each file that uses the constants or in the pre-compiled header for the project.You define these constants in a .m file like:// Constants.mNSString *const MyFirstConstant = @""FirstConstant"";NSString *const MySecondConstant = @""SecondConstant"";Constants.m should be added to your application/framework's target so that it is linked in to the final product.The advantage of using string constants instead of #define'd constants is that you can test for equality using pointer comparison (stringInstance == MyFirstConstant) which is much faster than string comparison ([stringInstance isEqualToString:MyFirstConstant]) (and easier to read, IMO)."
"data_i","edited Apr 17 '22 at 02:14","
        How do I check file size in Python?
    ","How do I get the size of a file in Python?","Use os.path.getsize:>>> import os>>> os.path.getsize(""/path/to/file.mp3"")2071611The output is in bytes."
"data_i","edited Jan 25 '16 at 09:33","
        How do I use vim registers?
    ","I only know of one instance using registers is via CtrlR* whereby I paste text from a clipboard. What are other uses of registers? How to use them? Everything you know about VI registers (let's focus on vi 7.2) -- share with us.","Registers in Vim let you run actions or commands on text stored within them.  To access a register, you type ""a before a command, where a is the name of a register.  If you want to copy the current line into register k, you can type""kyyOr you can append to a register by using a capital letter""KyyYou can then move through the document and paste it elsewhere using""kpTo paste from system clipboard on Linux""+pTo paste from system clipboard on Windows (or from ""mouse highlight"" clipboard on Linux)""*pTo access all currently defined registers type:reg"
"data_i","edited Jul 23 '13 at 23:56","
        Best way to use Google's hosted jQuery, but fall back to my hosted library on Google fail
    ","What would be a good way to attempt to load the hosted jQuery at Google (or other Google hosted libs), but load my copy of jQuery if the Google attempt fails?I'm not saying Google is flaky. There are cases where the Google copy is blocked (apparently in Iran, for instance).Would I set up a timer and check for the jQuery object?What would be the danger of both copies coming through?Not really looking for answers like ""just use the Google one"" or ""just use your own."" I understand those arguments. I also understand that the user is likely to have the Google version cached. I'm thinking about fallbacks for the cloud in general.Edit: This part added...Since Google suggests using google.load to load the ajax libraries, and it performs a callback when done, I'm wondering if that's the key to serializing this problem.I know it sounds a bit crazy. I'm just trying to figure out if it can be done in a reliable way or not.Update: jQuery now hosted on Microsoft's CDN.http://www.asp.net/ajax/cdn/","You can achieve it like this:<script src=""https://ajax.googleapis.com/ajax/libs/jquery/1.2.6/jquery.min.js""></script><script>       window.jQuery || document.write('<script src=""/path/to/your/jquery""><\/script>');</script>This should be in your page's <head> and any jQuery ready event handlers should be in the <body> to avoid errors (although it's not fool-proof!).One more reason to not use Google-hosted jQuery is that in some countries, Google's domain name is banned."
"data_i","edited Jul 09 '18 at 21:52","
        Why can't I use switch statement on a String?
    ","Is this functionality going to be put into a later Java version?Can someone explain why I can't do this, as in, the technical way Java's switch statement works?","Switch statements with String cases have been implemented in Java SE 7, at least 16 years after they were first requested. A clear reason for the delay was not provided, but it likely had to do with performance.Implementation in JDK 7The feature has now been implemented in javac with a ""de-sugaring"" process; a clean, high-level syntax using String constants in case declarations is expanded at compile-time into more complex code following a pattern. The resulting code uses JVM instructions that have always existed.A switch with String cases is translated into two switches during compilation. The first maps each string to a unique integer—its position in the original switch. This is done by first switching on the hash code of the label. The corresponding case is an if statement that tests string equality; if there are collisions on the hash, the test is a cascading if-else-if. The second switch mirrors that in the original source code, but substitutes the case labels with their corresponding positions. This two-step process makes it easy to preserve the flow control of the original switch.Switches in the JVMFor more technical depth on switch, you can refer to the JVM Specification, where the compilation of switch statements is described. In a nutshell, there are two different JVM instructions that can be used for a switch, depending on the sparsity of the constants used by the cases. Both depend on using integer constants for each case to execute efficiently.If the constants are dense, they are used as an index (after subtracting the lowest value) into a table of instruction pointers—the tableswitch instruction.If the constants are sparse, a binary search for the correct case is performed—the lookupswitch instruction.In de-sugaring a switch on String objects, both instructions are likely to be used. The lookupswitch is suitable for the first switch on hash codes to find the original position of the case. The resulting ordinal is a natural fit for a tableswitch.Both instructions require the integer constants assigned to each case to be sorted at compile time. At runtime, while the O(1) performance of tableswitch generally appears better than the O(log(n)) performance of lookupswitch, it requires some analysis to determine whether the table is dense enough to justify the space–time tradeoff. Bill Venners wrote a great article that covers this in more detail, along with an under-the-hood look at other Java flow control instructions.Before JDK 7Prior to JDK 7, enum could approximate a String-based switch. This uses the static valueOf method generated by the compiler on every enum type. For example:Pill p = Pill.valueOf(str);switch(p) {  case RED:  pop();  break;  case BLUE: push(); break;}"
"data_i","edited Apr 28 '17 at 07:01","
        How do I duplicate a line or selection within Visual Studio Code?
    ","Using Microsoft's Visual Studio Code, how do I duplicate a line of code and then move it up and down? (Similar to Sublime's cmd+shift+d behaviour)It's a feature that I use constantly, and am struggling using Visual Studio Code without it.","The commands your are looking for are editor.action.copyLinesDownAction and editor.action.copyLinesUpAction. You can see the associated keybindings by picking: File > Preferences > Keyboard Shortcuts Windows: Shift+Alt+Down and Shift+Alt+UpMac:Shift+Option+Down and Shift+OptionUpLinux:Ctrl+Shift+Alt+Down and Ctrl+Shift+Alt+Up(Might need to use numpad Down and Up for Linux)Furthermore, commands editor.action.moveLinesUpAction and editor.action.moveLinesDownAction are the ones to move lines and they are bound to Alt+Down and Alt+Up on Windows and Mac and Ctrl+Down and Ctrl+Up on Linux. "
"data_i","edited Sep 18 '21 at 18:08","
        How to permanently set $PATH on Linux/Unix
    ","On Linux, how can I add a directory to the $PATH so it remains persistent across different sessions?BackgroundI'm trying to add a directory to my path so it will always be in my Linux path. I've tried:export PATH=$PATH:/path/to/dirThis works, however each time I exit the terminal and start a new terminal instance, this path is lost, and I need to run the export command again.How can I do it so this will be set permanently?","You need to add it to your ~/.profile or ~/.bashrc file. export PATH=""$PATH:/path/to/dir""Depending on what you're doing, you also may want to symlink to binaries:cd /usr/binsudo ln -s /path/to/binary binary-nameNote that this will not automatically update your path for the remainder of the session. To do this, you should run:source ~/.profile orsource ~/.bashrc"
"data_i","edited Oct 22 '21 at 12:51","
        Shell: How to call one shell script from another shell script?
    ","I have two shell scripts, a.sh and b.sh.How can I call b.sh from within the shell script a.sh?","There are a couple of different ways you can do this:Make the other script executable, add the #!/bin/bash line at the top, and the path where the file is to the $PATH environment variable. Then you can call it as a normal command;Or call it with the source command (alias is .), like this:source /path/to/scriptOr use the bash command to execute it, like:/bin/bash /path/to/scriptThe first and third approaches execute the script as another process, so variables and functions in the other script will not be accessible.The second approach executes the script in the first script's process, and pulls in variables and functions from the other script (so they are usable from the calling script).In the second method, if you are using exit in second script, it will exit the first script as well. Which will not happen in first and third methods."
"data_i","edited Jul 14 '16 at 12:38","
        Why is setTimeout(fn, 0) sometimes useful?
    ","I've recently run into a rather nasty bug, wherein the code was loading a <select> dynamically via JavaScript.  This dynamically loaded <select> had a pre-selected value.  In IE6, we already had code to fix the selected <option>, because sometimes the <select>'s selectedIndex value would be out of sync with the selected <option>'s index attribute, as below:field.selectedIndex = element.index;However, this code wasn't working.  Even though the field's selectedIndex was being set correctly, the wrong index would end up being selected.  However, if I stuck an alert() statement in at the right time, the correct option would be selected.  Thinking this might be some sort of timing issue, I tried something random that I'd seen in code before:var wrapFn = (function() {    var myField = field;    var myElement = element;    return function() {        myField.selectedIndex = myElement.index;    }})();setTimeout(wrapFn, 0);And this worked!I've got a solution for my problem, but I'm uneasy that I don't know exactly why this fixes my problem.  Does anyone have an official explanation?  What browser issue am I avoiding by calling my function ""later"" using setTimeout()?","In the question, there existed a race condition between:The browser's attempt to initialize the drop-down list, ready to have its selected index updated, andYour code to set the selected indexYour code was consistently winning this race and attempting to set drop-down selection before the browser was ready, meaning that the bug would appear.This race existed because JavaScript has a single thread of execution that is shared with page rendering. In effect, running JavaScript blocks the updating of the DOM.Your workaround was:setTimeout(callback, 0)Invoking setTimeout with a callback, and zero as the second argument will schedule the callback to be run asynchronously, after the shortest possible delay - which will be around 10ms when the tab has focus and the JavaScript thread of execution is not busy.The OP's solution, therefore was to delay by about 10ms, the setting of the selected index. This gave the browser an opportunity to initialize the DOM, fixing the bug.Every version of Internet Explorer exhibited quirky behaviors and this kind of workaround was necessary at times. Alternatively it might have been a genuine bug in the OP's codebase. See Philip Roberts talk ""What the heck is the event loop?"" for more thorough explanation."
"data_i","edited Mar 13 '21 at 18:11","
        How to emulate a do-while loop?
    ","I need to emulate a do-while loop in a Python program. Unfortunately, the following straightforward code does not work:list_of_ints = [ 1, 2, 3 ]iterator = list_of_ints.__iter__()element = Nonewhile True:  if element:    print element  try:    element = iterator.next()  except StopIteration:    breakprint ""done""Instead of ""1,2,3,done"", it prints the following output:[stdout:]1[stdout:]2[stdout:]3None['Traceback (most recent call last):', '  File ""test_python.py"", line 8, in <module>    s = i.next()', 'StopIteration']What can I do in order to catch the 'stop iteration' exception and break a whileloop properly?An example of why such a thing may be needed is shown below as pseudocode.State machine:s = """"while True :  if state is STATE_CODE :    if ""//"" in s :      tokens.add( TOKEN_COMMENT, s.split( ""//"" )[1] )      state = STATE_COMMENT    else :      tokens.add( TOKEN_CODE, s )  if state is STATE_COMMENT :    if ""//"" in s :      tokens.append( TOKEN_COMMENT, s.split( ""//"" )[1] )    else      state = STATE_CODE      # Re-evaluate same line      continue  try :    s = i.next()  except StopIteration :    break","I am not sure what you are trying to do. You can implement a do-while loop like this:while True:  stuff()  if fail_condition:    breakOr:stuff()while not fail_condition:  stuff()What are you doing trying to use a do while loop to print the stuff in the list? Why not just use:for i in l:  print iprint ""done""Update:So do you have a list of lines? And you want to keep iterating through it? How about: for s in l:   while True:     stuff()     # use a ""break"" instead of s = i.next()Does that seem like something close to what you would want? With your code example, it would be:for s in some_list:  while True:    if state is STATE_CODE:      if ""//"" in s:        tokens.add( TOKEN_COMMENT, s.split( ""//"" )[1] )        state = STATE_COMMENT      else :        tokens.add( TOKEN_CODE, s )    if state is STATE_COMMENT:      if ""//"" in s:        tokens.append( TOKEN_COMMENT, s.split( ""//"" )[1] )        break # get next s      else:        state = STATE_CODE        # re-evaluate same line        # continues automatically"
"data_i","edited Nov 12 '17 at 10:09","
        Check whether a string matches a regex in JS
    ","I want to use JavaScript (can be with jQuery) to do some client-side validation to check whether a string matches the regex:^([a-z0-9]{5,})$Ideally it would be an expression that returned true or false. I'm a JavaScript newbie, does match() do what I need? It seems to check whether part of a string matches a regex, not the whole thing. ","Use regex.test() if all you want is a boolean result:console.log(/^([a-z0-9]{5,})$/.test('abc1')); // falseconsole.log(/^([a-z0-9]{5,})$/.test('abc12')); // trueconsole.log(/^([a-z0-9]{5,})$/.test('abc123')); // true...and you could remove the () from your regexp since you've no need for a capture."
"data_i","edited Apr 12 '17 at 15:56","
        Find all files in a directory with extension .txt in Python
    ","How can I find all the files in a directory having the extension .txt in python?","You can use glob:import glob, osos.chdir(""/mydir"")for file in glob.glob(""*.txt""):    print(file)or simply os.listdir:import osfor file in os.listdir(""/mydir""):    if file.endswith("".txt""):        print(os.path.join(""/mydir"", file))or if you want to traverse directory, use os.walk:import osfor root, dirs, files in os.walk(""/mydir""):    for file in files:        if file.endswith("".txt""):             print(os.path.join(root, file))"
"data_i","edited Apr 11 '20 at 10:44","
        How to dispatch a Redux action with a timeout?
    ","I have an action that updates the notification state of my application. Usually, this notification will be an error or info of some sort. I need to then dispatch another action after 5 seconds that will return the notification state to the initial one, so no notification. The main reason behind this is to provide functionality where notifications disappear automatically after 5 seconds.I had no luck with using setTimeout and returning another action and can't find how this is done online. So any advice is welcome.","Don’t fall into the trap of thinking a library should prescribe how to do everything. If you want to do something with a timeout in JavaScript, you need to use setTimeout. There is no reason why Redux actions should be any different.Redux does offer some alternative ways of dealing with asynchronous stuff, but you should only use those when you realize you are repeating too much code. Unless you have this problem, use what the language offers and go for the simplest solution.Writing Async Code InlineThis is by far the simplest way. And there’s nothing specific to Redux here.store.dispatch({ type: 'SHOW_NOTIFICATION', text: 'You logged in.' })setTimeout(() => {  store.dispatch({ type: 'HIDE_NOTIFICATION' })}, 5000)Similarly, from inside a connected component:this.props.dispatch({ type: 'SHOW_NOTIFICATION', text: 'You logged in.' })setTimeout(() => {  this.props.dispatch({ type: 'HIDE_NOTIFICATION' })}, 5000)The only difference is that in a connected component you usually don’t have access to the store itself, but get either dispatch() or specific action creators injected as props. However this doesn’t make any difference for us.If you don’t like making typos when dispatching the same actions from different components, you might want to extract action creators instead of dispatching action objects inline:// actions.jsexport function showNotification(text) {  return { type: 'SHOW_NOTIFICATION', text }}export function hideNotification() {  return { type: 'HIDE_NOTIFICATION' }}// component.jsimport { showNotification, hideNotification } from '../actions'this.props.dispatch(showNotification('You just logged in.'))setTimeout(() => {  this.props.dispatch(hideNotification())}, 5000)Or, if you have previously bound them with connect():this.props.showNotification('You just logged in.')setTimeout(() => {  this.props.hideNotification()}, 5000)So far we have not used any middleware or other advanced concept. Extracting Async Action CreatorThe approach above works fine in simple cases but you might find that it has a few problems:It forces you to duplicate this logic anywhere you want to show a notification.The notifications have no IDs so you’ll have a race condition if you show two notifications fast enough. When the first timeout finishes, it will dispatch HIDE_NOTIFICATION, erroneously hiding the second notification sooner than after the timeout.To solve these problems, you would need to extract a function that centralizes the timeout logic and dispatches those two actions. It might look like this:// actions.jsfunction showNotification(id, text) {  return { type: 'SHOW_NOTIFICATION', id, text }}function hideNotification(id) {  return { type: 'HIDE_NOTIFICATION', id }}let nextNotificationId = 0export function showNotificationWithTimeout(dispatch, text) {  // Assigning IDs to notifications lets reducer ignore HIDE_NOTIFICATION  // for the notification that is not currently visible.  // Alternatively, we could store the timeout ID and call  // clearTimeout(), but we’d still want to do it in a single place.  const id = nextNotificationId++  dispatch(showNotification(id, text))  setTimeout(() => {    dispatch(hideNotification(id))  }, 5000)}Now components can use showNotificationWithTimeout without duplicating this logic or having race conditions with different notifications:// component.jsshowNotificationWithTimeout(this.props.dispatch, 'You just logged in.')// otherComponent.jsshowNotificationWithTimeout(this.props.dispatch, 'You just logged out.')    Why does showNotificationWithTimeout() accept dispatch as the first argument? Because it needs to dispatch actions to the store. Normally a component has access to dispatch but since we want an external function to take control over dispatching, we need to give it control over dispatching.If you had a singleton store exported from some module, you could just import it and dispatch directly on it instead:// store.jsexport default createStore(reducer)// actions.jsimport store from './store'// ...let nextNotificationId = 0export function showNotificationWithTimeout(text) {  const id = nextNotificationId++  store.dispatch(showNotification(id, text))  setTimeout(() => {    store.dispatch(hideNotification(id))  }, 5000)}// component.jsshowNotificationWithTimeout('You just logged in.')// otherComponent.jsshowNotificationWithTimeout('You just logged out.')    This looks simpler but we don’t recommend this approach. The main reason we dislike it is because it forces store to be a singleton. This makes it very hard to implement server rendering. On the server, you will want each request to have its own store, so that different users get different preloaded data.A singleton store also makes testing harder. You can no longer mock a store when testing action creators because they reference a specific real store exported from a specific module. You can’t even reset its state from outside.So while you technically can export a singleton store from a module, we discourage it. Don’t do this unless you are sure that your app will never add server rendering.Getting back to the previous version:// actions.js// ...let nextNotificationId = 0export function showNotificationWithTimeout(dispatch, text) {  const id = nextNotificationId++  dispatch(showNotification(id, text))  setTimeout(() => {    dispatch(hideNotification(id))  }, 5000)}// component.jsshowNotificationWithTimeout(this.props.dispatch, 'You just logged in.')// otherComponent.jsshowNotificationWithTimeout(this.props.dispatch, 'You just logged out.')    This solves the problems with duplication of logic and saves us from race conditions.Thunk MiddlewareFor simple apps, the approach should suffice. Don’t worry about middleware if you’re happy with it.In larger apps, however, you might find certain inconveniences around it.For example, it seems unfortunate that we have to pass dispatch around. This makes it trickier to separate container and presentational components because any component that dispatches Redux actions asynchronously in the manner above has to accept dispatch as a prop so it can pass it further. You can’t just bind action creators with connect() anymore because showNotificationWithTimeout() is not really an action creator. It does not return a Redux action.In addition, it can be awkward to remember which functions are synchronous action creators like showNotification() and which are asynchronous helpers like showNotificationWithTimeout(). You have to use them differently and be careful not to mistake them with each other.This was the motivation for finding a way to “legitimize” this pattern of providing dispatch to a helper function, and help Redux “see” such asynchronous action creators as a special case of normal action creators rather than totally different functions.If you’re still with us and you also recognize as a problem in your app, you are welcome to use the Redux Thunk middleware.In a gist, Redux Thunk teaches Redux to recognize special kinds of actions that are in fact functions:import { createStore, applyMiddleware } from 'redux'import thunk from 'redux-thunk'const store = createStore(  reducer,  applyMiddleware(thunk))// It still recognizes plain object actionsstore.dispatch({ type: 'INCREMENT' })// But with thunk middleware, it also recognizes functionsstore.dispatch(function (dispatch) {  // ... which themselves may dispatch many times  dispatch({ type: 'INCREMENT' })  dispatch({ type: 'INCREMENT' })  dispatch({ type: 'INCREMENT' })  setTimeout(() => {    // ... even asynchronously!    dispatch({ type: 'DECREMENT' })  }, 1000)})When this middleware is enabled, if you dispatch a function, Redux Thunk middleware will give it dispatch as an argument. It will also “swallow” such actions so don’t worry about your reducers receiving weird function arguments. Your reducers will only receive plain object actions—either emitted directly, or emitted by the functions as we just described.This does not look very useful, does it? Not in this particular situation. However it lets us declare showNotificationWithTimeout() as a regular Redux action creator:// actions.jsfunction showNotification(id, text) {  return { type: 'SHOW_NOTIFICATION', id, text }}function hideNotification(id) {  return { type: 'HIDE_NOTIFICATION', id }}let nextNotificationId = 0export function showNotificationWithTimeout(text) {  return function (dispatch) {    const id = nextNotificationId++    dispatch(showNotification(id, text))    setTimeout(() => {      dispatch(hideNotification(id))    }, 5000)  }}Note how the function is almost identical to the one we wrote in the previous section. However it doesn’t accept dispatch as the first argument. Instead it returns a function that accepts dispatch as the first argument.How would we use it in our component? Definitely, we could write this:// component.jsshowNotificationWithTimeout('You just logged in.')(this.props.dispatch)We are calling the async action creator to get the inner function that wants just dispatch, and then we pass dispatch.However this is even more awkward than the original version! Why did we even go that way?Because of what I told you before. If Redux Thunk middleware is enabled, any time you attempt to dispatch a function instead of an action object, the middleware will call that function with dispatch method itself as the first argument.So we can do this instead:// component.jsthis.props.dispatch(showNotificationWithTimeout('You just logged in.'))Finally, dispatching an asynchronous action (really, a series of actions) looks no different than dispatching a single action synchronously to the component. Which is good because components shouldn’t care whether something happens synchronously or asynchronously. We just abstracted that away.Notice that since we “taught” Redux to recognize such “special” action creators (we call them thunk action creators), we can now use them in any place where we would use regular action creators. For example, we can use them with connect():// actions.jsfunction showNotification(id, text) {  return { type: 'SHOW_NOTIFICATION', id, text }}function hideNotification(id) {  return { type: 'HIDE_NOTIFICATION', id }}let nextNotificationId = 0export function showNotificationWithTimeout(text) {  return function (dispatch) {    const id = nextNotificationId++    dispatch(showNotification(id, text))    setTimeout(() => {      dispatch(hideNotification(id))    }, 5000)  }}// component.jsimport { connect } from 'react-redux'// ...this.props.showNotificationWithTimeout('You just logged in.')// ...export default connect(  mapStateToProps,  { showNotificationWithTimeout })(MyComponent)Reading State in ThunksUsually your reducers contain the business logic for determining the next state. However, reducers only kick in after the actions are dispatched. What if you have a side effect (such as calling an API) in a thunk action creator, and you want to prevent it under some condition?Without using the thunk middleware, you’d just do this check inside the component:// component.jsif (this.props.areNotificationsEnabled) {  showNotificationWithTimeout(this.props.dispatch, 'You just logged in.')}However, the point of extracting an action creator was to centralize this repetitive logic across many components. Fortunately, Redux Thunk offers you a way to read the current state of the Redux store. In addition to dispatch, it also passes getState as the second argument to the function you return from your thunk action creator. This lets the thunk read the current state of the store.let nextNotificationId = 0export function showNotificationWithTimeout(text) {  return function (dispatch, getState) {    // Unlike in a regular action creator, we can exit early in a thunk    // Redux doesn’t care about its return value (or lack of it)    if (!getState().areNotificationsEnabled) {      return    }    const id = nextNotificationId++    dispatch(showNotification(id, text))    setTimeout(() => {      dispatch(hideNotification(id))    }, 5000)  }}Don’t abuse this pattern. It is good for bailing out of API calls when there is cached data available, but it is not a very good foundation to build your business logic upon. If you use getState() only to conditionally dispatch different actions, consider putting the business logic into the reducers instead.Next StepsNow that you have a basic intuition about how thunks work, check out Redux async example which uses them.You may find many examples in which thunks return Promises. This is not required but can be very convenient. Redux doesn’t care what you return from a thunk, but it gives you its return value from dispatch(). This is why you can return a Promise from a thunk and wait for it to complete by calling dispatch(someThunkReturningPromise()).then(...).You may also split complex thunk action creators into several smaller thunk action creators. The dispatch method provided by thunks can accept thunks itself, so you can apply the pattern recursively. Again, this works best with Promises because you can implement asynchronous control flow on top of that.For some apps, you may find yourself in a situation where your asynchronous control flow requirements are too complex to be expressed with thunks. For example, retrying failed requests, reauthorization flow with tokens, or a step-by-step onboarding can be too verbose and error-prone when written this way. In this case, you might want to look at more advanced asynchronous control flow solutions such as Redux Saga or Redux Loop. Evaluate them, compare the examples relevant to your needs, and pick the one you like the most.Finally, don’t use anything (including thunks) if you don’t have the genuine need for them. Remember that, depending on the requirements, your solution might look as simple asstore.dispatch({ type: 'SHOW_NOTIFICATION', text: 'You logged in.' })setTimeout(() => {  store.dispatch({ type: 'HIDE_NOTIFICATION' })}, 5000)Don’t sweat it unless you know why you’re doing this."
"data_i","edited Sep 23 '19 at 09:35","
        How do I remove/delete a folder that is not empty?
    ","I am getting an 'access is denied' error when I attempt to delete a folder that is not empty. I used the following command in my attempt: os.remove(""/folder_name""). What is the most effective way of removing/deleting a folder/directory that is not empty?","import shutilshutil.rmtree('/folder_name')Standard Library Reference: shutil.rmtree.By design, rmtree fails on folder trees containing read-only files. If you want the folder to be deleted regardless of whether it contains read-only files, then useshutil.rmtree('/folder_name', ignore_errors=True)"
"data_i","edited Apr 10 '22 at 13:07","
        List comprehension vs. lambda + filter
    ","I have a list that I want to filter by an attribute of the items.Which of the following is preferred (readability, performance, other reasons)?xs = [x for x in xs if x.attribute == value]xs = filter(lambda x: x.attribute == value, xs)","It is strange how much beauty varies for different people. I find the list comprehension much clearer than filter+lambda, but use whichever you find easier.There are two things that may slow down your use of filter.The first is the function call overhead: as soon as you use a Python function (whether created by def or lambda) it is likely that filter will be slower than the list comprehension. It almost certainly is not enough to matter, and you shouldn't think much about performance until you've timed your code and found it to be a bottleneck, but the difference will be there.The other overhead that might apply is that the lambda is being forced to access a scoped variable (value). That is slower than accessing a local variable and in Python 2.x the list comprehension only accesses local variables. If you are using Python 3.x the list comprehension runs in a separate function so it will also be accessing value through a closure and this difference won't apply.The other option to consider is to use a generator instead of a list comprehension:def filterbyvalue(seq, value):   for el in seq:       if el.attribute==value: yield elThen in your main code (which is where readability really matters) you've replaced both list comprehension and filter with a hopefully meaningful function name."
"data_i","edited Aug 12 '18 at 12:32","
        Remove rows with all or some NAs (missing values) in data.frame
    ","I'd like to remove the lines in this data frame that:a) contain NAs across all columns. Below is my example data frame.              gene hsap mmul mmus rnor cfam1 ENSG00000208234    0   NA   NA   NA   NA2 ENSG00000199674    0   2    2    2    23 ENSG00000221622    0   NA   NA   NA   NA4 ENSG00000207604    0   NA   NA   1    25 ENSG00000207431    0   NA   NA   NA   NA6 ENSG00000221312    0   1    2    3    2Basically, I'd like to get a data frame such as the following.             gene hsap mmul mmus rnor cfam2 ENSG00000199674    0   2    2    2    26 ENSG00000221312    0   1    2    3    2b) contain NAs in only some columns, so I can also get this result:             gene hsap mmul mmus rnor cfam2 ENSG00000199674    0   2    2    2    24 ENSG00000207604    0   NA   NA   1    26 ENSG00000221312    0   1    2    3    2","Also check complete.cases :> final[complete.cases(final), ]             gene hsap mmul mmus rnor cfam2 ENSG00000199674    0    2    2    2    26 ENSG00000221312    0    1    2    3    2na.omit is nicer for just removing all NA's. complete.cases allows partial selection by including only certain columns of the dataframe:> final[complete.cases(final[ , 5:6]),]             gene hsap mmul mmus rnor cfam2 ENSG00000199674    0    2    2    2    24 ENSG00000207604    0   NA   NA    1    26 ENSG00000221312    0    1    2    3    2Your solution can't work. If you insist on using is.na, then you have to do something like:> final[rowSums(is.na(final[ , 5:6])) == 0, ]             gene hsap mmul mmus rnor cfam2 ENSG00000199674    0    2    2    2    24 ENSG00000207604    0   NA   NA    1    26 ENSG00000221312    0    1    2    3    2but using complete.cases is quite a lot more clear, and faster."
"data_i","edited Nov 08 '21 at 10:21","
        How to list all commits that changed a specific file?
    ","Is there a way to list all commits that changed a specific file?","The --follow works for a particular filegit log --follow -- filenameDifference to other solutions givenNote that other solutions include git log path (without the --follow). That approach is handy if you want to track e.g. changes in a directory, but stumbles when files were renamed (thus use --follow filename)."
